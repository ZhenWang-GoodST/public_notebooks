TY  - CONF
TI  - Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4825
EP  - 4832
AU  - A. Naz
AU  - B. Piranda
AU  - J. Bourgeois
AU  - S. C. Goldstein
PY  - 2018
KW  - approximation theory
KW  - distributed control
KW  - embedded systems
KW  - large-scale systems
KW  - mobile robots
KW  - multi-robot systems
KW  - tree searching
KW  - asynchronous distributed embedded systems
KW  - distributed system coordination
KW  - approximation algorithm
KW  - memory per node
KW  - neighboring modules
KW  - lattice structure
KW  - resource-constrained identical modules
KW  - distributed modular robotic ensembles
KW  - huge modular robot
KW  - large-scale systems
KW  - hardware modular robots
KW  - approximate-center node
KW  - k-BFS SumSweep algorithm
KW  - Approximation algorithms
KW  - Robot kinematics
KW  - Voting
KW  - Heuristic algorithms
KW  - Probabilistic logic
KW  - Embedded systems
KW  - Distributed algorithm
KW  - Modular robots
KW  - Center election
DO  - 10.1109/IROS.2018.8593612
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.
ER  - 

TY  - CONF
TI  - A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4833
EP  - 4839
AU  - F. Morbidi
AU  - E. Bretagne
PY  - 2018
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - position control
KW  - trajectory control
KW  - multiagent systems
KW  - classification task
KW  - conventional centered wheel
KW  - distance-bearing formations
KW  - unicycle robots
KW  - distance-bearing constraints
KW  - macro-robot
KW  - regular convex polygon
KW  - trajectory-tracking control problem
KW  - Mobile robots
KW  - Wheels
KW  - Robot kinematics
KW  - Kinematics
KW  - Vehicle dynamics
KW  - Axles
DO  - 10.1109/IROS.2018.8593984
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.
ER  - 

TY  - CONF
TI  - Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - H. Yang
AU  - N. Staub
AU  - A. Franchi
AU  - D. Lee
PY  - 2018
KW  - aerospace robotics
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - vibration control
KW  - MAGMaS
KW  - load flexibility
KW  - heterogeneous system
KW  - aerial robot
KW  - rigid load manipulation
KW  - load weight holding
KW  - long-slender object manipulation
KW  - multiple aerial-ground manipulator system
KW  - flexible load-tip pose tracking
KW  - vibration suppression controllability
KW  - Unmanned aerial vehicles
KW  - Manipulators
KW  - Load modeling
KW  - Vibrations
KW  - Mathematical model
KW  - Shape
DO  - 10.1109/IROS.2018.8593834
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.
ER  - 

TY  - CONF
TI  - Determining Effective Swarm Sizes for Multi-Job Type Missions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4848
EP  - 4853
AU  - M. Chandarana
AU  - M. Lewis
AU  - K. Sycara
AU  - S. Scherer
PY  - 2018
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - particle swarm optimisation
KW  - queueing theory
KW  - sensitivity analysis
KW  - vehicle routing
KW  - sensitivity analysis
KW  - M/M/k/k queuing model
KW  - swarm search and service mission
KW  - SSS mission
KW  - swarm sizes
KW  - DVR
KW  - dynamic vehicle routing
KW  - multijob type missions
KW  - multiagent framework
KW  - balancing vehicle allocation
KW  - human operators
KW  - Robot sensing systems
KW  - Routing
KW  - Time factors
KW  - Planning
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593919
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.
ER  - 

TY  - CONF
TI  - Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4854
EP  - 4861
AU  - D. Roy
AU  - A. Chowdhury
AU  - M. Maitra
AU  - S. Bhattacharya
PY  - 2018
KW  - collision avoidance
KW  - hierarchical systems
KW  - multi-robot systems
KW  - stability
KW  - switching systems (control)
KW  - trees (mathematics)
KW  - multirobot virtual structure switching
KW  - formation changing strategy
KW  - region-based shape controller
KW  - swarm-robotic framework
KW  - traditional obstacle-avoidance problem
KW  - virtual structure methodology
KW  - triangular formation
KW  - shrinking phenomena
KW  - variable structure
KW  - two-layer hierarchical control strategy
KW  - inter-agent formation
KW  - spanning-tree-assisted-shape-matching algorithm
KW  - stability analysis
KW  - Shape
KW  - Robots
KW  - Switches
KW  - Convergence
KW  - Simulation
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8594438
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.
ER  - 

TY  - CONF
TI  - Distributed Sensing Subject to Temporal Logic Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4862
EP  - 4868
AU  - Z. Serlin
AU  - K. Leahy
AU  - R. Tron
AU  - C. Belta
PY  - 2018
KW  - entropy
KW  - formal specification
KW  - greedy algorithms
KW  - multi-agent systems
KW  - optimisation
KW  - temporal logic
KW  - distributed sensing subject
KW  - temporal logic constraints
KW  - temporal logic specifications
KW  - local objective functions
KW  - motion plans
KW  - objective function
KW  - information entropy
KW  - unassigned agents
KW  - satisfaction guarantees
KW  - optimality loss
KW  - local greedy minimization
KW  - TL constraints
KW  - specification complexity
KW  - TL specification
KW  - product automaton based approach
KW  - Robot sensing systems
KW  - Linear programming
KW  - Task analysis
KW  - Planning
KW  - Automata
DO  - 10.1109/IROS.2018.8593574
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.
ER  - 

TY  - CONF
TI  - Comparison of Dynamic Models for Non-Contact Micromanipulation Based on Dielectrophoretic Actuation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4869
EP  - 4874
AU  - V. Gauthier
AU  - A. Bolopion
AU  - M. Gauthier
PY  - 2018
KW  - closed loop systems
KW  - drag
KW  - electrophoresis
KW  - microfluidics
KW  - micromanipulators
KW  - physics computing
KW  - wall-effect
KW  - dielectrophoretic systems
KW  - closed loop control
KW  - induced dielectrophoretic force
KW  - dielectrophoretic actuation
KW  - noncontact micromanipulation
KW  - anisotropic drag force
KW  - dielectrophoresis force
KW  - dipolar model
KW  - Force
KW  - Drag
KW  - Computational modeling
KW  - Dielectrophoresis
KW  - Electrodes
KW  - Trajectory
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594377
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Several approaches are proposed in the literature to calculate the drag force, the electric field and the induced dielectrophoretic force. This paper analyzes the performances of various models for closed loop control of dielectrophoretic systems in comparison with experiments. This article compares their performance in terms of accuracy, computation time, and memory consumption. Four classical approaches are available to calculate the electric field. Their performances are analyzed in the paper. We have shown that combining the dipolar model of dielectrophoresis force with an anisotropic drag force (integrating the wall-effect) provides an interesting ratio precision/computation time. This paper provides an original comparison of several models described in literature whose performances have been compared with experiments.
ER  - 

TY  - CONF
TI  - A New Robot Fly Design That is Easier to Fabricate and Capable of Flight and Ground Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4875
EP  - 4882
AU  - Y. M. Chukewad
AU  - A. T. Singh
AU  - J. M. James
AU  - S. B. Fuller
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - feedback
KW  - microrobots
KW  - mobile robots
KW  - stability
KW  - new robot fly design
KW  - insect-sized
KW  - potential advantages
KW  - larger robots
KW  - greater deployment numbers
KW  - previous iterations
KW  - locomotion capabilities
KW  - additionally land
KW  - long legs
KW  - wing-driven ground locomotion
KW  - flapping wings
KW  - landing
KW  - extremely confined spaces
KW  - simplifying fabrication
KW  - feedback-stabilized flights
KW  - Actuators
KW  - Legged locomotion
KW  - Fabrication
KW  - Laminates
KW  - Laser beam cutting
KW  - Solid lasers
DO  - 10.1109/IROS.2018.8593972
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Efforts to engineer insect-sized (~100 mg) robots are motivated by their potential advantages relative to larger robots, such as greater deployment numbers at the same cost. Previous iterations have demonstrated controlled flight, but were limited in terms of locomotion capabilities outside of flight. They also consisted of many parts, making them difficult to fabricate. Here we present a re-design that lowers the center of mass, allowing the robot to additionally land without the need for long legs. Furthermore, we show that the new design allows for wing-driven ground locomotion. This is achieved by varying the speed of downstroke relative to the upstroke of the flapping wings, which also allows for steering. By landing and subsequently moving along the ground, the robot can negotiate extremely confined spaces and underneath obstacles, as well as navigate to precise locations for sensing operations. The new design also drastically reduces the number of parts, simplifying fabrication. We describe the new design in detail and present results demonstrating these capabilities, as well as feedback-stabilized flights.
ER  - 

TY  - CONF
TI  - Milligram-Scale Micro Aerial Vehicle Design for Low-Voltage Operation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Bhushan
AU  - C. J. Tomlin
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - electromagnetic actuators
KW  - microrobots
KW  - milligram-scale microaerial vehicle design
KW  - low-voltage operation
KW  - wing-span
KW  - wing aerial vehicle
KW  - electromagnetic actuator
KW  - low-voltage input
KW  - actuation
KW  - single resonant mechanism
KW  - small-linear-displacement amplifying stages
KW  - ±45° wing strokes
KW  - ±45° wing plane
KW  - energy efficient electromagnetic design
KW  - electromagnetic works
KW  - mass 70.0 mg
KW  - size 3.0 cm
KW  - mass 60.0 mg
KW  - voltage 5.5 V
KW  - frequency 98.0 Hz
KW  - power 250.0 mW
KW  - mass 100.0 mg
KW  - Magnetic resonance
KW  - Actuators
KW  - Springs
KW  - Magnetic separation
KW  - Loss measurement
KW  - Mathematical model
KW  - Laser beams
DO  - 10.1109/IROS.2018.8594515
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a 70mg, 3cm wing-span, flapping wing aerial vehicle capable of generating up to 60mg of lift using an electromagnetic actuator with low-voltage input (≈5.5V). Its design is novel, with the actuation and transmission integrated into a single resonant mechanism, thus not requiring any small-linear-displacement amplifying stages seen in other works. It can produce ±45° wing strokes and ±45° wing plane rotations at 98Hz operation mimicking relevant insects at this size scale. With required input power of only 250mW, it is, to the best of our knowledge, the most energy efficient electromagnetic design at the sub-100mg scale reported to date, and an order of magnitude more efficient than all other electromagnetic works.
ER  - 

TY  - CONF
TI  - Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4889
EP  - 4894
AU  - I. Bouhadda
AU  - A. Mohand-Ousaid
AU  - G. Bourbon
AU  - P. L. Moal
AU  - P. Lutz
AU  - H. Hussein
AU  - Y. Haddab
PY  - 2018
KW  - digital control
KW  - mechanical stability
KW  - micromanipulators
KW  - micromechanical devices
KW  - microrobots
KW  - robot dynamics
KW  - mechanical stability
KW  - complex control strategies
KW  - bistable modules
KW  - mechanism size
KW  - repeatability analysis
KW  - multistable module
KW  - DiMiBot robots
KW  - digital microrobotics
KW  - complex systems
KW  - multistable prototype
KW  - multiple modules
KW  - reproducibility analysis
KW  - miniaturized structure
KW  - discrete stable positions
KW  - Clamps
KW  - Actuators
KW  - Prototypes
KW  - Task analysis
KW  - Switches
KW  - Silicon
KW  - Micromechanical devices
DO  - 10.1109/IROS.2018.8594259
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.
ER  - 

TY  - CONF
TI  - Depth Estimation of Optically Transparent Microrobots Using Convolutional and Recurrent Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4895
EP  - 4900
AU  - M. Grammatikopoulou
AU  - L. Zhang
AU  - G. Yang
PY  - 2018
KW  - closed loop systems
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - neurocontrollers
KW  - pose estimation
KW  - position control
KW  - recurrent neural nets
KW  - regression analysis
KW  - robot vision
KW  - three-dimensional printing
KW  - optically transparent microrobots
KW  - closed-loop control techniques
KW  - depth estimation method
KW  - supervised learning
KW  - depth regression model
KW  - 3D-printed microrobots
KW  - recurrent neural networks
KW  - convolutional neural networks
KW  - optical tweezers setup
KW  - three-dimensional position estimation
KW  - long short-term memory cell
KW  - Three-dimensional displays
KW  - Estimation
KW  - Solid modeling
KW  - Optical imaging
KW  - Lighting
KW  - Data models
KW  - Microscopy
DO  - 10.1109/IROS.2018.8593776
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating the three-dimensional (3D) position of microrobots is necessary in order to develop closed-loop control techniques and to improve the user's 3D perception in the micro-scale. This paper describes a depth estimation method based on supervised learning for optically transparent microrobots of known geometry. The proposed methodology uses Convolutional Neural Networks (CNNs) combined with a Recurrent Network, in particular a Long Short-Term Memory (LSTM) cell for depth regression. The proposed depth regression model is independent of the 3D orientation of the microrobot and is robust to varying illumination levels while it uses learned data-specific features. The model is trained and validated using microscope images and ground truth data generated from 3D-printed microrobots imaged in an Optical Tweezers (OT) setup. The validation results demonstrate that the proposed trained model can reconstruct the depth of the microrobot independently of its 3D orientation with submicron accuracy for the test set.
ER  - 

TY  - CONF
TI  - On Designing 2D Discrete Workspacesto Sort or Classify Polyominoes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Keldenich
AU  - S. Manzoor
AU  - L. Huang
AU  - D. Krupke
AU  - A. Schmidt
AU  - S. P. Fekete
AU  - A. T. Becker
PY  - 2018
KW  - materials handling
KW  - robotic assembly
KW  - polyominoes sorting
KW  - 2D discrete workspace design
KW  - dynamic sensorless classifiers
KW  - orthoconvex polyominoes
KW  - grid-based workspace
KW  - Sorting
KW  - Shape
KW  - Robot sensing systems
KW  - Two dimensional displays
KW  - Machine vision
KW  - Cams
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594150
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper studies the general problem of physically sorting polyominoes according to shape using a 2D, rigid, grid-based workspace. The workspace is designed for sensorless operation, using a fixed set of open-loop force-field inputs that move a polyomino from an inlet port to an outlet port that corresponds to the polyomino's shape, and reset the workspace to classify the next polyomino. This paper proves that static workspaces can classify all orthoconvex polyominoes of width w and height h, and provides a motion sequence and required size of workspace as a function of wand h. By allowing moving polyomino cams that assist in the sorting, we can design dynamic works paces that can sort all polyomi-noes that are “completely filled” using a constant number of force-field inputs. Hardware experiments using magnetic and gravity-based actuation demonstrate these static and dynamic sensorless classifiers at the millimeter scale.
ER  - 

TY  - CONF
TI  - Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Izuhara
AU  - T. Mashimo
PY  - 2018
KW  - closed loop systems
KW  - controllability
KW  - dexterous manipulators
KW  - end effectors
KW  - force control
KW  - linear motors
KW  - microactuators
KW  - microrobots
KW  - ultrasonic motors
KW  - miniature robot finger
KW  - microrobot hands
KW  - microlinear ultrasonic motor prototype
KW  - closed-loop six-bar-linkage mechanism
KW  - microfabrication
KW  - Acoustics
KW  - Stators
KW  - Robots
KW  - Couplings
KW  - Actuators
KW  - Electrodes
KW  - Vibrations
DO  - 10.1109/IROS.2018.8594098
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.
ER  - 

TY  - CONF
TI  - Resistive Pulse Study of Liposome Stability: Towards Precision and Efficient Drug Delivery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4914
EP  - 4919
AU  - Y. Lin
AU  - X. Liu
AU  - T. Arai
PY  - 2018
KW  - biological tissues
KW  - biomedical materials
KW  - biomembranes
KW  - cancer
KW  - cellular biophysics
KW  - drug delivery systems
KW  - lipid bilayers
KW  - molecular biophysics
KW  - nanofabrication
KW  - nanomedicine
KW  - nanoparticles
KW  - scanning electron microscopy
KW  - resistive pulse study
KW  - liposome stability
KW  - drug delivery vehicle
KW  - resistive pulse method
KW  - liposome fusion
KW  - cancerous tissue arrangement
KW  - organic nanoparticle measurement
KW  - 3D manipulator positioning
KW  - cellular in-vivo measurement
KW  - environmental SEM chamber
KW  - size 50.0 nm
KW  - size 100.0 nm
KW  - Lipidomics
KW  - Drug delivery
KW  - Manipulators
KW  - Stability analysis
KW  - Size measurement
KW  - Three-dimensional displays
KW  - Glass
KW  - drug delivery vehicle
KW  - liposome
KW  - 3D manipulator
KW  - resistive pulse method
KW  - size measurement
KW  - sub 100nm Nano pores
DO  - 10.1109/IROS.2018.8593731
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, the authors report the investigation of liposomes' stability as a drug delivery vehicle, using the method of resistive pulse method. The main objects of interest are the 50nm diameter liposomes, while the 100nm diameter liposomes are widely used for its stability. However, certain drug delivery scenarios arise, like tighter cancerous tissue arrangement and different circulation time requirement, which dictates the necessity of sub-100nm diameter vesicles. The size measurements upon freshly fabricated liposomes are performed frequently on increasing time interval. The results exhibit a trend of size increasing, suggesting the existence of liposome fusion. The possible models of fusion are proposed and discussed. This work demonstrates the localized organic nanoparticle measurement with fine dual 3D manipulator positioning, which paves the way for the possible cellular in-vivo measurement within an environmental SEM chamber.
ER  - 

TY  - CONF
TI  - Force/Velocity Manipulability Analysis for 3D Continuum Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4920
EP  - 4926
AU  - M. Khadem
AU  - L. Da Cruz
AU  - C. Bergeles
PY  - 2018
KW  - dexterous manipulators
KW  - mobile robots
KW  - path planning
KW  - continuum robots
KW  - continuum manipulators
KW  - effective manipulation
KW  - rigid robots
KW  - manipulability indices
KW  - unified force-velocity manipulability
KW  - concentric-tube robot
KW  - manipulability measurement
KW  - force-velocity manipulability analysis
KW  - Robot kinematics
KW  - Indexes
KW  - Force
KW  - Manipulators
KW  - Jacobian matrices
KW  - Ellipsoids
DO  - 10.1109/IROS.2018.8593874
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The enhanced dexterity and manipulability offered by continuum manipulators makes them the robots of choice for complex procedures inside the human body. However, without tailored analytical tools to evaluate their manipulability, many capabilities of continuum robots such as safe and effective manipulation will remain largely inaccessible. This paper presents a quantifiable measure for analysing force/velocity manipulability of continuum robots. We expand classical measures of manipulability for rigid robots to introduce three types of manipulability indices to continuum robots, namely, velocity, compliance, and unified force-velocity manipulability. We provide a specific case study using the proposed method to analyse the force/velocity manipulability for a concentric-tube robot. We investigate the application of the manipulability measures to compare performance of continuum robots in terms of compliance and force-velocity manipulability. The proposed manipulability measures enable future research on design and optimal path planning for continuum robots.
ER  - 

TY  - CONF
TI  - Analysis of Dynamic Response of an MRI-Guided Magnetically-Actuated Steerable Catheter System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - E. Erdem Tuna
AU  - T. Liu
AU  - R. C. Jackson
AU  - N. Lombard Poirot
AU  - M. Russell
AU  - M. C. Çavuşoğlu
PY  - 2018
KW  - biomedical MRI
KW  - catheters
KW  - closed loop systems
KW  - control nonlinearities
KW  - dynamic response
KW  - frequency response
KW  - linearisation techniques
KW  - magnetic actuators
KW  - medical image processing
KW  - medical robotics
KW  - open loop systems
KW  - robot vision
KW  - MRI-guided magnetically-actuated steerable catheter system
KW  - free-space open-loop dynamic response analysis
KW  - magnetically-actuated steerable intra-vascular catheter system
KW  - current carrying microcoils
KW  - magnetic torques
KW  - system nonlinearity
KW  - pendulum model
KW  - approximate input-output linearization
KW  - black-box system identification approach
KW  - frequency response analysis
KW  - camera system
KW  - free-space trajectories
KW  - robotic catheter
KW  - MRI guidance
KW  - magnetic resonance imaging scanner
KW  - free-space closed-loop control
KW  - Nyquist frequency
KW  - Catheters
KW  - Coils
KW  - Magnetic resonance imaging
KW  - Torque
KW  - Robots
KW  - Chirp
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594308
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a free-space open-loop dynamic response analysis for an MRI -guided magnetically-actuated steerable intra-vascular catheter system. The catheter tip is embedded with a set of current carrying micro-coils. The catheter is directly actuated via the magnetic torques generated on these coils by the magnetic field of the magnetic resonance imaging (MRI)scanner. The relationship between the input current commands and catheter tip deflection angle presents an inherent nonlinearity in the proposed catheter system. The system nonlinearity is analyzed by utilizing a pendulum model. The pendulum model is used to describe the system nonlinearity and to perform an approximate input-output linearization. Then, a black-box system identification approach is performed for frequency response analysis of the linearized dynamics. The optimal estimated model is reduced by observing the modes and considering the Nyquist frequency of the camera system that is used to track the catheter motion. The reduced model is experimentally validated with 3D open-loop Cartesian free-space trajectories. This study paves the way for effective and accurate free-space closed-loop control of the robotic catheter with real-time feedback from MRI guidance in subsequent research.
ER  - 

TY  - CONF
TI  - Development and validation of MRI compatible pediatric surgical robot with modular tooling for bone biopsy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4935
EP  - 4941
AU  - A. N. Alvara
AU  - T. Looi
AU  - R. Saab
AU  - A. Shorter
AU  - A. Goldenberg
AU  - J. Drake
PY  - 2018
KW  - biomedical MRI
KW  - bone
KW  - medical robotics
KW  - paediatrics
KW  - phantoms
KW  - surgery
KW  - tumours
KW  - PSR-BBT
KW  - cortical bone phantoms
KW  - cancellous bone phantoms
KW  - MRI testing
KW  - T1-FFE
KW  - T2-FFE
KW  - MR-guided robotic surgery
KW  - modular Tooling
KW  - magnetic resonance imaging
KW  - MR-compatible tools
KW  - surgical accuracy
KW  - Pediatric Surgery Robot platform
KW  - modular tool interface
KW  - Bone Biopsy Tooling
KW  - modified titanium bone biopsy needle
KW  - joint Cartesian level control
KW  - MRI compatible pediatric surgical robot
KW  - lesion
KW  - tumor
KW  - 5-DOF robot
KW  - Philips Achieva 3.0T MRI bore
KW  - surgical preplanning
KW  - control interface
KW  - Cartesian level control
KW  - axial force
KW  - signal-to-noise ratio variation
KW  - geometric distortion
KW  - magnetic flux density 3 T
KW  - Biopsy
KW  - Bones
KW  - Magnetic resonance imaging
KW  - Robots
KW  - Surgery
KW  - Signal to noise ratio
KW  - Tools
DO  - 10.1109/IROS.2018.8593523
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In clinical practice, magnetic resonance imaging (MRI) is used to locate a lesion/tumor for bone biopsy in children. However, there is a lack of MR-compatible tools that can be used simultaneously during imaging and biopsy while maintaining surgical accuracy and safety. The Pediatric Surgery Robot (PSR) platform is a 5-DOF robot with a modular tool interface. For the case of bone biopsy, a Bone Biopsy Tooling (BBT) is attached. It is designed to fit within a Philips Achieva 3.0T MRI bore and carry a modified titanium bone biopsy needle. A surgical pre-planning and control interface has been developed for joint and Cartesian level control. The PSR-BBT has demonstrated 1.65 +/- 1.77 mm accuracy in Cartesian control in free space. The PSR-BBT can generate 12.46 +/- 0.32 N of axial force while drilling at a speed of 30 rpm, which is sufficient for cortical and cancellous bone phantoms. Under MRI testing (T1-FFE, T1-SE, T2-FFE and T2-TSE scans), the system demonstrated less than 33% signal-to-noise ratio variation while drilling and a 0.46% geometric distortion while powered on without significantly impacting MRI guidance in situ. These results show that the PSR-BBT can allow the user to simultaneously image and perform the biopsy and presents the PSR as a viable platform for MR-guided robotic surgery.
ER  - 

TY  - CONF
TI  - Safe Motion Planning for Steerable Needles Using Cost Maps Automatically Extracted from Pulmonary Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4942
EP  - 4949
AU  - M. Fu
AU  - A. Kuntz
AU  - R. J. Webster
AU  - R. Alterovitz
PY  - 2018
KW  - blood vessels
KW  - cancer
KW  - computerised tomography
KW  - feature extraction
KW  - lung
KW  - medical image processing
KW  - needles
KW  - lung nodule biopsy
KW  - steerable needles
KW  - bronchoscope
KW  - bronchial tubes
KW  - blood vessels
KW  - safe motion planning
KW  - motion planning approach
KW  - lung pleura
KW  - pulmonary CT images
KW  - cost map
KW  - lung periphery
KW  - lung nodules
KW  - needle biopsy
KW  - lung cancer
KW  - Needles
KW  - Lung
KW  - Biomedical imaging
KW  - Planning
KW  - Biopsy
KW  - Computed tomography
KW  - Blood vessels
DO  - 10.1109/IROS.2018.8593407
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Lung cancer is the deadliest form of cancer, and early diagnosis is critical to favorable survival rates. Definitive diagnosis of lung cancer typically requires needle biopsy. Common lung nodule biopsy approaches either carry significant risk or are incapable of accessing large regions of the lung, such as in the periphery. Deploying a steerable needle from a bronchoscope and steering through the lung allows for safe biopsy while improving the accessibility of lung nodules in the lung periphery. In this work, we present a method for extracting a cost map automatically from pulmonary CT images, and utilizing the cost map to efficiently plan safe motions for a steerable needle through the lung. The cost map encodes obstacles that should be avoided, such as the lung pleura, bronchial tubes, and large blood vessels, and additionally formulates a cost for the rest of the lung which corresponds to an approximate likelihood that a blood vessel exists at each location in the anatomy. We then present a motion planning approach that utilizes the cost map to generate paths that minimize accumulated cost while safely reaching a goal location in the lung.
ER  - 

TY  - CONF
TI  - Trigonometric Ratio-Based Remote Center of Motion Mechanism for Bone Drilling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4958
EP  - 4963
AU  - S. Shim
AU  - S. Lee
AU  - D. Ji
AU  - H. Choi
AU  - J. Hong
PY  - 2018
KW  - actuators
KW  - bone
KW  - medical robotics
KW  - motion control
KW  - orthopaedics
KW  - robot vision
KW  - surgery
KW  - bone drilling robotic systems
KW  - drill alignment
KW  - RCM mechanism
KW  - remote center of motion mechanism
KW  - surgical procedures
KW  - linear actuators
KW  - gearless arc-guide
KW  - vision-guided navigation system
KW  - orientation guidance
KW  - trigonometric ratio
KW  - Bones
KW  - Robots
KW  - Surgery
KW  - Actuators
KW  - Force
KW  - Computed tomography
KW  - Task analysis
KW  - Remote center of motion mechanism
KW  - surgical robotics
KW  - vision-guided navigation
KW  - bone drilling
DO  - 10.1109/IROS.2018.8594069
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The remote center of motion (RCM) mechanism is a prominent candidate to aid bone drilling. The surgeon can simply place a drill with the RCM mechanism near the entry point to provide drill alignment with the target. Using this assistive mechanism for bone drilling improves drilling accuracy and reduces the complexity of bone drilling robotic systems. However, because most RCM mechanisms have been developed for laparoscopic surgery or needle insertion into soft tissue, they lack rigidity and are unsuitable for bone drilling. One of the most difficult and important surgical procedures in bone drilling is maintaining as well as guiding the orientation of the drill with respect to the target. This paper proposes an improved RCM mechanism in which a pair of linear actuators and a gearless arc-guide are employed to achieve high rigidity and resolution, which enable bone drilling. A vision-guided navigation system is also integrated into the proposed system to automatically guide the orientation. To verify that the proposed RCM mechanism has sufficient rigidity and targeting accuracy, a series of experiments was performed. The results obtained confirm that the proposed mechanism can maintain its tilting angle under up to 50 N, with a targeting error of approximately 0.28mm.
ER  - 

TY  - CONF
TI  - Rolling-Joint Design Optimization for Tendon Driven Snake-Like Surgical Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4964
EP  - 4971
AU  - P. Berthet-Rayne
AU  - K. Leibrandt
AU  - K. Kim
AU  - C. A. Seneci
AU  - J. Shang
AU  - G. Yang
PY  - 2018
KW  - manipulators
KW  - medical robotics
KW  - surgery
KW  - tendon driven snake-like surgical robots
KW  - intra-luminal procedures
KW  - flexibility
KW  - serial rolling-joints
KW  - base architecture
KW  - joint angle range
KW  - tendons
KW  - rolling-joint design optimization
KW  - optimized joints
KW  - Tendons
KW  - Tools
KW  - Navigation
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593517
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of snake-like robots for surgery is a popular choice for intra-luminal procedures. In practice, the requirements for strength, flexibility and accuracy are difficult to be satisfied simultaneously. This paper presents a computational approach for optimizing the design of a snake-like robot using serial rolling-joints and tendons as the base architecture. The method optimizes the design in terms of joint angle range and tendon placement to prevent the tendons and joints from colliding during bending motion. The resulting optimized joints were manufactured using 3D printing. The robot was characterized in terms of workspace, dexterity, precision and manipulation forces. The results show a repeatability as low as 0.9mm and manipulation forces of up to 5.6N.
ER  - 

TY  - CONF
TI  - Enhancing the Command-Following Bandwidth for Transparent Bilateral Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4972
EP  - 4979
AU  - H. Singh
AU  - A. Jafari
AU  - A. Peer
AU  - J. Ryu
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - telerobotics
KW  - command-following bandwidth
KW  - transparent bilateral teleoperation
KW  - slave robot motion controller
KW  - high motion controller gain
KW  - human user
KW  - successive stiffness increment approach
KW  - SSI approach
KW  - bilateral teleoperation controller
KW  - Pressing
KW  - Force
KW  - Bandwidth
KW  - Haptic interfaces
KW  - Trajectory
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593866
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Enhancing transparency of a teleoperation system by increasing the command-following bandwidth has not received lots of attention so far. This is considered a challenging task since in a teleoperation system the command-following bandwidth of the slave robot motion controller cannot be increased with a conventional motion controller as the desired trajectory is instantaneously commanded by the human user and thus, cannot be considered to be given in a pre-computed, smooth second order derivative form. We propose a method to increase the command-following bandwidth by extending the previously introduced Successive Stiffness Increment (SSI) approach to bilateral teleoperation. The approach allows realizing a very high motion controller gain, which cannot be realized with a conventional bilateral teleoperation controller as confirmed by experimental results.
ER  - 

TY  - CONF
TI  - Transparency-Optimal Passivity Layer Design for Time-Domain Control of Multi-DoF Haptic-Enabled Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4988
EP  - 4994
AU  - O. A. Moreno Franco
AU  - J. Bimbo
AU  - C. Pacchierotti
AU  - D. Prattichizzo
AU  - D. Barcelli
AU  - G. Bianchini
PY  - 2018
KW  - haptic interfaces
KW  - optimisation
KW  - telerobotics
KW  - time-domain scheme
KW  - optimization problem
KW  - optimization-based passivity control algorithm
KW  - virtual teleoperated environment
KW  - real-time implementation
KW  - optimal transparency
KW  - energy-bounding control
KW  - haptic-enabled bilateral teleoperation systems
KW  - multiDoF
KW  - time-domain control
KW  - transparency-optimal passivity layer design
KW  - Force
KW  - Task analysis
KW  - Computer architecture
KW  - Robots
KW  - Indexes
KW  - Time-domain analysis
KW  - Haptic interfaces
DO  - 10.1109/IROS.2018.8593443
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel optimization-based passivity control algorithm for haptic-enabled bilateral teleoperation systems involving multiple degrees of freedom. In particular, in the context of energy-bounding control, the contribution focuses on the implementation of a passivity layer for an existing time-domain scheme, ensuring optimal transparency of the interaction along subsets of the environment space which are preponderant for the given task, while preserving the energy bounds required for passivity. The involved optimization problem is convex and amenable to real-time implementation. The effectiveness of the proposed design is validated via an experiment performed on a virtual teleoperated environment.
ER  - 

TY  - CONF
TI  - Development and Evaluation of an Intuitive Flexible Interface for Teleoperating Soft Growing Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4995
EP  - 5002
AU  - H. El-Hussieny
AU  - U. Mehmood
AU  - Z. Mehdi
AU  - S. Jeong
AU  - M. Usman
AU  - E. W. Hawkes
AU  - A. M. Okarnura
AU  - J. Ryu
PY  - 2018
KW  - bending
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - telerobotics
KW  - user interfaces
KW  - intuitive flexible interface
KW  - teleoperating soft growing robots
KW  - robotic systems design
KW  - tip-extending
KW  - navigation
KW  - disaster scenarios
KW  - intuitive human control
KW  - intuitively map human bending
KW  - shape information
KW  - command mappings
KW  - developed interface
KW  - commercially available interfaces
KW  - virtual task scenarios
KW  - shape mapping
KW  - vine robot rolls
KW  - Shape
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Kinematics
KW  - Current measurement
DO  - 10.1109/IROS.2018.8593896
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobility by growth is a new paradigm in robotic systems design and their applications in the real world. Soft, tip-extending, or “growing”, robots have potential applications including inspection and navigation in disaster scenarios. However, due to their growing capability, such robots create unique challenges for intuitive human control. In this paper, a new flexible interface is proposed to intuitively map human bending commands into movements of the growing robot while providing shape information of the robot in order to improve situational awareness. Several command mappings are proposed, and a subjective study was conducted to assess the intuitiveness of the developed interface and mappings compared with other commercially available interfaces. The interfaces were evaluated using four metrics in two virtual task scenarios. The proposed interface with shape mapping performed better than the other interfaces, especially when the vine robot rolls over unintentionally during complex tasks.
ER  - 

TY  - CONF
TI  - Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - D. Krupke
AU  - F. Steinicke
AU  - P. Lubos
AU  - Y. Jonetzko
AU  - M. Görner
AU  - J. Zhang
PY  - 2018
KW  - control engineering computing
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - intelligent robots
KW  - mobile robots
KW  - multi-robot systems
KW  - service robots
KW  - user interfaces
KW  - virtual reality
KW  - multimodal heading
KW  - pointing gestures
KW  - human operator
KW  - co-located robots
KW  - head-mounted-display
KW  - HRI situations
KW  - enormous potential
KW  - MR human-robot collaboration system
KW  - industrial robot arm
KW  - multimodal HRI techniques
KW  - heading-based interaction techniques
KW  - multirobot system
KW  - current robot programming
KW  - human-robot interaction scenarios
KW  - virtual information
KW  - pick-and-place scenarios
KW  - potential robot actions
KW  - co-located mixed reality human-robot interaction
KW  - Microsoft HoloLens
KW  - Virtual reality
KW  - Service robots
KW  - Task analysis
KW  - Collaboration
KW  - Visualization
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594043
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.
ER  - 

TY  - CONF
TI  - Humanoid Teleoperation Using Task-Relevant Haptic Feedback
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5010
EP  - 5017
AU  - F. Abi-Farrajl
AU  - B. Henze
AU  - A. Werner
AU  - M. Panzirsch
AU  - C. Ott
AU  - M. A. Roa
PY  - 2018
KW  - compliance control
KW  - feedback
KW  - haptic interfaces
KW  - humanoid robots
KW  - stability
KW  - telerobotics
KW  - torque control
KW  - operating tools
KW  - space station
KW  - key technology
KW  - robotic teleoperation
KW  - task-relevant haptic feedback
KW  - humanoid robot TORO
KW  - torque-controlled humanoid robot
KW  - null-space autonomous controller
KW  - robot stability
KW  - haptic cues
KW  - humanoid teleoperation
KW  - task-relevant haptic interface
KW  - disaster scenarios
KW  - Humanoid robots
KW  - Task analysis
KW  - End effectors
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8593521
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic teleoperation is a key technology for a wide variety of fields. Teleoperating a humanoid in particular is essential as it allows the user to act remotely on an interface designed especially for humans, e.g., in a space station, or operating tools and machinery in disaster scenarios. This paper presents a `task-relevant' haptic interface for humanoid teleoperation, which bridges the gap between the task at hand and the balance of the robot. The operator is given command over the humanoid's hands and is informed through haptic cues about the impact of her/his potential actions on the robot' stability. Moreover, a null-space autonomous controller acts in the operator's null-space to provide her/him with a wider workspace and help in the successful execution of the task. The architecture is designed to top an existing compliance controller for a torque-controlled humanoid robot. Experiments on the humanoid robot TORO are reported to demonstrate the feasibility and effectiveness of the approach.
ER  - 

TY  - CONF
TI  - ROS Reality: A Virtual Reality Framework Using Consumer-Grade Hardware for ROS-Enabled Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - D. Whitney
AU  - E. Rosen
AU  - D. Ullman
AU  - E. Phillips
AU  - S. Tellex
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - Internet
KW  - operating systems (computers)
KW  - telerobotics
KW  - virtual reality
KW  - direct kinesthetic handling
KW  - robot operating system
KW  - ROS reality
KW  - virtual reality systems
KW  - virtual reality framework
KW  - VR teleoperation package
KW  - robotic frameworks
KW  - consumer-grade VR systems
KW  - consumer-grade hardware
KW  - robotic teleoperation tasks
KW  - Baxter robot
KW  - Unity-compatible VR headset
KW  - ROS-enabled robot
KW  - Robots
KW  - Task analysis
KW  - Solid modeling
KW  - Virtual reality
KW  - Hardware
KW  - Two dimensional displays
KW  - Engines
DO  - 10.1109/IROS.2018.8593513
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Virtual reality (VR)systems let users intuitively interact with 3D environments and have been used extensively for robotic teleoperation tasks. While more immersive than their 2D counterparts, early VR systems were expensive and required specialized hardware. Fortunately, there has been a recent proliferation of consumer-grade VR systems at affordable price points. These systems are inexpensive, relatively portable, and can be integrated into existing robotic frameworks. Our group has designed a VR teleoperation package for the Robot Operating System (ROS), ROS Reality, that can be easily integrated into such frameworks. ROS Reality is an open-source, over-the-Internet teleoperation interface between any ROS-enabled robot and any Unity-compatible VR headset. We completed a pilot study to test the efficacy of our system, with expert human users controlling a Baxter robot via ROS Reality to complete 24 dexterous manipulation tasks, compared to the same users controlling the robot via direct kinesthetic handling. This study provides insight into the feasibility of robotic teleoperation tasks in VR with current consumer-grade resources and exposes issues that need to be addressed in these VR systems. In addition, this paper presents a description of ROS Reality, its components, and architecture. We hope this system will be adopted by other research groups to allow for easy integration of VR teleoperated robots into future experiments.
ER  - 

TY  - CONF
TI  - User Evaluation of a Haptic-Enabled Shared-Control Approach for Robotic Telemanipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Abi-Farraj
AU  - C. Pacchierotti
AU  - P. R. Giordano
PY  - 2018
KW  - haptic interfaces
KW  - manipulators
KW  - telerobotics
KW  - grounded haptic interface
KW  - remaining null-space directions
KW  - human operator
KW  - slave manipulator degrees
KW  - effective approaches
KW  - nuclear sites
KW  - estimated cost
KW  - currently employed systems
KW  - handling radioactive waste
KW  - nuclear decommissioning sites
KW  - robotic telemanipulators
KW  - robotic telemanipulation
KW  - user evaluation
KW  - remote telemanipulation tasks
KW  - currently-available teleoperation systems
KW  - shared-control approach
KW  - 6-DOF teleoperation approach
KW  - shared-control architecture
KW  - robotic system
KW  - haptic cues
KW  - Task analysis
KW  - Manipulators
KW  - Grippers
KW  - Force
KW  - Grasping
DO  - 10.1109/IROS.2018.8594030
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic telemanipulators are already widely used in nuclear decommissioning sites for handling radioactive waste. However, currently employed systems are still extremely primitive, making the handling of these materials prohibitively slow and ineffective. As the estimated cost for the decommissioning and clean-up of nuclear sites keeps rising, it is clear that one would need faster and more effective approaches. Towards this goal, in this paper we present the user evaluation of a recently proposed haptic-enabled shared-control architecture for telemanipulation. An autonomous algorithm regulates a subset of the slave manipulator degrees of freedom (DoF) in order to help the human operator in grasping an object of interest. The human operator can then steer the manipulator along the remaining null-space directions with respect to the main task by acting on a grounded haptic interface. The haptic cues provided to the operator are designed in order to inform about the feasibility of the user's commands with respect to possible constraints of the robotic system. In this paper we compared this shared-control architecture against a classical 6-DOF teleoperation approach in a real scenario by running experiments with 10 subjects. The results clearly show that the proposed shared-control approach is a viable and effective solution for improving currently-available teleoperation systems in remote telemanipulation tasks.
ER  - 

TY  - CONF
TI  - Towards an Automatic Spasticity Assessment by Means of Collaborative Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Hernandez
AU  - E. Daniel Oña
AU  - J. M. Garcia-Haro
AU  - A. Jardon
AU  - C. Balaguer
PY  - 2018
KW  - biomechanics
KW  - brain
KW  - medical disorders
KW  - medical robotics
KW  - muscle
KW  - neurophysiology
KW  - patient rehabilitation
KW  - shear modulus
KW  - viscoelasticity
KW  - exaggerated stretch reflexes
KW  - upper motor neuron syndrome
KW  - collaborative robots
KW  - noninvasive biomechanical modelling
KW  - automatic spasticity assessment
KW  - muscle control disorder
KW  - muscle tone
KW  - upper limb joints
KW  - patient rehabilitation
KW  - 7-DOF Rosen kinematics
KW  - nonlinear state
KW  - Hills force-velocity relation
KW  - rigidity
KW  - viscoelasticity
KW  - extensibility
KW  - thixotropy
KW  - passive movement response
KW  - Collaboration
KW  - Biological system modeling
KW  - Muscles
KW  - Brain modeling
KW  - Biomechanics
KW  - Intelligent robots
KW  - Collaborative robotics
KW  - Movement capture
KW  - Rehabilitation
KW  - Spasticity
KW  - Upper limb modelling
DO  - 10.1109/IROS.2018.8594158
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Summary form only given. Robotics can play a significant role in the rehabilitation of patients with spasticity by improving their early diagnosis and reducing the costs associated with care. Spasticity is a muscle control disorder characterized by an increase in muscle tone with exaggerated stretch reflexes, as one component of the upper motor neuron syndrome. Furthermore, spasticity is present in other pathologies, such as cerebral palsy, spina bifida, brain stroke among others. This video shows the ongoing research on developing a platform for the modelling and the assessment of spasticity using collaborative robots as clinical tool. Our aim is to develop methods for non-invasive biomechanical modelling of upper limbs joints using 7-DOF Rosen Kinematics [1], mixed with a non-linear state of Hills force-velocity relation [2], improved by introducing new parameters such as rigidity, viscoelasticity, extensibility and thixotropy. After a learning phase performed by the therapist, the robot replicates the trajectories required to perform the assessment. The video also describes the detailed analysis of passive movement response (force/torque and position/velocity)of the limb. These parameters will be used to determine the degree of spasticity of patients in a fast and objective manner, while simultaneously developing new clinical scales, such as a modified version of Ashworth [3].
ER  - 

TY  - CONF
TI  - Research on Carved Turns of a Skiing Humanoid Robot on a Real-World Slope
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Han
AU  - D. Yoon
AU  - H. Song
AU  - B. Kim
AU  - Y. Kim
AU  - C. Park
AU  - Y. Eum
AU  - J. Moon
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - sport
KW  - South Korea
KW  - deep learning method
KW  - motion pattern
KW  - IMU sensor
KW  - skiing humanoid Robot
KW  - realworld slope
KW  - carved turn
KW  - skiing robot DIANA
KW  - Alpine slalom skiing competition
KW  - PyeongChang 2018 Winter Olympic Games
KW  - robot sports events
KW  - Humanoid robots
KW  - Sports
KW  - Robot sensing systems
KW  - Moon
KW  - Service robots
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593796
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humans play sports to improve their athletic ability. The robot, especially humanoid robot, is also able to improve its athletic performances, such as reaction speed and balancing, through robot sports. Therefore, robots have been developed through performing various robot sports events such as robot soccer, robot marathon, robot fight and so on. In this reason, The Ski Robot Challenge was held in South Korea in commemoration of the PyeongChang 2018 Winter Olympic Games. The event was an Alpine slalom skiing competition in the almost same rules to human's but on a relatively short course (80m). To participate in this ski tournament, the skiing robot DIANA has been developed. In this video, the skiing robot technologies were introduced. At first, she must be able to recognize the flags. The deep learning method was used to recognize them. Secondly, she had a motion pattern to perform the carving turn, the most difficult and fastest skiing technique. In order to improve the stability, she compensated her motion to follow reference COP, based on the measured F/T sensor data. In addition, IMU sensor was used to remove instantaneous disturbance. Using these methods, the humanoid robot, DIANA, that can perform the carved turn on a realworld slope was successfully developed.
ER  - 

TY  - CONF
TI  - Waiter Robot Application: Balance Control for Transporting Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. m. Garcia-Haro
AU  - E. Daniel Oña
AU  - S. Martinez
AU  - J. Hernandez-Vicen
AU  - C. Balaguer
PY  - 2018
KW  - force control
KW  - humanoid robots
KW  - manipulators
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - position control
KW  - robot vision
KW  - stability
KW  - waiter robot application
KW  - dynamic balance control
KW  - simplified mathematical model
KW  - robot arm
KW  - manipulation control system
KW  - nongrasping tasks
KW  - ZMP criterion
KW  - humanoid robot TEO
KW  - zero moment point stability criterion
KW  - force-torque sensors
KW  - computer vision
KW  - center of mass
KW  - CoM
KW  - Humanoid robots
KW  - Stability criteria
KW  - Sensors
KW  - Mathematical model
KW  - Control systems
KW  - Balance
KW  - Manipulation
KW  - Force-Torque
KW  - Vision
KW  - Humanoid
DO  - 10.1109/IROS.2018.8593760
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic balance control for humanoid robots encounters difficulties such as stability, speed, and smoothness. In most of the previous studies, joints act as controller of the Center of Mass (CoM)supported using a simplified mathematical model. Then, the stability of the motion is guaranteed using the Zero Moment Point (ZMP)stability criterion. In this video, a humanoid robot [1] will carry a tray secured to the wrist and the objects to be transported will be placed on the tray. This condition implies that the object is not grasped and therefore, the robot arm will be the only point of support of the object through the tray. Thus, the manipulation control system must be able to detect the stability of the object and act according to the different perturbations applied to it. A 3D balance control system for non-grasping tasks is presented and it is based on the ZMP criterion and 3D inverted pendulum equations. The perception system required is based on the use of Force-Torque sensors [2], computer vision [3], and their integration. The effectiveness of the proposed approach is being investigated with the humanoid robot TEO.
ER  - 

TY  - CONF
TI  - Visual-Inertial Teach and Repeat Powered by Google Tango
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Fehr
AU  - T. Schneider
AU  - R. Siegwart
PY  - 2018
KW  - automatic optical inspection
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - control engineering computing
KW  - Global Positioning System
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - trajectory control
KW  - human operator
KW  - visual inspection task
KW  - autonomous aerial vehicle
KW  - Google Tango visual-inertial mapping framework
KW  - pose estimates
KW  - GPS-denied environments
KW  - inspection points
KW  - feature-based localization map
KW  - industrial facilities
KW  - multicopters
KW  - visual-inertial teach
KW  - hedge maze
KW  - Robots
KW  - Inspection
KW  - Task analysis
KW  - Collision avoidance
KW  - Google
KW  - Autonomous systems
KW  - Visualization
DO  - 10.1109/IROS.2018.8593416
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.
ER  - 

TY  - CONF
TI  - Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 1
AU  - L. Briñón-Arranz
AU  - M. Muschinowski
AU  - J. Dumon
AU  - N. Marchand
PY  - 2018
KW  - aircraft control
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - tracking
KW  - trajectory control
KW  - multirobot systems
KW  - geometric parameters
KW  - distributed algorithm
KW  - tracking controller
KW  - robots position
KW  - distributed trajectory generator
KW  - mini aerial vehicles
KW  - distributed reconfigurable formation generator
KW  - Generators
KW  - Intelligent robots
KW  - Trajectory
KW  - Multi-robot systems
KW  - Distributed algorithms
DO  - 10.1109/IROS.2018.8593511
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.
ER  - 

TY  - CONF
TI  - Autonomous Underwater Vehicle Navigation in Structured Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5039
EP  - 5039
AU  - D. Park
AU  - Y. Lee
AU  - K. Jung
AU  - H. Kang
AU  - H. Ki
AU  - J. Lee
AU  - Y. Choi
AU  - J. Li
AU  - H. Myung
AU  - H. Choi
AU  - J. Suh
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cameras
KW  - geophysical image processing
KW  - image sensors
KW  - marine navigation
KW  - oceanographic techniques
KW  - position measurement
KW  - sensor fusion
KW  - sonar
KW  - AUV navigation system
KW  - autonomous underwater vehicle navigation system
KW  - signal uncertainties
KW  - signal distortion
KW  - cameras
KW  - position estimation
KW  - image sonar aided integrated navigation system
KW  - active vision markers
KW  - inherent drift of dead-reckoning velocities
KW  - jacket structure
KW  - artificial landmarks
KW  - sensor-fusion-based localization scheme
KW  - integrated navigation system
KW  - Sonar navigation
KW  - Oceans
KW  - Sonar
KW  - Autonomous robots
KW  - Industries
KW  - Intelligent robots
KW  - Autonomous underwater vehicles
DO  - 10.1109/IROS.2018.8594429
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With the increase in developments in underwater infrastructure, the demand for development of autonomous vehicle navigation system in structured environment is also increased. However, the localization in a structured environment is a challenging problem due to signal uncertainties and distortions. In order to overcome these problems, we propose the camera and sonar aided integrated navigation system. In the proposed sensor-fusion-based localization scheme, the AUV estimates its own position continuously using artificial landmarks. The artificial landmarks for image sonar is deployed along the path to guide the AUV to the structure. The active vision markers are installed on the jacket structure, and they function as both landmarks and waypoints. This approach prevents the inherent drift of dead-reckoning velocities and collision with structures. The proposed approach was verified through a real sea experiment. The AUV conducted the full autonomous navigation from the dock to the jacket structure, and then returned to the dock without collision or significant localization error. These results show the feasibility of full autonomous navigation in a structured environment.
ER  - 

TY  - CONF
TI  - Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5040
EP  - 5040
AU  - C. Kanellakis
AU  - S. S. Mansouri
AU  - E. Fresk
AU  - D. Kominiak
AU  - G. Nikolakopoulos
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - image reconstruction
KW  - inspection
KW  - Kalman filters
KW  - mobile robots
KW  - robot vision
KW  - wind turbines
KW  - UAVs
KW  - Aerial inspection
KW  - aerial tool
KW  - autonomous cooperative coverage
KW  - multiple Unmanned Aerial Vehicles
KW  - onboard computer
KW  - sensory system
KW  - autonomous navigation
KW  - localization system
KW  - Ultra Wideband
KW  - aerial team
KW  - realistic wind turbine inspection experiments
KW  - dense 3D reconstruction
KW  - inspected structures
KW  - state Kalman filter
KW  - 3D infrastructure
KW  - large scale aging infrastructure
KW  - Inspection
KW  - Three-dimensional displays
KW  - Tools
KW  - Intelligent robots
KW  - Aging
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593996
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.
ER  - 

TY  - CONF
TI  - Hear the Egg - Demonstrating Robotic Interactive Auditory Perception
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5041
EP  - 5041
AU  - E. Strahl
AU  - M. Kerzel
AU  - M. Eppe
AU  - S. Griffiths
AU  - S. Wermter
PY  - 2018
KW  - audio signal processing
KW  - hearing
KW  - humanoid robots
KW  - image classification
KW  - interactive video
KW  - mobile robots
KW  - robot vision
KW  - video retrieval
KW  - neuro inspired companion
KW  - plastic capsules
KW  - classic TV game show
KW  - material classification task
KW  - NICO
KW  - humanoid robot
KW  - interactive auditory perception approach
KW  - egg-demonstrating robotic interactive auditory perception
KW  - capsules content
KW  - Humanoid robots
KW  - Mel frequency cepstral coefficient
KW  - Intelligent robots
KW  - Plastics
KW  - Recurrent neural networks
KW  - Gold
DO  - 10.1109/IROS.2018.8593959
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an illustrative example of an interactive auditory perception approach performed by a humanoid robot called NICO, the Neuro Inspired COmpanion [1]. The video demonstrates a material classification task in the style of a classic TV game show. NICO and another candidate are supposed to determine the content of small plastic capsules that are visually indistinguishable. Shaking the capsules produces audio signals that range from rattling stones, over tinkling coins to swooshing sand. NICO can perceive and analyze these sounds to determine the material of the capsules content.
ER  - 

TY  - CONF
TI  - Computing Cross-Sections of the Workspace of Suspended Cable-Driven Parallel Robot with Sagging Cables Having Tension Limitations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5042
EP  - 5047
AU  - J. -. Merlet
PY  - 2018
KW  - cables (mechanical)
KW  - robot kinematics
KW  - suspended cable-driven parallel robot
KW  - sagging cables
KW  - horizontal cross-sections
KW  - tension limitations
KW  - CDPR
KW  - kinematics equations
KW  - inverse kinematics
KW  - Kinematics
KW  - Parallel robots
KW  - Mathematical model
KW  - Legged locomotion
KW  - Mechanical cables
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594321
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Although workspace is essential for the design and control of cable-driven parallel robots (CDPR) very few works have been devoted to this topic when sagging cables are considered, most probably because of the complexity of the cable model. In this paper we consider suspended CDPR with sagging cables that can support only a limited tension. We propose an algorithm to compute the border of horizontal cross-sections of the workspace for a given altitude and orientation of the platform. We show that singularities of the kinematics equations have to be taken into account for a proper determination of the border and that the workspace can be separated in several components according to the branch of the inverse kinematics on which the robot is evolving. We also compare the workspace obtained for ideal and sagging cables.
ER  - 

TY  - CONF
TI  - A Singularity-Robust LQR Controller for Parallel Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 270
EP  - 276
AU  - R. Bordalba
AU  - J. M. Porta
AU  - L. Ros
PY  - 2018
KW  - control system synthesis
KW  - linear quadratic control
KW  - mobile robots
KW  - nonlinear control systems
KW  - optimal control
KW  - robust control
KW  - torque control
KW  - singularity-robust LQR controller
KW  - five-bar parallel robot
KW  - optimal control law
KW  - expensive inverse dynamics computations
KW  - reliable controller
KW  - singularity-crossing trajectories
KW  - motion range
KW  - singularity-free regions
KW  - forward singularities
KW  - parallel robots
KW  - Trajectory
KW  - Parallel robots
KW  - Robot kinematics
KW  - Regulators
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594084
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Parallel robots exhibit the so-called forward singularities, which complicate substantially the planning and control of their motions. Often, such complications are circumvented by restricting the motions to singularity-free regions of the workspace. However, this comes at the expense of reducing the motion range of the robot substantially. It is for this reason that, recently, efforts are underway to control singularity-crossing trajectories. This paper proposes a reliable controller to stabilize such kind of trajectories. The controller is based on the classical theory of linear quadratic regulators, which we adapt appropriately to the case of parallel robots. As opposed to traditional computed-torque methods, the obtained controller does not rely on expensive inverse dynamics computations. Instead, it uses an optimal control law that is easy to evaluate, and does not generate instabilities at forward singularities. The performance of the controller is exemplified on a five-bar parallel robot accomplishing two tasks that require the traversal of singularities.
ER  - 

TY  - CONF
TI  - Performance of an IMU-Based Sensor Concept for Solving the Direct Kinematics Problem of the Stewart-Gough Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5055
EP  - 5062
AU  - S. Schulz
AU  - A. Seibel
AU  - J. Schlattmann
PY  - 2018
KW  - actuators
KW  - manipulator kinematics
KW  - pose estimation
KW  - sensor fusion
KW  - IMU-based sensor concept
KW  - direct kinematics problem
KW  - linear actuators
KW  - measurement errors
KW  - calculated manipulator platform
KW  - state-of-the-art Stewart-Gough platform
KW  - one-time pose determination
KW  - robustness
KW  - sensor fusion concepts
KW  - Manipulators
KW  - Actuators
KW  - Kinematics
KW  - Standards
KW  - Measurement errors
KW  - Accelerometers
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8594039
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The direct kinematics problem of the Stewart-Gough platform can be solved by measuring the manipulator platform's orientation and two of the linear actuators' orientations instead of the six linear actuators' lengths. In this paper, the effect of measurement errors on the calculated manipulator platform's pose is investigated using the Cramer-Ran lower bound and extensive experiments on a state-of-the-art Stewart-Gough platform. Furthermore, different algorithms and filters for one-time as well as continuous pose determinations are investigated. Finally, possible sensor fusion concepts for the one-time pose determination are presented to increase the robustness against noise and measurement errors.
ER  - 

TY  - CONF
TI  - An Active Stabilizer for Cable-Driven Parallel Robot Vibration Damping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5063
EP  - 5070
AU  - M. Lesellier
AU  - L. Cuvillon
AU  - J. Gangloff
AU  - M. Gouttefarde
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - closed loop systems
KW  - damping
KW  - manipulator kinematics
KW  - position control
KW  - vibration control
KW  - vibrations
KW  - parasitic vibrations
KW  - CDPR mobile platform
KW  - vibration damping
KW  - actuated rotating arms
KW  - control strategy
KW  - planar 3-DOF CDPR
KW  - three-arm stabilizer
KW  - cable-driven parallel robots
KW  - active stabilizer
KW  - position control
KW  - cable-driven parallel robot vibration
KW  - closed-loop system
KW  - Vibrations
KW  - Damping
KW  - Actuators
KW  - Stability analysis
KW  - Symmetric matrices
KW  - Torque
KW  - Jacobian matrices
DO  - 10.1109/IROS.2018.8594148
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Cable-Driven Parallel Robots (CDPRs) can execute fast motions across a large workspace. However, these performances are reached at the cost of a relatively low stiffness which often yields parasitic vibrations at the CDPR mobile platform. In this paper, vibration damping of CDPRs is addressed by means of an original active stabilizer consisting of actuated rotating arms installed on-board the CDPR mobile platform. A control strategy for the whole system, which consists of the CDPR and the stabilizer, and with one purpose for each-position control for the platform and vibration damping for the stabilizer-is designed. The system being controlled at two different time scales, the singular perturbation theory can be used to prove the stability of the corresponding closed-loop system. The efficiency of the proposed device and control strategy is tested in simulations in the case of a planar 3-DOF CDPR equipped with a three-arm stabilizer.
ER  - 

TY  - CONF
TI  - Design and Fabrication of a Bipedal Robot Using Serial-Parallel Hybrid Leg Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5095
EP  - 5100
AU  - K. G. Gim
AU  - J. Kim
AU  - K. Yamane
PY  - 2018
KW  - design engineering
KW  - legged locomotion
KW  - machine bearings
KW  - motion control
KW  - robot dynamics
KW  - velocity control
KW  - serial-parallel hybrid leg mechanism
KW  - forward walking motion
KW  - developed robot
KW  - feet workspace
KW  - pelvis structure
KW  - structural rigidity
KW  - bearings
KW  - carbon fiber tubes
KW  - agile bipedal locomotion
KW  - light structural inertia
KW  - parallel mechanism
KW  - serial mechanism
KW  - bipedal robot
KW  - performance evaluation
KW  - Legged locomotion
KW  - Foot
KW  - Hip
KW  - Servomotors
KW  - Humanoid robots
KW  - Knee
DO  - 10.1109/IROS.2018.8594182
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present the design and performance evaluation of a bipedal robot that utilizes the Hybrid Leg mechanism. It is a leg mechanism that achieves 6 DOF with a combined structure of serial and parallel mechanism. It is designed to have a light structural inertia and large workspace for agile bipedal locomotion. A new version of Hybrid Leg is fabricated with carbon fiber tubes and bearings to improve its structural rigidity and accuracy while supporting its weight. A pair of Hybrid Legs is assembled together for bipedal locomotion. In the assembly, we adopt a pelvis structure with an yaw angle offset to enlarge the feet workspace, inspired by the toe-out angle of the human feet. The workspace and range of velocity are presented in simulation and verified with hardware experiments. We also demonstrate a simple forward walking motion with the developed robot.
ER  - 

TY  - CONF
TI  - Configuration Space Metrics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5101
EP  - 5108
AU  - H. J. Jeon
AU  - A. D. Dragan
PY  - 2018
KW  - manipulator kinematics
KW  - path planning
KW  - configuration space metrics
KW  - robot manipulators
KW  - task constraint
KW  - Euclidean distance metric
KW  - robot behavior
KW  - 3DOF arm
KW  - Jaco 7DOF arm
KW  - Task analysis
KW  - Euclidean distance
KW  - Manifolds
KW  - End effectors
KW  - Elbow
DO  - 10.1109/IROS.2018.8593564
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics - metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.
ER  - 

TY  - CONF
TI  - Fused Angles and the Deficiencies of Euler Angles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5109
EP  - 5116
AU  - P. Allgeuer
AU  - S. Behnke
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - robot dynamics
KW  - fused angles
KW  - Euler angles representation
KW  - balance-related scenarios
KW  - parameter sensitivities
KW  - walking bipedal robots
KW  - three-dimensional Euclidean space
KW  - Quaternions
KW  - Task analysis
KW  - Legged locomotion
KW  - Rotation measurement
KW  - Intelligent robots
KW  - Sensitivity
DO  - 10.1109/IROS.2018.8593384
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Just like the well-established Euler angles representation, fused angles are a convenient parameterisation for rotations in three-dimensional Euclidean space. They were developed in the context of balancing bodies, most specifically walking bipedal robots, but have since found wider application due to their useful properties. A comparative analysis between fused angles and Euler angles is presented in this paper, delineating the specific differences between the two representations that make fused angles more suitable for representing orientations in balance-related scenarios. Aspects of comparison include the locations of the singularities, the associated parameter sensitivities, the level of mutual independence of the parameters, and the axisymmetry of the parameters.
ER  - 

TY  - CONF
TI  - Geometric Optimization of a Large Scale CDPR Operating on a Building Facade
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5117
EP  - 5124
AU  - H. Hussein
AU  - J. C. Santos
AU  - M. Gouttefarde
PY  - 2018
KW  - buildings (structures)
KW  - cables (mechanical)
KW  - construction industry
KW  - design engineering
KW  - mobile robots
KW  - optimisation
KW  - geometric design procedure
KW  - geometric optimization
KW  - building facade
KW  - large-scale construction applications
KW  - wrench-feasibility constraints
KW  - cable-driven parallel robot
KW  - cable tension
KW  - Geometry
KW  - Optimization
KW  - Indexes
KW  - Buildings
KW  - Robots
KW  - Trajectory
KW  - Payloads
DO  - 10.1109/IROS.2018.8593900
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper deals with the optimization of the geometry of a Cable-Driven Parallel Robot (CDPR) dedicated to large-scale construction applications. Since the maximum cable tension is a critical parameter in the design of the CDPR components, the geometry of the CDPR is optimized by minimizing the lowest maximum cable tension that ensures the validity of wrench-feasibility constraints. The geometric design procedure used in this paper consists of two phases, the CDPR cable connections is selected in the first phase followed by a second phase where the geometric parameters are optimized. The result of this procedure is an original fully-constrained CDPR geometry.
ER  - 

TY  - CONF
TI  - Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum Robot in SE(3)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5125
EP  - 5132
AU  - R. Grassmann
AU  - V. Modes
AU  - J. Burgner-Kahrs
PY  - 2018
KW  - actuators
KW  - approximation theory
KW  - neural nets
KW  - position control
KW  - robot kinematics
KW  - forward kinematics
KW  - concentric tube continuum robot
KW  - high computational load
KW  - nonlinear modeling effort
KW  - data-driven approach
KW  - physics-based model
KW  - robot prototype
KW  - inverse kinematics approximation
KW  - artificial neural network
KW  - ReLU
KW  - rectified linear unit
KW  - rotation actuator error
KW  - trigonometric function
KW  - mechanics modeling
KW  - position control
KW  - Electron tubes
KW  - Robots
KW  - Kinematics
KW  - Neural networks
KW  - Quaternions
KW  - Computational modeling
KW  - Load modeling
DO  - 10.1109/IROS.2018.8594451
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent physics-based models of concentric tube continuum robots are able to describe pose of the tip, given the preformed translation and rotation in joint space of the robot. However, such model-based approaches are associated with high computational load and highly non-linear modeling effort. A data-driven approach for computationally fast estimation of the kinematics without requiring the knowledge and the uncertainties in the physics-based model would be an asset. This paper introduces an approach to solve the forward kinematics as well as the inverse kinematics of concentric tube continuum robots with 6-DOF in three dimensional space SE(3). Two artificial neural networks with ReLU (rectified linear unit) activation functions are designed in order to approximate the respective kinematics. Measured data from a robot prototype are used in order to train, validate, and test the proposed approach. We introduce a representation of the rotatory joints by trigonometric functions that improves the accuracy of the approximation. The results with experimental measurements show higher accuracy for the forward kinematics compared to the state of the art mechanics modeling. The tip error is less then 2.3 mm w.r.t. position (1 % of total robot length) and 1.1° w.r.t. orientation. The single artificial neural network for the inverse kinematics approximation achieves a translation and rotation actuator error of 4.0 mm and 8.3 0, respectively.
ER  - 

TY  - CONF
TI  - Learning Forward and Inverse Kinematics Maps Efficiently
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5133
EP  - 5140
AU  - D. Kubus
AU  - R. Rayyes
AU  - J. J. Steil
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - elasticity
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - nonparametric statistics
KW  - learning forward kinematics maps
KW  - exploratory learning approaches
KW  - action-outcome sampling
KW  - omnielastic manipulators
KW  - rigid manipulators
KW  - inverse kinematics mappings
KW  - nonparametric models
KW  - elastic discretely-actuated robots
KW  - rigid discretely-actuated robots
KW  - tailored parametric models
KW  - data-efficiency
KW  - Manipulators
KW  - Kinematics
KW  - Solid modeling
KW  - Elasticity
KW  - Analytical models
KW  - Strain
DO  - 10.1109/IROS.2018.8593833
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.
ER  - 

TY  - CONF
TI  - A Fail-Safe Semi-Centralized Impedance Controller: Validation on a Parallel Kinematics Ankle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Ruscelli
AU  - A. Laurenzi
AU  - E. Mingo Hoffman
AU  - N. G. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - robot kinematics
KW  - torque control
KW  - fail-safe semicentralized impedance controller
KW  - parallel kinematics ankle
KW  - COMAN+
KW  - dual four-bar mechanism
KW  - fully centralized impedance control implementation
KW  - torque reference inputs
KW  - local joint torque controllers
KW  - safer robot response
KW  - Impedance
KW  - Torque
KW  - Kinematics
KW  - Actuators
KW  - Damping
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594112
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes the implementation of an impedance controller on the ankle level of COMAN+, a robot with parallel kinematics ankles actuated by a dual four-bar mechanism. The main contribution of the work is a realization of said control scheme that grants a less abrupt and safer robot response in case of system failures, that would cause the local joint torque controllers to lose their torque reference inputs. In particular, we propose a semi-centralized impedance control implementation which eliminates the instability of the pure joint torque control schemes used in the classical fully centralized methods when torque reference interruptions occur. Finally, we present experimental results, proving the effectiveness of our method and demonstrating how it ensures a safer behaviour compared to a fully centralized impedance control implementation when the communication to the ankle joints is interrupted. This paper is a follow-up work of [1], which presented and analyzed the parallel kinematics ankles.
ER  - 

TY  - CONF
TI  - Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5148
EP  - 5154
AU  - S. Ghosh
AU  - K. Otsu
AU  - M. Ono
PY  - 2018
KW  - aerospace robotics
KW  - Mars
KW  - mobile robots
KW  - path planning
KW  - planetary rovers
KW  - robot kinematics
KW  - state estimation
KW  - statistical distributions
KW  - light-weight analytic solution
KW  - rocky terrain
KW  - typical numeric approaches
KW  - onboard computation
KW  - single collision
KW  - unstructured terrain
KW  - robot motion planning
KW  - kinematics-based collision detection
KW  - planetary rovers
KW  - probabilistic kinematic state estimation
KW  - deterministic state bounds
KW  - distribution models
KW  - probabilistic safety guarantees
KW  - worst-case evaluation
KW  - deterministic bounds
KW  - probability distributions
KW  - frequent false positive detection
KW  - conservative safety check approach
KW  - worst-case values
KW  - constraint violation
KW  - terrain height
KW  - articulated suspension systems
KW  - Mars 2020 rover mission
KW  - Approximate Clearance Evaluation
KW  - Wheels
KW  - Kinematics
KW  - Planning
KW  - Space vehicles
KW  - Uncertainty
KW  - Numerical models
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593771
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.
ER  - 

TY  - CONF
TI  - Constrained Control of Robotic Manipulators Using the Explicit Reference Governor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5155
EP  - 5162
AU  - K. Merckaert
AU  - B. Vanderborght
AU  - M. M. Nicotra
AU  - E. Garone
PY  - 2018
KW  - actuators
KW  - collision avoidance
KW  - end effectors
KW  - manipulators
KW  - position control
KW  - robot arm
KW  - ERG
KW  - Explicit Reference Governor
KW  - nonconvex constraints
KW  - constrained control
KW  - 2DOF planar robotic manipulator
KW  - end-effector position
KW  - actuator saturations
KW  - static obstacles
KW  - joint ranges
KW  - Manipulator dynamics
KW  - Safety
KW  - End effectors
KW  - Actuators
KW  - Navigation
DO  - 10.1109/IROS.2018.8593857
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic manipulators that are intended to interact with humans in their operating region are systems that need formal safety guarantees. Current solutions cannot handle both input and state constraints, have difficulties handling nonconvex constraints, or are computationally too expensive. To tackle these drawbacks, we analyzed a constrained control strategy, the Explicit Reference Governor (ERG), which can address both input and state constraints, and does not require any online optimization, thus making it computationally inexpensive. This paper presents the theory of the ERG for a general robotic manipulator and shows simulations for a specific 2DOF planar robotic manipulator. The proposed control scheme is able to steer the robot arm to the desired end-effector position, or an admissible approximation, in the presence of limited joint ranges, actuator saturations, and static obstacles. As a result, the ERG is a promising tool for the control of robotic manipulators subject to constraints.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Novel Semi-Active Hybrid Unilateral Stance Control Knee Ankle Foot Orthosis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5163
EP  - 5168
AU  - J. Gil
AU  - M. C. Sánchez-Villamañán
AU  - J. Gòmez
AU  - A. Ortiz
AU  - J. L. Pons
AU  - J. C. Moreno
AU  - A. J. Del-Ama
PY  - 2018
KW  - bioelectric phenomena
KW  - gait analysis
KW  - medical control systems
KW  - muscle
KW  - neuromuscular stimulation
KW  - orthotics
KW  - patient rehabilitation
KW  - semiactive hybrid orthotic system
KW  - unilateral pathological human walking
KW  - mechanical control
KW  - noninvasive muscle electrostimulation
KW  - artificial activation
KW  - ankle joint muscles
KW  - hybrid scheme
KW  - electrical stimulation patterns
KW  - ankle muscles
KW  - stance control knee ankle foot orthoses
KW  - Iron
KW  - Muscles
KW  - Knee
KW  - Legged locomotion
KW  - Foot
KW  - Exoskeletons
KW  - Fatigue
DO  - 10.1109/IROS.2018.8594219
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents the design and development of a semi-active hybrid orthotic system for support and facilitation of unilateral pathological human walking. The system is based on a novel lower limb orthosis with mechanical control and its combination with non-invasive muscle electrostimulation. The paper presents the concept design and realization of a novel Stance Control Knee Ankle Foot Orthoses (SCKAFO) and the design of Functional Electrical Stimulation (FES) strategies for artificial activation of ankle joint muscles in this hybrid scheme for gait support. In particular, we present the investigation of the effects of electrical stimulation patterns of ankle muscles synchronized in real-time with gait events., on the possible biomechanical alterations to gait in able-bodied individuals (n=8). Bilateral 3D ground reaction forces (GRF) were analyzed between barefoot overground walking with and without FES of ankle muscles. The observed effects of the tested FES strategy are coherent with a physiological gait strategy and compatible with the proposed SCKAFO.
ER  - 

TY  - CONF
TI  - Iterative Learning Vector Field for FES-Supported Cyclic Upper Limb Movements in Combination with Robotic Weight Compensation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5169
EP  - 5174
AU  - A. Passon
AU  - T. Seel
AU  - J. Massmann
AU  - C. Freeman
AU  - T. Schauer
PY  - 2018
KW  - bioelectric phenomena
KW  - biomechanics
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - medical computing
KW  - medical robotics
KW  - muscle
KW  - neuromuscular stimulation
KW  - neurophysiology
KW  - patient rehabilitation
KW  - physiological models
KW  - control system
KW  - spinal cord injured patients
KW  - functional electrical stimulation
KW  - iterative learning control approaches
KW  - prespecified reference trajectory
KW  - self-selected cadence
KW  - smooth stimulation intensity profiles
KW  - complex neuromusculoskeletal model
KW  - initial RMS error
KW  - steady state RMS error
KW  - adaptive FES support
KW  - purely volitional movements
KW  - breaststroke motions
KW  - control algorithm
KW  - artificially activated muscles
KW  - learning algorithm
KW  - joint angle space
KW  - stimulation intensities
KW  - ILVF
KW  - transversal plane
KW  - cable tension forces
KW  - arm weight
KW  - breaststroke swimming exercises
KW  - repetitive arm movements
KW  - cable-driven robotic system
KW  - anterior deltoid
KW  - posterior deltoid
KW  - triceps
KW  - biceps
KW  - feedback-controlled FES
KW  - robotic weight compensation
KW  - FES-supported cyclic upper limb movements
KW  - iterative learning vector field
KW  - Iron
KW  - Muscles
KW  - Trajectory
KW  - Manipulators
KW  - Torque
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594120
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotics and Functional Electrical Stimulation (FES) are well-established technologies for the rehabilitation of stroke and spinal cord injured (SCI) patients. We propose a hybrid solution that combines feedback-controlled FES of biceps and triceps as well as posterior and anterior deltoid with a cable-driven robotic system to support repetitive arm movements, like “breaststroke swimming” exercises. The robotic system partially compensates the arm weight by controlling the cable tension forces, and the FES promotes motion in the transversal plane. To adjust the FES support to the needs of the individual patients we use an iterative learning vector field (ILVF) which encodes the stimulation intensities that are applied to guide the patient along a pre-specified reference trajectory in the joint angle space. In contrast to previous iterative learning control approaches, the ILVF allows the patient to perform the motion at self-selected cadence. The proposed learning algorithm explicitly takes the dynamics of the artificially activated muscles into account and assures smooth stimulation intensity profiles. The control algorithm is tested in simulations using a complex neuro-musculoskeletal model. For “breaststroke” motions, the initial RMS error of purely volitional movements is reduced from 38° to 10° within 21 cycles by the adaptive FES support. After 50 iterations of the ILVF, the algorithm converges to a steady state RMS error of 4°. Changes in the patient's muscle activity and cadence were well tolerated by the control system and did not cause a noticable increase in the steady state RMS error.
ER  - 

TY  - CONF
TI  - Cooperative Control for Knee Joint Flexion-Extension Movement Restoration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5175
EP  - 5180
AU  - M. A. Alouane
AU  - H. Rifai
AU  - Y. Amirat
AU  - S. Mohammed
PY  - 2018
KW  - adaptive control
KW  - closed loop systems
KW  - medical control systems
KW  - neuromuscular stimulation
KW  - nonlinear control systems
KW  - observers
KW  - orthotics
KW  - patient rehabilitation
KW  - torque control
KW  - knee joint angle trajectory
KW  - cooperative control
KW  - functional electrical stimulation
KW  - quadriceps muscle group
KW  - nonlinear disturbance observer
KW  - torque estimation
KW  - rehabilitation technologies
KW  - open-loop FES
KW  - closed-loop adaptive control
KW  - powered knee joint orthosis
KW  - knee joint flexion-extension movement restoration
KW  - Torque
KW  - Muscles
KW  - Knee
KW  - Iron
KW  - Estimation
KW  - Fatigue
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594230
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a cooperative control approach that combines the use of a powered knee joint orthosis along with Functional Electrical Stimulation (FES) for knee joint flexion-extension movement restoration. A closed-loop adaptive control and an open-loop FES of the quadriceps muscle group are combined together to track a desired knee joint angle trajectory of flexion/extension movements. A nonlinear disturbance observer is used to estimate the torque provided by the subject's muscles through the FES. Simulations and experiments with a healthy subject show the feasibility of the proposed approach. Experiments show the repeatability of motion and the complementarity between the torque provided by the quadriceps muscle through FES and the one delivered by the orthosis actuator to ensure satisfactory tracking of the desired trajectory.
ER  - 

TY  - CONF
TI  - New Approach of Cycling Phases Detection to Improve FES-Pedaling in SCI Individuals
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5181
EP  - 5186
AU  - R. Baptista
AU  - B. Sijobert
AU  - C. A. Coste
PY  - 2018
KW  - bioelectric phenomena
KW  - biomechanics
KW  - neuromuscular stimulation
KW  - patient rehabilitation
KW  - functional electrical stimulation
KW  - optimal pedaling force evolution
KW  - cyclist legs
KW  - inertial measurement units
KW  - motion segmentation
KW  - adaptive properties
KW  - muscle activation
KW  - tricycles
KW  - spinal cord
KW  - FES-pedaling
KW  - Knee
KW  - Superluminescent diodes
KW  - Hidden Markov models
KW  - Adaptation models
KW  - Switches
KW  - Legged locomotion
KW  - Muscles
DO  - 10.1109/IROS.2018.8594162
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - FES allows spinal cord injured individuals to propel tricycles by means of their own leg power. The stimulation patterns are in most of the cases predefined and muscle activation triggered on the basis of the pedal position. This requires an empirical tuning to fit the pattern to the pilot sitting position and distance to crank with no possible generalization and no adaptive properties. The aim of the present article is to introduce a new approach of motion segmentation based on inertial measurement units located on the cyclist legs with the final aim to predict the optimal pedaling force evolution. Results obtained with one healthy subject in different cycling conditions are presented and the application to FES-cycling discussed.
ER  - 

TY  - CONF
TI  - Adaptive FES Assistance Using a Novel Gait Phase Detection Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - W. Huo
AU  - V. Arnez-Paniagua
AU  - M. Ghedira
AU  - Y. Amirat
AU  - J. Gracies
AU  - S. Mohammed
PY  - 2018
KW  - bioelectric phenomena
KW  - bone
KW  - gait analysis
KW  - neuromuscular stimulation
KW  - walking speeds
KW  - gastrocnemius muscles
KW  - knee reextension
KW  - plantar flexor cocontraction
KW  - adaptive knee-joint based functional electrical stimulation method
KW  - classical FES method
KW  - abnormal gaits
KW  - normal gaits
KW  - foot contact conditions
KW  - foot-mounted inertial measurement unit
KW  - late swing
KW  - dorsiflexor stimulation
KW  - swing phase
KW  - paretic patients
KW  - foot drop
KW  - gait phase detection approach
KW  - adaptive FES assistance
KW  - Integrated circuits
KW  - Iron
KW  - Foot
KW  - Legged locomotion
KW  - Knee
KW  - Accelerometers
KW  - Sensors
DO  - 10.1109/IROS.2018.8594051
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an adaptive knee-joint based Functional Electrical Stimulation (FES)method to correct the foot drop of paretic patients during swing phase. The rationale behind the adaptive FES is to amplify dorsiflexor stimulation in the late swing when it is most needed in order to face the increased plantar flexor co-contraction as gastrocnemius muscles are stretched by knee re-extension. To accurately detect the swing phase (i.e., toes off (TO)and initial contact (IC)), a novel algorithm is proposed by using a foot-mounted inertial measurement unit (IMU). The proposed strategy is verified by experiments conducted with three healthy subjects and three paretic patients. The experimental results show that highly accurate detection of TO/I C can be achieved under different walking speeds and foot contact conditions (normal and abnormal gaits). The clinical experimental results with paretic patients also reveal that similar effects on ankle dorsiflexion can be observed during mid and late swing using the proposed adaptive FES with respect to the classical FES method, while the adaptive FES used lower stimulation intensity.
ER  - 

TY  - CONF
TI  - Online Self-Supervised Long-Range Scene Segmentation for MAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5194
EP  - 5199
AU  - S. Daftry
AU  - Y. Agrawal
AU  - L. Matthies
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - vision-based autonomous MAV flight
KW  - self-supervised online learning
KW  - adaptive scene segmentation
KW  - data-driven methods
KW  - manually annotated training data
KW  - geometry-based methods
KW  - sensor capabilities
KW  - robust scene understanding
KW  - complex dynamic environments
KW  - autonomous flights
KW  - lightweight MicroAerial Vehicles
KW  - MAVs
KW  - online self-supervised long-range scene segmentation
KW  - Image segmentation
KW  - Training
KW  - Robot sensing systems
KW  - Visualization
KW  - Real-time systems
KW  - Convolution
DO  - 10.1109/IROS.2018.8594405
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.
ER  - 

TY  - CONF
TI  - PAMPC: Perception-Aware Model Predictive Control for Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - D. Falanga
AU  - P. Foehn
AU  - P. Lu
AU  - D. Scaramuzza
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - nonlinear programming
KW  - path planning
KW  - predictive control
KW  - robot vision
KW  - PAMPC
KW  - lighting conditions
KW  - visual-inertial odometry pipeline
KW  - low-power ARM computer
KW  - nonlinear optimization problem
KW  - action objective
KW  - numerical optimization
KW  - perception-aware model predictive control framework
KW  - model-based optimization framework
KW  - perception objective
KW  - quadrotor
KW  - motion planning
KW  - Cameras
KW  - Trajectory
KW  - Optimization
KW  - Robot vision systems
KW  - Predictive control
KW  - Planning
DO  - 10.1109/IROS.2018.8593739
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.
ER  - 

TY  - CONF
TI  - History-Aware Autonomous Exploration in Confined Environments Using MAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Witting
AU  - M. Fehr
AU  - R. Bähnemann
AU  - H. Oleynikova
AU  - R. Siegwart
PY  - 2018
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - sampling-based exploration algorithms
KW  - 3D exploration planner
KW  - field-of-view depth sensor
KW  - configuration space
KW  - high sampling efficiency
KW  - computational constrained real world MAV
KW  - history-aware autonomous exploration
KW  - confined environments
KW  - inspection tasks
KW  - high-dimensional path planning problem
KW  - microaerial vehicle
KW  - search and rescue missions
KW  - next-best views
KW  - robot orientation
KW  - Planning
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Trajectory
KW  - History
KW  - Optimization
DO  - 10.1109/IROS.2018.8594502
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.
ER  - 

TY  - CONF
TI  - Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Kouris
AU  - C. Bouganis
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - convolutional neural nets
KW  - feature extraction
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - regression analysis
KW  - robot vision
KW  - sensor fusion
KW  - velocity control
KW  - indoor flights
KW  - unmanned aerial vehicles
KW  - civilian applications
KW  - indoor-flight dataset
KW  - agent distance-to-collision prediction
KW  - drone safe deployment
KW  - on-board monocular camera
KW  - external sensors
KW  - spatio-temporal feature extraction
KW  - static appearance information
KW  - motion information
KW  - robot distance estimation
KW  - linear velocity
KW  - navigation policy learning
KW  - real-distance labels
KW  - raw visual input
KW  - regression CNN
KW  - real-time obstacle avoidance
KW  - indoor robot navigation
KW  - autonomous navigation methods
KW  - UAV
KW  - self-supervised CNN-based approach
KW  - navigation policy
KW  - Robots
KW  - Navigation
KW  - Sensors
KW  - Drones
KW  - Cameras
KW  - Task analysis
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594204
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.
ER  - 

TY  - CONF
TI  - Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5224
EP  - 5231
AU  - S. MohaimenianPour
AU  - R. Vaughan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - control engineering computing
KW  - convolutional neural nets
KW  - face recognition
KW  - feature extraction
KW  - gesture recognition
KW  - human-robot interaction
KW  - image colour analysis
KW  - image segmentation
KW  - object detection
KW  - robust control
KW  - video signal processing
KW  - YOLOv2 deep convolutional neural network
KW  - hand-and-face detector
KW  - gestural human-UAV interface
KW  - robust control
KW  - hand-labelled videos
KW  - face-engagement
KW  - robust sensor front-end
KW  - gray-scale images
KW  - robust real-time system
KW  - mono-camera user detection
KW  - human-robot interaction
KW  - human-UAV interaction experiments
KW  - Detectors
KW  - Feature extraction
KW  - Proposals
KW  - Training
KW  - Object detection
KW  - Face detection
KW  - Cameras
DO  - 10.1109/IROS.2018.8593709
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.
ER  - 

TY  - CONF
TI  - Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5232
EP  - 5238
AU  - J. Stevens
AU  - R. Mahony
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - helicopters
KW  - image sequences
KW  - mobile robots
KW  - robot vision
KW  - dense high-speed optical flow
KW  - real-time motion cues
KW  - obstacle avoidance
KW  - smooth trajectory
KW  - image flow representation
KW  - forest environment
KW  - forward sensitive reactive control
KW  - quadrotor VTOL
KW  - aerial robotic vehicles
KW  - 3D full reconstruction
KW  - fully image based control criteria
KW  - Optical sensors
KW  - Optical imaging
KW  - Adaptive optics
KW  - Velocity measurement
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8593606
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.
ER  - 

TY  - CONF
TI  - Angle-Encoded Swarm Optimization for UAV Formation Path Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5239
EP  - 5244
AU  - V. T. Hoang
AU  - M. D. Phung
AU  - T. H. Dinh
AU  - Q. P. Ha
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - multi-robot systems
KW  - particle swarm optimisation
KW  - angle-encoded particle swarm optimization
KW  - 3DR solo drones
KW  - mission planner
KW  - Internet-of- Things
KW  - UAV formation path planning
KW  - triangular formation maintenance
KW  - swarm convergence
KW  - multiple-objective optimisation algorithm
KW  - unmanned aerial vehicles
KW  - feasible path planning technique
KW  - Trajectory
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Task analysis
KW  - Cost function
KW  - Shape
KW  - Quadcopter
KW  - θ-PSO
KW  - path planning
KW  - loT
KW  - triangular formation
KW  - collision avoidance
DO  - 10.1109/IROS.2018.8593930
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - An Integrated Localization-Navigation Scheme for Distance-Based Docking of UAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5245
EP  - 5250
AU  - T. Nguyen
AU  - Z. Qiu
AU  - M. Cao
AU  - T. H. Nguyen
AU  - L. Xie
PY  - 2018
KW  - adaptive estimation
KW  - autonomous aerial vehicles
KW  - convergence
KW  - image sequences
KW  - invariance
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - position control
KW  - single landmark
KW  - unmanned aerial vehicles
KW  - GPS-less environment
KW  - optical flow sensors
KW  - ultra-wideband ranging sensors
KW  - discrete-time LaSalle invariance principle
KW  - UAV
KW  - distance-based docking problem
KW  - integrated localization-navigation scheme
KW  - asymptotic docking
KW  - delicate control scheme
KW  - relative position
KW  - nonlinear adaptive estimation scheme
KW  - bounded velocity
KW  - discrete-time integrators
KW  - navigation tasks
KW  - relative localization
KW  - integrated estimation-control scheme
KW  - arbitrarily unknown position
KW  - Navigation
KW  - Convergence
KW  - Distance measurement
KW  - Adaptive estimation
KW  - Estimation
KW  - Task analysis
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8594251
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we study the distance-based docking problem of unmanned aerial vehicles (UAVs) by using a single landmark placed at an arbitrarily unknown position. To solve the problem, we propose an integrated estimation-control scheme to simultaneously achieve the relative localization and navigation tasks for discrete-time integrators under bounded velocity: a nonlinear adaptive estimation scheme to estimate the relative position to the landmark, and a delicate control scheme to ensure both the convergence of the estimation and the asymptotic docking at the given landmark. A rigorous proof of convergence is provided by invoking the discrete-time LaSalle's invariance principle, and we also validate our theoretical findings on quadcopters equipped with ultra-wideband ranging sensors and optical flow sensors in a GPS-less environment.
ER  - 

TY  - CONF
TI  - Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5307
EP  - 5312
AU  - J. Stria
AU  - V. Hlavác
PY  - 2018
KW  - clothing
KW  - computer graphics
KW  - control engineering computing
KW  - convolutional neural nets
KW  - feature extraction
KW  - image classification
KW  - manipulators
KW  - neurocontrollers
KW  - robot vision
KW  - service robots
KW  - support vector machines
KW  - 3D objects
KW  - feature vector extraction
KW  - t-shirts
KW  - hanging garments classification
KW  - 3D point clouds
KW  - SVM
KW  - generalized convolution operation
KW  - single global feature vector
KW  - convolutional neural network
KW  - depth maps
KW  - robotic arm
KW  - hanging state
KW  - robotic manipulation
KW  - garment category
KW  - Clothing
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Convolution
KW  - Image reconstruction
DO  - 10.1109/IROS.2018.8593741
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The presented work deals with classification of garment categories including pants, shorts, shirts, T-shirts and towels. The knowledge of the garment category is crucial for its robotic manipulation. Our work focuses particularly on garments being held in a hanging state by a robotic arm. The input of our method is a set of depth maps taken from different viewpoints around the garment. The depths are fused into a single 3D point cloud. The cloud is fed into a convolutional neural network that transforms it into a single global feature vector. The network utilizes a generalized convolution operation defined over the local neighborhood of a point. It can deal with permutations of the input points. It was trained on a large dataset of common 3D objects. The extracted feature vector is classified with SVM trained on smaller datasets of garments. The proposed method was evaluated on publicly available data and compared to the original methods, achieving competitive performance and better generalization capability.
ER  - 

TY  - CONF
TI  - Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5313
EP  - 5319
AU  - M. Santos
AU  - M. Egerstedt
PY  - 2018
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - multirobot teams
KW  - heterogeneous sensing capabilities
KW  - coverage algorithm
KW  - multirobot systems
KW  - qualitatively different sensing modalities
KW  - required sensing modalities
KW  - particular sensory capability
KW  - distributed control algorithm
KW  - robotic platform
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Monitoring
KW  - Temperature sensors
KW  - Density functional theory
DO  - 10.1109/IROS.2018.8594056
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.
ER  - 

TY  - CONF
TI  - An Adaptive Robot for Building In-Plane Programmable Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Pieber
AU  - R. Neurauter
AU  - J. Gerstmayr
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - mechatronics
KW  - mesh generation
KW  - nonlinear control systems
KW  - optimal control
KW  - position control
KW  - robot kinematics
KW  - supports
KW  - autonomous cells
KW  - unstructured triangular meshes
KW  - arbitrary planar shapes
KW  - self-reconfigurable system
KW  - programmable matter
KW  - kinematic model
KW  - cellular robot
KW  - positioning errors
KW  - simplified mechanical model
KW  - adaptive robot
KW  - single elements
KW  - triangular cells
KW  - linear actuators
KW  - triangular shapes
KW  - in-plane programmable structures
KW  - Actuators
KW  - Robots
KW  - Couplings
KW  - Kinematics
KW  - Shape
KW  - Latches
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593381
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new approach for cellular robots is presented. The single elements of the robot are triangular cells, which can change their shape by means of linear actuators at each edge. The novelty concerns the connection of autonomous cells at their edges rather than at the vertices. In this way, unstructured triangular meshes can be formed. The robot can self-reconfigure and thus can reproduce almost arbitrary planar shapes. In a similar way, the system has been realized with tetrahedrons in a simplified way within a previous work. The self-reconfigurable system shall serve as a basis for programmable matter. The present paper includes the mechatronic design, its components and the kinematic model of the cellular robot. In order to reduce positioning errors, a model is developed, which considers compliance and clearance in the links and joints. Based on a simplified mechanical model using elastic trusses, the positioning errors can be predicted. The parameters of these models are identified from simple motion sequences. Furthermore, the nonlinearity of actuators is identified and corrected. In this way, the desired triangular shapes can be prescribed without measuring the position of the cells.
ER  - 

TY  - CONF
TI  - Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5344
EP  - 5349
AU  - D. St-Onge
AU  - C. Pinciroli
AU  - G. Beltrame
PY  - 2018
KW  - finite state machines
KW  - mobile robots
KW  - multi-robot systems
KW  - spatiotemporal phenomena
KW  - computation-free robots
KW  - emergent behavioural structure
KW  - finite state machine
KW  - minimal robots
KW  - nonholonomic robots
KW  - self-healing circle formations
KW  - frontal binary sensor
KW  - grid-search method
KW  - computation-free behaviour
KW  - spatio-temporal dynamics
KW  - Robot sensing systems
KW  - Mobile robots
KW  - Robot kinematics
KW  - Apertures
KW  - Standards
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593439
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.
ER  - 

TY  - CONF
TI  - Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Lee
AU  - D. Yi
AU  - S. S. Srinivasa
PY  - 2018
KW  - Bayes methods
KW  - Markov processes
KW  - Monte Carlo methods
KW  - Pareto optimisation
KW  - path planning
KW  - implicit uniform distribution
KW  - Pareto-frontier
KW  - progressive objective evaluation
KW  - objective functions
KW  - Pareto-optimal trajectories
KW  - multiobjective motion planning
KW  - multiobjective motion-planning problems
KW  - sampling trajectories
KW  - Pareto-optimal set
KW  - Markov chain Monte Carlo method
KW  - Trajectory
KW  - Markov processes
KW  - Planning
KW  - Monte Carlo methods
KW  - Sociology
KW  - Optimization
DO  - 10.1109/IROS.2018.8593735
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.
ER  - 

TY  - CONF
TI  - Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5366
EP  - 5371
AU  - J. Jesús Roldán
AU  - J. Del Cerro
AU  - A. Barrientos
PY  - 2018
KW  - game theory
KW  - preferred task allocations
KW  - competitive algorithm
KW  - game theoretical algorithms
KW  - described scenario
KW  - relevant question
KW  - partial information
KW  - disaster area
KW  - drone swarms
KW  - task allocation
KW  - game theory
KW  - Task analysis
KW  - Robots
KW  - Resource management
KW  - Games
KW  - Drones
KW  - Nash equilibrium
KW  - Genetic algorithms
DO  - 10.1109/IROS.2018.8594145
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.
ER  - 

TY  - CONF
TI  - Magnetic Navigation of a Rotating Colloidal Swarm Using Ultrasound Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5380
EP  - 5385
AU  - Q. Wang
AU  - L. Yang
AU  - J. Yu
AU  - C. Vong
AU  - P. W. Yan Chiu
AU  - L. Zhang
PY  - 2018
KW  - biomedical ultrasonics
KW  - image enhancement
KW  - magnetic particles
KW  - medical image processing
KW  - medical robotics
KW  - microrobots
KW  - nanomedicine
KW  - nanoparticles
KW  - magnetic navigation
KW  - rotating colloidal swarm
KW  - ultrasound images
KW  - paramagnetic nanoparticle-based swarm
KW  - simple rotating magnetic fields
KW  - microrobotic swarm
KW  - enhanced ultrasound imaging
KW  - imaging contrast
KW  - microrobot imaging
KW  - nanoparticle
KW  - solid surface
KW  - Magnetic resonance imaging
KW  - Ultrasonic imaging
KW  - Nanoparticles
KW  - Magnetic recording
KW  - Magnetic moments
KW  - Navigation
DO  - 10.1109/IROS.2018.8593898
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Microrobots are considered as promising tools for biomedical applications. However, the imaging of them becomes challenges in order to be further applied on in vivo environments. Here we report the magnetic navigation of a paramagnetic nanoparticle-based swarm using ultrasound images. The swarm can be generated using simple rotating magnetic fields, resulting in a region containing particles with a high area density. Ultrasound images of the swarm shows a periodic changing of imaging contrast. The reason for such dynamic contrast has been analyzed and experimental results are presented. Moreover, this swarm exhibits enhanced ultrasound imaging in comparison to that formed by individual nanoparticles with a low area density, and the relationship between imaging contrast and area density is testified. Furthermore, the microrobotic swarm can be navigated near a solid surface at different velocities, and the imaging contrast show negligible changes. This method allows us to localize and navigate a microrobotic swarm with enhanced ultrasound imaging indicating a promising approach for imaging of microrobots.
ER  - 

TY  - CONF
TI  - A Multi-Rate State Observer for Visual Tracking of Magnetic Micro-Agents Using 2D Slow Medical Imaging Modalities
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Kaya
AU  - A. Denasi
AU  - S. Scheggi
AU  - E. Agbahca
AU  - C. Yoon
AU  - D. H. Gracias
AU  - S. Misra
PY  - 2018
KW  - biological tissues
KW  - biomedical optical imaging
KW  - biomedical ultrasonics
KW  - cameras
KW  - Kalman filters
KW  - medical image processing
KW  - object tracking
KW  - observers
KW  - sampling methods
KW  - surgery
KW  - multirate state observer
KW  - visual tracking
KW  - magnetic microagents
KW  - Luenberger state estimators
KW  - minimally invasive surgery
KW  - tracking error
KW  - ultrasound microscope
KW  - ultrasound machine
KW  - electromagnetic coils
KW  - Kalman state estimator
KW  - multirate state estimation
KW  - medical imaging modality
KW  - multirate sampling methods
KW  - Visualization
KW  - Tracking
KW  - Biomedical imaging
KW  - Jacobian matrices
KW  - Two dimensional displays
KW  - State estimation
KW  - Magnetic resonance imaging
DO  - 10.1109/IROS.2018.8594349
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Minimally invasive surgery can benefit greatly from utilizing micro-agents. These miniaturized agents need to be clearly visualized and precisely controlled to ensure the success of the surgery. Since medical imaging modalities suffer from low acquisition rate, multi-rate sampling methods can be used to estimate the intersample states of micro-agents. Hence, the sampling rate of the controller can be virtually increased even if the position data is acquired using a slow medical imaging modality. This study presents multi-rate Luenberger and Kalman state estimators for visual tracking of micro-agents. The micro-agents are tracked using sum of squared differences and normalized cross correlation based visual tracking. Further, the outputs of the two methods are merged to minimize the tracking error and prevent tracking failures. During the experiments, the micro-agents with different geometrical shapes and sizes are imaged using a 2D ultrasound machine and a microscope, and manipulated using electromagnetic coils. The multi-rate state estimation accuracy is measured using a high speed camera. The precision of the tracking and multi-rate state estimation are verified experimentally under challenging conditions. For this purpose, an elliptical shaped magnetic micro-agent with a length of 48 pixels is used. Maximum absolute error in x and y axes are 2.273 and 2.432 pixels for an 8-fold increase of the sample rate (25 frames per second), respectively. During the experiments, it was observed that the micro-agents could be tracked more reliably using normalized cross correlation based visual tracking and inters ample states could be estimated more accurately using Kalman state estimator. Experimental results show that the proposed method could be used to track micro-agents in medical imaging modalities and estimate system states at intermediate time instants in real-time.
ER  - 

TY  - CONF
TI  - Human Motion Classification Based on Multi-Modal Sensor Data for Lower Limb Exoskeletons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5431
EP  - 5436
AU  - J. Beil
AU  - I. Ehrenberger
AU  - C. Scherer
AU  - C. Mandery
AU  - T. Asfour
PY  - 2018
KW  - biomechanics
KW  - force sensors
KW  - gait analysis
KW  - hidden Markov models
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - patient rehabilitation
KW  - pattern classification
KW  - wearable computers
KW  - human motion classification
KW  - multimodal sensor data
KW  - lower limb exoskeletons
KW  - intuitive exoskeleton control
KW  - improved user acceptance
KW  - wearability comfort
KW  - exoskeleton control system
KW  - online classification
KW  - lower-limb exoskeleton
KW  - defined motion patterns
KW  - recent sensor measurements
KW  - sliding window approach
KW  - training data
KW  - passive exoskeleton
KW  - 3D-force sensors
KW  - 3 inertial measurement units
KW  - correct classification
KW  - generalization performance
KW  - hidden Markov models
KW  - Exoskeletons
KW  - Hidden Markov models
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Force
KW  - Force sensors
KW  - Thigh
DO  - 10.1109/IROS.2018.8594110
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.
ER  - 

TY  - CONF
TI  - A Novel Joint Torque Estimation Method and Sensory System for Assistive Lower Limb Exoskeletons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Saccares
AU  - I. Sarakoglou
AU  - N. G. Tsagarakis
PY  - 2018
KW  - biomechanics
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - torque
KW  - torque control
KW  - novel joint torque estimation method
KW  - sensory System
KW  - assistive lower limb exoskeletons
KW  - hip
KW  - reference signals
KW  - life scenarios
KW  - noncyclic locomotion activity
KW  - unexpected terrain
KW  - unpredicted interactions
KW  - upper body
KW  - mass location
KW  - sensorized shoe sensing system
KW  - inverse static analysis
KW  - lower limbs
KW  - leg joint
KW  - body posture sensors
KW  - sensorized shoes
KW  - interaction loads
KW  - irregular terrains
KW  - natural feet postures
KW  - knee torques
KW  - iT-Knee Bipedal System
KW  - assistive task
KW  - Sensors
KW  - Foot
KW  - Torque
KW  - Task analysis
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Knee
DO  - 10.1109/IROS.2018.8594250
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a novel method for estimating online the torques at the ankle, knee and hip of a user with the goal of generating reference signals for torque controlled lower limb exoskeletons. In particular, this approach attempts to address difficulties arising in real life scenarios when noncyclic locomotion activity, unexpected terrain or unpredicted interactions with the surroundings occur. An advantage of the proposed method is that it does not require any information on the user's upper body (i.e. pose, weight and center of mass location)or on any interaction of the user's upper body with the environment (i.e. payload handling or pushing and pulling task). By monitoring the interaction of the user's feet with the ground through a novel sensorized shoe sensing system, the method applies an inverse static analysis on the user's lower limbs to estimate in real time the torque at each leg joint. The system is fully wearable, ergonomic and portable and uses a reduced number of body posture sensors. The design of the sensorized shoes permits plantar flexion, while measuring the toe and heel orientation and the interaction loads. This allows walking on irregular terrains and natural feet postures in different tasks. Trials were performed to validate the proposed approach under different tasks and terrains. Finally, the knee torques estimated online by the proposed strategy were used as reference signals to drive the iT-Knee Bipedal System in an assistive task.
ER  - 

TY  - CONF
TI  - Robotic Hand-Free-Stick for Walking Balance Assistance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5445
EP  - 5450
AU  - Y. Tanaka
AU  - N. Oyama
AU  - T. Takenaka
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - humanoid robots
KW  - legged locomotion
KW  - pressure measurement
KW  - servomotors
KW  - stick motion
KW  - walking tests
KW  - HFS
KW  - ZMP area
KW  - walking balance assistance
KW  - robotic hand-free-stick
KW  - wearable robotic stick
KW  - walking assistance
KW  - nonserious dysfunction
KW  - Zero moment point
KW  - hands free conditions
KW  - body balance ability
KW  - boots type prototype
KW  - lightweight robotic stick
KW  - slider-link mechanism
KW  - stick angle
KW  - hand-free-stick
KW  - Legged locomotion
KW  - Hafnium
KW  - Foot
KW  - Prototypes
KW  - Senior citizens
KW  - Weight measurement
DO  - 10.1109/IROS.2018.8593389
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a wearable robotic stick for walking assistance, called “Hand-Free-Stick” (HFS), for people with non-serious dysfunction in their gait. The basic idea of the proposed HFS is to enlarge ZMP (Zero moment point) area of a user under hands free conditions and to augment his/her body balance ability in walking. A boots type prototype of the HFS is developed with a lightweight robotic stick using a servomotor, in which the slider-link mechanism works to regulate the stick angle and length at the same time. The stick motion is controlled by a single-board computer based on the distribution of foot/feet pressures measured by the sensor system using eight load cells attached at the sole of boots. A set of walking tests with/without the prototype of HFS is carried out for four healthy subjects and demonstrates the effectiveness of the proposed HFS to expand the ZMP area leading to walking balance assistance.
ER  - 

TY  - CONF
TI  - Soft Fabric Actuator for Robotic Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5451
EP  - 5456
AU  - S. Y. Yang
AU  - K. H. Cho
AU  - Y. Kim
AU  - K. Kim
AU  - J. H. Park
AU  - H. S. Jung
AU  - J. U. Ko
AU  - H. Moon
AU  - J. C. Koo
AU  - H. Rodrigue
AU  - J. W. Suk
AU  - J. Nam
AU  - H. R. Choi
PY  - 2018
KW  - electroactive polymer actuators
KW  - fabrics
KW  - microactuators
KW  - polymer fibres
KW  - polymers
KW  - wearable robots
KW  - weaving
KW  - coiled soft actuators
KW  - STCA multiple fabrication method
KW  - continuous fabrication method
KW  - actuation test
KW  - soft fabric actuator
KW  - actuation strain
KW  - robotic applications
KW  - twisted and coiled soft actuators
KW  - Spandex TCA
KW  - Nylon TCA
KW  - human arm size mannequin
KW  - angle control
KW  - Actuators
KW  - Fabrics
KW  - Fabrication
KW  - Strain
KW  - Weaving
KW  - Yarn
KW  - Connectors
DO  - 10.1109/IROS.2018.8594275
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.
ER  - 

TY  - CONF
TI  - Child-Sized Passive Exoskeleton for Supporting Voluntary Sitting and Standing Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5457
EP  - 5462
AU  - K. Sasaki
AU  - M. Sugimoto
AU  - T. Sugiyama
AU  - D. F. Paez Granados
AU  - K. Suzuki
PY  - 2018
KW  - biomechanics
KW  - handicapped aids
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - position control
KW  - springs (mechanical)
KW  - wearable robots
KW  - child-sized passive exoskeleton
KW  - voluntary sitting-standing posture transition
KW  - lower limb impairment
KW  - gas springs
KW  - voluntary upper body motion
KW  - posture transition model
KW  - minimum jerk criterion
KW  - toilet usage
KW  - toilet seat
KW  - voluntary posture transition
KW  - voluntary sitting motion
KW  - voluntary standing motion
KW  - exoskeleton design
KW  - center of gravity transition
KW  - seating position
KW  - locomotion capability
KW  - children self-reliant social activities
KW  - Exoskeletons
KW  - Knee
KW  - Wheelchairs
KW  - Pediatrics
KW  - Mathematical model
KW  - Trajectory
KW  - Springs
DO  - 10.1109/IROS.2018.8593744
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a novel passive exoskeleton for voluntary sitting-standing posture transition for children with lower limb impairment. The design of the exoskeleton is based on the utilization of the center of gravity transition through the user's upper body motion. The passive exoskeleton powered by gas springs allows the user to realize a natural-like posture transition by the user's voluntary upper body motion. We designed the posture transition model such that the user can realize the posture transition in a natural manner based on a minimum jerk criterion. The proposed design aims to permit toilet usage without transferring seating positions between the exoskeleton and toilet seat. Furthermore, the developed mechanism can be integrated with a regular wheelchair, which would allow users to have locomotion capability. We believe that the design can improve children's self-reliant social activities by supporting their voluntary posture transition and toilet use. In this paper, we describe the detailed design process of the exoskeleton and preliminary experiments to investigate its effectiveness through evaluation with a healthy participant.
ER  - 

TY  - CONF
TI  - Hands-Free Assistive Manipulator Using Augmented Reality and Tongue Drive System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5463
EP  - 5468
AU  - F. Chu
AU  - R. Xu
AU  - Z. Zhang
AU  - P. A. Vela
AU  - M. Ghovanloo
PY  - 2018
KW  - assisted living
KW  - augmented reality
KW  - handicapped aids
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - user interfaces
KW  - augmented reality glasses
KW  - robot autonomy
KW  - tongue drive system
KW  - egocentric perspective
KW  - visual feedback
KW  - Cartesian control
KW  - robotic assistant
KW  - cognitive burden
KW  - physical disabilities
KW  - hands-free collaborative manipulation
KW  - human-in-the-loop system
KW  - hands-free assistive manipulator
KW  - robotic arm
KW  - Manipulators
KW  - Task analysis
KW  - Visualization
KW  - Tongue
KW  - Three-dimensional displays
KW  - Machine vision
DO  - 10.1109/IROS.2018.8594508
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A human-in-the-loop system is proposed to enable hands-free collaborative manipulation for people with physical disabilities. Studies show that the cognitive burden of interfacing with a robotic assistant decreases with increased robot autonomy. Incorporating modern advances in perception with augmented reality, this paper describes a framework for obtaining high-level intents from the user to specify manipulation tasks for execution. Augmented reality glasses provide an egocentric perspective to the robot. The glasses also provide visual feedback to users on a virtual menu showing a summary of robot affordances. The system processes the vision input to interpret the users environment. A Tongue Drive System serves as the input modality for triggering task execution by the robotic arm. Several manipulation experiments are performed with comparison to Cartesian control. The outcomes are also compared to reported state-of-the-art approaches. The results demonstrate competitive performance with minimal user input requirements.
ER  - 

TY  - CONF
TI  - Machine Learning Based Skill-Level Classification for Personal Mobility Devices Using Only Operational Characteristics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5469
EP  - 5476
AU  - Y. Huang
AU  - T. Mori
AU  - U. E. Manawadu
AU  - M. Kamezaki
AU  - T. Ishihara
AU  - M. Nakano
AU  - K. Koshiji
AU  - N. Higo
AU  - T. Tubaki
AU  - S. Sugano
PY  - 2018
KW  - electric vehicles
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - wheelchairs
KW  - machine learning
KW  - skill-level classification
KW  - personal mobility devices
KW  - operational characteristics
KW  - electric-powered wheelchairs
KW  - handicapped people
KW  - comfort travel
KW  - skill level classification method
KW  - skill level clusters
KW  - joystick operation data
KW  - five-level classification
KW  - supervised learning
KW  - user operation skills
KW  - unsupervised clustering
KW  - speed control
KW  - direction control
KW  - gradient boosting
KW  - Boosting
KW  - Vehicles
KW  - Sensors
KW  - Feature extraction
KW  - Acceleration
DO  - 10.1109/IROS.2018.8593578
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Some electric-powered wheelchairs are recently redefined as personal mobility devices. Their users are not only elderly or handicapped people, but also passengers with large baggage or pedestrians going from station to destination, i.e., last-mile transport. Consequently, people with different operation skills and expectations on personal mobility would become new users of this kind of devices. Safe and comfort travel in human co-existing environment such as sidewalks and airports is a social expectation for personal mobility. In order to realize this, understanding the operation skill of each user by a practical and simple method is essential. This paper thus introduced a skill level classification method by machine learning using only joystick data as input. In order to determine the number of skill level clusters, basic 26 features of joystick operation data are used for unsupervised clustering (single-linkage). We then made evaluation indexes by using speed, speed control, and direction control. For a five-level classification by using gradient boosting as supervised learning, we achieved a 67% accuracy (tolerance: 0) and a 98% accuracy (tolerance: 1). Further analysis of the feature importance of gradient boosting revealed key features to a good operation. Results also show that skill level differed among people with different driving experiences.
ER  - 

TY  - CONF
TI  - Pneumatic Microneedle-Based High-Density sEMG Sleeve for Stable and Comfortable Skin Contact During Dynamic Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5477
EP  - 5482
AU  - M. Kim
AU  - G. Gu
AU  - W. K. Chung
PY  - 2018
KW  - biomechanics
KW  - biomedical electrodes
KW  - biomedical measurement
KW  - electromyography
KW  - medical signal processing
KW  - needles
KW  - skin
KW  - microneedle-based electrodes
KW  - pneumatic microneedle-based high-density sEMG sleeve
KW  - pneumatic air control
KW  - sEMG signal processing
KW  - wireless signal transmission
KW  - sEMG signal quality
KW  - stable skin contact
KW  - comfortable skin contact
KW  - skin impedance
KW  - sEMG signal measurement
KW  - surface electromyography signals
KW  - motion artifacts
KW  - Velcro armbands
KW  - pneumatic pressure
KW  - needle length
KW  - Electrodes
KW  - Skin
KW  - Impedance
KW  - Needles
KW  - Solenoids
KW  - Valves
KW  - Motion artifacts
DO  - 10.1109/IROS.2018.8594135
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skin impedance should be minimized to obtain reliable and precise surface electromyography (sEMG) signals. High skin impedance decreases sensitivity to muscular activation and makes sEMG signals vulnerable to external noise. Microneedle-based electrodes have been proposed to achieve low skin impedance and high spatial resolution. However, unstable skin contact can occur during dynamic motion due to the electrodes small contact area, and the signal is easily influenced by motion artifacts. In this study, a pneumatic microneedle-based high-density sEMG sleeve is proposed that guarantees stable sEMG signal measurement by pressing the electrodes to the skin. Pneumatic air control, sEMG signal processing, and wireless signal transmission are processed in a single processor. The proposed interface automatically controls the air volume according to sEMG signal quality and is comfortable for users. The usability of the proposed interface was compared to conventional Velcro armbands by examining acquired sEMG signals. The results indicated that the proposed pneumatic sleeve guarantees reliable sEMG signal measurement during dynamic motion. Additionally, optimal pneumatic pressure and needle length were investigated.
ER  - 

TY  - CONF
TI  - Supervised Autonomous Locomotion and Manipulation for Disaster Response with a Centaur-Like Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - T. Klamt
AU  - D. Rodriguez
AU  - M. Schwarz
AU  - C. Lenz
AU  - D. Pavlichenko
AU  - D. Droeschel
AU  - S. Behnke
PY  - 2018
KW  - disasters
KW  - legged locomotion
KW  - manipulators
KW  - motion control
KW  - rescue robots
KW  - telerobotics
KW  - autonomous locomotion
KW  - mobile manipulation tasks
KW  - SAR
KW  - flexible locomotion
KW  - terrains
KW  - anthropomorphic upper body
KW  - complex tasks
KW  - direct teleoperation approaches
KW  - supervised autonomy approaches
KW  - disaster response scenarios
KW  - centaur-like robot Centauro
KW  - hybrid legged-wheeled base
KW  - operator assistance functionalities
KW  - search and rescue
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Legged locomotion
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8594509
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile manipulation tasks are one of the key challenges in the field of search and rescue (SAR) robotics requiring robots with flexible locomotion and manipulation abilities. Since the tasks are mostly unknown in advance, the robot has to adapt to a wide variety of terrains and workspaces during a mission. The centaur-like robot Centauro has a hybrid legged-wheeled base and an anthropomorphic upper body to carry out complex tasks in environments too dangerous for humans. Due to its high number of degrees of freedom, controlling the robot with direct teleoperation approaches is challenging and exhausting. Supervised autonomy approaches are promising to increase quality and speed of control while keeping the flexibility to solve unknown tasks. We developed a set of operator assistance functionalities with different levels of autonomy to control the robot for challenging locomotion and manipulation tasks. The integrated system was evaluated in disaster response scenarios and showed promising performance.
ER  - 

TY  - CONF
TI  - Design of a Lightweight, Ergonomic Manipulator for Enabling Expressive Gesturing in Telepresence Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5491
EP  - 5496
AU  - J. T. Slack
AU  - K. DeProw
AU  - Z. Anderson
AU  - R. M. Albacete Di Bartolomeo
AU  - J. L. Gorlewicz
AU  - J. B. Weinberg
PY  - 2018
KW  - end effectors
KW  - ergonomics
KW  - gesture recognition
KW  - human-robot interaction
KW  - telerobotics
KW  - anthropomorphic end effector
KW  - telepresence experience
KW  - expressive gesturing
KW  - tangible interactions
KW  - face-to-face interactions
KW  - remote users
KW  - local users
KW  - remote communication
KW  - telepresence robots
KW  - telepresence interactions
KW  - ergonomic manipulator
KW  - lightweight manipulator
KW  - engaging communication
KW  - expressive communication
KW  - physical actions
KW  - subconscious quality
KW  - primary social behaviors
KW  - physical referencing
KW  - expressive gestures
KW  - Manipulators
KW  - Shoulder
KW  - Telepresence
KW  - Elbow
KW  - Kinematics
KW  - Torque
DO  - 10.1109/IROS.2018.8593533
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent research on telepresence robots demonstrates that while they enable new heights of remote communication, there still exists challenges for both local and remote users in creating a connectedness one only encounters in face-to-face interactions. A large part of communication is beyond hearing and vision. Tangible interactions, expressive gestures, and physical referencing represent three of the primary social behaviors missing in the current telepresence experience. There is an inherent, subconscious quality to these physical actions that has been shown to allow more expressive and engaging communication. In this project we present the design, fabrication, and initial performance validation of a lightweight, ergonomic manipulator with a heavy, anthropomorphic end effector that enables gesturing capabilities for telepresence interactions.
ER  - 

TY  - CONF
TI  - Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5497
EP  - 5502
AU  - D. Lee
AU  - Y. S. Park
PY  - 2018
KW  - augmented reality
KW  - dexterous manipulators
KW  - haptic interfaces
KW  - human computer interaction
KW  - telerobotics
KW  - augmented teleoperation System
KW  - robot operating system
KW  - rugged robots
KW  - resource sharing
KW  - system integration
KW  - telerobotic system
KW  - operator interface
KW  - virtual fixture generation
KW  - current technology basis
KW  - human operator
KW  - complex robotic systems
KW  - telerobotic operation
KW  - enhanced teleoperator interface incorporating multimodal
KW  - current telerobotics technology
KW  - complex manipulation
KW  - dexterous manipulation
KW  - severe task requirements
KW  - unstructured nuclear environment
KW  - remote systems
KW  - ROS
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Telerobotics
KW  - Haptic interfaces
KW  - Fixtures
DO  - 10.1109/IROS.2018.8594482
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.
ER  - 

TY  - CONF
TI  - Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5503
EP  - 5508
AU  - M. Di Castro
AU  - C. V. Almagro
AU  - G. Lunghi
AU  - R. Marin
AU  - M. Ferre
AU  - A. Masi
PY  - 2018
KW  - force feedback
KW  - human computer interaction
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - telerobotics
KW  - velocity control
KW  - human-robot interface
KW  - tracking experiments
KW  - metallic parts
KW  - vision-based control system
KW  - robotic arm
KW  - monochromatic objects
KW  - metallic connectors
KW  - metallic plates
KW  - featureless objects
KW  - teleoperation loop
KW  - tracking system
KW  - object recognition
KW  - higher-level applications
KW  - safer system
KW  - interaction modalities
KW  - force feedback
KW  - bilateral teleoperation
KW  - low level interaction methods
KW  - multimodal interactions
KW  - robotic operator
KW  - harsh environments
KW  - safe robotic interventions
KW  - robotic guidance
KW  - metallic pieces
KW  - depth estimation
KW  - Cameras
KW  - Estimation
KW  - Robot vision systems
KW  - Correlation
KW  - Object recognition
KW  - Target tracking
DO  - 10.1109/IROS.2018.8594229
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.
ER  - 

TY  - CONF
TI  - Managing Off-Nominal Events in Shared Teleoperation with Learned Task Compliance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5509
EP  - 5516
AU  - P. Owan
AU  - J. Garbini
AU  - S. Devasia
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - telerobotics
KW  - off-nominal events
KW  - shared teleoperation
KW  - learned task compliance
KW  - teleoperation assistance
KW  - remote manufacturing
KW  - off-nominal situations
KW  - attenuate assistance
KW  - hole-cleaning task
KW  - imitation learning policies
KW  - Haptic interfaces
KW  - Task analysis
KW  - Robots
KW  - Collaboration
KW  - Trajectory
KW  - Tools
KW  - Force
DO  - 10.1109/IROS.2018.8594195
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This article studies imitation learning policies that encode task compliance to provide teleoperation assistance for remote manufacturing. The central challenge is how to handle off-nominal situations, such as out-of-sequence work or unplanned obstacles, since the assistance has not been trained to handle such scenarios. In such cases, there is potential for the assistance to degrade-rather than improve-operator performance. This work proposes a method that exploits the learned task compliance to classify persistent human actions as off-nominal, and attenuate assistance in these regions. Applied to a hole-cleaning task with n = 11 subjects, the proposed method shows up to 17% reduction in task completion time and up to 68% reduction in forces in off-nominal situations as compared to assistance without the method. Additionally, the method retains the performance improvements of assistance in nominal operating regimes.
ER  - 

TY  - CONF
TI  - Inferring Semantic State Transitions During Telerobotic Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. S. Bauer
AU  - P. Schmaus
AU  - A. Albu-Schäffer
AU  - D. Leidner
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - inference mechanisms
KW  - manipulators
KW  - mobile robots
KW  - service robots
KW  - telerobotics
KW  - telerobotic manipulation
KW  - autonomous operations
KW  - service robots
KW  - robot teleoperation
KW  - automated planning
KW  - higher abstraction level
KW  - semantic reasoning
KW  - abstract state
KW  - operational modes
KW  - simulation based geometric tracking
KW  - semantic state transitions inference
KW  - state inference entities
KW  - Semantics
KW  - Planning
KW  - Computational modeling
KW  - Physics
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594458
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human teleoperation of robots and autonomous operations go hand in hand in today's service robots. While robot teleoperation is typically performed on low to medium levels of abstraction, automated planning has to take place on a higher abstraction level, i.e. by means of semantic reasoning. Accordingly, an abstract state of the world has to be maintained in order to enable an operator to switch seamlessly between both operational modes. We propose a novel approach that combines simulation based geometric tracking and semantic state inference by means of so called State Inference Entities to overcome this issue. We also demonstrate how Evolutionary Strategies can be employed to refine simulation parameters. All experiments are demonstrated in real-world experiments conducted with the humanoid robot Rollin' Justin.
ER  - 

TY  - CONF
TI  - Smoother Position-Drift Compensation for Time Domain Passivity Approach Based Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5525
EP  - 5532
AU  - A. Coelho
AU  - H. Singh
AU  - T. Muskardin
AU  - R. Balachandran
AU  - K. Kondak
PY  - 2018
KW  - compensation
KW  - delays
KW  - force feedback
KW  - motion control
KW  - position control
KW  - robust control
KW  - synchronisation
KW  - telerobotics
KW  - robust methods
KW  - bilateral teleoperation
KW  - position drift
KW  - slave devices
KW  - position synchronization
KW  - position-drift problem
KW  - TDPA-based teleoperation
KW  - force feedback
KW  - high impulse-like force signals
KW  - teleoperation task
KW  - energy-based TDPA
KW  - compensator
KW  - regular-amplitude forces
KW  - time domain passivity approach
KW  - position tracking
KW  - position-drift compensation
KW  - master devices
KW  - robust stability
KW  - time 500.0 ms
KW  - Force
KW  - Task analysis
KW  - Delays
KW  - Communication channels
KW  - Time-domain analysis
KW  - Delay effects
KW  - Admittance
DO  - 10.1109/IROS.2018.8594125
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite being one of the most robust methods in bilateral teleoperation, Time Domain Passivity Approach (TDPA)presents the drawback of accumulating position drift between master and slave devices. The lack of position synchronization poses an obstacle to the performance of teleoperation and may prevent the successful accomplishment of such tasks. Several techniques have been developed in order to solve the position-drift problem in TDPA-based teleoperation. However, they either present poor transparency by over-conservatively constraining force feedback or add high impulse-like force signals that can be harmful to the hardware and to the human operator. We propose a new approach to compensate position drift in TDPA-based teleoperation in a smoother way, which keeps the forces within the normal range of the teleoperation task while preserving the level of transparency and the robust stability of energy-based TDPA. We also add a way of tuning the compensator to behave in accordance with the task being performed, whether it requires faster or smoother compensation. The feasibility and performance of the method were experimentally validated. Good position tracking and regular-amplitude forces are demonstrated with up to 500 ms round-trip constant and variable delays for hard-wall contacts.
ER  - 

TY  - CONF
TI  - An Ungrounded Master Device for Tele-Microassembly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Sakr
AU  - T. Daunizeau
AU  - D. Reversat
AU  - S. Régnier
AU  - S. Haliyo
PY  - 2018
KW  - grippers
KW  - haptic interfaces
KW  - manipulator kinematics
KW  - microassembling
KW  - micromanipulators
KW  - position control
KW  - robotic assembly
KW  - telerobotics
KW  - velocity control
KW  - ungrounded master device
KW  - tele-microassembly
KW  - intuitive remote handling interface
KW  - portable instrumented tweezers
KW  - spatial motion
KW  - slave kinematics
KW  - slave robot
KW  - hand-held assembly tool
KW  - joystick-like interfaces
KW  - microgripper
KW  - haptic feedback
KW  - position variables
KW  - speed variables
KW  - Tracking
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Force
KW  - Tools
DO  - 10.1109/IROS.2018.8594063
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Micro-assembly is a challenging issue for automation due to particularities of micro-world physics and limitations on sensors. Consequently, most applications are human-operated often with basic joystick-like interfaces. Beside being nonintuitive, these solutions do not provide their users with a meaningful insight into the microworld. This paper proposes a novel intuitive remote handling interface, using a classical hand-held assembly tool as a paradigm. The master device is a portable instrumented tweezers with one active degree of freedom. Its spatial motion, tracked by optical means, controls the slave kinematics while its pinch commands the slave robot's microgripper and provides haptic feedback. Different coupling strategies using position or speed variables are demonstrated.
ER  - 

TY  - CONF
TI  - “Hammer: Robot Programming Interface for Common People”
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5539
EP  - 5539
AU  - A. Brunete
AU  - M. Hernando
AU  - E. Gambao
PY  - 2018
KW  - Android (operating system)
KW  - augmented reality
KW  - control engineering computing
KW  - industrial robots
KW  - production engineering computing
KW  - robot programming
KW  - user interfaces
KW  - visual programming
KW  - Hammer
KW  - robot programming interface
KW  - tablet-based end-user interface
KW  - industrial robot programming
KW  - Hephestos European project
KW  - Android application
KW  - Android OS
KW  - visual programming concept
KW  - online programming
KW  - reprogramming
KW  - robot control
KW  - manual-guidance interface
KW  - augmented-reality-based-monitoring system
KW  - scratch programming language
KW  - sensors systems
KW  - Service robots
KW  - Robot programming
KW  - Task analysis
KW  - Robot sensing systems
KW  - Intelligent robots
KW  - Industrial Robots
KW  - Human-Centered Robotics
KW  - Intelligent and Flexible Manufacturing
DO  - 10.1109/IROS.2018.8594453
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video shows the main features of Hammer, a tablet-based end-user interface for industrial robot programming, in a real environment: a robotic cell created for the Hephestos European project. Hammer is an Android application that makes easier to program tasks for industrial robots like polishing, milling or grinding. It is based on the Scratch programming language, but specifically design and created for Android OS. It is a visual programming concept that allows non-skilled operators to create programs. The application allows to monitor the tasks while it is being executed by overlapping real time information through augmented reality. The application includes a teach pendant screen that can be customized according to the operator needs at every moment. The application is designed for online programming and reprogramming; easy use of learn-by-demonstration methods; easy connection with the robot control and sensors systems; and safety-system integration. It aims to be intuitive, easy to use, and simple. The application has four main parts: customized teach pendant, robot programming IDE and simulator, manual-guidance interface and augmented-reality-based-monitoring system.
ER  - 

TY  - CONF
TI  - The Art of Manipulation: Learning to Manipulate Blindly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Haddadin
AU  - L. Johannsmeier
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - peg-in-hole problem
KW  - manipulation learning
KW  - human performance
KW  - robot manipulation
KW  - high-level manipulation planning
KW  - autonomous skill learning
KW  - inter-class generalization
KW  - insertion skills
KW  - human-level performance
KW  - manipulation strategies
KW  - basic motor control
KW  - Task analysis
KW  - Motor drives
KW  - Planning
KW  - Intelligent robots
KW  - Art
KW  - Bridges
DO  - 10.1109/IROS.2018.8593923
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Performing skillfull manipulation is a very challenging task for robots. So far, even experts could barely program them to e.g. perform the well known peg-in-hole problem in the real world. Autonomously acquiring such skills, let alone generalizing them to new tasks, is still a major challenge. Typically, manipulation learning is approached with the help of large computation power, very long learning times, or possibly both. However, the performance achieved up to now is still far from human performance. We show the results of our new paradigm to robot manipulation. It bridges and unifies basic motor control, simple and complex manipulation strategies and high-level manipulation planning. The robots show autonomous skill learning, intra-class and inter-class generalization of insertion skills at human-level performance.
ER  - 

TY  - CONF
TI  - Toward the Next Generation of Robotic Waiters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5541
EP  - 5541
AU  - L. Moriello
AU  - D. Chiaravalli
AU  - L. Biagiotti
AU  - C. Melchiorri
PY  - 2018
KW  - compensation
KW  - feedforward
KW  - manipulators
KW  - service robots
KW  - sloshing phenomena
KW  - orientation compensation
KW  - robotic waiters
KW  - feed-forward control
KW  - robot arm
KW  - feed-forward controller
KW  - motion capture system
KW  - robot manipulator
KW  - Glass
KW  - Manipulators
KW  - Intelligent robots
KW  - Next generation networking
KW  - Steel
KW  - Tracking
DO  - 10.1109/IROS.2018.8594475
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The gap between human waiters and state-of-the-art robot systems that try to serve something to drink is often embarrassing, with the former able to manipulate glasses and trays or glasses on trays with incredible dexterity and the latter that move at incredible slowness. In this video, we want to show that robots can do it better by moving a bottle or a tankard full of beer that are simply placed on a flat steel plate connected the flange of a robot manipulator. The robot tracks the trajectory defined by a human operator that moves its hand in the 3D space, with a motion capture system that acquires in real time the position. A feed-forward controller, placed between the user and the robot and based on the combination of a smoother and proper orientation compensation, counteracts the lateral accelerations and suppress sloshing phenomena of the liquids. Eventually a camera mounted on the robot arm provides a visual feedback to the operator with monitoring purposes. The challenge for the operator was to drop the carried object. will the feed-forward control be robust enough to avoid this event, even at high speed? Watch the video and find out!
ER  - 

TY  - CONF
TI  - Human-Robot-Cooperation Real Time Robot Path Planning for Dynamic HRC-Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5542
EP  - 5542
AU  - M. Bdiwi
AU  - S. Hou
AU  - K. Delang
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - collision optimization
KW  - real time robot path planning
KW  - dynamic obstacles
KW  - motion planning framework
KW  - pre-programmed robot paths
KW  - dynamic HRC-applications
KW  - human-robot-cooperation
KW  - unstructured environment
KW  - robot velocity
KW  - movement paths
KW  - free robot trajectories
KW  - framework plans
KW  - human-robot shared workspace
KW  - human obstacles
KW  - Robots
KW  - Collision avoidance
KW  - Real-time systems
KW  - Machine tools
KW  - Dynamics
KW  - Safety
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594014
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-Robot shared workspace is a dynamic and unstructured environment. In such environment, pre-programmed robot paths might cause collisions or production disruptions. In order to solve this problem, motion planning framework has been proposed that adapts the robot's movement (path and speed)according to the human movement or any other dynamic obstacles in real time. Firstly, it defines the safety distance between robot and human or other obstacles. During run-time the 3D-Smart-Sensors capture the current position of human and other dynamic/static obstacles in human-robot shared workspace. The proposed framework plans and optimizes collision free robot trajectories with consideration for safety distance, path length and executing time. Once a new optimal trajectory is found, the framework controls the robot to adjust its movement paths. Moreover, the proposed framework can adjust the robot velocity based on the 3D-Zone Model of human-robot shared workspace. Therefore, the robot can reach its goal quickly and safely in a dynamic and unstructured environment.
ER  - 

TY  - CONF
TI  - High Power Hand with Retention Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5543
EP  - 5543
AU  - T. Mouri
AU  - H. Kawasaki
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - disasters
KW  - motion control
KW  - plates (structures)
KW  - power system control
KW  - retention mechanism
KW  - electrical power supply
KW  - electrical power saving
KW  - high power hand
KW  - multifingered robot hand
KW  - power manipulation
KW  - dexterous motion
KW  - Robots
KW  - Thumb
KW  - Power supplies
KW  - Force
KW  - Mechanical engineering
KW  - Conferences
DO  - 10.1109/IROS.2018.8594216
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.
ER  - 

TY  - CONF
TI  - On-Chip Virtual Vortex Gear and Its Application
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5544
EP  - 5544
AU  - T. Takayama
AU  - C. Dylan Tsai
AU  - M. Kaneko
PY  - 2018
KW  - flow visualisation
KW  - microchannel flow
KW  - pattern formation
KW  - valves
KW  - vortices
KW  - VVG
KW  - controllable valve
KW  - microfluidic system
KW  - flow speed
KW  - flow energy
KW  - chemical injection
KW  - sheath flow
KW  - 3D flow patterns
KW  - On-Chip Virtual Vortex Gear
KW  - Reynolds number
KW  - parallel streamlines
KW  - circular chamber
KW  - target chamber
KW  - spontaneous diffusing
KW  - Gears
KW  - Valves
KW  - Chemicals
KW  - Mechanical engineering
KW  - Microfluidics
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593418
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video presents a microfluidic phenomenon called “Virtual Vortex Gear (VVG)” and an application of it. The video contains 4 parts and is described as follows: The 1st part shows an application of VVG as a controllable valve in a micro fluidic system and the on and off of the valve are controlled by different flow speeds. The valve is turned on when the flow speed is high enough, and vice versa. The 2nd part shows the generation of VVG and its mechanism. When the flow speed, which is proportional to Reynolds Number, is gradually increased, the flow pattern evolves in the order as (1)parallel streamlines, (2)one vortex, (3)two vortices and eventually (4)three vortices including the last vortex inside the circular chamber. The evolution indicates the transmission of flow energy from the main stream to the inside of the chamber when the flow speed is over a certain range. In addition, every two adjacent vortices rotate in opposite directions which is just like a set of gears, and that is why we named it “VVG”. In the 3rd part, an application of VVG for chemical injection is demonstrated. A colored liquid is represented for the chemical and is surrounded by different sheath flow for the control of injection locations. It is found that only the fluid in a particular pinpoint can be injected into the target chamber. Furthermore, the complex but stable 3D flow patterns are visualized from the video. The last part of the video shows that different amount of chemical injection can be performed in different chambers along the same main stream and the distribution of the color is gradually become uniform by spontaneous diffusing.
ER  - 

TY  - CONF
TI  - Deformation Capture via Self-Sensing Capacitive Arrays (Video)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5545
EP  - 5545
AU  - O. Glauser
AU  - D. Panozzo
AU  - O. Hilliges
AU  - O. Sorkine-Hornung
PY  - 2018
KW  - capacitance
KW  - capacitance measurement
KW  - capacitive sensors
KW  - computerised instrumentation
KW  - data acquisition
KW  - deformation
KW  - mesh generation
KW  - neural nets
KW  - deformation capture
KW  - soft self-sensing capacitive arrays
KW  - dense surface deformations
KW  - electrode patterns
KW  - single silicone compound
KW  - electrode strip patterns
KW  - local capacitors
KW  - local capacitance measurements change
KW  - fabrication technique
KW  - modern fablabs
KW  - resulting sensors
KW  - area changes
KW  - underlying motion
KW  - deep neural network
KW  - sensor geometry
KW  - local area measurements
KW  - motion capture system
KW  - runtime vertex positions
KW  - state-of-the-art elastic surface energy
KW  - prototype sensor
KW  - deforming skeletal
KW  - Robot sensing systems
KW  - Strain
KW  - Electrodes
KW  - Fabrication
KW  - Intelligent robots
KW  - Compounds
KW  - Capacitors
DO  - 10.1109/IROS.2018.8594203
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this video we present soft self-sensing capacitive arrays and demonstrate their use in capturing dense surface deformations without requiring line of sight. The capacitive arrays are made of two electrode patterns embedded into a single silicone compound. The overlaps of the electrode strip patterns form local capacitors. As the sensor is stretched the local capacitance measurements change. We introduce a fabrication technique that allows to produce such sensors while only requiring hardware readily available in modern fablabs. The resulting sensors are able to densely capture area changes as they deform. Since they do not directly measure bend, a prior is required to fully reconstruct the underlying motion. We propose a deep neural network regressing the sensor geometry from the local area measurements. A motion capture system is used for training data acquisition. At runtime vertex positions are predicted and used as positional constraints to deform a mesh using a state-of-the-art elastic surface energy. The flexibility and accuracy of the introduced sensors is demonstrated in a series of controlled experiments and by fabricating a prototype sensor and applying it to capture deforming skeletal and non-skeletal objects.
ER  - 

TY  - CONF
TI  - Excuse Me, May I Say Something? A Robot Facilitating Q&A for Lectures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5546
EP  - 5546
AU  - O. Palinko
AU  - J. Shimaya
AU  - K. Hoeck
AU  - K. Ogawa
AU  - N. Jinnai
AU  - Y. Yoshikawa
AU  - H. Ishiguro
PY  - 2018
KW  - computer aided instruction
KW  - humanoid robots
KW  - human-robot interaction
KW  - Internet
KW  - neural nets
KW  - young students
KW  - CommU
KW  - desktop social robot
KW  - online messaging system
KW  - robot facilitating Q&a
KW  - Hiroshi Ishiguro
KW  - Logic gates
KW  - Intelligent robots
KW  - Monitoring
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593656
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hiroshi Ishiguro gave a lecture to a group of young students. We employed CommU, the desktop social robot, to manage the questions and answers for the talk. We encouraged the students to ask questions anytime. Half of the classroom was told to ask questions by raising their hand while the other half was shown an online messaging system developed for CommU, which allows the audience to post questions, which the robot would directly say. We had a gatekeeper to monitor for invalid sentences. In the middle of the presentation we asked the students to shift roles. The robot used a neural network based estimator of interruptibility to find the best time to speak. We did not expect too many questions, but the audience really embraced using the robot. They posted 44 questions to the presenter through CommU. On the other hand they asked 8 direct questions by raising their hands and standing up. Students thought that they gained more information from the lecturer using the robot than using the conventional method. In this instance we didnt stop the students from asking too many questions, but in a real-world application the gatekeeper will have to play an important role.
ER  - 

TY  - CONF
TI  - Towards Autonomous Auto Calibration of Unregistered RGB-D Setups: The Benefit of Plane Priors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5547
EP  - 5554
AU  - G. Halmetschlager-Funek
AU  - J. Prankl
AU  - M. Vincze
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - optimisation
KW  - spatial variables measurement
KW  - autonomous autocalibration
KW  - color sensor
KW  - depth sensor
KW  - camera system
KW  - structure from motion reconstructions
KW  - SfM reconstructions
KW  - optimization
KW  - robust calibration algorithm
KW  - robot perception
KW  - unregistered RGB-D setups
KW  - Calibration
KW  - Cameras
KW  - Sensors
KW  - Robots
KW  - Image color analysis
KW  - Image reconstruction
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593715
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the last few years novel color and depth (RGB-D) sensors have greatly pushed robot perception. To enable a precise pixel-wise fusion of color and depth information good calibration is needed. The calibration determines the intrinsic parameters, the extrinsic parameters, and corrects for depth errors. While classic calibration approaches involve a dedicated calibration target and a trained expert, the autonomous calibration of such camera systems for robots operating in unknown environments is still an open problem. It demands for robust methods that do not need an expert to set up or tune the algorithm. Hence, we present a robust calibration algorithm that utilizes structure from motion (SfM) reconstructions as a calibration target and incorporates plane priors in the optimization to improve the convergence behavior and improve the calibration robustness. We evaluate our method against the state of the art performing over 300 experiments on ten different datasets, and show a significant improvement of the calibration accuracy.
ER  - 

TY  - CONF
TI  - Adaptive Sensor Bias Estimation in Nine Degree of Freedom Inertial Measurement Units: Theory and Preliminary Evaluation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5555
EP  - 5561
AU  - A. R. Spielvogel
AU  - L. L. Whitcomb
PY  - 2018
KW  - angular measurement
KW  - attitude measurement
KW  - calibration
KW  - gyroscopes
KW  - inertial systems
KW  - magnetic field measurement
KW  - magnetic sensors
KW  - magnetometers
KW  - adaptive sensor bias estimation
KW  - three-axis magnetometers
KW  - three-axis accelerometers
KW  - three-axis angular rate sensors
KW  - high-end angular rate sensors
KW  - ring-laser gyros
KW  - MEMS gyros
KW  - compensation
KW  - attitude estimation
KW  - attitude and heading reference systems
KW  - nine degree of freedom inertial measurement units
KW  - sensor bias calibration methods
KW  - adaptive sensor bias observer
KW  - magnetic-north AHRS heading
KW  - DOF inertial measurement units
KW  - true-North heading AHRS estimation
KW  - Earth-rate estimation
KW  - 9-DOF IMU measurements
KW  - Robot sensing systems
KW  - Magnetometers
KW  - Instruments
KW  - Accelerometers
KW  - Observers
KW  - Gyroscopes
DO  - 10.1109/IROS.2018.8594439
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nine degrees of freedom (DOF) inertial measurement units (IMUs) comprised of three-axis magnetometers, three-axis accelerometers, and three-axis angular rate sensors are commonly used in attitude and heading reference systems (AHRSs). Two classes of AHRSs exist: systems that estimate true-North heading and systems that estimate magnetic-North heading. True-North heading AHRSs require high-end angular rate sensors which are sensitive enough to dynamically estimate Earth-rate (typically fiber-optic and ring-laser gyros), while magnetic-North AHRSs employ gyros that are not sensitive enough to dynamically estimate Earth-rate (i.e. all MEMS gyros). Thus, magnetic-North AHRSs employ magnetometers for estimating heading. This paper will focus on this class of magnetic-North AHRSs. These systems fuse IMU measurements to generate estimates of the instrument's roll, pitch, and magnetic heading. However, their accuracy is limited by sensor measurement bias that is unknown a priori. Hence, accurate sensor bias estimation and compensation is essential for true attitude estimation. This paper reports a novel adaptive sensor bias observer for sensor measurement biases in 9-DOF IMUs. The algorithm requires smaller angular movements of the instrument than other reported sensor bias calibration methods, does not require a priori knowledge of local fields like the local magnetic field or the local gravity vector, and does not require knowledge of the attitude of the instrument. Stability proofs, preliminary simulations, and a full-scale vehicle experimental evaluation are reported.
ER  - 

TY  - CONF
TI  - Automatic Extrinsic Calibration of a Camera and a 3D LiDAR Using Line and Plane Correspondences
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5562
EP  - 5569
AU  - L. Zhou
AU  - Z. Li
AU  - M. Kaess
PY  - 2018
KW  - calibration
KW  - cameras
KW  - measurement errors
KW  - optical radar
KW  - optical sensors
KW  - checkerboard
KW  - 3D light detection and ranging sensor
KW  - 3D line correspondences
KW  - 3D plane correspondences
KW  - measurement errors
KW  - plane-only algorithms
KW  - LiDAR measurement
KW  - LiDAR intrinsic scale factor
KW  - calibration process
KW  - laser points
KW  - parallel planar targets
KW  - automatic extrinsic calibration
KW  - Cameras
KW  - Laser radar
KW  - Calibration
KW  - Three-dimensional displays
KW  - Lasers
KW  - Robot vision systems
KW  - Approximation algorithms
DO  - 10.1109/IROS.2018.8593660
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we address the problem of extrinsic calibration of a camera and a 3D Light Detection and Ranging (LiDAR) sensor using a checkerboard. Unlike previous works which require at least three checkerboard poses, our algorithm reduces the minimal number of poses to one by combining 3D line and plane correspondences. Besides, we prove that parallel planar targets with parallel boundaries provide the same constraints in our algorithm. This allows us to place the checkerboard close to the LiDAR so that the laser points better approximate the target boundary without loss of generality. Moreover, we present an algorithm to estimate the similarity transformation between the LiDAR and the camera for the applications where only the correspondences between laser points and pixels are concerned. Using a similarity transformation can simplify the calibration process since the physical size of the checkerboard is not needed. Meanwhile, estimating the scale can yield a more accurate result due to the inevitable measurement errors of the checkerboard size and the LiDAR intrinsic scale factor that transforms the LiDAR measurement to the metric measurement. Our algorithm is validated through simulations and experiments. Compared to the plane-only algorithms, our algorithm can obtain more accurate result by fewer number of poses. This is beneficial to the large-scale commercial application.
ER  - 

TY  - CONF
TI  - SCALAR - Simultaneous Calibration of 2D Laser and Robot's Kinematic Parameters Using Three Planar Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5570
EP  - 5575
AU  - T. S. Lembono
AU  - F. Suárez-Ruiz
AU  - Q. Pham
PY  - 2018
KW  - calibration
KW  - industrial robots
KW  - laser ranging
KW  - position control
KW  - robot kinematics
KW  - calibration approaches
KW  - calibration parameters
KW  - geometric planar constraints
KW  - 2D Laser Range Finder
KW  - 6-DoF robot
KW  - calibration method
KW  - laser tracker
KW  - expensive external measurement system
KW  - calibrations
KW  - robot accuracy
KW  - industrial robots
KW  - kinematic parameters
KW  - simultaneous calibration
KW  - SCALAR
KW  - robot system
KW  - Robot kinematics
KW  - Calibration
KW  - Cameras
KW  - Measurement by laser beam
KW  - Kinematics
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8594073
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Industrial robots are increasingly used in various applications where the robot accuracy becomes very important, hence calibrations of the robot's kinematic parameters and the measurement system's extrinsic parameters are required. However, the existing calibration approaches are either too cumbersome or require another expensive external measurement system such as laser tracker or measurement spinarm. In this paper, we propose SCALAR, a calibration method to simultaneously improve the kinematic parameters of a 6-DoF robot and the extrinsic parameters of a 2D Laser Range Finder (LRF) that is attached to the robot. Three flat planes are placed around the robot, and for each plane the robot moves to several poses such that the LRF's ray intersect the respective plane. Geometric planar constraints are then used to optimize the calibration parameters using Levenberg-Marquardt nonlinear optimization algorithm. We demonstrate through simulations that SCALAR can reduce the average position and orientation errors of the robot system from 14.6 mm and 4.05° to 0.09 mm and 0.02°.
ER  - 

TY  - CONF
TI  - Keyframe-Based Photometric Online Calibration and Color Correction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Quenzel
AU  - J. Horn
AU  - S. Houben
AU  - S. Behnke
PY  - 2018
KW  - calibration
KW  - cameras
KW  - computer vision
KW  - image colour analysis
KW  - image motion analysis
KW  - image texture
KW  - photometry
KW  - pose estimation
KW  - splines (mathematics)
KW  - exposure estimation
KW  - thin plate splines
KW  - meshing algorithms
KW  - camera view poses estimation
KW  - sparse visual SLAM
KW  - gamma curve
KW  - structure-from-motion system
KW  - textured meshes
KW  - camera response function
KW  - sparsely sampled scene points
KW  - sixth-order polynomial
KW  - TPS
KW  - camera view
KW  - illumination
KW  - uniformly illuminated surfaces
KW  - global-shutter color cameras
KW  - real-time online vignetting
KW  - constant intensity
KW  - photoconsistency
KW  - computer vision algorithms
KW  - vignetting function
KW  - color correction
KW  - keyframe-based photometric online calibration
KW  - Cameras
KW  - Calibration
KW  - Splines (mathematics)
KW  - Image color analysis
KW  - Lighting
KW  - Estimation
KW  - Visualization
DO  - 10.1109/IROS.2018.8593595
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Finding the parameters of a vignetting function for a camera currently involves the acquisition of several images in a given scene under very controlled lighting conditions, a cumbersome and error-prone task where the end result can only be confirmed visually. Many computer vision algorithms assume photoconsistency, constant intensity between scene points in different images, and tend to perform poorly if this assumption is violated. We present a real-time online vignetting and response calibration with additional exposure estimation for global-shutter color cameras. Our method does not require uniformly illuminated surfaces, known texture or specific geometry. The only assumptions are that the camera is moving, the illumination is static and reflections are Lambertian. Our method estimates the camera view poses by sparse visual SLAM and models the vignetting function by a small number of thin plate splines (TPS) together with a sixth-order polynomial to provide a dense estimation of attenuation from sparsely sampled scene points. The camera response function (CRF) is jointly modeled by a TPS and a Gamma curve. We evaluate our approach on synthetic datasets and in real-world scenarios with reference data from a Structure-from-Motion (SfM) system. We show clear visual improvement on textured meshes without the need for extensive meshing algorithms. A useful calibration is obtained from a few keyframes which makes an on-the-fly deployment conceivable.
ER  - 

TY  - CONF
TI  - Automatic Calibration of Multiple Cameras and Depth Sensors with a Spherical Target
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Kümmerle
AU  - T. Kühner
AU  - M. Lauer
PY  - 2018
KW  - calibration
KW  - cameras
KW  - sensor fusion
KW  - spatial variables measurement
KW  - automatic calibration
KW  - multisensor calibration
KW  - spherical calibration target
KW  - subresolution detection accuracy
KW  - camera
KW  - depth sensor
KW  - Calibration
KW  - Cameras
KW  - Image edge detection
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Detectors
DO  - 10.1109/IROS.2018.8593955
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we present a novel approach for multi-sensor calibration that significantly outperforms current state-of-the-art. We introduce a new spherical calibration target which has major benefits over existing targets. Those are subresolution detection accuracy in both camera and depth sensor, view invariance and applicability to a wider range of sensor setups than current approaches. With our method a single person achieves high quality calibration in less than a minute. No preparations for setting up the environment for calibration is needed. Our method is fast, easy to use and fully automatic. We evaluate our method in simulation and show high accuracy with an error of less than 3mm in translation and 0.1 0 in rotation on real data.
ER  - 

TY  - CONF
TI  - Automated Tool Coordinate Calibration System of an Industrial Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5592
EP  - 5597
AU  - R. C. Luo
AU  - H. Wang
PY  - 2018
KW  - artificial intelligence
KW  - calibration
KW  - cameras
KW  - computer vision
KW  - error compensation
KW  - industrial manipulators
KW  - industrial robots
KW  - machine tools
KW  - neural nets
KW  - position control
KW  - production engineering computing
KW  - robot vision
KW  - tool calibration
KW  - automated tool
KW  - freight handling
KW  - tool replacement
KW  - collision accident
KW  - routine maintenance
KW  - tool coordinates
KW  - current industrial practices
KW  - artificial intelligence method
KW  - manual method
KW  - system independent method
KW  - automatic calibration
KW  - hand camera
KW  - tool position data
KW  - coordinate system conversion
KW  - calibration system functions
KW  - current robot
KW  - 6-degree-0f-freedom industrial robot
KW  - optimal deep neural network method error compensation
KW  - Tools
KW  - Robot kinematics
KW  - Cameras
KW  - Calibration
KW  - Service robots
KW  - Robot vision systems
KW  - Calibration
KW  - Tool Coordinate
KW  - CamShift
KW  - MeanShift
KW  - DNN
DO  - 10.1109/IROS.2018.8594298
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Due to the widespread use of industrial robots in market, its application has extended to welding, painting, and freight handling. And tool coordinate calibration is regularly modified after tool replacement due to collision accident or routine maintenance. After tool replacement, operators often rebuild tool coordinates. This is the traditional mode of operation in the current industrial practices. However, smart factory will make artificial intelligence method replace manual method. This paper presents a system independent method for automatic calibration of the tool coordinate system which is faster, simpler, cheaper and more effective than the manual method. The proposed method required images to be captured using two “eye to hand” cameras and one “eye in hand” camera. Tool position data is then acquired through CamShift and MeanShift algorithm for image trajectory tracking along with coordinate system conversion, several methods like PCA, LDA can deal with the vision data. Optimal Deep Neural Network (DNN) method error compensation of a robot allows the tool to automatically run with the calibration system functions. We have developed a 6 degrees of freedom(DoF) industrial robot for this experiment. Nine different kinds of DNN models are built and finally with suitable tool coordinate error compensation for the current robot, tool calibration can be achieved adaptively and efficiently.
ER  - 


