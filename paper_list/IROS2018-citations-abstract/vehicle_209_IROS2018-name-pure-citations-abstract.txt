total paper: 209
Title: A distributed vision-based consensus model for aerial-robotic teams
Key Words: autonomous aerial vehicles  geometry  mobile robots  object detection  position control  robot vision  target tracking  target position  PID-controlled steering responses  autonomous aerial robots  aerial-robotic teams  distributed vision-based consensus model  noisy detections  steering commands  ego-centric view  geometric constraints  Robot kinematics  Robot sensing systems  Cameras  Task analysis  Noise measurement 
Abstract: We present a distributed model for a team of autonomous aerial robots to collaboratively track a target without external control. The model uses distributed consensus to coordinate actions and to maintain formation via geometric constraints. Each robot uses its ego-centric view of a target and the relative distance from its two closest neighbors to infer its steering commands. To account for noisy and missing target detections, the robots exchange their estimated target position and formation configuration through shared PID-controlled steering responses. We show that the proposed model enables the team to maintain the view of a maneuvering target with varying acceleration under noisy detections and failures up to situations when all robots but one lose the target from their field of view.


Title: Self-Supervised Learning of the Drivable Area for Autonomous Vehicles
Key Words: image segmentation  learning (artificial intelligence)  neural nets  object detection  stereo image processing  road segmentation  automatic labeling pipeline  deterministic stereo-based approach  ground plane detection  KITTI dataset  semantic segmentation  good segmentation results  self-supervised learning  autonomous vehicles  training data  drivable area segmentation  deep neural networks  impressive progress  deep learning  traditional machine learning  deterministic algorithms  large-scale datasets  associated ground truth labels  expensive labor-intensive problem  off-the-shelf DNN  Image segmentation  Training data  Labeling  Generators  Histograms  Training  Cameras 
Abstract: We propose a new approach for generating training data for the task of drivable area segmentation with deep neural networks (DNN). The impressive progress of deep learning in recent years demonstrated a superior performance of DNNs over traditional machine learning and deterministic algorithms for various tasks. Nevertheless, the acquisition of large-scale datasets with associated ground truth labels still poses an expensive and labor-intensive problem. We contribute to the solution of this problem for the task of road segmentation by proposing an automatic labeling pipeline which leverages a deterministic stereo-based approach for ground plane detection to create large datasets suitable for training neural networks. Based on the popular Cityscapes [1] and KITTI dataset [2] and two off-the-shelf DNNs for semantic segmentation, we show that we can achieve good segmentation results on monocular images, which substantially exceed the performance of the algorithm employed for automatic labeling without the need of any manual annotation.


Title: Path-Following through Control Funnel Functions
Key Words: control system synthesis  feedback  learning (artificial intelligence)  mobile robots  motion control  road vehicles  robot dynamics  robust control  trajectory control  vehicle dynamics  control feedback laws  control funnel functions  path following  reference trajectory  autonomous vehicles  robustness  timing law  mathematical model  vehicle dynamics  demonstration-based learning algorithm  autonomous vehicle  Parkour car  trajectory tracking  Trajectory  Robustness  Autonomous vehicles  Timing  Vehicle dynamics  Automobiles  Trajectory tracking 
Abstract: We present an approach to path following using so-called control funnel functions. Synthesizing controllers to “robustly” follow a reference trajectory is a fundamental problem for autonomous vehicles. Robustness, in this context, requires our controllers to handle a specified amount of deviation from the desired trajectory. Our approach considers a timing law that describes how fast to move along a given reference trajectory and a control feedback law for reducing deviations from the reference. We synthesize both feedback laws using “control funnel functions” that jointly encode the control law as well as its correctness argument over a mathematical model of the vehicle dynamics. We adapt a previously described demonstration-based learning algorithm to synthesize a control funnel function as well as the associated feedback law. We implement this law on top of a 1/8th scale autonomous vehicle called the Parkour car. We compare the performance of our path following approach against a trajectory tracking approach by specifying trajectories of varying lengths and curvatures. Our experiments demonstrate the improved robustness obtained from the use of control funnel functions.


Title: Variational Autoencoder for End-to-End Control of Autonomous Driving with Novelty Detection and Training De-biasing
Key Words: learning (artificial intelligence)  neural nets  traffic engineering computing  variational autoencoder  end-to-end control  autonomous driving  novelty detection  end-to-end training  deep neural networks  DNN training  sufficient training data  trained models  insufficient training data  biased training data  self-supervised learning  latent variables  insufficiently trained situations  training data imbalance  latent distributions  training pipeline  full-scale autonomous vehicle  end-to-end controller  Training  Autonomous vehicles  Aerospace electronics  Image reconstruction  Training data  Data models  Robots 
Abstract: This paper introduces a new method for end-to-end training of deep neural networks (DNNs) and evaluates it in the context of autonomous driving. DNN training has been shown to result in high accuracy for perception to action learning given sufficient training data. However, the trained models may fail without warning in situations with insufficient or biased training data. In this paper, we propose and evaluate a novel architecture for self-supervised learning of latent variables to detect the insufficiently trained situations. Our method also addresses training data imbalance, by learning a set of underlying latent variables that characterize the training data and evaluate potential biases. We show how these latent distributions can be leveraged to adapt and accelerate the training pipeline by training on only a fraction of the total dataset. We evaluate our approach on a challenging dataset for driving. The data is collected from a full-scale autonomous vehicle. Our method provides qualitative explanation for the latent variables learned in the model. Finally, we show how our model can be additionally trained as an end-to-end controller, directly outputting a steering control command for an autonomous vehicle.


Title: Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  closed loop systems  computational complexity  hydrophones  inertial navigation  marine navigation  mobile robots  particle filtering (numerical methods)  position control  localization  autonomous underwater vehicles  Doppler velocity log  positional error  acoustic beacon  DVL-aided INS  LBL system  SandShark AUV  underwater navigation  computational complexity  phased-array beamforming  closed-loop operation  particle filter  vehicle-mounted passive hydrophone receiver-array  multiAUV operations  power requirements  inertial navigation system  robotic vehicle  Acoustics  Navigation  Array signal processing  Receivers  Acoustic measurements  Transponders  Time-frequency analysis 
Abstract: Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.


Title: Unscented Kalman Filter on Lie Groups for Visual Inertial Odometry
Key Words: distance measurement  Kalman filters  Lie groups  nonlinear filters  SLAM (robots)  state estimation  stereo image processing  unscented Kalman filter  Lie groups  visual information  inertial measurements  state estimation  robust estimation  computational efficiency  low-cost aerial vehicles  processor power  innovative filter  stereo visual inertial odometry building  invariant filtering theory  computational complexity  stereo multistate constraint Kalman filter  EuRoC dataset  MAV outdoor dataset  Cameras  Kalman filters  Visualization  Computational modeling  Uncertainty  Robustness  Noise measurement  Lie groups  unscented Kalman filter  visual inertial odometry  aerial vehicle  localization 
Abstract: Fusing visual information with inertial measurements for state estimation has aroused major interests in recent years. However, combining a robust estimation with computational efficiency remains challenging, specifically for low-cost aerial vehicles in which the quality of the sensors and the processor power are constrained by size, weight and cost. In this paper, we present an innovative filter for stereo visual inertial odometry building on: (i) the recently introduced stereo multistate constraint Kalman filter; (ii) the invariant filtering theory; and (iii) the unscented Kalman filter (UKF) on Lie groups. Our solution combines accuracy, robustness and versatility of the UKF. We then compare our approach to state-of-art solutions in terms of accuracy, robustness and computational complexity on the EuRoC dataset and a challenging MAV outdoor dataset.


Title: A Multi-Position Joint Particle Filtering Method for Vehicle Localization in Urban Area
Key Words: distance measurement  image matching  mobile robots  particle filtering (numerical methods)  path planning  probability  robot vision  flexible multiposition joint particle filtering  position error  anchor point  curving roads  ego-trajectory  probabilistic filtering method  flexible road map  long range navigation  error accumulation  visual odometry  traditional visual localization methods  autonomous vehicles  robust localization  urban area  vehicle localization  dense parallel road branches  Roads  Trajectory  Filtering  Urban areas  Wheels  Simultaneous localization and mapping  Navigation 
Abstract: Robust localization is a prerequisite for autonomous vehicles. Traditional visual localization methods like visual odometry suffer error accumulation on long range navigation. In this paper, a flexible road map based probabilistic filtering method is proposed to tackle this problem. To effectively match the ego-trajectory to various curving roads in map, a new representation based on anchor point (AP) which captures the main curving points on the trajectory is presented. Based on APs of the map and trajectory, a flexible Multi-Position Joint Particle Filtering (MPJPF) framework is proposed to correct the position error. The method features the capability of adaptively estimating a series of APs jointly and only updates the estimation at situations with low uncertainty. It explicitly avoids the drawbacks of obliging to determine the current position at large uncertain situations such as dense parallel road branches. The experiments carried out on KITTI benchmark demonstrate our success.


Title: Courteous Autonomous Cars
Key Words: automobiles  road traffic  traffic engineering computing  courteous autonomous cars  driving quality  cost function  purely selfish cost  interactive drivers  autonomous car  courtesy term  robot car  human behavior  courteous robot cars  human driver behavior  Autonomous automobiles  Vehicles  Cost function  Planning  Robot kinematics  Safety 
Abstract: Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.


Title: Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP
Key Words: automobiles  cameras  iterative methods  laser ranging  mobile robots  motion estimation  optical scanners  pose estimation  sensor fusion  SLAM (robots)  joint ego-motion estimation  laser scanner  monocular camera  autonomous vehicles  SLAM algorithms  sensor suite  laser range finder  3D point clouds  iterative closest point problem  sensor modality  orientation estimation  autonomous cars  pose estimation  autonomous robots  1-DoF ICP  data association  Cameras  Iterative closest point algorithm  Lasers  Three-dimensional displays  Robot vision systems  Image color analysis 
Abstract: Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.


Title: Fire-Aware Planning of Aerial Trajectories and Ignitions
Key Words: aerospace computing  aerospace control  autonomous aerial vehicles  computer simulation  helicopters  ignition  path planning  trajectory control  wildfires  fire-aware planning  aerial trajectories  fire vectors  fire simulation  fire-aware planner  fire simulator predictions  ignition spheres  unmanned aerial system for prescribed fires  helicopter  UAS-Rx Android application  Ignition  Robots  Computational modeling  Planning  Sensors  Mathematical model  Trajectory 
Abstract: Prescribed fires can lessen wildfire severity and control invasive species, but they can also be risky and costly. Unmanned aerial systems can reduce those drawbacks by, for example, dropping ignition spheres to ignite the most hazardous areas. Existing systems, however, lack awareness of the fire vectors to operate autonomously, safely, and efficiently. In this work we address that limitation, introducing an approach that integrates a lightweight fire simulator and a planner for trajectories and ignition sphere drop waypoints. Both components are unique in that they are amenable to input from the system's sensors and the fire crew to increase fire awareness. We conducted a preliminary study that confirms that such inputs improve the accuracy of the fire simulation to counter the unpredictability of the target environment. The field study of the system showed that the fire-aware planner generated safe trajectories with effective ignitions leveraging the fire simulator predictions.


Title: Deep Semantic Lane Segmentation for Mapless Driving
Key Words: automobiles  feature extraction  image colour analysis  image segmentation  mobile robots  neural nets  object detection  path planning  road traffic  robot vision  deep semantic lane segmentation  autonomous driving systems  automated cars  sensor system  urban scenarios  deep neural network  lane semantics  road scene  mapless autonomous driving  street scenes  RGB images  lane detection  cityscapes dataset  Roads  Semantics  Neural networks  Image segmentation  Autonomous vehicles  Three-dimensional displays  Pipelines 
Abstract: In autonomous driving systems a strong relation to highly accurate maps is taken to be inevitable, although street scenes change frequently. However, a preferable system would be to equip the automated cars with a sensor system that is able to navigate urban scenarios without an accurate map. We present a novel pipeline using a deep neural network to detect lane semantics and topology given RGB images. On the basis of this classification, the information about the road scene can be extracted just from the sensor setup supporting mapless autonomous driving. In addition to superseding the huge effort of creating and maintaining highly accurate maps, our system reduces the need for precise localization. Using an extended Cityscapes dataset, we show accurate ego lane detection including lane semantics on challenging scenarios for autonomous driving.


Title: Semantic Grid Estimation with a Hybrid Bayesian and Deep Neural Network Approach
Key Words: Bayes methods  belief networks  image colour analysis  image segmentation  learning (artificial intelligence)  neural nets  optical radar  particle filtering (numerical methods)  semantic grid estimation  hybrid Bayesian  deep neural network  autonomous vehicle setting  high-level semantic information  grid cell  semantic label  hybrid approach  semantic segmentation  monocular RGB images  supervised learning  labeled groundtruth data  occupancy grids  LIDAR data  generative Bayesian particle filter  geometric information  RGB data  Semantics  Image segmentation  Bayes methods  Laser radar  Neural networks  Three-dimensional displays  Sensors 
Abstract: In an autonomous vehicle setting, we propose a method for the estimation of a semantic grid, i.e. a bird's eye grid centered on the car's position and aligned with its driving direction, which contains high-level semantic information about the environment and its actors. Each grid cell contains a semantic label with divers classes, as for instance {Road, Vegetation, Building, Pedestrian, Car...}. We propose a hybrid approach, which combines the advantages of two different methodologies: we use Deep Learning to perform semantic segmentation on monocular RGB images with supervised learning from labeled groundtruth data. We combine these segmentations with occupancy grids calculated from LIDAR data using a generative Bayesian particle filter. The fusion itself is carried out with a deep neural network, which learns to integrate geometric information from the LIDAR with semantic information from the RGB data. We tested our method on two datasets, namely the KITTI dataset, which is publicly available and widely used, and our own dataset obtained with our own platform, equipped with a LIDAR and various sensors. We largely outperform baselines which calculate the semantic grid either from the RGB image alone or from LIDAR output alone, showing the interest of this hybrid approach.


Title: Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning
Key Words: aerospace computing  aerospace robotics  aircraft control  control engineering computing  gradient methods  helicopters  learning (artificial intelligence)  mobile robots  robot vision  visual servoing  deep reinforcement learning algorithm  deep deterministic policy gradients  image-based visual servoing controller  IBVS policy  linear velocity commands  multirotor aerial robots  simulated flight scenarios  Gazebo-based simulation scenario  RL-IBVS controller  Visual servoing  Reinforcement learning  Unmanned aerial vehicles  Task analysis  Detectors  Cameras 
Abstract: In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.


Title: C-blox: A Scalable and Consistent TSDF-based Dense Mapping Approach
Key Words: autonomous aerial vehicles  image reconstruction  image sensors  robot vision  SLAM (robots)  truncated signed distance field  TSDF subvolumes  lightweight micro aerial vehicle  scalable maps  map growth  bundle adjustment  feature-based camera tracking  dense 3D mapping  map consistency  delayed loop closure  accumulated camera tracking error  precise dense 3D maps  higher level decision making  robotic platforms  consistent dense map  Cameras  Simultaneous localization and mapping  Image reconstruction  Three-dimensional displays  Robot vision systems 
Abstract: In many applications, maintaining a consistent dense map of the environment is key to enabling robotic platforms to perform higher level decision making. Several works have addressed the challenge of creating precise dense 3D maps from visual sensors providing depth information. However, during operation over longer missions, reconstructions can easily become inconsistent due to accumulated camera tracking error and delayed loop closure. Without explicitly addressing the problem of map consistency, recovery from such distortions tends to be difficult. We present a novel system for dense 3D mapping which addresses the challenge of building consistent maps while dealing with scalability. Central to our approach is the representation of the environment as a collection of overlapping Truncated Signed Distance Field (TSDF) subvolumes. These subvolumes are localized through feature-based camera tracking and bundle adjustment. Our main contribution is a pipeline for identifying stable regions in the map, and to fuse the contributing subvolumes. This approach allows us to reduce map growth while still maintaining consistency. We demonstrate the proposed system on a publicly available dataset and simulation engine, and demonstrate the efficacy of the proposed approach for building consistent and scalable maps. Finally we demonstrate our approach running in real-time onboard a lightweight Micro Aerial Vehicle (MAV).


Title: Challenges of Autonomous Flight in Indoor Environments
Key Words: aircraft navigation  autonomous aerial vehicles  Global Positioning System  indoor navigation  sensors  indoor environments  GPS  velocity estimates  global navigation systems  drone research  indoor navigation  autonomous flight  onboard sensors  Indoor environments  Drones  Robots  Measurement  Global Positioning System  Collision avoidance  Cameras 
Abstract: Indoor navigation has been a major focus of drone research over the last few decades. The main reason for the term “indoor” came from the fact that in outdoor environments, drones could rely on global navigation systems such as GPS for their position and velocity estimates. By focusing on unknown indoor environments, the research had to focus on solutions using onboard sensors and processing. In this article, we present an overview of the state of the art and remaining challenges in this area, with a focus on small drones.


Title: A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform
Key Words: attitude control  autonomous aerial vehicles  continuous systems  helicopters  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  robot vision  state-space methods  deep learning techniques  deep deterministic policy gradients algorithm  motion control  deep Q- learning  active domain  robotics-related tasks  multirotor control  attitude control  state space  continuous action space  deep reinforcement learning technique  vision-based autonomous multirotor landing maneuver  continuous state  continuous action domain  moving platform  Reinforcement learning  Unmanned aerial vehicles  Robots  Cameras  Aerospace electronics  Neural networks  Task analysis 
Abstract: Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.


Title: Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments
Key Words: distance measurement  image colour analysis  image segmentation  indoor environment  learning (artificial intelligence)  mobile robots  neural nets  object detection  particle filtering (numerical methods)  pose estimation  robot vision  SLAM (robots)  stereo image processing  indoor environments  particle filter localization approach  semantic information  mini-aerial robots  stereo VO algorithm  semantic measurements  pre-trained deep learning based object detector  3D point clouds  visual SLAM approach  stereo visual odometry  semantics based localization  DL  RGB spectrum  drift free pose estimation  Semantics  Three-dimensional displays  Unmanned aerial vehicles  Robots  Atmospheric measurements  Particle measurements  Prediction algorithms 
Abstract: In this paper we propose a particle filter localization approach, based on stereo visual odometry (VO) and semantic information from indoor environments, for mini-aerial robots. The prediction stage of the particle filter is performed using the 3D pose of the aerial robot estimated by the stereo VO algorithm. This predicted 3D pose is updated using inertial as well as semantic measurements. The algorithm processes semantic measurements in two phases; firstly, a pre-trained deep learning (DL) based object detector is used for real time object detections in the RGB spectrum. Secondly, from the corresponding 3D point clouds of the detected objects, we segment their dominant horizontal plane and estimate their relative position, also augmenting a prior map with new detections. The augmented map is then used in order to obtain a drift free pose estimate of the aerial robot. We validate our approach in several real flight experiments where we compare it against ground truth and a state of the art visual SLAM approach.


Title: Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning
Key Words: autonomous aerial vehicles  collision avoidance  learning (artificial intelligence)  mobile robots  traditional motion planning algorithms  precise maps  fast reactive navigation algorithm  multirotor aerial robots  2D-laser range measurements  Gazebo-based simulation scenario  artificial potential field formulation  laser-based reactive navigation  collision avoidance capabilities  reactive navigation behavior  deep reinforcement learning  dynamic obstacles  static obstacles  Navigation  Robots  Unmanned aerial vehicles  Lasers  Heuristic algorithms  Reinforcement learning  Planning 
Abstract: Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.


Title: Drone Detection Using Depth Maps
Key Words: autonomous aerial vehicles  collision avoidance  image sensors  learning (artificial intelligence)  mobile robots  object detection  static obstacle avoidance  dynamic objects  field-of-view requirements  on-board small UAVs  relative altitude  azimuth  depth map-based approach  collision avoidance  depth map sequences  unmanned aerial vehicle navigation  collision-free path planning  FOV  deep learning-based drone detection model  sensing technologies  3D localization  Drones  Cameras  Three-dimensional displays  Atmospheric modeling  Sensors  Neural networks  Two dimensional displays 
Abstract: Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV) navigation. While solutions have been proposed for static obstacle avoidance, systems enabling avoidance of dynamic objects, such as drones, are hard to implement due to the detection range and field-of-view (FOV) requirements, as well as the constraints for integrating such systems on-board small UAVs. In this work, a dataset of 6k synthetic depth maps of drones has been generated and used to train a state-of-the-art deep learning-based drone detection model. While many sensing technologies can only provide relative altitude and azimuth of an obstacle, our depth map-based approach enables full 3D localization of the obstacle. This is extremely useful for collision avoidance, as 3D localization of detected drones is key to perform efficient collision-free path planning. The proposed detection technique has been validated in several real depth map sequences, with multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7 %, an average recall of 74.7 % and a record detection range of 9.5 meters.


Title: Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots
Key Words: aerospace control  autonomous aerial vehicles  dynamic programming  fires  learning (artificial intelligence)  Markov processes  Monte Carlo methods  optimal control  rescue robots  distributed deep reinforcement learning based strategy  UAVs  Markov decision process  deep RL approach  deep RL policy  forest sizes  simulated forest fire  unmanned aerial vehicles  aerial robots  Vegetation  Forestry  Sensors  Retardants  Monitoring  Lattices  Unmanned aerial vehicles 
Abstract: This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.


Title: Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision
Key Words: autonomous aerial vehicles  convolutional neural nets  image classification  learning (artificial intelligence)  mobile robots  path planning  probability  random processes  robot vision  target tracking  online search tasks  multitarget environments  dynamic targets  UAV-like vision  deep learning  dynamic search  strategic explorational agency  single deep network  navigational actions  dual-stream classification paradigm  sensory processing  agent location  static evolutions  dynamic evolutions  probabilistic placement  fully random target walks  herd-inspired behaviours  dual-stream architecture  unmanned aerial vehicle  convolutional neural network  multitarget behaviour classes  optimal navigational decision samples  long term map memory  Navigation  Robot sensing systems  Task analysis  History  Visualization  Vehicle dynamics  Reinforcement learning 
Abstract: This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish3 key source code and associated models.


Title: A Series Elastic Brake Pedal to Preserve Conventional Pedal Feel under Regenerative Braking
Key Words: actuators  brakes  closed loop systems  elasticity  force control  force feedback  regenerative braking  robust control  series elastic brake pedal  force-feedback brake pedal  series elastic actuation  closed-loop force control  pedal feel compensation  regenerative braking  robust controller  fidelity force control  impedance characteristic  frequency spectrum  Brakes  Force  Friction  Force control  Actuators  Vehicles  Couplings 
Abstract: We propose a force-feedback brake pedal with series elastic actuation to preserve the conventional brake pedal feel during cooperative regenerative braking. The novelty of the proposed design is due to the deliberate introduction of a compliant element between the actuator and the brake pedal whose deflections are measured to estimate interaction forces and to perform closed-loop force control. Thanks to its series elasticity, the force-feedback brake pedal can utilize robust controllers to achieve high fidelity force control, possesses favorable output impedance characteristics over the entire frequency spectrum, and can be implemented in a compact package using low-cost components. The applicability and effectiveness of the proposed series elastic brake pedal have been tested through human subject experiments that evaluate simulated cooperative regenerative braking scenarios with and without pedal feel compensation. The experimental results and responses to the accompanying questionnaire indicate that pedal feel compensation through the series elastic brake pedal can significantly decrease hard braking instances, improving safety and driver experience.


Title: Unmanned Aerial Auger for Underground Sensor Installation
Key Words: Auger effect  autonomous aerial vehicles  geophysical equipment  geophysical techniques  sensors  soil  underground equipment  digging mechanism  power consumption  unmanned aerial systems  target soil sensors  unmanned aerial auger performance  UAS  underground sensor installation  depth 120.0 mm  Force  Robot sensing systems  Substrates  Fasteners  Monitoring  Soil moisture 
Abstract: Using an Unmanned Aerial Systems (UAS) to autonomously deploy soil sensors enables their installation in otherwise hard to access locations. In this paper, we present a system that integrates a UAS and a digging mechanism which can carry, secure, and install a small sensor into dirt effectively and efficiently. The integrated system includes 1) a low profile, light-weight, inexpensive auger mechanism, 2) a sensor carrying and deploying mechanism with low power consumption, and 3) sensors and software that control and evaluate the auger performance during digging. When tested on a suite of target soils and a target depth of 120mm, the system achieved a success rate of 100% for indoor tests and 92.5% for outdoors, verifying the potential of the approach.


Title: Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  design engineering  drag  mobile robots  optimal control  pitch control (position)  robot dynamics  active pitch control strategy  center-of-mass location  morphological intelligence  optimal control strategy  collapsible airfoils  nonsteady-state gliding performance  gliding robots  drag coefficients  aerodynamic complexities  Robots  Automotive components  Aerodynamics  Optimization  Atmospheric modeling  Trajectory  Springs 
Abstract: Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.


Title: Development of Camber-Flat Wing Structure Convert Mechanism for Asymmetric Flapping Micro Air Vehicle
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  design engineering  vehicle dynamics  r asymmetric flapping micro air vehicle  rigidity  camber-flat wing structure convert mechanism  Force  Muscles  Robots  Drag  Force measurement  Insects  Actuators 
Abstract: This study presents principle of the camber-flat wing structure conversion mechanism, which is inspired by a dragonfly, and its applicability to MAV. The camber-flat wing structure convert mechanism makes MAV flight using asymmetric flapping pattern through control of angle of attack without complicate structure. This mechanism was inspired from the dragonfly's feature that the camber structure of the wing increases the rigidity of wing structure and makes dragonfly has asymmetric flapping pattern. Experimental results show that MAV has asymmetric flapping pattern that can more stable flight performance when hovering flight with a camber structure and superior performance when the forward flight with a flat structure. The average lift force in the camber wing structure was 0.02N, the average thrust force was 0.02N and the average lift force was 0.011N in the flat wing structure at 20 Hz flapping frequency.


Title: Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts
Key Words: coal  floods  inspection  maintenance engineering  mining  mobile robots  navigation  path planning  sensors  shafts  underwater vehicles  flooded shafts  EU project STAMS  autonomous underwater robotic system  periodic monitoring  underwater robot navigation  flooded mine shafts inspection  flooded mine shafts maintenance  sensor information  Robot sensing systems  Shafts  Three-dimensional displays  Sonar  Navigation  Visual odometry 
Abstract: The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.


Title: Mechanical subsystems integration and structural analysis for the autonomous underwater explorer
Key Words: autonomous underwater vehicles  finite element analysis  mechanical strength  mobile robots  robot dynamics  strain gauges  position requirements  finite element method  perception unit  FEM  strain gauge locations  modular mechanical design  autonomous underwater explorer  structural analysis  mechanical subsystems integration  hull endures pressures  deep dives  hull strength  structural strength analysis  orientation requirements  navigation systems  propulsion unit  ballast system  UX-1  Shape  Robots  Electronic ballasts  Manifolds  Propulsion  Finite element analysis  Cameras 
Abstract: The aim of this study is to analyse the modular mechanical design and integration of all three low-level modules in UX-1 (pendulum, ballast system and propulsion unit). The components of the perception and navigation systems have position and orientation requirements that dictate the shape of the hull. A structural strength analysis using Finite Element method (FEM) was made to study the hull strength during deep dives. The results are presented here, which indicates that the hull endures pressures related to deep dives. Also for validation, strain gauge locations were defined.


Title: UX 1 system design - A robotic system for underwater mining exploration
Key Words: cameras  control system synthesis  innovation management  mining  mobile robots  robot vision  sonar  underwater vehicles  UX 1 system design  underwater mining exploration  UX-1 underwater mine exploration robotic system  UNEXMIN project  international innovation action  EU H2020 program  flooded underground mines  UX-1 robot prototype  recovery system  post-processing computational infrastructure  spherical robot  rotating laser line structured light systems  comprehensive mine model  robot design  UV-light  natural gamma-ray detector  multi-spectral camera  electro-conductivity  magnetic field sensors  high resolution imagery  Robot sensing systems  Sonar  Cameras  Payloads  Three-dimensional displays 
Abstract: This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.


Title: Design, Modeling and Control of a Spherical Autonomous Underwater Vehicle for Mine Exploration
Key Words: autonomous underwater vehicles  control system synthesis  intelligent control  motion control  oceanographic equipment  position control  three-term control  flooded mine tunnel networks  unique mechanical hardware design  electrical hardware design  high-fidelity dynamic model  underwater experiments  controlled environment  standard motion patterns  Proportional-Integral-Derivative controller  PID controller  advanced control schemes  spherical AUV  tested underwater motions  spherical autonomous underwater vehicle  vehicle prototype  novel spherical autonomous  Prototypes  DC motors  Manifolds  Mathematical model  Robots  Propulsion  Shape 
Abstract: This paper presents the design, implementation and validation of a novel spherical Autonomous Underwater Vehicle (AUV) prototype, developed for inspection and exploration of flooded mine tunnel networks. The unique mechanical, electrical and hardware design is presented, as well as the development of a theoretical 6 degree-of-freedom (DOF) high-fidelity dynamic model of the system. A series of underwater experiments were carried out in a controlled environment to test the standard motion patterns of the AUV with a Proportional-Integral-Derivative (PID) controller. The performance of the PID controller will be used as the baseline for comparison of more advanced control schemes. The experimental results demonstrated that the spherical AUV was able to realize the tested underwater motions with notable performance.


Title: ίVAMOS! Underwater Mining Machine Navigation System
Key Words: autonomous underwater vehicles  Kalman filters  mining  mining equipment  mobile robots  nonlinear filters  satellite navigation  sensor fusion  underwater acoustic communication  underwater mining machine navigation system  data fusion approach  sensor information  extended kalman filter  EKF  ¡VAMOS  multiple antenna GNSS system  inverted ultra-short baseline  surface vessel  underwater mining vehicle  multiple vehicle underwater localization solution  Position measurement  Global navigation satellite system  Receivers  Transponders  Accelerometers  Data mining  Gravity 
Abstract: Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.


Title: Multi-Agent Imitation Learning for Driving Simulation
Key Words: intelligent transportation systems  learning (artificial intelligence)  multi-agent systems  multiagent Imitation Learning  human drivers  multiagent setting  PS-GAIL method  single-agent GAIL policies  curriculum learning  multiple agents  test time  multiagent driving scenarios  single-agent environments  representative human driver models  Generative Adversarial Imitation Learning  autonomous vehicles  appealing option  Vehicles  Training  Trajectory  Optimization  Biological system modeling  Testing  Markov processes 
Abstract: Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.


Title: Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides
Key Words: actuators  force sensors  grippers  optical sensors  optical waveguides  remotely operated vehicles  soft robotic hand  optical sensing elements  proprioception  curvature sensing elements  contact force sensors  normal force  sensor design decisions  simulated deep-sea environments  curvature sensors  soft finger actuators  soft curvature  deep-sea grasping  intentionally-lossy optical waveguides  soft robotic grasping applications  subNewton force sensitivity  temperature -10.0 degC to 50.0 degC  Optical waveguides  Optical sensors  Optical device fabrication  Optical losses  Optical refraction  Optical variables control 
Abstract: In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.


Title: Localization of an Acoustic Fish-Tag using the Time-of-Arrival Measurements: Preliminary results using eXogenous Kalman Filter
Key Words: Kalman filters  remotely operated vehicles  time-varying systems  time-of-arrival measurement  eXogenous Kalman filter  three stage estimation strategy  time-of-transmission  acoustic fish-tag localization  uniformly globally asymptotically stable  UGAS  unmanned surface vessels  Kalman Filter based estimator  quasilinear time-varying measurement model  pseudorange measurement equation  acoustic receiver  acoustic signal  source localization problem  Acoustics  Mathematical model  Receivers  Acoustic measurements  Kalman filters  Estimation  Measurement uncertainty 
Abstract: This paper addresses the source localization problem of an acoustic fish-tag using the Time-of-Arrival measurement of an acoustic signal, transmitted by the fish-tag. The Time-of-Arrival measurements denote the pseudo-range information between the acoustic receiver and the fish-tag, except that the Time-of-Transmission of the acoustic signal is unknown. Starting with the pseudo-range measurement equation, a globally valid quasi-linear time-varying measurement model is presented that is independent of the Time-of-Transmission of the acoustic signal. Using this measurement model, an Uniformly Globally Asymptotically Stable (UGAS), three stage estimation strategy (eXogenous Kalman Filter) is designed to estimate the position of an acoustic fish-tag and evaluated against a benchmark Extended Kalman Filter based estimator. The efficacy of the developed estimation method is demonstrated experimentally, in presence of intermittent observations using an array of receivers mounted on three Unmanned Surface Vessels (USVs).


Title: Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
Key Words: feature extraction  inference mechanisms  learning (artificial intelligence)  legged locomotion  motion control  path planning  robot vision  terrain mapping  multilegged robot  crawled terrain  hexapod robot  legged robot  terrain features inference  aerial scan  robot locomotion  incremental learning  geometrical data  visual data  terrain learning  extraterrestrial missions  robot deployment  robot motion planning  cost of transport estimation  terrain descriptors  mechanical properties  Robots  Feature extraction  Image color analysis  Estimation  Unmanned aerial vehicles  Three-dimensional displays  Visualization 
Abstract: The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.


Title: An Adaptive Landing Gear for Extending the Operational Range of Helicopters
Key Words: actuators  adaptive control  aircraft landing guidance  autonomous aerial vehicles  force control  gears  helicopters  legged locomotion  shock absorbers  springs (mechanical)  vibration control  off-field landing  skid based helicopter landing gears  mountain rescue  economic practicability  innovative actuation  brake  motor  spring-damper system  force control  tipping  aircraft  unmanned helicopter  landing phase  optimal load distribution  leg  wheel based helicopter landing gears  adaptive landing gear  Legged locomotion  Gears  Helicopters  Foot  Brakes  Rotors  Damping 
Abstract: Conventional skid or wheel based helicopter landing gears severely limit off-field landing possibilities, which are crucial when operating in scenarios such as mountain rescue. In this context, slopes beyond 8° and small obstacles can already pose a substantial hazard. An adaptive landing gear is proposed to overcome these limitations. It consists of four legs with one degree of freedom each. The total weight was minimized to demonstrate economic practicability. This was achieved by an innovative actuation, composed of a parallel arrangement of motor and brake, which relieves the motor from large impact loads during hard landings. The loads are alleviated by a spring-damper system acting in series to the actuation. Each leg is individually force controlled for optimal load distribution on compliant ground and to avoid tipping. The operation of the legs is fully autonomous during the landing phase. A prototype was designed and successfully tested on an unmanned helicopter with a maximum take-off weight of 78 kg. Finally, the implementation of the landing gear concept on aircraft of various scales was discussed.


Title: Received Signal Strength of Electromagnetic Waves Aided Integrated Inertial Navigation System for Underwater Vehicle
Key Words: inertial navigation  Kalman filters  mobile robots  navigation  position measurement  remotely operated vehicles  sensor fusion  underwater vehicles  wireless sensor networks  Kalman filter  Earth-fixed reference sensors  EM waves attenuation  long-term navigation  basin environment  underwater wireless sensor networks  EM waves sensors  sensor-fusion-based localization scheme  electromagnetic waves sensors  sensor fusion  underwater localization scheme  strong signal attenuation  signal uncertainties  underwater environment  unmanned underwater vehicle  sensory information  integrated inertial navigation system  Manganese  Attenuation  Sensor fusion  Robot sensing systems  Noise measurement  Time measurement 
Abstract: Sensory information from an Earth-fixed reference is necessary to guarantee a high localization accuracy of an unmanned underwater vehicle (UUV). However, the implementation of these sensors in an underwater environment is challenging because of signal uncertainties and strong signal attenuation. In this paper, we propose an underwater localization scheme with a sensor fusion of inertial navigation system (INS) and received signal strength of electromagnetic (EM) waves sensors. In the proposed sensor-fusion-based localization scheme, the UUV predicts its location by using INS based on dead-reckoning and corrects the predicted position by Kalman filter using EM waves sensor information when the UUV receives the signals of EM waves sensors in underwater wireless sensor networks. The proposed scheme enables localization with high accuracy and high sampling rate during a long-term task. The results of an experiment performed in a basin environment shows the feasibility of the proposed scheme. The scheme achieved reliable localization accuracy by comparing the pre-measured ground-truth position and long-term navigation. These results show the feasibility of exploiting EM waves attenuation as Earth-fixed reference sensors.


Title: Multibeam Data Processing for Underwater Mapping
Key Words: image segmentation  oceanographic techniques  sonar  sonar detection  sonar imaging  underwater vehicles  balanced trade-off  underwater mapping literature  underwater mapping literature  local thresholding techniques  subsea structures  multibeam data processing  DIDSON imaging sonar  map accuracy  sonar-based underwater mapping  sonar artifacts  range measurements  occupied regions  free regions  received acoustic echos  sonars output  underwater mapping platforms  primary sensor  multibeam sonars  Sonar measurements  Robot sensing systems  Acoustic beams  Image segmentation  Mathematical model  Acoustics 
Abstract: From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.


Title: Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection
Key Words: autonomous underwater vehicles  cameras  collision avoidance  convolutional neural nets  mobile robots  navigation  object detection  robot vision  supervised learning  proportional controller  vision-based autonomous underwater swimming  computer vision  visual target selection  coral-deprived regions  monocular image data  convolutional neural network  supervised learning  motor controller  collision avoidance  autonomous robot swimming  autonomous coral reef navigation  obstacle-avoidance  forward-facing camera  Navigation  Cameras  Robot vision systems  Task analysis  Visualization  Neural networks 
Abstract: We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.


Title: Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop
Key Words: autonomous underwater vehicles  data acquisition  marine safety  mobile robots  perception  robust continuous system integration  critical deep-sea robot operations  knowledge-enabled simulation  reliability  self-localization  system components  safety  simulation in the loop methodology  SIL methodology  Task analysis  Robot sensing systems  Data models  Benchmark testing  Continuous time systems 
Abstract: Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.


Title: Reliable fusion of black-box estimates of underwater localization
Key Words: estimation theory  Kalman filters  mobile robots  Monte Carlo methods  sensor fusion  underwater vehicles  inertial sensory  Kalman filter  augmented Monte Carlo localization algorithms  geophysical sensory  task context  localization signal  heuristic model  underwater robot localization  un-modeled noise  adaptive fusion policy  redundant parametric estimations  information fusion  robot tracking  black-box estimates  reliable fusion  Estimation  Task analysis  Reliability  Robot sensing systems  Global Positioning System  Computational modeling 
Abstract: The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.


Title: A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
Key Words: autonomous underwater vehicles  bridges (structures)  inspection  multi-robot systems  path planning  underwater structures  DSCPP  smooth paths  spiral path  popular boustrophedon-based coverage approach  intervention autonomous underwater vehicle  deformable spiral coverage path planning algorithm  smooth coverage path planning  deformable spiral-based algorithm  Spirals  Cleaning  Path planning  Fatigue  Underwater structures  Manipulators  Poles and towers 
Abstract: Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.


Title: Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs
Key Words: autonomous underwater vehicles  calibration  clocks  Global Positioning System  hydrophones  integer programming  linear programming  mobile robots  sensors  synchronisation  time-of-arrival estimation  underwater sound  underwater acoustic transmitter  real-time calibration algorithms  TOF measurements  temperature variation  mixed integer linear program  AUV  TDOA filtering methods  mean localization errors  acoustic tag state estimation  unsynchronized hydrophones  underwater robotic sensor system  marine animals  time difference of arrival  autonomous underwater vehicle  nonlinear clock skews  time of flight  GPS data  TOF filtering methods  standard deviation  Clocks  Sonar equipment  Acoustics  Temperature measurement  Acoustic measurements  Estimation 
Abstract: This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.


Title: Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process
Key Words: aerospace robotics  aircraft control  autonomous aerial vehicles  force control  manipulators  position control  springs (mechanical)  vibration control  emergency switch process  dangerous work situation  industrial leakage accidents  flexible robot  small robot  aerial manipulator system  hexa-rotor UAV  UAV platform  hover flight  impedance control algorithm  force-sensorless contact force control method  one-DOF manipulator  spring-mass-damper system model  Manipulators  Force  Contacts  Attitude control  Force control  Pressing 
Abstract: The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.


Title: Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM
Key Words: mixed analogue-digital integrated circuits  mobile robots  neural nets  neurophysiology  pose estimation  SLAM (robots)  pose estimation  spiking neural networks  neuromorphic SLAM  biologically inspired neuronal path integration  mobile robot  neuronal map formation architecture  simultaneous localization and mapping  mixed signal analog-digital neuromorphic hardware  ultra low-power neuromorphic hardware  robotic vehicle simulation  on-board plasticity  Neurons  Neuromorphics  Collision avoidance  Simultaneous localization and mapping  Synapses 
Abstract: In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).


Title: Precise Localization in High-Definition Road Maps for Urban Regions
Key Words: cameras  image resolution  Kalman filters  nonlinear filters  road vehicles  satellite navigation  stereo image processing  traffic engineering computing  high-resolution road maps  road borders  Unscented Kalman Filter  narrow urban roads  highly automated driving  precise localization  high-definition road maps  sensor specific feature layers  stereo camera  vehicle odometry  low-cost GNSS module  size 5.0 km  size 0.08 m  Roads  Global navigation satellite system  Simultaneous localization and mapping  Semantics  Urban areas  Receivers 
Abstract: The future of automated driving in urban areas will most probably rely on highly accurate road maps. However, the necessary precision of a localization in such maps has so far only been reached using extra, sensor specific feature layers for localization. In this paper we want to show that it is possible to achieve sufficient accuracy without a separate localization layer. Instead, elements are used that are already contained in high-resolution road maps, such as markings and road borders. For this, we introduce a modular approach in which detections from different detection algorithms are associated with elements in the map and then fused to an absolute pose using an Unscented Kalman Filter. We evaluate our approach using a sensor setup that employs a stereo camera, vehicle odometry and a low-cost GNSS module on a 5km test route covering both narrow urban roads and multi-lane main roads under varying weather conditions. The results show that this approach is capable to be used for highly automated driving, showing an accuracy of 0.08m in typical road scenarios and a is available 98% of the time.


Title: Decentralized Localization Framework using Heterogeneous Map-matchings
Key Words: decentralised control  mobile robots  road vehicles  sensor fusion  stability  stochastic processes  decentralized localization framework  heterogeneous map-matchings  system stability  localization methods  map matchings  stochastic situational analysis model  heterogeneous map-matching sources  dissimilar sensors  fusion methods  multienvironment sensors  single environmental sensor  autonomous driving applications  robust real-time localization  Roads  Laser radar  Three-dimensional displays  Cameras  Feature extraction  Sensor fusion 
Abstract: Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.


Title: People as Sensors: Imputing Maps from Human Actions
Key Words: collision avoidance  driver information systems  mobile robots  pedestrians  road vehicles  human actions  autonomous vehicles  pedestrian detection  collision avoidance  map estimation  human driving experiments  landmark-based mapping approaches  agents actions  Random variables  Estimation  Automobiles  Computational modeling  Intelligent sensors 
Abstract: Despite growing attention in autonomy, there are still many open problems, including how autonomous vehicles will interact and communicate with other agents, such as human drivers and pedestrians. Unlike most approaches that focus on pedestrian detection and planning for collision avoidance, this paper considers modeling the interaction between human drivers and pedestrians and how it might influence map estimation, as a proxy for detection. We take a mapping inspired approach and incorporate people as sensors into mapping frameworks. By taking advantage of other agents' actions, we demonstrate how we can impute portions of the map that would otherwise be occluded. We evaluate our framework in human driving experiments and on real-world data, using occupancy grids and landmark-based mapping approaches. Our approach significantly improves overall environment awareness and outperforms standard mapping techniques.


Title: Uncertainty-based Online Mapping and Motion Planning for Marine Robotics Guidance
Key Words: autonomous underwater vehicles  path planning  probability  robot dynamics  vehicle dynamics  uncertainty-based framework  online computation constraints  motion planning  marine robotics guidance  robotic systems  safe path  underwater environments  autonomous vehicles  probabilistic safety  online mapping  Uncertainty  Safety  Planning  Probabilistic logic  Robot sensing systems  Vehicle dynamics 
Abstract: In real-world robotics, motion planning remains to be an open challenge. Not only robotic systems are required to move through unexplored environments, but also their manoeuvrability is constrained by their dynamics and often suffer from uncertainty. One approach to overcome this problem is to incrementally map the surroundings while, simultaneously, planning a safe and feasible path to a desired goal. This is especially critical in underwater environments, where autonomous vehicles must deal with both motion and environment uncertainties. In order to cope with these constraints, this work proposes an uncertainty-based framework for mapping and planning3 feasible motions online with probabilistic safety-guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by (i) incrementally representing the environment as a collection of local maps, and (ii) iteratively (re)planning kinodynamically-feasible and probabilistically-safe paths to goal. The proposed framework is evaluated on the Sparus II, a nonholonomic torpedo-shaped AUV, by conducting simulated and real-world trials, thus proving the efficacy of the method and its suitability even for systems with limited on-board computational power.


Title: Heterogeneous Vehicles Routing for Water Canal Damage Assessment
Key Words: autonomous aerial vehicles  canals  graph theory  inspection  integer programming  irrigation  path planning  quadratic programming  vehicle routing  water canal damage assessment  irrigation water canals  manual inspection  shortened inspection time  reduced labor cost  automated inspection  road networks  path planning  UAV  unmanned aerial vehicles  ground vehicles  integer quadratic program  IQP  heterogeneous vehicle routing  Irrigation  Automobiles  Inspection  Roads  Planning  Batteries  Routing 
Abstract: In Japan, inspection of irrigation water canals has been mostly conducted manually. However, the huge demand for more regular inspections as infrastructure ages, coupled with the limited time window available for inspection, has rendered manual inspection increasingly insufficient. With shortened inspection time and reduced labor cost, automated inspection using a combination of unmanned aerial vehicles (UAVs) and ground vehicles (cars) has emerged as an attractive alternative to manual inspection. In this paper, we propose a path planning framework that generates optimal plans for UAVs and cars to inspect water canals in a large agricultural area (tens of square kilometers). In addition to optimality, the paths need to satisfy several constraints, in order to guarantee UAV navigation safety and to abide by local traffic regulations. In the proposed framework, the canal and road networks are first modeled as two graphs, which are then partitioned into smaller subgraphs that can be covered by a given fleet of UAVs within one battery charge. The problem of finding optimal paths for both UAVs and cars on the graphs, subject to the constraints, is formulated as a integer quadratic program (IQP). The proposed framework can also quickly generate new plans when a current plan is interrupted. The effectiveness of the proposed framework is validated by simulation results showing the successful generation of plans covering all given canal segments, and the ability to quickly revise the plan when conditions change.


Title: Passive acoustic tracking for behavior mode classification between surface and underwater vehicles
Key Words: autonomous underwater vehicles  hydrophones  mobile robots  acoustic modems  vehicle state  communication line  submerged vehicles  hydrophone arrays  AUV mode estimates  dynamic time  simulation data  simulation-based classifier  bearing tracking data  passive tracking  TTI data  field array data  experiment data  surface vessels  AUV behavior  passive acoustic tracking  behavior mode classification  autonomous underwater vehicles  speed-of-light communication  AUV platforms  surface vehicle behavior  K-nearest-neighbor  Boats  Acoustics  Sea surface  Trajectory  Arrays  Data models  Sonar equipment 
Abstract: Autonomous underwater vehicles (AUVs) pose significant communication challenges: vehicles are submerged for periods of time in which speed-of-light communication is impossible. This is a particular problem on low-cost AUV platforms, on which acoustic modems are not available to get vehicle state or provide re-deploy commands. We investigate one possible method of providing operators with a communication line to these vehicles by using noise underwater to both classify behavior of submerged vehicles and to command them. In this scheme, processing of data from hydrophone arrays provide operators with AUV mode estimates and AUVs with surface vehicle behavior updates. Simulation studies were used to characterize trajectories for simple transect versus loiter behaviors based on the bearing and time to intercept (TTI). A classifier based on K-nearest-neighbor with dynamic time warping as a distance metric was used to classify simulation data. The simulation-based classifier was then applied to classify bearing tracking data from passive tracking of a loitering AUV and bearing and TTI data from passive tracking of a transecting boat based on field array data. Experiment data was classified with 76 % accuracy using bearing-only data, 96% accuracy for TTI -only data and 99 % accuracy for combined classification. The techniques developed here could be used for AUV cuing by surface vessels and monitoring of AUV behavior.


Title: Stochastic Optimization for Autonomous Vehicles with Limited Control Authority
Key Words: gradient methods  greedy algorithms  mobile robots  optimisation  state-space methods  stochastic processes  SGA  multivehicle information gathering  action space representation  stochastic optimization scheme  perturbed action sequences  state space information function  sequential greedy allocation  autonomous vehicles  stochastic gradient ascent algorithm  vehicle control authority  navy coastal ocean model  NCOM  Gulf of Mexico  GoM  Monte Carlo tree search method  MCTS  Oceans  Optimization  Stochastic processes  Approximation algorithms  Trajectory  Aerospace electronics  Robots 
Abstract: In this work, we present a Stochastic Gradient Ascent (SGA) algorithm for multi-vehicle information gathering that accounts for limitations on a vehicle's control authority caused by external forces. By representing vehicle paths using a novel action space representation, rather than a state space representation, we remove the need to perform feasibility calculations on the vehicle's path. Our algorithm uses a stochastic optimization scheme by sampling perturbed action sequences around the current best known sequence to estimate the gradient of a state space information function with respect to the action sequence. Additionally, we use sequential greedy allocation to plan for multiple vehicles. Results are shown using a Navy Coastal Ocean Model (NCOM) for the Gulf of Mexico (GoM). SGA shows improvement in the amount of information gained over a greedy baseline. Additionally, we compare to Monte Carlo Tree Search (MCTS) Method, which is able to gather competitive amounts of information but is more computationally intensive than our approach.


Title: Proactive Collision Avoidance for ASVs using A Dynamic Reciprocal Velocity Obstacles Method
Key Words: collision avoidance  marine vehicles  mobile robots  velocity control  reciprocal velocity obstacles framework  dynamic obstacles  collision avoidance decisions  international regulations  autonomous surface vessel  future behavior  interactive behavior  collision avoidance method  dynamic reciprocal velocity obstacles method  proactive collision avoidance  COLREGs  ASV behavior  complex dynamic models  RVO framework  predictive approach  Collision avoidance  Decision making  Propulsion  Uncertainty  Sensor systems  Computational modeling 
Abstract: We propose a collision avoidance method that incorporates the interactive behavior of agents and is proactive in dealing with the uncertainty of the future behavior of obstacles. The proposed method considers interactions that will be experienced by an autonomous surface vessel (ASV) in an environment governed by the international regulations for preventing collisions at sea (COLREGs). Our approach aims at encouraging dynamic obstacles to cooperate according to COLREGs. Therefore, we propose a strategy for assessing the cooperative behavior of obstacles, and the result of the assessment is used to adapt collision avoidance decisions within the Reciprocal Velocity Obstacles (RVO) framework. Moreover, we propose a predictive approach to solving known limitations of the RVO framework, and we present computationally feasible extensions that enable the use of complex dynamic models and objectives suitable for ASVs. We demonstrate the performance and potentials of our method through a simulation study, and the results show that the proposed method leads to proactive and more predictable ASV behavior compared with both Velocity Obstacles (VO) and RVO, especially when obstacles cooperate by following COLREGs.


Title: A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints
Key Words: redundant manipulators  multiple kinematic chains  hard joint  reverse priority framework  kinematic control  redundant robots  reverse priority method  robotic systems  bilateral constraints  unilateral constraints  multitask priority framework  joint priorities  Cartesian constraints  Task analysis  Kinematics  Jacobian matrices  Redundancy  End effectors 
Abstract: This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.


Title: Vision-based Target Tracking for a Skid-steer Vehicle using Guided Policy Search with Field-of-view Constraint
Key Words: learning (artificial intelligence)  mobile robots  optimisation  remotely operated vehicles  robot dynamics  robot kinematics  robot vision  search problems  steering systems  target tracking  skid-steer vehicle  guided policy search  skid-type robot  local policy optimization  FOV constraint  vision-based tracking policy  skid-steer mobile robot  field-of-view constraint  vision-based target tracking method  end-to-end policy  pixel image data  deep reinforcement learning  kinematic slip model  Mobile robots  Training  Kinematics  Cameras  Target tracking  Wheels 
Abstract: This paper describes a vision-based target tracking method for a skid-steer vehicle. With the development of deep reinforcement learning, many researchers have tried to generate an end-to-end policy to control the mobile robot from a raw pixel image data. However, the action in most research only concerns high-level decisions such as go straight, turn left and right. High-level decisions alone are not sufficient to precisely control platforms such as a skid-steer vehicle due to the lack of steering mechanism. Thus, unlike existing work, we aim to control the motor command for the wheels directly. To this end, we employ guided policy search (GPS) based on the general kinematic slip model for the skid-type robot. Furthermore, to prohibit the target from getting out of the camera field of view (FOV) in the training phase, we update local policy optimization with a FOV constraint and perform a pre-training to make the initial policy more efficient. Our method allows the skid-type robot to automatically acquire the vision-based tracking policy while local policies satisfy the FOV constraint during the training phase. We evaluate our method through both simulation and experiment with a skid-steer mobile robot. Finally, we test the performance of learned policy with a moving target in a new environment.


Title: Slip Modeling and Estimation for a Planetary Exploration Rover: Experimental Results from Mt. Etna
Key Words: aerospace robotics  mobile robots  planetary rovers  position control  wheels  wheel-soil interaction properties  inherent errors  wheel slippage  parameter-based approach  whole-body slip modeling  lightweight rover system  slip parameter calibration  system-specific implementation  experimental results  Mt. Etna  resulting wheel odometry measurements  space exploration scenario  planetary exploration rover  wheeled mobile systems  planetary rovers  planetary exploration missions  Wheels  Jacobian matrices  Trajectory  Current measurement  Extraterrestrial measurements  Soil  Mathematical model 
Abstract: For wheeled mobile systems, the wheel odometry is an important source of information about the current motion of the vehicle. It is used e.g. in the context of pose estimation and self-localization of planetary rovers, which is a crucial part of the success of planetary exploration missions. Depending on the wheel-soil interaction properties, wheel odometry measurements are subject to inherent errors such as wheel slippage. In this paper, a parameter-based approach for whole-body slip modeling and calibration is applied to a four-wheeled lightweight rover system. Details on the method for slip parameter calibration as well as the system-specific implementation are given. Experimental results from a test campaign on Mt. Etna are presented, showing significant improvements of the resulting wheel odometry measurements. The results are validated during a long range drive of approx. 900 m and discussed w. r. t. the advantages but also limitations of the method within a space exploration scenario.


Title: A minimalist Stair Climbing Robot (SCR) formed as a leg balancing & climbing Mobile Inverted Pendulum (MIP)
Key Words: feedback  legged locomotion  motion control  pendulums  robot kinematics  service robots  stability  wheels  SCR  leg balancing  patent-pending  minimal-complexity Stair Climbing Robot  vehicle design  stairs  leveraging feedback control  foot  MIP drive wheels  reaction wheels  stair-climbing throwbot  mobile inverted pendulum  left-right stability  fore-aft stabilization  chassis-wheel assembly  minimalist stair climbing robot  Wheels  Legged locomotion  Robot kinematics  Gears  Torque 
Abstract: This paper presents a (patent-pending) small, quasi-static, minimal-complexity Stair Climbing Robot (SCR). The vehicle design is given simply by adding a third motor to a (Segway-like) Mobile Inverted Pendulum (MIP), enabling it to maneuver up stairs, leveraging feedback control, by planting it's “foot” onto the ground in front of the next step, lifting the chassis/wheel assembly up it's own “leg”, leaning over onto the top of the next step, self uprighting, and repeating for the following step(s). Fore/aft stabilization during leg balancing is given by using the MIP drive wheels as reaction wheels, while left/right stability is given by the width of the foot itself. The design is small and simple enough to potentially be ruggedized as a stair-climbing throwbot, akin to the Recon Scout (but able to climb up stairs) for reconnaissance in military and homeland security applications.


Title: Tracking a moving sound source from a multi-rotor drone
Key Words: acoustic signal processing  audio signal processing  autonomous aerial vehicles  cameras  feature extraction  helicopters  humanoid robots  particle filtering (numerical methods)  signal denoising  spatial filters  time-frequency analysis  ground-truth trajectory  noisy estimations  direction of arrival  ego-noise  human speaker  multirotor drone  moving sound source  moving source  short audio segments  time-frequency spatial filter  specific drone  propellers  motors  emergency whistle  Drones  Time-frequency analysis  Direction-of-arrival estimation  Microphone arrays  Loudspeakers  Propellers 
Abstract: We propose a method to track from a multi-rotor drone a moving source, such as a human speaker or an emergency whistle, whose sound is mixed with the strong ego-noise generated by rotating motors and propellers. The proposed method is independent of the specific drone and does not need pre-training nor reference signals. We first employ a time-frequency spatial filter to estimate, on short audio segments, the direction of arrival of the moving source and then we track these noisy estimations with a particle filter. We quantitatively evaluate the results using a ground-truth trajectory of the sound source obtained with an on-board camera and compare the performance of the proposed method with baseline solutions.


Title: Synthesizing Neural Network Controllers with Probabilistic Model-Based Reinforcement Learning
Key Words: learning (artificial intelligence)  mobile robots  neurocontrollers  underwater vehicles  complex neural network controllers  motor controllers  probabilistic model-based reinforcement learning  robotics systems  sample-based version  Deep-PILeO  model-based algorithm  random numbers  clips gradients  neural network dynamics model  data-efficient synthesis  complex neural network policies  data-efficiency  truncated log-normal noise  Robots  Optimization  Vehicle dynamics  Task analysis  Heuristic algorithms  Neural networks  Stochastic processes 
Abstract: We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.


Title: Relative and inertial attitude determination in three-vehicle long formations
Key Words: attitude control  attitude measurement  inertial navigation  mobile robots  multi-robot systems  inertial attitude  three-vehicle long formations  attitude determination problem  three-vehicle formation  independent inertial measurement  attitude relations  relative attitude  inertial candidates  constrained formations  sensor noise  Position measurement  Sensors  Extraterrestrial measurements  Visualization  Estimation  Space vehicles  Navigation 
Abstract: This paper addresses a new attitude determination problem for formations. It considers a three-vehicle formation with relative and inertial measurements from sensors, where Constraints limit the relative measurements, which are not available between two of the vehicles, also known as deputies. The other vehicle is called the chief and does not have any limitation. Furthermore, each of the vehicles has an independent inertial measurement, whose references are known. The goal is to determine all attitude relations, both inertial and relative. The solution for this problem is divided into different stages. First, the relative attitude between the chief and the deputies is assessed, which results in two candidates for each of these relations. Then, each candidate yields a candidate for the inertial attitude of the chief. Next, comparing the four inertial candidates gives the solution for their respective relations and consequently for the relative relations as well. The remaining relations derive directly from those already known. The paper also provides some early insights about degeneracies, possible particular cases of the solution, and the effect of sensor noise. Finally, the solution is validated with a simulation, whose results are similar to attitude determination problems in constrained formations.


Title: Experience-Based Model Selection to Enable Long-Term, Safe Control for Repetitive Tasks Under Changing Conditions
Key Words: Gaussian processes  learning (artificial intelligence)  learning systems  mobile robots  regression analysis  robot dynamics  learning approaches  significant performance improvements  robotic control  realistic scenarios  rapid changes  existing single-mode safe learning controller  increasing number  nonlinear models  robot dynamics  visited operating conditions  new operating condition  distinct operating condition  control loop  physical changes  artificial changes  experience-based model selection  enable long-term  safe control  repetitive tasks  Gaussian process regression  Robots  Vehicle dynamics  Safety  Heuristic algorithms  Data models  Computational modeling  Task analysis 
Abstract: Learning approaches have enabled significant performance improvements in robotic control allowing robots to execute motions that were previously impossible. The majority of the work to date, however, assumes that the parts to be learned are static or slowly changing, which limits their applicability in realistic scenarios with rapid changes in the conditions. This paper presents a method to extend an existing single-mode safe learning controller based on Gaussian Process Regression to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experiences from a large number of previously visited operating conditions, and to safely adapt when a new and distinct operating condition is encountered. This allows the robot to achieve safety and high performance in a large number of operating conditions that do not have to be specified ahead of time. Our approach runs independently from the controller, imposing no additional computation time on the control loop regardless of the number of previous operating conditions considered. We demonstrate the effectiveness of our approach in experiment on a 900 kg ground robot with both physical and artificial changes to its dynamics. All of our experiments are conducted using vision for localization.


Title: Automated Tuning of Nonlinear Model Predictive Controller by Reinforcement Learning
Key Words: autonomous aerial vehicles  control engineering computing  iterative methods  learning (artificial intelligence)  nonlinear control systems  predictive control  trajectory control  nonlinear MPC  trajectory tracking control  aerial robots  NMPC weights  automated tuning  nonlinear model predictive controller  reinforcement learning  nontrivial weight tuning process  generic user-independent framework  trial-and-error method  iterative Gazebo simulations  standard desktop computer  Tuning  Rotors  Computational modeling  Optimization  Aerodynamics  Iron  Reinforcement learning 
Abstract: One of the major challenges of model predictive control (MPC) for robotic applications is the non-trivial weight tuning process while crafting the objective function. This process is often executed using the trial-and-error method by the user. Consequently, the optimality of the weights and the time required for the process become highly dependent on the skill set and experience of the user. In this study, we present a generic and user-independent framework which automates the tuning process by reinforcement learning. The proposed method shows competency in tuning a nonlinear MPC (NMPC) which is employed for trajectory tracking control of aerial robots. It explores the desirable weights within less than an hour in iterative Gazebo simulations running on a standard desktop computer. The real world experiments illustrate that the NMPC weights explored by the proposed method result in a satisfactory trajectory tracking performance.


Title: Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  path planning  safe operation  deep reinforcement learning  complex interactions  environment increases  dynamic agents  particular behavior rules  arbitrary number  motion planning  decision-making agents  collision avoidance algorithms  Collision avoidance  Robots  Training  Decision making  Heuristic algorithms  Sensors  Navigation 
Abstract: Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.


Title: Generative Modeling of Multimodal Multi-Human Behavior
Key Words: approximation theory  behavioural sciences computing  bin packing  human-robot interaction  learning (artificial intelligence)  mobile robots  multi-agent systems  statistical distributions  deep learning approximations  probabilistic graphical models  candidate future agent behavior  crowded environments  human-driven vehicles  human-robot collaborative bin packing  multimodal probability distribution  multihuman interactions  basketball player trajectories  multimodal multihuman behavior  self-driving cars  warehouse  autoencoders  response dynamics  robotic applications  proxy  Trajectory  Predictive models  Analytical models  Deep learning  Ground penetrating radar  Data models  Robots 
Abstract: This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.


Title: UAV Based Wireless Charging of Sensor Networks Without Prior Knowledge
Key Words: autonomous aerial vehicles  wireless sensor networks  Power Transfer Efficiency Compensation  efficiency drops  real-world power transfer scenarios  knowledge algorithm  maximum power transfer efficiency  constant maximum efficiency CPTEC  UAV based Wireless Charging  Unmanned Aerial Vehicles  Wireless Rechargeable Sensor Networks  charging efficiency  wireless transmitter  charged node  sensor nodes  power information  limits scalability  wireless receiver  power level increase  power level increase  Robot sensing systems  Unmanned aerial vehicles  Wireless sensor networks  Wireless communication  Receivers  Wireless power transfer 
Abstract: Unmanned Aerial Vehicles (UAVs) can charge Wireless Rechargeable Sensor Networks (WRSNs) in remote or hard to access locations. However, the charging efficiency is heavily affected by the distance between the wireless transmitter and receiver. This efficiency impacts the possible power level increase of each charged node. Most charging algorithms require full knowledge of sensor nodes' power levels to identify the nodes to charge. Collecting this power information adds overhead to the network and limits scalability. We propose and implement Charging with Power Transfer Efficiency Compensation (CPTEC), an algorithm that charges a WRSN without the need for a priori knowledge of the nodes' power levels. We show that CPTEC compensates for efficiency drops, due to landing alignments, making it practical for real-world power transfer scenarios. Our results show that CPTEC is able to perform with a median at ≈ 72% of the optimal performance of a full knowledge algorithm that assumes maximum power transfer efficiency, while other work drops to ≈ 22%. Under constant maximum efficiency CPTEC performs ≈ 90% of the optimal full knowledge case.


Title: Octree map based on sparse point cloud and heuristic probability distribution for labeled images
Key Words: calibration  cameras  convolutional neural nets  image recognition  object recognition  octrees  probability  stereo image processing  semantic octree maps  probabilistic octree framework  single lidar scans  octree map building algorithm  labeled lidar scan  camera-lidar calibration parameters  convolutional neural network  accurate driving maneuvers  automated vehicle  urban roads  labeled images  heuristic probability distribution  sparse point cloud  Three-dimensional displays  Semantics  Laser radar  Uncertainty  Octrees  Cameras  Buildings 
Abstract: To navigate through urban roads, an automated vehicle must be able to perceive and recognize objects in a three-dimensional environment. A high level contextual understanding of the surroundings is necessary to execute accurate driving maneuvers. This paper presents a novel approach to build three dimensional semantic octree maps from lidar scans and the output of a convolutional neural network (CNN) to obtain the labels of the environment. We present a heuristic method to associate uncertainties to the labels from the images based on a combination of the labels themselves, score maps retrieved by the CNN and the raw images. These uncertainties and the camera-lidar calibration parameters for multiple cameras are considered in the projection of the labels and their uncertainties into the point cloud. Every labeled lidar scan works as an input to an octree map building algorithm that calculates and updates the label probabilities of the voxels in the map. This paper also presents a qualitative and quantitative evaluation of accuracy, analyzing projection in single lidar scans and complete maps built with our probabilistic octree framework.


Title: VLASE: Vehicle Localization by Aggregating Semantic Edges
Key Words: feature extraction  geographic information systems  image retrieval  image segmentation  road vehicles  traffic information systems  semantic edge features  edge contours  building-sky  state-of-the-art localization algorithms  individual prominent features  VLASE  vehicle localization  on-road localization  semantic classes  VLAD framework  image retrieval  SIFT-VLAD  NetVLAD  SLC Marathon dataset  Salt Lake city  lighting variations  Semantics  Image edge detection  Feature extraction  Buildings  Databases  Visualization  Urban areas 
Abstract: We propose VLASE, a framework to use semantic edge features from images to achieve on-road localization. Semantic edge features denote edge contours that separate pairs of distinct objects such as building-sky, road-sidewalk, and building-ground. While prior work has shown promising results by utilizing the boundary between prominent classes such as sky and building using skylines, we generalize this to consider 19 semantic classes. We extract semantic edge features using CASENet architecture and utilize VLAD framework to perform image retrieval. We achieve improvement over state-of-the-art localization algorithms such as SIFT-VLAD and its deep variant NetVLAD. Ablation study shows the importance of different semantic classes, and our unified approach achieves better performance compared to individual prominent features such as skylines. We also introduce SLC Marathon dataset, a challenging dataset covering most of Salt Lake City with sufficient lighting variations.


Title: Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles
Key Words: cameras  computer vision  image reconstruction  image resolution  image texture  mesh generation  mobile robots  optical radar  robot vision  scan matching techniques  end-to-end real time framework  real time incremental foveal texture mapping  real time incremental foveal texture mapping  precise localization  detailed map  urban environment  high resolution graphics grade  texture mapping error  texture error  output map  computation time  ray-filtering  sparse input LIDAR scan  high resolution 3D  camera image information  pose-refinement procedure  color texture  coherent 3D surface  computer games  background map  planning algorithms  virtual test bed  autonomous vehicles  navigation  Three-dimensional displays  Laser radar  Cameras  Real-time systems  Image color analysis  Global Positioning System 
Abstract: We propose an end-to-end real time framework to generate high resolution graphics grade textured 3D map of urban environment. The generated detailed map finds its application in the precise localization and navigation of autonomous vehicles. It can also serve as a virtual test bed for various vision and planning algorithms as well as a background map in the computer games. In this paper, we focus on two important issues: (i) incrementally generating a map with coherent 3D surface, in real time and (ii) preserving the quality of color texture. To handle the above issues, firstly, we perform a pose-refinement procedure which leverages camera image information, Delaunay triangulation and existing scan matching techniques to produce high resolution 3D map from the sparse input LIDAR scan. This 3D map is then texturized and accumulated by using a novel technique of ray-filtering which handles occlusion and inconsistencies in pose-refinement. Further, inspired by human fovea, we introduce foveal-processing which significantly reduces the computation time and also assists ray-filtering to maintain consistency in color texture and coherency in 3D surface of the output map. Moreover, we also introduce texture error (TE) and mean texture mapping error (MTME), which provides quantitative measure of texturing and overall quality of the textured maps.


Title: Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
Key Words: collision avoidance  human-robot interaction  mobile robots  optical radar  path planning  probability  directional grid maps  occupancy map  mobile robot  robotic arm  static environments  dynamic objects  safer navigation  human-robot interaction  directional statistics  robotic mapping  model circular data  angular motion  probability measure-field  angular variations  indoor environments  outdoor environments  dynamic environments  grid maps  multimodal angular uncertainty  Vehicle dynamics  Robot sensing systems  Data models  Uncertainty  Navigation 
Abstract: Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.


Title: Human Motion Prediction Under Social Grouping Constraints
Key Words: Markov processes  mobile robots  motion control  multi-robot systems  planning (artificial intelligence)  probability  random processes  human motion prediction  social grouping constraints  long-term prediction  social relations  social norms  surrounding agents  MDP planning problem  social forces  social grouping information  prediction process  soft formation constraints  mobile robots  Force  Task analysis  Trajectory  Predictive models  Computational modeling  Tracking  Planning 
Abstract: Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.


Title: Robust LIDAR Localization for Autonomous Driving in Rain
Key Words: feature extraction  mobile robots  optical radar  particle filtering (numerical methods)  stereo image processing  traffic engineering computing  3D LIDAR scans  histogram filter  particle filter  posterior distributions  vehicle poses  complex urban environments  fair weather  rainy weather  robust LIDAR localization  autonomous driving  map-based localization method  rainy conditions  ground reflectivity features  vertical features extraction  Feature extraction  Three-dimensional displays  Laser radar  Histograms  Rain  Measurement by laser beam  Two dimensional displays 
Abstract: This paper introduces a map-based localization method aiming to increase robustness in rainy conditions. This method utilizes two types of features: ground reflectivity features and vertical features extracted from 3D LIDAR scans and builds vehicle pose belief with two filters: a histogram filter and a particle filter. The posterior distributions from the two filters are integrated to estimate vehicle poses. This method exploits advantages of both features and filters, compensating respective weakness to deal with complex urban environments. Testing was performed in the fair and rainy weather. Road test results prove robustness and reliability of the proposed method.


Title: Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
Key Words: collision avoidance  emergency management  mobile robots  motion control  multi-robot systems  trajectory control  safe navigation  safe motion controls  emergency trajectory candidates  just-in-time emergency trajectories  autonomous navigation  vehicle operation  safe system state  MHTP  moving horizon trajectory planner  safety requirements  vehicle's local control system  differential-drive mobile agent  nonstatic environment  robot  Trajectory  Safety  Navigation  Robots  Vehicle dynamics  Planning  Collision avoidance 
Abstract: Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.


Title: PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
Key Words: feature extraction  mobile robots  optical radar  path planning  local views  sliding window fashion  matching current  old features  map representation  local maps  off-road environments  single localization failure  distinctive features  coined PoseMap  dynamic environments  robotic systems  long-term localization  multienvironment 3D LiDAR localization  frequency 8.0 Hz  time 18.0 month  Simultaneous localization and mapping  Three-dimensional displays  Laser radar  Optimization  Feature extraction 
Abstract: Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.


Title: Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction
Key Words: collision avoidance  human computer interaction  mobile robots  navigation  pedestrians  road vehicles  vehicles  personal mobility vehicle autonomous navigation  pedestrian flow  data driven approach  parameter extraction  safe navigation  moving obstacles  public pedestrian paths  robotic PMV  human-driven smooth navigation  PMV-Human interaction  Navigation  Legged locomotion  Trajectory  Three-dimensional displays  Wheelchairs  Bicycles 
Abstract: In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.


Title: Identifying Driver Behaviors Using Trajectory Features for Vehicle Navigation
Key Words: automobiles  behavioural sciences computing  driver information systems  feature extraction  Internet  mobile robots  vehicle trajectories  autonomous vehicles  car trajectories  data-driven mapping  vehicle navigation simulation system  driver behavior identification  Web-based user study  Trajectory  Navigation  Automobiles  Feature extraction  Measurement  Acceleration 
Abstract: We present a novel approach to automatically identify driver behaviors from vehicle trajectories and use them for safe navigation of autonomous vehicles. We propose a novel set of features that can be easily extracted from car trajectories. We derive a data-driven mapping between these features and six driver behaviors using an elaborate web-based user study. We also compute a summarized score indicating a level of awareness that is needed while driving next to other vehicles. We also incorporate our algorithm into a vehicle navigation simulation system and demonstrate its benefits in terms of safer realtime navigation, while driving next to aggressive or dangerous drivers.


Title: Preliminary Evaluation of Null-Space Dynamic Process Model Identification with Application to Cooperative Navigation of Underwater Vehicles
Key Words: least squares approximations  marine communication  parameter estimation  position control  underwater vehicles  vehicle dynamics  UV model parameters  control-surface parameters  thruster-model parameters  preliminary evaluation  null-space dynamic process model identification  underactuated underwater vehicle  control-input parameters  UV nonlinear plant-model parameters  nonlinear model identification  underwater communication  cooperative navigation  null-space least-squares parameter identification method  Navigation  Vehicle dynamics  Acoustics  Underwater vehicles  Heuristic algorithms  Kinematics  Kalman filters 
Abstract: This paper reports a method and preliminary evaluation of a novel null-space least-squares parameter identification method for a fully nonlinear second -order 6-degree-of-freedom (DOF) dynamic process model of an underactuated underwater vehicle (UV) for which both the model parameters and the control-input parameters are unknown. This paper further reports the application of the identified plant models in combined underwater communication and navigation (cooperative navigation) of UVs. We report an approach to model identification that simultaneously identifies 6-DOF UV nonlinear plant-model parameters, control-surface parameters, and thruster-model parameters. We believe this approach is suitable for identifying plant model parameters from data obtained in full-scale experimental trials of UVs in controlled motion. The reported approach to nonlinear model identification of UVs is evaluated in simulation studies. The resulting identified UV plant models are further evaluated in simulated cooperative navigation missions of the UV that are representative of high-precision survey missions. To the best of our knowledge, this paper reports the first method to identify 6-DOF UV model parameters, control-surface parameters, and thruster-model parameters simultaneously.


Title: Efficient Computation of Invariably Safe States for Motion Planning of Self-Driving Vehicles
Key Words: collision avoidance  Markov processes  road vehicles  stochastic systems  self-driving vehicles  planning horizon  infinite time horizon  time-to-react metric  motion planning  Trajectory  Planning  Safety  Dynamics  Vehicle dynamics  Measurement  Reachability analysis 
Abstract: Safe motion planning requires that a vehicle reaches a set of safe states at the end of the planning horizon. However, safe states of vehicles have not yet been systematically defined in the literature, nor does a computationally efficient way to obtain them for online motion planning exist. To tackle the aforementioned issues, we introduce invariably safe sets. These are regions that allow vehicles to remain safe for an infinite time horizon. We show how invariably safe sets can be computed and propose a tight under-approximation which can be obtained efficiently in linear time with respect to the number of traffic participants. We use invariably safe sets to lift safety verification from finite to infinite time horizons. In addition, our sets can be used to determine the existence of feasible evasive maneuvers and the criticality of scenarios by computing the time-to-react metric.


Title: Strategic-Tactical Planning for Autonomous Underwater Vehicles over Long Horizons
Key Words: autonomous underwater vehicles  control engineering computing  mobile robots  planning (artificial intelligence)  robot dynamics  vehicle dynamics  strategic-tactical planning  autonomous underwater vehicles  long horizons  persistent autonomy  AI Planners  long-term autonomous behaviour  abstraction planning techniques  two-level hierarchical structure  hierarchical decompositions  Task analysis  Planning  Manifolds  Batteries  Inspection  Robots  Valves 
Abstract: In challenging environments where human intervention is expensive, robust and persistent autonomy is a key requirement. AI Planners can efficiently construct plans to achieve this long-term autonomous behaviour. However, in plans which are expected to last over days, or even weeks, the size of the state-space becomes too large for current planners to solve as a single problem. These problems are well-suited to decomposition and abstraction planning techniques. We present a novel approach in the context of persistent autonomy in autonomous underwater vehicles, in which tasks are complex and diverse and plans cannot be precomputed. Our approach performs a decomposition into a two-level hierarchical structure, which dynamically constructs planning problems at the upper level of the hierarchy using solution plans from the lower level. Solution plans are then executed and monitored simultaneously at both levels. We evaluate the approach, showing that compared to strictly top-down hierarchical decompositions, our approach leads to more robust solution plans of higher quality.


Title: End to End Vehicle Lateral Control Using a Single Fisheye Camera
Key Words: automobiles  cameras  collision avoidance  convolutional neural nets  mobile robots  robot vision  steering systems  label augmentation  short range fisheye camera  open road driving  single fisheye camera  convolutional neural networks  steering angle  autonomous cars  end-to-end control evaluation  end-to-end vehicle lateral control  urban road  sharp turns  obstacle avoidance  data augmentation  Automobiles  Cameras  Roads  Training  Neural networks  Testing 
Abstract: Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.


Title: Game-Theoretic Cooperative Lane Changing Using Data-Driven Models
Key Words: game theory  learning (artificial intelligence)  Markov processes  multi-agent systems  road traffic  data-driven models  self-driving vehicles  autonomous driving  road-bound multivehicle systems  DRL  game theory  proactive-passive lane changing framework  Markov game  multiagent autonomous vehicle tasks  deep reinforcement learning  single-agent RL setting  Games  Markov processes  Merging  Reinforcement learning  Autonomous vehicles  Neural networks  Space vehicles 
Abstract: Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.


Title: Robust Sensor Fusion with Self-Tuning Mixture Models
Key Words: adaptive control  control system synthesis  expectation-maximisation algorithm  Gaussian processes  least squares approximations  mixture models  nonlinear control systems  optimisation  robots  robust control  self-adjusting systems  sensor fusion  state estimation  robust sensor fusion  self-tuning mixture models  nonlinear state estimation  robotics  robust cost functions  nonGaussian error models  environmental changes  ageing  error distribution  state estimation process  Gaussian mixture  sensor model  standard state estimation  implicit expectation-maximization approach  distribution parameters  self-tuning algorithm  least-squares optimization framework  parameter tuning  Estimation  Robot sensing systems  Optimization  Tuning  Biological system modeling  Heuristic algorithms  Standards 
Abstract: A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.


Title: Scale Correct Monocular Visual Odometry Using a LiDAR Altimeter
Key Words: distance measurement  image sequences  mobile robots  optical radar  robot vision  SLAM (robots)  stereo image processing  stereo visual SLAM  monocular vision  inherent scale ambiguity  LiDAR altimeter  scale correct monocular visual odometry  RGB-D methods  scale drift  keyframe basis  scale constraint  mapping algorithm  keyframe based tracking  Visual Odometry method  laser altimeter  range data  exploration vehicles  power requirements  computational load  metrological accuracy  RGB-D sensors  3D LiDARs  metric references  sensory sources  Cameras  Laser radar  Measurement  Three-dimensional displays  Visual odometry  Visualization  Sensors 
Abstract: The inherent scale ambiguity in monocular vision is a well known issue that forces the integration of other sensory sources to obtain metric references. However, 2D or 3D LiDARs and RGB-D sensors, while guaranteeing metrological accuracy, impose a non negligible burden both in terms of computational load and power requirements limiting the feasibility of being implemented on small exploration vehicles. This paper presents a scale aware monocular Visual Odometry framework that fuses range data from a laser altimeter in order to recover and maintain a correct metric scale. The proposed Visual Odometry method consists of a keyframe based tracking and mapping algorithm using optical flow where range data serves as a scale constraint on a keyframe to keyframe basis. An optimization backend based on iSAM2 is employed in order to refine the trajectory and map estimates eliminating the scale drift without the need of performing loop closures. We demonstrate that our algorithm can obtain very similar performances to state of the art stereo visual SLAM and RGB-D methods.


Title: Robust Visual-Inertial State Estimation with Multiple Odometries and Efficient Mapping on an MAV with Ultra-Wide FOV Stereo Vision
Key Words: autonomous aerial vehicles  cameras  distance measurement  estimation theory  image fusion  image sensors  inertial navigation  motion estimation  motion measurement  state estimation  stereo image processing  visual perception  wide-angle stereo cameras  multicopter system  inertial measurement unit  virtual pinhole cameras  independent visual odometry  vision system  sensor fusion  robust visual-inertial state estimation  ultrawide FOV stereo vision  MAV  IMU  robust visual-inertial navigation  omnidirectional 3D mapping pipeline experiment  field of view  synthesized pinhole stereo systems  motion estimation fusion  image processing  multiVO approach  Cameras  Distortion  Image resolution  Computational modeling  Navigation  Visual odometry  Hardware 
Abstract: The here presented flying system uses two pairs of wide-angle stereo cameras and maps a large area of interest in a short amount of time. We present a multicopter system equipped with two pairs of wide-angle stereo cameras and an inertial measurement unit (IMU) for robust visual-inertial navigation and time-efficient omni-directional 3D mapping. The four cameras cover a 240 degree stereo field of view (FOV) vertically, which makes the system also suitable for cramped and confined environments like caves. In our approach, we synthesize eight virtual pinhole cameras from four wide-angle cameras. Each of the resulting four synthesized pinhole stereo systems provides input to an independent visual odometry (VO). Subsequently, the four individual motion estimates are fused with data from an IMU, based on their consistency with the state estimation. We describe the configuration and image processing of the vision system as well as the sensor fusion and mapping pipeline on board the MAV. We demonstrate the robustness of our multi-VO approach for visual-inertial navigation and present results of a 3D-mapping experiment.


Title: Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
Key Words: aerospace robotics  dynamic programming  integer programming  linear programming  mobile robots  multi-robot systems  path planning  visibility-based monitoring  heterogeneous robot team  terrain path  aerial robots  route planning  dynamic programming approach  integer linear programming solution  ground robots  Unmanned aerial vehicles  Robot sensing systems  Educational robots  Monitoring  Dynamic programming  Integrated circuits 
Abstract: We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.


Title: Underwater Surveying via Bearing Only Cooperative Localization
Key Words: mobile robots  path planning  remotely operated vehicles  underwater vehicles  bearing only cooperative localization  aerial ground vehicles  underwater domain  robotic applications  cave mapping  marine archeology surveying  fresh water  South Carolina  visibility conditions  depth sensors  magnetic sensors  inertial sensors  Florida  Barbados  Cameras  Springs  Robot kinematics  Lakes  Robot sensing systems 
Abstract: Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.


Title: Ego-Motion Estimate Corruption Due to Violations of the Range Flow Constraint
Key Words: distance measurement  image sensors  image sequences  mobile robots  motion estimation  robot vision  range sensors  visual odometry techniques  dense geometry-based visual odometry methods  range flow constraint equation  temporal derivatives  spatial derivatives  range images  ego-motion estimation  range data  Mathematical model  Cameras  Optical imaging  Visual odometry  Optical sensors  Adaptive optics  Optical variables control 
Abstract: Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.


Title: Semi-Supervised SLAM: Leveraging Low-Cost Sensors on Underground Autonomous Vehicles for Position Tracking
Key Words: cameras  learning (artificial intelligence)  mining  mining industry  mobile robots  object tracking  robot vision  SLAM (robots)  ORB-SLAM2  ground map locations  deep learning  position tracking  operational underground mining vehicles  single camera localization  map creation  mine environment  mining companies  underground environment  SemiSupervised SLAM  underground autonomous vehicles  low-cost sensors  Simultaneous localization and mapping  Cameras  Measurement  Grounding  Visual odometry  Lighting 
Abstract: This work presents Semi-Supervised SLAM - a method for developing a map suitable for coarse localization within an underground environment with minimal human intervention, with system characteristics driven by real-world requirements of major mining companies. This work leverages existing information common within a mining environment - namely a surveyed mine map - which is used to sparsely ground map locations within the mine environment, increasing map accuracy and allowing localization within a global frame. Map creation utilizes a low cost camera sensor and minimal user information to produce a map which can be used for single camera localization within a mining environment. We evaluate the localization capabilities of the proposed approach in depth by performing data collection on operational underground mining vehicles within an active underground mine and by simulating occlusions common to the environment such as dust and water. The proposed system is capable of producing maps which have an average localization error 2.5 times smaller than the next best performing method ORB-SLAM2, comparable localization performance to a state-of-the-art deep learning approach (which is not a feasible solution due to both compute and training requirements) and is robust to simulated environmental obscurants.


Title: Multi-Level Bayesian Decision-Making for Safe and Flexible Autonomous Navigation in Highway Environment
Key Words: Bayes methods  control engineering computing  decision making  navigation  probability  road safety  road traffic control  road vehicles  traffic engineering computing  TSLDN  driving situation assessment  vehicle navigation task  control architecture  probabilistic decision-making  safe navigation  flexible autonomous navigation  highway environment  MCA  multi-level Bayesian decision-making  multi-controller architecture  two-sequential level decision network  Extended Time-To-Collision metric  ETTC metric  Predicted Inter-Distance Profile  Safety  Decision making  Navigation  Trajectory  Road transportation  Uncertainty  Probabilistic logic 
Abstract: This paper proposes an overall Multi-Controller Architecture (MCA) for safe and flexible navigation of autonomous navigation, under uncertainties in highway use-cases. In addition to the details given about the main modules (and their interactions) composing the proposed MCA, an important focus of the paper is made on the definition of a robust Two-Sequential Level Decision Network (TSLDN), which uses both: Extended Time-To-Collision (ETTC) metric and a new definition of a specific Predicted Inter-Distance Profile (PIDP, between vehicles during lane changes maneuvers) in order to estimate the maneuvers risks. The TSLDN is utilized for: the driving situation assessment, decision-making and for safety retrospection over the current maneuver risk. It allows us to have the best decision to achieve the vehicle navigation task while maximizing its safety. Several simulation results show the good performance of the overall proposed control architecture, mainly in terms of efficiency to handle probabilistic decision-making even for very risky scenarios.


Title: Interaction-Aware Probabilistic Behavior Prediction in Urban Environments
Key Words: Bayes methods  belief networks  control engineering computing  driver information systems  inference mechanisms  Markov processes  mobile robots  Monte Carlo methods  probability  road vehicles  traffic engineering computing  combinatorial scene developments  road layouts  future scenes  probabilistic forward simulation  sequential Monte Carlo inference  single agents  context-dependent motion models  complete scene  dynamic Bayesian network  probabilistic prediction framework  mutual interaction  traffic rules  road-geometry  route intentions  traffic participants  urban scenarios  complex scenarios  autonomous driving  urban environments  interaction-aware probabilistic behavior prediction  interaction-unaware physics  real-world scenarios  Trajectory  Estimation  Vehicles  Probabilistic logic  Hidden Markov models  Predictive models  Bayes methods 
Abstract: Planning for autonomous driving in complex, urban scenarios requires accurate prediction of the trajectories of surrounding traffic participants. Their future behavior depends on their route intentions, the road-geometry, traffic rules and mutual interaction, resulting in interdependencies between their trajectories. We present a probabilistic prediction framework based on a dynamic Bayesian network, which represents the state of the complete scene including all agents and respects the aforementioned dependencies. We propose Markovian, context-dependent motion models to define the interaction-aware behavior of drivers. At first, the state of the dynamic Bayesian network is estimated over time by tracking the single agents via sequential Monte Carlo inference. Secondly, we perform a probabilistic forward simulation of the network's estimated belief state to generate the different combinatorial scene developments. This provides the corresponding trajectories for the set of possible, future scenes. Our framework can handle various road layouts and number of traffic participants. We evaluate the approach in online simulations and real-world scenarios. It is shown that our interaction-aware prediction outperforms interaction-unaware physics- and map-based approaches.


Title: Improved Quadcopter Disturbance Rejection Using Added Angular Momentum
Key Words: attitude control  control system synthesis  helicopters  position control  stability  torque control  vehicle dynamics  wheels  quadcopter disturbance rejection  added angular momentum  novel quadcopter design  added momentum wheel  enhanced stability  torque disturbance rejection capabilities  standard quadcopter  vehicle dynamics  torque disturbances  torque impulses  Wheels  Vehicle dynamics  Propellers  Torque  Attitude control  Angular velocity  State feedback 
Abstract: This paper presents a novel quadcopter design with an added momentum wheel for enhanced stability. The novel vehicle has improved torque disturbance rejection capabilities compared to a standard quadcopter. An analysis of the vehicle dynamics shows that the effect of torque disturbances decreases monotonically with increasing angular momentum of the momentum wheel. A framework for choosing the mass moment of inertia and speed of the momentum wheel is given based on an upper bound on the allowable energy stored in the wheel. Theoretical results are experimentally validated by comparing responses to torque impulses applied to the vehicle with and without the momentum wheel spinning.


Title: A Universal Controller for Unmanned Aerial Vehicles
Key Words: aerodynamics  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  helicopters  mobile robots  UAVs  agile fixed-wing aircraft  control logic  unmanned aerial vehicles  tilt-rotor  vehicle flight envelope  single physics-based controller  multicopters  autonomous flight  quadrotor  Force  Aircraft  Quaternions  Attitude control  Actuators 
Abstract: Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.


Title: Passive Compliance Control of Aerial Manipulators
Key Words: aerospace components  compliance control  end effectors  force control  manipulators  position control  time domain passivity technique  passive compliance control  aerial manipulators  stable environmental interactions  body-planar directions  aerial vehicle  manipulator  Manipulator dynamics  End effectors  Dynamics  Unmanned aerial vehicles  Mathematical model  Task analysis 
Abstract: This paper presents a passive compliance control for aerial manipulators to achieve stable environmental interactions. The main challenge is the absence of actuation along body-planar directions of the aerial vehicle which might be required during the interaction to preserve passivity. The controller proposed in this paper guarantees passivity of the manipulator through a proper choice of end-effector coordinates, and that of vehicle fuselage is guaranteed by exploiting time domain passivity technique. Simulation studies validate the proposed approach.


Title: Guidance Laws for Partially-Observable Interception Based on Linear Covariance Analysis
Key Words: aerospace control  autonomous aerial vehicles  covariance analysis  differential games  optimal control  differential game  linear covariance analysis  maneuvers  resulting guidance law  guidance laws  pursuit-evasion games  partial measurements  visual sensing  bearing measurements  partially-observable interception problem  observability  Observability  Games  Uncertainty  Mathematical model  Vehicle dynamics  Extraterrestrial measurements  Task analysis 
Abstract: We consider pursuit-evasion games in which the pursuer is tasked with intercepting the evader using only partial measurements. Motivated by the utilization of visual sensing on board the pursuer, we focus on the case when only bearing measurements are available to the pursuer. The resulting partially-observable interception problem is computationally challenging, and the separation principle does not hold in general. In this paper, we identify a set of maneuvers that improve observability, and we propose an algorithm that utilizes these maneuvers to move the pursuer so that the expected payoff of the differential game is maximized. The algorithm uses in-the-loop uncertainty propagation based on linear covariance analysis to assess the effect of the maneuvers. We evaluate the resulting guidance law in experiments involving a quadcopter in flight representing the pursuer, and a simulated evader.


Title: SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors
Key Words: aircraft control  autonomous aerial vehicles  human-robot interaction  microrobots  multi-robot systems  path planning  tactile sensors  trajectory control  impedance controlled swarm  nanoquadrotors  novel interaction strategy  human-swarm communication  human operator guides  quadrotors  impedance control  human hand velocity  formation shape  Crazyflie 2.0 quadrotor platform  control algorithm  tactile patterns  controllability  complex life-like formation  tactile sensation  drone formation  human-swarm interaction  swarm navigation  Impedance  Drones  Robots  Mathematical model  Shape  Force  Safety 
Abstract: We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.


Title: Design and Implementation of a Novel Aerial Manipulator with Tandem Ducted Fans
Key Words: aerospace testing  aircraft control  autonomous aerial vehicles  compensation  control system synthesis  fans  feedforward  helicopters  manipulator dynamics  stability  vehicle dynamics  aerial vehicle dynamics  manipulator dynamics  tandem ducted fans  trafficability  comprehensive integrated dynamic model  aerial manipulator  loading  multirotor  multilayer composite controller  feedforward compensation  flight tests  Manipulator dynamics  Fans  Payloads  Helicopters  Ducts 
Abstract: This paper proposes a novel aerial manipulator with tandem ducted fans, which takes both trafficability and effective loading into account. The aerial manipulator is particularly suitable for grasping in complex and narrow environment, in which traditional multi-rotor and helicopter would be inaccessible. The comprehensive integrated dynamic model is established by taking the aerial vehicle dynamics and manipulator dynamics as a whole. On this basis, a multilayer composite controller with feedforward compensation is designed, considering the mutual reactive influence between the aerial vehicle and the manipulator to improve the stability of the system under the motion of the manipulator. The simulation and actual flight tests verify the effectiveness of the design and show good stability and tracking performance of the system.


Title: Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels
Key Words: image sensors  lenses  photodetectors  robot vision  stereo image processing  visual perception  WAF lens  wide angle fovea lens  high-definition imager  autonomous robot  vehicle supersensing vision system  robotic vision  field of view  FOV  high-resolution photosensitive imaging chip  stereo vision system  optical performance  aspherical surface  projection testing  Lenses  Prototypes  Spatial resolution  Cameras  Robots  Optical imaging 
Abstract: This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.


Title: Reach-Avoid Problems via Sum-or-Squares Optimization and Dynamic Programming
Key Words: dynamic programming  reachability analysis  state-space methods  reach-avoid problem  dynamic programming  sum-of-squares optimization  polynomial system dynamics  mathematical guarantees  Optimization  Dynamic programming  System dynamics  Games  Planning  Automobiles  Vehicle dynamics 
Abstract: Reach-avoid problems involve driving a system to a set of desirable configurations while keeping it away from undesirable ones. Providing mathematical guarantees for such scenarios is challenging but have numerous potential practical applications. Due to the challenges, analysis of reach-avoid problems involves making trade-offs between generality of system dynamics, generality of problem setups, optimality of solutions, and computational complexity. In this paper, we combine sum-of-squares optimization and dynamic programming to address the reach-avoid problem, and provide a conservative solution that maintains reaching and avoidance guarantees. Our method is applicable to polynomial system dynamics and to general problem setups, and is more computationally scalable than previous related methods. Through a numerical example involving two single integrators, we validate our proposed theory and compare our method to Hamilton-Jacobi reachability. Having validated our theory, we demonstrate the computational scalability of our method by computing the reach-avoid set of a system involving two kinematic cars.


Title: Collaborative Planning for Mixed-Autonomy Lane Merging
Key Words: control engineering computing  decision making  driver information systems  game theory  mobile robots  multi-agent systems  path planning  road traffic  road vehicles  collaborative planning  social activity  mixed-autonomy traffic  Human-driven Vehicle  HV  Autonomous Vehicle drive  AV  planning framework  two-lane highway  double lane merging  collaborative decision making  mixed-autonomy lane merging  Automobiles  Planning  Merging  Collaboration  Robots  Autonomous vehicles 
Abstract: Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.


Title: Probabilistic Collision Threat Assessment for Autonomous Driving at Road Intersections Inclusive of Vehicles in Violation of Traffic Rules
Key Words: belief networks  collision avoidance  decision making  mobile robots  probability  road safety  road traffic  road vehicles  traffic rules violation  vehicles road intersections inclusive  Bayesian networks  time window filtering  decision-making  in-vehicle testing  nonviolation vehicles  closed urban test road  violation vehicles  autonomous vehicle  probabilistic collision threat assessment algorithm  autonomous driving  Roads  Reliability  Principal component analysis  Probabilistic logic  Prediction algorithms  Autonomous vehicles 
Abstract: In this paper, we propose a probabilistic collision threat assessment algorithm for autonomous driving at road intersections that assesses a given traffic situation at an intersection reliably and robustly for an autonomous vehicle to cross the intersection safely, even in the face of violation vehicles (that is, vehicles in violation of traffic rules at the intersection). To this end, the proposed algorithm employs a detailed digital map to predict future paths of observed vehicles and then utilizes the predicted future paths to identify potential threats (vehicles) and potential collision areas, regardless of whether observed vehicles are obeying traffic rules at the intersection. Next, by means of Bayesian networks and time window filtering under an independent and distributed reasoning structure, it assesses the potential threats regarding the possibility of collision reliably and robustly, even under uncertain and incomplete noise data. Then, it has been tested and evaluated through in-vehicle testing on a closed urban test road under traffic conditions inclusive of non-violation and violation vehicles. In-vehicle testing results show that the performance of the proposed algorithm is sufficiently reliable to be used in decision-making for autonomous driving at intersections in terms of reliability and robustness, even in the face of violation vehicles.


Title: Search-Based Optimal Motion Planning for Automated Driving
Key Words: mobile robots  optimisation  path planning  road vehicles  search problems  trajectory control  automated driving  fast motion planning  robust motion planning  real-time computation  urban conditions  convenient geometrical representation  search space  driving constraints  classical path planning approach  exact cost-to-go map  optimal motion trajectory  time horizons  fast driving conditions  slow driving conditions  search-based optimal motion planning  Planning  Vehicle dynamics  Trajectory  Dynamics  Roads  Search problems  Automation  motion planning  automated driving  lane change  multi-lane driving  traffic lights  A* search  MPC 
Abstract: This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.


Title: Visual Vehicle Tracking Through Noise and Occlusions Using Crowd-Sourced Maps
Key Words: image motion analysis  image reconstruction  image segmentation  object detection  object tracking  traffic engineering computing  video signal processing  video surveillance  camera phones  performed city-scale structure-from-motion  high-accuracy localisation  unsupervised motion prediction  real-time visual tracking pipeline  monocular camera  large-scale datasets  New York City  perception system  large-scale crowd-sourced maps  visual vehicle tracking  location-specific method  Automobiles  Trajectory  Tracking  Three-dimensional displays  Cameras  Pipelines  Hidden Markov models 
Abstract: We present a location-specific method to visually track the positions of observed vehicles based on large-scale crowd-sourced maps. We equipped a large fleet of cars that drive around cities with camera phones mounted on the dashboard, and performed city-scale structure-from-motion to accurately reconstruct the trajectories taken by the vehicles. We show that these data can be used to first create a system enabling high-accuracy localisation, and then to accurately predict the future motion of newly observed cars in the camera view. As a basis for the method we use a recently proposed system [1] for unsupervised motion prediction and extend it to a real-time visual tracking pipeline which can track vehicles through noise and extended occlusions using only a monocular camera. The system is tested using two large-scale datasets of San Francisco and New York City containing millions of frames. We demonstrate the performance of the system in a variety of traffic, time, and weather conditions. The presented system requires no manual annotation or knowledge of road infrastructure. To our knowledge, this is the first time a perception system based on a large-scale crowd-sourced maps has been evaluated at this scale.


Title: Vehicle Rebalancing for Mobility-on-Demand Systems with Ride-Sharing
Key Words: integer programming  linear programming  road traffic  road vehicles  scheduling  vehicle routing  historical taxi data  integer linear programming  idle vehicle redistribution  MoD systems  urban transportation  mobility-on-demand systems  real-time demand estimate  fleet operating area  MoD fleet  vehicle routes  road vehicles  ride-sharing  vehicle rebalancing  average waiting time  rebalancing regions  time 13.7 s  Schedules  Real-time systems  Delays  Partitioning algorithms  Public transportation  Automobiles 
Abstract: Recent developments in Mobility-on-Demand (MoD) systems have demonstrated the potential of road vehicles as an efficient mode of urban transportation Newly developed algorithms can compute vehicle routes in real-time for batches of requests and allow for multiple requests to share vehicles. These algorithms have primarily focused on optimally producing vehicle schedules to pick up and drop off requests. The redistribution of idle vehicles to areas of high demand, known as rebalancing, on the contrary has received little attention in the context of ride-sharing. In this paper, we present a method to rebalance idle vehicles in a ride-sharing enabled MoD fleet. This method consists of an algorithm to optimally partition the fleet operating area into rebalancing regions, an algorithm to determine a real-time demand estimate for every region using incoming requests, and an algorithm to optimize the assignment of idle vehicles to these rebalancing regions using an integer linear program. Evaluation with historical taxi data from Manhattan shows that we can service 99.8% of taxi requests in Manhattan using 3000 vehicles with an average waiting time of 57.4 seconds and an average in-car delay of 13.7 seconds. Moreover, we can achieve a higher service rate using 2000 vehicles than prior work achieved with 3000. Furthermore, with a fleet of 3000 vehicles, we reduce the average travel delay by 86%, the average waiting time by 37%, and the amount of ignored requests by 95% compared to earlier work at the expense of an increased distance travelled by the fleet.


Title: Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots
Key Words: collision avoidance  learning (artificial intelligence)  legged locomotion  microrobots  mobile robots  neural nets  robot dynamics  underactuated legged systems  hand-engineered controllers  dynamic maneuvers  complex terrains  real-world legged millirobot  learned neural network models  predictive model  expressive capacity neural network models  high-capacity neural network models  effective learning  dynamic legged millirobot  image-conditioned dynamics models  underactuated legged millirobots  low manufacturing costs  complex environments  highly dynamic systems  Vehicle dynamics  Legged locomotion  Neural networks  Adaptation models  Predictive models  Robot sensing systems 
Abstract: Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.


Title: Through-the-Lens Drone Filming
Key Words: autonomous aerial vehicles  cameras  feature extraction  Global Positioning System  image motion analysis  image sensors  mobile robots  pose estimation  robot vision  video signal processing  image composition  monocular 3D human pose estimation  drone control system  drone filming system  wearable GPS-based sensors  wearable infrared-based sensors  through-the-lens drone filming  aerial filming  camera control  drone hardware  human actions  drone camera system  through-the-lens camera planning  flight control  through-the-lens drone  wearable-sensor-based solutions  drone platform  outdoor environments  human movement  remote controller  action scenes  Cameras  Drones  Three-dimensional displays  Sensors  Pose estimation  Solid modeling  Two dimensional displays 
Abstract: Aerial filming in action scenes using a drone is difficult for inexperienced flyers because manipulating a remote controller and meeting the desired image composition are two independent, while concurrent, tasks. Existing systems attempt to utilize wearable GPS-based or infrared-based sensors to track the human movement and to assist in capturing footage. However, these sensors work only in either indoor (infrared-based) or outdoor environments (GPS-based), but not both. In this paper, we introduce a novel drone filming system which integrates monocular 3D human pose estimation and localization into a drone platform to remove the constraints imposed by wearable-sensor-based solutions. Meanwhile, given the estimated position, we propose a novel drone control system, called “through-the-lens drone filming”, to allow a cameraman to conveniently control the drone by manipulating a 3D model in the preview, which closes the gap between the flight control and the viewpoint design. Our system includes two key enabling techniques: 1) subject localization based on visual-inertial fusion, and 2) through-the-lens camera planning. This is the first drone camera system which allows users to capture human actions by manipulating the camera in a virtual environment. From the drone hardware, we integrate a gimbal camera and two GPUs into the limited space of a drone and demonstrate the feasibility of running the entire system onboard with insignificant delays, which are sufficient for filming in our real-time application. Experimental results, in both simulation and real-world scenarios, demonstrate that our techniques can greatly ease camera control and capture better videos.


Title: Towards Aerial Recovery of Parachute-Deployed Payloads
Key Words: aerospace robotics  aircraft control  mobile robots  position control  parachute-deployed payloads  sensor payloads  atmospheric profiling applications  inaccessible regions  multirotor unmanned aerial system  parachute-payload system  long-term payload transportation systems  aerial recovery  Payloads  Target tracking  Cameras  Robot sensing systems  Vehicle dynamics  Aerodynamics 
Abstract: Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.


Title: Airborne Docking for Multi-Rotor Aerial Manipulations
Key Words: autonomous aerial vehicles  mobile robots  multirotor aerial robots  transport multirotor UAV  winch mechanism  onboard locolization  mobile manipulation system  airborne docking method  IMU data  multirotor aerial manipulations  Winches  Bars  Cameras  Robot vision systems  DC motors  Propellers 
Abstract: We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.


Title: Optimal Time Allocation for Quadrotor Trajectory Generation
Key Words: autonomous aerial vehicles  convex programming  helicopters  mobile robots  optimal control  polynomials  robot dynamics  trajectory control  optimal time allocation  quadrotor flights  quadrotor trajectory generation problem  spatial trajectory  time optimization  polynomial trajectories  quadrotor platform  kinodynamic limits  autonomous flights  open-source ROS-package  temporal trajectory  convex program  mapping function  Trajectory  Resource management  Safety  Optimization  Acceleration  Time-domain analysis  Shape 
Abstract: In this paper, we present a framework to do optimal time allocation for quadrotor trajectory generation. Using this method, we can generate minimum-time piecewise polynomial trajectories for quadrotor flights. We decouple the quadrotor trajectory generation problem into two folds. Firstly we generate a smooth and safe curve which is parameterized by a virtual variable. This curve named spatial trajectory is independent of time and has fixed spatial properties. Then a mapping function which decides how the quadrotor moves along the spatial trajectory respecting kinodynamic limits is found by minimizing total trajectory time. The mapping function maps the virtual variable to time is named temporal trajectory. We formulate the minimum-time temporal trajectory generation problem as a convex program which can be efficiently solved. We show that the proposed method can corporate with various types of previous trajectory generation method to obtain the optimal time allocation. The proposed method is integrated into a customized light-weight quadrotor platform and is validated by presenting autonomous flights in indoor and outdoor environments. We release our code for time optimization as an open-source ros-package.


Title: Aerial Radio-Based Telemetry for Tracking Wildlife
Key Words: autonomous aerial vehicles  directive antennas  mobile radio  mobile robots  radio tracking  telemetry  aerial radio-based telemetry  measurement locations  radio collar  low-cost directional antenna  USB receiver  wedges  online strategy  measurement noise  autonomous aerial robot  wildlife tracking  localization uncertainty  Antenna measurements  Animals  Measurement uncertainty  Uncertainty  Time measurement  Sensors  Robots 
Abstract: This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.


Title: Planning to Monitor Wildfires with a Fleet of UAVs
Key Words: autonomous aerial vehicles  emergency management  fires  path planning  search problems  wildfires  fire propagation process  observation trajectories  fire model  wildfire monitoring  variable neighborhood search method  fixed-wing UAV fleet  Trajectory  Monitoring  Cameras  Ignition  Planning  Fuels  Shape 
Abstract: We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind. The approach tailors a generic Variable Neighborhood Search method to these models and associated constraints. Simulation results show ability to plan observation trajectories for a small fleet of UAVs, and to update the plans when new information on the fire are incorporated in the fire model.


Title: Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
Key Words: aerospace control  aerospace robotics  aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  path planning  robot dynamics  stability  multilinked model  near-hover condition  motion sequence  improved dynamics derivation  flight control method  flight stability  small opening  flight motion  transformable multilinked aerial robot  multilinked robot  transformable aerial robot  under-actuated multirotors  aggressive maneuvering  necessary condition  crucial problems  unknown obstacle  multirotor  robot body  Unmanned aerial vehicles  Rotors  Collision avoidance  Path planning  Stability analysis  Robot sensing systems 
Abstract: In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).


Title: Optimal Constrained Trajectory Generation for Quadrotors Through Smoothing Splines
Key Words: autonomous aerial vehicles  helicopters  optimisation  path planning  splines (mathematics)  time optimal control  trajectory control  vehicles physical limits  large-scale fitting problem  human sketching  optimal constrained trajectory generation  inequality constraints  closed-form solution  safe flying zones  interval-wise constraints  axes-coupled  time optimal control techniques  polynomial splines  optimal smoothing B-spline  quadrotors  Trajectory  Splines (mathematics)  Optimization  Smoothing methods  Closed-form solutions  Space vehicles  Safety 
Abstract: In this paper, we present a trajectory generation method for quadrotors based on the optimal smoothing B-spline. Compared to existing methods which rely on polynomial splines or time optimal control techniques, our method systematically addresses the issue of axes-coupled and interval-wise constraints. These constraints can be used to construct safe flying zones and satisfy vehicle's physical limits. The proposed approach has also been extended to generate trajectories from the nominal plan which consists of not only points but also lines and planes, opening a door for new improvements and applications. Moreover, a closed-form solution can be obtained for cases without inequality constraints. Such a solution is numerically stable for the large-scale fitting problem, which allows us to directly fit the human sketching input from the touch device and capture all subtle details. Our approach is verified by various real flight experiments..


Title: LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain
Key Words: embedded systems  feature extraction  image segmentation  optical radar  optimisation  pose estimation  robot vision  SLAM (robots)  SLAM framework  edge features  feature extraction  point cloud segmentation  lightweight and ground-optimized lidar odometry  real-time six degree-of-freedom pose estimation  low-power embedded system  ground plane  two-step Levenberg-Marquardt optimization method  optimization steps  ground vehicles  LeGO-LOAM  Feature extraction  Three-dimensional displays  Laser radar  Image segmentation  Pose estimation  Real-time systems  Iterative closest point algorithm 
Abstract: We propose a lightweight and ground-optimized lidar odometry and mapping method, LeGO-LOAM, for realtime six degree-of-freedom pose estimation with ground vehicles. LeGO-LOAM is lightweight, as it can achieve realtime pose estimation on a low-power embedded system. LeGO-LOAM is ground-optimized, as it leverages the presence of a ground plane in its segmentation and optimization steps. We first apply point cloud segmentation to filter out noise, and feature extraction to obtain distinctive planar and edge features. A two-step Levenberg-Marquardt optimization method then uses the planar and edge features to solve different components of the six degree-of-freedom transformation across consecutive scans. We compare the performance of LeGO-LOAM with a state-of-the-art method, LOAM, using datasets gathered from variable-terrain environments with ground vehicles, and show that LeGO-LOAM achieves similar or better accuracy with reduced computational expense. We also integrate LeGO-LOAM into a SLAM framework to eliminate the pose estimation error caused by drift, which is tested using the KITTI dataset.


Title: A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
Key Words: mobile robots  multi-agent systems  multi-robot systems  position control  trajectory control  multiagent systems  classification task  conventional centered wheel  distance-bearing formations  unicycle robots  distance-bearing constraints  macro-robot  regular convex polygon  trajectory-tracking control problem  Mobile robots  Wheels  Robot kinematics  Kinematics  Vehicle dynamics  Axles 
Abstract: In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.


Title: Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
Key Words: aerospace robotics  manipulators  mobile robots  multi-robot systems  vibration control  MAGMaS  load flexibility  heterogeneous system  aerial robot  rigid load manipulation  load weight holding  long-slender object manipulation  multiple aerial-ground manipulator system  flexible load-tip pose tracking  vibration suppression controllability  Unmanned aerial vehicles  Manipulators  Load modeling  Vibrations  Mathematical model  Shape 
Abstract: The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.


Title: Determining Effective Swarm Sizes for Multi-Job Type Missions
Key Words: multi-agent systems  multi-robot systems  optimisation  particle swarm optimisation  queueing theory  sensitivity analysis  vehicle routing  sensitivity analysis  M/M/k/k queuing model  swarm search and service mission  SSS mission  swarm sizes  DVR  dynamic vehicle routing  multijob type missions  multiagent framework  balancing vehicle allocation  human operators  Robot sensing systems  Routing  Time factors  Planning  Task analysis 
Abstract: Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.


Title: Milligram-Scale Micro Aerial Vehicle Design for Low-Voltage Operation
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  electromagnetic actuators  microrobots  milligram-scale microaerial vehicle design  low-voltage operation  wing-span  wing aerial vehicle  electromagnetic actuator  low-voltage input  actuation  single resonant mechanism  small-linear-displacement amplifying stages  ±45° wing strokes  ±45° wing plane  energy efficient electromagnetic design  electromagnetic works  mass 70.0 mg  size 3.0 cm  mass 60.0 mg  voltage 5.5 V  frequency 98.0 Hz  power 250.0 mW  mass 100.0 mg  Magnetic resonance  Actuators  Springs  Magnetic separation  Loss measurement  Mathematical model  Laser beams 
Abstract: We present a 70mg, 3cm wing-span, flapping wing aerial vehicle capable of generating up to 60mg of lift using an electromagnetic actuator with low-voltage input (≈5.5V). Its design is novel, with the actuation and transmission integrated into a single resonant mechanism, thus not requiring any small-linear-displacement amplifying stages seen in other works. It can produce ±45° wing strokes and ±45° wing plane rotations at 98Hz operation mimicking relevant insects at this size scale. With required input power of only 250mW, it is, to the best of our knowledge, the most energy efficient electromagnetic design at the sub-100mg scale reported to date, and an order of magnitude more efficient than all other electromagnetic works.


Title: Resistive Pulse Study of Liposome Stability: Towards Precision and Efficient Drug Delivery
Key Words: biological tissues  biomedical materials  biomembranes  cancer  cellular biophysics  drug delivery systems  lipid bilayers  molecular biophysics  nanofabrication  nanomedicine  nanoparticles  scanning electron microscopy  resistive pulse study  liposome stability  drug delivery vehicle  resistive pulse method  liposome fusion  cancerous tissue arrangement  organic nanoparticle measurement  3D manipulator positioning  cellular in-vivo measurement  environmental SEM chamber  size 50.0 nm  size 100.0 nm  Lipidomics  Drug delivery  Manipulators  Stability analysis  Size measurement  Three-dimensional displays  Glass  drug delivery vehicle  liposome  3D manipulator  resistive pulse method  size measurement  sub 100nm Nano pores 
Abstract: In this work, the authors report the investigation of liposomes' stability as a drug delivery vehicle, using the method of resistive pulse method. The main objects of interest are the 50nm diameter liposomes, while the 100nm diameter liposomes are widely used for its stability. However, certain drug delivery scenarios arise, like tighter cancerous tissue arrangement and different circulation time requirement, which dictates the necessity of sub-100nm diameter vesicles. The size measurements upon freshly fabricated liposomes are performed frequently on increasing time interval. The results exhibit a trend of size increasing, suggesting the existence of liposome fusion. The possible models of fusion are proposed and discussed. This work demonstrates the localized organic nanoparticle measurement with fine dual 3D manipulator positioning, which paves the way for the possible cellular in-vivo measurement within an environmental SEM chamber.


Title: Visual-Inertial Teach and Repeat Powered by Google Tango
Key Words: automatic optical inspection  autonomous aerial vehicles  collision avoidance  control engineering computing  Global Positioning System  mobile robots  pose estimation  robot vision  trajectory control  human operator  visual inspection task  autonomous aerial vehicle  Google Tango visual-inertial mapping framework  pose estimates  GPS-denied environments  inspection points  feature-based localization map  industrial facilities  multicopters  visual-inertial teach  hedge maze  Robots  Inspection  Task analysis  Collision avoidance  Google  Autonomous systems  Visualization 
Abstract: Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.


Title: Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
Key Words: aircraft control  distributed algorithms  mobile robots  multi-robot systems  tracking  trajectory control  multirobot systems  geometric parameters  distributed algorithm  tracking controller  robots position  distributed trajectory generator  mini aerial vehicles  distributed reconfigurable formation generator  Generators  Intelligent robots  Trajectory  Multi-robot systems  Distributed algorithms 
Abstract: This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.


Title: Autonomous Underwater Vehicle Navigation in Structured Environment
Key Words: autonomous underwater vehicles  cameras  geophysical image processing  image sensors  marine navigation  oceanographic techniques  position measurement  sensor fusion  sonar  AUV navigation system  autonomous underwater vehicle navigation system  signal uncertainties  signal distortion  cameras  position estimation  image sonar aided integrated navigation system  active vision markers  inherent drift of dead-reckoning velocities  jacket structure  artificial landmarks  sensor-fusion-based localization scheme  integrated navigation system  Sonar navigation  Oceans  Sonar  Autonomous robots  Industries  Intelligent robots  Autonomous underwater vehicles 
Abstract: With the increase in developments in underwater infrastructure, the demand for development of autonomous vehicle navigation system in structured environment is also increased. However, the localization in a structured environment is a challenging problem due to signal uncertainties and distortions. In order to overcome these problems, we propose the camera and sonar aided integrated navigation system. In the proposed sensor-fusion-based localization scheme, the AUV estimates its own position continuously using artificial landmarks. The artificial landmarks for image sonar is deployed along the path to guide the AUV to the structure. The active vision markers are installed on the jacket structure, and they function as both landmarks and waypoints. This approach prevents the inherent drift of dead-reckoning velocities and collision with structures. The proposed approach was verified through a real sea experiment. The AUV conducted the full autonomous navigation from the dock to the jacket structure, and then returned to the dock without collision or significant localization error. These results show the feasibility of full autonomous navigation in a structured environment.


Title: Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure
Key Words: autonomous aerial vehicles  collision avoidance  image reconstruction  inspection  Kalman filters  mobile robots  robot vision  wind turbines  UAVs  Aerial inspection  aerial tool  autonomous cooperative coverage  multiple Unmanned Aerial Vehicles  onboard computer  sensory system  autonomous navigation  localization system  Ultra Wideband  aerial team  realistic wind turbine inspection experiments  dense 3D reconstruction  inspected structures  state Kalman filter  3D infrastructure  large scale aging infrastructure  Inspection  Three-dimensional displays  Tools  Intelligent robots  Aging  Unmanned aerial vehicles  Robot sensing systems 
Abstract: This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.


Title: Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers
Key Words: aerospace robotics  Mars  mobile robots  path planning  planetary rovers  robot kinematics  state estimation  statistical distributions  light-weight analytic solution  rocky terrain  typical numeric approaches  onboard computation  single collision  unstructured terrain  robot motion planning  kinematics-based collision detection  planetary rovers  probabilistic kinematic state estimation  deterministic state bounds  distribution models  probabilistic safety guarantees  worst-case evaluation  deterministic bounds  probability distributions  frequent false positive detection  conservative safety check approach  worst-case values  constraint violation  terrain height  articulated suspension systems  Mars 2020 rover mission  Approximate Clearance Evaluation  Wheels  Kinematics  Planning  Space vehicles  Uncertainty  Numerical models  Probabilistic logic 
Abstract: Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.


Title: Online Self-Supervised Long-Range Scene Segmentation for MAVs
Key Words: autonomous aerial vehicles  image segmentation  learning (artificial intelligence)  microrobots  mobile robots  object detection  robot vision  vision-based autonomous MAV flight  self-supervised online learning  adaptive scene segmentation  data-driven methods  manually annotated training data  geometry-based methods  sensor capabilities  robust scene understanding  complex dynamic environments  autonomous flights  lightweight MicroAerial Vehicles  MAVs  online self-supervised long-range scene segmentation  Image segmentation  Training  Robot sensing systems  Visualization  Real-time systems  Convolution 
Abstract: Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.


Title: PAMPC: Perception-Aware Model Predictive Control for Quadrotors
Key Words: autonomous aerial vehicles  helicopters  mobile robots  nonlinear programming  path planning  predictive control  robot vision  PAMPC  lighting conditions  visual-inertial odometry pipeline  low-power ARM computer  nonlinear optimization problem  action objective  numerical optimization  perception-aware model predictive control framework  model-based optimization framework  perception objective  quadrotor  motion planning  Cameras  Trajectory  Optimization  Robot vision systems  Predictive control  Planning 
Abstract: We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.


Title: History-Aware Autonomous Exploration in Confined Environments Using MAVs
Key Words: attitude control  autonomous aerial vehicles  mobile robots  path planning  sampling-based exploration algorithms  3D exploration planner  field-of-view depth sensor  configuration space  high sampling efficiency  computational constrained real world MAV  history-aware autonomous exploration  confined environments  inspection tasks  high-dimensional path planning problem  microaerial vehicle  search and rescue missions  next-best views  robot orientation  Planning  Robot sensing systems  Three-dimensional displays  Trajectory  History  Optimization 
Abstract: Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.


Title: Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
Key Words: autonomous aerial vehicles  collision avoidance  convolutional neural nets  feature extraction  indoor navigation  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  regression analysis  robot vision  sensor fusion  velocity control  indoor flights  unmanned aerial vehicles  civilian applications  indoor-flight dataset  agent distance-to-collision prediction  drone safe deployment  on-board monocular camera  external sensors  spatio-temporal feature extraction  static appearance information  motion information  robot distance estimation  linear velocity  navigation policy learning  real-distance labels  raw visual input  regression CNN  real-time obstacle avoidance  indoor robot navigation  autonomous navigation methods  UAV  self-supervised CNN-based approach  navigation policy  Robots  Navigation  Sensors  Drones  Cameras  Task analysis  Trajectory 
Abstract: Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.


Title: Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight
Key Words: autonomous aerial vehicles  cameras  control engineering computing  convolutional neural nets  face recognition  feature extraction  gesture recognition  human-robot interaction  image colour analysis  image segmentation  object detection  robust control  video signal processing  YOLOv2 deep convolutional neural network  hand-and-face detector  gestural human-UAV interface  robust control  hand-labelled videos  face-engagement  robust sensor front-end  gray-scale images  robust real-time system  mono-camera user detection  human-robot interaction  human-UAV interaction experiments  Detectors  Feature extraction  Proposals  Training  Object detection  Face detection  Cameras 
Abstract: We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.


Title: Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  helicopters  image sequences  mobile robots  robot vision  dense high-speed optical flow  real-time motion cues  obstacle avoidance  smooth trajectory  image flow representation  forest environment  forward sensitive reactive control  quadrotor VTOL  aerial robotic vehicles  3D full reconstruction  fully image based control criteria  Optical sensors  Optical imaging  Adaptive optics  Velocity measurement  Robot sensing systems  Cameras 
Abstract: Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.


Title: Angle-Encoded Swarm Optimization for UAV Formation Path Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  particle swarm optimisation  angle-encoded particle swarm optimization  3DR solo drones  mission planner  Internet-of- Things  UAV formation path planning  triangular formation maintenance  swarm convergence  multiple-objective optimisation algorithm  unmanned aerial vehicles  feasible path planning technique  Trajectory  Collision avoidance  Unmanned aerial vehicles  Task analysis  Cost function  Shape  Quadcopter  θ-PSO  path planning  loT  triangular formation  collision avoidance 
Abstract: This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.


Title: An Integrated Localization-Navigation Scheme for Distance-Based Docking of UAVs
Key Words: adaptive estimation  autonomous aerial vehicles  convergence  image sequences  invariance  mobile robots  navigation  path planning  position control  single landmark  unmanned aerial vehicles  GPS-less environment  optical flow sensors  ultra-wideband ranging sensors  discrete-time LaSalle invariance principle  UAV  distance-based docking problem  integrated localization-navigation scheme  asymptotic docking  delicate control scheme  relative position  nonlinear adaptive estimation scheme  bounded velocity  discrete-time integrators  navigation tasks  relative localization  integrated estimation-control scheme  arbitrarily unknown position  Navigation  Convergence  Distance measurement  Adaptive estimation  Estimation  Task analysis  Optical sensors 
Abstract: In this paper we study the distance-based docking problem of unmanned aerial vehicles (UAVs) by using a single landmark placed at an arbitrarily unknown position. To solve the problem, we propose an integrated estimation-control scheme to simultaneously achieve the relative localization and navigation tasks for discrete-time integrators under bounded velocity: a nonlinear adaptive estimation scheme to estimate the relative position to the landmark, and a delicate control scheme to ensure both the convergence of the estimation and the asymptotic docking at the given landmark. A rigorous proof of convergence is provided by invoking the discrete-time LaSalle's invariance principle, and we also validate our theoretical findings on quadcopters equipped with ultra-wideband ranging sensors and optical flow sensors in a GPS-less environment.


Title: Machine Learning Based Skill-Level Classification for Personal Mobility Devices Using Only Operational Characteristics
Key Words: electric vehicles  handicapped aids  learning (artificial intelligence)  pattern classification  wheelchairs  machine learning  skill-level classification  personal mobility devices  operational characteristics  electric-powered wheelchairs  handicapped people  comfort travel  skill level classification method  skill level clusters  joystick operation data  five-level classification  supervised learning  user operation skills  unsupervised clustering  speed control  direction control  gradient boosting  Boosting  Vehicles  Sensors  Feature extraction  Acceleration 
Abstract: Some electric-powered wheelchairs are recently redefined as personal mobility devices. Their users are not only elderly or handicapped people, but also passengers with large baggage or pedestrians going from station to destination, i.e., last-mile transport. Consequently, people with different operation skills and expectations on personal mobility would become new users of this kind of devices. Safe and comfort travel in human co-existing environment such as sidewalks and airports is a social expectation for personal mobility. In order to realize this, understanding the operation skill of each user by a practical and simple method is essential. This paper thus introduced a skill level classification method by machine learning using only joystick data as input. In order to determine the number of skill level clusters, basic 26 features of joystick operation data are used for unsupervised clustering (single-linkage). We then made evaluation indexes by using speed, speed control, and direction control. For a five-level classification by using gradient boosting as supervised learning, we achieved a 67% accuracy (tolerance: 0) and a 98% accuracy (tolerance: 1). Further analysis of the feature importance of gradient boosting revealed key features to a good operation. Results also show that skill level differed among people with different driving experiences.


Title: Adaptive Sensor Bias Estimation in Nine Degree of Freedom Inertial Measurement Units: Theory and Preliminary Evaluation
Key Words: angular measurement  attitude measurement  calibration  gyroscopes  inertial systems  magnetic field measurement  magnetic sensors  magnetometers  adaptive sensor bias estimation  three-axis magnetometers  three-axis accelerometers  three-axis angular rate sensors  high-end angular rate sensors  ring-laser gyros  MEMS gyros  compensation  attitude estimation  attitude and heading reference systems  nine degree of freedom inertial measurement units  sensor bias calibration methods  adaptive sensor bias observer  magnetic-north AHRS heading  DOF inertial measurement units  true-North heading AHRS estimation  Earth-rate estimation  9-DOF IMU measurements  Robot sensing systems  Magnetometers  Instruments  Accelerometers  Observers  Gyroscopes 
Abstract: Nine degrees of freedom (DOF) inertial measurement units (IMUs) comprised of three-axis magnetometers, three-axis accelerometers, and three-axis angular rate sensors are commonly used in attitude and heading reference systems (AHRSs). Two classes of AHRSs exist: systems that estimate true-North heading and systems that estimate magnetic-North heading. True-North heading AHRSs require high-end angular rate sensors which are sensitive enough to dynamically estimate Earth-rate (typically fiber-optic and ring-laser gyros), while magnetic-North AHRSs employ gyros that are not sensitive enough to dynamically estimate Earth-rate (i.e. all MEMS gyros). Thus, magnetic-North AHRSs employ magnetometers for estimating heading. This paper will focus on this class of magnetic-North AHRSs. These systems fuse IMU measurements to generate estimates of the instrument's roll, pitch, and magnetic heading. However, their accuracy is limited by sensor measurement bias that is unknown a priori. Hence, accurate sensor bias estimation and compensation is essential for true attitude estimation. This paper reports a novel adaptive sensor bias observer for sensor measurement biases in 9-DOF IMUs. The algorithm requires smaller angular movements of the instrument than other reported sensor bias calibration methods, does not require a priori knowledge of local fields like the local magnetic field or the local gravity vector, and does not require knowledge of the attitude of the instrument. Stability proofs, preliminary simulations, and a full-scale vehicle experimental evaluation are reported.


Title: PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python
Key Words: aerospace robotics  cameras  computer aided instruction  control engineering education  educational courses  mobile robots  Python  remotely operated vehicles  robot programming  robot vision  state estimation  three-term control  high-level planning  PiDrone  autonomous educational drone  Python  compelling robotics course  low-cost aerial educational platform  associated college-level introductory robotics course  autonomous aircraft  downward facing RGB camera  distance sensor  onboard Raspberry Pi  accessible platform  inexpensive platform  SSH capable computer  base station  programming platform  robotics operating system framework  ROS framework  PID control  state estimation  Drones  Educational robots  Robot sensing systems  Python  Service robots  Hardware 
Abstract: A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.


Title: State Estimate Recovery for Autonomous Quadcopters
Key Words: acceleration measurement  aerodynamics  autonomous aerial vehicles  channel bank filters  helicopters  Kalman filters  nonlinear filters  robot dynamics  state estimation  state estimate recovery  autonomous quadcopters  aerodynamic force model  extended Kalman filters  linear acceleration measurements  complete recovery logic  quadcopter platform  IMU  Aerodynamics  Gravity  Mathematical model  Accelerometers  Propellers  Data models  Position measurement 
Abstract: A method for recovery from the complete loss of the state estimate is presented for autonomous quadcopters. Given an aerodynamic force model, the only measurements used to reinitialize the state estimate by means of a bank of extended Kalman filters are the angular rate and linear acceleration measurements of an IMU. The method is integrated within a complete recovery logic on a quadcopter platform and experimentally evaluated.


Title: A Revisited Approach to Lateral Acceleration Modeling for Quadrotor UAVs State Estimation
Key Words: aerodynamics  autonomous aerial vehicles  blades  drag  helicopters  Kalman filters  mobile robots  nonlinear filters  robot dynamics  state estimation  lateral acceleration modeling  quadrotor UAVs state estimation  rotors angular speeds  quadrotor drag  lateral accelerations  flight test data  attitude state estimator  EKF-based estimator  velocity state estimator  vehicle aerodynamics modeling  blade element theory  Rotors  Blades  Acceleration  Optical sensors  Data models  Atmospheric modeling  Aerodynamics 
Abstract: Quadrotor state estimation generally relies on the vehicle aerodynamics modeling to achieve improved performance. In this paper the effects of the rotors angular speeds on the quadrotor drag, and therefore on the lateral accelerations, are investigated. While these effects are usually disregarded, we analyze their modeling starting from the Blade Element Theory and flight test data. Two lateral acceleration formulations are proposed. They are adopted within a velocity and attitude state estimator and validated in real-world flights. The EKF-based estimator fuses measurements from low-cost sensors present in the majority of quadrotors (IMU, magnetometer, ultrasonic sensor, optical flow) with the accelerations of the vehicle predicted from the revisited models. Experimental results show the benefits of adopting these innovative models in the estimator when compared with the existing modeling approach.


Title: Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles
Key Words: aerospace robotics  collision avoidance  inspection  optical sensors  power overhead lines  sensor placement  collision avoidance  optical sensors  sensor placement  fixed energy infrastructure  aerial inspection  multirotor platform  assisted control technology  aerial vehicles  semiautonomous power infrastructure inspection  proximity inspection tasks  assisted control approach  Inspection  Wires  Measurement  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles  Task analysis 
Abstract: This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.


Title: Bidirectional Thrust for Multirotor MAVs with Fixed-Pitch Propellers
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  helicopters  propellers  fixed-pitch propellers  multirotor MicroAerial Vehicles  bidirectional thrust vector  dedicated motor controllers  controller design  control allocation approach  static thrust test  inverted flight  multirotor MAV  unidirectional thrust vehicles  Propellers  Rotors  Torque  Resource management  Force  Attitude control  Trajectory 
Abstract: This paper is devoted to the study of multirotor Micro Aerial Vehicles (MAVs) with fixed-pitch propellers and bidirectional thrust vector. The latter is realized by using dedicated motor controllers, which allow to invert the propellers' direction of rotation during flight (so-called 3D mode), and almost or fully symmetric propellers. We present a unified modeling, controller design, and control allocation approach that accounts for bidirectional thrust. Suitable propellers with the ability to produce thrust and torque in both directions are compared and their parameters are identified through a static thrust test. Furthermore, we discuss applications of bidirectional thrust, like inverted flight or surface slip reduction, which are impossible to realize with common unidirectional thrust vehicles. We generate suitable flight trajectories and evaluate our unified approach in experiments with a custom-built quadrotor.


Title: DREGON: Dataset and Methods for UAV-Embedded Sound Source Localization
Key Words: acoustic noise  acoustic signal processing  aerospace computing  audio signal processing  autonomous aerial vehicles  control engineering computing  microphone arrays  broad-band source localization  microphone array  noisy in-flight audio recordings  3D position  rotor rotational speed  loud noise conditions  extreme noise levels  accurate motion capture system  target sound source  UAV-embedded sound source localization  DREGON  Microphone arrays  Propellers  Drones  Robots  White noise 
Abstract: This paper introduces DREGON, a novel publicly-available dataset that aims at pushing research in sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). The dataset contains both clean and noisy in-flight audio recordings continuously annotated with the 3D position of the target sound source using an accurate motion capture system. In addition, various signals of interests are available such as the rotational speed of individual rotors and inertial measurements at all time. Besides introducing the dataset, this paper sheds light on the specific properties, challenges and opportunities brought by the emerging task of UAV-embedded sound source localization. Several baseline methods are evaluated and compared on the dataset, with real-time applicability in mind. Very promising results are obtained for the localization of a broad-band source in loud noise conditions, while speech localization remains a challenge under extreme noise levels.


Title: Joint 3D Proposal Generation and Object Detection from View Aggregation
Key Words: image classification  image colour analysis  image fusion  mobile robots  neural nets  object detection  optical radar  radar detection  regression analysis  road vehicle radar  robot vision  high resolution feature maps  reliable 3D object proposals  multiple object classes  category classification  second stage detection network  AVOD  KITTI 3D object detection  autonomous vehicles  3D bounding box regression  multimodal feature fusion  RPN  region proposal network  RGB images  LIDAR point clouds  neural network architecture  autonomous driving scenarios  Aggregate View Object Detection network  joint 3D proposal generation  Three-dimensional displays  Feature extraction  Proposals  Computer architecture  Agriculture  Object detection  Two dimensional displays 
Abstract: We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.


Title: Real-Time Segmentation with Appearance, Motion and Geometry
Key Words: autonomous aerial vehicles  cameras  distance measurement  Global Positioning System  image motion analysis  image segmentation  mobile robots  motion estimation  object detection  remotely operated vehicles  robot vision  domain knowledge  planar scenes  high altitude unmanned aerial vehicles  homography compensated flow  urban scenes  autonomous driving  depth estimates  segmentation accuracy  geometric priors  UAV imagery  baseline network  sparse depth  motion segmentation solution  assisted systems  traffic monitoring  unmanned aerial vehicles imagery  two-stream convolutional network  geometric cues  computational efficiency trade-offs  real-time segmentation  GPS-IMU sensory data  KITTI-MoSeg  Motion segmentation  Computer vision  Real-time systems  Convolutional codes  Autonomous vehicles  Unmanned aerial vehicles  Image segmentation 
Abstract: Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at1.


Title: Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation
Key Words: cameras  collision avoidance  control engineering computing  convolutional neural nets  edge detection  image segmentation  mobile robots  remotely operated vehicles  robot vision  stereo image processing  water edge  stereo extensions  joint stereo-view semantic segmentation  unmanned surface vehicles  scene semantic segmentation problem  single-view model  consistent class labels assignment  monocular CNN  class-label posterior map  stereo-based obstacle detection  Semantics  Image segmentation  Cameras  Image edge detection  Sea surface  Graphical models  Three-dimensional displays 
Abstract: We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.


Title: Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics
Key Words: cameras  energy harvesting  feature extraction  Haar transforms  image classification  image colour analysis  image texture  mobile robots  neural nets  robot vision  solar power  terrain mapping  wavelet transforms  outdoor mobile robots  feature extraction  visual-spectrum images  on-board camera  Haar wavelet transform  color information  textural information  ANN  high dynamic range imagery  energy consumption  traversability criteria  energy harvesting capabilities  vision-based artificial neural network  sequential methodology  solar irradiance map  terrain classes  solar-powered mobile robots  real-time terrain classification  solar irradiance mapping  vision-based terrain classification  Image color analysis  Feature extraction  Neural networks  Training  Image segmentation  Wavelet transforms  Sensors  Field Robotics  Image Processing  Solar Mapping  Terrain Classification  Solar Robotics 
Abstract: This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.


Title: Robust Fixed-Wing UAV Guidance with Circulating Artificial Vector Fields
Key Words: aircraft control  asymptotic stability  autonomous aerial vehicles  control system synthesis  Lyapunov methods  robust control  vectors  constrained input controls  asymptotic stability  control law  robust fixed-wing UAV guidance  guidance vector field strategy  unmanned aerial vehicle  closed curve  control system  aircraft model  artificial vector fields  Convergence  Uncertainty  Atmospheric modeling  Aircraft  Three-dimensional displays  Unmanned aerial vehicles  Shape 
Abstract: This paper presents a guidance vector field strategy to control a fixed-wing UAV (unmanned aerial vehicle)subject to uncertainty in order to converge to and circulate a closed curve in ℝ3. The control system is designed based on a reference model of the airplane with constrained input controls. The law is independent of the vector field's structure, however, some analysis considers a consolidated vector field approach. Asymptotic stability is proven with Lyapunov Theory and ultimate bounds are found when bounded uncertainties are taken into account. The control law is continuous except in the surroundings of the unavoidable field's singularities. A theorem ensures asymptotic convergence when a switch is made. Simulations with a 6 DOF, 12 states realistic aircraft model demonstrate the efficiency of the strategy and its advantages.


Title: Real-Time Quad-Rotor Path Planning for Mobile Obstacle Avoidance Using Convex Optimization
Key Words: attitude control  collision avoidance  convex programming  helicopters  propellers  mobile obstacle avoidance  on-board convex-optimization-based path planning  multirotors  fixed-pitch propellers  fixed-pitch actuators  uni-directional thrust  commanded total thrust  sufficient independent attitude control authority  indoor flight demonstration  second-order cone programming problems  real-time quad-rotor path planning  real-time 3-dimensional path planning  Trajectory  Real-time systems  Software  Acceleration  Vehicle dynamics  Attitude control 
Abstract: In this paper, we employ convex optimization to perform real-time 3-dimensional path planning on-board a quad-rotor and demonstrate its real-time capabilities. Building on our previous work, we make the following modifications: (1)we assume the obstacles are mobile, and (2)we introduce a simple framework to continuously recompute and update the trajectory. The contribution of this paper is to demonstrate the feasibility of real-time on-board convex-optimization-based path planning. For multi-rotors with fixed-pitch propellers, this path planning problem has two sources of non-convexity. First, since fixed-pitch actuators produce uni-directional thrust, the commanded total thrust must be maintained above a non-zero minimum in order to retain sufficient independent attitude control authority. The second source of non-convexity is due to the keep-out zones that envelop each obstacle. To circumvent the non-convexities introduced by these control and state constraints, we employ lossless and successive con-vexification, respectively. Consequently, we cast the original problem as a sequence of Second-Order Cone Programming problems, which can be solved quickly and reliably on-board. We conclude by presenting indoor flight demonstration and timing results of a scenario with three mobile obstacles. In this scenario, our algorithm assumes that the obstacles move with constant acceleration, and is re-executed regularly to account for uncertainties in the motion of the obstacles. The results show that new trajectories can be computed at rates in excess of 10 Hz, quickly enough to adapt to the uncertainty introduced in our flight demonstration.


Title: Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators
Key Words: active disturbance rejection control  end effectors  feedforward  H∞ control  hydraulic actuators  loading equipment  mining  mobile robots  PD control  vehicle dynamics  wheels  active disturbance rejection control  skid-steer loader  H∞ control  PD control  ADRC  inertial sensors  hydraulic arm dynamics  wheels  end-effector  front-end loaders  robotic mining mobile manipulators  material spillage  hydraulic actuators  autonomous machines  feedforward action  proportional-derivative control  Manipulator dynamics  Force  Dynamics  Mathematical model  Hydraulic actuators  Wheels 
Abstract: Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H∞ control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat® 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.


Title: Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy
Key Words: learning (artificial intelligence)  object detection  remotely operated vehicles  indoor environments  Udacity dataset  image conditioned energy based generative adversarial network  on-line monitoring framework  assured autonomy  Adversarial Learning-Based On-Line Anomaly Monitoring  autonomous ground vehicle  sensor data  action condition video prediction framework  anomalous actuator commands  proper actuator commands  generative adversarial network  SFAM  system-focused anomaly detection  CFAM  controller-focused anomaly detection  sensor inputs  unmanned ground vehicle  learning-based control systems  Generators  Convolution  Actuators  Monitoring  Anomaly detection  Robot sensing systems  Computer architecture 
Abstract: The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.


Title: Safe Reinforcement Learning on Autonomous Vehicles
Key Words: learning (artificial intelligence)  remotely operated vehicles  road traffic control  road vehicles  intersection handling behaviors  autonomous vehicle  safety critical applications  learning process  safe reinforcement learning  Safety  Autonomous vehicles  Trajectory  Games  Pipelines  Noise measurement  Standards 
Abstract: There have been numerous advances in reinforcement learning, but the typically unconstrained exploration of the learning process prevents the adoption of these methods in many safety critical applications. Recent work in safe reinforcement learning uses idealized models to achieve their guarantees, but these models do not easily accommodate the stochasticity or high-dimensionality of real world systems. We investigate how prediction provides a general and intuitive framework to constraint exploration, and show how it can be used to safely learn intersection handling behaviors on an autonomous vehicle.


Title: A Novel Monocular-Based Navigation Approach for UAV Autonomous Transmission-Line Inspection
Key Words: autonomous aerial vehicles  control engineering computing  image registration  inspection  mobile robots  neural nets  object detection  path planning  poles and towers  power overhead lines  robot vision  UAV autonomous navigation approach  pan-tilt monocular-based navigation scheme  neural network  homography matrix  distance variation  point set registration model  tower detection  overhead transmission lines  UAV autonomous transmission-line inspection  Poles and towers  Inspection  Navigation  Power transmission lines  Kernel  Cameras  Safety 
Abstract: This paper proposes a unique and robust UAV autonomous navigation approach along one side of overhead transmission lines for inspection. To this end, we establish a perspective model and develop a novel Pan/Tilt monocular-based navigation scheme. Simultaneously, the following three key issues are addressed. First, to locate the effective landmark - transmission tower timely and reliably, we customize a neural network for tower detection and combine it with a fast and smooth tracking. Second, to provide UAV with a robust and precise heading, we detect the transmission lines and compute and optimize their vanishing point. Third, to keep a safe distance from transmission lines, we optimize a homography matrix to restore the parallel nature of transmission lines and perceive the distance variation by a point set registration model. Finally, by the designed UAV platform, we test the whole system in a real-world transmission-line inspection scenario under different weather condition and achieve an encouraging result. Our approach provides great flexibility for refined inspection and effectively improves inspection safety.


Title: Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
Key Words: autonomous aerial vehicles  biomimetics  control system synthesis  helicopters  manipulators  mobile robots  path planning  robot vision  sensors  AGRASP  multirotor aerial vehicles  robotics perception  vision-based path planning  highly-constrained sensor  autonomous grasping robotic aerial system for perching  biomimetically-inspired manipulation  perch structures  innovative manipulator design  active grasp  passive grip  quadrotor autonomously detection  onboard sensing  onboard processing  Manipulators  Tendons  Robot sensing systems  Bars  Grasping  Three-dimensional displays 
Abstract: This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.


Title: Energy-Efficient Trajectory Generation for a Hexarotor with Dual- Tilting Propellers
Key Words: autonomous aerial vehicles  matrix algebra  optimal control  propellers  trajectory control  hexarotor  maneuverability  control allocation matrix  brushless motors  angular accelerations  optimal control problem  underactuation degree  dual- tilting propellers  energy-efficient trajectory generation  Propellers  Trajectory  Brushless motors  Batteries  Silicon  Force  Resource management 
Abstract: In this paper, we consider a non-conventional hexarotor whose propellers can be simultaneously tilted about two orthogonal axes: in this way, its underactuation degree can be easily adapted to the task at hand. For a given tilt profile, the minimum-energy trajectory between two prescribed boundary states is explicitly determined by solving an optimal control problem with respect to the angular accelerations of the six brushless motors. We also perform, for the first time, a systematic study of the singularities of the control allocation matrix of the hexarotor, showing the presence of subtle singular configurations that should be carefully avoided in the design phase. Numerical experiments conducted with the FAST-Hex platform illustrate the theory and delineate the pros and cons of dual-tilting paradigm in terms of maneuverability and energy efficiency.


Title: Towards Autonomous Stratospheric Flight: A Generic Global System Identification Framework for Fixed-Wing Platforms
Key Words: aerodynamics  aerospace components  aircraft control  aircraft testing  autonomous aerial vehicles  error analysis  interpolation  Mach number  parameter estimation  Mach numbers  parameter identification techniques  fixed-wing platforms  flight test data  aerodynamic model  autonomous stratospheric flight  generic global system identification  high altitude long endurance fixed-wing aerial vehicles  extrapolation analysis  error analysis  autonomous missions  time efficient model  Aerodynamics  Atmospheric modeling  Aircraft  Mathematical model  Databases  Data models  Unmanned aerial vehicles 
Abstract: System identification of High Altitude Long Endurance fixed-wing aerial vehicles is challenging as its operating flight envelope covers wide ranges of altitudes and Mach numbers. We present a new global system identification framework geared towards such fixed-wing aerial platforms where the aim is to build a global aerodynamic model without many repetitions of local system identification procedures or the use of any aerodynamic database. Instead we apply parameter identification techniques to virtually created system identification data and update the identified parameters with available flight test data. The proposed framework was evaluated using data set outside the flight envelope of the available flight test data, i.e. at different airspeeds considering both interpolation and extrapolation scenarios. The error analysis has shown that the obtained longitudinal aerodynamic model can accurately predict the pitch rate and pitch angle, mostly within a tolerance of +1.5 degrees/s and +2 degrees respectively. Such a cost and time efficient model development framework enables high fidelity simulation and precise control which ultimately leads to higher success rates in autonomous missions.


Title: Design and Implementation of Cloud-Like Soft Drone S-Cloud
Key Words: aerodynamics  airships  attitude control  autonomous aerial vehicles  flow control  helium  prototypes  rotors (mechanical)  soft blimp part  center-pierced torus-shaped part  flow control mechanism  co-axial rotors  2-axis crossed flaps  cloud-like soft drone S-cloud  translational motion  helium gas  collision damage  altitude control  attitude control  vehicle translational movements  Newton-Euler formulation  prototypes  He  Rotors  Force  Drones  Helium  Vehicle dynamics  Buoyancy 
Abstract: This study presents a new drone, called S-CLOUD, developed for safe and long flight time. It provides 3-axial (x, y, and z)translational motion and stable hovering for more than an hour after takeoff. S-CLOUD consists of two parts; soft blimp part and driving one. The soft blimp is a center-pierced torus-shaped part filled with Helium gas. Thus, it is safe to fly near people because it is light and soft, and all its rotating parts are at the center of the vehicle, which does not get damaged on collision. The driving part is plugged into the center of the soft blimp and includes the flow control mechanism, which consists of co-axial rotors and 2-axis crossed flaps. It controls the altitude, attitude, and translational movements of the vehicle. Its dynamic and reaction features against disturbances are derived using Newton-Euler formulation, and the simulation results are discussed. Finally, a prototype of S-CLOUD is fabricated and its feasibility is experimentally validated with practical applications.


Title: Recovery Control for Quadrotor UAV Colliding with a Pole
Key Words: autonomous aerial vehicles  cameras  collision avoidance  helicopters  mobile robots  robot dynamics  robot vision  telerobotics  inertial onboard sensing  propeller-protected quadrotor UAV  collision recovery control solutions  poles  operator error  wind gusts  onboard cameras  microUAVs  air quality measurement  civil infrastructure inspection  police surveillance  disaster response  postcollision dynamics  onboard vision failure  Force  Collision avoidance  Mathematical model  Geometry  Drones  Aerodynamics  Propellers 
Abstract: Small quadrotor UAVs are projected to fly increasingly in urban environments for a wide variety of applications such as disaster response, police surveillance, civil infrastructure inspection, and air quality measurement. Micro UAVs can detect and avoid obstacles using onboard cameras; nevertheless, disturbances such as wind gusts, operator error, or failure of onboard vision can still result in dangerous collisions with objects. In the urban setting, the most predominant obstacles are walls and poles. With the aim of developing collision recovery control solutions for quadrotor UAVs, this paper investigates the collision dynamics between a propeller-protected quadrotor UAV and a vertical pole. Simulations provide insight into a quadrotor's post-collision dynamics and experimental trials demonstrate the feasibility of autonomously recovering to stable flight using only inertial onboard sensing in real-time.


Title: ArduSoar: An Open-Source Thermalling Controller for Resource-Constrained Autopilots
Key Words: aerospace components  aerospace simulation  aircraft control  autonomous aerial vehicles  resource-constrained autopilots  autonomous soaring capability  soaring controller  autopilot software suite  algorithmic standpoint  ArduPlane autopilot  parameter tuning  open-source thermalling controller  fixed-wing UAV  ArduSoars robustness  Aircraft  Atmospheric modeling  Computational modeling  Kalman filters  Mathematical model  Heating systems  Earth 
Abstract: Autonomous soaring capability has the potential to significantly increase time aloft for fixed-wing UAVs. In this paper, we introduce ArduSoar, the first soaring controller integrated into a major autopilot software suite for small UAVs. We describe ArduSoar from the algorithmic standpoint, outline its integration with the ArduPlane autopilot, discuss parameter tuning for it, and conduct a series of flight tests on real sUAVs that show ArduSoar's robustness even in highly nonideal atmospheric conditions.


Title: DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance
Key Words: collision avoidance  graph theory  image segmentation  image sensors  mobile robots  motion control  neural nets  robot vision  stereo image processing  multiple disparity images  C-space expansion  disparity space representation  generic obstacles  wire pixels  confidence map  semantic segmentation paradigm  convolutional neural network  monocular wire detection  generic obstacle avoidance  robust autonomous aerial vehicles  depth estimation  DROAN - disparity-space representation  Wires  Robot sensing systems  Three-dimensional displays  Cameras  Trajectory  Uncertainty 
Abstract: Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.


Title: Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges
Key Words: autonomous aerial vehicles  constraint handling  control engineering computing  distance measurement  iterative methods  least squares approximations  mobile robots  pose estimation  robot vision  tree searching  pose uncertainty domains  interval constraint propagation techniques  simulated two-robots configurations  unmanned aerial vehicles  bounded error measurements  distances measurements  ground station  camera images  UAV  cooperative localization  branch and bound algorithm  nonlinear iterative weighted least squares  Cameras  Robot kinematics  Robot vision systems  Position measurement  Base stations 
Abstract: An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.


Title: Active Disturbance Rejection Control of a Flying-Wing Tailsitter in Hover Flight
Key Words: active disturbance rejection control  aerodynamics  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  control system synthesis  helicopters  motion control  observers  position control  active disturbance rejection control  flying-wing tailsitter  hover flight  tailsitter unmanned aerial vehicle  vehicle aerodynamics  accurate vertical flying  attitude controller  tracking differentiator  vertical takeoff and landing  tailsitter design  position controller  VTOL  six-degrees-of-freedom model  6-DOF model  outdoor stationary hovering  ADRC  extended state observer  ESO  TD  Propellers  Aerodynamics  Attitude control  Aircraft  Earth  Unmanned aerial vehicles  Gravity 
Abstract: This paper presents the development and hovering control of a tailsitter unmanned aerial vehicle (UAV) that merges long endurance and vertical takeoff and landing (VTOL) abilities. The designed tailsitter contains one flying-wing with two motors and two elevons. Vehicle aerodynamics and a six-degrees-of-freedom (6-DOF) model are especially developed for the tailsitter. To achieve a good performance in outdoor stationary hovering and accurate vertical flying, the active disturbance rejection control (ADRC) for attitude controller is proposed. With signals from extended state observer (ESO) and tracking differentiator (TD), ADRC decouples the system model into a controllable chain of integrators. Based on the decoupled system dynamics, the motion of tailsitter can be easily handled by developed position controller. Experimental results are presented to corroborate the effectiveness of the controller in disturbance rejection.


Title: Underwater Modeling, Experiments and Control Strategies of FroBot
Key Words: legged locomotion  mobile robots  motion control  optimal control  propulsion  robot dynamics  underwater vehicles  two-degree-of-freedom robotic swing-legs  2DOF  Frobot model  Frobot underwater  caudal fins  Morison equation  control applications  CPGs control strategy  optimal control strategy  dynamic model  dual swing-legs propulsion mechanism  Legged locomotion  Mathematical model  Dynamics  Propulsion  Force  Acceleration 
Abstract: FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.


Title: A Practical Method to Speed-Up the Experimental Procedure of Iterative Learning Controllers
Key Words: adaptive control  autonomous aerial vehicles  control system synthesis  iterative learning control  vehicle dynamics  traditional practice  ILC experiments  ILC signal  experimental data  accurate linear model  total experimental time  predicted system data  practical method  experimental procedure  iterative learning controllers  practical approach  lengthy experimentational processes  iterative learning control  low-order identified models  Trajectory  Data models  Optimization  Attitude control  Process control  Predictive models  Tracking 
Abstract: This paper proposes a practical approach for fastening the lengthy experimentational processes that may occur with iterative learning control (ILC) upto a certain level using simple low-order identified models. The traditional practice in ILC experiments is to update the ILC signal by directly using the experimental data after each run of the process which corresponds to one ILC update per one run. When considered from the point of experimental time, even conducting a moderate number of ILC updates can take quite long with this procedure. Since an accurate linear model can adequately represent the actual system upto a certain amplitude and/or frequency of the desired reference, we propose that the total experimental time can be reduced by updating the ILC signal via predicted system data until the limits of the linear model. This approach allows one to carry out large number of ILC updates while not needing to carry out the same amount of real experiments. Consequently, a significant number of experiments that would be needed for achieving the same results can be skipped with a simulation approach. The efficiency of the proposed method was tested through experimentation with three different UAV reference trajectories and the results demonstrated that it is possible to attain significant amount of tracking precision in several flight experiments.


Title: A Partially Filled Jamming Gripper for Underwater Recovery of Objects Resting on Soft Surfaces
Key Words: compliance control  end effectors  grippers  seawater  sediments  underwater vehicles  partially filled jamming gripper  soft surfaces  partially filled membrane  submerged objects  soft substrates  jamming grippers  particle jamming  end effector membrane  internal membrane pressure  deep sea shipwrecks  downward force  maximum lifting force  gripper membrane  soft sediment  irregular objects  grasping  fresh water tank experiment  seawater  compliant foam  fine loose sediment  waterlogged timbers  compliance control  underwater object recovery  Grippers  Jamming  Force  Manifolds  Solids  Substrates  Sediments  soft robotics  universal jamming grippers  marine archeology 
Abstract: In this paper we demonstrate a universal jamming gripper with a partially filled membrane that can pick up submerged objects resting on soft substrates. Jamming grippers take advantage of the phenomenon of particle jamming to control the compliance of an end effector membrane. Changes in internal membrane pressure are used to transition the membrane between hard and soft states. The effort was motivated by the need for tools to sample artifacts on deep sea shipwrecks, which are often found resting on waterlogged timbers, or partially buried in fine, loose sediment. Limiting downward force protects the target, and reduces the likelihood that it will be pushed down in to the substrate, which could lead to a failed grasp. In benchtop tests, the downward force, and the ratio of maximum lifting force to downward force, are shown to be strongly dependent on the initial volume of particles and fluid in the gripper membrane. The gripper achieves lifting forces 6.7 times the downward force on targets with high aspect ratios. Experiments in a fresh water tank demonstrate the ability to grasp objects resting on soft sediment, and compliant foam. Finally, experiments at sea demonstrate that the end effector functions at depths of more than 1000m seawater, successfully grasping a range of irregular objects.


Title: Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration
Key Words: control engineering computing  decision making  learning (artificial intelligence)  mobile robots  motion control  path planning  road vehicles  vehicle dynamics  human-vehicle interaction simulation framework  driving motions  vehicle maneuver motion primitives  driving decision-making  vehicle design  human demonstration  vehicle dynamics  motion control  motion primitive library  longitudinal vehicle control  motion reproduction  dynamic motion primitives  imitation learning methods  fixed-base driving simulation  vehicle maneuver motion planning  Vehicles  Computational modeling  Task analysis  Motion segmentation  Vehicle dynamics  Hidden Markov models  Dynamics 
Abstract: High-fidelity computational human models provide a safe and cost-efficient method for studying driver experience in vehicle maneuvers and for validation of vehicle design. Compared to passive human models, active human models capable of reproducing the decision-making, as well as vehicle maneuver motion planning and control, will be able to support realistic simulation of human-vehicle interaction. In this paper, we propose an integrated human-vehicle interaction simulation framework which learns vehicle maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions. Specifically, we recruited six experienced drivers and recorded their vehicle maneuver motions on a fixed-base driving simulation testbed. We further segmented and classified the collected data based on their similarity in joint coordination. Using a combination of imitation learning methods, we extracted the regularity and variability of vehicle maneuver motions across subjects, and learned the dynamic motion primitives to be used for motion reproduction in simulation. We present an implementation of the framework on lower-extremity joint coordination in pedal activation for longitudinal vehicle control. Our research efforts lead to a motion primitive library which enables planning natural driver motions, and will be integrated with the driving decision-making, motion control, and vehicle dynamics in the proposed framework for simulating human-vehicle interaction.


Title: Adaptive Admittance Control in Task-Priority Framework for Contact Force Control in Autonomous Underwater Floating Manipulation* This work is part of a project titled “Force/position control system to enable compliant manipulation from a floating I-AUV”, which received funding from the European Union's Horizon 2020 research and innovation programme, under the Marie Sklodowska-Curie grant agreement no. 750063.
Key Words: autonomous underwater vehicles  cooperative systems  end effectors  force control  manipulator dynamics  manipulator kinematics  manipulators  mobile robots  position control  task-priority kinematic control algorithm  custom force control strategy  impedance control  TP algorithm  inequality tasks  singular configurations  force control part  impedance concept  exerted force  stable contact  control architecture  adaptive admittance control  task-priority framework  contact force control  underwater vehicle-manipulator system  end-effector configuration  floating-base manipulation  Force control  Task analysis  Force  Impedance  Robots  Heuristic algorithms  Inspection 
Abstract: This paper presents a control architecture for an underwater vehicle-manipulator system (UVMS) to enable simultaneous tracking of end-effector configuration and contact force during floating-base manipulation. The main feature of the architecture is its combination of a task-priority (TP) kinematic control algorithm with a custom force control strategy, based on impedance (admittance) control. The TP algorithm used in the work includes recent treatment of equality and inequality tasks as well as original concepts to handle operation in singular configurations of the system. In the force control part the impedance concept is extended to allow for direct control over the value of exerted force and torque. Additional feed-forward signal is used to ensure stable contact. The performance of the control architecture is demonstrated by experiments in a test tank, with GIRONA500 I-AUV performing pipe inspection.


Title: Flatness-Based Model Predictive Control for Quadrotor Trajectory Tracking
Key Words: control system synthesis  convex programming  feedback  feedforward  helicopters  nonlinear control systems  nonlinear programming  position control  predictive control  quadratic programming  stability  trajectory control  quadrotor trajectory tracking  trajectory tracking performance  constraint satisfaction  differentially flat nonlinear systems  FMPC couples feedback model predictive control  linear model predictive control  couple model predictive control  nonlinear model  control approaches  flatness-based model predictive control approach  Feedforward systems  Predictive control  Feedback linearization  Robustness  Computational modeling  Predictive models  Trajectory 
Abstract: The use of model predictive control for quadro-tor applications requires balancing trajectory tracking performance and constraint satisfaction with fast computation. This paper proposes a Flatness-based Model Predictive Control (FMPC) approach that can be applied to quadrotors, and more generally, differentially flat nonlinear systems. Our proposed FMPC couples feedback model predictive control with feedforward linearization. The proposed approach has the computational advantage that, similar to linear model predictive control, it only requires solving a convex quadratic program instead of a nonlinear program. However, unlike linear model predictive control, we still account for the nonlinearity in the model through the use of an inverse term. In simulation, we demonstrate improved robustness over approaches that couple model predictive control with feedback linearization. In experiments using quadrotor vehicles, we also demonstrate improved trajectory tracking compared to classical linear and nonlinear model predictive control approaches.


Title: Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations
Key Words: actuators  autonomous aerial vehicles  feedback  industrial manipulators  inspection  manipulator dynamics  manipulator kinematics  mobile robots  motion control  pendulums  position control  torque control  inspection operations  multirotor blades  environmental obstacles  inspection tasks  long reach aerial manipulator  hexarotor platform  compliant joint arm  one-meter-length link  passive pendulum configuration  force/torque estimation-control  joint deflection  visual inspection  wearable exoskeleton interface  aerial manipulator kinematics  aerial manipulator dynamics  Manipulator dynamics  Inspection  Robot sensing systems  Visualization  Exoskeletons  Cameras 
Abstract: The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.


Title: Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles
Key Words: autonomous aerial vehicles  collision avoidance  feedback  mobile robots  multi-robot systems  predictive control  state feedback  trajectory control  prediction horizon  decentralized collision avoidance system  fast nonlinear feedback  virtual UAV  translational dynamics  nonlinear state feedback  linear model predictive controller  optimal trajectory tracking  unmanned aerial vehicles  model predictive trajectory tracking  priority-based collision resolution strategy  tracking mechanism  in-advance collision-free planning  linear MPC  Trajectory  Collision avoidance  Unmanned aerial vehicles  Robot kinematics  Planning  Robot sensing systems 
Abstract: We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.


Title: Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  pressure control  pressure sensors  state estimation  wind tunnels  pressure sensors  NASA Langley Research Center  distributed algorithm  wind tunnel  commercial air transportation  self-aware autonomous aerial vehicles  lattice-based subcomponents  14-foot wingspan  skin panels  flexible aerostructure  aerodynamic state estimation  modular distributed pressure sensing skin  autonomous systems  adaptable self-state estimation  robust self-state estimation  autonomous aerial transportation  pressure distribution  Robot sensing systems  Pressure sensors  Skin  Aerodynamics  NASA 
Abstract: Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.


Title: Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow
Key Words: distance measurement  Gaussian processes  image reconstruction  learning (artificial intelligence)  mobile robots  motion estimation  neural nets  pose estimation  robot vision  SLAM (robots)  stereo image processing  learning monocular visual odometry  monocular SLAM  simultaneous localization  neural network  dual-stream L-VO network  6DOF relative pose  bivariate Gaussian modeling  KITTI odometry  visual SLAM system  dense 2D flow  fully deep learning approach  dense 3D flow  dense 3D mapping  Three-dimensional displays  Simultaneous localization and mapping  Visual odometry  Two dimensional displays  Deep learning  Cameras  Training 
Abstract: This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 % for average translational error and 0.0143°/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.


Title: Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels
Key Words: automobiles  collision avoidance  control system synthesis  feedback  mobile robots  motion control  robust control  input constraints  control input signals  admissible funnels  planning process  constrained motion  car-like robots  VFO control strategy  parallelized planning  car-like kinematics  mobile robotics  intelligent vehicles  feedback control algorithms  motion execution  VFO control law  state constraints  motion planning algorithms  robot actuation  open loop control signals  parallelized deterministic sampling-based algorithm  vector field orientation  steering dynamics  modeling uncertainties  Robots  Planning  Kinematics  Electron tubes  Vehicle dynamics  Uncertainty  Feedback control 
Abstract: Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.


Title: ASPiC: An Acting System Based on Skill Petri Net Composition
Key Words: path planning  Petri nets  robots  ASPiC  acting system  skill Petri net composition  high-level action  executable commands  autonomous robots  formal model  robot skills  control-flow Petri net model  autonomous surface vehicle  area protection mission  Petri nets  Robots  Analytical models  Adaptation models  Tools  Planning  Inductors 
Abstract: Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.


Title: Coverage Path Planning with Adaptive Viewpoint Sampling to Construct 3D Models of Complex Structures for the Purpose of Inspection
Key Words: autonomous aerial vehicles  image sampling  mobile robots  path planning  robot vision  search problems  adaptive search space coverage path planner  unmanned aerial vehicle  coverage path planning  adaptive sampling  onboard sensors  reference model  accurate 3D models  complex structure  adaptive viewpoint sampling  Sensors  Adaptation models  Path planning  Solid modeling  Entropy  Clustering algorithms  Octrees 
Abstract: In this paper, we introduce a coverage path planning algorithm with adaptive viewpoint sampling to construct accurate 3D models of complex large structures using Unmanned Aerial Vehicle (UAV). The developed algorithm, Adaptive Search Space Coverage Path Planner (ASSCPP), utilizes an existing 3D reference model of the complex structure and the onboard sensors' noise models to generate paths that are evaluated based on the traveling distance and the quality of the model. The algorithm generates a set of viewpoints by performing adaptive sampling that directs the search towards areas with low accuracy and low coverage. The algorithm predicts the coverage percentage obtained by following the generated coverage path using the reference model. A set of experiments were conducted in real and simulated environments with structures of different complexities to test the validity of the proposed algorithm.


Title: Learning-based Path Tracking Control of a Flapping-wing Micro Air Vehicle
Key Words: aerodynamics  aerospace simulation  autonomous aerial vehicles  learning (artificial intelligence)  mobile robots  neurocontrollers  predictive control  vehicle dynamics  autonomous flight  neural network  MPC  Reynolds number  model predictive control  model-based control strategy  FWMAV  flapping-wing microair vehicle  path tracking control  Batteries  Training  Neural networks  Dynamics  Data models  Trajectory  Vehicle dynamics 
Abstract: Flapping-wing micro air vehicles (FWMAVs) become promising research platforms due to their advantages such as various maneuverability, and concealment. However, unsteady flow at low Reynolds number around the wings makes their dynamics time-varying and highly non-linear. It makes autonomous flight of FWMAV as a big challenge. In this paper, we suggest a model-based control strategy for FWMAV using learning architecture. For this task, we construct a ground station for logging flight data and control inputs, and train dynamics with a neural network. Then, we apply model predictive control (MPC) to the trained model. We validate our method by hardware experiments.


Title: A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
Key Words: Bayes methods  image fusion  image sensors  Kalman filters  mobile robots  nonlinear filters  object detection  probability  remotely operated vehicles  robot vision  mobile robot  multistage Bayesian approaches  multistage localization approach  global coordinate frame  multistage target observation approach  target engagement  multiple sensors  Bayesian framework  simultaneous robot localization  sensors on-board  target detection  associated detection probability  extended Kalman filter  unmanned ground vehicle  Robot kinematics  Robot sensing systems  Bayes methods  Mobile robots  Uncertainty 
Abstract: This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.


Title: Motion Planning for an Underwater Mobile Manipulator by Exploiting Loose Coupling
Key Words: autonomous underwater vehicles  manipulators  motion control  path planning  trajectory control  intervention autonomous underwater vehicle  MR-MHA *  multirepresentation multiheuristic A*  realistic simulated underwater intervention environment  intervention mission  generated trajectories  high-dimensional underwater manipulator  search-based planner  motion coordination  complex manipulation tasks  floating-based intervention  task-priority redundancy control framework  GIRONA 500  SAUVIM  autonomous manipulation skills  I-AUV  underwater mobile manipulator  motion planning  Task analysis  Planning  Manipulators  Search problems  Trajectory  Kinematics 
Abstract: Intervention Autonomous Underwater Vehicle or I-AUV has recently started to grab researchers attention in the last 20 years. Only three I-AUVs have demonstrated autonomous manipulation skills: ALIVE, SAUVIM and GIRONA 500. While prior systems rely on variations of the task-priority redundancy control framework, our recent research showed preliminary results using motion planning for floating-based intervention in the presence of obstacles. With the increasing need for autonomously performing more complex manipulation tasks, two main challenges need to be addressed: the high-dimensionality of the system, and the motion coordination between the mobile base and the working arm. The latter challenge is of high importance if accurate execution is required, especially considering the floating nature of the AUV and the control challenges that come with it. Our approach relies on exploiting the loose coupling between the AUV and the arm. In particular we present an approach based on MR-MHA * (Multi-Representation, Multi-Heuristic A*), and we show how it can generate efficient trajectories by exploiting decoupling. We show for the first time the use of a search-based planner on a high-dimensional underwater manipulator. In addition, we support our claims with experimental analysis of the generated trajectories with respect to various metrics in different environments. Furthermore, we demonstrate the ability of our approach to conduct a full intervention mission in a realistic simulated underwater intervention environment.


Title: Long-Duration Autonomy for Small Rotorcraft UAS Including Recharging
Key Words: autonomous aerial vehicles  helicopters  mobile robots  surveillance  autonomous small rotorcraft  autonomous operation  UAS  recharging station  vision-based precision landing  human operators  mission execution  emergency response  unmanned aerial vehicle surveillance  Global Positioning System  Batteries  Magnetometers  Sensors  Monitoring  Three-dimensional displays  State estimation 
Abstract: Many unmanned aerial vehicle surveillance and monitoring applications require observations at precise locations over long periods of time, ideally days or weeks at a time (e.g. ecosystem monitoring), which has been impractical due to limited endurance and the requirement of humans in the loop for operation. To overcome these limitations, we propose a fully autonomous small rotorcraft UAS that is capable of performing repeated sorties for long-term observation missions without any human intervention. We address two key technologies that are critical for such a system: full platform autonomy including emergency response to enable mission execution independently from human operators, and the ability of vision-based precision landing on a recharging station for automated energy replenishment. Experimental results of up to 11 hours of fully autonomous operation in indoor and outdoor environments illustrate the capability of our system.


Title: Fast Trajectory Planning for Automated Vehicles Using Gradient-Based Nonlinear Model Predictive Control
Key Words: gradient methods  mobile robots  nonlinear control systems  optimisation  path planning  predictive control  road vehicles  automated vehicles  motion trajectory planning  dynamically changing environment  nonlinear system dynamics  automated driving  nonlinear system model  optimization algorithms  gradient-based nonlinear model predictive control  standard PC  Mathematical model  Planning  Vehicle dynamics  Trajectory  Optimization  Task analysis  Heuristic algorithms 
Abstract: Motion trajectory planning is one crucial aspect for automated vehicles, as it governs the own future behavior in a dynamically changing environment. A good utilization of a vehicle's characteristics requires the consideration of the nonlinear system dynamics within the optimization problem to be solved. In particular, real-time feasibility is essential for automated driving, in order to account for the fast changing surrounding, e.g. for moving objects. The key contributions of this paper are the presentation of a fast optimization algorithm for trajectory planning including the nonlinear system model. Further, a new concurrent operation scheme for two optimization algorithms is derived and investigated. The proposed algorithm operates in the submillisecond range on a standard PC. As an exemplary scenario, the task of driving along a challenging reference course is demonstrated.


Title: Multi-Layer Coverage Path Planner for Autonomous Structural Inspection of High-Rise Structures
Key Words: autonomous aerial vehicles  inspection  path planning  structural engineering  travelling salesman problems  autonomous structural inspection  high-rise structures  buildings  towers  unmanned aerial vehicle  multi-layer coverage path planner  3D coverage path planning  traveling salesman problem  Inspection  Three-dimensional displays  Path planning  Planning  Unmanned aerial vehicles  Solid modeling  Spirals 
Abstract: In this paper, a novel 3D coverage path planning method, which is efficient and practical for inspection of high-rise structures such as buildings or towers, using an unmanned aerial vehicle (UAV) is presented. Our approach basically focuses on developing a model-based path planner for structural inspection with a prior map, which is opposite to a non-model based exploration. The proposed method uses a volumetric map which is made before the path planning. With the map, the whole structure is divided into several layers for efficient path planning. Firstly, in each layer, a set of the normal vectors of the center point of every voxel is calculated, and then the opposing vectors become viewpoints. Due to too many viewpoints and an overlapped inspection surface, we down-sample them with a voxel grid filter. Then, the shortest tour connecting the reduced viewpoints must be computed with the Traveling Salesman Problem (TSP) solver. Lastly, all the paths in each layer are combined to form the complete path. The results are verified using simulations with a rotary wing UAV and compared with other state-of-the-art algorithm. It is proven that our method performs much better for structural inspection with respect to computation time as well as the coverage completeness.


Title: Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty
Key Words: mobile robots  path planning  flow-aware tralatory planning  motion pattern uncertainty  flow-aware trajectory  dynamic environments  flow model uncertainty  flow-aware planning  statistical model  map flow patterns  biasing functions  RRT* planning algorithm  CLiFF-map model  flow-compliant trajectories  flow motion patterns  Trajectory  Robots  Planning  Cost function  Uncertainty  Vehicle dynamics  Aerospace electronics 
Abstract: In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.


Title: Towards an Adaptive-Compliance Aerial Manipulator for Contact- Based Interaction
Key Words: actuators  autonomous aerial vehicles  inspection  manipulators  adaptive-compliance aerial manipulator  contact-based interaction  unmanned aerial vehicles  UAV  initial flight tests  novel adaptively compliant actuator  pick placement  remote sensors  structural testing  contact-based inspection  key results  active compliant manipulator  manipulator controller gains  physical pulses  vibration sensors  initial results  compliant aerial actuator  Manipulator dynamics  End effectors  Sensors  Force  Task analysis  Inspection 
Abstract: As roles for unmanned aerial vehicles (UAVs)continue to diversify, the ability to sense and interact closely with the environment becomes increasingly important. Within this paper we report on the initial flight tests of a novel adaptively compliant actuator which will allow a UAV to carry out such tasks as the “pick and placement” of remote sensors, structural testing and contact-based inspection. Three key results are discussed and presented; the ability to physically apply forces with the UAV through the use of an active compliant manipulator; the ability to tailor these forces through tuning of the manipulator controller gains; and the ability to apply a rapid series of physical pulses in order to excite remotely placed sensors, e.g. vibration sensors. A series of over sixty flight tests have been used to generate initial results which clearly demonstrate the potential of this new type of compliant aerial actuator.


Title: A Comparative Study on Sigma-Point Kalman Filters for Trajectory Estimation of Hybrid Aerial-Aquatic Vehicles
Key Words: autonomous aerial vehicles  autonomous underwater vehicles  Kalman filters  Monte Carlo methods  nonlinear filters  robot dynamics  state estimation  detailed dynamic model simulation  nonlinear algorithm  derivative-free nonlinear Kalman Filters  Cubature Kalman Filter  CKF  nonlinear probabilistic estimators  average execution time  Monte Carlo simulations  in-production HUAUV prototype  state augmentation  sensor data filtering  trajectory estimation  high dimensional state spaces  comparative study  sigma-point Kalman  aerial-aquatic vehicles  nonlinear state estimation methods  transformed unscented Kalman filter  root-mean square error  hybrid unmanned aerial underwater vehicles  HUAUV  Kalman filters  Trajectory tracking  State estimation  Vehicle dynamics  Robot sensing systems 
Abstract: In this paper, a study on nonlinear state estimation methods for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) is presented. Based on a detailed dynamic model simulation, we analyse and elect the best nonlinear algorithm among those presented in the state-of-the-art literature addressing local derivative-free nonlinear Kalman Filters (KFs): the Unscented Kalman Filter (UKF), the Cubature Kalman Filter (CKF) and the Transformed Unscented Kalman Filter (TUKF). Here, these three nonlinear probabilistic estimators were compared in terms of the Root Mean Square Error (RMSE) and the average execution time over Monte Carlo simulations. We simulated real-world conditions for our in-production HUAUV prototype using Inertial Measurement Unit (IMU) data and state augmentation for sensor data filtering and trajectory estimation. We have concluded that the CKF proved to be the most interesting KF to low-cost on-board applications for high dimensional state spaces.


Title: Constrained Motion Cueing for Driving Simulators Using a Real-Time Nonlinear MPC Scheme
Key Words: nonlinear control systems  optimisation  predictive control  road traffic control  real-time nonlinear MPC scheme  motion cueing algorithm  MCA  nonlinear model predictive control  realistic motion feeling  realtime gradient algorithm  augmented Lagrangian method  constrained motion cueing  driving simulators  Acceleration  Fasteners  Real-time systems  Trajectory  Vehicles  Software algorithms  Minimization 
Abstract: This contribution presents a motion cueing algorithm (MCA) for driving simulators using nonlinear model predictive control (MPC). The goal of the MCA is to generate a realistic motion feeling while keeping the simulator within its workspace limits. The approach relies on a realtime gradient algorithm in combination with the augmented Lagrangian method in order to directly incorporate the system constraints into the optimization. Simulation results for a reference trajectory with typical driving situations demonstrate the performance as well as the computational efficiency of the approach.


Title: Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture
Key Words: agricultural safety  agriculture  environmental factors  hazardous materials  mobile robots  off-road vehicles  soil  spraying  ultra wideband technology  UWB  Ultra Wide Band technology  soil compaction  safety aspects  chemical products  human activities  environmental impact  autonomous robots  hazardous products  agricultural application  off-road mobile robots  production levels  human health  human operators  smart spraying  radio beacons  Mobile robots  Robot kinematics  Robot sensing systems  Spraying  Agriculture 
Abstract: Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.


Title: Catenary Tether Shape Analysis for a UAV - USV Team
Key Words: aerodynamics  autonomous aerial vehicles  hydrodynamics  marine vehicles  polynomials  position control  dynamic heave events  tether length  convenient curves  nondimensional relative position parameter  catenary analysis  catenary tether shape analysis  UAV - USV team  quasistatic catenary curve  semislack tether  unmanned surface vehicle  empirical analysis  system robustness  vertical heave  optimum condition  cable length  stationary unmanned air vehicle  heave robustness analysis  lookup table  Unmanned aerial vehicles  Winches  Robustness  Mathematical model  Shape  Vehicle dynamics  Sea surface 
Abstract: The quasi-static catenary curve of a semi-slack tether between an essentially stationary unmanned air vehicle (UAV) and a small unmanned surface vehicle (USV) is investigated and characterized. An empirical analysis, performed over a discretized space of vertical and horizontal separations of the two vehicles, determines an optimum cable length & tension for maximizing system robustness during the vertical heave of the USV due to high seas. Operating at this optimum condition allows for equal displacements of the USV in the up and down directions, minimizing the possibility of both fouling (with the tether touching the water) and excessive downforce on the UAV (with the tether pulled taut) during dynamic heave events. Scaling the horizontal offset, tether length, and tension by the flying height collapses all empirical results into convenient curves depending only on a nondimensional relative position parameter (Δx/Δy), accurately fit by low order polynomials. This eliminates the need for a lookup table, and decreases computation time during implementation. The heave robustness analysis results in a recommended operating relative position of Δx/Δy ≈ .46. Experimental results are presented and confirm the catenary analysis for the proposed tether.


Title: Inertial Velocity and Attitude Estimation for Quadrotors
Key Words: aircraft control  attitude control  autonomous aerial vehicles  drag  helicopters  inertial navigation  Kalman filters  linear drag parameters  drag forces  linear drag model  IMU  inertial measurement unit  quadrotor UAV  body-fixed z axis  attitude estimation  inertial velocity  Aerodynamics  Sensors  Accelerometers  Estimation  Magnetometers  Kalman filters  Velocity measurement 
Abstract: This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.


Title: Quadtree-Accelerated Real-Time Monocular Dense Mapping
Key Words: autonomous aerial vehicles  image fusion  image motion analysis  image reconstruction  image resolution  mobile robots  path planning  quadtrees  robot vision  stereo image processing  real-time monocular dense mapping  truncated signed distance function  dense 3D maps  resolution depth maps  pixels  dynamic belief propagation  pixel selection  depth map  intensity image  quadtree structure  single localized moving camera  high-quality dense depth maps  robotic navigation  Cameras  Three-dimensional displays  Belief propagation  Estimation  Optimization  Real-time systems  Image resolution 
Abstract: In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.


Title: The Deformable Quad-Rotor Enabled and Wasp-Pedal-Carrying Inspired Aerial Gripper
Key Words: aerodynamics  aircraft control  autonomous aerial vehicles  controllability  deformation  grippers  helicopters  mobile robots  stability  aerial gripper design  REMS  quadrotor body  quadrotor deformation  rigid elements based morphing structure  aerodynamic flow  wasp grasping behavior  stability  unmanned aerial vehicles  Grippers  Grasping  Strain  Payloads  Rotors  Manipulators  Gravity 
Abstract: The paper presents the development of a novel deformable quad-rotor enabled aerial gripper. The mechanism of our deformable quad-rotor is based on simultaneous expansion or contraction of the quad-rotor body, which is generated by controlling a rigid elements based morphing structure (REMS). Such deformation results in a highly deformable quad-rotor that can not only perform morphological adaptation in response to environmental changes and obstacles, but also improve the flight performance by contracting to facilitate the agility/maneuverability or by expanding to enhance the stability. Meanwhile, inspired by the wasp grasping behavior, such controllable expansion and contraction from the REMS ingeniously enable a new function of aerial gripper. In this paper, we start to detail the mechanism and design of the REMS based deformable quad-rotor, then present the quad-rotor deformation enabled aerial gripper design, its dynamics modeling, the grasping function and analysis. The simulation was conducted in order to graphically show the elicited aerodynamic flow situation during expansion or contraction of the quad-rotor with and without carrying payload. Experiments were further implemented to validate the grasping function of the gripper and the flight performance of the quad-rotor. Finally, two case studies on the new aerial gripper were performed. All results demonstrate the excellent performance of the deformable quad-rotor enabled aerial gripper, that is, it has the advantages of both flight maneuverability and grasping capability during performing tasks.


Title: Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions
Key Words: adaptive control  helicopters  mobile robots  optimisation  predictive control  robust control  trajectory control  uncertain systems  wind disturbances  cost function  optimal reference input  quadrotor  MPC  trajectory tracking error  predictive approach  adaptive control strategies  unmodeled dynamics  dynamic environments  automated systems  adaptive model predictive control  nonadaptive approach  Adaptation models  Predictive models  Trajectory tracking  Uncertainty  Adaptive control  Vehicle dynamics 
Abstract: Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L1 adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.


Title: Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator
Key Words: aerospace control  autonomous aerial vehicles  convolutional neural nets  grippers  image colour analysis  learning (artificial intelligence)  manipulators  path planning  rescue robots  robot vision  SLAM (robots)  autonomous wristband placement  robotic system  automatic wristband placement  remote sensor readings  continuous health monitoring  unmanned aerial manipulator  automatic wrist detection  RGB-D camera  convolutional neural network  Faster R-CNN  passive detachable gripper  VGG-16 neural network  target localization  trajectory planning  machine learning  parallel delta manipulator  search-and-rescue aerial manipulator  search and rescue operations  unmanned aerial vehicles  Manipulators  Wrist  Cameras  Grippers  Robot kinematics  Robot sensing systems 
Abstract: A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.


Title: Nonlinear Adaptive Control of Quadrotor Multi-Flipping Maneuvers in the Presence of Time-Varying Torque Latency
Key Words: adaptive control  aerodynamics  aircraft control  closed loop systems  control nonlinearities  control system synthesis  delays  helicopters  least squares approximations  linear systems  nonlinear control systems  position control  robust control  time-varying systems  torque control  recursive least-squares algorithm  high-performance linear controller  adaptive controller  nonlinear adaptive control scheme  linear time-varying model  linear time-invariant model  backstepping-based control scheme  LTV latency model  time-varying angular speed  torque delay  backstepping-based nonlinear controller  controller synthesis methods  high-speed multiflips  aerobatic maneuvers  closed-loop control schemes  stability robustness  time-varying torque  quadrotor multiflipping maneuvers  Torque  Aerodynamics  Linear systems  Adaptation models  Vehicle dynamics  Angular velocity  Propellers 
Abstract: The dynamics of quadrotors are affected by time-varying torque latency, which can greatly alter the stability robustness and performance of the closed-loop control schemes employed for flight; this issue is especially relevant during the execution of aerobatic maneuvers such as high-speed multi-flips. To address this problem, we propose two controller synthesis methods associated with two different modeling approaches. In the first approach, we describe torque latency with a linear time-invariant (LTI)model, identified through ground experiments, which is then used to design a backstepping-based nonlinear controller. In the second approach, we employ an improved linear time-varying (LTV)model with a priori unknown parameters, which is used to synthesize and implement a novel nonlinear adaptive control scheme updated in real time using the recursive least-squares (RLS)algorithm. Empirical observations suggest that the torque delay affecting the system depends on the time-varying angular speed of the flyer and its derivative. This phenomenon is explained by the fact that the aerodynamic forces produced by, and acting on, the rotating propellers vary with the local velocity of the incident flows. Hence, in the proposed adaptive structure, we define the parameters of the LTV latency model as linear functions of the angular speed reference and its derivative. Experimental results compellingly demonstrate the efficacy of the methods introduced in this paper; compared to the highperformance linear controller in [1]-[3], the backstepping-based control scheme and adaptive controller decrease the average root mean square (RMS)value of the control error by 17.82 % and 38.42 %, respectively.


Title: LIMO: Lidar-Monocular Visual Odometry
Key Words: cameras  distance measurement  feature extraction  mobile robots  motion estimation  object tracking  optical radar  pose estimation  robot vision  stereo image processing  visual localization  depth extraction algorithm  camera feature tracks  outlier rejection  sensor combination  LIMO  lidar-monocular visual odometry  higher level functionality  autonomous driving  precise motion estimate  powerful algorithms  great majority  binocular imagery  bundle adjustment  LIDAR measurements  Feature extraction  Laser radar  Cameras  Estimation  Three-dimensional displays  Calibration  Visual odometry 
Abstract: Higher level functionality in autonomous driving depends strongly on a precise motion estimate of the vehicle. Powerful algorithms have been developed. However, their great majority focuses on either binocular imagery or pure LIDAR measurements. The promising combination of camera and LIDAR for visual localization has mostly been unattended. In this work we fill this gap, by proposing a depth extraction algorithm from LIDAR measurements for camera feature tracks and estimating motion by robustified keyframe based Bundle Adjustment. Semantic labeling is used for outlier rejection and weighting of vegetation landmarks. The capability of this sensor combination is demonstrated on the competitive KITTI dataset, achieving a placement among the top 15. The code is released to the community.


Title: A Motion Planning Approach for Marsupial Robotic Systems
Key Words: graph theory  mobile robots  multi-robot systems  path planning  free-space regions  topological graph planning  high-level motion plan  low-level path planner  motion planning approach  marsupial robotic systems  automatic coordination  heterogeneous multirobot teams  marsupial-based subset  carrier robots  passenger robots  high-level watershed segmentation  Robot kinematics  Planning  Trajectory  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles 
Abstract: This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.


Title: Passive Nonlinear Impedance Control for Port-Hamiltonian Systems
Key Words: closed loop systems  control system synthesis  feedback  nonlinear control systems  numerical analysis  controlled system  passive nonlinear impedance control  port-Hamiltonian system  nonholonomic system  fully actuated mechanical systems  closed loop system  numerical simulation  two-wheeled vehicle  feedback controller  generalized canonical transformation  Impedance  Control systems  Mechanical systems  Symmetric matrices  Man-machine systems  Mathematical model  Robots 
Abstract: This paper describes a procedure to design a passive nonlinear impedance control for port-Hamiltonian systems. By expressing the system with the port-Hamiltonian system, the proposed method can be applied to the nonholonomic system as well as fully actuated mechanical systems. The feedback controller for nonlinear impedance control is acquired by utilizing the results of generalized canonical transformation for port-Hamiltonian system. In addition, we investigate the passivity of the closed loop system and discuss the characteristics of the controlled system. A numerical simulation of two-wheeled vehicle shows the effectiveness of the proposed control method.


Title: FOCS: Planning by Fusion of Optimal Control & Search and its Application to Navigation
Key Words: graph theory  optimal control  path planning  car-like vehicle  Hamilton-Jacobi-Bellman equation  FOCS  minimum-time path  returned path  sub-optimality  path planning  Search-based Planning  Optimal Control & Search  Planning  Optimal control  Robots  Optimized production technology  Heuristic algorithms  Dynamic programming  Search problems 
Abstract: Both Optimal Control and Search-based Planning are used extensively for path planning and have their own set of advantages and disadvantages. In this paper, we propose an algorithm FOCS (Fusion of Optimal Control and Search) that combines these two classes of approaches together. FOCS finds a path exploiting the advantages of both approaches while providing a bound on the sub-optimality of its solution. The returned path is a concatenation of the path found in the implicit graph constructed by search and the path generated by following the negative gradient of the value function obtained as a solution of the Hamilton-Jacobi-Bellman equation. We analyze the algorithm and illustrate its effectiveness in finding a minimum-time path for a car-like vehicle in different environments.


Title: Social Cohesion in Autonomous Driving
Key Words: automobiles  control engineering computing  mobile robots  road safety  road traffic  statistical analysis  traffic information systems  social cohesion  autonomous driving  autonomous car  perception issues  incorrect dynamics models  obscure rules  human traffic systems  exact failure mode  socially cohesive cars  nearby human drivers  socially acceptable behavior  Automobiles  Roads  Autonomous automobiles  Trajectory  Autonomous vehicles 
Abstract: Autonomous cars can perform poorly for many reasons. They may have perception issues, incorrect dynamics models, be unaware of obscure rules of human traffic systems, or follow certain rules too conservatively. Regardless of the exact failure mode of the car, often human drivers around the car are behaving correctly. For example, even if the car does not know that it should pull over when an ambulance races by, other humans on the road will know and will pull over. We propose to make socially cohesive cars that leverage the behavior of nearby human drivers to act in ways that are safer and more socially acceptable. The simple intuition behind our algorithm is that if all the humans are consistently behaving in a particular way, then the autonomous car probably should too. We analyze the performance of our algorithm in a variety of scenarios and conduct a user study to assess people's attitudes towards socially cohesive cars. We find that people are surprisingly tolerant of mistakes that cohesive cars might make in order to get the benefits of driving in a car with a safer, or even just more socially acceptable behavior.


Title: Blade-Type Crawler Capable of Running on the Surface of Water as Bio-Inspired by a Basilisk Lizard
Key Words: blades  legged locomotion  motion control  robot dynamics  hard-to-reach-locations  water surface  basilisk lizard  blade-type crawler robot  terrain adaptability  Crawlers  Blades  Wheels  Rough surfaces  Surface roughness  Legged locomotion 
Abstract: For unmanned rescue, observation, and/or research, vehicles with high terrain adaptability, high speed, and high reliability are needed to reach hard-to-reach-locations. In order to extend the areas that can be explored, we propose a method and a robot capable of running on the surface of water without having to bypass the puddles and streams that exist on uneven terrain. The method that enables the robot to run on the water surface is bio-inspired by the basilisk lizard that can walk on the surface of water. We developed a blade-type crawler robot with a simple and reliable mechanism, capable of traversing uneven terrain at high speed. The robot with the method was tested on a real water surface and the result confirmed the ability of the robot to run on the water surface.


Title: Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks
Key Words: autonomous aerial vehicles  autonomous underwater vehicles  control engineering computing  public domain software  software packages  specification languages  unmanned aerial vehicles  task orchestration language  autonomous vehicle networks  extensible programming language  Dolphin program  orchestrated execution  multiple vehicles  one-vehicle tasks  event-based task flow  Dolphin language  autonomous vehicles  unmanned underwater vehicles  Groovy DSL  software packages  robotic toolkits  open-source toolchain  Task analysis  Dolphins  DSL  Autonomous vehicles  Engines  Runtime  Java 
Abstract: We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).


Title: π-SoC: Heterogeneous SoC Architecture for Visual Inertial SLAM Applications
Key Words: energy consumption  mobile computing  mobile robots  optimisation  SLAM (robots)  system-on-chip  visual inertial SLAM applications  autonomous vehicles  robotics  core technologies  battery-powered mobile devices  energy budget  energy consumption  energy efficiency  visual inertial SLAM workloads  60 FPS performance  heterogeneous SoC architecture  simultaneous localization and mapping  hardware accelerator  IO interface  memory hierarchy  Simultaneous localization and mapping  Feature extraction  Three-dimensional displays  Instruction sets  Power demand  Graphics processing units  Computer architecture 
Abstract: In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles and robotics. One of the core technologies enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. Hence, performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. Previous attempts to optimize SLAM performance and energy efficiency usually involve optimizing one function and fail to approach the problem systematically. In this paper, we first study the characteristics of visual inertial SLAM workloads on existing heterogeneous SoCs. Then based on the initial findings, we propose π-SoC, a heterogeneous SoC design that systematically optimize the IO interface, the memory hierarchy, as well as the the hardware accelerator. We implemented this system on a Xilinx Zynq UltraScale MPSoC and was able to deliver over 60 FPS performance with average power less than 5 W.


Title: vTSL - A Formally Verifiable DSL for Specifying Robot Tasks
Key Words: constraint handling  control engineering computing  formal specification  formal verification  learning (artificial intelligence)  mobile robots  robot programming  specification languages  vTSL  formally verifiable DSL  robot tasks  preprogramming  automated planning  symbolic learning  robotic application  user-defined tasks  integrity constraints  robotic platform  verifiable task specification language  task-specific constraints  robotic systems  Task analysis  DSL  Semantics  Planning  Loading  Robot sensing systems 
Abstract: Preprogramming of tasks still plays an important role in complex robotic systems despite the advances in automated planning and symbolic learning. Often, it is desired that end-users implement further tasks to adapt the robotic application to their needs. These user-defined tasks have to meet safety and integrity constraints for protecting the robotic platform and its users. We introduce a verifiable task specification language (vTSL) that enables to automatically prove that a task specification satisfies a set of predefined or task-specific constraints. We illustrate our approach using an example of a self-driving vehicle for intra-logistics and report experiences with two commercial applications.


Title: Attitude Estimation from Polarimetric Cameras
Key Words: attitude control  autonomous aerial vehicles  cameras  image sensors  mobile robots  path planning  robot vision  robotic applications  attitude estimation  polarimetric camera  path planning applications  visual systems  perspective cameras  depth cameras  catadioptric cameras  systems capture information  sky regions  visual cue  vision applications  sky information  polarimetric sensors  visual sensors  navigation applications  unmanned aerial vehicle  Cameras  Scattering  Robot vision systems  Sun  Estimation  Atmospheric modeling 
Abstract: In the robotic field, navigation and path planning applications benefit from a wide range of visual systems (e.g, perspective cameras, depth cameras, catadioptric cameras, etc.). In outdoor conditions, these systems capture information in which sky regions cover a major segment of the images acquired. However, sky regions are discarded and are not considered as visual cue in vision applications. In this paper, we propose to estimate attitude of Unmanned Aerial Vehicle (UAV) from sky information using a polarimetric camera. Theoretically, we provide a framework estimating the attitude from the skylight polarized patterns. We showcase this formulation on both simulated and real-word data sets which proved the benefit of using polarimetric sensors along with other visual sensors in robotic applications.


Title: The Earth Ain't Flat: Monocular Reconstruction of Vehicles on Steep and Graded Roads from a Moving Camera
Key Words: cameras  image reconstruction  pose estimation  road vehicles  SLAM (robots)  stereo image processing  traffic engineering computing  local bundle-adjustment like procedure  3D pose  semantic cues  moving ego vehicle  shape estimation  plain roads  monocular localization demonstrations  autonomous driving systems  traffic participants  moving camera  monocular reconstruction  arbitrarily-shaped roads  monocular object localization  road plane configurations  local ground plane  local planar patches  monocular camera  Shape  Roads  Three-dimensional displays  Cameras  Image reconstruction  Automobiles  Surface reconstruction 
Abstract: Accurate localization of other traffic participants is a vital task in autonomous driving systems. State-of-the-art systems employ a combination of sensing modalities such as RGB cameras and LiDARs for localizing traffic participants, but monocular localization demonstrations have been confined to plain roads. We demonstrate - to the best of our knowledge - the first results for monocular object localization and shape estimation on surfaces that are non-coplanar with the moving ego vehicle mounted with a monocular camera. We approximate road surfaces by local planar patches and use semantic cues from vehicles in the scene to initialize a local bundle-adjustment like procedure that simultaneously estimates the 3D pose and shape of the vehicles, and the orientation of the local ground plane on which the vehicle stands. We also demonstrate that our approach transfers from synthetic to real data, without any hyperparameter-/fine-tuning. We evaluate the proposed approach on the KITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations. The proposed approach significantly improves the state-of-the-art for monocular object localization on arbitrarily-shaped roads.


Title: Lane Marking Quality Assessment for Autonomous Driving
Key Words: cameras  Global Positioning System  image processing  optical radar  road vehicles  traffic engineering computing  road curvature  background road surfaces  dual-modal algorithm  lane marking quality assessment  autonomous driving  future transportation systems  inspection vehicle  frontal-view camera  global positioning system receiver  light detection and ranging system  LIDAR  Roads  Measurement  Laser radar  Cameras  Shape  Global Positioning System  Three-dimensional displays 
Abstract: Measuring the quality of roads and ensuring they are ready for autonomous driving is important for future transportation systems. Here we focus on developing metrics and algorithms to assess lane marking (LM)qualities from an egocentric view of an inspection vehicle equipped with a global positioning system (GPS)receiver, a frontal-view camera, and a light detection and ranging (LIDAR)system. We propose three quality metrics for LMs: correctness, shape, and visibility. The correctness metric measures the divergence between the expected LMs based on prior map inputs and the actual sensor inputs. The shape metric evaluates smoothness in road curvature and width range. The visibility metric evaluates the contrast between LMs and background road surfaces. We propose a dual-modal algorithm to compute these metrics. We have implemented the algorithms and tested them under KITTI dataset. The results show that our metrics can successfully detect LM anomalies in all testing scenarios.


Title: P-CAP: Pre-Computed Alternative Paths to Enable Aggressive Aerial Maneuvers in Cluttered Environments
Key Words: autonomous aerial vehicles  collision avoidance  data structures  graph theory  mobile robots  navigation  probability  search problems  p-CAP  pre-computed alternative paths  cluttered environments  fast autonomous flight  autonomous navigation  complex environment  continuous heuristic search  k-connected grid  probabilistic scheme  onboard sensors  prior map information  data structure  flight experiments  unstructured environments  aggressive aerial maneuvers  graph  forests-like environments  obstacles avoidance  Navigation  Sensors  Switches  Collision avoidance  Forestry  Gold  Planning 
Abstract: We propose a novel method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous heuristic search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle progresses, modification of the graph with data from onboard sensors is expensive as is search on the graph, especially if the paths must be kino-dynamically feasible. We suggest that computation needed to find safe paths during fast flight can be greatly reduced if we precompute and carefully arrange a dense set of alternative paths before the flight. Any prior map information can be used to prune the alternative paths to come up with a data structure that enables very fast online computation to deal with obstacles that are not on the map but only detected by onboard sensors. To test this idea, we have conducted a large number of flight experiments in structured (large industrial facilities) and unstructured (forests-like) environments. We show that even in the most unstructured environments, this method enables flight at a speed up to 10m/s while avoiding obstacles detected from onboard sensors.


Title: Motion Planning for a Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  collision avoidance  feedback  mobile robots  robot dynamics  trees (mathematics)  cruise-to-hover transition  hover-to-cruise transition  motion planner  motion planning  aerobatic fixed-wing  fixed-wing unmanned aerial vehicle  static obstacles  goal region  rapidly-exploring random trees algorithm  Aircraft  Trajectory  Libraries  Aerodynamics  Atmospheric modeling  Heuristic algorithms  Planning 
Abstract: A motion planner is developed for guiding a small aerobatic fixed-wing unmanned aerial vehicle to a desired goal region in a highly constrained, three-dimensional, known environment with static obstacles. The planner is based on the Rapidly-Exploring Random Trees (RRT) algorithm, and pieces together feasible trajectories from a library of motion primitives. Among other more conventional motion primitives, the library includes three extreme maneuvers: a cruise-to-hover transition, a hover-to-cruise transition, and an aggressive turn-around. The algorithm is efficient; it can be run in real-time to rapidly generate a plan starting from the aircraft's configuration at run-time. The motion planner is closely coupled to a feedback controller. Simulations using an aircraft dynamics model demonstrate the effectiveness of the system to guide and control the aircraft to a desired goal region. Preliminary flight test results are also presented.


Title: First Experimental Results on Motion Planning for Transportation in Aerial Long-Reach Manipulators with Two Arms
Key Words: autonomous aerial vehicles  collision avoidance  manipulators  mobile robots  search problems  transportation  aerial robotic system  RRT* algorithms  motion planning problem  dual arm  aerial platform  passive revolute joint  long-reach manipulation  long-bar extension  aerial long-reach manipulators  cluttered environment  transportation  Manipulators  Planning  Trajectory  Transportation  Bars  Task analysis 
Abstract: This paper presents the motion planning of a novel aerial robotic system with a long-bar extension and two arms for long-reach manipulation in cluttered environments. The novel aerial long-reach manipulator includes a passive revolute joint between the aerial platform and the dual arm. This feature minimises the torque induced to the aerial system in case of unexpected collisions of the manipulator. The motion planning problem is addressed considering jointly the complete set of configuration variables for the aerial platform and the dual arm. Furthermore, the planner has been built over the fundamentals of RRT* algorithms in order to optimise the performance of the trajectories in terms of energy and time. The proposed planning method has been experimentally validated in a realistic industrial scenario, the transportation of a long bar through a cluttered environment consisting of several pipe structures.


Title: Sparse 3D Topological Graphs for Micro-Aerial Vehicle Planning
Key Words: autonomous aerial vehicles  computational geometry  graph theory  image colour analysis  mobile robots  path planning  topology  Euclidean signed distance field  3D generalized Voronoi diagram  RGB-D sensing  global planning  skeleton diagram  topological information  noisy sensor data  sparse map representations  compact map representations  MAV  microaerial vehicle planning  sparse 3D topological graphs  Planning  Three-dimensional displays  Two dimensional displays  Skeleton  Robot sensing systems  Topology 
Abstract: Micro-Aerial Vehicles (MAVs) have the advantage of moving freely in 3D space. However, creating compact and sparse map representations that can be efficiently used for planning for such robots is still an open problem. In this paper, we take maps built from noisy sensor data and construct a sparse graph containing topological information that can be used for 3D planning. We use a Euclidean Signed Distance Field, extract a 3D Generalized Voronoi Diagram (GVD), and obtain a thin skeleton diagram representing the topological structure of the environment. We then convert this skeleton diagram into a sparse graph, which we show is resistant to noise and changes in resolution. We demonstrate global planning over this graph, and the orders of magnitude speed-up it offers over other common planning methods. We validate our planning algorithm in real maps built onboard an MAV, using RGB-D sensing.


Title: Motion Planning for a UAV with a Straight or Kinked Tether
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  motion control  multi-robot systems  robot vision  confined environment  cluttered environment  tethered aerial vehicles  tethered agent  nonfree space  motion planning frameworks  motion planning strategies  motion planning algorithms  UAV  robotic locomotion  reachable configuration space  marsupial heterogeneous robotic teams  Fotokite Pro  Planning  Visualization  Casting  Cameras  Robot sensing systems  Unmanned aerial vehicles 
Abstract: This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.


Title: Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots
Key Words: aerospace robotics  integer programming  linear programming  multi-robot systems  path planning  tree searching  terrain  persistent monitoring  heterogeneous team  aerial robots  ground robots  MILP formulation  branch-and-cut framework  separation algorithm  Fuels  Monitoring  Unmanned aerial vehicles  Routing  Robot sensing systems  Kernel 
Abstract: There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.


Title: A Mobility Model Based on Improved Artificial Potential Fields for Swarms of UAVs
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  path planning  remotely operated vehicles  information sharing  path planning  obstacles avoidance  mobility model  swarms  UAV  involved UAVs collaborate  mobility strategies  autonomous UAVs  collaborative tasks  multiple platforms  artificial potential fields principle  APF principle  Path planning  Sensors  Adaptation models  Collaboration  Task analysis  Laser radar  Collision avoidance 
Abstract: A combination of several autonomous UAVs can be used to perform collaborative tasks. Such a combination is referred to as a swarm of drones. The use of multiple platforms can extend the system global capacities thanks to the resulting variety of embedded sensors and to information sharing. In this case, path planning and thus obstacles avoidance is still a major task. To deal with this issue, mobility models have to be implemented. Our contribution presented in this paper is a mobility model for swarms of UAVs based on the Artificial Potential Fields (APF) principle. In our model, the involved UAVs collaborate by sharing data about the obstacles that they detected. By doing so, a UAV which is not close enough to an obstacle to detect it thanks to its own sensors will still have the proper data to take this obstacle into account in its path planning. To validate our mobility strategies with realistic constraints we simulate the performances of existing sensors and transmitters, and consider real-world environment.


Title: UAV/UGV Search and Capture of Goal-Oriented Uncertain Targets*This research was supported in part by ISF grant #1337/15 and part by a grant from MOST, Israel and the JST Japan
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  optimisation  probability  remotely operated vehicles  UAV/UGV collaborative efforts  stochastic-temporal belief  attacker capture  defender real-time algorithmic framework  probability optimization  goal-oriented uncertain targets  UAV/UGV search  Games  Uncertainty  Search problems  Real-time systems  Task analysis  Mathematical model  Roads 
Abstract: This paper considers a new, complex problem of UAV/UGV collaborative efforts to search and capture attackers under uncertainty. The goal of the defenders (UAV/UGV team) is to stop all attackers as quickly as possible, before they arrive at their selected goal. The uncertainty considered is twofold: the defenders do not know the attackers' location and destination, and there is also uncertainty in the defenders' sensing. We suggest a real-time algorithmic framework for the defenders, combining entropy and stochastic-temporal belief, that aims at optimizing the probability of a quick and successful capture of all of the attackers. We have empirically evaluated the algorithmic framework, and have shown its efficiency and significant performance improvement compared to other solutions.


Title: Lightweight Collision Avoidance for Resource-Constrained Robots
Key Words: collision avoidance  control system synthesis  mobile robots  motion control  resource-constrained robot  controller design  lightweight collision avoidance strategy  embedded control  reference control input  dynamic environment  low level motion control  on-board sensors  vehicle  physical robots  low computational requirements  Collision avoidance  Robot sensing systems  Navigation  Vehicle dynamics 
Abstract: One of the safest and most reliable strategies for vehicle's collision avoidance is embedded control at low level to guarantee safe motion in all situations using on-board sensors. In this paper, we propose a novel lightweight collision avoidance strategy that can be implemented as a low level motion control to achieve safe motion while simultaneously tracking the robot's reference control input. This strategy is designed to be general so that it can be easily integrated with most control designs, with the primary target of resource-constrained robot swarms that act in real-time, dynamic environments. The main advantages of our approach are a very simple structure and low computational requirements. We verified the effectiveness of the proposed collision avoidance strategy through two simulated scenarios and with physical robots. We believe our design can be directly used in many areas, such as autonomous driving, intelligent transportation and planetary exploration.


Title: Drivers' Manoeuvre Prediction for Safe HRI
Key Words: control engineering computing  decision making  human-robot interaction  mobile robots  motion control  road safety  road traffic control  traffic engineering computing  safe HRI  autonomous vehicles  decision-making systems  vehicles robots  human-robot interaction  autonomous agent  human driver interacts  motion tracking data  manoeuvre classification  drivers manoeuvre prediction  human-vehicle interaction  Task analysis  Vehicles  Robots  Roads  Decision making  Predictive models  Training 
Abstract: Machines with high levels of autonomy such as robots and our growing need to interact with them creates challenges to ensure safe operation. The recent interest to create autonomous vehicles through the integration of control and decision-making systems makes such vehicles robots too. We therefore applied estimation and decision-making mechanisms currently investigated for human-robot interaction to human-vehicle interaction. In other words, we define the vehicle as an autonomous agent with which the human driver interacts, and focus on understanding the human intentions and decision-making processes. These are then integrated into the ro-bot`s/vehicle's own control and decision-making system not only to understand human behaviour while it occurs but to predict the next actions. To obtain knowledge about the human's intentions, this work relies heavily on the use of motion tracking data (i.e. skeletal tracking, body posture)gathered from drivers whilst driving. We use a data-driven approach to both classify current driving manoeuvres and predict future manoeuvres, by using a fixed prediction window and augmenting a standard set of manoeuvres. Results are validated against drivers of different sizes, seat preferences and levels of driving expertise to evaluate the robustness of the methods; precision and recall metrics higher than 95% for manoeuvre classification and 90% for manoeuvre prediction with time-windows of up to 1.3 seconds are obtained. The idea of prediction adds a highly novel aspect to human-robot/human-vehicle interaction, allowing for decision and control at a later point.


