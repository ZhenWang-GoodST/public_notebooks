total paper: 770
Title: Real-time Convolutional Networks for Depth-based Human Pose Estimation
Abstract: We propose to combine recent Convolutional Neural Networks (CNN) models with depth imaging to obtain a reliable and fast multi-person pose estimation algorithm applicable to Human Robot Interaction (HRI) scenarios. Our hypothesis is that depth images contain less structures and are easier to process than RGB images while keeping the required information for human detection and pose inference, thus allowing the use of simpler networks for the task. Our contributions are threefold. (i) we propose a fast and efficient network based on residual blocks (called RPM) for body landmark localization from depth images; (ii) we created a public dataset DIH comprising more than 170k synthetic images of human bodies with various shapes and viewpoints as well as real (annotated) data for evaluation; (iii) we show that our model trained on synthetic data from scratch can perform well on real data, obtaining similar results to larger models initialized with pre-trained networks. It thus provides a good trade-off between performance and computation. Experiments on real data demonstrate the validity of our approach.


Title: Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline
Abstract: In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.


Title: 3D Human Pose Estimation on a Configurable Bed from a Pressure Image
Abstract: Robots have the potential to assist people in bed, such as in healthcare settings, yet bedding materials like sheets and blankets can make observation of the human body difficult for robots. A pressure-sensing mat on a bed can provide pressure images that are relatively insensitive to bedding materials. However, prior work on estimating human pose from pressure images has been restricted to 2D pose estimates and flat beds. In this work, we present two convolutional neural networks to estimate the 3D joint positions of a person in a configurable bed from a single pressure image. The first network directly outputs 3D joint positions, while the second outputs a kinematic model that includes estimated joint angles and limb lengths. We evaluated our networks on data from 17 human participants with two bed configurations: supine and seated. Our networks achieved a mean joint position error of 77 mm when tested with data from people outside the training set, outperforming several baselines. We also present a simple mechanical model that provides insight into ambiguity associated with limbs raised off of the pressure mat, and demonstrate that Monte Carlo dropout can be used to estimate pose confidence in these situations. Finally, we provide a demonstration in which a mobile manipulator uses our network's estimated kinematic model to reach a location on a person's body in spite of the person being seated in a bed and covered by a blanket.


Title: Predicting Out-of-View Feature Points for Model-Based Camera Pose Estimation
Abstract: In this work we present a novel framework that uses deep learning to predict object feature points that are out-of-view in the input image. This system was developed with the application of model-based tracking in mind, particularly in the case of autonomous inspection robots, where only partial views of the object are available. Out-of-view prediction is enabled by applying scaling to the feature point labels during network training. This is combined with a recurrent neural network architecture designed to provide the final prediction layers with rich feature information from across the spatial extent of the input image. To show the versatility of these out-of-view predictions, we describe how to integrate them in both a particle filter tracker and an optimisation based tracker. To evaluate our work we compared our framework with one that predicts only points inside the image. We show that as the amount of the object in view decreases, being able to predict outside the image bounds adds robustness to the final pose estimation.


Title: FSG: A statistical approach to line detection via fast segments grouping
Abstract: Line extraction is a preliminary step in various visual robotic tasks performed in low textured scenes such as city and indoor settings. Several efficient line segment detection algorithms such as LSD and EDLines have recently emerged. However, the state of the art segment grouping methods are not robust enough or not amenable for detecting lines in real-time. In this paper we present FSG, a fast and robust line detection algorithm. It is based on two independent components. A proposer that greedily cluster segments suggesting plausible line candidates and a probabilistic model that decides if a group of segments is an actual line. In the experiments we show that our procedure is more robust and faster than the best methods in the literature and achieves state-of-the art performance in a high level robot localization task such as vanishing points detection.


Title: Optimized Contrast Enhancements to Improve Robustness of Visual Tracking in a SLAM Relocalisation Context
Abstract: Robustness of indirect SLAM techniques to light changing conditions remains a central issue in the robotics community. With the change in the illumination of a scene, feature points are either not extracted properly due to low contrasts, or not matched due to large differences in descriptors. In this paper, we propose a multi-layered image representation (MLI) in which each layer holds a contrast enhanced version of the current image in the tracking process in order to improve detection and matching. We show how Mutual Information can be used to compute dynamic contrast enhancements on each layer. We demonstrate how this approach dramatically improves the robustness in dynamic light changing conditions on both synthetic and real environments compared to default ORB-SLAM. This work focalises on the specific case of SLAM relocalisation in which a first pass on a reference video constructs a map, and a second pass with a light changed condition relocalizes the camera in the map.


Title: Key-frame Selection for Multi-robot Simultaneous Localization and Tracking in Robot Soccer Field
Abstract: Optical images provide rich features but require extensive computation resources to process for SLAM. When there are limited computation resources on the robots, it becomes a heavy burden to process the images in real-time. This paper presents the design and implementation of key-frame selection algorithm for multiple robots simultaneous localization and tracking on the multi-robot soccer games which have pre-defined field and objects. Compared to traditional key-frame selection algorithms, this work makes use of the temporal and spatial relationship among objects on the pre-defined field to compute the information entropy. The selection ratio can be adjusted by two parameters: entropy threshold and the maximum moving distance. The experimental results show that the developed method can effectively detect the change of scene using selected key-frames. And comparing with the localization results using all the images, using less than 20% of all images after walking 11,203mm it only increase up to 0.87% trajectory errors.


Title: Egocentric Spatial Memory
Abstract: Egocentric spatial memory (ESM) defines a memory system with encoding, storing, recognizing and recalling the spatial information about the environment from an egocentric perspective. We introduce an integrated deep neural network architecture for modeling ESM. It learns to estimate the occupancy state of the world and progressively construct top-down 2D global maps from egocentric views in a spatially extended environment. During the exploration, our proposed ESM model updates belief of the global map based on local observations using a recurrent neural network. It also augments the local mapping with a novel external memory to encode and store latent representations of the visited places over longterm exploration in large environments which enables agents to perform place recognition and hence, loop closure. Our proposed ESM network contributes in the following aspects: (1) without feature engineering, our model predicts free space based on egocentric views efficiently in an end-to-end manner; (2) different from other deep learning-based mapping system, ESMN deals with continuous actions and states which is vitally important for robotic control in real applications. In the experiments, we demonstrate its accurate and robust global mapping capacities in 3D virtual mazes and realistic indoor environments by comparing with several competitive baselines.


Title: Efficient Long-term Mapping in Dynamic Environments
Abstract: As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.


Title: A distributed vision-based consensus model for aerial-robotic teams
Abstract: We present a distributed model for a team of autonomous aerial robots to collaboratively track a target without external control. The model uses distributed consensus to coordinate actions and to maintain formation via geometric constraints. Each robot uses its ego-centric view of a target and the relative distance from its two closest neighbors to infer its steering commands. To account for noisy and missing target detections, the robots exchange their estimated target position and formation configuration through shared PID-controlled steering responses. We show that the proposed model enables the team to maintain the view of a maneuvering target with varying acceleration under noisy detections and failures up to situations when all robots but one lose the target from their field of view.


Title: Fast Kinodynamic Bipedal Locomotion Planning with Moving Obstacles
Abstract: In this paper, we present a sampling-based kino-dynamic planning framework for a bipedal robot in complex environments. Unlike other footstep planning algorithms which typically plan footstep locations and the biped dynamics in separate steps, we handle both simultaneously. Three primary advantages of this approach are (1) the ability to differentiate alternate routes while selecting footstep locations based on the temporal duration of the route as determined by the Linear Inverted Pendulum Model (LIPM) dynamics, (2) the ability to perform collision checking through time so that collisions with moving obstacles are prevented without avoiding their entire trajectory, and (3) the ability to specify a minimum forward velocity for the biped. To generate a dynamically consistent description of the walking behavior, we exploit the Phase Space Planner (PSP) [1] [2]. To plan a collision-free route toward the goal, we adapt planning strategies from non-holonomic wheeled robots to gather a sequence of inputs for the PSP. This allows us to efficiently approximate dynamic and kinematic constraints on bipedal motion, to apply a sampling-based planning algorithm such as RRT or RRT*, and to use the Dubin's path [3] as the steering method to connect two points in the configuration space. The results of the algorithm are sent to a Whole Body Controller [1] to generate full body dynamic walking behavior. Our planning algorithm is tested in a 3D physics-based simulation of the humanoid robot Valkyrie.


Title: Artificial Invariant Subspace for Humanoid Robot Balancing in Locomotion
Abstract: Legged robots that make use of compliant actuators have demonstrated greater robustness of locomotion than their rigid counterparts. Stiffness and damping are key parameters that characterize the adaptation to perturbations. In this work, by drawing inspirations from controllable compliance and damping in existing soft and bio-inspired legged robots, we propose an approach to design a nonlinear controller for the balancing of humanoid robots with rigid bodies. Existing literature has proposed simplified dynamical models of biped robots in order to predict the timing and placement of swing foot for walking without falling. We further employ the properties of invariance to perturbations in damped harmonic oscillators and formulate continuous feedback control in combination with predictive foot stepping in order to achieve continuous adaptive recoveries of the nominal walking cycle from unexpected physical disturbances. Our method allows asymptotic convergence of the rigid body dynamics to a subspace with the desired energy level. We demonstrate the robustness of the proposed algorithm base on extensive push recovery experiments on a NAO robot on flat terrains.


Title: Real-time Control of Whole-body Robot Motion and Trajectory Generation for Physiotherapeutic Juggling in VR
Abstract: Motor rehabilitation is in increasingly high demand to deal with minor functional motor impairments resulting from stroke, cerebellar ataxia, or Parkinson's disease. Juggling physiotherapy has shown to induce brain plasticity and to improve coordination and balance in this context. The physiotherapy, however, relies on large number of repetitions to be effective which prompts to deploy robots to release the burden on therapists both in terms of time as well as physical strain. This paper provides a framework to enable juggling games for patients in interacting with robots through Virtual Reality (VR). A set of throwing motions is recorded from the therapist and is retargeted to the humanoid robot COMAN's wrist. The respective whole-body motion is then solved in a stack of Quadratic Programs (QP) in a real-time architecture that integrates OROCOS and Gazebo. The resulting motion is finally streamed to VR for animation of the robot and the thrown ball, which the user can catch in VR using a controller device. We regard the VR setting as an essential step towards physiotherapeutic robotic juggling, because it ensures safety of the patients and effective testing of the methods and already has potential for actual therapeutic intervention. The control framework, however, is already validated in this paper for switching to full real-time operation on the physical robot.


Title: Deep Neural Object Analysis by Interactive Auditory Exploration with a Humanoid Robot
Abstract: We present a novel approach for interactive auditory object analysis with a humanoid robot. The robot elicits sensory information by physically shaking visually indistinguishable plastic capsules. It gathers the resulting audio signals from microphones that are embedded into the robotic ears. A neural network architecture learns from these signals to analyze properties of the contents of the containers. Specifically, we evaluate the material classification and weight prediction accuracy and demonstrate that the framework is fairly robust to acoustic real-world noise.


Title: Cloud services for robotic nurses? Assessing legal and ethical issues in the use of cloud services for healthcare robots
Abstract: This paper explores ethical and legal implications arising from the intertwinement of cloud services, healthcare and robotics. It closes an existing gap in the literature by highlighting the distinctive ethical and legal concerns associated with the inter-dependence of the cyber- and the physical aspects of healthcare cloud robotics. The identified core concerns include uncertainties with regard to data protection requirements; distributed responsibilities for unintended harm; achievement of transparency and consent for cloud robot services especially for vulnerable robot users; secondary uses of cloud data derived from robot activities; data security; and wider social issues. The paper aims to raise awareness and stimulate reflection of the legal and ethical impacts on different stakeholders arising from the use of cloud services in healthcare robotics. We show that due to the complexity of these concerns the design and implementation of such robots in healthcare requires an interdisciplinary development and impact assessment process. In light of legal requirements and ethical responsibilities towards end-users and other stakeholders, we draw practical considerations for engineers developing cloud services for robots in healthcare.


Title: Towards Norm Realization in Institutions Mediating Human-Robot Societies
Abstract: Social norms are the understandings that govern the behavior of members of a society. As such, they regulate communication, cooperation and other social interactions. Robots capable of reasoning about social norms are more likely to be recognized as an extension of our human society. However, norms stated in a form of the human language are inherently vague and abstract. This allows for applying norms in a variety of situations, but if the robots are to adhere to social norms, they must be capable of translating abstract norms to the robotic language. In this paper we use a notion of institution to realize social norms in real robotic systems. We illustrate our approach in a case study, where we translate abstract norms into concrete constraints on cooperative behaviors of humans and robots. We investigate the feasibility of our approach and quantitatively evaluate the performance of our framework in 30 real experiments with user-based evaluation with 40 participants.


Title: “Oh! I am so sorry!”: Understanding User Physiological Variation while Spoiling a Game Task
Abstract: This paper investigates how individuals react in a situation when an experimenter (human or robot) either tells them to stop in the middle of playing the Jenga game, or accidentally bumps into a table and makes the tower fall down. The mood of the participants and different physiological parameters (i.e., galvanic skin response (GSR) and facial temperature variation) are extracted and analysed based on the condition, experimenter, and psychological questionnaires (i.e., TEQ, TEIQ, RST-PQ). This study was a between participants study with 23 participants. Our results show that multiple GSR parameters (e.g., latency, amplitude, number of peaks) differ significantly based on the condition and the experimenter the participants interacted with. The temperature variation in three regions of interest (i.e., forehead, left, and right periorbital regions) are good indicators of how ready an individual is to react in an unforeseen situation.


Title: An Extended Bayesian User Model (BUM) for Capturing Cultural Attributes with a Social Robot
Abstract: In this work we propose a Bayesian User Model which is able capture a unified representation of cultural attributes from heterogeneous information in the context of Human-Robot Interaction. Despite the latest advances in robotic technologies, virtually no robots are able to cope with the specificities of the “modus vivendi” of different cultures. We start by proposing Bayesian classifiers to capture unitary attributes of different users, clustering them in a n-dimensional semantic attribute space, aggregating groups of persons that share similar attributes. Results show a highly accurate classification framework, both capable of detecting specific subtleties in user's properties, and generalizing them into representative profiles. We then discuss its application towards adapting the actions of a robot and its potential impact on culture-awareness, demonstrating how the proposed framework can enable culture-awareness, exploring this new frontier in social robotics.


Title: Culturally aware Planning and Execution of Robot Actions
Abstract: The way in which humans behave, speak and interact is deeply influenced by their culture. For example, greeting is done differently in France, in Sweden or in Japan; and the average interpersonal distance changes from one cultural group to the other. In order to successfully coexist with humans, robots should also adapt their behavior to the culture, customs and manners of the persons they interact with. In this paper, we deal with an important ingredient of cultural adaptation: how to generate robot plans that respect given cultural preferences, and how to execute them in a way that is sensitive to those preferences. We present initial results in this direction in the context of the CARESSES project, a joint EU-Japan effort to build culturally competent assistive robots.


Title: CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism
Abstract: Many children on autism spectrum have atypical behavioral expressions of engagement compared to their neu-rotypical peers. In this paper, we investigate the performance of deep learning models in the task of automated engagement estimation from face images of children with autism. Specifically, we use the video data of 30 children with different cultural backgrounds (Asia vs. Europe) recorded during a single session of a robot-assisted autism therapy. We perform a thorough evaluation of the proposed deep architectures for the target task, including within- and across-culture evaluations, as well as when using the child-independent and child-dependent settings. We also introduce a novel deep learning model, named CultureNet, which efficiently leverages the multi-cultural data when performing the adaptation of the proposed deep architecture to the target culture and child. We show that due to the highly heterogeneous nature of the image data of children with autism, the child-independent models lead to overall poor estimation of target engagement levels. On the other hand, when a small amount of data of target children is used to enhance the model learning, the estimation performance on the held-out data from those children increases significantly. This is the first time that the effects of individual and cultural differences in children with autism have empirically been studied in the context of deep learning performed directly from face images.


Title: Object Assembly Guidance in Child-Robot Interaction using RGB-D based 3D Tracking
Abstract: This work examines how and to what benefit an autonomous humanoid robot can supervise a child in an object assembly task. In order to understand the child's actions, a novel 3D object tracking algorithm for RGB-D data is employed. The tracker consists of two stages: the first performs a tracking-by-detection scheme on the color stream, to locate the objects on the image plane, while the second uses a particle filter that operates on the depth data stream to refine the first stage output and infer the objects' rotations. Given the six degrees-of-freedom of the assembly part poses, the system is able to recognize which connections have been completed at any given time. This information is then used to select an appropriate verbal or gestural response for the robot. Experimental results show that (a) the tracking algorithm is accurate, fast and robust to severe occlusions and fast movements, (b) the proposed method of assembly state estimation is indeed effective, and (c) the resulting Child-Robot Interaction scenario is educational and enjoyable for the children involved.


Title: Reachset Conformance of Forward Dynamic Models for the Formal Analysis of Robots
Abstract: Model-based design of robotic systems has many advantages, among them faster development cycles and reduced costs due to early detections of design flaws. Approximate models are sufficient for many classical robotic applications; however, they no longer suffice for safety-critical applications. For instance, a dangerous situation which has not been detected by model-based testing might occur in a human-robot co-existence scenario since models do not exactly replicate behaviors of real systems-this problem arises no matter how accurate a model is, since even disturbances and sensor noise can cause a mismatch. We address this issue by adding non-determinism to robotic models and by computing the whole set of possible behaviors using reachability analysis. By using reachset conformance, we automatically adjust the required non-determinism so that all recorded behaviors are captured. For the first time this approach is demonstrated for a real robot.


Title: Timestamp Offset Calibration for an IMU-Camera System Under Interval Uncertainty
Abstract: To properly fuse IMU and camera information for robotics applications, the relative timestamp offset between both sensors' data streams has to be considered. However, finding the exact timestamp offset is often impossible. Thus, it is necessary to additionally consider the offset's uncertainty if we want to produce reliable results. In order to find the offset and its uncertainty, we determine orientation estimates from IMU and camera under interval uncertainty. Subsequently, these intervals are used as a common representation for our bounded-error approach that finds an interval enclosing the true offset while also modeling the uncertainty. Calibration data can be acquired in a few seconds using a simple setup of IMU, camera and camera target. Results using both simulated and real data demonstrate that we are able to determine the offset to an accuracy of 20 ms with a computation time that is suitable for future online applications. Here, our approach could be used to monitor the timestamp offset in a guaranteed way. Additionally, our method can be adapted to determine an interval for the rotation between both sensors. While this increases the computation time drastically, it also enhances the accuracy of the timestamp offset to less than 10 ms.


Title: Online inference of human belief for cooperative robots
Abstract: For human-robot cooperation, inferring a hu-man's cognitive state is very important for an efficient and natural interaction. Similar to human-human cooperation, understanding what the partner plans and knowing, if he is situation aware, is necessary to prevent collisions, offer support at the right time, correct mistakes before they happen or choose the best actions for oneself as early as possible. We propose a model-based belief filter to extract relevant aspects of a human's mental state online during cooperation. It performs inference based on human actions and its own task knowledge, modeling cognitive processes like perception and action selection. In contrast to most prior work, we explicitly estimate the human belief instead of inferring only a single mode or intention. Since this is a double inference process, we focus on representing the human estimates of environmental state and task as well as corresponding uncertainties. We designed a human-robot cooperation experiment that allowed for a variety of cognitive states of both agents and collected data to test and evaluate the proposed belief filter. The results are promising, as our system can be used to provide reasonable predictions of the human action and insights into his situation awareness. At the same time it is inferring interpretable information about the underlying cognitive states - A belief about the human's belief about the environment.


Title: An Omnidirectional Jumper with Expanded Movability via Steering, Self-Righting and Take-off Angle Adjustment
Abstract: In this paper, we propose an omnidirectional jumper with expanded locomotion capabilities. The mechanisms for four functions-jumping, steering, self-righting and take-off angle adjustment-are designed using only two motors to maximize the jumping performance. Jumping uses the modified active triggering mechanism with one motor. Steering shares this motor and uses the wheel touching the ground. The take-off angle is adjusted by changing the angle between the body and the foot using another motor. Self-righting is possible by utilizing combinations of the movements that occur in the energy storing and angle adjustment processes. With these four functions, the robot is capable of jumping in all directions and can jump anywhere in between the maximum height and maximum distance. It can also jump multiple times by self-righting. The robot, with a mass of 64.4 g, jumps up to 113 cm in vertical height, and 170 cm in horizontal distance. This robot can be deployed to explore various environments. Moreover, the design method to implement more functions than the number of motors can be applied to design other small-scale robots.


Title: Delineating boundaries of feasibility between robot designs
Abstract: Motivated by the need for tools to aid in the design of effective robots, we examine how to determine the role that particular sensing and actuator resources play in enabling a robot to achieve useful ends. Rather than merely asking “will this sensor suffice?” we classify general modifications to the set of sensors and actuators based on the feasibility of accomplishing given tasks using these sets. The goal is to probe the boundary between modifications that are destructive on a given planning problem, and modifications that are not. Since this boundary itself can be impractically large, classic search methods are of no avail to summarize discriminatory features on this boundary. Instead, we propose a decision tree learning method to efficiently construct a compact implicit representation of the boundary. The idea is to allow the designer to use prior knowledge to constrain the search, then use the tool to probe the boundary subject to those constraints, gaining insight into the information necessary for a robot to ensure task achievement. Ultimately we envision a interactive process where additional constraints are repeatedly included as new light is shed. We aim to pave the way for interactive tools that help the roboticist navigate the complexities of the design space. We describe an implementation of this approach along with experimental results that show that the method can construct decision trees with explanatory value. Our experiments suggest that some domain knowledge (specifically picking features that emphasize monotonicity) substantially improves running-time with only negligible reduction in accuracy.


Title: Discrete Configuration Space Methods for Determining Modular Connector Area of Acceptance in Higher Dimensions
Abstract: Physical connectors with self-aligning geometry aid in the docking process for many robotic and automatic control systems such as robotic self-reconfiguration and air-to-air refueling. This self-aligning geometry provides a wider range of acceptable error tolerance in relative pose between the two rigid objects, increasing successful docking chances. We present a new method for computing the error range (or area of acceptance) for a pair of rigid connector objects with self-aligning geometry capable of higher dimensional analysis which was previously limited to three. The method is based on the configuration space obstacle model, which gives us a representation of the space of contact states between the two objects. Using an approach direction as analogous to gravity, and assuming the target docked configuration is stable, the set of misaligned points that lead to docking is the target configuration's watershed for an arbitrarily dimensioned configuration space obstacle. It is well known that the watershed of a height map on a discrete grid can be found using any number of algorithms from image segmentation. We present an implementation based on Meyer's flooding algorithm to determine this watershed and measure the AA for simple connectors in 2D and 3D. Results are presented for systems including unconstrained motion in SE(2) and motion constrained to four dimensions (ie. x,y,z,pitch) in SE(3).


Title: Design and Development of Biaxial Active Nozzle with Flexible Flow Channel for Air Floating Active Scope Camera
Abstract: Long flexible continuum robots have a high potential for search and rescue operations that explore deep layered debris. A general problem of these robots is in the control of the head motion because their thin bodies limit the space available to mount multiple actuators. This paper develops a biaxial active nozzle which can rotate the air jet direction along a roll and pitch axis in order to control the direction of reaction force and the head motion of a long flexible robot. A major challenge is how to change the air jet direction without a large resistance to the flow, which reduces the reaction force induced by the air jet. We propose a nozzle whose outlet is connected with a flexible air tube. The direction of the air jet is controlled by the smooth shape deformation of the tube. The nozzle should be compact enough to be installed on a thin robot, although the shape deformation of the tube may cause buckling. The flexible tube is modeled and simulated by a multiple link model used to derive the geometric parameters of the nozzle so that the nozzle is compact and the tube does not buckle. Based on the derived parameters, the biaxial active nozzle was developed. A basic performance experiment shows that the nozzle can change the reaction force direction by deforming the tube shape, while the magnitude of the reaction force is almost constant. We integrated the proposed nozzle with a conventional Active Scope Camera (ASC). The range where the robot can look around in a vertical exploration was significantly improved, which was three times larger than the previous ASC whose head was controlled by pneumatic actuators. The rubble field test demonstrates that the integrated ASC could move over rubble (maximum height of 200 mm) and steer the course.


Title: Auxetic Sleeves for Soft Actuators with Kinematically Varied Surfaces
Abstract: Soft actuators with auxetic, or negative Poisson's ratio (NPR), behavior offer a way to create soft robots with novel kinematic behavior. This paper presents an original framework for reinforcement of a soft actuator using a generalized NPR element, called a Representative Auxetic Element (RAE), and an experimental validation of the kinematic behavior that it enables. We build a generalized kinematic model that enables the design of RAE-patterned actuators and reveal the distinct auxetic behavior of RAE actuators with comparable model accuracy to the legacy McKibben actuators. A simple, reproducible way of designing and fabricating RAE actuators is described and varied prototypes are shown. This RAE-based design scheme can be used to create actuators with specified kinematics like bending, extension, and radial expansion, which can also vary across the actuator's surface both circumferentially and axially in a tractable, scalable manner.


Title: A Unified Controller for Region-reaching and Deforming of Soft Objects
Abstract: Emerging applications of robotic manipulation of deformable objects have opened up new challenges in robot control. While several control techniques have been developed to manipulate deformable objects, the performance of existing methods is commonly limited by two issues: 1) implicit assumption that the physical contact between the end-effector and the object is always maintained, and 2) requirements of exact parameters of deformation model, which are difficult to obtain. This paper presents a new control scheme for robotic manipulation of deformable objects, which allows the robot to automatically contact then actively deform the deformable object by assessing the status of deformation in real time. Instead of designing multiple controllers and switching among them, the proposed method smoothly and stably integrates two control phases (i.e. region reaching and active deforming) into a single controller. The stability of the closed-loop system is rigorously proved with the consideration of the uncertain deformation model and uncalibrated cameras. Hence, the proposed control scheme enhances the autonomous capability of active deformable object manipulation. Experimental studies are conducted with different initial conditions to demonstrate the performance of the proposed controller.


Title: Dual-arm robotic manipulation of flexible cables
Abstract: Deforming a cable to a desired (reachable) shape is a trivial task for a human to do without even knowing the internal dynamics of the cable. This paper proposes a framework for cable shapes manipulation with multiple robot manipulators. The shape is parameterized by a Fourier series. A local deformation model of the cable is estimated on-line with the shape parameters. Using the deformation model, a velocity control law is applied on the robot to deform the cable into the desired shape. Experiments on a dual-arm manipulator are conducted to validate the framework.


Title: Online Shape Estimation based on Tactile Sensing and Deformation Modeling for Robot Manipulation
Abstract: Precise robot manipulation of deformable objects requires an accurate and fast estimation of their shape as they deform. So far, visual sensing has been mostly used to solve this issue, but vision sensors are sensitive to occlusions, which might be inevitable when manipulating an object with robot. To address this issue, we present a modular pipeline to track the shape of a soft object in an online manner by coupling tactile sensing with a deformation model. Using a model of a tactile sensor, we compute the magnitude and location of a contact force and apply it as an external force to the deformation model. The deformation model then updates the nodal positions of a mesh that describes the shape of the deformable object. The proposed sensor model and pipeline, are evaluated using a Shadow Dexterous Hand equipped with BioTac sensors on its fingertips and an RGB-D sensor.


Title: Accounting for Directional Rigidity and Constraints in Control for Manipulation of Deformable Objects without Physical Simulation
Abstract: Deformable objects like cloth and rope are challenging to manipulate because it is difficult to predict the state of the object given a motion of the gripper(s) holding it. In much previous work, physical models (such as Mass-Spring or Finite-Element) have been used to model such affects. However, these models often require significant parameter tuning for each scenario and can be expensive to simulate inside a control loop. Furthermore, it is difficult to create a practical controller for deformable object manipulation that preserves constraints, especially avoiding overstretching the object. In this paper, we developed a more effective controller than previous work by (1) constructing a more accurate geometric model of how the direction of gripper motion and obstacles affect deformable objects; and (2) specifying a novel stretching avoidance constraint to prevent the object from being overstretched by the robot. Experiments comparing our new method to the previous method in simulation and on a physical robot suggest that our new model captures the behavior of the object more accurately. We also find that our controller is able to prevent tearing that would occur when using the previous method.


Title: A Series Elastic Tactile Sensing Array for Tactile Exploration of Deformable and Rigid Objects
Abstract: Tactile sensing arrays are used to detect contacts of robotic systems with the environment. They are particularly useful for scenarios in which vision-based sensors cannot be used. Thanks to the presence of multiple sensing elements, tactile arrays also provide spatial information about the contact location. In this work, we present our series elastic tactile array to enable tactile exploration for position-controlled robot manipulators. Sixteen compliant sensing elements are arranged as a 4×4 array. This allows the position-controlled robot to explore objects via palpation. Tactile sensing was accomplished by measuring the change of the magnetic field caused by neodymium magnets embedded into the series elastic elements. We demonstrate the efficacy of our sensor with two sets of experiments involving physical interaction scenarios. Firstly, we show that the sensor can be used to differentiate between rigid and deformable objects. Secondly, we show that point clouds of objects can be generated quickly with our sensor module attached to a position-controlled robot manipulator as an end-effector.


Title: Learning Symbolic Representations for Planning with Parameterized Skills
Abstract: A critical capability required for generally intelligent robot behavior is the ability to sequence motor skills to reach a goal. This requires a (typically abstract) representation that supports goal-directed planning, which raises the question of how to construct such a representation. Previous work has addressed this question in the context of simple black-box motor skills, which are insufficiently flexible to support the wide range of behavior required of intelligent robots. We now extend that work to include parametrized motor skills, where a robot must both select an action to execute and also decide how to parametrize it. We show how to construct a representation suitable for planning with parametrized motor skills, and specify conditions which are sufficient to separate the selection of motor skills from the parametrization of those skills. Our method results in a simple discrete abstract representation for planning followed by a parameter selection process that operates on a fixed plan. We first demonstrate learning this representation in a virtual domain based on Angry Birds and then learn an abstract symbolic representation for a robot manipulation task.


Title: Regularizing Reinforcement Learning with State Abstraction
Abstract: State abstraction in a discrete reinforcement learning setting clusters states sharing a similar optimal action to yield an easier to solve decision process. In this paper, we generalize the concept of state abstraction to continuous action reinforcement learning by defining an abstract state as a state cluster over which a near-optimal policy of simple shape exists. We propose a hierarchical reinforcement learning algorithm that is able to simultaneously find the state space clustering and the optimal sub-policies in each cluster. The main advantage of the proposed framework is to provide a straightforward way of regularizing reinforcement learning by controlling the behavioral complexity of the learned policy. We apply our algorithm on several benchmark tasks and a robot tactile manipulation task and show that we can match state-of-the-art deep reinforcement learning performance by combining a small number of linear policies.


Title: CReaM: Condensed Real-time Models for Depth Prediction using Convolutional Neural Networks
Abstract: Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30 frames per second on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a “from teacher to student” style knowledge transfer.


Title: A Bio-inspired Reinforcement Learning Rule to Optimise Dynamical Neural Networks for Robot Control
Abstract: Most approaches for optimisation of neural networks are based on variants of back-propagation. This requires the network to be time invariant and differentiable; neural networks with dynamics are thus generally outside the scope of these methods. Biological neural circuits are highly dynamic yet clearly able to support learning. We propose a reinforcement learning approach inspired by the mechanisms and dynamics of biological synapses. The network weights undergo spontaneous fluctuations, and a reward signal modulates the centre and amplitude of fluctuations to converge to a desired network behaviour. We test the new learning rule on a 2D bipedal walking simulation, using a control system that combines a recurrent neural network, a bio-inspired central pattern generator layer and proportional-integral control, and demonstrate the first successful solution to this benchmark task.


Title: Teaching Robots to Predict Human Motion
Abstract: Teaching a robot to predict and mimic how a human moves or acts in the near future by observing a series of historical human movements is a crucial first step in human-robot interaction and collaboration. In this paper, we instrument a robot with such a prediction ability by leveraging recent deep learning and computer vision techniques. First, our system takes images from the robot camera as input to produce the corresponding human skeleton based on real-time human pose estimation obtained with the OpenPose library. Then, conditioning on this historical sequence, the robot forecasts plausible motion through a motion predictor, generating a corresponding demonstration. Because of a lack of high-level fidelity validation, existing forecasting algorithms suffer from error accumulation and inaccurate prediction. Inspired by generative adversarial networks (GANs), we introduce a global discriminator that examines whether the predicted sequence is smooth and realistic. Our resulting motion GAN model achieves superior prediction performance to state-of-the-art approaches when evaluated on the standard H3.6M dataset. Based on this motion GAN model, the robot demonstrates its ability to replay the predicted motion in a human-like manner when interacting with a person.


Title: Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails
Abstract: Robots hold promise in many scenarios involving outdoor use, such as search-and-rescue, wildlife management, and collecting data to improve environment, climate, and weather forecasting. However, autonomous navigation of outdoor trails remains a challenging problem. Recent work has sought to address this issue using deep learning. Although this approach has achieved state-of-the-art results, the deep learning paradigm may be limited due to a reliance on large amounts of annotated training data. Collecting and curating training datasets may not be feasible or practical in many situations, especially as trail conditions may change due to seasonal weather variations, storms, and natural erosion. In this paper, we explore an approach to address this issue through virtual-to-real-world transfer learning using a variety of deep learning models trained to classify the direction of a trail in an image. Our approach utilizes synthetic data gathered from virtual environments for model training, bypassing the need to collect a large amount of real images of the outdoors. We validate our approach in three main ways. First, we demonstrate that our models achieve classification accuracies upwards of 95% on our synthetic data set. Next, we utilize our classification models in the control system of a simulated robot to demonstrate feasibility. Finally, we evaluate our models on real-world trail data and demonstrate the potential of virtual-to-real-world transfer learning.


Title: Robust Model-Predictive Deformation Control of a Soft Object by Using a Flexible Continuum Robot
Abstract: Flexible continuum robots have exhibited unique advantages in working in an unstructured environment. Many applications require robots to actively control the deformation of soft objects, such as soft tissues in surgery. Thus, this study presents a robust model-predictive deformation control of a soft object using a flexible continuum robot. A linear approximation model for mapping from actuation space of a continuum robot to deformation space of a soft object is established. Jacobian matrix is estimated online by using a robust Geman-McClure estimator. Then, the deformation of the soft object is regulated by using a prediction horizon-based controller with exponential weighting for model uncertainty. The proposed control approach is effective in manipulating a soft object with a flexible continuum robot that is in contact with obstacles.


Title: Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles
Abstract: Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.


Title: Courteous Autonomous Cars
Abstract: Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.


Title: Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP
Abstract: Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.


Title: Fractional-Order Trajectory-Following Control for Two-Legged Dynamic Walking
Abstract: This research seeks greater efficiency for walking robots. Efficiency can be improved in two ways: better performance (i.e., less wasted motion) and reduced energy consumption. Fractional-order control is a pathway to both of these improvements because of the flexibility it offers in designing a control strategy. Compared to the existing proportional-derivative architecture, changing the order of the derivative - the number of derivatives taken - to real numbers other than 1 has yielded both types of improvement for a simulated walker. The evidence of better performance is the leg angles' improvement in maintaining a desired relationship with respect to one another. Depending on the controller chosen, the walker can also be made to achieve the original level of performance with reduced control signals and less torque delivered to the hip joint, implying greater energy efficiency.


Title: Walking on a Steep Slope Using a Rope by a Life-Size Humanoid Robot
Abstract: In this paper, we propose methods for walking on a steep slope using a rope by a humanoid robot. There are two difficulties for walking on a steep slope without a rope. First, range of motion of ankle joints get limited. Second, feet of a robot slip on a steep slope. For these problems, using a rope is effective solution because the robot can receive enough friction force from the slope and walk on a steep slope by pulling a rope with proper tension. In addition, the robot pulling a rope on a slope can relax limitations of ankle joints. Therefore, we propose methods to determine tension of a grasped rope by solving a linear least-square problem considering deformability of a rope. With these methods, a life-size humanoid robot HRP-2 could walk on a steep slope which angle is 40 degree.


Title: Perception Based Locomotion System for a Humanoid Robot with Adaptive Footstep Compensation under Task Constraints
Abstract: In order to accurately reach a target position while executing a task which imposes occlusion or constraints of the posture, a humanoid robot requires an adaptive locomotion system, which can comprehensively integrate localization, environmental mapping, global locomotion planning and local error correction. In this paper, we propose a method of constructing a perception based locomotion system for a humanoid robot. The major contribution of this paper is solving a problem of the locomotion error caused by the task constraints, by locally compensating footsteps and assessing the need for global footstep re-planning online based on environmental measurements. The proposed system provides an accurate and dense ground point cloud, called HeightField, using plane estimation and space interpolation, and obstacle point cloud for frequent collision avoidance by accumulating laser scans. This environmental perception enables a humanoid robot to plan footsteps globally even in the situation where the sight of the robot is limited and compensate footsteps while estimating landing state during locomotion online with the localization result. We evaluated the practicality of the proposed system by applying it to our humanoid robot carrying a heavy object in a construction site and confirmed that the proposed system contributed to improved locomotion abilities of a humanoid robot engaging in heavy-duty or dangerous tasks.


Title: Adaptive step rotation in biped walking
Abstract: We want to enable the robot to reorient its feet in order to face its direction of motion. Model Predictive Control schemes for biped walking usually assume fixed feet rotation since adapting them online leads to a nonlinear problem. Nonlinear solvers do not guarantee the satisfaction of nonlinear constraints at every iterate and this can be problematic for the real-time operation of robots. We propose to define safe linear constraints that are always inside the intersection of the nonlinear constraints. We make simulations of the robot walking on a crowd and compare the performance of the proposed method with respect to the original nonlinear problem solved as a Sequential Quadratic Program.


Title: Implementing Full-body Torque Control in Humanoid Robot with High Gear Ratio Using Pulse Width Modulation Voltage
Abstract: Most state-of-the-art torque control-based legged robots show excellent performance, exceeding that of conventional position control-based robots. Many conventional position control-based legged robots have high gear ratios, but do not have joint torque sensors. In addition, some robots cannot generate current for controlling the motor torque. To apply torque control-based walking algorithms to a position control-based humanoid robot, we proposed current control using a motor thermal model and realized joint torque control by compensating for the joint dynamics and robot dynamics. We conducted experiments to verify the performance of the Hubo2 platform developed in 2008 by applying a full-body dynamics control framework. The results confirmed the possibility of using torque control algorithms with existing position-based robots.


Title: Towards Minimal Intervention Control with Competing Constraints
Abstract: As many imitation learning algorithms focus on pure trajectory generation in either Cartesian space or joint space, the problem of considering competing trajectory constraints from both spaces still presents several challenges. In particular, when perturbations are applied to the robot, the underlying controller should take into account the importance of each space for the task execution, and compute the control effort accordingly. However, no such controller formulation exists. In this paper, we provide a minimal intervention control strategy that simultaneously addresses the problems of optimal control and competing constraints between Cartesian and joint spaces. In light of the inconsistency between Cartesian and joint constraints, we exploit the robot null space from an information-theory perspective so as to reduce the corresponding conflict. An optimal solution to the aforementioned controller is derived and furthermore a connection to the classical finite horizon linear quadratic regulator (LQR) is provided. Finally, a writing task in a simulated robot verifies the effectiveness of our approach.


Title: Design and Evaluation of Torque Based Bipedal Walking Control System That Prevent Fall Over by Impulsive Disturbance
Abstract: In this paper, we develop a bipedal robot control system that has an ability to perform instantaneous high power and flexibility to absorb an impulsive disturbance. We utilize a sensor-less whole body torque control method executed in a high responsive realtime distributed system. This system also includes a robust online walking controller that can avoid fall over caused by a strong collision with the robot's legs. We evaluated the proposed control system by hitting a rubber ball or adding a leg sweep disturbance and verified the functionality of the absorbing motion and the balance restoring motion.


Title: Humanoid Robot COM Kinematics Estimation based on Compliant Inverted Pendulum Model and Robust State Estimator
Abstract: This work proposes a humanoid robot center of mass (COM) estimation framework based on the compliant inverted pendulum model and the robust estimator. Humanoids' limited structural stiffness and relatively long legs result in undesired flexibility, and this undesired motion hinders the state estimation. The models used in previous studies were either not suitable for estimation or too simple to express these key characteristics of humanoid robots. Here, to enhance the estimation performance, the compliant inverted pendulum model, which is developed by attaching a spring and damper to the original pendulum, is adopted. The additional elements can represent the mechanical deformation and undesired flexibility. This model can reflect the important characteristics of the humanoid robot while taking advantage of the merits of the sing-mass model. In addition, a robust state estimator that was proposed in our previous work is adopted to compensate for an estimation error caused by a modeling error. Using these two factors, an improved COM kinematics estimates could be obtained.


Title: Robotic Sewing and Knot Tying for Personalized Stent Graft Manufacturing
Abstract: This paper presents a versatile robotic system for sewing a 3D structured object. Leveraging on using a customized robotic sewing device and closed-loop visual servoing control, an all-in-one solution for sewing personalized stent graft is demonstrated. Stitch size planning and automated knot tying are proposed as two key functions of the system. By using effective stitch size planning, sub-millimetre sewing accuracy is achieved for stitch sizes ranging from 2mm to 5mm. In addition, a thread manipulator for thread management and tension control is also proposed to perform successive knot tying to secure each stitch. Detailed laboratory experiments have been performed to evaluate the proposed instruments and allied algorithms. The proposed framework can be generalised to a wide range of applications including 3D industrial sewing, as well as transferred to other clinical areas such as surgical suturing.


Title: Estimation of Interaction Forces in Robotic Surgery using a Semi-Supervised Deep Neural Network Model
Abstract: Providing force feedback as a feature in current Robot-Assisted Minimally Invasive Surgery systems still remains a challenge. In recent years, Vision-Based Force Sensing (VBFS) has emerged as a promising approach to address this problem. Existing methods have been developed in a Supervised Learning (SL) setting. Nonetheless, most of the video sequences related to robotic surgery are not provided with ground-truth force data, which can be easily acquired in a controlled environment. A powerful approach to process unlabeled video sequences and find a compact representation for each video frame relies on using an Unsupervised Learning (UL) method. Afterward, a model trained in an SL setting can take advantage of the available ground-truth force data. In the present work, UL and SL techniques are used to investigate a model in a Semi-Supervised Learning (SSL) framework, consisting of an encoder network and a Long-Short Term Memory (LSTM) network. First, a Convolutional Auto-Encoder (CAE) is trained to learn a compact representation for each RGB frame in a video sequence. To facilitate the reconstruction of high and low frequencies found in images, this CAE is optimized using an adversarial framework and a L1-loss, respectively. Thereafter, the encoder network of the CAE is serially connected with an LSTM network and trained jointly to minimize the difference between ground-truth and estimated force data. Datasets addressing the force estimation task are scarce. Therefore, the experiments have been validated in a custom dataset. The results suggest that the proposed approach is promising.


Title: Cross-Scene Suture Thread Parsing for Robot Assisted Anastomosis based on Joint Feature Learning
Abstract: Task autonomy is an important consideration for the development of future surgical robots. For robot-assisted anastomosis, suture thread detection is a prerequisite for subsequent robot manipulation. Previous works on automatic thread detection are focused on the learning of the models with specific surgical settings that are poorly generalisable to generic settings. In this paper, we propose a joint feature learning framework that caters for the foreground and background adaptation for surgical suture thread detection. The proposed method is developed in the context of semi-supervised and unsupervised domain adaptation, leveraging the labelled training data from the source domain to learn the detection model for unlabelled or partially labelled target domain, which can also be from different types of threads or organs. Based on adversarial learning, we further preserve the semantic identity and introduce curriculum adaptation to generate synthetic data. Experiments on four domain adaptation tasks for suture thread detection demonstrate the strength of the proposed method being able to generate good quality synthetic data and transfer between specific domains with limited or even no labelled data of the target domain.


Title: Unsupervised Trajectory Segmentation and Promoting of Multi-Modal Surgical Demonstrations
Abstract: To improve the efficiency of surgical trajectory segmentation for robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. Unsupervised deep learning network, stacking convolutional auto-encoder, is employed to extract more discriminative features from videos in an effective way. To further improve the accuracy of segmentation, on one hand, wavelet transform is used to filter out the noises existed in the features from video and kinematic data. On the other hand, the segmentation result is promoted by identifying the adjacent segments with no state transition based on the predefined similarity measurements. Extensive experiments on a public dataset JIGSAWS show that our method achieves much higher accuracy of segmentation than state-of-the-art methods in the shorter time.


Title: Autonomous Localization, Navigation and Haustral Fold Detection for Robotic Endoscopy
Abstract: Capsule endoscopes have gained popularity over the last decade as minimally invasive devices for diagnosing gastrointestinal abnormalities such as colorectal cancer. While this technology offers a less invasive and more convenient alternative to traditional scopes, these capsules are only able to provide observational capabilities due to their passive nature. With the addition of a reliable mobility system and a real-time navigation system, capsule endoscopes could transform from observational devices into active surgical tools, offering biopsy and therapeutic capabilities and even autonomous navigation in a single minimally invasive device. In this work, a vision system is developed to allow for autonomous lumen center tracking and haustral fold identification and tracking during colonoscopy. This system is tested for its ability to accurately identify and track multiple haustral folds across many frames in both simulated and in vivo video, and the lumen center tracking is tested onboard a robotic endoscope platform (REP) within an active simulator to demonstrate autonomous navigation. In addition, real-time localization is demonstrated using open source ORB-SLAM2. The vision system successfully identified 95.6% of Haustral folds in simulator frames and 70.6% in in vivo frames and false positives occurred in less than 1% of frames. The center tracking algorithm showed in vivo center estimates within a mean error of 6.6% of physician estimates and allowed for the REP to traverse 2 m of the active simulator in 6 minutes without intervention.


Title: Towards to a Robotic Assisted System for Percutaneous Nephrolithotomy
Abstract: Percutaneous Nephrolithotomy is a recommended treatment method for large kidney stone removal. However, the first and most important step, i.e., getting the percutaneous access to create the tract between the targeted calyx and the flank skin, is challenging as the surgeon is often occupied by several tasks at a given time. Therefore, in this paper, we propose a robotic assisted system that collaborates with the surgeon and provides assistance in order for the surgeons to focus on more critical jobs resulting in better surgical performance. A procedure for this robot including three working stages is described. This procedure allows the surgeon to choose a suitable percutaneous target using an ultrasound probe based on his or her experience and the robot will track the respiratory motion of the target kidney stone and insert the needle automatically after the surgeon releases the probe. Experiments are conducted to demonstrate the procedure with the proposed assisted robot for PCNL.


Title: On Muscle Activation for Improving Robotic Rehabilitation after Spinal Cord Injury
Abstract: Spinal cord stimulation (SCS) has recently enabled humans with motor complete spinal cord injury (SCI) to independently stand and recover some lost autonomic function. However, the nature of the recovered motor activity and the interplay between SCS and motor training are not well understood. Understanding the effect of stand training and spinal stimulation on motor activity during bipedal standing is important for designing spinal rehabilitation therapies that seek to combine spinal stimulation and rehabilitative robots. In this study, we examined electromyography (EMG) data gathered from two SCI patients and six healthy subjects as they attempted standing. We analyzed the muscle activation patterns and EMG waveform shape to quantify both the changes in SCI patient motor activity with training, and the differences between healthy motor activity and SCI patient motor activity under stimulation. We also looked for correlations between the similarity in SCI patients' motor activity to healthy subjects and their overall standing ability. We found that good standing in SCI patients does not emulate healthy standing muscle activity. Furthermore, patient stand training heavily influenced motor activation patterns, but not in ways that improved standing ability. These results indicate that current training techniques do not optimally influence motor activity, and robotic rehabilitation strategies for SCI patients should target essential features of motor activity to optimize functional performance, rather than emulate healthy activity.


Title: Printing Strain Gauges on Intuitive Surgical da Vinci Robot End Effectors
Abstract: Force feedback during robotic surgery is critical in order to minimize potential injury to the patient and decrease recovery time from surgical procedures. Here we describe the use of a novel strain gauge printing method to apply low profile, low cost sensors directly to the surface of da Vinci surgical robot end effectors (Intuitive Surgical, Inc.) to sense deflection and provide force feedback. This additive, vapor-deposition-based sensor fabrication method is used to deposit strain gauges directly onto the surfaces of the end effectors with minimal disruption to the device and without the need for adhesives or machining operations. Initial experiments characterize sensor performance and indicate the applicability of the proposed approach for force feedback during minimally invasive procedures.


Title: Group emotion recognition strategies for entertainment robots
Abstract: In this paper, a system to determine the emotion of a group of people via facial expression analysis is proposed for the Waseda Entertainment Robots. General models and standard methods for emotion definition and recognition are briefly described, as well as strategies for computing the group global emotion, knowing the individual emotions of group members. This work is based on Ekman's extended “Big Six” emotional model, popular in Computer Science and Affective Computing. Emotion recognition via facial expression analysis is performed with a cloud-computing based solution, using Microsoft Azure Cognitive services. First, the performances of both the Face API to detect faces, and Emotion API, to compute emotion via face expression analysis, are tested. After that, a solution to compute the emotion of a group of people has been implemented and its performances compared to human perceptions. This work presents concepts and strategies which can be generalized for applications within the scope of assistive robotics and, more broadly, affective computing, wherever it will be necessary to determine the emotion of a group of people.


Title: Learning How Pedestrians Navigate: A Deep Inverse Reinforcement Learning Approach
Abstract: Humans and mobile robots will be increasingly cohabiting in the same environments, which has lead to an increase in studies on human robot interaction (HRI). One important topic in these studies is the development of robot navigation algorithms that are socially compliant to humans navigating in the same space. In this paper, we present a method to learn human navigation behaviors using maximum entropy deep inverse reinforcement learning (MEDIRL). We use a large open dataset of pedestrian trajectories collected in an uncontrolled environment as the expert demonstrations. Human navigation behaviors are captured by a nonlinear reward function through deep neural network (DNN) approximation. The developed MEDIRL algorithm takes feature inputs including social affinity map (SAM) that are extracted from human motion trajectories. We perform simulation experiments using the learned reward function, and the performance is evaluated comparing it with the real measured pedestrian trajectories in the dataset. The evaluation results show that the proposed method has acceptable prediction accuracy compared to other state-of-the-art methods, and it can generate pedestrian trajectories similar to real human trajectories with natural social navigation behaviors such as collision avoidance, leader-follower, and split-and-rejoin.


Title: Situated Human–Robot Collaboration: predicting intent from grounded natural language
Abstract: Research in human teamwork shows that a key element of fluid and fluent interactions is the interpretation of implicit verbal and non-verbal cues in context. This poses an issue to robotic platforms, however, as they have historically worked best when controlled through explicit commands that have employed structured, unequivocal representations of the external world and their human partners. In this work, we present a framework for effectively grounding situated and naturalistic speech to action selection during human-robot collaborative activities. This is accomplished by maintaining and incrementally updating separate “speech” and “context” models that jointly classify a collaborator's utterance. We evaluate the efficacy of the system on a collaborative construction task with an autonomous robot and human participants. We first demonstrate that our system is capable of acquiring and deploying new task representations from limited and naturalistic data sets, and without any prior domain knowledge of language or the task itself. Finally, we show that our system is capable of significantly improving performance on an unfamiliar task after a one-shot exposure.


Title: Social Coordination for Looking-Together Situations
Abstract: People engage in social coordination without explicitly communicating when they are conflicting over spatial resources, e.g., a shop clerk who yields to customers the best place to view products. In this study, we proposed a method that achieves such social coordination with a robot. Our idea is that the social coordination between two agents can be represented as utility-maximizing behavior for joint utility rather than just by a single agent utility. That is, given that each agent's reasonable behavior can be represented as utility-maximizing behavior for single agent utility, we model each agent's plans for himself as well as for the partner agent. Moreover, superiority relationships exist in this joint-utility computation. Since each agent knows such superiority relationships, social coordination can be modeled as utility-yielding behavior based on informed superiority. We specifically focus on looking-together situations for which we developed a utility model. With simulations, we investigate whether the above joint-utility-based modeling successfully reproduces social coordination in looking-together situations. We conducted an experiment in a situation where a tele-operated robot and a customer together look at products in a shop environment. Our experimental results show that our proposed method enables the robot to socially coordinate spatial resources, yielding significantly more thoughtful, less-self-centered, and appropriate impressions than the alternate robot.


Title: Policy Shaping with Supervisory Attention Driven Exploration
Abstract: Robots deployed for long periods of time need to be able to explore and learn from their environment. One approach to this problem has been reinforcement learning (RL), in which robots receive rewards from the environment that allow them to choose optimal actions. To speed learning when human supervision is available, interactive reinforcement learning solicits feedback from a human teacher. However, this approach typically assumes that learning takes place under continuous supervision, which is unlikely to hold in long-term scenarios. We propose an extension to a method of interactive reinforcement learning, policy shaping, that takes into account human attention. Our approach enables better performance while unattended by favoring information-gathering actions when attended and actions that have received positive feedback when unattended. We test our approach in both simulation and on a robot, finding that our method learns faster than policy shaping and performs more safely than policy shaping while no one is paying attention to the robot.


Title: Friendly Motion Learning towards Sustainable Human Robot Interaction
Abstract: For generating interactive behavior of robot to build a long-term relationship between humans and robots, we focus on the difference in familiarity of the human behaviors during conversation. It is difficult to extract interaction motion features correlated to such familiarity as a model in manual. Therefore, we use a machine learning technique: convolution neural network to learn and generate interaction behavior with different familiarity. In the evaluation experiment, we generated interaction behavior using a convolution neural network, which learned from the behaviors of friendship and unknown relationship, who have high and low familiarity respectively. We evaluated how much such interaction behavior affect the human impression by questionnaire survey.


Title: On the Robustness of Speech Emotion Recognition for Human-Robot Interaction with Deep Neural Networks
Abstract: Speech emotion recognition (SER) is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.


Title: Modeling Supervisor Safe Sets for Improving Collaboration in Human-Robot Teams
Abstract: When a human supervisor collaborates with a team of robots, the human's attention is divided, and cognitive resources are at a premium. We aim to optimize the distribution of these resources and the flow of attention. To this end, we propose the model of an idealized supervisor to describe human behavior. Such a supervisor employs a potentially inaccurate internal model of the the robots' dynamics to judge safety. We represent these safety judgements by constructing a safe set from this internal model using reachability theory. When a robot leaves this safe set, the idealized supervisor will intervene to assist, regardless of whether or not the robot remains objectively safe. False positives, where a human supervisor incorrectly judges a robot to be in danger, needlessly consume supervisor attention. In this work, we propose a method that decreases false positives by learning the supervisor's safe set and using that information to govern robot behavior. We prove that robots behaving according to our approach will reduce the occurrence of false positives for our idealized supervisor model. Furthermore, we empirically validate our approach with a user study that demonstrates a significant (p = 0.0328) reduction in false positives for our method compared to a baseline safety controller.


Title: Closed-Loop Robot Task Planning Based on Referring Expressions
Abstract: Increasing the accessibility of autonomous robots also for inexperienced users requires user-friendly and high-level control opportunities of robotic systems. While automated planning is able to decompose a complex task into a sequence of steps which reaches an intended goal, it is difficult to formulate such a goal without knowing the internals of the planning system and the exact capabilities of the robot. This becomes even more important in dynamic environments in which manipulable objects are subject to change. In this paper, we present an adaptive control interface which allows users to specify goals based on an internal world model by incrementally building referring expressions to the objects in the world. We consider fetch-and-carry tasks and automatically deduce potential high-level goals from the world model to make them available to the user. Based on its perceptions our system can react to changes in the environment by adapting the goal formulation within the domain-independent planning system.


Title: Learning Robotic Grasping Strategy Based on Natural-Language Object Descriptions
Abstract: Given the description of an object, s physical attributes, humans can determine a proper strategy and grasp an object. This paper proposes an approach to determine grasping strategy for an anthropomorphic robotic hand simply based on natural-language descriptions of an object. A learning-based approach is proposed to help a robotic hand learn suitable grasp poses starting from the natural language description of the object. Object features are parsed from natural-language descriptions by using a customized natural-language processing technique. The most likely grasp type for the given object is learned from the human grasping taxonomy based on the parsed features. The grasping strategy generated by the proposed approach is evaluated both by simulation study and execution of the grasps on an AR10 robotic hand.


Title: PRISM: Pose Registration for Integrated Semantic Mapping
Abstract: Many robotics applications involve navigating to positions specified in terms of their semantic significance. A robot operating in a hotel may need to deliver room service to a named room. In a hospital, it may need to deliver medication to a patient's room. The Building-Wide Intelligence Project at UT Austin has been developing a fleet of autonomous mobile robots, called BWIBots, which perform tasks in the computer science department. Tasks include guiding a person, delivering a message, or bringing an object to a location such as an office, lecture hall, or classroom. The process of constructing a map that a robot can use for navigation has been simplified by modern SLAM algorithms. The attachment of semantics to map data, however, remains a tedious manual process of labeling locations in otherwise automatically generated maps. This paper introduces a system called PRISM to automate a step in this process by enabling a robot to localize door signs - a semantic markup intended to aid the human occupants of a building - and to annotate these locations in its map.


Title: 3D Deep Object Recognition and Semantic Understanding for Visually-Guided Robotic Service
Abstract: For the success of visually-guided robotic errand service, it is critical to ensure dependability under various ill-conditioned visual environments. To this end, we have developed Adaptive Bayesian Recognition Framework in which in-situ selection of multiple sets of optimal features or evidences as well as proactive collection of sufficient evidences are proposed to implement the principle of dependability. The framework has shown excellent performance with a limited number of objects in a scene. However, there arises a need to extend the framework for handling a larger number of objects without performance degradation, while avoiding difficulty in feature engineering. To this end, a novel deep learning architecture, referred to here as FER-CNN, is introduced and integrated into the Adaptive Bayesian Recognition Framework. FER-CNN has capability of not only extracting but also reconstructing a hierarchy of features with the layer-wise independent feedback connections that can be trained. Reconstructed features representing parts of 3D objects then allow them to be semantically linked to ontology for exploring object categories and properties. Experiments are conducted in a home environment with real 3D daily-life objects as well as with the standard ModelNet dataset. In particular, it is shown that FER-CNN allows the number of objects and their categories to be extended by 10 and 5 times, respectively, while registering the recognition rate for ModelNet10 and ModelNet40 by 97% and 89.5%, respectively.


Title: Semantic Mapping with Simultaneous Object Detection and Localization
Abstract: We present a filtering-based method for semantic mapping to simultaneously detect objects and localize their 6 degree-of-freedom pose. For our method, called Contextual Temporal Mapping (or CT-Map), we represent the semantic map as a belief over object classes and poses across an observed scene. Inference for the semantic mapping problem is then modeled in the form of a Conditional Random Field (CRF). CT-Map is a CRF that considers two forms of relationship potentials to account for contextual relations between objects and temporal consistency of object poses, as well as a measurement potential on observations. A particle filtering algorithm is then proposed to perform inference in the CT-Map model. We demonstrate the efficacy of the CT-Map method with a Michigan Progress Fetch robot equipped with a RGB-D sensor. Our results demonstrate that the particle filtering based inference of CT-Map provides improved object detection and pose estimation with respect to baseline methods that treat observations as independent samples of a scene.


Title: Optimization-based Design and Analysis of Planar Rotary Springs
Abstract: This paper develops new methods to design high performance rotary series elastic actuator springs for robotics applications. The approach is based on a spring arm mathematical model that was previously introduced by the authors. The key contribution is the development of an optimization-based design method which maximizes the springs' overall torque density through optimization of the arm profile. An improved analysis algorithm allows for rapid torsional loading response simulation with possible internal contacts between the spring arms. The proposed design and analysis algorithms are validated through FEA and prototype mechanical testing.


Title: Design of a 2 Motor 2 Degrees-of-Freedom Coupled Tendon-driven Joint Module
Abstract: A 2 motor 2 degrees-of-freedom (2M2D) coupled tendon driven joint module is proposed as a basic component for robot arms. Torque reallocation via tendon coupling can enhance the output torque of one single joint. According to the motor position, the joint module is classified into four types: the externally-actuated structure, the internally-coaxially-actuated structure, the internally-separately-actuated structure, and the hybrid-actuated structure. The four structures are analyzed and compared, and their implementation design examples are given. Experiments comparing the proposed joint module with directly-actuated traditional joint suggested that the 2M2D coupled tendon-driven joint module can obtain high control accuracy, and the torque reallocation via tendon coupling is effective to improve output torque. Additionally, an anthropomorphic robot arm with low weight and high payload was developed to show the utility of the proposed joint module.


Title: A Differential Elastic Joint for Multi-linked Pipeline Inspection Robots
Abstract: This study presents a differential elastic joint for use in multi-linked pipeline inspection robots. Active joints to stretch against the pipe wall are essential for adapting robots to use in vertical pipes and slippery inner surfaces where a large traction force is required. Series elastic actuators with a high reduction system have typically been used to sense force/torque in such applications. However, compactness, power, and bi-directional series elasticity are required to conduct in-pipe inspections. In this study, we propose an active joint using a differential elastic actuator with a rubber spring for decreasing the size and increasing the stiffness of the joint. After describing the configuration of the differential elastic actuator that is suitable for our robot and the design theory of the rubber spring cross-section, we conducted experiments to verify its torque property.


Title: A Novel Design of Extended Coaxial Spherical Joint Module for a New Modular Type-Multiple DOFs Robotic Platform
Abstract: In this study, we propose an extended coaxial spherical joint module (E-CoSMo) with three to four degrees of freedom (DOFs) for a multi-DOF robot platform. The E-CoSMo consists of a coaxial spherical parallel mechanism (CSPM) with three DOFs and one extended DOF based on a universal joint mechanism (UJM) coaxially connected to the CSPM. This structure enables the application of serial link configuration (such as shoulder-elbow) with wide and universal ROMs while allowing all four actuators to be placed in the base. This makes the inertia of the moving link part to be dramatically reduced and thus contributes to decreasing the mechanical impedance of the multi-DOF robot system. In addition, through the effective design of the coaxial spherical joint module, the output rotational torque in a specific axial direction reaches approximately three times then the torque of a single actuator. To optimally implement this, we applied an optimal design approach that considers the mechanical performance and design constraints. The mechanical impedance reduction effect through the proposed module is discussed. The feasibility of the E-CoSMo is also verified through a dynamic simulation. Finally, the proposed mechanism is verified using a fabricated prototype.


Title: A Novel Cable Actuation Mechanism for 2-DOF Hyper-redundant Bending Robot Composed of Pulleyless Rolling Joints
Abstract: Many surgical robots are remotely actuated by means of wire cables. In the past, the cables wound around circular pulleys at the robot joints did not constitute a problem of the cable driver structure. However, the pulleys inside the joints are removed recently in order to miniaturize the joints, so a specially designed cable driver suitable for the miniature joint structure is required for stable driving. In this paper, we propose a novel cable driver design for driving a pulleyless rolling joint and extend it to 2-DOF structure. Then, the proposed cable driver is manufactured using 3D printing with the 2-DOF bending joint, and an experiment is performed to evaluate them using the prototype. The cable driver proposed in this paper can drive pulleyless rolling joints stably with low cable tension. In addition, it can decouple yaw and pitch motion of the joints completely, therefore it can be applied to a variety of thin robots and instruments including steerable endoscopes and surgical robots.


Title: Design of Robotic Gripper with Constant Transmission Ratio Based on Twisted String Actuator: Concept and Evaluation
Abstract: Robotic systems for object handling and manipulation are hugely important for modern engineering and industry, with their efficiency, agility and robustness often depending on gripper design and performance. In this work, we investigate a gripper design that, when driven by a twisted string actuator, exhibits nearly-constant transmission ratio throughout its motion range. This allows for design of a highly-compact, modular and efficient robotic gripper driven by a low-power motor. We investigate kinematics of the device, experimentally verify developed models with a practical gripper testbed, and analyze transmission ratio and efficiency of the designed device. The resulting system has a nearly-constant transmission ratio of 550, with the constancy coefficient of 0.985.


Title: Stopper Angle Design for a Multi-link Articulated Wheeled In-pipe Robot with Underactuated Twisting Joints
Abstract: In this paper, we present a multi-link articulated wheeled in-pipe robot that can drive the wheel and roll joint by using only a single actuator installed in each link. The proposed mechanism enables the robot to move forward or backward and helically in pipes owing to rotation of the drive wheel and twisting of the body. These two movements are generated by a miter-geared differential mechanism installed in each joint, and the magnitudes of these movements depend on the load applied to the wheels and roll joints. However, controlling of two outputs independently and aligning the rotation of the roll joints as desired are extremely challenging. Therefore, in this study, we switch those two movements by driving the rear wheels and the front wheels of the robot alternately. In addition, a stopper is used to constrain the roll joint movement. By calculating the angle of elevation of the robot's helical movement in the pipe by using a kinematic model, we can design a stopper to precisely adjust the roll angle. We verified that the robot can twist using the differential mechanism, and we validated experimentally the effectiveness of the stopper.


Title: Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning
Abstract: In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.


Title: C-blox: A Scalable and Consistent TSDF-based Dense Mapping Approach
Abstract: In many applications, maintaining a consistent dense map of the environment is key to enabling robotic platforms to perform higher level decision making. Several works have addressed the challenge of creating precise dense 3D maps from visual sensors providing depth information. However, during operation over longer missions, reconstructions can easily become inconsistent due to accumulated camera tracking error and delayed loop closure. Without explicitly addressing the problem of map consistency, recovery from such distortions tends to be difficult. We present a novel system for dense 3D mapping which addresses the challenge of building consistent maps while dealing with scalability. Central to our approach is the representation of the environment as a collection of overlapping Truncated Signed Distance Field (TSDF) subvolumes. These subvolumes are localized through feature-based camera tracking and bundle adjustment. Our main contribution is a pipeline for identifying stable regions in the map, and to fuse the contributing subvolumes. This approach allows us to reduce map growth while still maintaining consistency. We demonstrate the proposed system on a publicly available dataset and simulation engine, and demonstrate the efficacy of the proposed approach for building consistent and scalable maps. Finally we demonstrate our approach running in real-time onboard a lightweight Micro Aerial Vehicle (MAV).


Title: A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform
Abstract: Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.


Title: Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments
Abstract: In this paper we propose a particle filter localization approach, based on stereo visual odometry (VO) and semantic information from indoor environments, for mini-aerial robots. The prediction stage of the particle filter is performed using the 3D pose of the aerial robot estimated by the stereo VO algorithm. This predicted 3D pose is updated using inertial as well as semantic measurements. The algorithm processes semantic measurements in two phases; firstly, a pre-trained deep learning (DL) based object detector is used for real time object detections in the RGB spectrum. Secondly, from the corresponding 3D point clouds of the detected objects, we segment their dominant horizontal plane and estimate their relative position, also augmenting a prior map with new detections. The augmented map is then used in order to obtain a drift free pose estimate of the aerial robot. We validate our approach in several real flight experiments where we compare it against ground truth and a state of the art visual SLAM approach.


Title: Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning
Abstract: Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.


Title: Real-Time Dance Generation to Music for a Legged Robot
Abstract: The development of robots that can dance has received considerable attention. However, they are often either limited to a pre-defined set of movements and music or demonstrate little variance when reacting to external stimuli, such as microphone or camera input. In this paper, we contribute with a novel approach allowing a legged robot to listen to live music while dancing in synchronization with the music in a diverse fashion. This is achieved by extracting the beat from an onboard microphone in real-time, and subsequently creating a dance choreography by picking from a user-generated dance motion library at every new beat. Dance motions include various stepping and base motions. The process of picking from the library is defined by a probabilistic model, namely a Markov chain, that depends on the previously picked dance motion and the current music tempo. Finally, delays are determined online by time-shifting a measured signal and a reference signal, and minimizing the least squares error with the time-shift as parameter. Delays are then compensated for by using a combined feedforward and feedback delay controller which shifts the robot whole-body controller reference input in time. Results from experiments on a quadrupedal robot demonstrate the fast convergence and synchrony to the perceived music.


Title: Semantically Meaningful View Selection
Abstract: An understanding of the nature of objects could help robots to solve both high-level abstract tasks and improve performance at lower-level concrete tasks. Although deep learning has facilitated progress in image understanding, a robot's performance in problems like object recognition often depends on the angle from which the object is observed. Traditionally, robot sorting tasks rely on a fixed top-down view of an object. By changing its viewing angle, a robot can select a more semantically informative view leading to better performance for object recognition. In this paper, we introduce the problem of semantic view selection, which seeks to find good camera poses to gain semantic knowledge about an observed object. We propose a conceptual formulation of the problem, together with a solvable relaxation based on clustering. We then present a new image dataset consisting of around 10k images representing various views of 144 objects under different poses. Finally we use this dataset to propose a first solution to the problem by training a neural network to predict a “semantic score” from a top view image and camera pose. The views predicted to have higher scores are then shown to provide better clustering results than fixed top-down views.


Title: Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots
Abstract: This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.


Title: Kitting in the Wild through Online Domain Adaptation
Abstract: Technological developments call for increasing perception and action capabilities of robots. Among other skills, vision systems that can adapt to any possible change in the working conditions are needed. Since these conditions are unpredictable, we need benchmarks which allow to assess the generalization and robustness capabilities of our visual recognition algorithms. In this work we focus on robotic kitting in unconstrained scenarios. As a first contribution, we present a new visual dataset for the kitting task. Differently from standard object recognition datasets, we provide images of the same objects acquired under various conditions where camera, illumination and background are changed. This novel dataset allows for testing the robustness of robot visual recognition algorithms to a series of different domain shifts both in isolation and unified. Our second contribution is a novel online adaptation algorithm for deep models, based on batch-normalization layers, which allows to continuously adapt a model to the current working conditions. Differently from standard domain adaptation algorithms, it does not require any image from the target domain at training time. We benchmark the performance of the algorithm on the proposed dataset, showing its capability to fill the gap between the performances of a standard architecture and its counterpart adapted offline to the given target domain.


Title: Compact & Comprehensive Canonical Appearances Discovered Autonomously
Abstract: This paper presents an exploration approach for discovering canonical appearances in unknown environments using an autonomous ground robot equipped with a depth sensor. This approach is based on the previously proposed two-stage algorithm that alternates between local and global decision making for efficient topological mapping based on bubble space representation. Differing from it, the approach aims to identify vantage viewpoints with characterizing views for subsequent appearance-based learning as well as achieving complete coverage. This is demonstrated by a series of experiments using an outdoor benchmark data set including a comparative study with evaluation metrics including the exploration path length and number of canonical appearances discovered.


Title: Hybrid Multi-camera Visual Servoing to Moving Target
Abstract: Visual servoing is a well-known task in robotics. However, there are still challenges when multiple visual sources are combined to accurately guide the robot or occlusions appear. In this paper we present a novel visual servoing approach using hybrid multi-camera input data to lead a robot arm accurately to dynamically moving target points in the presence of partial occlusions. The approach uses four RGBD sensors as Eye-to-Hand (EtoH) visual input, and an arm-mounted stereo camera as Eye-in-Hand (EinH). A Master supervisor task selects between using the EtoH or the EinH, depending on the distance between the robot and target. The Master also selects the subset of EtoH cameras that best perceive the target. When the EinH sensor is used, if the target becomes occluded or goes out of the sensor's view-frustum, the Master switches back to the EtoH sensors to re-track the object. Using this adaptive visual input data, the robot is then controlled using an iterative planner that uses position, orientation and joint configuration to estimate the trajectory. Since the target is dynamic, this trajectory is updated every time-step. Experiments show good performance in four different situations: tracking a ball, targeting a bulls-eye, guiding a straw to a mouth and delivering an item to a moving hand. The experiments cover both simple situations such as a ball that is mostly visible from all cameras, and more complex situations such as the mouth which is partially occluded from some of the sensors.


Title: Detecting and Picking of Folded Objects with a Multiple Sensor Integrated Robot Hand
Abstract: Robotic picking of folded objects such as books is required for picking various objects. As a folded object is easily unfolded, it is difficult to carry it stably and place it in a desired pose due to its dangling part. For overcoming this difficulty, we propose a trial-and-error picking system using our Suction Pinching Hand, which can push the dangling part up with pinch grasp until the object lifted with suction grasp is folded. That system utilizes proximity sensors on the hand to predict whether folding will succeed with a current hand pose and decide whether to retry with another pose. Also, proximity sensors, flex sensors and an air pressure sensor are used to deal with uncertainty of the image recognition, the hand hardware and suction grasp. We evaluate our proposed system with experiments of picking and placing folded objects. It is confirmed that our proposed system realizes picking with the ability of our Suction Pinching Hand to carry folded objects stably and place them in desired poses. It is also proved that our proposed system is robust against the uncertainty.


Title: Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition
Abstract: Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.


Title: DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments
Abstract: Simultaneous Localization and Mapping (SLAM) is considered to be a fundamental capability for intelligent mobile robots. Over the past decades, many impressed SLAM systems have been developed and achieved good performance under certain circumstances. However, some problems are still not well solved, for example, how to tackle the moving objects in the dynamic environments, how to make the robots truly understand the surroundings and accomplish advanced tasks. In this paper, a robust semantic visual SLAM towards dynamic environments named DS-SLAM is proposed. Five threads run in parallel in DS-SLAM: tracking, semantic segmentation, local mapping, loop closing and dense semantic map creation. DS-SLAM combines semantic segmentation network with moving consistency check method to reduce the impact of dynamic objects, and thus the localization accuracy is highly improved in dynamic environments. Meanwhile, a dense semantic octo-tree map is produced, which could be employed for high-level tasks. We conduct experiments both on TUM RGB-D dataset and in real-world environment. The results demonstrate the absolute trajectory accuracy in DS-SLAM can be improved one order of magnitude compared with ORB-SLAM2. It is one of the state-of-the-art SLAM systems in high-dynamic environments.


Title: HMAPs - Hybrid Height- Voxel Maps for Environment Representation
Abstract: This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.


Title: Kalman Filter Based Observer for an External Force Applied to Medium-sized Humanoid Robots
Abstract: External force observer for humanoid robots has been widely studied in the literature. However, most of the proposed approaches generally rely on information from six-axis force/torque sensors, which the small or medium-sized humanoid robots usually do not have. As a result, those approaches cannot be applied to this category of humanoid robots, which is widely used nowadays in education or research. In this paper, we improve the external force observer in [1] to handle the case of an external force applied in any direction and at an arbitrary point of the robot structure. The new observer is based on Kalman filter formulation and it allows the estimation of the three force components. The observer is simple to implement and can easily run in real time using the embedded processor of a medium-sized humanoid robot such as Nao or Darwin-OP. Moreover, the observer does not require any change to the robot hardware as it only uses measurements from the available force-sensing resistors (FSR) inserted under the feet of the humanoid robot and from the robot inertial measurement unit (IMU). The proposed observer was extensively validated on a Nao humanoid robot. In all conducted experiments, the observer successfully estimated the external force within a reasonable margin of error.


Title: CPG-based Controllers can Generate Both Discrete and Rhythmic Movements
Abstract: Complex tasks require the combination of both discrete and rhythmic movements. Though scientists do not yet agree on the neural architecture involved in both types and in the transition from one to the other, the importance of having robot controllers able to behave rhythmically and discretely is universally recoanized. In this paper, a bio-inspired robot controller based on oscillating neurons is proposed to realize both discrete and rhythmic movements and easily transition from one to the other. It is shown that, under certain parameter conditions, the CPG controller behaves like a PID controller. In order to demonstrate the feasibility of controlling both discrete and rhythmic movements, the CPG is applied to the initiation of handshaking, namely, reach towards the human hand and start to shake it. Results show that this architecture is suitable for both discrete and rhythmic movements and can easily transition from one to the other.


Title: Exploiting Friction in Torque Controlled Humanoid Robots
Abstract: A common architecture for torque controlled humanoid robots consists in two nested loops. The outer loop generates desired joint/motor torques, and the inner loop stabilizes these desired values. In doing so, the inner loop usually compensates for joint friction phenomena, thus removing their inherent stabilizing property that may be also beneficial for high level control objectives. This paper shows how to exploit friction for joint and task space control of humanoid robots. Experiments are carried out on the humanoid robot iCub.


Title: Structure preserving Multi-Contact Balance Control for Series-Elastic and Visco-Elastic Humanoid Robots
Abstract: This paper proposes an integration of multi-body and actuator control for multi-contact balancing for robots with highly elastic joints. Inspired by the structure preserving control concept for series-elastic fixed-base robots, the presented approach aims to minimize the control effort by keeping the system structure intact. Balancing on multiple contacts requires to solve the force distribution problem. In locomotion, contacts change quickly, requiring a swift redistribution of contact forces. This is a challenge for elastic robots as the actuator dynamics and limits prevent instantaneous changes of contact forces. The proposed dynamically consistent force distribution is implemented as a model predictive controller which resolves redundancy while complying with contact force and actuator constraints.


Title: Feedback Control For Cassie With Deep Reinforcement Learning
Abstract: Bipedal locomotion skills are challenging to develop. Control strategies often use local linearization of the dynamics in conjunction with reduced-order abstractions to yield tractable solutions. In these model-based control strategies, the controller is often not fully aware of many details, including torque limits, joint limits, and other non-linearities that are necessarily excluded from the control computations for simplicity. Deep reinforcement learning (DRL) offers a promising model-free approach for controlling bipedal locomotion which can more fully exploit the dynamics. However, current results in the machine learning literature are often based on ad-hoc simulation models that are not based on corresponding hardware. Thus it remains unclear how well DRL will succeed on realizable bipedal robots. In this paper, we demonstrate the effectiveness of DRL using a realistic model of Cassie, a bipedal robot. By formulating a feedback control problem as finding the optimal policy for a Markov Decision Process, we are able to learn robust walking controllers that imitate a reference motion with DRL. Controllers for different walking speeds are learned by imitating simple time-scaled versions of the original reference motion. Controller robustness is demonstrated through several challenging tests, including sensory delay, walking blindly on irregular terrain and unexpected pushes at the pelvis. We also show we can interpolate between individual policies and that robustness can be improved with an interpolated policy.


Title: Robust and Stretched-Knee Biped Walking Using Joint-Space Motion Control
Abstract: Comparing to IK (Inverse Kinematics) based motion control, joint-space motion control is more advantageous in terms of not being restricted by kinematics singularity problem. In this paper, we start with SIMBICON (Simple Biped Locomotion Control) based controller, a joint-space motion control method, extend it for enhancing walking's robustness and versatility. We propose a motion optimization method considering walking robustness, desired walking velocity and energy efficient minimization for walking motion generation. This method enables us to achieve human-like walking motion, which has stretched-knee posture and robust to large push disturbances. We also apply our proposed method to a life-sized biped robot and validate its effectiveness with push recovery and walking on unknown debris experiments.


Title: Public perception of android robots: Indications from an analysis of YouTube comments
Abstract: The public perception of android robots is a field of growing applied relevance. Currently, most androids are confined within controlled environments rendering interactions between potential end-users, and robots challenging. Even more challenging is for researchers to investigate end-users' perception of androids. We exploit pre-existing YouTube comments as artifacts for quantitative content analysis to gain an indication of social perception on androids. We perform a content analysis of 10301 YouTube comments from four different videos, and reflect on the textual reactions to video stimuli of four extremely human-like android robots. We use text mining and machine learning techniques to process and analyze our corpus. Our findings reveal three equally important topics that should be considered for paving the way towards a robotic society: human-robot relationships, technical specifications, and the science fiction valley. Considering people's attitudes, fears and wishes towards androids, researchers can increase citizen awareness, and engagement.


Title: Towards Automatic 3D Shape Instantiation for Deployed Stent Grafts: 2D Multiple-class and Class-imbalance Marker Segmentation with Equally-weighted Focal U-Net
Abstract: Robot-assisted Fenestrated Endovascular Aortic Repair (FEVAR) is currently navigated by 2D fluoroscopy which is insufficiently informative. Previously, a semi-automatic 3D shape instantiation method was developed to instantiate the 3D shape of a main, deployed, and fenestrated stent graft from a single fluoroscopy projection in real-time, which could help 3D FEVAR navigation and robotic path planning. This proposed semi-automatic method was based on the Robust Perspective-S-Point (RP5P) method, graft gap interpolation and semiautomatic multiple-class marker center determination. In this paper, an automatic 3D shape instantiation could be achieved by automatic multiple-class marker segmentation and hence automatic multiple-class marker center determination. Firstly, the markers were designed into five different shapes. Then, Equally-weighted Focal U-Net was proposed to segment the fluoroscopy projections of customized markers into five classes and hence to determine the marker centers. The proposed Equally-weighted Focal U-Net utilized U-Net as the network architecture, equally-weighted loss function for initial marker segmentation, and then equally-weighted focal loss function for improving the initial marker segmentation. This proposed network outperformed traditional Weighted U-Net on the class-imbalance segmentation in this paper with reducing one hyperparameter - the weight. An overall mean Intersection over Union (mIoU) of 0.6943 was achieved on 78 testing images, where 81.01 % markers were segmented with a center position error <; 1.6mm. Comparable accuracy of 3D shape instantiation was also achieved and stated. The data, trained models and TensorFlow codes are available on-line.


Title: A Confidence-Based Shared Control Strategy for the Smart Tissue Autonomous Robot (STAR)
Abstract: Autonomous robotic assisted surgery (RAS) systems aim to reduce human errors and improve patient outcomes leveraging robotic accuracy and repeatability during surgical procedures. However, full automation of RAS in complex surgical environments is still not feasible and collaboration with the surgeon is required for safe and effective use. In this work, we utilize our Smart Tissue Autonomous Robot (STAR) to develop and evaluate a shared control strategy for the collaboration of the robot with a human operator in surgical scenarios. We consider 2D pattern cutting tasks with partial blood occlusion of the cutting pattern using a robotic electrocautery tool. For this surgical task and RAS system, we i) develop a confidence-based shared control strategy, ii) assess the pattern tracking performances of manual and autonomous controls and identify the confidence models for human and robot as well as a confidence-based control allocation function, and iii) experimentally evaluate the accuracy of our proposed shared control strategy. In our experiments on porcine fat samples, by combining the best elements of autonomous robot controller with complementary skills of a human operator, our proposed control strategy improved the cutting accuracy by 6.4%, while reducing the operator work time to 44% compared to a pure manual control.


Title: Magnetic- Visual Sensor Fusion-based Dense 3D Reconstruction and Localization for Endoscopic Capsule Robots
Abstract: Reliable and real-time 3D reconstruction and localization functionality is a crucial prerequisite for the navigation of actively controlled capsule endoscopic robots as an emerging, minimally invasive diagnostic and therapeutic technology for use in the gastrointestinal (GI) tract. In this study, we propose a fully dense, non-rigidly deformable, strictly real-time, intraoperative map fusion approach for actively controlled endoscopic capsule robot applications which combines magnetic and vision-based localization, with non-rigid deformations based frame-to-model map fusion. The performance of the proposed method is evaluated using four different ex-vivo porcine stomach models. Across different trajectories of varying speed and complexity, and four different endoscopic cameras, the root mean square surface reconstruction errors vary from 1.58 to 2.17 cm.


Title: Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties
Abstract: Alignment of two point clouds is an essential problem in medical robotics and computer-assisted surgery. In this paper, we first formally formulate the generalized point cloud registration problem in a probabilistic manner. Specifically, not only positional but also the orientational information are incorporated into registration. Notably, the positional error is assumed to obey a multivariate Gaussian distribution to accommodate anisotropic cases. Expectation conditional maximization framework is utilized to solve the problem. In E-step, the correspondence probabilities between points in two generalized point clouds are computed. In M -step, the constrained optimization problem with respect to the transformation matrix is re-formulated as an unconstrained one. Extensive experiments are conducted to compare the proposed algorithm with the state-of-the-art registration methods. The experimental results demonstrate the algorithm's robustness to noise and outliers, fast convergence speed.


Title: Vision-Based Surgical Tool Pose Estimation for the da Vinci® Robotic Surgical System
Abstract: This paper presents an approach to surgical tool tracking using stereo vision for the da Vinci® Surgical Robotic System. The proposed method is based on robot kinematics, computer vision techniques and Bayesian state estimation. The proposed method employs a silhouette rendering algorithm to create virtual images of the surgical tool by generating the silhouette of the defined tool geometry under the da Vinci® robot endoscopes. The virtual rendering method provides the tool representation in image form, which makes it possible to measure the distance between the rendered tool and real tool from endoscopic stereo image streams. Particle Filter algorithm employing the virtual rendering method is then used for surgical tool tracking. The tracking performance is evaluated on an actual da Vinci® surgical robotic system and a ROS/Gazebo-based simulation of the da Vinci® system.


Title: A Parallel Robotic Mechanism for the Stabilization and Guidance of an Endoscope Tip in Laser Osteotomy
Abstract: This paper presents a parallel robotic mechanism for endoscope tip stabilization and guidance for a robot-assisted minimally invasive laser osteotome. The mechanism attaches to the bone of the patient, providing a stable and robust platform for the laser integrated in the endoscope tip which has to be moved precisely in the sub-millimeter range along a preoperatively planned path. This method is only possible because cutting bone with laser instead of using conventional bone drills and saws involves considerably lower interaction forces. The design, kinematics, control, and motion performance of the concept are presented for an upscaled prototype. The obtained deviation of the endoscope tip motion from the reference path lies in the sub-millimeter range. This result allows us to conclude that the concept is more than promising. Furthermore, we expect that the herein presented principle will influence the way osteotomies will be performed in the future.


Title: RoboTracker: Collaborative robotic assistant device with electromechanical patient tracking for spinal surgery
Abstract: Due to the risks of muscle, bone and neural damage in spinal surgical procedures that require pedicle screw fixation, technological improvements have appeared to help surgeons perform the procedures with higher accuracy. Systems based on optical tracking navigation impose a stringent limitation in the workflow of surgeons since a clear line of sight has to be kept between the cameras and the tracked elements. Other solutions are based on mounting a miniature robot on the spine of the patient, which is very invasive and entails some risks. For these reasons, a novel robotic assisted surgery system capable to guide surgical instruments with minimal deviations compensating patient motion is being developed. This paper presents the system and the electromechanical tracking device used to sense patient motion.


Title: A Sliding Mode Control Architecture for Human-Manipulator Cooperative Surface Treatment Tasks
Abstract: This paper presents a control architecture readily suitable for surface treatment tasks such as polishing, grinding, finishing or deburring as carried out by a human operator, with the added benefit of accuracy, recurrence and physical strength as administered by a robotic manipulator partner. The shared strategy effectively couples the human operator propioceptive abilities and fine skills through his interactions with the autonomous physical agent. The novel proposed control scheme is based on task prioritization and a non-conventional sliding mode control, which is considered to benefit from its inherent robustness and low computational cost. The system relies on two force sensors, one located between the last link of the robot and the surface treatment tool, and the other located in some place of the robot end-effector: the former is used to suitably accomplish the conditioning task, while the latter is used by the operator to manually guide the robotic tool. When the operator chooses to cease guiding the tool, the robot motion safely switches back to an automatic reference tracking. The paper presents the theories for the novel collaborative controller, whilst its effectiveness for robotic surface treatment is substantiated by experimental results using a redundant 7R manipulator and a mock-up conditioning tool.


Title: Human Intention Estimation based on Neural Networks for Enhanced Collaboration with Robots
Abstract: In human-robot collaboration, the robot is required to provide assistance to the user by facilitating task execution. However, due to stability requirements, a well-damped admittance behavior of the robot is necessary during interaction, thus inducing fatigue in the operator. While available schemes involve variable impedance controllers to mitigate this effect, here we propose an alternative approach entailing a proactive robot behavior that assists in the cooperative execution of trajectories towards desired goals, by estimating the user intention. To this end, we make use of Recurrent Neural Networks (RNNs) to predict and classify cooperative motions, on the basis of a set of predefined goals in the workspace and model-based generated data of human movements. Manual guidance validation experiments are conducted on a 6 d.o.f. ABB IRB140 industrial robot equipped with a force sensor.


Title: Variable Admittance Control for Human-Robot Collaboration based on Online Neural Network Training
Abstract: In this paper, a method for variable admittance control in human-robot cooperation is proposed. A multilayer feedforward neural network is designed using the Cartesian velocity of the robot and the applied force by the operator as its inputs to modify online the virtual damping of the admittance controller. The neural network is trained online using the error backpropagation algorithm based on the error between the velocity of the minimum jerk trajectory model and the measured velocity of the robot. The performance of the proposed controller and the NN generalization ability are evaluated by conducting a point-to-point cooperative motion with multiple subjects using the KUKA LWR robot.


Title: Online Human Muscle Force Estimation for Fatigue Management in Human-Robot Co-Manipulation
Abstract: In this paper, we propose a novel method for selective management of muscle fatigue in human-robot co-manipulation. The proposed framework enables the detection of excessive fatigue levels of an individual muscle group while executing a certain task, and provides anticipatory robotic responses to distribute the effort among less-fatigued muscles of human arm. Our approach uses a machine learning technique to enable online predictions of muscle forces in different arm configurations and endpoint interaction forces. The estimated muscle forces are then used for the model-based estimation of muscle fatigue levels. Through optimisation, the fatigue management system can alter the task execution in a way that specific fatigued muscles are offloaded, while at the same time enables the production of task force using muscles with lower levels of fatigue. The main advantage of the proposed method is that it can operate online, and that all the measurements are performed by the robot sensory system, which can significantly increase the applicability in real-world scenarios. To validate the proposed method, we performed proof-of-concept experiments where the task of the human operator was to use a tool to polish an object that was manipulated by the robot.


Title: Evolutionary Motion Control Optimization in Physical Human-Robot Interaction
Abstract: Given that the success of an interaction task depends on the capability of the robot system to handle physical contact with its environment, pure motion control is often insufficient. This is especially true in the context of medical freehand ultrasound where the human body is a deformable surface and an unstructured environment, representing both a safety concern and a challenge for trajectory planning and control. The systematic tuning of practical high degree-of-freedom physical human-robot interaction (pHRI) tasks is not trivial and there are many parameters to be tuned. While traditional tuning is generally performed ad hoc and requires knowledge of the robot and environment dynamics, we propose a simple and effective online tuning framework using differential evolution (DE) to optimize the motion parameters for parallel force/impedance control in a pHRI and medical ultrasound motion application. Through real-world experiments with a KUKA LBR iiwa 7 R800 collaborative robot, the DE framework tuned motion control for optimal and safe trajectories along a human leg phantom. The optimization process was able to successfully reduce the mean absolute error of the motion contact force to 0.537 N through the evolution of eight motion control parameters.


Title: Human-Robot Cooperative Object Manipulation with Contact Changes
Abstract: This paper presents a system for cooperatively manipulating large objects between a human and a robot. This physical interaction system is designed to handle, transport, or manipulate large objects of different shapes in cooperation with a human. Unique points are the bi-manual physical cooperation, the sequential characteristic of the cooperation including contact changes, and a novel architecture combining force interaction cues, interactive search-based planning, and online trajectory and motion generation. The resulting system implements a mixed initiative collaboration strategy, deferring to the human when his intentions are unclear, and driving the task once understood. This results in an easy and intuitive human-robot interaction. It is evaluated in simulations and on a bi-manual mobile robot with 32 degrees of freedom.


Title: From Human Physical Interaction To Online Motion Adaptation Using Parameterized Dynamical Systems
Abstract: In this work, we present an adaptive motion planning approach for impedance-controlled robots to modify their tasks based on human physical interactions. We use a class of parameterized time-independent dynamical systems for motion generation where the modulation of such parameters allows for motion flexibility. To adapt to human interactions, we update the parameters of our dynamical system in order to reduce the tracking error (i.e., between the desired trajectory generated by the dynamical system and the real trajectory influenced by the human interaction). We provide analytical analysis and several simulations of our method. Finally, we investigate our approach through real world experiments with a 7-DOF KUKA LWR 4+ robot performing tasks such as polishing and pick-and-place.


Title: Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy
Abstract: Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.


Title: Robotic Boreblending: The Future of In-Situ Gas Turbine Repair
Abstract: Automation of inspection and repair tasks on complex installations is gaining attention from industries with high-value assets such as aerospace, nuclear and marine. This paper reports on a five degrees of freedom robotic system capable of performing accurate and repeatable repair procedures through a narrow inspection port, which minimizes the cost and downtime associated with unscheduled maintenance. Careful study of the target working volume and repair process informed the design of a robotic probe capable of replicating the operation. Kinematic analysis of the robot's flexible, prismatic and rotary joints was used to define accurate machining paths in 3D space, and the results were verified using an optical motion capture system (accuracy of 0.25 mm). After comprehensive verifications of the constitutive elements, the robotic system was successfully demonstrated for repair of a high-pressure compressor aerofoil in a gas turbine. The results not only proves the ability of the system to address such difficult repair scenarios but also highlights a domain of opportunities in developing specialist robotics for repair of high-value assets, which is a subject to growing global demand.


Title: Design of an Autonomous Robot for Mapping, Navigation, and Manipulation in Underground Mines
Abstract: Underground mines are a dangerous working environment and, therefore, robots could help putting less humans at risk. Traditional robots, sensors, and software often do not work reliably underground due to the harsh environment. This paper analyzes requirements and presents a robot design capable of navigating autonomously underground and manipulating objects with a robotic arm. The robot's base is a robust four wheeled platform powered by electric motors and able to withstand the harsh environment. It is equipped with color and depth cameras, lighting, laser scanners, an inertial measurement unit, and a robotic arm. We conducted two experiments testing mapping and autonomous navigation. Mapping a 75 meters long route including a loop closure results in a map that qualitatively matches the original map to a good extent. Testing autonomous driving on a previously created map of a second, straight, 150 meters long route was also successful. However, without loop closure, rotation errors cause apparent deviations in the created map. These first experiments showed the robot's operability underground.


Title: Design and Performance Evaluation of an Infotaxis-Based Three-Dimensional Algorithm for Odor Source Localization
Abstract: In this paper we tackle the problem of finding the source of a gaseous leak with a robot in a three-dimensional (3-D) physical space. The proposed method extends the operational range of the probabilistic Infotaxis algorithm [1] into 3-D and makes multiple improvements in order to increase its performance in such settings. The method has been tested systematically through high-fidelity simulations and in a wind tunnel emulating realistic conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments. The algorithm shows good performance in various environmental conditions, particularly in high wind speeds and different source release rates.


Title: Cognition-enabled Framework for Mixed Human-Robot Rescue Teams
Abstract: With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.


Title: Pulleys and Force Sensors Influence on Payload Estimation of Cable-Driven Parallel Robots
Abstract: The subject of this paper is about the use of a suspended Cable-Driven Parallel Robot (CDPR) for pick-and-place operations of heavy and heterogeneous objects. The knowledge of the payload mass and its center of mass in realtime is an asset for robust control of the device, which is required to ensure a good stability, especially when the objects have different shapes, sizes and masses. Accordingly, this paper aims at experimentally evaluating the effects of (i) the pulleys modeling and (ii) the use of force sensors for the payload estimation. It turns out that the consideration of the pulleys into the geometric model of the robot improves the mass and center of mass estimations of the payload. A comparison is made between the estimation of cable tensions from force sensors and from motor currents. Finally, a torque controller with a feedforward term for real-time mass compensation is proposed and implemented on a CDPR prototype.


Title: Body-Mounted Robot for Image-Guided Percutaneous Interventions: Mechanical Design and Preliminary Accuracy Evaluation
Abstract: This paper presents a body-mounted, four degree-of-freedom (4-DOF) parallel mechanism robot for image-guided percutaneous interventions. The design of the robot is optimized to be light weight and compact such that it could be mounted to the patient body. It has a modular design that can be adopted for assisting various image-guided, needle-based percutaneous interventions such as arthrography, biopsy and brachytherapy seed placement. The robot mechanism and the control system are designed and manufactured with components compatible with imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT). The current version of the robot presented in this paper is optimized for shoulder arthrography under MRI guidance; a Z-shaped fiducial frame is attached to the robot, providing accurate and repeatable robot registration with the MR scanner coordinate system. Here we present the mechanical design of the manipulator, robot kinematics, robot calibration procedure, and preliminary bench-top accuracy assessment. The bench-top accuracy evaluation of the robotic manipulator shows average translational error of 1.01 mm and 0.96 mm in X and Z axes, respectively, and average rotational error of 3.06 degrees and 2.07 degrees about the X and Z axes, respectively.


Title: HERI II: A Robust and Flexible Robotic Hand based on Modular Finger design and Under Actuation Principles
Abstract: This paper introduces the design of a novel under-actuated hand with highly integrated modular finger units, which can be easily reconfigured in terms of finger arrangement and number to account for the manipulation needs of different applications. Each finger module is powered by a single actuator through an under-actuated transmission and equipped with a sensory system for delicate and precise grasping, which includes absolute position measurements, contact pressure sensing at finger phalanxes and motor current readings. Finally, intrinsic elasticity integrated in the transmission system make the hand robust and adaptive to impacts when interacting with the objects and environment. This highly integrated hand (HERI II) was developed for the Centauro Robot to enable robust and resilient manipulation. A set of experiments demonstrating the hand's grasping performance were carried out and fully verified the design effectiveness of the proposed hand.


Title: Design, Modeling and Control of a Soft Robotic Arm
Abstract: In this paper we present the design of a hybrid robotic arm using soft, inflatable bladders for actuation. Low cost switching valves are used for pressure control, where the valve model is identified experimentally. A model of the robotic arm is derived based on system identification and used to derive a linear quadratic Gaussian controller. A method to solve limitations of the employed switching valves is proposed and experimentally proven to improve tracking performance. The closed loop control performance of the robotic arm is demonstrated by stabilizing a rotational inverted pendulum known as the Furuta pendulum.


Title: Energy-Efficient Design and Control of a Vibro-Driven Robot
Abstract: Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficiency. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller for the driving pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.


Title: Design of Compliant Mechanosensory Composite (CMC) and its Application Toward the Sensible Mesoscale Robotics
Abstract: Sensed information greatly helps a robot to adjust its motion or modulate the locomotory behavior. While many sensing components have been developed for macroscale robots, such off-the-shelf sensors are hardly integrated with a mesoscale (i.e., 0.1 mm to 10 mm) robot due to the size limitation. In this work, we propose a Compliant Mechanosensory Composite (CMC) to fabricate a small compliant mechanism with embedded sensing ability. As the first demonstration of CMC, we directly print a conductive polymer PEDOT:PSS onto the flexible joint of a compliant mechanism to sense the motion of the flexible joint itself. Owing to the variation of electric contact resistance (ECR) upon bending, the CMC could estimate its bending angle. The performance of the CMC was verified by analyzing the cyclic bending, transient and stationary response. Overall, a sparsely printed serpentine pattern with thicker line exhibited consistent response without a noticeable hysteresis. To demonstrate the applicability of the CMC process, a small gripper actuated by a SMA (shape memory alloy) coil was fabricated, and its motion was successfully measured using the embedded sensors. We expect the proposed CMC will enable a small robot to become sensible at its self motion, external load, and physical contacts in future.


Title: Conductive Knit-covered Pneumatic Artificial Muscle (k-PAM) Actuator
Abstract: The paper presents design, fabrication and characteristics of two kinds of conductive Knit-covered Pneumatic Artificial Muscle (it is called as k-PAM in the paper) actuators, in which two different knits are made by braiding silver-coated (conductive) yarn and spandex (non-conductive) yarn with different stitch methods. The k-PAM is able to measure the change in length of the actuator body according to the applied air pressures as well as the strain due to external force. A complete fabrication method is presented to make the actuator work for higher pressure (≥ 300[kPa]). Since the force generated by the actuator is decoupled from the external force, ultimately, it can be directly used to measure not only the length but also the force. Experimental validations are performed describing the characteristics of two different types of k-PAMs. It is expected that the k-PAM can be used directly for robotic applications in higher pressure condition, while the semi-permanent conductive knit provides the actuator with durability in high repetitive operation environment.


Title: Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts
Abstract: The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.


Title: UX 1 system design - A robotic system for underwater mining exploration
Abstract: This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.


Title: The benefits and challenges of robotics in the mineral raw materials sector - an overview
Abstract: Robotics applications in the raw materials sector are becoming increasingly common due to their many perceived benefits. In mining, the extended use of robotics is especially seen in the exploration and exploitation phases, where mineral resources are discovered, extracted and processed. The use of robotics in the mining industry started in the 60s and today it is seen in the automation of material transport or in robotic digging and loading. Potential benefits include improved productivity, decreased production costs, better operational efficiency, increased safety, reduced waste and, ultimately, more value creation. The increasing amount of robotics used in the raw materials sector is coupled with a series of ethical and legal issues, regulatory challenges and policy requirements that affect both producers and end-users of robotic technologies. The benefits and challenges of robotics applications, often overlooked by the stakeholders, can hinder both their integration in the sector and the further development of mining activities, if not properly addressed.


Title: Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System
Abstract: This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.


Title: Model-Based Action Exploration for Learning Dynamic Motion Skills
Abstract: Deep reinforcement learning has achieved great strides in solving challenging motion control tasks. Recently, there has been significant work on methods for exploiting the data gathered during training, but there has been less work on how to best generate the data to learn from. For continuous action domains, the most common method for generating exploratory actions involves sampling from a Gaussian distribution centred around the mean action output by a policy. Although these methods can be quite capable, they do not scale well with the dimensionality of the action space, and can be dangerous to apply on hardware. We consider learning a forward dynamics model to predict the result, (xt+1), of taking a particular action, (u), given a specific observation of the state, (xt). With this model we perform internal lookahead predictions of outcomes and seek actions we believe have a reasonable chance of success. This method alters the exploratory action space, thereby increasing learning speed and enables higher quality solutions to difficult problems, such as robotic locomotion and juggling.


Title: Active Learning based on Data Uncertainty and Model Sensitivity
Abstract: Robots can rapidly acquire new skills from demonstrations. However, during generalisation of skills or transitioning across fundamentally different skills, it is unclear whether the robot has the necessary knowledge to perform the task. Failing to detect missing information often leads to abrupt movements or to collisions with the environment. Active learning can quantify the uncertainty of performing the task and, in general, locate regions of missing information. We introduce a novel algorithm for active learning and demonstrate its utility for generating smooth trajectories. Our approach is based on deep generative models and metric learning in latent spaces. It relies on the Jacobian of the likelihood to detect non-smooth transitions in the latent space, i.e., transitions that lead to abrupt changes in the movement of the robot. When non-smooth transitions are detected, our algorithm asks for an additional demonstration from that specific region. The newly acquired knowledge modifies the data manifold and allows for learning a latent representation for generating smooth movements. We demonstrate the efficacy of our approach on generalising elementary skills, transitioning across different skills, and implicitly avoiding collisions with the environment. For our experiments, we use a simulated pendulum where we observe its motion from images and a 7-DoF anthropomorphic arm.


Title: Deep Reinforcement Learning for Audio-Visual Gaze Control
Abstract: We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.


Title: An Ensemble with Shared Representations Based on Convolutional Networks for Continually Learning Facial Expressions
Abstract: Social robots able to continually learn facial expressions could progressively improve their emotion recognition capability towards people interacting with them. Semi-supervised learning through ensemble predictions is an efficient strategy to leverage the high exposure of unlabelled facial expressions during human-robot interactions. Traditional ensemble-based systems, however, are composed of several independent classifiers leading to a high degree of redundancy, and unnecessary allocation of computational resources. In this paper, we proposed an ensemble based on convolutional networks where the early layers are strong low-level feature extractors, and their representations shared with an ensemble of convolutional branches. This results in a significant drop in redundancy of low-level features processing. Training in a semi-supervised setting, we show that our approach is able to continually learn facial expressions through ensemble predictions using unlabelled samples from different data distributions.


Title: Deep Q-Learning for Dry Stacking Irregular Objects
Abstract: We propose a reinforcement learning approach for automatically building dry stacked (i.e. no mortar) structures with irregular objects. Stacking irregular objects is a challenging problem since each assembly action can be drawn from a continuous space of poses for an object, and several local geometric and physical considerations strongly affect the stability. To tackle this challenge, we concentrate on a simplified 2D version of the problem. We present a reinforcement learning algorithm based on deep Q-learning, where the learned Q-function, which maps state-action pairs into expected long-term rewards, is represented by a deep neural network. As the action space is continuous the Q-network is trained by sampling a finite number of actions that consider both geometric and physical constraints to approximate the target Q-values, Experiments show that the proposed method outperforms previous heuristics-based planning, leading to super construction with objects containing a significant amount of variations. We validate the generated stacking plans by executing them using a robot arm and manufactured, irregular objects.


Title: Learning Actionable Representations from Visual Observations
Abstract: In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.


Title: Efficient Distributed Torque Computation for Large Scale Robot Skin
Abstract: The realization of a kinesthetic robot behavior using robot skin requires a reactive skin torque controller, which fuses skin information and robot information to an appropriate skin joint torque in real-time. This fusion of information in real-time is challenging when deploying large scale skin. In this paper, we present a system which efficiently computes the torque of distributed skin cells locally at the point of contacts, completely removing this complex computations from the real-time loop. We demonstrate the feasibility of realizing the skin joint torque computations on the local micro-controllers of the skin cells. Conducting experiments with a real robot, we compare the accuracy of the distributed skin joint torque computation with the computation on the control PC. We also show that the novel distributed approach completely eliminates the computational delay of computing skin joint torques in the robot's real-time control loop. As a result, this approach removes any limits for the maximum number of skin cells in control.


Title: A Robust and Efficient Dynamic Network Protocol for a large-scale artificial robotic skin
Abstract: Artificial robotic skins are continuously in contact with their environment, and therefore highly rely on proper connections in their skin cells' network. With a static network protocol approach, the affected skin area is unusable after a connection failure. Therefore, we developed a dynamic network protocol for large-scale artificial robotic skins, which re-routes the network upon connection failures to keep the whole skin in operation. Furthermore, the protocol balances the load for driving larger skins without packet loss. For verification, we validated the protocol on a large artificial robot skin we have developed and analyzed its performance with a skin network consisting of up to 204 cells. The failure recovery of the protocol converges in at most 50ms. We showed that the balancing method achieves a packet loss reduction of over 30% compared to the previously used protocol.


Title: 3D Shape Perception from Monocular Vision, Touch, and Shape Priors
Abstract: Perceiving accurate 3D object shape is important for robots to interact with the physical world. Current research along this direction has been primarily relying on visual observations. Vision, however useful, has inherent limitations due to occlusions and the 2D-3D ambiguities, especially for perception with a monocular camera. In contrast, touch gets precise local shape information, though its efficiency for reconstructing the entire shape could be low. In this paper, we propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories. We use vision first, applying neural networks with learned shape priors to predict an object's 3D shape from a single-view color image. We then use tactile sensing to refine the shape; the robot actively touches the object regions where the visual prediction has high uncertainty. Our method efficiently builds the 3D shape of common objects from a color image and a small number of tactile explorations (around 10). Our setup is easy to apply and has potentials to help robots better perform grasping or manipulation tasks on real-world objects.


Title: Exploration and Reconstruction of Unknown Objects using a Novel Normal and Contact Sensor
Abstract: Tactile sensing of surface normals is essential for exploration of unknown objects. Many tactile sensors have been developed for contact measurement. However, few of these sensors provide surface orientation, and only up to a limited degree. This paper presents a novel contact and surface orientation sensor concept and its application for surface reconstruction of unknown objects. The sensor is comprised of an Inertial Measurement Unit (IMU) and a pressure sensor to accurately estimate the surface orientation in a wide range, while at the same time measuring contact force. We describe the developed sensor prototype and evaluate its performance regarding contact detection capability and normal estimation accuracy. We use this to reconstruct the surface of unknown objects using the humanoid robot ARMAR-III resulting in a mean reconstruction accuracy of 3.6 mm.


Title: Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides
Abstract: In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.


Title: Realtime State Estimation with Tactile and Visual Sensing for Inserting a Suction-held Object
Abstract: We develop a real-time state estimation system to recover the pose and contact formation of an object relative to its environment. In this paper, we focus on the application of inserting an object picked by a suction cup into a tight space, a key technology for robotic packaging. We propose a framework that fuses tactile and visual sensing. Visual sensing is versatile and non-intrusive, but suffers from occlusions and limited accuracy, especially for tasks involving contact. Tactile sensing is local, but provides accuracy and robustness to occlusions. The proposed algorithm to fuse them is based on iSAM, an on-line estimation technique, which we use to incorporate kinematic measurements from the robot, contact geometry of the object and the container, and visual tracking. In this paper, we generalize previous results in planar settings [1] to a 3D task with more complex contact interactions. A key challenge is that we do not observe contact locations between the suction-held object and the container directly. We propose a data-driven method to infer the contact formation, which is then used in real-time by the state estimator. We demonstrate and evaluate the algorithm in a setup instrumented to provide groundtruth.


Title: Finding safe 3D robot grasps through efficient haptic exploration with unscented Bayesian optimization and collision penalty
Abstract: Robust grasping is a major, and still unsolved, problem in robotics. Information about the 3D shape of an object can be obtained either from prior knowledge (e.g., accurate models of known objects or approximate models of familiar objects) or real-time sensing (e.g., partial point clouds of unknown objects) and can be used to identify good potential grasps. However, due to modeling and sensing inaccuracies, local exploration is often needed to refine such grasps and successfully apply them in the real world. The recently proposed unscented Bayesian optimization technique can make such exploration safer by selecting grasps that are robust to uncertainty in the input space (e.g., inaccuracies in the grasp execution). Extending our previous work on 2D optimization, in this paper we propose a 3D haptic exploration strategy that combines unscented Bayesian optimization with a novel collision penalty heuristic to find safe grasps in a very efficient way: while by augmenting the search-space to 3D we are able to find better grasps, the collision penalty heuristic allows us to do so without increasing the number of exploration steps.


Title: Navigation without localisation: reliable teach and repeat based on the convergence theorem
Abstract: We present a novel concept for teach-and-repeat visual navigation. The proposed concept is based on a mathematical model, which indicates that in teach-and-repeat navigation scenarios, mobile robots do not need to perform explicit localisation. Rather than that, a mobile robot which repeats a previously taught path can simply “replay” the learned velocities, while using its camera information only to correct its heading relative to the intended path. To support our claim, we establish a position error model of a robot, which traverses a taught path by only correcting its heading. Then, we outline a mathematical proof which shows that this position error does not diverge over time. Based on the insights from the model, we present a simple monocular teach-and-repeat navigation method. The method is computationally efficient, it does not require camera calibration, and it can learn and autonomously traverse arbitrarily-shaped paths. In a series of experiments, we demonstrate that the method can reliably guide mobile robots in realistic indoor and outdoor conditions, and can cope with imperfect odometry, landmark deficiency, illumination variations and naturally-occurring environment changes. Furthermore, we provide the navigation system and the datasets gathered at www.github.com/gestom/stroll_bearnav.


Title: Accurate Mix-Norm-Based Scan Matching
Abstract: Highly accurate mapping and localization is of prime importance for mobile robotics, and its core lies in efficient scan matching. Previous research are focusing on designing a robust objective function and the residual error distribution is often ignored or simply assumed as unitary or mixture of simple distributions. In this paper, a mixture of exponential power (MoEP) distributions is proposed to approximate the residual error distribution. The objective function induced by MoEP-based residual error modelling ensembles a mix-norm-based scan matching (MiNoM), which enhances the matching accuracy and convergence characteristic. Both the parameters of transformation (rotation and translation) and residual error distribution are estimated efficiently via an EM-like algorithm. The optimization of MiNoM is iteratively achieved via two phases: An on-line parameter learning (OPL) phase to learn residual error distribution for better representation according to the likelihood field model (LFM), and an iteratively reweighted least squares (IRLS) phase to attain transformation for accuracy and efficiency. Extensive experimental results validate that the proposed MiNoM out-performs several state-of-the-art scan matching algorithms in both convergence characteristic and matching accuracy.


Title: StreetMap - Mapping and Localization on Ground Planes using a Downward Facing Camera
Abstract: This paper describes a system to map a ground-plane, and to subsequently use the map for localization of a mobile robot. The robot has a downward-facing camera, and works on a variety of ground textures including general texture like tarmac, man-made designs like carpet, and rectilinear textures like indoor tiles or outdoor slabs. Such textures provide a basis for measuring relative motion (i.e. computer mouse functionality). But the goal here is the more challenging one of absolute localization. The paper describes a complete working pipeline to build a globally consistent map of a given ground-plane and subsequently to localize within this map at real-time. Two algorithms are described. The first is a feature-based approach which is general to any ground plane texture. The second algorithm takes advantage of the extra constraints available for common rectilinear textures like indoor tiling, paving slabs, and laid brickwork. Quantitative and qualitative experimental results are shown for mapping and localization on a variety of ground-planes.


Title: The TUM VI Benchmark for Evaluating Visual-Inertial Odometry
Abstract: Visual odometry and SLAM methods have a large variety of applications in domains such as augmented reality or robotics. Complementing vision sensors with inertial measurements tremendously improves tracking accuracy and robustness, and thus has spawned large interest in the development of visual-inertial (VI) odometry approaches. In this paper, we propose the TUM VI benchmark, a novel dataset with a diverse set of sequences in different scenes for evaluating VI odometry. It provides camera images with 1024×1024 resolution at 20 Hz, high dynamic range and photometric calibration. An IMU measures accelerations and angular velocities on 3 axes at 200 Hz, while the cameras and IMU sensors are time-synchronized in hardware. For trajectory evaluation, we also provide accurate pose ground truth from a motion capture system at high frequency (120 Hz) at the start and end of the sequences which we accurately aligned with the camera and IMU measurements. The full dataset with raw and calibrated data is publicly available. We also evaluate state-of-the-art VI odometry approaches on our dataset.


Title: Scale-Robust Localization Using General Object Landmarks
Abstract: Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3× difference in scale between map and query images. We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change. This technique is training-free and class-agnostic, and in principle can be deployed in any environment out-of-the-box. We evaluate the proposed technique on the KITTI Odometry benchmark and on a novel dataset of outdoor images exhibiting changes in visual scale of 7× and greater, which we have released to the public. Our technique consistently outperforms localization using either SIFT features or the proposed object features alone, achieving both greater accuracy and much lower failure rates under large changes in scale.


Title: Invariant smoothing on Lie Groups
Abstract: In this paper we propose a (non-linear) smoothing algorithm for group-affine observation systems, a recently introduced class of estimation problems on Lie groups that bear a particular structure. As most non-linear smoothing methods, the proposed algorithm is based on a maximum a posteriori estimator, determined by optimization. But owing to the specific properties of the considered class of problems, the involved linearizations are proved to have a form of independence with respect to the current estimates, leveraged to avoid (partially or sometimes totally) the need to relinearize. The method is validated on a robot localization example, both in simulations and on real experimental data.


Title: Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids
Abstract: Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.


Title: A Combined RGB and Depth Descriptor for SLAM with Humanoids
Abstract: In this paper, we present a visual simultaneous localization and mapping (SLAM) system for humanoid robots. We introduce a new binary descriptor called DLab that exploits the combined information of color, depth, and intensity to achieve robustness with respect to uniqueness, reproducibility, and stability. We use DLab within ORB-SLAM, where we replaced the place recognition module with a modification of FAB-MAP that works with newly built codebooks using our binary descriptor. In experiments carried out in simulation and with a real Nao humanoid equipped with an RGB-D camera, we show that DLab has a superior performance in comparison to other descriptors. The application to feature tracking and place recognition reveal that the new descriptor is able to reliably track features even in sequences with seriously blurred images and that it has a higher percentage of correctly identified similar images. As a result, our new visual SLAM system has a lower absolute trajectory error in comparison to ORB-SLAM and is able to accurately track the robot's trajectory.


Title: Neural-Network-Controlled Spring Mass Template for Humanoid Running
Abstract: To generate dynamic motions such as hopping and running on legged robots, model-based approaches are usually used to embed the well studied spring-loaded inverted pendulum (SLIP) model into the whole-body robot. In producing controlled SLIP-like behaviors, existing methods either suffer from online incompatibility or resort to classical interpolations based on lookup tables. Alternatively, this paper presents the application of a data-driven approach which obviates the need for solving the inverse of the running return map online. Specifically, a deep neural network is trained offline with a large amount of simulation data based on the SLIP model to learn its dynamics. The trained network is applied online to generate reference foot placements for the humanoid robot. The references are then mapped to the whole-body model through a QP-based inverse dynamics controller. Simulation experiments on the WALK-MAN robot are conducted to evaluate the effectiveness of the proposed approach in generating bio-inspired and robust running motions.


Title: Quadruped Locomotion Control Based on Two Bipeds Jointly Carrying Model
Abstract: A novel gait planning and control framework was developed for quadruped locomotion of a robot. It modeled the quadruped robot as two bipeds carrying the body from the front and rear ends. We first mapped the relationship between the joint torques of support legs and the torso forces of the bipedal sub-robots. Then the equations describing the relationship between the quadruped body forces and the bipedal torso forces under various operating modes of the robot were deduced and solved. Virtual forces were generated on the quadruped body to manipulate its velocity and orientation. Then these virtual forces were distributed to the front and hind sub-robots to generate support leg torques. The state machines and gait generators for the two bipedal sub-robots were designed individually, resulting in the decoupling of the gait parameters in the front legs and hind legs. The effectiveness of the controller was validated through dynamic simulations.


Title: Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
Abstract: The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.


Title: Determining Optimal Gait Parameters for a Statically Stable Walking Human Assistive Quadruped Robot
Abstract: In this paper we propose a method to determine an optimal statically stable gait for a quadruped robot walking in the presence of an expected disturbance. There exists a tradeoff between a stable gait and an energy efficient gait. Our goal is to determine an energy efficient quadruped gait that will maintain stability while a human uses the device to stabilize themselves while walking. In order to determine an optimal gait, we present a cost function consisting of an energy term and a stability term. A method of evaluating the cost function using dynamics and quasi-static analysis is demonstrated. The optimization is implemented for a human assistive device currently being designed and the results are verified in simulation.


Title: Designing Concentric Tube Manipulators for Stability Using Topology Optimization
Abstract: One of the major problems facing the development and road to practical usage of concentric tube continuum robots in surgical environments is that of instability. This issue, also known as the snapping problem, is caused by a tube having a high bending to torsional stiffness ratio (BTSR). Past efforts have shown that by cutting patterns on the tubes, this problem can be avoided. This paper seeks to redesign the topology of the tubes so that BTSR is decreased and the snapping problem is resolved in a particular tube set. The generated designs are then tested through finite element analysis as well as experimental testing to demonstrate the elimination of the snapping problem. Using this novel tube design on a concentric tube robotic system can increase its stable workspace because it allows the usage of greater tube curvatures and/or curve lengths.


Title: Haptic Feedback and Dynamic Active Constraints for Robot-Assisted Endovascular Catheterization
Abstract: Robotic and computer assistance can bring significant benefits to endovascular procedures in terms of precision and stability, reduced radiation doses, improved comfort and access to difficult and tortuous anatomy. However, the design of current commercially available platforms tends to alter the natural bedside manipulation skills of the operator, so that the manually acquired experience and dexterity are not well utilized. Furthermore, most of these systems lack of haptic feedback, preventing their acceptance and limiting the clinical usability. In this paper a new robotic platform for endovascular catheterization, the CathBot, is presented. It is an ergonomic master-slave system with navigation system and integrated vision-based haptic feedback, designed to maintain the natural bedside skills of the vascular surgeon. Unlike previous work reported in literature, dynamic motion tracking of both the vessel walls the catheter tip is incorporated to create dynamic active constraints. The system was evaluated through a combined quantitative and qualitative user study simulating catheterization tasks on a phantom. Forces exerted on the phantom were measured. The results showed a 70% decrease in mean force and 61% decrease in maximum force when force feedback is provided. This research provides the first integration of vision-based dynamic active constraints within an ergonomic robotic catheter manipulator. The technological advances presented here, demonstrates that vision-based haptic feedback can improve the effectiveness, precision, and safety of robot-assisted endovascular procedures.


Title: Intuitive Gaze-Control of a Robotized Flexible Endoscope
Abstract: Flexible endoscopy is a routinely performed procedure that has predominantly remained unchanged for decades despite its many challenges. This paper introduces a novel, more intuitive and ergonomic platform that can be used with any flexible endoscope, allowing easier navigation and manipulation. A standard endoscope is robotized and a gaze control system based on eye-tracking is developed and implemented, allowing hands-free manipulation. The system characteristics and step response has been evaluated using visual servoing. Further, the robotized system has been compared with a manually controlled endoscope during a user study. The users (n=11) showed a preference for the gaze controlled endoscope and a lower task load when the task was performed with the gaze control. In addition, gaze control was related to a higher success rate and a lower time to perform the task. The results presented validate the system's technical performance and demonstrate the intuitiveness of hands-free gaze control in flexible endoscopy.


Title: A Soft Robot to Navigate the Lumens of the Body Using Undulatory Locomotion Generated by a Rotating Magnetic Dipole Field
Abstract: In this paper, we describe a soft-robotic actuation concept to enable a mesoscale medical robot to navigate the natural lumens of the body, such as blood vessels and intestines. The concept comprises a simple soft robot with two embedded permanent magnets with alternating magnetic polarity, and a rotating (nonuniform) dipole magnetic field that is swept over the robot, resulting in a traveling-wave undulatory motion that propels the robot forward and backward. This soft-actuation technology can be fabricated in a wide range of sizes due to its simplicity, and has the potential to be applied in a variety of diagnostic and therapeutic contexts. We conduct experiments and numerical simulations to verify the movement of the soft robot. Then, we confirm the benefits of using nonuniform dipole fields over using uniform fields, as well as the benefits of alternating the polarity of the magnets embedded in the device.


Title: A Robot System for Automated Wound Filling with Jetted Materials
Abstract: Skin surface wounds due to burns, surgeries and chronic illness affect millions of people worldwide. Tissue engineering has become an increasingly popular treatment, but it is a highly manual process. Increasing the automation in tissue engineering could increase the rate of treatment for patients and improve outcomes. We present an initial investigation into an automated in-situ treatment. In our proposed method, a 3D machine vision system detects a skin wound to be treated and then determines the 3D point set corresponding to the wound. The 3D point set is then passed to path planning algorithm for a robot manipulator to move an ink-jet nozzle over the wound and fill the cavity with quick-curing/gelling fluids such collagen and other biomaterials and cell growth promoters. This paper details initial results and experimental validation of each of the proposed steps.


Title: State Estimation for MRI-Actuated Cathers via Catadioptric Stereo Camera
Abstract: An MRI-actuated catheter is a novel robotic catheter system that utilizes the MR scanner for both remote steering and catheter tracking. In order to develop the mathematical model and the planning algorithm of the catheter in parallel to the MR tracking system, an alternative catheter tracking method is needed. This paper presents a catheter tracking algorithm based on the particle filter and the catadioptric camera system. The motion model of the particle filter is based on the quasi-static kinematics of the catheter. The measurement model calculates the weights of the particles according to the normalized crosscorrelation of the segmented image from camera and a virtual rendering of the catheter. The efficacy of the tracking algorithm is demonstrates via experimental results.


Title: Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots
Abstract: In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.


Title: Bayesian-inferred Flexible Path Generation in Human-Robot Collaborative Networks
Abstract: This paper presents a novel method for generating the trajectory of a robot assisting a human in servicing a set of tasks embedded in a convex 2-D domain. This method makes use of Bayesian inference to predict human intent in task selection. Rather than following optimal trajectory towards a single task, the robot computes a set of potentially optimal tasks each weighted by the human's posterior probability and superimposes them into a cost function that is designed to minimize the weighted Euclidean distance relative to set. The effect is a flexible path human-robot collaborative network that is shown in simulation to complete all tasks in a given domain in less time than existing methods for a certain class of highly impulsive humans, i.e., humans that tend to randomly switch tasks at times generated by a Poisson counting process. The algorithm is also illustrated through an experimental demonstration.


Title: Head-Mounted Augmented Reality for Explainable Robotic Wheelchair Assistance
Abstract: Robotic wheelchairs with built-in assistive features, such as shared control, are an emerging means of providing independent mobility to severely disabled individuals. However, patients often struggle to build a mental model of their wheelchair's behaviour under different environmental conditions. Motivated by the desire to help users bridge this gap in perception, we propose a novel augmented reality system using a Microsoft Hololens as a head-mounted aid for wheelchair navigation. The system displays visual feedback to the wearer as a way of explaining the underlying dynamics of the wheelchair's shared controller and its predicted future states. To investigate the influence of different interface design options, a pilot study was also conducted. We evaluated the acceptance rate and learning curve of an immersive wheelchair training regime, revealing preliminary insights into the potential beneficial and adverse nature of different augmented reality cues for assistive navigation. In particular, we demonstrate that care should be taken in the presentation of information, with effort-reducing cues for augmented information acquisition (for example, a rear-view display) being the most appreciated.


Title: Robot Programming Through Augmented Trajectories in Augmented Reality
Abstract: This paper presents a future-focused approach for robot programming based on augmented trajectories. Using a mixed reality head-mounted display (Microsoft Hololens) and a 7-DOF robot arm, we designed an augmented reality (AR) robotic interface with four interactive functions to ease the robot programming task: 1) Trajectory specification. 2) Virtual previews of robot motion. 3) Visualization of robot parameters. 4) Online reprogramming during simulation and execution. We validate our AR-robot teaching interface by comparing it with a kinesthetic teaching interface in two different scenarios as part of a pilot study: creation of contact surface path and free space path. Furthermore, we present an industrial case study that illustrates our AR manufacturing paradigm by interacting with a 7-DOF robot arm to reduce wrinkles during the pleating step of the carbon-fiber-reinforcement-polymer vacuum bagging process in a simulated scenario.


Title: The HRC Model Set for Human-Robot Collaboration Research
Abstract: In this paper, we present a model set for designing human-robot collaboration (HRC) experiments. It targets a common scenario in HRC, which is the collaborative assembly of furniture, and it consists of a combination of standard components and custom designs. With this work, we aim at reducing the amount of work required to set up and reproduce HRC experiments, and we provide a unified framework to facilitate the comparison and integration of contributions to the field. The model set is designed to be modular, extendable, and easy to distribute. Importantly, it covers the majority of relevant research in HRC, and it allows tuning of a number of experimental variables that are particularly valuable to the field. Additionally, we provide a set of software libraries for perception, control and interaction, with the goal of encouraging other researchers to proactively contribute to our work.


Title: Band of Brothers and Bolts: Caring About Your Robot Teammate
Abstract: It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.


Title: DNN-based Speech Recognition System dealing with Motor State as Auxiliary Information of DNN for Head Shaking Robot
Abstract: In this paper, a deep neural network (DNN) based integrated background noise suppression and acoustic modeling for speech recognition proposed in which on/off state of the motor for the head shaking robot is employed as the relevant auxiliary information of the DNN input. Since the motor sound being generated when the robot is moving or shaking its head severely degrades the performance of the speech recognition accuracy, we propose to use the motor on/off state as additional information when designing the DNN-based recognition system. Our speech recognition algorithm consists of two parts including the feature mapping model for feature enhancement and the acoustic model for phoneme recognition. As for the feature mapping, the stacked DNN is designed for the precise feature enhancement such that the lower DNN and upper DNN are trained separately and combined after which the motor state is plugged into both the lower DNN and upper DNN in addition to the input noisy speech. Then, the acoustic model is trained upon the feature enhancement model in which the motor state is again used as the augmented feature. The proposed technique to suppress the acoustic and motor noises was evaluated in term of the phoneme error rate (PER) and showed a significant improvement over the conventional system.


Title: The Power of a Hand-shake in Human-Robot Interactions
Abstract: In this paper, we study the influence of a handshake in the human emotional bond to a robot. In particular, we evaluate the human willingness to help a robot whether the robot first introduces itself to the human with or without a handshake. In the tested paradigm the robot and the human have to perform a joint task, but at a certain stage, the robot needs help to navigate through an obstacle. Without requesting explicit help from the human, the robot performs some attempts to navigate through the obstacle, suggesting to the human that it requires help. In a study with 45 participants, we measure the human's perceptions of the social robot Vizzy, comparing the handshake vs non-handshake conditions. In addition, we evaluate the influence of a handshake in the pro-social behaviour of helping it and the willingness to help it in the future. The results show that a handshake increases the perception of Warmth, Animacy, Likeability, and the tendency to help the robot more, by removing the obstacle.


Title: Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection
Abstract: We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.


Title: Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop
Abstract: Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.


Title: Reliable fusion of black-box estimates of underwater localization
Abstract: The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.


Title: A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
Abstract: Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.


Title: Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs
Abstract: This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.


Title: GelSlim: A High-Resolution, Compact, Robust, and Calibrated Tactile-sensing Finger
Abstract: This work describes the development of a high-resolution tactile-sensing finger for robot grasping. This finger, inspired by previous GelSight sensing techniques (Johnson and Adelson 2009), features an integration that is slimmer, more robust, and with more homogeneous output than previous vision-based tactile sensors. To achieve a compact integration, we redesign the optical path from illumination source to camera by combining light guides and an arrangement of mirror reflections. We parameterize the optical path with geometric design variables and describe the tradeoffs between the finger thickness, camera depth of field, and size of the tactile sensing area. The sensor sustains the wear from continuous use - and abuse - in grasping tasks by combining tougher materials for the compliant gel, a textured fabric skin, a structurally rigid body, and a calibration process that maintains homogeneous illumination and contrast of the tactile images during use. Finally, we evaluate the sensor's durability along four metrics that track the signal quality during more than 3000 grasping experiments.


Title: Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors
Abstract: Robots need to use their end-effectors not only to grasp and manipulate objects but also to understand the environment surrounding them. Object identification is of paramount importance in robotics applications, as it facilitates autonomous object handling, sorting, and quality inspection. In this paper, we present a new hyper-adaptive robot hand that is capable of discriminating between different everyday objects, as well as `model' objects with the same external geometry but varying material, density, or volume, with a single grasp. This work leverages all the benefits of simple, adaptive grasping mechanisms (robustness, simplicity, low weight, adaptability), a Random Forests classifier, tactile modules based on barometric sensors, and radar technology offered by the Google Soli sensor. Unlike prior work, the method does not rely on object exploration, object release or re-grasping and works for a wide variety of everyday objects. The feature space used consists of the Google Soli readings, the motor positions and the contact forces measured at different time instances of the grasping process. The whole approach is model-free and the hand is controlled in an open-loop fashion, achieving stable grasps with minimal complexity. The efficiency of the designs, sensors, and methods has been experimentally validated with experimental paradigms involving model and everyday objects.


Title: Encoding Guidelines for a Culturally Competent Robot for Elderly Care
Abstract: The functionalities and behaviours of socially assistive robots for the care of older people are usually defined by the robot's designers with limited room for runtime adaptation to meet the preferences, expectations and needs of the assisted person. However, adaptation plays a crucial role for the robot's acceptability and ultimately for its effectiveness. Culture, which deeply influences a person's preferences and habits, can be viewed as an invaluable “enabling technology” to achieve such level of adaptation. This paper discusses how guidelines describing culturally competent assistive behaviours can be encoded in a robot to effectively tune its actions, gestures and words. The proposed system is implemented on a Pepper robot and tested with an Indian persona, whose habits and preferences the robot discovers and adapts to at runtime.


Title: Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots
Abstract: Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.


Title: Developing a New Brand of Culturally-Aware Personal Robots Based on Local Cultural Practices in the Danish Health Care System
Abstract: In earlier work it has been shown how culture can be used as a parameter influencing human robot interaction in general (e.g. [1]). While this is a good starting point, in our work with concrete application fields we encounter that culture in its usual definition as national culture (e.g. [2]; [3]) is too general a concept to be useful in these concrete applications. Thus, we shifted our focus instead to a concept of local cultural practices, which is derived from situated practices as in Wengers communities of practice [4] and grounded loosely in Sperbers idea of an epidemiology of representations [5], i.e. culture or rather cultural practices as an emergent phenomenon from learning processes in a given group. Developing this new kind of culture-aware robots can then not start from a general definition of culture like Hofstede [2], Schwartz and Sagiv [6], etc. but has to take the actual group of users (and stakeholders) into account. We exemplify this approach with our work in a residency for citizens with acquired brain damage.


Title: Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction
Abstract: Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.


Title: AIBO Robot Mortuary Rites in the Japanese Cultural Context*
Abstract: In 1999 Sony released the AlBO Entertainment Robot, selling more than 150,000 units worldwide until 2006. By 2014, Sony had stopped offering upgrades and maintenance for the product, and owners were faced with the fact their pet-like robots would “die”. Some shrines and temples in Japan hold ningyo kuyo̅ or mass funerals for dolls and other toys. At the suggestion of a small Japanese tech-repair company called A-Fun, one temple began offering a Buddhist funeral ceremony for AIBOs. Approximately 700 AIBOs have so far received a funeral service. This paper surveys A-Fun`s maintenance services for old AIBOs, the AIBO funerals, and Sony's new 2018 AIBO release, in the cross-disciplinary context of human-machine relations in Japan and elsewhere. Drawing on the author's interviews with key actors, it articulates links between philosophy and neuroscience to explain tendencies toward zoomorphism in robot design. Perceiving presence (sonzai kan) and sensibility (kansei) in objects is a culturally contingent phenomenon. Whereas ways of conceiving the partly animate are largely absent from Western philosophy, in the case of AIBO ownership in Japan there is a reverential mindfulness of the technology's inherent contradictions.


Title: Social Robots as a Means of Integration? an Explorative Acceptance Study considering Gender and Non-verbal Behaviour
Abstract: The integration of migrants and refugees is currently a severe challenge for European states. Especially the imparting of culture- and gender-specific behaviours is an important issue. Social robots might be a valuable tool to introduce refugees to culture-specific behaviours of their host country. In this paper, we investigate the general acceptance of a social robot as well as users' perception of a robot presenting stereo-typical Arabic vs. German female non-verbal behaviour to Syrian newcomers to Germany. Our preliminary study revealed a generally positive attitude towards robots and the idea of an educational robot. Culture-specific manipulations were reflected in participants' partial preference for the Arabic version, but not in participants' perceptual ratings.


Title: Do I act familiar? Investigating the Similarity-Attraction Principle on Culture-specific Communicative behaviour for Social Robots
Abstract: Culture, amongst other individual and social factors, plays a crucial role in human-human interactions. If robots should become a part of our society, they should be able to act in culture-specific manners as well. In this paper, we showcase the implementation of a cultural dichotomy, namely individualism vs. collectivism, in a social robots' conversation. Presenting these conversations to human observers from Germany and Japan, we investigate whether the implemented differences are recognized as such, and whether stereotypical culture-specific behaviours that correspond to the observers' cultural background is preferred. Results suggest that the manipulations in behaviour had the intended effect, but are not reflected in personal preferences.


Title: Dexterous Manipulation Graphs
Abstract: We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.


Title: Instance Segmentation of Visible and Occluded Regions for Finding and Picking Target from a Pile of Objects
Abstract: We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order. The fundamental idea is to segment instances with both visible and occluded masks, which we call `instance occlusion segmentation'. To achieve this, we extend an existing instance segmentation model with a novel `relook' architecture, in which the model explicitly learns the inter-instance relationship. Also, by using image synthesis, we make the system capable of handling new objects without human annotations. The experimental results show the effectiveness of the relook architecture when compared with a conventional model and of the image synthesis when compared to a human-annotated dataset. We also demonstrate the capability of our system to achieve picking a target in a cluttered environment with a real robot.


Title: Online prediction of threading task failure using Convolutional Neural Networks
Abstract: Fasteners assembly automation in different industries require flexible systems capable of dealing with faulty situations. Fault detection and isolation (FDI) techniques are used to detect failure and deal with them, avoiding losses on parts, tools or robots. However, FDI usually deals with the faults after or at the moment they occur. Thus, we propose a method that predicts potential failures online, based on the forces and torques signatures captured during the task. We demonstrate the approach experimentally using an industrial robot, equipped with a force-torque sensor and a pneumatic gripper, used to align and thread nuts into bolts. All effort information is fed into a supervised machine learning algorithm, based on a Convolutional Neural Network (CNN) classifier. The network was able to predict and classify the threading task outcomes in 3 groups: mounted, not mounted or jammed. Our approach was able to reduce in 10.9% the threading task execution time when compared to a reference without FDI, but had problem to predict jammed cases. The same experiment was also performed with other two additional learning algorithms, and the results were systematically compared.


Title: Deep Reinforcement Learning for Robotic Assembly of Mixed Deformable and Rigid Objects
Abstract: Reinforcement learning for assembly tasks can yield powerful robot control algorithms for applications that are challenging or even impossible for “conventional” feedback control methods. Insertion of a rigid peg into a deformable hole of smaller diameter is such a task. In this contribution we solve this task with Deep Reinforcement Learning. Force-torque measurements from a robot arm wrist sensor are thereby incorporated two-fold; they are integrated into the policy learning process and they are exploited in an admittance controller that is coupled to the neural network. This enables robot learning of contact-rich assembly tasks without explicit joint torque control or passive mechanical compliance. We demonstrate our approach in experiments with an industrial robot.


Title: A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*
Abstract: Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.


Title: Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process
Abstract: The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.


Title: Mechatronic fingernail with static and dynamic force sensing
Abstract: Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.


Title: Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM
Abstract: In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).


Title: Virtual Occupancy Grid Map for Submap-based Pose Graph SLAM and Planning in 3D Environments
Abstract: In this paper, we propose a mapping approach that constructs a globally deformable virtual occupancy grid map (VOG-map) based on local submaps. Such a representation allows pose graph SLAM systems to correct globally accumulated drift via loop closures while maintaining free space information for the purpose of path planning. We demonstrate use of such a representation for implementing an underwater SLAM system in which the robot actively plans paths to generate accurate 3D scene reconstructions. We evaluate performance on simulated as well as real-world experiments. Our work furthers capabilities of mobile robots actively mapping and exploring unstructured, three dimensional environments.


Title: Energetic Efficiency of a Compositional Controller on a Monoped With an Articulated Leg and SLIP Dynamics
Abstract: Embedding the dynamics of the Spring Loaded Inverted Pendulum (SLIP) and applying a compositional controller around it can simplify dynamic legged robot locomotion control, but what is the energetic cost of this convenience? This paper measures the magnitude of this effect in such a way that the results are applicable to a wide class of jumping robots. A three-link monoped model with revolute joints is used to compare the energetic costs of locomotion using two different control approaches: 1) SLIP-embedding with a Raibert-style controller optimized for energetic efficiency, and 2) a trajectory optimized only for energetic efficiency. By performing this comparison in simulation for a large number of different monopeds randomly sampled from a space of realistic robot designs, it is found that the SLIP-Raibert approach requires, on average, almost twice the energy of the trajectory-optimized controller to traverse a given distance. Furthermore, the increase in energetic cost does not depend much on the particulars of the robot design, as the SLIP-Raibert approach requires at least 50% more energy for approximately 88% of realistic robot designs.


Title: Precision Jumping Limits from Flight-phase Control in Salto-1P
Abstract: We developed a deadbeat foot placement hopping controller for an untethered monopedal robot, Salto-1P. The controller uses a third order Taylor series approximation to an offline dynamic model and performs well on the physical platform. The robot demonstrated precise foot placement even on trajectories with aggressive changes in speed, direction, and height: in a random walk, its error standard deviation was 0.10 m. We establish how foot placement precision is tightly limited by attitude control accuracy, requiring attitude error less than 0.7 degrees for some tasks. We also show how foot placement precision degrades linearly as hopping height increases. These precision results apply to the large class of controllers that prescribe touchdown angle to control running velocity.


Title: Analytically-Guided Design of a Tailed Bipedal Hopping Robot
Abstract: We present the first fully spatial hopping gait of a 12 DoF tailed biped driven by only 4 actuators. The control of this physical machine is built up from parallel compositions of controllers for progressively higher DoF extensions of a simple 2 DoF, 1 actuator template. These template dynamics are still not themselves integrable, but a new hybrid averaging analysis yields a conjectured closed form representation of the approximate hopping limit cycle as a function of its physical and control parameters. The resulting insight into the role of the machines kinematic and dynamical design choices affords a redesign leading to the newly achieved behavior.


Title: MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot
Abstract: This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.


Title: Magneto: A Versatile Multi-Limbed Inspection Robot
Abstract: In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.


Title: Data-Driven Discrete Planning for Targeted Hopping of Compliantly Actuated Robotic Legs
Abstract: Motion planning for fast locomotion of compliantly actuated robotic legs is generally considered to be a challenging issue, posing considerable real-time problems. This is at least the case if time-continuous trajectories need to be generated online. In this paper we take advantage of a simple controller structure, which reduces the motion planning to a discrete-time planning problem, in which only a small set of input parameters need to be determined for each step. We show that for a planar leg with serial elastic actuation, hopping on a ground with stairs of irregular length and height can be planned online, based on a parameter mapping which has been learned in a data-driven manner by performing hopping trials with an adaptive exploration algorithm to evenly sample the parameter space. Experiments on a planar hopping leg prototype validate the approach.


Title: Quadrupedal walking motion and footstep placement through Linear Model Predictive Control
Abstract: The present work addresses the generation of a walking gait with automatic footstep placement for a quadrupedal robot, within a Linear Model Predictive Control framework. Existing work has shown how this is only possible within a non-convex programming framework, finding a solution of which is well-known to be very hard. We propose a way to formulate the joint optimization problem as an approximate QP with linear constraints, whose global optimum can be quickly found with off-the-shelf solvers. More specifically, this is done by introducing auxiliary states and control inputs, each of which is subject to linear constraints that are inspired from the literature on bipedal locomotion. Finally, we validate our method on the CENTAURO robot, a hybrid wheeled-legged quadruped with a humanoid upper-body.


Title: A Synergetic Voluntary Control for Exoskeleton based on Spinal Cord Mapping of Peripheral Bioelectric Activity
Abstract: Walking rehabilitation must be performed based on voluntary motion intention, and for this purpose, the development of a control method for an exoskeleton robot based on voluntary intention is investigated. This study proposes a method of exoskeleton robot control to estimate the voluntary lower limb muscle activities lost after a spinal cord injury (SCI). This method is based on the spinal cord mapping of the remaining muscle activities and its matching to the one obtained from healthy participants considering the muscle synergy of the whole body during the walking motion. By implementing the matching procedure at the spinal cord map level and incorporating information of reliable and unreliable spinal cord levels based on a diagnosis, the method has the potential to provide a maximally voluntary locomotion for people with SCI. We report an analysis of the synergy of the whole-body muscle activity during walking and its spinal cord mapping using non-negative matrix factorization and the computation of the transformation matrix to estimate the intended lower limb muscle activity from the remaining spinal cord activity. The implementation of the proposed method using the right leg of the hybrid assistive limb and walking experiments with a healthy participant are also reported.


Title: Similarity of the Impact of Humanoid and In-Person Communications on Frontal Brain Activity of Older People
Abstract: We report results of the analyses of the effect of communication through a humanoid robot in comparison with in-person, video-chat, and speaker on frontal brain activity of older people during an storytelling experiment. Our results suggest that whereas communicating through a physically embodied medium potentially induces a significantly higher pattern of brain activation with respect to video-chat and speaker, its difference is non-significant in comparison with in-person communication. These results imply that communicating through a humanoid robot induces a pattern of brain activity in older people that is potentially similar to in-person communication. Our findings benefit researchers and practitioners in rehabilitation and elderly care facilities in search of effective means of communication with their patients to increase their involvement in the incremental steps of their treatments. Moreover, they imply the utility of brain information as a promising sensory gateway in characterization of the behavioural responses in human-robot interaction.


Title: Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform
Abstract: Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.


Title: Cable Actuated Dexterous (CADEX) Glove for Effective Rehabilitation of the Hand for Patients with Neurological diseases
Abstract: Neuroplastic changes in motor cortex is essential for the recovery motor function of patients with neurological diseases. To enlarge neuroplastic change, various movements should be provided to stimulate larger motor cortical area, and because hands occupy the largest area, it is especially important. Many wearable robotic devices have been developed for rehabilitation of the hand, and soft robotic devices in particular have drawn attention for their compact design. However, most soft devices provide simple thumb motions, which flex or extend all joints without assistance of opposition/reposition of the carpometacarpal joint although the importance in producing various grasps. In this study, the design of a cable actuated dexterous (CADEX) glove is proposed. For dexterous motion, the structure and orientation of major finger tendons were replicated with exotendons (actuated cables), and four exotendons were used for the thumb with the path optimized to provide flexion/extension of the thumb and decoupled opposition/reposition of the carpometacarpal with other joints. To provide consistent motion, silicon was used for stable anchoring of exotendons while preventing slippage and reducing deformation. The motion generated by the CADEX glove was experimentally evaluated for a single healthy subject. The result shows that the CADEX glove could flex and extend the finger with various ratios among joints, and the opposition/reposition of carpometacarpal joint of the thumb could be achieved consistently with minimal effect on the other joints. The CADEX glove is expected to help providing various tasks which is expected to enhance the functional recovery of patients with neurological disease.


Title: SMA based wrist exoskeleton for rehabilitation therapy*
Abstract: This paper presents a rehabilitation wearable exoskeleton for wrist joint with two degrees of freedom (DOF), flexion-extension and adduction-abduction (radial and ulnar deviation), actuated with Shape Memory Alloy (SMA) based actuators. Thanks to this type of actuators, the proposed device presents a very light weight and noiseless operation, in comparison with similar devices. The preliminary results obtained over real tests with the wrist exoskeleton are presented. This prototype demonstrates that SMA actuator technology is a viable alternative when investigating possible improvement of rehabilitation robotic devices in terms of weight, size and cost.


Title: Utility Model Re-description within a Motivational System for Cognitive Robotics
Abstract: This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.


Title: A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *
Abstract: Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.


Title: Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots
Abstract: Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.


Title: How do humans read robotics? The matter of the lexical ambiguity resolution
Abstract: The words used to describe robotic performances include a degree of ambiguity that the human brain should solve without difficulty. However, the language used in-and about-robotics seems to escape from the ordinary processing of lexical ambiguity resolution. In this paper, we argue that there is no lack of an adequate language for robotics but that the lexicon at hand is forced by our representations. We investigate the main representational issues of the notions that express robotic actions and dispositions (i.e. behaviors).


Title: Free-View, 3D Gaze-Guided, Assistive Robotic System for Activities of Daily Living
Abstract: Patients suffering from quadriplegia have limited body motion which prevents them from performing daily activities. We have developed an assistive robotic system with an intuitive free-view gaze interface. The user's point of regard is estimated in 3D space while allowing free head movement and is combined with object recognition and trajectory planning. This framework allows the user to interact with objects using fixations. Two operational modes have been implemented to cater for different eventualities. The automatic mode performs a pre-defined task associated with a gaze-selected object, while the manual mode allows gaze control of the robot's end-effector position on the user's frame of reference. User studies reported effortless operation in automatic mode. A manual pick and place task achieved a success rate of 100% on the users' first attempt.


Title: The Future of Legal and Ethical Regulations for Autonomous Robotics
Abstract: “Autonomous robotics” promise significant improvements across a host of different complex systems, which will need to be managed within regulatory frameworks to promote, at a minimum, device safety. Contrary to how they are often portrayed, however, these systems do not necessarily require fundamentally new approaches to engineering or regulatory challenges, i.e., the development of a novel “autonomy framework” applicable to different types of devices. Rather, because autonomous systems generally represent a progressive improvement of existing complex systems, preexisting regulatory scheme offer the best guidance for considering future regulation of autonomous elements. Moreover, the regulatory landscape differs considerably based on the type of device at issue (e.g., consumer electronics vis-á-vis medical devices). This paper argues that users and regulators must consider future autonomy regulations within the specific framework those devices currently inhabit, rather than focusing on a novel set of rules divorced from the preexisting context.


Title: Uncertainty-based Online Mapping and Motion Planning for Marine Robotics Guidance
Abstract: In real-world robotics, motion planning remains to be an open challenge. Not only robotic systems are required to move through unexplored environments, but also their manoeuvrability is constrained by their dynamics and often suffer from uncertainty. One approach to overcome this problem is to incrementally map the surroundings while, simultaneously, planning a safe and feasible path to a desired goal. This is especially critical in underwater environments, where autonomous vehicles must deal with both motion and environment uncertainties. In order to cope with these constraints, this work proposes an uncertainty-based framework for mapping and planning3 feasible motions online with probabilistic safety-guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by (i) incrementally representing the environment as a collection of local maps, and (ii) iteratively (re)planning kinodynamically-feasible and probabilistically-safe paths to goal. The proposed framework is evaluated on the Sparus II, a nonholonomic torpedo-shaped AUV, by conducting simulated and real-world trials, thus proving the efficacy of the method and its suitability even for systems with limited on-board computational power.


Title: A Rationale-Driven Team Plan Representation for Autonomous Intra-Robot Replanning*
Abstract: For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.


Title: A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints
Abstract: This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.


Title: Vision-based Target Tracking for a Skid-steer Vehicle using Guided Policy Search with Field-of-view Constraint
Abstract: This paper describes a vision-based target tracking method for a skid-steer vehicle. With the development of deep reinforcement learning, many researchers have tried to generate an end-to-end policy to control the mobile robot from a raw pixel image data. However, the action in most research only concerns high-level decisions such as go straight, turn left and right. High-level decisions alone are not sufficient to precisely control platforms such as a skid-steer vehicle due to the lack of steering mechanism. Thus, unlike existing work, we aim to control the motor command for the wheels directly. To this end, we employ guided policy search (GPS) based on the general kinematic slip model for the skid-type robot. Furthermore, to prohibit the target from getting out of the camera field of view (FOV) in the training phase, we update local policy optimization with a FOV constraint and perform a pre-training to make the initial policy more efficient. Our method allows the skid-type robot to automatically acquire the vision-based tracking policy while local policies satisfy the FOV constraint during the training phase. We evaluate our method through both simulation and experiment with a skid-steer mobile robot. Finally, we test the performance of learned policy with a moving target in a new environment.


Title: On the Kinematics of Wheeled Motion Control of a Hybrid Wheeled-Legged CENTAURO robot
Abstract: Legged-wheeled robots combine the advantages of efficient wheeled mobility with the adaptability to real-world terrains through the legged locomotion. Due to this hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, their versatile mobility increases the number of constraints in their motion control where both the properties of legged and wheeled systems need to be considered. Relevant schemes for legged-wheeled platforms so far have been developed exploiting separate motion control of the wheeled and legged functionalities. This paper discusses the legged-wheeled motion kinematics without constraining the camber angles of the wheels, and it proposes a first-order inverse kinematics scheme that stabilizes the legged-wheeled system in the wheeled motion. Furthermore, the work adopts a floating base model that allows to easily incorporate the legged motion to the scheme. The developed controller is tested in simulation and experiments on a legged-wheeled centaur-like robot - CENTAURO.


Title: Development of Stone Throwing Robot and High Precision Driving Control for Curling
Abstract: In this paper, a novel mobile robot developed to perform Curling sports is introduced. The developed robot is a Stone Throwing Robot (STR) for Curling that can travel on the ice with wheels and throw a stone as well as make curls of the stone. The STR is developed as a robot component of an Artificial Intelligence(AI) system that can autonomously play the curling sport. The proposed STR can throw a stone at any desired speed and in any desired direction, which are determined by the AI system. To achieve this precise driving of the STR and throwing of the stone, two dimensional drive control is developed for the STR, which consists of 1) anti-slip control for high traction, 2) precise velocity control and 3) high accuracy heading angle control. In addition to the conventional PID controller, model-based feedforward control, Model Following Control (MFC) for the anti-slip control of the wheel on the ice and Yaw Moment Observer (YMO) for the robust heading angle control are applied as key technologies for the STR driving. The design configurations of the STR to achieve the detection of its own location and throwing/curling of the stone is proposed in this paper as well as the detail of the precise driving control.


Title: MAP - A Mobile Agile Printer Robot for on-site Construction
Abstract: In this paper, we present a Mobile Agile Printer (MAP) construction robot; a highly agile, 4-legged, omnidirectional robot capable of 3D printing large structures. To overcome dynamic challenges when operating within an outdoors construction site, MAP incorporates a high-DoF 3D printing system connected to a mobile platform with novel features designed to enable disturbance rejection and live adaption to the robot's pose. In doing so, we demonstrate the benefits of designing construction robots with a focus on agility, a compact working volume and ability to operate within a potentially unlimited workspace. Performance tests were conducted showing smooth omni-directional motion as a key requirement for maintaining low 3D printing trajectory deviations over a large volume. In doing so, we show that MAP has the ability to construct in new ways more sensitive to its environment, context and concurrent on-site operations.


Title: User-specific Gaussian Process Model of Wheelchair Drivers with a Haptic Joystick Interface
Abstract: In collaborative human-robot navigation such as when driving semi-autonomous robotic wheelchairs, intuitive control of the mobile robot is only possible if the robot understands its user. This becomes especially important as users present varying levels of abilities and heterogeneous driving styles. Furthermore, the robot needs to consider the inherent uncertainty on its navigation task because the user may not be able to communicate his or her plans explicitly. In order to address these requirements, we have adopted a probabilistic framework to recognise navigation plans. A key component in this framework is a personalised driver model, which captures how a particular user transforms his or her mental navigation plan into inputs to the robot. In this work, we evaluate the use of Gaussian Processes to implement and calibrate this probabilistic, user-specific driver model, and this for use with haptic joysticks. Furthermore, special care was taken to obtain fast online evaluation of this user model through sparse approximation and parallel computation on a GPU. This resulted in an achievable user model evaluation frequency of 40 Hz, which is far above the navigation assistance frequency we aimed for, i.e. 5 Hz. We illustrate the validity of the approach by recognising the navigation plans of a spastic wheelchair user.


Title: A minimalist Stair Climbing Robot (SCR) formed as a leg balancing & climbing Mobile Inverted Pendulum (MIP)
Abstract: This paper presents a (patent-pending) small, quasi-static, minimal-complexity Stair Climbing Robot (SCR). The vehicle design is given simply by adding a third motor to a (Segway-like) Mobile Inverted Pendulum (MIP), enabling it to maneuver up stairs, leveraging feedback control, by planting it's “foot” onto the ground in front of the next step, lifting the chassis/wheel assembly up it's own “leg”, leaning over onto the top of the next step, self uprighting, and repeating for the following step(s). Fore/aft stabilization during leg balancing is given by using the MIP drive wheels as reaction wheels, while left/right stability is given by the width of the foot itself. The design is small and simple enough to potentially be ruggedized as a stair-climbing throwbot, akin to the Recon Scout (but able to climb up stairs) for reconnaissance in military and homeland security applications.


Title: Tire Force Estimation of Dynamic Wheeled Mobile Robots using Tire-Model Based Constrained Kalman Filtering
Abstract: We propose a novel real-time algorithm to estimate the full three-dimensional individual tire forces (i.e., vertical, longitudinal as well as lateral) of a car-like rearwheel-driven four wheel wheeled mobile robots equipped with onboard navigation sensors and wheel encoders. The key enabling idea for this is to utilize the tire model (i.e., the magic formula) in a feedback manner on the framework of the constrained Kalman filtering to render the tire force estimation: 1) more accurate as compared to the typical tire force estimation techniques neglecting the tire-road interaction; and 2) more robust as compared to the results adopting the tire model, yet, only in an open-loop manner. Our proposed algorithm, while performing this full tire force onboard/real-time estimation, also provides the estimation of: 1) tire-road friction coefficient; and 2) torque inputs of the rear left and right wheels, which are connected via differential gear. Simulations with CarSim and outdoor experiments are performed to validate the proposed estimation algorithm.


Title: Online Spatial Sound Perception Using Microphone Array on Mobile Robot*
Abstract: The paper proposes a spatial sound perception system for an autonomous mobile robot. The system performs three-dimensional position localization and recognition as online processing from a robot in motion. For online processing, the sound positions are estimated as probabilistic regions in three dimensional space, because the robot could observe only arrival direction of the sound at a moment. The detected sound signals are recognized using Convolutional Neural Network (CNN), for the adjustment to short input signals. The experimental results show our mobile robot could observe surrounding sound sources online and continuously update its position and sound label.


Title: Extracting the Relationship between the Spatial Distribution and Types of Bird Vocalizations Using Robot Audition System HARK
Abstract: For a deeper understanding of ecological functions and semantics of wild bird vocalizations (i.e., songs and calls), it is important to clarify the fine-scaled and detailed relationships among their characteristics of vocalizations and their behavioral contexts. However, it takes a lot of time and effort to obtain such data using conventional recordings or by human observation. Bringing out a robot to a field is our approach to solve this problem. We are developing a portable observation system called HARKBird using a robot audition HARK and microphone arrays to understand temporal patterns of vocalizations characteristics and their behavioral contexts. In this paper, we introduce a prototype system to 2D localize vocalizations of wild birds in real-time, and to classify their song types after recording. We show that the system can estimate the position of songs of a target individual and classify their songs with a reasonable quality to discuss their song - behavior relationships.


Title: Failure Detection Using Proprioceptive, Auditory and Visual Modalities
Abstract: Handling safety is crucial to achieve lifelong autonomy for robots. Unsafe situations might arise during manipulation in unstructured environments due to noises in sensory feedback, improper action parameters, hardware limitations or external factors. In order to assure safety, continuous execution monitoring and failure detection procedures are mandatory. To this end, we present a multimodal failure monitoring and detection system to detect manipulation failures. Rather than relying only on a single sensor modality, we consider integration of different modalities to get better detection performance in different failure cases. In our system, high level proprioceptive, auditory and visual predicates are extracted by processing each modality separately. Then, the extracted predicates are fused. Experiments on a humanoid robot for tabletop manipulation scenarios indicate that the contribution of each modality is different depending on the action in execution and multimodal fusion results in an overall performance increase in detecting failures compared to the performance attained by unimodal processing.


Title: HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System
Abstract: This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.


Title: Multi-timescale Feature-extraction Architecture of Deep Neural Networks for Acoustic Model Training from Raw Speech Signal
Abstract: This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.


Title: Kinematic Morphing Networks for Manipulation Skill Transfer
Abstract: The transfer of a robot skill between different geometric environments is non-trivial since a wide variety of environments exists, sensor observations as well as robot motions are high-dimensional, and the environment might only be partially observed. We consider the problem of extracting a low-dimensional description of the manipulated environment in form of a kinematic model. This allows us to transfer a skill by defining a policy on a prototype model and morphing the observed environment to this prototype. A deep neural network is used to map depth image observations of the environment to morphing parameter, which include transformations and configurations of the prototype model. Using the concatenation property of affine transformations and the ability to convert point clouds to depth images allows to apply the network in an iterative manner. The network is trained on data generated in a simulator and on augmented data that is created with its own predictions. The algorithm is evaluated on different tasks, where it is shown that iterative predictions lead to a higher accuracy than one-step predictions.


Title: Distributed Deep Reinforcement Learning based Indoor Visual Navigation
Abstract: Recently, as the rise of deep reinforcement learning, it not only can help the robot to convert the complicated environment scene to motor control command directly but also can accomplish the navigation task properly. In this paper, we propose a novel structure, where the objective is to achieve navigation in large-scale indoor complex environment without pre-constructed map. Generally, it requires good understanding of such indoor environment to make complex spatial perception possible, especially when the indoor space consists of many walls and doors which might block the view of robot leading to complex navigation path. By the proposed distributed deep reinforcement learning in different local regions, our method can achieve indoor visual navigation in the aforementioned large-scale environment without extra map information and human instruction. In the experiments, we validate our proposed method by conducting highly promising navigation tasks both in simulation and real environments.


Title: Synthesizing Neural Network Controllers with Probabilistic Model-Based Reinforcement Learning
Abstract: We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.


Title: Composite Reinforcement Learning for Social Robot Navigation
Abstract: For a service robot, it is not adequate to let its navigational movement be based only on a single metric, such as minimum distance path. In the environment where the robot and humans are coexisting, the robot should always perform social navigation whenever it is moving. However, to perform social navigation, the robot needs to follow certain “social norms” of the environment. Recently, deep reinforcement learning (DRL) technique is popularly applied to the robotics field; yet, it is rarely used to solve the mentioned social navigation problem, generally deemed as a high dimension complex problem. In this paper, we propose the composite reinforcement learning (CRL) framework under which the robot learns appropriate social navigation with sensor input and reward update based on human feedback. For learning the aspect of human robot interaction (HRI), we provide a method to facilitate the training of DRL in real environment by incorporating prior knowledge to the system. It turns out that our CRL system not only can incrementally learn how to set its velocity and to perform HRI but also keep collecting human feedback to synchronize the reward functions to the current social norms. The experiments show that the proposed CRL system can safely learn how to navigate in the environment and show that our system is able to perform HRI for social navigation.


Title: Object Recognition Through Active Sensing Using a Multi-Fingered Robot Hand with 3D Tactile Sensors
Abstract: This paper investigates tactile object recognition with relatively densely distributed force vector measurements and evaluates what kind of tactile information is beneficial for object recognition. The uSkin tactile sensors are embedded in an Allegro Hand, and provide 240 triaxial force vector measurements in total in all fingers. Active object sensing is used to gather time-series training and testing data. A simple feedforward, a recurrent, and a convolutional neural network are used for recognizing objects. Evaluations with different number of employed measurements, static vs. time series data and force vector vs. only normal force vector measurements show that the high-dimensional information provided by the sensors is indeed beneficial. An object recognition rate of up to 95% for 20 objects was achieved.


Title: Sensory-motor augmentation of the robot with shared human perception
Abstract: Robots have replaced people in many manufacturing production lines but the information they gather from sensors might not be sufficient to autonomously accomplish dexterous manipulation operations. Symbiotic human-robot cooperation appears to be a more realistic near future in industrial scenarios. In this paper we present a configuration of human-robot collaboration in which the robot is sensory-augmented by means of a set of tactile signals coming from the human operator. The incorporation of low-level robot “intelligence” permits the cooperative manipulation of an object while enabling the human operator to stay focused on task itself and carry it out in the most natural way. The effectiveness of this approach is demonstrated in a use case in which a robot helps a human operator to successfully accomplish a writing task. System performance has been evaluated, considering several positions of the tiny vibration sensor in charge of gathering the human perception, by testing it on both the human hand and the co-manipulated object. Results suggest that the sensor provides valuable information for recognizing operator actions when it is placed either on the human hand or on the co-manipulated object. However, the sensor on the finger directly represents the operator's perception, while the output of the sensor attached to the object changes according to the distance between the interaction point and the sensor itself. In addition, in wearing the sensor, neither the object nor the robot need to be instrumented: the operator is free to interact with a large set of objects and collaborate with any existing robot without requiring supplemental equipment.


Title: HTC Vive: Analysis and Accuracy Improvement
Abstract: HTC Vive has been gaining attention as a cost-effective, off-the-shelf tracking system for collecting ground truth pose data. We assess this system's pose estimation through a series of controlled experiments where we show its precision to be in the millimeter magnitude and accuracy to range from millimeter to meter. We also show that Vive gives greater weight to inertial measurements in order to produce a smooth trajectory for virtual reality applications. Hence, the Vive's off the shelf algorithm is poorly suited for robotics applications such as measuring ground truth poses, where accuracy and repeatability are key. Therefore we introduce a new open-source tracking algorithm and calibration procedure for Vive which address these problems. We also show that our approach improves the pose estimation repeatability and accuracy by up to two orders of magnitude.


Title: Improving indoor robots localisation by fusing different sensors
Abstract: Indoor mobile robots navigation must use external sensors to complement odometry. This paper analyses two different external sensors such as a laser LMS-200 and an omnidirectional camera Mobotix C2S. Experiments with only one of these sensors and with both integrated are carried out on a tour guide robot in order to obtain conclusions about their contribution to robot pose estimation, and how to locate external landmarks in the environment.


Title: Efficient Map Representations for Multi-Dimensional Normal Distributions Transforms
Abstract: Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.


Title: Modeling and Control of an Articulated Tail for Maneuvering a Reduced Degree of Freedom Legged Robot
Abstract: This paper presents dynamic modeling and control of an articulated robotic tail to maneuver and stabilize a reduced degree-of-freedom (DOF) quadruped robot. Conventional legged robotic systems consist of leg mechanisms that provide simultaneous propulsion, maneuvering and stabilization. However, in nature animals have been observed to utilize their tails to assist the legs in multiple tasks. Similarly, by incorporating an articulated tail onboard a quadruped robot, dynamic tail motions can be used to aid maneuvering. Therefore, tail implementation can potentially lead to simplifications in design and control of the legged robot since the legs will be responsible for only propulsion tasks. In this paper, a robotic system design consisting of an articulated tail and quadruped robot system is presented. Dynamic models are derived to analyze an optimal tail mass and length ratio to enhance inertial adjustment applications and develop an outer loop controller to plan tail trajectories for desired maneuvering applications. Results of analytical optimization are corroborated with measured data from biological animals. To decouple the dynamics of the articulated tail mechanism an inner loop controller using feedback linearization maps the desired behavior to the actuator inputs. This approach is validated using hardware-in-the-loop experiments with tail prototype in conjunction with simulated quadruped platform. Results demonstrate the capabilities of the articulated tail in enabling precise left and right turning (maneuvering).


Title: Modeling and Fuzzy Control of One-legged Somersaulting Robot
Abstract: Research on legged robots has developed rapidly in the recent decades. One-legged robots, unlike multi-legged ones, have only one type of motion, called hopping. Hopping motion is generally divided into stance and flight phases. Switching between these two phases represents a hybrid dynamic model. Dynamic stabilization of hopping motion is a challenging control issue. Most of one-legged hopping robots studied in the past are able to hop with their one springy leg. In this paper, a novel one-legged robot is introduced and studied with two springs on the two sides. The one-legged somersaulting robot is able to hop with both springy sides. This ability causes lower energy consumption in passing obstacles and a longer step length in comparison with well-known SLIP robots with hopping motion stemming from the fact that it only has one rotary actuator. Fuzzy logic control is applied to achieve a stable limit cycle in the robot's somersaulting motion.


Title: Towards a Passive Adaptive Planar Foot with Ground Orientation and Contact Force Sensing for Legged Robots
Abstract: Adapting to the ground enables stable footholds in legged locomotion by exploiting the structure of the terrain. On that account, we present a passive adaptive planar foot with three rotational degrees of freedom that is lightweight and thus suited for highly dynamic legged robots. Its low laying pivot joint provides high stability towards kinking. Information about the relative foot sole pose, and accordingly, the ground orientation is gathered by inertial measurement units (IMUs) placed on the foot sole and the shank. A complementary filter is presented that fuses these orientation estimates with an angular encoder to obtain a drift-free relative foot sole pose. The passive adaptive planar foot has been tested and compared to the classical point foot design on a variety of terrains and shows superior traction performance, especially on compressible soils. Being mounted on the quadrupedal robot ANYmal, the foot provides a reliable contact detection based on the fusion of the built-in 6-axis force/torque transducer and the IMUs. This allows to walk and trot on uneven terrain, loose soils, as well as climbing up a ramp and stairs while keeping the entire foot sole in ground contact all the time.


Title: SLIP-Model-Based Dynamic Motion Transition Between Different Fixed Points in One Stride in a Leg-Wheel Transformable Robot
Abstract: We report on the development of a motion generation strategy that allows the robot to transit from one stable running motion to another in one stride by actively changing leg stiffness in real time. Stable motion of the robot is generated based on the stable fixed-point trajectories of the spring-loaded inverted pendulum (SLIP) model. While the transition of the ordinary SLIP model with fixed parameters gradually converges if stable, a robot that uses force control to simulate the passive spring of the SLIP can actively modulate leg-spring stiffness. This enables the robot to switch instantly to another fixed-point trajectory of the SLIP model without going through multi-stride transition. The proposed method is implemented on a leg-wheel transformable robot, TurboQuad, and is evaluated experimentally. The results confirm that the robot can successfully transit between different fixed-point trajectories.


Title: Continuous Shape Changing Locomotion of 32-legged Spherical Robot
Abstract: Shape changing robot is an approach towards locomotion on uncertain terrain due to its omni-directional features. However, the current locomotion method for such robots rely on discontinuous rolling. We propose a free form locomotion: an omni directional continuous crawling for deformable robots. This method introduce continuous shifting of contact surface similar to amoeba movement. A Mochibot that has thirty two telescopic legs is developed to verify the proposed locomotion method. Through the experiments, we have confirmed that the robot can track smooth paths: straight, smooth, and hand written curves. We also evaluate errors between desired and measured trajectories of the robot.


Title: End-effector with a Hook and Two Fingers for the Locomotion and Simple Work of a Four-limbed Robot
Abstract: In this paper, we propose an end-effector for realizing various locomotion modes and simple work of a legged robot. The locomotion modes include climbing a vertical ladder, crawling, and walking. The simple work includes grasping and switching motions required at a disaster site. The developed end-effector has a two-pronged hook shape and two fingers for grasping and working and can be used to perform the locomotion and manipulation tasks described above. The experimental results confirmed that the four-limb robot WAREC-1 (WAseda REsCuer-No. 1) equipped with our proposed end-effector was able to climb a vertical ladder and perform the crawling motion. We also confirmed that the end-effector could grasp and switch five types of objects: a cylinder, cylinder with trigger, T-shaped, disk, and thin plate.


Title: A Framework for Modeling Closed Kinematic Chains with a Focus on Legged Robots
Abstract: This paper presents the foundations of a MATLAB framework for dynamic modeling and simulation of closed kinematic chain (CKC) mechanisms, with a particular focus on implementation with legged locomotive mechanisms. As such, the framework supports both floating-base and fixed-base systems. Through the use of singular perturbation theory, various CKC mechanisms can be modeled so that constraint errors asymptotically converge to zero, thus avoiding the numerical drift that plagues commonly used methods. A functional API and the relevant core commands necessary to construct a model are presented. Two robotic legs incorporating CKC mechanisms are utilized as case studies, and simulations of each leg performing a dynamic monopedal gait are illustrated.


Title: Steering of an Underactuated Legged Robot through Terrain Contact with an Active Tail
Abstract: This paper analyzes and implements two novel turning strategies for underactuated legged robots that leverage contact of an active tail against terrain. The first strategy produces a sustained turn with a tail dragging against the ground during forward locomotion. The second strategy produces a rapid point turn by impacting the tail against the ground. LoadRoACH, a 55 g palm-sized legged robot, is developed to carry the active tail payload used in turning experiments. A steady-state turning model predicts the achievable turn speed of the robot on carpet, and open-loop turning experiments characterize the performance of the two tail contact turning strategies. Tail drag turning provides comparable turning maneuverability to differential drive turning gaits on carpet and gravel surfaces. Tail impact turning can produce rapid point turns on carpet, tarp, and gravel, but has a large variability in turn angle and time to recover from the turn. Finally, tail drag and tail impact turning control methods are implemented in an aggressive closed-loop corner steering maneuver.


Title: Design and Experimental Characterisation of a Hydrostatic Transmission for Upper Limb Exoskeletons
Abstract: This paper introduces a novel hydrostatic air-liquid torque transmission system for an upper limb exoskeleton. The proposed design is based on remote electrical actuation, with grounded motors, combined with high performance fluid power transmission employed to deliver the power to the joints of the exoskeleton. The fluid transmission is based on rolling membrane cylinders that guarantee leakage-free operation, no backlash, and virtually zero stick-friction. This solution makes it possible to obtain easy controllability, good efficiency, intrinsic backdrivable operation, and reduced mass/inertia of the links of the robot. Additionally, the proposed system can be potentially implemented at relatively low-costs thanks to the employment of standard components and an architecture based on a modular approach. A test bench of the fluid transmission system is developed and a campaign of experiments is conducted to characterize its static/dynamic response for different choice of design parameters. In addition, we present a preliminary complete integrated arrangement of an upper limb exoskeleton equipped with the proposed transmission system. Results confirm the feasibility of the proposed actuation approach for the envisaged application.


Title: Muscle Activation Source Model-based sEMG Signal Decomposition and Recognition of Interface Rotation
Abstract: Muscle activation signals are measured from the skin surface as surface electromyography (EMG) signals that contain information on human intentions; therefore, they are widely used in various robotics applications owing to their usability. However, selective muscle activation extraction is difficult because of the complexity of muscle structures. This study investigated muscle activation source model-based sEMG signal decomposition that considers the anatomical factors of muscle structures. The main advantage of the proposed model-based signal decomposition is that sEMG interface rotation can be recognized by comparing source parameters identified before and after rotation. To assess the performance of the proposed model-based decomposition method, hand motion estimation and rotation recognition were conducted. Additionally, two-dimensional simultaneous control was conducted with an inertial measurement unit to verify the usability of the proposed model. The results indicate that the proposed model decomposes an sEMG signal based on motion with good performance and demonstrate feasibility of motion estimation independent of sEMG interface rotation.


Title: Design, Control and Preliminary Test of Robotic Ankle Prosthesis
Abstract: Currently, most of commercially available ankle foot prosthesis are passive, which don't exhibit appropriate biomechanics during walking and could not adapt to dynamic property of able-bodied walking. In this paper, we present a novel robotic ankle foot prosthesis with variable transmission series elastic actuator (SEA). Slider crank mechanism is applied to transform linear motion of series elastic actuator to rotary motion of ankle foot joint. And this could contribute to variable transmission ratio while ankle angle varies. Because of variable transmission ratio, ankle joint torque is increasing while ankle angle is flexed from plantar flexion to dorsiflexion, whose feature has similar increase trend with human's ankle joint torque-angle relationship, and exhibits an appropriate characteristic for developing robotic ankle foot prosthesis. Larger torque could be obtained in powered plantar flexion, and this indicates that variable transmission mechanism would help reduce required motor torque compared with traditional mechanism. Energy stored in springs of series elastic actuator contribute a torque to powered plantar flexion. Preliminary experiments with a transtibial amputee and a transferomal amputee have been performed to test the prototype.


Title: A Method for Robot Motor Fatigue Management in Physical Interaction and Human-Robot Collaboration Tasks
Abstract: Collaborative robots are often designed with limited power and force capacity, with the aim to provide affordable solutions and ensure human safety in case of accidental collisions and impacts. If a task requires a power beyond this capacity, or is performed repeatedly over long periods, such limits may be exceeded, which can cause inevitable robot damage and contribute to the lost productivity. In such cases, where hardware solutions and improvements are not applicable, effective software frameworks can prolong robot productivity and lifetime. To this end, in this paper we propose a novel technique for the monitoring and management of robot fatigue in repetitive or high-effort task execution scenarios. The robot fatigue is estimated by the measured temperature of motors in the joints. The proposed fatigue management system is composed of two-stage reaction process that is triggered by different levels of the estimated fatigue. The first stage exploits the kinematic redundancy of robot structure in attempt to minimise the load in the specific joints that under fatigue by reconfiguration in the joint space through the null space of the Cartesian task production. If the first stage is not successful in reducing the fatigue, the second stage is activated that gradually reduces the forces of hybrid controller. At that point, the human co-worker can temporarily take over the task execution until the robot will be recovered from the excessive fatigue. To validate the proposed approach we conducted experiments on KUKA Lightweight Robot performing two interaction tasks: autonomous surface wiping and collaborative human-robot surface polishing.


Title: Adaptive Task Planner for Performing Home Service Tasks in Cooperation with a Human
Abstract: To perform a home service task through cooperation with a human in a real environment, a robot needs to deal with the environmental changes and accordingly plan appropriate behavior sequence. For this purpose, in this paper, we propose an adaptive task planner which is based on memory and reasoning. A robot perceives user behaviors and objects using an RGB-depth and thermal sensor. The robot stores a temporal sequence of behaviors for performing a task in its episodic memory that is realized by a sequence to sequence network. When the user command is given, the episodic memory is used to retrieve the behavior sequence to carry out the command. On the other hand, when the robot perceives user behaviors, the robot postpones its behavior till his/her behavior is stopped. Once stopped, the episodic memory retrieves the behavior sequence to conduct a task that the user has intended. A task scheduler schedules the behavior sequence from the memory and sends it to an internal simulator. The internal simulator confirms the behavior sequence to be executable and then if executable, it sends the next executable behavior to the execution module. If a behavior fails in the internal simulation test, fast forward planner generates an alternative behavior sequence to resolve the failed behavior problem. The effectiveness and applicability of the proposed planner is demonstrated by a wheel-based humanoid robot.


Title: Design of SUPERball v2, a Compliant Tensegrity Robot for Absorbing Large Impacts
Abstract: In this paper, we present the system design and initial testing of SUPERball v2, a completely re-designed 2-meter spherical six-bar tensegrity robot designed to survive high-speed landings as well as locomote to desired locations. SUPERball v2 was designed to enable a host of new actuation and experimentation. The prototype features a fully actuated six-bar design (24 actuators), compliant nylon cables (up to 15% stretch), torque-control enabled motors, and a robust mechanical structure capable of surviving impact velocities upwards of 8 m/s.


Title: Slip Avoidance in Dual-Arm Manipulation
Abstract: In multi-finger or multi-arm grasping with friction contacts, maintaining force closure during motion is critical. Violation of this condition would cause contact slippage and possibly loss of grasp. This issue is of particular importance in space robotics, where the loss of grasp could lead to catastrophic consequences. There has been ample literature on stable grasp and force closure under static conditions. This paper investigates multi-arm grasping during motion, where the inertial force from the load could adversely affect grasp stability. Our approach dynamically adjusts the squeeze force and commanded robot/load motion to maintain a safe force closure condition. For a specified motion trajectory, the squeeze force is updated to prevent slippage based on the estimated inertial force. When the required squeeze force is beyond what the manipulators can safely apply, the trajectory will be scaled to reduce the inertial force component. In addition to motion-induced disturbance force, contact between the load and other objects in the environment can also cause slippage. The slip prevention strategy is extended to this case as well. The application scenario is based on the dual-arm transportation and berthing of a load in a micro-gravity environment. For laboratory testing, we use a fixed-base dual-arm robot to grasp, transport, and berth an object on a planar air bearing table. We also extend the transportation tests to a more general spatial setting, and use the dynamic squeeze adjustment to grasp, lift, and transport an object. Experimental results show the proposed method is effective at avoiding contact slippage during motion and when the object is in contact with the environment.


Title: Steerable Locomotion Controller for Six-strut Icosahedral Tensegrity Robots
Abstract: This paper proposes a novel steerable locomotion controller for six-strut tensegrity robots. Tensegrity robots are lightweight and have many promising features such as robustness, shape-shifting capabilities, and deployability, making them good candidates for exploration and scouting of remote areas. Despite these advantages, tensegrity robots are challenging to control due to their large number of degrees of freedom, nonlinear dynamics, and intrinsic compliance. Recently, many step-wise motion controllers have been employed to simplify the locomotion problem, thanks to the discrete nature of the tensegrity structure. In this paper we present a novel locomotion controller which will steer the direction of motion of a six-strut tensegrity robot when used in conjunction with any preexisting step-wise controller. We validated our controller on the SUPERball v2 robot, showing straight and curved trajectories, and an example of navigation around obstacles. Our method is computationally inexpensive, only requires knowledge about the current base triangle (e.g, via accelerometer data), and can be generalized to any six-strut tensegrity robot which can perform step-wise locomotion.


Title: Image Based Visual Servoing for Tumbling Objects
Abstract: Objects in space often exhibit a tumbling motion around the major inertial axis. In this paper, we address the image based visual servoing of a robotic system towards an uncooperative tumbling object. In contrast to previous approaches that require explicit reconstruction of the object and an estimation of its velocity, we propose a novel controller that is able to minimize the feature error directly in image space. This is achieved by observing that the feature points on the tumbling object follow a circular path around the axis of rotation and their projection creates an elliptical track in the image plane. Our controller minimizes the error between this elliptical track and the desired features, such that at the desired pose the features lie on the circumference of the ellipse. The effectiveness of our framework is exhibited by implementing the algorithm in simulation as well on a mobile robot.


Title: Online Path Planning and Compliance Control of Space Robot for Capturing Tumbling Large Object
Abstract: This paper presents the path planning and coordinated control of a space robot with a manipulator for capturing a rotating large object. As the grasping point on a rotating large object is translationally moving fast, an appropriate strategy and coordinated motion control of the spacecraft base and robotic arm must be employed for approaching and tracking such a grasping point. In this paper, we propose a robust control scheme including the online path planning and compliance control for grasping such a target. The path planning is derived in a simple form that allows the desired end-effector trajectory to be easily modified in real-time using the newly updated states without complex numerical calculation. In addition, the compliance control allows the end-effector to track the planned trajectory or the moving grasping point, while using contact force feedback to reduce the end-effector position error from the grasping point when capturing the target. This end-effector motion is implemented by coordinated control on the spacecraft base and robotic arm, which can suitably alter their distribution of motion according to scenes using a weighted pseudoinverse matrix. Experiments are conducted to demonstrate the validity of the proposed path planning and compliance control.


Title: Robotic Grasping Using Proximity Sensors for Detecting both Target Object and Support Surface
Abstract: The robustness of the positioning and posturing of robot hands relative to target object and support surface is an important issue for autonomous grasping. For example, to perform a grasping action such as picking up thin objects from a table top, the position and posture of the hand must be controlled to keep adequate relative posture and distance to the support surface besides those between the hand and the target object. Because slight errors in the posture and position are enough to cause grasping failure, the positioning and posturing of the hand must be precise enough, specially when the hand is close to the target object and support surface. To improve the robustness of robotic grasping, in this paper we present a method by grasping control based on the relative posture and position between hand and support surface besides those between hand and target object, using proximity sensors. Proximity sensors are newly installed on fingernails besides on the fingertips. As the fingernail sensor, an integration of Time-of-Flight (TOF) sensor and photo-reflector is designed to realize long range detection, as well as with precise and high-speed detection regardless of the reflectance of support surfaces when approaching the support surface. By the sensors, the hand can approach the object and support surface coarsely first, and then can be controlled fast and precisely to realize adequate grasping motion along the support surface but without contact with the support face. The method has been implemented to a manipulator system, and successful grasping experiments have demonstrated the effectiveness of the proposed method.


Title: Model-free and learning-free grasping by Local Contact Moment matching
Abstract: This paper addresses the problem of grasping arbitrarily shaped objects, observed as partial point-clouds, without requiring: models of the objects, physics parameters, training data, or other a-priori knowledge. A grasp metric is proposed based on Local Contact Moment (LoCoMo). LoCoMo combines zero-moment shift features, of both hand and object surface patches, to determine local similarity. This metric is then used to search for a set of feasible grasp poses with associated grasp likelihoods. LoCoMo overcomes some limitations of both classical grasp planners and learning-based approaches. Unlike force-closure analysis, LoCoMo does not require knowledge of physical parameters such as friction coefficients, and avoids assumptions about fingertip contacts, instead enabling robust contacts of large areas of hand and object surface. Unlike more recent learning-based approaches, LoCoMo does not require training data, and does not need any prototype grasp configurations to be taught by kinesthetic demonstration. We present results of real-robot experiments grasping 21 different objects, observed by a wrist-mounted depth camera. All objects are grasped successfully when presented to the robot individually. The robot also successfully clears cluttered heaps of objects by sequentially grasping and lifting objects until none remain.


Title: A Framework for Robot Grasp Transferring with Non-rigid Transformation
Abstract: Grasp planning is essential for robots to execute dexterous tasks. Solving the optimal grasps for various objects online, however, is challenging due to the heavy computation load during exhaustive sampling, and the difficulties to consider task requirements. This paper proposes a framework to combine analytic approach with learning for efficient grasp generation. The example grasps are taught by human demonstration and mapped to similar objects by a non-rigid transformation. The mapped grasps are evaluated analytically and refined by an orientation search to improve the grasp robustness and robot reachability. The proposed approach is able to plan high-quality grasps, avoid collision, satisfy task requirements, and achieve efficient online planning. The effectiveness of the proposed method is verified by a series of experiments.


Title: Using human studies to analyze capabilities of underactuated and compliant hands in manipulation tasks
Abstract: We present a human-subjects study approach that supports the analysis of the manipulation performance of robotic hands that have the same morphology but different actuation and compliance. Specifically, we use this approach to analyze three different types of hands (one underactuated, one fully actuated, one fully actuated with compliant distal joints) as they are used to perform two manipulation tasks. The first task uses a power grasp (spraying with a spray bottle), the second a precision grasp (tracing a line on a bowl with a pen). We show that compliance in the distal joints significantly improves performance and task completion. We also show that humans choose significantly different poses for the same task when using a fully-actuated versus underactuated hand, which also results in superior task performance. Our results suggest that humans use a combination of under-actuated and fully-actuated techniques, which when used on robotic systems would also improve their performance on manipulation tasks.


Title: Affordance Wayfields for Task and Motion Planning
Abstract: Affordances provide a natural means for a robot to describe its agency as actions it can perform on objects. Further, affordances can enable robots to reason complicated, multi-step tasks that involve proper use of a diversity of objects. This paper proposes the concept of affordance wayfields for representing manipulation affordances as objective functions in configuration space. Affordance wayfields quantify how well a path, or sequence of motions, will accomplish an afforded action on an object. Paths that enact affordances can be located by performing a randomized form of gradient descent over affordance wayfields. Incorporating obstacles, or other constraints into wayfields allows our method to adaptively generate valid motions for executing afforded actions. We demonstrate that affordance wayfields can enable robots, such as the Michigan Progress Fetch mobile manipulator, to solve complex real-world tasks such as assembling a table, or loading and unloading objects from a storage chest.


Title: Tactile Regrasp: Grasp Adjustments via Simulated Tactile Transformations
Abstract: This paper presents a novel regrasp control policy that makes use of tactile sensing to plan local grasp adjustments. Our approach determines regrasp actions by virtually searching for local transformations of tactile measurements that improve the quality of the grasp. First, we construct a tactile-based grasp quality metric using a deep convolutional neural network trained on over 2800 grasps. The quality of each grasp, a continuous value between 0 and 1, is determined experimentally by measuring its resistance to external perturbations. Second, we simulate the tactile imprints associated with robot motions relative to the initial grasp by performing rigid-body transformations of the given tactile measurements. The newly generated tactile imprints are evaluated with the learned grasp quality network and the regrasp action is chosen to maximize the grasp quality. Results show that the grasp quality network can predict the outcome of grasps with an average accuracy of 85% on known objects and 75% on novel objects. The regrasp control policy improves the success rate of grasp actions by an average relative increase of 70% on a test set of 8 objects. We provide a video summarizing our approach at https://youtu.be/gjn7DmfpwDk.


Title: Adaptive Autonomous Grasp Selection via Pairwise Ranking
Abstract: Autonomous grasp selection for robot pick-and-place applications makes use of either empirical methods leveraging object databases, which generate grasps for specific objects at the initial cost of modeling effort, or analytical methods, which generalize to novel objects but fail on object subsets that require specific grasping strategies not captured by the algorithm. We introduce a grasp selection algorithm that ranks grasp candidates with a set of grasp metrics augmented with object features, creating an approach that adapts its strategies based on user-specified grasp preferences. We formulate grasp selection as a pairwise ranking problem, which significantly reduces data collection compared to traditional grasp ranking methods and generalizes to novel objects. Our approach outperforms a state-of-the-art grasp calculation baseline and a pointwise ranking formulation of the same problem.


Title: Experience-Based Model Selection to Enable Long-Term, Safe Control for Repetitive Tasks Under Changing Conditions
Abstract: Learning approaches have enabled significant performance improvements in robotic control allowing robots to execute motions that were previously impossible. The majority of the work to date, however, assumes that the parts to be learned are static or slowly changing, which limits their applicability in realistic scenarios with rapid changes in the conditions. This paper presents a method to extend an existing single-mode safe learning controller based on Gaussian Process Regression to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experiences from a large number of previously visited operating conditions, and to safely adapt when a new and distinct operating condition is encountered. This allows the robot to achieve safety and high performance in a large number of operating conditions that do not have to be specified ahead of time. Our approach runs independently from the controller, imposing no additional computation time on the control loop regardless of the number of previous operating conditions considered. We demonstrate the effectiveness of our approach in experiment on a 900 kg ground robot with both physical and artificial changes to its dynamics. All of our experiments are conducted using vision for localization.


Title: Efficient Model Identification for Tensegrity Locomotion
Abstract: This paper aims to identify in a practical manner unknown physical parameters, such as mechanical models of actuated robot links, which are critical in dynamical robotic tasks. Key features include the use of an off-the-shelf physics engine and the Bayesian optimization framework. The task being considered is locomotion with a high-dimensional, compliant Tensegrity robot. A key insight, in this case, is the need to project the space of models into an appropriate lower dimensional space for time efficiency. Comparisons with alternatives indicate that the proposed method can identify the parameters more accurately within the given time budget, which also results in more precise locomotion control.


Title: Robot-driven Trajectory Improvement for Feeding Tasks
Abstract: Kinesthetic learning is a type of learning from demonstration in which the teacher manually moves the robot through the demonstrated trajectory. It shows great promise in the area of assistive robotics since it enables a caretaker who is not an expert in computer programming to communicate a novel task to an assistive robot. However, the trajectory the caretaker demonstrates to solve the task may be a high-cost trajectory for the robot. The demonstrated trajectory could be high-cost because the teacher does not know what trajectories are easy or hard for the robot to perform, which would be due to a limitation of the teacher's knowledge, or because the teacher has difficulty moving all the robotic joints precisely along the desired trajectories, which would be due to a limitation of the teacher's coordination. We propose the Parameterized Similar Path Search (PSPS) algorithm to extend kinesthetic learning so that a robot can improve the learned trajectory over a known cost function. This algorithm is based on active learning from the robot through collaboration between the robot's knowledge of the cost function and the caretaker's knowledge of the constraints of the assigned task.


Title: Accelerating Learning in Constructive Predictive Frameworks with the Successor Representation
Abstract: We propose using the Successor Representation (SR) to accelerate learning in a constructive knowledge system based on General Value Functions (GVFs). In real-world settings, like robotics for unstructured and dynamic environments, it is impossible to model all meaningful aspects of a system and its environment by hand. Instead, robots must learn and adapt to changes in their environment and task, incrementally constructing models from their own experience. GVFs, taken from the field of reinforcement learning (RL), are a way of modeling the world as predictive questions. One approach to such models proposes a massive network of interconnected and interdependent GVFs, which are incrementally added over time. It is reasonable to expect that new, incrementally added predictions can be learned more swiftly if the learning process leverages knowledge gained from past experience. The SR provides a means of capturing regularities that can be reused across multiple GVFs by separating the dynamics of the world from the prediction targets. As a primary contribution of this work, we show that using the SR can improve sample efficiency and learning speed of GVFs in a continual learning setting where new predictions are incrementally added and learned over time. We analyze our approach in a grid-world and then demonstrate its potential on data from a physical robot arm.


Title: Reinforcement Learning with Symbolic Input-Output Models
Abstract: It is well known that reinforcement learning (RL) can benefit from the use of a dynamic prediction model which is learned on data samples collected online from the process to be controlled. Most RL algorithms are formulated in the state-space domain and use state-space models. However, learning state-space models is difficult, mainly because in the vast majority of problems the full state cannot be measured on the system or reconstructed from the measurements. To circumvent this limitation, we propose to use input-output models of the NARX (nonlinear autoregressive with exogenous input) type. Symbolic regression is employed to construct parsimonious models and the corresponding value functions. Thanks to this approach, we can learn accurate models and compute optimal policies even from small amounts of training data. We demonstrate the approach on two simulated examples, a hopping robot and a 1-DOF robot arm, and on a real inverted pendulum system. Results show that our proposed method can reliably determine a good control policy based on a symbolic input-output process model and value function.


Title: A Framework for Teaching Impedance Behaviours by Combining Human and Robot ‘Best Practice’
Abstract: This paper presents a programming by demonstration framework for teaching impedance modulation using human demonstrations. Physiologically, human stiffness and damping are coupled at the muscle level, restricting the ability to modulate impedance according to task demands. Robotic systems often do not have this restriction (stiffness and damping can be varied independently), but the challenge is to devise an appropriate variable impedance profile for a given task. In this paper, the task critical component is first learned for imitation and a robot-specific controller is then blended into the control using the null space. In doing so, the control cheme takes advantage of both human and robot `best practice'. Experimental results on a physical robot suggest an order of magnitude better mean performance, with lower variance, can be achieved using the blended scheme.


Title: Automated Tuning of Nonlinear Model Predictive Controller by Reinforcement Learning
Abstract: One of the major challenges of model predictive control (MPC) for robotic applications is the non-trivial weight tuning process while crafting the objective function. This process is often executed using the trial-and-error method by the user. Consequently, the optimality of the weights and the time required for the process become highly dependent on the skill set and experience of the user. In this study, we present a generic and user-independent framework which automates the tuning process by reinforcement learning. The proposed method shows competency in tuning a nonlinear MPC (NMPC) which is employed for trajectory tracking control of aerial robots. It explores the desirable weights within less than an hour in iterative Gazebo simulations running on a standard desktop computer. The real world experiments illustrate that the NMPC weights explored by the proposed method result in a satisfactory trajectory tracking performance.


Title: Soft-obstacle Avoidance for Redundant Manipulators with Recurrent Neural Network
Abstract: Compressing soft-obstacles secondary to a controlled motion task is common for human beings. While these tasks are nearly trivial for teleoperated robots, they remain a challenging problem in robotic autonomy. Addressing the problem is significant. For example, in Minimally Invasive Surgeries (MISs), safely compressing soft tissues ensures the surgical safety and decreases tissue removal, thus dramatically decreases surgical trauma and operating room time, and leads to improved surgical outcomes. In this work, we define the problem of soft-obstacle avoidance and project the safety motion constraints into the task space and the velocity space. We illustrate the significance of addressing this problem in the robotic surgery scenario. We present a Recurrent Neural Networks (RNNs) based solution, which formulates the problem as an inequality constrained optimization problem and solves it in its dual space. The application of the proposed method was demonstrated in the Raven II surgical robot. Experimental results demonstrated that the proposed method is effective in addressing the soft-obstacle avoidance problem.


Title: GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation
Abstract: We present semi-supervised deep learning approaches for traversability estimation from fisheye images. Our method, GONet, and the proposed extensions leverage Generative Adversarial Networks (GANs) to effectively predict whether the area seen in the input image(s) is safe for a robot to traverse. These methods are trained with many positive images of traversable places, but just a small set of negative images depicting blocked and unsafe areas. This makes the proposed methods practical. Positive examples can be collected easily by simply operating a robot through traversable spaces, while obtaining negative examples is time consuming, costly, and potentially dangerous. Through extensive experiments and several demonstrations, we show that the proposed traversability estimation approaches are robust and can generalize to unseen scenarios. Further, we demonstrate that our methods are memory efficient and fast, allowing for real-time operation on a mobile robot with single or stereo fisheye cameras. As part of our contributions, we open-source two new datasets for traversability estimation. These datasets are composed of approximately 24h of videos from more than 25 indoor environments. Our methods outperform baseline approaches for traversability estimation on these new datasets.


Title: Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning
Abstract: Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.


Title: Real-Time Workload Classification during Driving using HyperNetworks
Abstract: Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks (m-HyperLSTM), a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9% precision and 87.8% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.


Title: Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing
Abstract: An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.


Title: Learning to Pour using Deep Deterministic Policy Gradients
Abstract: Pouring is a fundamental skill for robots in both domestic and industrial environments. Ideally, a robot should be able to pour with high accuracy to specific, pre-defined heights and without spilling. However, due to the complex dynamics of liquids, it is difficult to learn how to pour to achieve these goals. In this paper we present an approach to learn a policy for pouring using Deep Deterministic Policy Gradients (DDPG). We remove the need for collecting training experiences on a real robot, by using a state-of-the-art liquid simulator, which allows for learning the liquid dynamics. We show through our experiments, performed with a PR2 robot, that it is possible to successfully transfer the learned policy to a real robot and even apply it to different liquids.


Title: Learning Sample-Efficient Target Reaching for Mobile Robots
Abstract: In this paper, we propose a novel architecture and a self-supervised policy gradient algorithm, which employs unsupervised auxiliary tasks to enable a mobile robot to learn how to navigate to a given goal. The dependency on the global information is eliminated by providing only sparse range-finder measurements to the robot. The partially observable planning problem is addressed by splitting it into a hierarchical process. We use convolutional networks to plan locally, and a differentiable memory to provide information about past time steps in the trajectory. These modules, combined in our network architecture, produce globally consistent plans. The sparse reward problem is mitigated by our modified policy gradient algorithm. We model the robots uncertainty with unsupervised tasks to force exploration. The novel architecture we propose with the modified version of the policy gradient algorithm allows our robot to reach the goal in a sample efficient manner, which is orders of magnitude faster than the current state of the art policy gradient algorithm. Simulation and experimental results are provided to validate the proposed approach.


Title: Generative Modeling of Multimodal Multi-Human Behavior
Abstract: This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.


Title: Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs
Abstract: For a robot to manipulate an object, it has to understand the functions and the actions that can be subjected to the object. This set of information is known as affordance of the object. Affordances are generally defined by the geometrical structures and physical properties of the objects. In this paper, we present an affordance detection network (ADNet) for detecting object affordances using multimodal input i.e., RGB-D data. The method is based on the state-of-the-art fully convolutional network with two encoding streams and one decoding stream. In the presented formulation, the network learns powerful discriminative features independently from the RGB and depth images, which enables it to abstract rich photometrical and geometrical properties of the objects. The multimodal encoding is combined at multiple stages of the network using the late-fusion strategy and used is for predicting the potential affordances of the objects.


Title: Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments
Abstract: Mobile robot navigation in complex and dynamic environments is a challenging but important problem. Reinforcement learning approaches fail to solve these tasks efficiently due to reward sparsities, temporal complexities and high-dimensionality of sensorimotor spaces which are inherent in such problems. We present a novel approach to train action policies to acquire navigation skills for wheel-legged robots using deep reinforcement learning. The policy maps height-map image observations to motor commands to navigate to a target position while avoiding obstacles. We propose to acquire the multifaceted navigation skill by learning and exploiting a number of manageable navigation behaviors. We also introduce a domain randomization technique to improve the versatility of the training samples. We demonstrate experimentally a significant improvement in terms of data-efficiency, success rate, robustness against irrelevant sensory data, and also the quality of the maneuver skills.


Title: Learning and Generalization of Dynamic Movement Primitives by Hierarchical Deep Reinforcement Learning from Demonstration
Abstract: This paper presents an approach to learn and generalize robotic skills from a demonstration using deep reinforcement learning (deep RL). Dynamic Movement Primitives (DMPs) formulate a nonlinear differential equation and produce the observed movement from a demonstration. However, it is hard to generate new behaviors from using DMPs. Thus, we apply DMPs framework into deep RL as an initial setting for learning the robotic skills. First, we build a network to represent this differential equation, and learn and generalize the movements by optimizing the shape of DMPs with respect to the rewards up to the end of each sequence of movement primitives. In order to do this, we consider a deterministic actor-critic algorithm for deep RL and we also apply a hierarchical strategy. This drastically reduces the search space for a robot by decomposing the task, which allows to solve the sparse reward problem from a complex task. In order to integrate DMPs with hierarchical deep RL, the differential equation is considered as temporal abstraction of option. The overall structure is mainly composed of two controllers: meta-controller and sub-controller. The meta-controller learns a policy over intrinsic goals and a sub-controller learns a policy over actions to accomplish the given goals. We demonstrate our approach on a 6 degree-of-freedom (DOF) arm with a I-DOF gripper and evaluate our approach through a pick-and-place task.


Title: Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network
Abstract: In recent years, various shadow detection methods from a single image have been proposed and used in vision systems; however, most of them are not appropriate for the robotic applications due to the expensive time complexity. This paper introduces a fast shadow detection method using a deep learning framework, with a time cost that is appropriate for robotic applications. In our solution, we first obtain a shadow prior map with the help of multi-class support vector machine using statistical features. Then, we use a semantic-aware patch-level Convolutional Neural Network that efficiently trains on shadow examples by combining the original image and the shadow prior map. Experiments on benchmark datasets demonstrate the proposed method significantly decreases the time complexity of shadow detection, by one or two orders of magnitude compared with state-of-the-art methods, without losing accuracy.


Title: Heterogeneous Sensor-Robot Team Positioning and Mixed Strategy Scheduling
Abstract: We are faced with the problem of optimally placing a heterogeneous team of sensors and effector robots in an area while taking into account the environment, anticipated arrival traffic, and desired power consumption of the team. We stage the problems of anticipating arrival traffic and determining a proper power schedule as an adversarial game, incorporating our analysis of the game in the objective function which evaluates sensor positions. We obtain the set of sensor positions which performs best at the desired power consumption, evaluating the mixed strategy of sensor activity that best counters the anticipated potential arrival paths. To determine an approximate global optima for a large number of heterogeneous nodes, we employ Adaptive Simulated Annealing (ASA) to ensure our algorithm is flexible over a varied range of scenarios. We compare the proposed algorithm to a gradient-based greedy placement algorithm with a uniform power schedule within simulation.


Title: Robotic Subsurface Pipeline Mapping with a Ground-penetrating Radar and a Camera
Abstract: We propose a novel subsurface pipeline mapping method by fusing Ground Penetrating Radar (GPR) scans and camera images. To facilitate the simultaneous detection of multiple pipelines, we model the GPR sensing process and prove hyperbola response for general scanning with non-perpendicular angles. Furthermore, we fuse visual simultaneous localization and mapping outputs, encoder readings with GPR scans to classify hyperbolas into different pipeline groups. We extensively apply the J-Linkage method and maximum likelihood estimation to improve algorithm robustness and accuracy. As the result, we optimally estimate the radii and locations of all pipelines. We have implemented our method and tested it in physical experiments with representative pipeline configurations. The results show that our method successfully reconstructs all subsurface pipes. Moreover, the average localization error is 4.69cm.


Title: Mobile Robot Localization Considering Class of Sensor Observations
Abstract: Localization robustness against environment dynamics is significant for robots to achieve autonomous navigation in unmodified environments. A basic method of improving the robustness of a robot is considering the sensor observations obtained from mapped obstacles and using them for localizing the robot's pose. This study proposes an observation model that considers the class of sensor observations, where “class” categorizes the sensor observations as those obtained from mapped and unmapped obstacles. In the proposed approach, the robot's pose and the class are estimated simultaneously. As a result, the robot's pose can be localized using the sensor observations obtained only from mapped obstacles. First, we evaluated the performance of the proposed approach using simulations. Further, we tested the proposed approach in a real-world mobile robot navigation competition, called “Tsukuba Challenge,” held in Japan. The robustness and effectiveness of the proposed approach against environment dynamics were verified from the experimental results.


Title: A B-Spline Mapping Framework for Long-Term Autonomous Operations
Abstract: This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.


Title: Building Dense Reflectance Maps of Indoor Environments Using an RGB-D Camera
Abstract: The ability to build models of the environment is an essential prerequisite for many robotic applications. In recent years, mapping of dense surface geometry using RGB-D cameras has seen extensive progress. Many approaches build colored models, typically directly using the intensity values provided by the camera. Unfortunately, these intensities are inherently affected by illumination. Therefore, the resulting maps only represent the environment for one specific lighting condition. To overcome this limitation, we propose to build reflectance maps that are invariant against changes in lighting. Our approach estimates the diffuse reflectance of a surface by recovering its radiosity and the corresponding irradiance. As imperfections in this process can significantly degrade the reflectance estimate, we remove outliers in the high dynamic range radiosity estimation and propose a method to refine the reflectance estimate. Our system implements the whole pipeline for offline reconstruction of dense reflectance maps including the segmentation of light emitters in the scene. We demonstrate the applicability of our approach in real-world experiments under varying lighting conditions.


Title: 3D Underground Mapping with a Mobile Robot and a GPR Antenna
Abstract: Automatic subsurface mapping is essential in the construction services, as it is anticipated to become the main operational environment of the future robots to be realized in the respective domain. Towards this direction, the paper at hand, introduces for the first time herein, an integrated framework for subsurface mapping by exploiting a surface operating mobile robot with a Ground Penetrating Radar (GPR). The mobile robot tows the GPR antenna, which is mounted on a specifically designed trailer, and is utilized as the mean to cover the surface area, while at the same time the antenna scans the subsurface by emitting electromagnetic pulses. The gathered data are processed for the construction of a subsurface 3D map. Specifically, image processing techniques, that involve background segmentation, HOG [1] feature extraction, hypothesis verification and matching are applied on the 2D radargram (B-Scan) for the detection of the salient points that correspond to buried utilities. By employing the pulse propagation velocity into the subsurface and the soil utilities, the salient points are expressed in world coordinates and used for the composition of the 3D subsurface map. Our method has been evaluated on a real test site, accompanied by ground-truth annotation data of experts and revealed remarkable performance, exhibiting not only the feasibility of underground mapping but also the capacity to obtain exploitable results for underground robotic applications.


Title: Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
Abstract: Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.


Title: The Effect of Swing Leg Retraction on Biped Walking Stability is Influenced by the Walking Speed and Step-Length
Abstract: Swing Leg Retraction (SLR) is observed in human walking and running. Previous studies have concluded that SLR improves the stability and robustness of biped walking. But this conclusion was based on analysis of robot models that can only walk at a very small range of step-lengths and slow or fixed speeds. By contrast, humans can walk with a large range of speeds and step-lengths. Moreover, human walking patterns have a special feature that has not been considered in the previous studies on SLR effects: At a given walking speed, v, humans prefer a step-length, s, which satisfies the power law, s-vβ. Therefore, previous studies on SLR can't tell us whether their conclusion will still hold in the full range of human walking patterns (i.e., various walking speeds and step-lengths). This is the question we want to answer in this paper. In this study, using a simple biped model, we studied how the SLR affects the walking stability in the full range of human walking speeds/step-lengths. Preliminary analysis of both models suggests the same conclusion: (1) SLR improves the stability more evidently in human-preferred walking patterns than in other walking patterns. (2) In walking patterns that are very unlike human-preferred ones, the SLR improves the stability very little, or even deteriorates it drastically. Therefore, the new finding of our study is that how the SLR affects the biped walking stability depends on the walking speed and step-length. SLR does not always improve the stability of biped walking.


Title: An Analytical Study on Trotting at Constant Velocity and Height
Abstract: Quadrupedal trotting gaits of constant forward velocity and body height are studied. A method is developed, which is structured upon analytical expressions derived from the dynamics of a reduced single-legged model comprised of a point mass, and two actuated rotational joints. The inputs of the method include the robot mass, the leg and actuator properties, and the desired forward velocity, yielding all robot body feasible trajectories and their energy footprints. Thus, the method predicts the maximum forward velocity of a trotting quadruped; it also suggests energetically optimal combinations of body height and step length for a given forward velocity.


Title: Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick
Abstract: The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.


Title: Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)
Abstract: Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.


Title: Sensor-Based Reactive Execution of Symbolic Rearrangement Plans by a Legged Mobile Manipulator
Abstract: We demonstrate the physical rearrangement of wheeled stools in a moderately cluttered indoor environment by a quadrupedal robot that autonomously achieves a user's desired configuration. The robot's behaviors are planned and executed by a three layer hierarchical architecture consisting of: an offline symbolic task and motion planner; a reactive layer that tracks the reference output of the deliberative layer and avoids unanticipated obstacles sensed online; and a gait layer that realizes the abstract unicycle commands from the reactive module through appropriately coordinated joint level torque feedback loops. This work also extends prior formal results about the reactive layer to a broad class of nonconvex obstacles. Our design is verified both by formal proofs as well as empirical demonstration of various assembly tasks.


Title: An Assist-as-Needed Velocity Field Control Scheme for Rehabilitation Robots
Abstract: This paper addresses the problem of assist-as-needed (AAN) control for rehabilitation robots. To achieve a motion which is not explicitly a function of time, the velocity field control is considered in this paper. The proposed new controller consists of a proportional-like feedback term and a neural network (NN) term, where the later is exploited to compensate for the dynamic uncertainties of the system. The AAN property is facilitated by means of a dead-zone function in the feedback control term and a forgetting factor in the adaptation law of NN component. The designed controller guarantees the stability of the system with a bounded control command. The performance of the proposed AAN scheme is validated through the simulation and experiment conducted on a lower-limb exoskeleton.


Title: Robot Controllers Compatible with Human Beam Balancing Behavior
Abstract: Standing on a beam is a challenging motor skill that requires the regulation of upright balance and stability. In this paper, we analyzed the behavior of humans balancing on a narrow beam without footwear. The results revealed high anti-correlation between lumped upper- and lower-body angular momentum. Despite differences in gross measures of balance, interlimb coordination was consistent between the novice and expert subjects, suggesting that both performances could be described with the same balance controller. By simulating a double inverted pendulum model utilizing different balancing controllers described in the robotics literature, we identified that the whole behavior observed from humans standing on a beam was best replicated with controllers that predominantly utilized hip actuation.


Title: Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study
Abstract: The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.


Title: Prediction of Manipulation Action Classes Using Semantic Spatial Reasoning
Abstract: Human-robot interaction strongly benefits from fast, predictive action recognition. For us this is relatively easy but difficult for a robot. To address this problem, here we present a novel prediction algorithm for manipulation action classes in video sequences. Manipulations are first represented using the Enriched Semantic Event Chain (ESEC) framework. This creates a temporal sequence of static and dynamic spatial relations between the objects that take part in the manipulation by which an action can be quickly recognized. We measured performance on 32 ideal as well as real manipulations and compared our method also against a state of the art trajectory-based HMM method for action recognition. We observe that manipulations can be correctly predicted after only (on average) 45% of action's total time and that we are almost twice as fast as the HMM-based method. Finally, we demonstrate the advantage of this framework in a simple robot demonstration comparing two different approaches.


Title: Human Motion Prediction Under Social Grouping Constraints
Abstract: Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.


Title: Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans
Abstract: In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.


Title: Effects of Integrated Intent Recognition and Communication on Human-Robot Collaboration
Abstract: Human-robot interaction research to date has investigated intent recognition and communication separately. In this paper, we explore the effects of integrating both the robot's ability to generate intentional motion and predict the human's motion in a collaborative physical task. We implemented an intent recognition system to recognize the human partner's hand motion intent and a motion planner system to enable the robot to communicate its intent by using legible and predictable motion. We tested this bi-directional intent system in a 2-way within-subjects user study. Results suggest that an integrated intent recognition and communication system may facilitate more collaborative behavior among team members.


Title: After You: Doorway Negotiation for Human-Robot and Robot-Robot Interaction
Abstract: We propose and test an autonomous robot behavior for socially-compliant navigation of doorways with both human and robot interlocutors. Building on previous work for “aggressive” interaction between robots to resolve navigation deadlocks in corridors, we demonstrate an “assertive” robot that negotiates right-of-way when faced with a human or other robot. The negotiation is implemented using only motion and common navigation sensors, without explicit message-passing. Our goal is for the correct agent to take priority, as decided both by time-efficiency and as judged subjectively by naive human participants. Our contribution is a practical method for doorway negotiation, and a study of human users' responses to a robot that appears to participate in existing social customs surrounding doors. Our method is evaluated with robot-robot experiments and a human-robot interaction study with nonexpert users.


Title: The Power of Color: A Study on the Effective Use of Colored Light in Human-Robot Interaction
Abstract: In times of more and more complex interaction techniques, we point out the powerfulness of colored light as a simple and cheap feedback mechanism. Since it is visible over a distance and does not interfere with other modalities, it is especially interesting for mobile robots. In an online survey, we asked 56 participants to choose the most appropriate colors for scenarios that were presented in the form of videos. In these scenarios a mobile robot accomplished tasks, in some with success, in others it failed because the task is not feasible, in others it stopped because it waited for help. We analyze in what way the color preferences differ between these three categories. The results show a connection between colors and meanings and that it depends on the participants' technical affinity, experience with robots and gender how clear the color preference is for a certain category. Finally, we found out that the participants' favorite color is not related to color preferences.


Title: Neuroscientifically-Grounded Research for Improved Human-Robot Interaction
Abstract: The present study highlights the benefits of using well-controlled experimental designs, grounded in experimental psychology research and objective neuroscientific methods, for generating progress in human-robot interaction (HRI) research. More specifically, we aimed at implementing a well-studied paradigm of attentional cueing through gaze (the so-called “joint attention” or “gaze cueing”) in an HRI protocol involving the iCub robot. Similarly to documented results in gaze-cueing research, we found faster response times and enhanced event-related potentials of the EEG signal for discrimination of cued, relative to uncued, targets. These results are informative for the robotics community by showing that a humanoid robot with mechanistic eyes and human-like characteristics of the face is in fact capable of engaging a human in joint attention to a similar extent as another human would do. More generally, we propose that the methodology of combining neuroscience methods with an HRI protocol, contributes to understanding mechanisms of human social cognition in interactions with robots and to improving robot design, thanks to systematic and well-controlled experimentation tapping onto specific cognitive mechanisms of the human, such as joint attention.


Title: Move Base Flex A Highly Flexible Navigation Framework for Mobile Robots
Abstract: We present Move Base Flex (MBF), a highly flexible, modular, map-independent, open-source navigation framework for use in ROS. MBF provides modular actions for executing plugins for path planning, motion control, and recovery. These actions define interfaces for external executives to allow highly flexible navigation strategies, which can be intertwined with other robot tasks. MBF has been successfully deployed in a professional setting at customer facilities to control robots in highly dynamic environments. We compare MBF with the well-known move_base and present the architecture as well as different deployment approaches, including how MBF can be used with different executives to perform complex navigation tasks interleaved with other robot operations.


Title: Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
Abstract: Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.


Title: PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
Abstract: Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.


Title: Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction
Abstract: In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.


Title: Autonomous Acquisition of Behavior Trees for Robot Control
Abstract: Behavior trees (BT) are a popular control architecture in the computer game industry, and have been more recently applied in robotics. One open question is how can intelligent agents/robots autonomously acquire their behavior trees for task level control? In contrast with existing approaches that either refine an initially given BT, or directly build the BT based on human feedback/demonstration, we leverage reinforcement learning (RL) that allows robots to autonomously learn control policies by repeated task interaction, but often expressed in a language more difficult to interpret than BTs. The learned control policy is then converted to a behavior tree via our proposed decanonicalization algorithm. The feasibility of this idea is based on a proposed notion of canonical behavior trees (CBT). In particular, we show (1) CBTs are sufficiently expressive to capture RL control policies, and (2) that RL can be independent of an optimal behavior permutation, despite the BT convention of left-to-right priority, thus obviating the need for a combinatorial search. Two evaluation domains help illustrate our approach.


Title: Learning-Based Modular Task-Oriented Grasp Stability Assessment
Abstract: Assessing grasp stability is essential to prevent the failure of robotic manipulation tasks due to sensory data and object uncertainties. Learning-based approaches are widely deployed to infer the success of a grasp. Typically, the underlying model used to estimate the grasp stability is trained for a specific task, such as lifting, hand-over, or pouring. Since every task has individual stability demands, it is important to adapt the trained model to new manipulation actions. If the same trained model is directly applied to a new task, unnecessary grasp adaptations might be triggered, or in the worst case, the manipulation might fail. To address this issue, we divide the manipulation task used for training into seven sub-tasks, defined as modular tasks. We deploy a learning-based approach and assess the stability for each modular task separately. We further propose analytical features to reduce the dimensionality and the redundancy of the tactile sensor readings. A main task can thereby be represented as a sequence of relevant modular tasks. The stability prediction of the main task is computed based on the inferred success labels of the modular tasks. Our experimental evaluation shows that the proposed feature set lowers the prediction error up to 5.69% compared to other sets used in state-of-the-art methods. Robotic experiments demonstrate that our modular task-oriented stability assessment avoids unnecessary grasp force adaptations and regrasps for various manipulation tasks.


Title: Interactive Robotic Manipulation of Elastic Objects
Abstract: In this paper, we address the challenge of robotic manipulation of elastically deforming objects. To this end, we model elastic objects using the Finite Element Method. Through a quasi-static assumption, we leverage sensitivity analysis to mathematically model how changes in the robot's configuration affect the deformed shape of the object being manipulated. This enables an interactive, simulation-based control methodology, wherein user-specified deformations for the elastic objects are automatically mapped to joint angle commands. The optimization formulation we introduce is general, operates directly within a robot's workspace and can readily incorporate joint limits as well as collision avoidance between the links. We validate our control methodology on a YuMi® IRB 14000, which we use to manipulate a variety of elastic objects.


Title: Domain Randomization and Generative Models for Robotic Grasping
Abstract: Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.


Title: Intrinsically Motivated Self-Supervised Deep Sensorimotor Learning for Grasping
Abstract: Deep learning has been successful in a variety of applications that have high-dimensional state spaces such as object recognition, video games, and machine translation. Deep neural networks can automatically learn important features from high-dimensional state given large training datasets. However, the success of deep learning in robot systems in the realworld is limited due to the cost of obtaining these large datasets. To overcome this problem, we propose an information-theoretic, intrinsically motivated, self-labeling mechanism using closed-loop control states. Taking this approach biases exploration to informative interactions-as such, a robot requires much less training to achieve reliable performance. In this paper, we explore the impact such an approach has on learning how to grasp objects. We evaluate different intrinsic motivators present in the literature applied appropriately in our framework and discuss the benefits and drawbacks of each.


Title: Manipulation Planning Under Changing External Forces
Abstract: We present a manipulation planning algorithm for a robot to keep an object stable under changing external forces. We particularly focus on the case where a human may be applying forceful operations, e.g. cutting or drilling, on an object that the robot is holding. The planner produces an efficient plan by intelligently deciding when the robot should change its grasp on the object as the human applies the forces. The planner also tries to choose subsequent grasps such that they will minimize the number of regrasps that will be required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the problem of bimanual regrasp planning, where the object is not placed on a support surface, but instead it is held by a single gripper until the second gripper moves to a new position on the object. This requires the planner to also reason about the stability of the object under gravity. We provide an implementation on a bimanual robot and present experiments to show the performance of our planner.


Title: Jacquard: A Large Scale Dataset for Robotic Grasp Detection
Abstract: Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset.


Title: Planning Hand-Arm Grasping Motions with Human-Like Appearance
Abstract: This paper addresses the problem of obtaining human-like motions on hand-arm robotic systems performing grasping actions. The focus is set on the coordinated movements of the robotic arm and the anthropomorphic mechanical hand, with which the arm is equipped. For this, human movements performing different grasps are captured and mapped to the robot in order to compute the human hand synergies. These synergies are used to both obtain human-like movements and to reduce the complexity of the planning phase by reducing the dimension of the search space. In addition, the paper proposes a sampling-based planner, which guides the motion planning following the synergies and considering different types of grasps. The introduced approach is tested in an application example and thoroughly compared with a state-of-the-art planning algorithm, obtaining better results.


Title: Reactive Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps
Abstract: In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.


Title: Integrating Human-Provided Information into Belief State Representation Using Dynamic Factorization
Abstract: In partially observed environments, it can be useful for a human to provide the robot with declarative information that represents probabilistic relational constraints on properties of objects in the world, augmenting the robot's sensory observations. For instance, a robot tasked with a search-and-rescue mission may be informed by the human that two victims are probably in the same room. An important question arises: how should we represent the robot's internal knowledge so that this information is correctly processed and combined with raw sensory information? In this paper, we provide an efficient belief state representation that dynamically selects an appropriate factoring, combining aspects of the belief when they are correlated through information and separating them when they are not. This strategy works in open domains, in which the set of possible objects is not known in advance, and provides significant improvements in inference time over a static factoring, leading to more efficient planning for complex partially observed tasks. We validate our approach experimentally in two open-domain planning problems: a 2D discrete gridworld task and a 3D continuous cooking task. A supplementary video can be found at http://tinyurl.com/chitnis-iros-18.


Title: Simultaneous Task Allocation and Planning Under Uncertainty
Abstract: We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.


Title: Grid-Based Motion Planning Using Advanced Motions for Hexapod Robots
Abstract: This paper presents the motion planning framework for a hexapod, based on advanced motions, for accessing challenging spaces, namely narrow pathways and large holes, both of which are surrounded by walls. The advanced motions, wall and chimney walking, utilise environment surfaces that are perpendicular to the ground plane to support the robot motion. Such techniques have not yet been studied in the literature. The hierarchical planning framework proposed here is an extension to existing approaches which have only considered ground walking where foothold contacts are confined to the ground plane. During the pre-processing phase of the 2.5D grid map, the motion primitives employed are assessed for each cell and stacked to the graph if valid. The A* algorithm is then used to find a path to the goal position. Following that, the path is post-processed to smoothen the motions and generate a continuous path. Footholds are then selected along the path. The framework has been evaluated in simulation on the custom-designed Corin hexapod. The resulting path enables access to areas that are previously thought to be inaccessible and reduces the travelling distance compared to previous studies.


Title: Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment
Abstract: Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10-5Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.


Title: Progress and Prospects of EAST Remote Maintenance System
Abstract: Fast inspection and light maintenance capability is already a clear demand to control the tokamak condition and improve the efficiency of the experimental campaigns. EAST remote maintenance system has been developed to implement inspection and grasping tasks during plasma. The paper presents design description of EAMA (EAST articulated maintenance arm) robot, the gripper and the CASK. The field commissioning was performed both in mockup and EAST tokamak to demonstrate the availability and functionalities of EAMA system. To be able to realize fully routine operation on EAST, improvement of EAMA control system was proposed with integration developed algorithm, such as the robot flexible model modeling, vision servo, motion planning, etc. Finally, thoughts for CFETR In-Vessel Inspection System (CIVIS) are given.


Title: Pose Estimation for Mobile Robots to Maximise Data Quality of Fixed-Focus Laser Diagnostics in Hazardous Environments
Abstract: Characterisation of nuclear environments is critical for long term operation and decommissioning. Laser Induced Breakdown Spectroscopy (LIBS) is an example of a scientific instrument that could be deployed to aid in characterisation of unknown environments. LIBS consists of a high intensity pulsed laser being focussed down onto a target to create a plasma, and optical emission from the plasma is then used to determine elemental composition of unknown materials. For robots deployed with these instruments in extreme environments, mission time can be limited by hazards present such as radiation. Once deployed a robot must be able to collect the best data possible whilst maximising operational runtime. We present a data quality based probabilistic approach to robot pose estimation to maximise data quality, by considering optimum sensor placement whilst avoiding harmful environmental features such as radiation for a fixed-focus laser diagnostic such as LIBS. This approach is able to determine optimum robot poses for arbitrary targets in 3D for arbitrary diagnostic mounting with respect to the robot. The approach is able to avoid obstacles and avoid occlusion of the target by said obstacles. This can be used as part of autonomous investigation and characterisation performed by mobile robots in hazardous environments.


Title: A Variational Feature Encoding Method of 3D Object for Probabilistic Semantic SLAM
Abstract: This paper presents a feature encoding method of complex 3D objects for high-level semantic features. Recent approaches to object recognition methods become important for semantic simultaneous localization and mapping (SLAM). However, there is a lack of consideration of the probabilistic observation model for 3D objects, as the shape of a 3D object basically follows a complex probability distribution. Furthermore, since the mobile robot equipped with a range sensor observes only a single view, much information of the object shape is discarded. These limitations are the major obstacles to semantic SLAM and view-independent loop closure using 3D object shapes as features. In order to enable the numerical analysis for the Bayesian inference, we approximate the true observation model of 3D objects to tractable distributions. Since the observation likelihood can be obtained from the generative model, we formulate the true generative model for 3D object with the Bayesian networks. To capture these complex distributions, we apply a variational auto-encoder. To analyze the approximated distributions and encoded features, we perform classification with maximum likelihood estimation and shape retrieval.


Title: A Novel OCR-RCNN for Elevator Button Recognition
Abstract: Autonomous elevator operation is considered an intelligent solution in handling the inter-floor navigation problem of service robots. As one of the most fundamental steps, elevator button recognition starts to receive more and more attention. However, due to the challenging image conditions and severe class imbalance problem, the performance of existing results is unsatisfying. In this paper, we propose to combine an optical character recognition (OCR) network and the Faster RCNN architecture into a single neural network, called OCR-RCNN to facilitate an end-to-end training and elevator button recognition procedure. To verify our method, we collect a large dataset of elevator panels and carry out extensive comparative experiments. The experiment results show that our method can greatly outperform the traditional recognition pipelines, yielding an accurate and robust performance on recognizing untrained elevator buttons.


Title: Cost Functions for Robot Motion Style
Abstract: We focus on autonomously generating robot motion for day to day physical tasks that is expressive of a certain style or emotion. Because we seek generalization across task instances and task types, we propose to capture style via cost functions that the robot can use to augment its nominal task cost and task constraints in a trajectory optimization process. We compare two approaches to representing such cost functions: a weighted linear combination of hand-designed features, and a neural network parameterization operating on raw trajectory input. For each cost type, we learn weights for each style from user feedback. We contrast these approaches to a nominal motion across different tasks and for different styles in a user study, and find that they both perform on par with each other, and significantly outperform the baseline. Each approach has its advantages: featurized costs require learning fewer parameters and can perform better on some styles, but neural network representations do not require expert knowledge to design features and could even learn more complex, nuanced costs than an expert can easily design.


Title: Imitation Learning for Object Manipulation Based on Position/Force Information Using Bilateral Control
Abstract: This study proposes an imitation learning method based on force and position information. Force information is required for precise object manipulation but is difficult to obtain because the acting and reaction forces cannot be separated. To separate the forces, we proposed to introduce bilateral control, in which the acting and reaction forces are divided using two robots. In the proposed method, two models of neural networks learn a task; to draw a line along a ruler. We verify the possibility that force information is essential to imitate the human skill of object manipulation.


Title: Learning Implicit Sampling Distributions for Motion Planning
Abstract: Sampling-based motion planners have experienced much success due to their ability to efficiently and evenly explore the state space. However, for many tasks, it may be more efficient to not uniformly explore the state space, especially when there is prior information about its structure. Previous methods have attempted to modify the sampling distribution using hand selected heuristics that can work well for specific environments but not universally. In this paper, a policy-search based method is presented as an adaptive way to learn implicit sampling distributions for different environments. It utilizes information from past searches in similar environments to generate better distributions in novel environments, thus reducing overall computational cost. Our method can be incorporated with a variety of sampling-based planners to improve performance. Our approach is validated on a number of tasks, including a 7DOF robot arm, showing marked improvement in number of collision checks as well as number of nodes expanded compared with baseline methods.


Title: Online Temporal Calibration for Monocular Visual-Inertial Systems
Abstract: Accurate state estimation is a fundamental module for various intelligent applications, such as robot navigation, autonomous driving, virtual and augmented reality. Visual and inertial fusion is a popular technology for 6-DOF state estimation in recent years. Time instants at which different sensors' measurements are recorded are of crucial importance to the system's robustness and accuracy. In practice, timestamps of each sensor typically suffer from triggering and transmission delays, leading to temporal misalignment (time offsets) among different sensors. Such temporal offset dramatically influences the performance of sensor fusion. To this end, we propose an online approach for calibrating temporal offset between visual and inertial measurements. Our approach achieves temporal offset calibration by jointly optimizing time offset, camera and IMU states, as well as feature locations in a SLAM system. Furthermore, the approach is a general model, which can be easily employed in several feature-based optimization frameworks. Simulation and experimental results demonstrate the high accuracy of our calibration approach even compared with other state-of-art offline tools. The VIO comparison against other methods proves that the online temporal calibration significantly benefits visual-inertial systems. The source code of temporal calibration is integrated into our public project, VINS-Mono1.


Title: Modular Sensor Fusion for Semantic Segmentation
Abstract: Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.


Title: Robust Sensor Fusion with Self-Tuning Mixture Models
Abstract: A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.


Title: Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates
Abstract: In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.


Title: Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization
Abstract: Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.


Title: On the Use of Energy Tanks for Multi-Robot Interconnection
Abstract: In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.


Title: A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications
Abstract: Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.


Title: Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks
Abstract: Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.


Title: Optimal Redeployment of Multirobot Teams for Communication Maintenance
Abstract: In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.


Title: Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
Abstract: We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.


Title: Algorithms for Task Allocation in Homogeneous Swarm of Robots
Abstract: In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.


Title: Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform
Abstract: This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.


Title: Hybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs
Abstract: The factor graph framework is a convenient modeling technique for robotic state estimation where states are represented as nodes, and measurements are modeled as factors. When designing a sensor fusion framework for legged robots, one often has access to visual, inertial, joint encoder, and contact sensors. While visual-inertial odometry has been studied extensively in this framework, the addition of a preintegrated contact factor for legged robots has been only recently proposed. This allowed for integration of encoder and contact measurements into existing factor graphs, however, new nodes had to be added to the graph every time contact was made or broken. In this work, to cope with the problem of switching contact frames, we propose a hybrid contact preintegration theory that allows contact information to be integrated through an arbitrary number of contact switches. The proposed hybrid modeling approach reduces the number of required variables in the nonlinear optimization problem by only requiring new states to be added alongside camera or selected keyframes. This method is evaluated using real experimental data collected from a Cassie-series robot where the trajectory of the robot produced by a motion capture system is used as a proxy for ground truth. The evaluation shows that inclusion of the proposed preintegrated hybrid contact factor alongside visual-inertial navigation systems improves estimation accuracy as well as robustness to vision failure, while its generalization makes it more accessible for legged platforms.


Title: Stable, Autonomous, Unknown Terrain Locomotion for Quadrupeds Based on Visual Feedback and Mixed-Integer Convex Optimization
Abstract: This paper presents a complete motion planning approach for quadruped locomotion across an unknown terrain using a framework based on mixed-integer convex optimization and visual feedback. Vision data is used to find convex polygons in the surrounding environment, which acts as potentially feasible foothold regions. Then, a goal position is initially provided, which the best feasible destination planner uses to solve for an actual feasible goal position based on the extracted polygons. Next, a footstep planner uses the feasible goal position to plan a fixed number of footsteps, which may or may not result in the robot reaching the position. The center of mass (COM) trajectory planner using quadratic programming is extended to solve for a trajectory in 3D space while maintaining convexity, which reduces the computation time, allowing the robot to plan and execute motions online. The suggested method is implemented as a policy rather than a path planner, but its performance as a path planner is also shown. The approach is verified on both simulation and on a physical robot, ALPHRED, walking on various unknown terrains.


Title: Iterative Learning of Energy-Efficient Dynamic Walking Gaits
Abstract: Dynamic walking robots have the potential for efficient and lifelike locomotion, but computing efficient gaits and tracking them is difficult in the presence of under-modeling. Iterative Learning Control (ILC) is a method to learn the control signal to track a periodic reference over several attempts, augmenting a model with online data. Terminal ILC (TILC), a variant of ILC, allows other performance objectives to be addressed at the cost of ignoring parts of the reference. However, dynamic walking robot gaits are not necessarily periodic in time. In this paper, we adapt TILC to jointly optimize final foot placement and energy efficiency on dynamic walking robots by indexing by a phase variable instead of time, yielding “phase-indexed TILC” (θ - TILC). When implemented on a five-link walker in simulation, θ- TILC learns a more energy-efficient walking motion compared to traditional time-indexed TILC.


Title: Bipedal Hopping: Reduced-Order Model Embedding via Optimization-Based Control
Abstract: This paper presents the design and validation of controlling hopping on the 3D bipedal robot Cassie. A spring-mass model is identified from the kinematics and compliance of the robot. The spring stiffness and damping are encapsulated by the leg length, thus actuating the leg length can create and control hopping behaviors. Trajectory optimization via direct collocation is performed on the spring-mass model to plan jumping and landing motions. The leg length trajectories are utilized as desired outputs to synthesize a control Lyapunov function based quadratic program (CLF-QP). Centroidal angular momentum, taking as an addition output in the CLF-QP, is also stabilized in the jumping phase to prevent whole body rotation in the underactuated flight phase. The solution to the CLF-QP is a nonlinear feedback control law that achieves dynamic jumping behaviors on bipedal robots with compliance. The framework presented in this paper is verified experimentally on the bipedal robot Cassie.


Title: An Actuator Design Criterion to Maximize Physical Balance Recovery
Abstract: This paper first presents a formula to predict the largest balance disturbance from which a legged robot can recover without taking a step. It then presents an actuator design criterion derived from this formula that maximizes the robot's ability to recover. In this study, it is assumed that the robot is using a single major joint (e.g, a hip joint) to perform its balance recovery movement, and that the actuator consists of an electric motor and reduction gear. It is also assumed that the robot's support polygon is sufficiently small that it can be approximated as a point, and that the balance recovery motion is essentially planar, so that a 2-D analysis remains valid in 3-D. Finally, it is assumed that, for the purpose of studying balance recovery motion, the robot can be approximated by a reaction wheel pendulum. The theory has been tested experimentally on a robot designed to be good at balancing, and was found to agree closely with experimental results.


Title: Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors
Abstract: During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.


Title: Trajectory Optimization of Robot-Assisted Endovascular Catheterization with Reinforcement Learning
Abstract: Emerging robot-assisted endovascular intervention has the potential to reduce X-ray radiations to the operator while enhancing the stability and dexterity of catheter manipulation. Supervised and shared autonomy of endovascular procedures could add further improvements in reduced fatigue and cognitive workloads of the operator, higher success rates of cannulation and improved surgical outcomes. However, robotic path planning for endovascular procedure is challenging due to complex and non-linear flow dynamics inside the vasculature. This paper presents a learning-based robotic catheterization platform addressing those challenges, this approach incorporates path integral reinforcement learning (RL) framework based on dynamic movement primitives (DMP) to enhance catheterization tasks by a customized robotic manipulator. The robotic trajectories were optimized through RL in order to avoid unwanted contacts between the catheter tip and the vessel wall. The proposed methods can adapt to different flow simulations, vascular models, and catheterization tasks. The quality of the catheterization was evaluated with performance metrics. The results show significant refinement of catheter paths by the proposed approach, resulting in shorter overall lengths and fewer contact forces, which can potentially reduce risks in endothelial wall damages, embolization, and stroke. The results support the development of robotic path planning for endovascular procedures as well as designing intelligent, hands-on robotic navigation platforms.


Title: ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery
Abstract: Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.


Title: I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration
Abstract: This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users.


Title: Recursive Bayesian Human Intent Recognition in Shared-Control Robotics
Abstract: Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.


Title: A Novel Shared Position Control Method for Robot Navigation Via Low Throughput Human-Machine Interfaces
Abstract: In this paper, we analyze systems with low throughput human-machine interfaces (such as a brain-computer interface, single switch interface) from the controls perspective. We develop some principles for performance improvement in such systems based on the parallelization of inference and robot motion. The proposed principles are used to design a novel shared position control to navigate a circular massless holonomic robot in a known environment. The system is implemented in simulation and integrated with a real robotic wheelchair. Robot experiments demonstrated the viability of the proposed navigation method in various modes of operation.


Title: Robot Identification and Localization with Pointing Gestures
Abstract: We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.


Title: Establishing Appropriate Trust via Critical States
Abstract: In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.


Title: Interaction System Based on an Avatar Projected on a Pyramidal Display
Abstract: In this paper an interaction system based on a three dimensional virtual head projected onto a pyramidal display is proposed. The proposed system makes use of a social robot behavioral architecture already developed in our lab, which allows us to interchange developments between our robotic realizations and the 3D avatar. The overall system is divided into two parts: back projection subsystem and expression generator subsystem. The back projection subsystem projects a three-dimensional avatar onto a pyramidal structure in order to achieve a sensation of depth and realism. The expression generator subsystem carries out the avatar animations using shape keys and bones, following the Facial Action Coding System (FACS). The system consists in several nodes that are integrated in ROS middleware (Robotic Operating System), and includes a user interface that makes the avatar teleoperation easier (the package is avaible in github public respository). In order to evaluate the expressiveness of the system, two sets of experiments have been performed: one to analyze the avatar's gestural ability, that is, its capability to perform expressions that can be identified by an observer, and a second experiment to measure the emotion displaying ability in terms of valence and arousal.


Title: Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions
Abstract: Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.


Title: Underwater Surveying via Bearing Only Cooperative Localization
Abstract: Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.


Title: An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication
Abstract: Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.


Title: Estimating Achievable Range of Ground Robots Operating on Single Battery Discharge for Operational Efficacy Amelioration
Abstract: Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.


Title: An Adaptive Robotic Gripper with L-Shape Fingers for Peg-in-Hole Tasks
Abstract: This paper develops an adaptive gripper for peg-in-hole tasks. Conventional grippers require complicated compliant mechanisms or complicated control strategy and force sensing to successfully insert pegs into holes. Different from them, this paper proposes a simple gripper with an L-shape finger as a low-cost peg-in-hole solution. The basic idea is to divide a peg-in-hole process into a preparation phase and an execution phase, and eliminate uncertainty step-by-step by pushing using the L-shape finger in the preparation phase. The robustness of the gripper for peg-in-hole tasks is examined by repeated executions for different pegs in the International Robotic Exhibition 2017 (IREX) in Tokyo. The experimental section presents details of the executions, and qualitatively shows the high performance of the proposed gripper.


Title: Interleaving Hierarchical Task Planning and Motion Constraint Testing for Dual-Arm Manipulation
Abstract: In recent years the topic of combining motion and symbolic planning to perform complex tasks in the field of robotics has received a lot of attention. The underlying idea is to have access at once to the reasoning capabilities of a task planner and to the ability of the motion planner to verify that the plan is feasible from a physical and geometrical point of view. The present work describes a framework to perform manipulation tasks that require the use of two robotic manipulators. To do so we employ a Hierarchical Task Network (HTN) planner interleaved with geometric constraint verification. In this framework we also consider observation actions and handle noisy perceptions from a probabilistic perspective. These ideas are put into practice by means of an experimental set-up in which two Barrett WAM robots have to cooperatively solve a geometric puzzle. Our findings provide further evidence that considering explicitly physical constraints during task planning, rather than deferring their validation to the moment of execution, is advantageous in terms of execution time and breadth of situations that can be handled.


Title: Sequence Pattern Extraction by Segmenting Time Series Data Using GP-HSMM with Hierarchical Dirichlet Process
Abstract: Humans recognize perceived continuous information by dividing it into significant segments such as words and unit motions. We believe that such unsupervised segmentation is also an important ability that robots need to learn topics such as language and motions. Hence, in this paper, we propose a method for dividing continuous time-series data into segments in an unsupervised manner. To this end, we proposed a method based on a hidden semi-Markov model with Gaussian process (GP-HSMM). If Gaussian processes, which are nonparametric models, are used, unit motion patterns can be extracted from complicated continuous motion. However, this approach requires the number of classes of segments in the time-series data in advance. To overcome this problem, in this paper, we extend GP-HSMM to a nonparametric Bayesian model by introducing a hierarchical Dirichlet process (HDP) and propose the hierarchical Dirichlet processes-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). In the nonparametric Bayesian model, an infinite number of classes is assumed and it becomes difficult to estimate the parameters naively. Instead, the parameters of the proposed HDP-GP-HSMM are estimated by applying slice sampling. In the experiments, we use various synthetic and motion-capture data to show that our proposed model can estimate a more correct number of classes and achieve more accurate segmentation than baseline methods.


Title: Persistent Anytime Learning of Objects from Unseen Classes
Abstract: We present a fast and very effective method for object classification that is particularly suited for robotic applications such as grasping and semantic mapping. Our approach is based on a Random Forest classifier that can be trained incrementally. This has the major benefit that semantic information from new data samples can be incorporated without retraining the entire model. Even if new samples from a previously unseen class are presented, our method is able to perform efficient updates and learn a sustainable representation for this new class. Further features of our method include a very fast and memory-efficient implementation, as well as the ability to interrupt the learning process at any time without a significant performance degradation. Experiments on benchmark data for robotic applications show the clear benefits of our incremental approach and its competitiveness with standard offline methods in terms of classification accuracy.


Title: Adaptive Robot Body Learning and Estimation Through Predictive Coding
Abstract: The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.


Title: Online Learning of Body Orientation Control on a Humanoid Robot Using Finite Element Goal Babbling
Abstract: How can high dimensional robots learn general sets of skills from experience in the real world? Many previous approaches focus on maximizing a single utility function and require large datasets of experience to do this, something that is not possible to collect outside of simulation as every data point is expensive both in time and in a potential wear down of the robot. This paper addresses this question using a newly developed framework called Finite Element Goal Babbling (FEGB). FEGB is an online learning method that aims at providing general control over some measurable feature, in contrast to optimizing it to some given utility function. It generalizes standard goal babbling by breaking down the full learning problem into local sub-problems, and combining it with a planner that learns how to navigate between these subproblems. We test FEGB using a real humanoid robot Nao, and find that it could quickly learn to robustly control its body orientation. After only 20-30 minutes of training, the robot could freely move into any body orientation between lying on either side and on its back. Rapid learning of body orientation control in high dimensional real robots is largely an unexplored field of robotics, and although many challenges remain, FEGB shows a feasible approach to the problem.


Title: Active Model Learning and Diverse Action Sampling for Task and Motion Planning
Abstract: The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world. In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world? We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.


Title: Improving Reinforcement Learning Pre-Training with Variational Dropout
Abstract: Reinforcement learning has been very successful at learning control policies for robotic agents in order to perform various tasks, such as driving around a track, navigating a maze, and bipedal locomotion. One significant drawback of reinforcement learning methods is that they require a large number of data points in order to learn good policies, a trait known as poor data efficiency or poor sample efficiency. One approach for improving sample efficiency is supervised pre-training of policies to directly clone the behavior of an expert, but this suffers from poor generalization far from the training data. We propose to improve this by using Gaussian dropout networks with a regularization term based on variational inference in the pre-training step. We show that this initializes policy parameters to significantly better values than standard supervised learning or random initialization, thus greatly reducing sample complexity compared with state-of-the-art methods, and enabling an RL algorithm to learn optimal policies for high-dimensional continuous control problems in a practical time frame.


Title: A Framework for Dexterous Manipulation
Abstract: In this work, we introduce a framework for performing dexterous manipulations on the humanoid robot Robonaut-2. This framework memorizes how actions change perceptions and can learn a sequence of actions based on demonstrations. With the anthropomorphic Robonaut-2 hand and arm, a variety of manipulation tasks such as grasping novel objects, rotating a drill for grasping, and tightening a bolt with a ratchet can be accomplished. This framework was also used to compete in the IROS2018 Fan Robotic Challenge that requires manipulating a hand fan and was a winner of the phase I modality A competition.


Title: An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge
Abstract: The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.


Title: Development of Low-Inertia High-Stiffness Manipulator LIMS2 for High-Speed Manipulation of Foldable Objects
Abstract: In this paper, a dual-arm robot system for high-speed manipulations, which is named LIMS2-AMBIDEX and is developed to compete in the IROS2018 Robotic Challenge, is presented. It has two seven-degrees-of-freedom (DO F) lightweight arms, a three-DOF head, and a one-DOF gripper to manipulate foldable objects. Because all the heavy actuators are placed at the shoulder, it has remarkably low mass beyond the shoulder (2.63 kg), which guarantees an inherent safety at high speeds. Utilizing tension-amplification mechanisms, the high stiffness and strength are achieved, and thus it has the control performance comparable to conventional industrial manipulators. A unique three-DOF wrist mechanism, whose motions directly represent the quaternion values of the joint orientation, can manipulate objects without singular points in the entire range of motion. In order to utilize the object's inertia during rapid manipulation, the gripper was specially designed: it has a one-DOF finger to grasp the upper rib of the foldable fan and two supporting forks to grasp the bottom rib stably. For real-time performance and increased scalability, a software framework was developed based on Robot Operating System (ROS). The real-time capability is achieved by using the real-time development framework Xenomai and the high-speed communication protocol EtherCAT. As most of the algorithms are implemented in the distributed nodes using ROS, it is convenient to expand, improve, and replace the algorithms. Consequentially, the entire motion of the Fan Robotic Challenge Phase I Modality B required 1.05 s, which is substantially faster than a similar manipulation by most humans.


Title: Flamen − 7 DOF Robotic Arm to Manipulate a Spanish Fan
Abstract: A Spanish fan is a hand held traditional fan which is used as an accessory and also by Flamenco dancers. The manipulation of the fan is quite difficult as it involves dynamic motion which includes opening, flapping and closing the fan along a pivotal point. The key points include the motion to be quick and the fan to be opened to the maximum degree possible without human intervention. A robotic arm with 7 Degrees of Freedom (DOF) is used to manipulate the autonomous motion. The fan placed on the table is localized and detected using a camera by background subtraction, masking and filtering; post which the contour of the fan is detected. The pixels obtained is then transformed into real life coordinates. The Dynamixel motors then traverses to the coordinates of the fan's position to grasp, open, flap, close and put the fan down.


Title: IROS 2018 Fan Challenge - Team DLR Augsburg
Abstract: It's a hot summer in 2021 and the blistering sun is shining upon Madrid. You are enjoying some tinto de verano on your terraza. Sizzling in the scorching heat, you are trying to relax. With a simple gesture you call your robotic assistant to help you cool down a little bit. Without further ado, your robot provides some relaxing shade holding a parasol for you, picks up a fan autonomously and starts waving it and the gentle breeze brings you some light relief.


Title: Real-Time Light Field Processing for Autonomous Robotics
Abstract: Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.


Title: Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels
Abstract: This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.


Title: Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning
Abstract: Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/


Title: Towards Material Classification of Scenes Using Active Thermography
Abstract: By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.


Title: Vision-Based State Estimation and Trajectory Tracking Control of Car-Like Mobile Robots with Wheel Skidding and Slipping
Abstract: Most existing trajectory tracking controllers are based on non-skidding and non-slipping assumptions, also assume that full states are accessible, which is unrealistic for real-world applications due to tire-road interaction. This paper presents a novel vision-based approach to achieve high performance tracking control of a Car-Like Mobile Robot (CLMR) with wheel skidding and slippage. A visual estimation algorithm is proposed to provide reliable position, velocity, skidding and slipping information to close the control loop. The stability of the proposed system can be guaranteed by Lyapunov method since the position tracking error and the estimation error converge to zero simultaneously. Simulation is made to validate the effectiveness of the developed controller in the presence of skidding and slipping with online visual estimator.


Title: Recruitment Near Worksites Facilitates Robustness of Foraging E-Puck Swarms to Global Positioning Noise
Abstract: We compare the ability of two different robot controllers for collective foraging to cope with noise in robot global positioning data and show how recruitment, in the form of broadcast messages near worksites, can make swarms more robust. Swarms of five e-puck robots are used in a semi-virtual environment, facilitated by the VICON positioning system. This setup allows us to control the amount of noise in the robot positioning data and to generate pseudo-random environments, while retaining important physical aspects of the experiment. The effect of inherent noise in the robot infra-red sensors, used for obstacle avoidance, is noted and the importance of modelling such noise in agent-based simulations is highlighted.


Title: Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis
Abstract: Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.


Title: $\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms
Abstract: In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.


Title: Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms
Abstract: We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.


Title: A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems
Abstract: In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.


Title: Resilient Active Information Gathering with Mobile Robots
Abstract: Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.


Title: Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams
Abstract: We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.


Title: Development of Rimless Wheel with Controlled Wobbling Mass
Abstract: This paper presents a novel method for generating level-ground walking for a rimless wheel with a controlled wobbling mass. Our rimless wheel achieves level-ground walking by simply controlling the wobbling mass attached to the wheel. We mathematically demonstrate that the controlled wobbling mass generates propulsive effects for the rimless wheel. The walking speed of the rimless wheel can be changed by varying the amplitude of the wobbling mass: thus slow walking to high-speed walking can be realized for the wheel. Moreover, we have developed a robot based on a rimless wheel to show effectiveness of our proposed methods. We then analyze the walking properties with respect to the physical parameters and control parameters of our robot through numerical simulation.


Title: Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution
Abstract: We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.


Title: Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis
Abstract: This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.


Title: Fast Walking with Rhythmic Sway of Torso in a 2D Passive Ankle Walker
Abstract: There is a category of biped robots that are equipped with passive or un-actuated ankles, which we call Passive-Ankle Walkers (PAWs). Lack of actuation at ankles is a disadvantage in the fast walking of PAWs. We started this study with an intuitive hypothesis that rhythmic sway of torso may enable faster walking in PAWs. To test this hypothesis, firstly, we optimized the rhythmic sway of torso of a simulated PAW model for fast walking speed, and analyzed the robustness of the optimal trajectories. Then we implemented the optimal trajectories on a real robot. Both the simulation analysis and the experimental results indicated that optimized torso-swaying can greatly increase the walking speed by 40%. By analyzing the walking patterns of the simulated model and the real robot, we identified the reason for the faster walking with swaying-torso: The rhythmic sway of torso enables the robot to walk with a relatively large step-length while still keeninu a hizh sten-frenuencv.


Title: Torque Controlled Biped Model Through a Bio-Inspired Controller Using Adaptive Learning
Abstract: Biped robots have not achieved the efficient and harmonious locomotion of the human beings, capable of walking and running on unstructured terrains, with obstacles, holes and slopes. With this in mind, researchers started the development of biomimetic solutions to control the locomotion of biped models. This work presents a new solution of motion control of bipedal robots with adaptable stiffness, by exploring effects of joint stiffness in modulating walking behavior. Further, torque adjustment is achieved through a biomimetic controller that mimics and adjusts the natural dynamics of the robot to the environment. Specifically, the torque adjustment is made using AFOs (adaptive frequency oscillator) to generate the correct equilibrium positions that will be applied to the impedance control that computes the torque of each joint. Results show that the biped model is capable of walking in several types of terrain, including flat terrain, ramps, stairs and flat terrain with obstacles.


Title: High-Speed Stealth Walking of Underactuated Biped Utilizing Effects of Upper-Body Control and Semicircular Feet
Abstract: Stealth walking is a way of walking carefully and noiselessly, and is an approach to stable legged locomotion of underactuated robotic walkers on irregular terrains. This paper proposes a method for generating a high-speed stealth walking gait without including double-limb support phase, and discusses the effect of upper-body control and semicircular feet on the gait properties. First, we introduce a model of a 3-link planar underactuated biped with an upper body and semicircular feet, and derive the approximate target initial state of the upper body by using the linearized equation of motion. Second, we conduct numerical simulations of the nonlinear model to observe the typical stealth walking gaits, and analyze the changing tendency of the upper body motion with respect to the foot radius. Furthermore, we discuss the advantage of semicircular feet through parametric studies of the gait efficiencies.


Title: A Comparison of Assistive Methods for Suturing in MIRS
Abstract: In Minimally Invasive Robotic Surgery (MIRS) a robot is interposed between the surgeon and the surgical site to increase the precision, dexterity, and to reduce surgeon's effort and cognitive load with respect to the standard laparoscopic interventions. However, the modern robotic systems for MIRS are still based on the traditional telemanipulation paradigm, e.g. the robot behaviour is fully under surgeon's control, and no autonomy or assistance is implemented. In this work, supervised and shared controllers have been developed in a vision-free, human-in-the-Ioop, control framework to help surgeon during a surgical suturing procedure. Experiments conducted on the da Vinci Research Kit robot proves the effectiveness of the method indicating also the guidelines for improving results.


Title: External Force/Torque Estimation on a Dexterous Parallel Robotic Surgical Instrument Wrist
Abstract: This paper describes a novel sensorless force estimation algorithm for the rigid link parallel wrist mechanism of a robotic surgical instrument. The method utilizes novel reaction force observers (RFOB) in joint space, which are modified disturbance observers (DOB) combined with Neural Networks (NN) for inverse dynamics calculations, to estimate external forces acting on the motors. External force/torque estimation in Cartesian space is achieved by the use of the robot Jacobian. The proposed algorithm is applicable to any back-drivable rigid-link wrist mechanism without the need for force sensors. In this paper, the method is implemented on a novel 3 degree-of-freedom (DOF) parallel robotic surgical wrist mechanism that is designed for high dexterity (±90 degrees pitch-yaw rotations, thrust motion) and force/torque estimation. The wrist is actuated extracorporally with 3 rigid push-pull rods and 3 linear motors. With a rigid transmission and high back-drivability, external force/torque estimation can be achieved from the motor position readings utilizing the proposed method. Several experiments were performed on the manufactured prototype of the instrument and results validate the efficacy of the wrist and estimation method with RMS force/torque estimation error values of 0.0024 Nm in pitch axis, 0.0043 Nm in yaw axis and 0.1866 N in thrust axis.


Title: Hand-Impedance Measurement During Laparoscopic Training Coupled with Robotic Manipulators
Abstract: This paper presents measurements of human hand-impedance during a laparoscopic training program with physically interactive robotic manipulators. The knowledge of how the hand-impedance changes due to training might be useful to inform better training programs and to introduce co-manipulated robotic assistants for effective trainings. Ten novice subjects participated in a three weeks training program for a suturing activity in laparoscopy. The subjects have been instructed to set the needle, enter the skin, and tie knots by using laparoscopic tools within a Minimally Invasive Surgery training box. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle. Based on the interaction force and end-effector position information, impedances of the left and right hands were computed in four different directions. The computed results were compared with respect to the participants skill progression.


Title: Comparison of 3D Surgical Tool Segmentation Procedures with Robot Kinematics Prior
Abstract: 3D reconstruction and surgical tool segmentation are necessary for several advanced tasks in robot-assisted laparoscopic surgery. These tasks include vision-based force estimation, surgical guidance, and medical image registration where pre-operative data (CT or MRI scan image slices) are overlaid on patient anatomy in real-time during surgery [1] to name a few. In this work, two main strategies were considered: (1) initialize with surgical tool segmentation from 2D images, then proceed to local 3D reconstruction near the tool-tissue interaction region by projecting the segmented result into 3D space, and (2) initialize with 3D reconstruction of the entire surgical task space, followed by surgical tool segmentation from within the 3D reconstructed model. Both methods were implemented on the Raven II surgical robot system, and accuracy and time complexity for both methods were comparatively analyzed while considering various task parameters. Finally, based on the results of this work, guidelines for selecting reconstruction and segmentation strategies and procedure for particular situations are outlined in Section V.


Title: Preference-Based Assistance Prediction for Human-Robot Collaboration Tasks
Abstract: Human-Robot Collaboration (HRC) aims to develop robots that provide assistance to human workers while performing physical tasks. Such assistance comes in the form of supportive behaviors that are different from the actions part of the task, and that are meant to help a human worker more effectively accomplish the task. Learning how to provide useful behaviors that are tailored to a human peer represents a difficult challenge. This is due to the need of large amounts of training data in the form of real world observations that include information about such preferences. This data needs to encode not only the structure and progression of the task, but also the different workers' preferences with respect to when and what assistance the robot should provide. Our work separates the challenge of learning a model of the task (which requires a large amount of training data) from that of learning supportive behavior preferences for the interaction (which has obvious restrictions for the number of user-provided demonstrations to which we have access). We first learn a hidden Markov model (HMM) from a training set consisting of observed human workers performing the considered task in simulation. We then use this model to predict, while observing the human peer, what supportive behaviors a robot should offer throughout the task. Building upon the hidden state representation, our system is able to learn the supportive behaviors based on as few as five user-annotated demonstrations, learning a personalized supportive behavior model. We evaluate our system on a user study with 14 participants, and show results on par with human-level prediction for the task.


Title: Adaptive Modality Selection Algorithm in Robot-Assisted Cognitive Training
Abstract: Interaction of socially assistive robots with users is based on social cues coming from different interaction modalities, such as speech or gestures. However, using all modalities at all times may be inefficient as it can overload the user with redundant information and increase the task completion time. Additionally, users may favor certain modalities over the other as a result of their disability or personal preference. In this paper, we propose an Adaptive Modality Selection (AMS) algorithm that chooses modalities depending on the state of the user and the environment, as well as user preferences. The variables that describe the environment and the user state are defined as resources, and we posit that modalities are successful if certain resources possess specific values during their use. Besides the resources, the proposed algorithm takes into account user preferences which it learns while interacting with users. We tested our algorithm in simulations, and we implemented it on a robotic system that provides cognitive training, specifically Sequential memory exercises. Experimental results show that it is possible to use only a subset of available modalities without compromising the interaction. Moreover, we see a trend for users to perform better when interacting with a system with implemented AMS algorithm.


Title: Continuous Shared Control for Robotic Arm Reaching Driven by a Hybrid Gaze-Brain Machine Interface
Abstract: The brain-machine interface (BMI) has been reported to offer the potential for controlling the assistive robot for the motor impaired people, using the non-invasively obtained electroencephalogram (EEG) signals. However, the EEG based BMI may not be sufficient and stable to drive the robot moving freely in its 2D or 3D workspace. The robot autonomy may provide assistance for the BMI users with the shared control paradigm. Nevertheless, users suffers from several limitations of the current shared control paradigms applied on BMI, e.g., loss of sense of control, high mental workload due to unintuitive control with the human-robot interface and fixed level of assistance. To overcome these drawbacks, we propose a new control paradigm for the robotic arm reaching task where the robot autonomy is dynamically blended with the gaze-BMI control from a user. In this paradigm, the hybrid gaze-BMI constitutes an intuitive and effective input to continuously control the robotic arm end-effector moving freely in its 2D workspace, with an adjustable speed proportional to the motion intention strength. Furthermore, the adjustable level of assistance by our paradigm allows the system to balance the user's capabilities and feelings of control while compensating for the reaching task's difficulty. The proposed paradigm is verified in the task where a healthy subject utilizes the hybrid gaze-BMI to control the robotic arm end-effector reaching for a target object while avoiding the obstacle in the path. The experimental results demonstrate that the movements with our shared control paradigm are safer, more efficient and less difficult than those without shared control.


Title: The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity
Abstract: We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.


Title: Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace
Abstract: Recent advances in mixed-reality technologies have renewed interest in alternative modes of communication for human-robot interaction. However, most of the work in this direction has been confined to tasks such as teleoperation, simulation or explication of individual actions of a robot. In this paper, we will discuss how the capability to project intentions affect the task planning capabilities of a robot. Specifically, we will start with a discussion on how projection actions can be used to reveal information regarding the future intentions of the robot at the time of task execution. We will then pose a new planning paradigm - projection-aware planning - whereby a robot can trade off its plan cost with its ability to reveal its intentions using its projection actions. We will demonstrate each of these scenarios with the help of a joint human-robot activity using the HoloLens.


Title: KnowRobSIM — Game Engine-Enabled Knowledge Processing Towards Cognition-Enabled Robot Control
Abstract: AI knowledge representation and reasoning methods consider actions to be blackboxes that abstract away from how they are executed. This abstract view does not suffice for the decision making capabilities required by robotic agents that are to accomplish manipulation tasks. Such robots have to reason about how to pour without spilling, where to grasp a pot, how to open different containers, and so on. To enable such reasoning it is necessary to consider how objects are perceived, how motions can be executed and parameterized, and how motion parameterization affects the physical effects of actions. To this end, we propose to complement and extend symbolic reasoning methods with KnowRobSIM, an additional reasoning infrastructure based on modern game engine technology, including the subsymbolic world modeling through data structures, action simulation based on physics engine, and world scene rendering. We demonstrate how KnowRobSIM can perform powerful reasoning, prediction, and learning tasks that are required for informed decision making in object manipulation.


Title: Model-Free Grasp Planning for Configurable Vacuum Grippers
Abstract: A concept consisting of a new configurable vacuum gripper system and a corresponding method for determining optimal grasp configurations solely based on 3D vision is introduced. The robot system consists of a dynamically configurable vacuum gripper, a visual sensor, and a robot arm that are used in combination with a new grasp planner to robustly grasp unknown objects in arbitrary positions. For this purpose, formalized aspects of selecting contact surfaces for arbitrary suction cups are described; the concept involves visual detection of the objects, segmentation, iterative grasp planning, and action execution. The approach allows for a fast and efficient, yet precise execution of grasps. The core idea is a two-step 3D data acquisition approach and grasp point computation that takes advantage of the fact that the suction cups of the gripper can all be aligned axis-parallel. Therefore, an adequate sensor-based surface acquisition is done from a single viewpoint with respect to the gripper. Results of realworld experiments show that the proposed concept is suitable for a wide range of different and unknown objects in our setup.


Title: Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints
Abstract: Human hands can not only grasp objects of various shape and size and manipulate them in hands but also exert such a large gripping force that they can support the body in the situations such as dangling a bar and climbing a ladder. On the other hand, it is difficult for most robot hands to manage both. Therefore in this paper we developed the hand which can grasp various objects and exert large gripping force. To develop such hand, we focused on the thumb CM joint with wide range of motion and the MP joints of four fingers with the DOF of abduction and adduction. Based on the hand with large gripping force and flexibility using machined spring, we applied above mentioned joint mechanism to the hand. The thumb CM joint has wide range of motion because of the combination of three machined springs and MP joints of four fingers have variable rigidity mechanism instead of driving each joint independently in order to move joint in limited space and by limited actuators. Using the developed hand, we achieved the grasping of various objects, supporting a large load and several motions with an arm.


Title: The Co-Gripper: A Wireless Cooperative Gripper for Safe Human Robot Interaction
Abstract: In this paper, we introduce a set of guidelines for the design of grippers suitable for a safe human robot/interaction in cooperative tasks. Modularity, adaptability, robustness, intuitive control, limited weight are some of the key elements that could allow to effectively spread these devices in industrial and service applications. Following such guidelines, we present the prototype of the Co-Gripper: a robotic device for cooperative manipulation tasks with humans. The gripper is composed of two pairs of fingers, actuated with two motors, that can be controlled in a coordinated way or independently. Each finger has a modular underactuated structure, composed of three phalanges connected by passive joints. The gripper is wireless, so it can be easily connected both to the robotic arms and on passive structures. We designed a wearable wireless control interface composed of a ring and a bracelet allowing a simple and intuitive activation of the gripper without limiting human operator's manipulation capabilities. We performed a set of tests to quantify gripper performance and to exploit its potentialities in human-robot cooperation tasks.


Title: The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm
Abstract: This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.


Title: Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots
Abstract: Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.


Title: Online Adaptation of Robot Pushing Control to Object Properties
Abstract: Pushing is a common task in robotic scenarios. In real-world environments, robots need to manipulate various unknown objects without previous experience. We propose a data-driven approach for learning local inverse models of robot-object interaction for push manipulation. The robot makes observations of the object behaviour on the fly and adapts its movement direction. The proposed model is probabilistic, and we update it using maximum a posteriori (MAP) estimation. We test our method by pushing objects with a holonomic mobile robot base. Validation of results over a diverse object set demonstrates a high degree of robustness and a high success rate in pushing objects towards a fixed target and along a path compared to previous methods. Moreover, based on learned inverse models, the robot can learn object properties and distinguish between different object behaviours when they are pushed from different sides.


Title: Composable Learning with Sparse Kernel Representations
Abstract: We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.


Title: Compensating for Context by Learning Local Models of Perception Performance
Abstract: Perception system performance can vary dramatically with contextual factors such as environmental geometry, appearance, and other phenomena. In this work we present a theoretical framework for understanding the role of context in perception and discuss three approaches for predicting probabilistic performance from observations by efficiently learning local performance models. We compare these approaches with experiments on the monocular and stereo visual odometry systems for a ground robot, and show that they can effectively predict system failures in a wide variety of environments.


Title: Setting up a Reinforcement Learning Task with a Real-World Robot
Abstract: Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.


Title: CINet: A Learning Based Approach to Incremental Context Modeling in Robots
Abstract: There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we pose the task of when to increment as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks.


Title: Learning Generalizable Robot Skills from Demonstrations in Cluttered Environments
Abstract: Learning from Demonstration (LfD) is a popular approach to endowing robots with skills without having to program them by hand. Typically, LfD relies on human demonstrations in clutter-free environments. This prevents the demonstrations from being affected by irrelevant objects, whose influence can obfuscate the true intention of the human or the constraints of the desired skill. However, it is unrealistic to assume that the robot's environment can always be restructured to remove clutter when capturing human demonstrations. To contend with this problem, we develop an importance weighted batch and incremental skill learning approach, building on a recent inference-based technique for skill representation and reproduction. Our approach reduces unwanted environmental influences on the learned skill, while still capturing the salient human behavior. We provide both batch and incremental versions of our approach and validate our algorithms on a 7-DOF JACO2 manipulator with reaching and placing skills.


Title: Verification of a Robotic Ankle Exoskeleton Control Scheme for Gait Assistance in Individuals with Cerebral Palsy
Abstract: Walking ability is critically important for pediatric health, well-being, and independence. Children with cerebral palsy (CP), the most prevalent cause of pediatric physical disability, often present pathological gait patterns that negatively impact walking capacity. Reduced function of the muscles surrounding the ankle joint in those with CP also greatly increases the energy cost of transport leading to reduce mobility. Ankle-foot-orthoses show limited effectiveness for clinically relevant improvement in gait mechanics, while orthopedic surgery, muscle injections and physical therapy are unable to completely restore gait function. While wearable exoskeletons hold promise for gait rehabilitation, appropriately controlling the timing and magnitude of powered assistance across individuals and conditions remains a considerable challenge. This work seeks to address this challenge through the design and initial clinical verification of a simple ankle exoskeleton control scheme designed to reduce the metabolic cost of transport during walking in an individual with CP. Preliminary experimental results from instrumented gait analysis following 5 training visits demonstrated a 45% increase in positive ankle power and a 16% reduction in net metabolic rate during walking with the exoskeleton providing powered plantar-flexion assistance compared to walking without the exoskeleton. Future work will expand this investigation to a larger cohort of individuals with CP and across additional modes of locomotion.


Title: Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training
Abstract: Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.


Title: A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model
Abstract: Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.


Title: Airborne Docking for Multi-Rotor Aerial Manipulations
Abstract: We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.


Title: Aerial Radio-Based Telemetry for Tracking Wildlife
Abstract: This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.


Title: Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
Abstract: In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).


Title: Hallucinating Robots: Inferring Obstacle Distances from Partial Laser Measurements
Abstract: Many mobile robots rely on 2D laser scanners for localization, mapping, and navigation. However, those sensors are unable to correctly provide distance to obstacles such as glass panels and tables whose actual occupancy is invisible at the height the sensor is measuring. In this work, instead of estimating the distance to obstacles from richer sensor readings such as 3D lasers or RGBD sensors, we present a method to estimate the distance directly from raw 2D laser data. To learn a mapping from raw 2D laser distances to obstacle distances we frame the problem as a learning task and train a neural network formed as an autoencoder. A novel configuration of network hyperparameters is proposed for the task at hand and is quantitatively validated on a test set. Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the trained network can successfully infer obstacle distances from partial 2D laser readings.


Title: Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder
Abstract: Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.


Title: Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping
Abstract: We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.


Title: Uncertain Local Leader Selection in Distributed Formations
Abstract: Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.


Title: Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm
Abstract: Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.


Title: A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
Abstract: In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.


Title: Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
Abstract: The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.


Title: Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment
Abstract: This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.


Title: Distributed Sensing Subject to Temporal Logic Constraints
Abstract: This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.


Title: A New Robot Fly Design That is Easier to Fabricate and Capable of Flight and Ground Locomotion
Abstract: Efforts to engineer insect-sized (~100 mg) robots are motivated by their potential advantages relative to larger robots, such as greater deployment numbers at the same cost. Previous iterations have demonstrated controlled flight, but were limited in terms of locomotion capabilities outside of flight. They also consisted of many parts, making them difficult to fabricate. Here we present a re-design that lowers the center of mass, allowing the robot to additionally land without the need for long legs. Furthermore, we show that the new design allows for wing-driven ground locomotion. This is achieved by varying the speed of downstroke relative to the upstroke of the flapping wings, which also allows for steering. By landing and subsequently moving along the ground, the robot can negotiate extremely confined spaces and underneath obstacles, as well as navigate to precise locations for sensing operations. The new design also drastically reduces the number of parts, simplifying fabrication. We describe the new design in detail and present results demonstrating these capabilities, as well as feedback-stabilized flights.


Title: Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics
Abstract: The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.


Title: Depth Estimation of Optically Transparent Microrobots Using Convolutional and Recurrent Neural Networks
Abstract: Estimating the three-dimensional (3D) position of microrobots is necessary in order to develop closed-loop control techniques and to improve the user's 3D perception in the micro-scale. This paper describes a depth estimation method based on supervised learning for optically transparent microrobots of known geometry. The proposed methodology uses Convolutional Neural Networks (CNNs) combined with a Recurrent Network, in particular a Long Short-Term Memory (LSTM) cell for depth regression. The proposed depth regression model is independent of the 3D orientation of the microrobot and is robust to varying illumination levels while it uses learned data-specific features. The model is trained and validated using microscope images and ground truth data generated from 3D-printed microrobots imaged in an Optical Tweezers (OT) setup. The validation results demonstrate that the proposed trained model can reconstruct the depth of the microrobot independently of its 3D orientation with submicron accuracy for the test set.


Title: Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage
Abstract: To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.


Title: Force/Velocity Manipulability Analysis for 3D Continuum Robots
Abstract: The enhanced dexterity and manipulability offered by continuum manipulators makes them the robots of choice for complex procedures inside the human body. However, without tailored analytical tools to evaluate their manipulability, many capabilities of continuum robots such as safe and effective manipulation will remain largely inaccessible. This paper presents a quantifiable measure for analysing force/velocity manipulability of continuum robots. We expand classical measures of manipulability for rigid robots to introduce three types of manipulability indices to continuum robots, namely, velocity, compliance, and unified force-velocity manipulability. We provide a specific case study using the proposed method to analyse the force/velocity manipulability for a concentric-tube robot. We investigate the application of the manipulability measures to compare performance of continuum robots in terms of compliance and force-velocity manipulability. The proposed manipulability measures enable future research on design and optimal path planning for continuum robots.


Title: Analysis of Dynamic Response of an MRI-Guided Magnetically-Actuated Steerable Catheter System
Abstract: This paper presents a free-space open-loop dynamic response analysis for an MRI -guided magnetically-actuated steerable intra-vascular catheter system. The catheter tip is embedded with a set of current carrying micro-coils. The catheter is directly actuated via the magnetic torques generated on these coils by the magnetic field of the magnetic resonance imaging (MRI)scanner. The relationship between the input current commands and catheter tip deflection angle presents an inherent nonlinearity in the proposed catheter system. The system nonlinearity is analyzed by utilizing a pendulum model. The pendulum model is used to describe the system nonlinearity and to perform an approximate input-output linearization. Then, a black-box system identification approach is performed for frequency response analysis of the linearized dynamics. The optimal estimated model is reduced by observing the modes and considering the Nyquist frequency of the camera system that is used to track the catheter motion. The reduced model is experimentally validated with 3D open-loop Cartesian free-space trajectories. This study paves the way for effective and accurate free-space closed-loop control of the robotic catheter with real-time feedback from MRI guidance in subsequent research.


Title: Development and validation of MRI compatible pediatric surgical robot with modular tooling for bone biopsy
Abstract: In clinical practice, magnetic resonance imaging (MRI) is used to locate a lesion/tumor for bone biopsy in children. However, there is a lack of MR-compatible tools that can be used simultaneously during imaging and biopsy while maintaining surgical accuracy and safety. The Pediatric Surgery Robot (PSR) platform is a 5-DOF robot with a modular tool interface. For the case of bone biopsy, a Bone Biopsy Tooling (BBT) is attached. It is designed to fit within a Philips Achieva 3.0T MRI bore and carry a modified titanium bone biopsy needle. A surgical pre-planning and control interface has been developed for joint and Cartesian level control. The PSR-BBT has demonstrated 1.65 +/- 1.77 mm accuracy in Cartesian control in free space. The PSR-BBT can generate 12.46 +/- 0.32 N of axial force while drilling at a speed of 30 rpm, which is sufficient for cortical and cancellous bone phantoms. Under MRI testing (T1-FFE, T1-SE, T2-FFE and T2-TSE scans), the system demonstrated less than 33% signal-to-noise ratio variation while drilling and a 0.46% geometric distortion while powered on without significantly impacting MRI guidance in situ. These results show that the PSR-BBT can allow the user to simultaneously image and perform the biopsy and presents the PSR as a viable platform for MR-guided robotic surgery.


Title: Trigonometric Ratio-Based Remote Center of Motion Mechanism for Bone Drilling
Abstract: The remote center of motion (RCM) mechanism is a prominent candidate to aid bone drilling. The surgeon can simply place a drill with the RCM mechanism near the entry point to provide drill alignment with the target. Using this assistive mechanism for bone drilling improves drilling accuracy and reduces the complexity of bone drilling robotic systems. However, because most RCM mechanisms have been developed for laparoscopic surgery or needle insertion into soft tissue, they lack rigidity and are unsuitable for bone drilling. One of the most difficult and important surgical procedures in bone drilling is maintaining as well as guiding the orientation of the drill with respect to the target. This paper proposes an improved RCM mechanism in which a pair of linear actuators and a gearless arc-guide are employed to achieve high rigidity and resolution, which enable bone drilling. A vision-guided navigation system is also integrated into the proposed system to automatically guide the orientation. To verify that the proposed RCM mechanism has sufficient rigidity and targeting accuracy, a series of experiments was performed. The results obtained confirm that the proposed mechanism can maintain its tilting angle under up to 50 N, with a targeting error of approximately 0.28mm.


Title: Rolling-Joint Design Optimization for Tendon Driven Snake-Like Surgical Robots
Abstract: The use of snake-like robots for surgery is a popular choice for intra-luminal procedures. In practice, the requirements for strength, flexibility and accuracy are difficult to be satisfied simultaneously. This paper presents a computational approach for optimizing the design of a snake-like robot using serial rolling-joints and tendons as the base architecture. The method optimizes the design in terms of joint angle range and tendon placement to prevent the tendons and joints from colliding during bending motion. The resulting optimized joints were manufactured using 3D printing. The robot was characterized in terms of workspace, dexterity, precision and manipulation forces. The results show a repeatability as low as 0.9mm and manipulation forces of up to 5.6N.


Title: Enhancing the Command-Following Bandwidth for Transparent Bilateral Teleoperation
Abstract: Enhancing transparency of a teleoperation system by increasing the command-following bandwidth has not received lots of attention so far. This is considered a challenging task since in a teleoperation system the command-following bandwidth of the slave robot motion controller cannot be increased with a conventional motion controller as the desired trajectory is instantaneously commanded by the human user and thus, cannot be considered to be given in a pre-computed, smooth second order derivative form. We propose a method to increase the command-following bandwidth by extending the previously introduced Successive Stiffness Increment (SSI) approach to bilateral teleoperation. The approach allows realizing a very high motion controller gain, which cannot be realized with a conventional bilateral teleoperation controller as confirmed by experimental results.


Title: Development and Evaluation of an Intuitive Flexible Interface for Teleoperating Soft Growing Robots
Abstract: Mobility by growth is a new paradigm in robotic systems design and their applications in the real world. Soft, tip-extending, or “growing”, robots have potential applications including inspection and navigation in disaster scenarios. However, due to their growing capability, such robots create unique challenges for intuitive human control. In this paper, a new flexible interface is proposed to intuitively map human bending commands into movements of the growing robot while providing shape information of the robot in order to improve situational awareness. Several command mappings are proposed, and a subjective study was conducted to assess the intuitiveness of the developed interface and mappings compared with other commercially available interfaces. The interfaces were evaluated using four metrics in two virtual task scenarios. The proposed interface with shape mapping performed better than the other interfaces, especially when the vine robot rolls over unintentionally during complex tasks.


Title: Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction
Abstract: Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.


Title: Humanoid Teleoperation Using Task-Relevant Haptic Feedback
Abstract: Robotic teleoperation is a key technology for a wide variety of fields. Teleoperating a humanoid in particular is essential as it allows the user to act remotely on an interface designed especially for humans, e.g., in a space station, or operating tools and machinery in disaster scenarios. This paper presents a `task-relevant' haptic interface for humanoid teleoperation, which bridges the gap between the task at hand and the balance of the robot. The operator is given command over the humanoid's hands and is informed through haptic cues about the impact of her/his potential actions on the robot' stability. Moreover, a null-space autonomous controller acts in the operator's null-space to provide her/him with a wider workspace and help in the successful execution of the task. The architecture is designed to top an existing compliance controller for a torque-controlled humanoid robot. Experiments on the humanoid robot TORO are reported to demonstrate the feasibility and effectiveness of the approach.


Title: ROS Reality: A Virtual Reality Framework Using Consumer-Grade Hardware for ROS-Enabled Robots
Abstract: Virtual reality (VR)systems let users intuitively interact with 3D environments and have been used extensively for robotic teleoperation tasks. While more immersive than their 2D counterparts, early VR systems were expensive and required specialized hardware. Fortunately, there has been a recent proliferation of consumer-grade VR systems at affordable price points. These systems are inexpensive, relatively portable, and can be integrated into existing robotic frameworks. Our group has designed a VR teleoperation package for the Robot Operating System (ROS), ROS Reality, that can be easily integrated into such frameworks. ROS Reality is an open-source, over-the-Internet teleoperation interface between any ROS-enabled robot and any Unity-compatible VR headset. We completed a pilot study to test the efficacy of our system, with expert human users controlling a Baxter robot via ROS Reality to complete 24 dexterous manipulation tasks, compared to the same users controlling the robot via direct kinesthetic handling. This study provides insight into the feasibility of robotic teleoperation tasks in VR with current consumer-grade resources and exposes issues that need to be addressed in these VR systems. In addition, this paper presents a description of ROS Reality, its components, and architecture. We hope this system will be adopted by other research groups to allow for easy integration of VR teleoperated robots into future experiments.


Title: User Evaluation of a Haptic-Enabled Shared-Control Approach for Robotic Telemanipulation
Abstract: Robotic telemanipulators are already widely used in nuclear decommissioning sites for handling radioactive waste. However, currently employed systems are still extremely primitive, making the handling of these materials prohibitively slow and ineffective. As the estimated cost for the decommissioning and clean-up of nuclear sites keeps rising, it is clear that one would need faster and more effective approaches. Towards this goal, in this paper we present the user evaluation of a recently proposed haptic-enabled shared-control architecture for telemanipulation. An autonomous algorithm regulates a subset of the slave manipulator degrees of freedom (DoF) in order to help the human operator in grasping an object of interest. The human operator can then steer the manipulator along the remaining null-space directions with respect to the main task by acting on a grounded haptic interface. The haptic cues provided to the operator are designed in order to inform about the feasibility of the user's commands with respect to possible constraints of the robotic system. In this paper we compared this shared-control architecture against a classical 6-DOF teleoperation approach in a real scenario by running experiments with 10 subjects. The results clearly show that the proposed shared-control approach is a viable and effective solution for improving currently-available teleoperation systems in remote telemanipulation tasks.


Title: Towards an Automatic Spasticity Assessment by Means of Collaborative Robots
Abstract: Summary form only given. Robotics can play a significant role in the rehabilitation of patients with spasticity by improving their early diagnosis and reducing the costs associated with care. Spasticity is a muscle control disorder characterized by an increase in muscle tone with exaggerated stretch reflexes, as one component of the upper motor neuron syndrome. Furthermore, spasticity is present in other pathologies, such as cerebral palsy, spina bifida, brain stroke among others. This video shows the ongoing research on developing a platform for the modelling and the assessment of spasticity using collaborative robots as clinical tool. Our aim is to develop methods for non-invasive biomechanical modelling of upper limbs joints using 7-DOF Rosen Kinematics [1], mixed with a non-linear state of Hills force-velocity relation [2], improved by introducing new parameters such as rigidity, viscoelasticity, extensibility and thixotropy. After a learning phase performed by the therapist, the robot replicates the trajectories required to perform the assessment. The video also describes the detailed analysis of passive movement response (force/torque and position/velocity)of the limb. These parameters will be used to determine the degree of spasticity of patients in a fast and objective manner, while simultaneously developing new clinical scales, such as a modified version of Ashworth [3].


Title: Research on Carved Turns of a Skiing Humanoid Robot on a Real-World Slope
Abstract: Humans play sports to improve their athletic ability. The robot, especially humanoid robot, is also able to improve its athletic performances, such as reaction speed and balancing, through robot sports. Therefore, robots have been developed through performing various robot sports events such as robot soccer, robot marathon, robot fight and so on. In this reason, The Ski Robot Challenge was held in South Korea in commemoration of the PyeongChang 2018 Winter Olympic Games. The event was an Alpine slalom skiing competition in the almost same rules to human's but on a relatively short course (80m). To participate in this ski tournament, the skiing robot DIANA has been developed. In this video, the skiing robot technologies were introduced. At first, she must be able to recognize the flags. The deep learning method was used to recognize them. Secondly, she had a motion pattern to perform the carving turn, the most difficult and fastest skiing technique. In order to improve the stability, she compensated her motion to follow reference COP, based on the measured F/T sensor data. In addition, IMU sensor was used to remove instantaneous disturbance. Using these methods, the humanoid robot, DIANA, that can perform the carved turn on a realworld slope was successfully developed.


Title: Waiter Robot Application: Balance Control for Transporting Objects
Abstract: Dynamic balance control for humanoid robots encounters difficulties such as stability, speed, and smoothness. In most of the previous studies, joints act as controller of the Center of Mass (CoM)supported using a simplified mathematical model. Then, the stability of the motion is guaranteed using the Zero Moment Point (ZMP)stability criterion. In this video, a humanoid robot [1] will carry a tray secured to the wrist and the objects to be transported will be placed on the tray. This condition implies that the object is not grasped and therefore, the robot arm will be the only point of support of the object through the tray. Thus, the manipulation control system must be able to detect the stability of the object and act according to the different perturbations applied to it. A 3D balance control system for non-grasping tasks is presented and it is based on the ZMP criterion and 3D inverted pendulum equations. The perception system required is based on the use of Force-Torque sensors [2], computer vision [3], and their integration. The effectiveness of the proposed approach is being investigated with the humanoid robot TEO.


Title: Visual-Inertial Teach and Repeat Powered by Google Tango
Abstract: Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.


Title: Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
Abstract: This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.


Title: Hear the Egg - Demonstrating Robotic Interactive Auditory Perception
Abstract: We present an illustrative example of an interactive auditory perception approach performed by a humanoid robot called NICO, the Neuro Inspired COmpanion [1]. The video demonstrates a material classification task in the style of a classic TV game show. NICO and another candidate are supposed to determine the content of small plastic capsules that are visually indistinguishable. Shaking the capsules produces audio signals that range from rattling stones, over tinkling coins to swooshing sand. NICO can perceive and analyze these sounds to determine the material of the capsules content.


Title: Computing Cross-Sections of the Workspace of Suspended Cable-Driven Parallel Robot with Sagging Cables Having Tension Limitations
Abstract: Although workspace is essential for the design and control of cable-driven parallel robots (CDPR) very few works have been devoted to this topic when sagging cables are considered, most probably because of the complexity of the cable model. In this paper we consider suspended CDPR with sagging cables that can support only a limited tension. We propose an algorithm to compute the border of horizontal cross-sections of the workspace for a given altitude and orientation of the platform. We show that singularities of the kinematics equations have to be taken into account for a proper determination of the border and that the workspace can be separated in several components according to the branch of the inverse kinematics on which the robot is evolving. We also compare the workspace obtained for ideal and sagging cables.


Title: A Singularity-Robust LQR Controller for Parallel Robots
Abstract: Parallel robots exhibit the so-called forward singularities, which complicate substantially the planning and control of their motions. Often, such complications are circumvented by restricting the motions to singularity-free regions of the workspace. However, this comes at the expense of reducing the motion range of the robot substantially. It is for this reason that, recently, efforts are underway to control singularity-crossing trajectories. This paper proposes a reliable controller to stabilize such kind of trajectories. The controller is based on the classical theory of linear quadratic regulators, which we adapt appropriately to the case of parallel robots. As opposed to traditional computed-torque methods, the obtained controller does not rely on expensive inverse dynamics computations. Instead, it uses an optimal control law that is easy to evaluate, and does not generate instabilities at forward singularities. The performance of the controller is exemplified on a five-bar parallel robot accomplishing two tasks that require the traversal of singularities.


Title: An Active Stabilizer for Cable-Driven Parallel Robot Vibration Damping
Abstract: Cable-Driven Parallel Robots (CDPRs) can execute fast motions across a large workspace. However, these performances are reached at the cost of a relatively low stiffness which often yields parasitic vibrations at the CDPR mobile platform. In this paper, vibration damping of CDPRs is addressed by means of an original active stabilizer consisting of actuated rotating arms installed on-board the CDPR mobile platform. A control strategy for the whole system, which consists of the CDPR and the stabilizer, and with one purpose for each-position control for the platform and vibration damping for the stabilizer-is designed. The system being controlled at two different time scales, the singular perturbation theory can be used to prove the stability of the corresponding closed-loop system. The efficiency of the proposed device and control strategy is tested in simulations in the case of a planar 3-DOF CDPR equipped with a three-arm stabilizer.


Title: Design and Fabrication of a Bipedal Robot Using Serial-Parallel Hybrid Leg Mechanism
Abstract: In this paper, we present the design and performance evaluation of a bipedal robot that utilizes the Hybrid Leg mechanism. It is a leg mechanism that achieves 6 DOF with a combined structure of serial and parallel mechanism. It is designed to have a light structural inertia and large workspace for agile bipedal locomotion. A new version of Hybrid Leg is fabricated with carbon fiber tubes and bearings to improve its structural rigidity and accuracy while supporting its weight. A pair of Hybrid Legs is assembled together for bipedal locomotion. In the assembly, we adopt a pelvis structure with an yaw angle offset to enlarge the feet workspace, inspired by the toe-out angle of the human feet. The workspace and range of velocity are presented in simulation and verified with hardware experiments. We also demonstrate a simple forward walking motion with the developed robot.


Title: Configuration Space Metrics
Abstract: When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics - metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.


Title: Fused Angles and the Deficiencies of Euler Angles
Abstract: Just like the well-established Euler angles representation, fused angles are a convenient parameterisation for rotations in three-dimensional Euclidean space. They were developed in the context of balancing bodies, most specifically walking bipedal robots, but have since found wider application due to their useful properties. A comparative analysis between fused angles and Euler angles is presented in this paper, delineating the specific differences between the two representations that make fused angles more suitable for representing orientations in balance-related scenarios. Aspects of comparison include the locations of the singularities, the associated parameter sensitivities, the level of mutual independence of the parameters, and the axisymmetry of the parameters.


Title: Geometric Optimization of a Large Scale CDPR Operating on a Building Facade
Abstract: This paper deals with the optimization of the geometry of a Cable-Driven Parallel Robot (CDPR) dedicated to large-scale construction applications. Since the maximum cable tension is a critical parameter in the design of the CDPR components, the geometry of the CDPR is optimized by minimizing the lowest maximum cable tension that ensures the validity of wrench-feasibility constraints. The geometric design procedure used in this paper consists of two phases, the CDPR cable connections is selected in the first phase followed by a second phase where the geometric parameters are optimized. The result of this procedure is an original fully-constrained CDPR geometry.


Title: Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum Robot in SE(3)
Abstract: Recent physics-based models of concentric tube continuum robots are able to describe pose of the tip, given the preformed translation and rotation in joint space of the robot. However, such model-based approaches are associated with high computational load and highly non-linear modeling effort. A data-driven approach for computationally fast estimation of the kinematics without requiring the knowledge and the uncertainties in the physics-based model would be an asset. This paper introduces an approach to solve the forward kinematics as well as the inverse kinematics of concentric tube continuum robots with 6-DOF in three dimensional space SE(3). Two artificial neural networks with ReLU (rectified linear unit) activation functions are designed in order to approximate the respective kinematics. Measured data from a robot prototype are used in order to train, validate, and test the proposed approach. We introduce a representation of the rotatory joints by trigonometric functions that improves the accuracy of the approximation. The results with experimental measurements show higher accuracy for the forward kinematics compared to the state of the art mechanics modeling. The tip error is less then 2.3 mm w.r.t. position (1 % of total robot length) and 1.1° w.r.t. orientation. The single artificial neural network for the inverse kinematics approximation achieves a translation and rotation actuator error of 4.0 mm and 8.3 0, respectively.


Title: Learning Forward and Inverse Kinematics Maps Efficiently
Abstract: When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.


Title: A Fail-Safe Semi-Centralized Impedance Controller: Validation on a Parallel Kinematics Ankle
Abstract: This paper proposes the implementation of an impedance controller on the ankle level of COMAN+, a robot with parallel kinematics ankles actuated by a dual four-bar mechanism. The main contribution of the work is a realization of said control scheme that grants a less abrupt and safer robot response in case of system failures, that would cause the local joint torque controllers to lose their torque reference inputs. In particular, we propose a semi-centralized impedance control implementation which eliminates the instability of the pure joint torque control schemes used in the classical fully centralized methods when torque reference interruptions occur. Finally, we present experimental results, proving the effectiveness of our method and demonstrating how it ensures a safer behaviour compared to a fully centralized impedance control implementation when the communication to the ankle joints is interrupted. This paper is a follow-up work of [1], which presented and analyzed the parallel kinematics ankles.


Title: Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers
Abstract: Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.


Title: Constrained Control of Robotic Manipulators Using the Explicit Reference Governor
Abstract: Robotic manipulators that are intended to interact with humans in their operating region are systems that need formal safety guarantees. Current solutions cannot handle both input and state constraints, have difficulties handling nonconvex constraints, or are computationally too expensive. To tackle these drawbacks, we analyzed a constrained control strategy, the Explicit Reference Governor (ERG), which can address both input and state constraints, and does not require any online optimization, thus making it computationally inexpensive. This paper presents the theory of the ERG for a general robotic manipulator and shows simulations for a specific 2DOF planar robotic manipulator. The proposed control scheme is able to steer the robot arm to the desired end-effector position, or an admissible approximation, in the presence of limited joint ranges, actuator saturations, and static obstacles. As a result, the ERG is a promising tool for the control of robotic manipulators subject to constraints.


Title: Iterative Learning Vector Field for FES-Supported Cyclic Upper Limb Movements in Combination with Robotic Weight Compensation
Abstract: Robotics and Functional Electrical Stimulation (FES) are well-established technologies for the rehabilitation of stroke and spinal cord injured (SCI) patients. We propose a hybrid solution that combines feedback-controlled FES of biceps and triceps as well as posterior and anterior deltoid with a cable-driven robotic system to support repetitive arm movements, like “breaststroke swimming” exercises. The robotic system partially compensates the arm weight by controlling the cable tension forces, and the FES promotes motion in the transversal plane. To adjust the FES support to the needs of the individual patients we use an iterative learning vector field (ILVF) which encodes the stimulation intensities that are applied to guide the patient along a pre-specified reference trajectory in the joint angle space. In contrast to previous iterative learning control approaches, the ILVF allows the patient to perform the motion at self-selected cadence. The proposed learning algorithm explicitly takes the dynamics of the artificially activated muscles into account and assures smooth stimulation intensity profiles. The control algorithm is tested in simulations using a complex neuro-musculoskeletal model. For “breaststroke” motions, the initial RMS error of purely volitional movements is reduced from 38° to 10° within 21 cycles by the adaptive FES support. After 50 iterations of the ILVF, the algorithm converges to a steady state RMS error of 4°. Changes in the patient's muscle activity and cadence were well tolerated by the control system and did not cause a noticable increase in the steady state RMS error.


Title: Online Self-Supervised Long-Range Scene Segmentation for MAVs
Abstract: Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.


Title: History-Aware Autonomous Exploration in Confined Environments Using MAVs
Abstract: Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.


Title: Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
Abstract: Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.


Title: Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight
Abstract: We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.


Title: Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL
Abstract: Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.


Title: Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds
Abstract: The presented work deals with classification of garment categories including pants, shorts, shirts, T-shirts and towels. The knowledge of the garment category is crucial for its robotic manipulation. Our work focuses particularly on garments being held in a hanging state by a robotic arm. The input of our method is a set of depth maps taken from different viewpoints around the garment. The depths are fused into a single 3D point cloud. The cloud is fed into a convolutional neural network that transforms it into a single global feature vector. The network utilizes a generalized convolution operation defined over the local neighborhood of a point. It can deal with permutations of the input points. It was trained on a large dataset of common 3D objects. The extracted feature vector is classified with SVM trained on smaller datasets of garments. The proposed method was evaluated on publicly available data and compared to the original methods, achieving competitive performance and better generalization capability.


Title: Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*
Abstract: This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.


Title: An Adaptive Robot for Building In-Plane Programmable Structures
Abstract: A new approach for cellular robots is presented. The single elements of the robot are triangular cells, which can change their shape by means of linear actuators at each edge. The novelty concerns the connection of autonomous cells at their edges rather than at the vertices. In this way, unstructured triangular meshes can be formed. The robot can self-reconfigure and thus can reproduce almost arbitrary planar shapes. In a similar way, the system has been realized with tetrahedrons in a simplified way within a previous work. The self-reconfigurable system shall serve as a basis for programmable matter. The present paper includes the mechatronic design, its components and the kinematic model of the cellular robot. In order to reduce positioning errors, a model is developed, which considers compliance and clearance in the links and joints. Based on a simplified mechanical model using elastic trusses, the positioning errors can be predicted. The parameters of these models are identified from simple motion sequences. Furthermore, the nonlinearity of actuators is identified and corrected. In this way, the desired triangular shapes can be prescribed without measuring the position of the cells.


Title: Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure
Abstract: In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.


Title: Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning
Abstract: In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.


Title: Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms
Abstract: Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.


Title: Magnetic Navigation of a Rotating Colloidal Swarm Using Ultrasound Images
Abstract: Microrobots are considered as promising tools for biomedical applications. However, the imaging of them becomes challenges in order to be further applied on in vivo environments. Here we report the magnetic navigation of a paramagnetic nanoparticle-based swarm using ultrasound images. The swarm can be generated using simple rotating magnetic fields, resulting in a region containing particles with a high area density. Ultrasound images of the swarm shows a periodic changing of imaging contrast. The reason for such dynamic contrast has been analyzed and experimental results are presented. Moreover, this swarm exhibits enhanced ultrasound imaging in comparison to that formed by individual nanoparticles with a low area density, and the relationship between imaging contrast and area density is testified. Furthermore, the microrobotic swarm can be navigated near a solid surface at different velocities, and the imaging contrast show negligible changes. This method allows us to localize and navigate a microrobotic swarm with enhanced ultrasound imaging indicating a promising approach for imaging of microrobots.


Title: Robotic Hand-Free-Stick for Walking Balance Assistance
Abstract: This paper proposes a wearable robotic stick for walking assistance, called “Hand-Free-Stick” (HFS), for people with non-serious dysfunction in their gait. The basic idea of the proposed HFS is to enlarge ZMP (Zero moment point) area of a user under hands free conditions and to augment his/her body balance ability in walking. A boots type prototype of the HFS is developed with a lightweight robotic stick using a servomotor, in which the slider-link mechanism works to regulate the stick angle and length at the same time. The stick motion is controlled by a single-board computer based on the distribution of foot/feet pressures measured by the sensor system using eight load cells attached at the sole of boots. A set of walking tests with/without the prototype of HFS is carried out for four healthy subjects and demonstrates the effectiveness of the proposed HFS to expand the ZMP area leading to walking balance assistance.


Title: Soft Fabric Actuator for Robotic Applications
Abstract: This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.


Title: Hands-Free Assistive Manipulator Using Augmented Reality and Tongue Drive System
Abstract: A human-in-the-loop system is proposed to enable hands-free collaborative manipulation for people with physical disabilities. Studies show that the cognitive burden of interfacing with a robotic assistant decreases with increased robot autonomy. Incorporating modern advances in perception with augmented reality, this paper describes a framework for obtaining high-level intents from the user to specify manipulation tasks for execution. Augmented reality glasses provide an egocentric perspective to the robot. The glasses also provide visual feedback to users on a virtual menu showing a summary of robot affordances. The system processes the vision input to interpret the users environment. A Tongue Drive System serves as the input modality for triggering task execution by the robotic arm. Several manipulation experiments are performed with comparison to Cartesian control. The outcomes are also compared to reported state-of-the-art approaches. The results demonstrate competitive performance with minimal user input requirements.


Title: Supervised Autonomous Locomotion and Manipulation for Disaster Response with a Centaur-Like Robot
Abstract: Mobile manipulation tasks are one of the key challenges in the field of search and rescue (SAR) robotics requiring robots with flexible locomotion and manipulation abilities. Since the tasks are mostly unknown in advance, the robot has to adapt to a wide variety of terrains and workspaces during a mission. The centaur-like robot Centauro has a hybrid legged-wheeled base and an anthropomorphic upper body to carry out complex tasks in environments too dangerous for humans. Due to its high number of degrees of freedom, controlling the robot with direct teleoperation approaches is challenging and exhausting. Supervised autonomy approaches are promising to increase quality and speed of control while keeping the flexibility to solve unknown tasks. We developed a set of operator assistance functionalities with different levels of autonomy to control the robot for challenging locomotion and manipulation tasks. The integrated system was evaluated in disaster response scenarios and showed promising performance.


Title: Design of a Lightweight, Ergonomic Manipulator for Enabling Expressive Gesturing in Telepresence Robots
Abstract: Recent research on telepresence robots demonstrates that while they enable new heights of remote communication, there still exists challenges for both local and remote users in creating a connectedness one only encounters in face-to-face interactions. A large part of communication is beyond hearing and vision. Tangible interactions, expressive gestures, and physical referencing represent three of the primary social behaviors missing in the current telepresence experience. There is an inherent, subconscious quality to these physical actions that has been shown to allow more expressive and engaging communication. In this project we present the design, fabrication, and initial performance validation of a lightweight, ergonomic manipulator with a heavy, anthropomorphic end effector that enables gesturing capabilities for telepresence interactions.


Title: Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)
Abstract: Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.


Title: Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance
Abstract: In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.


Title: Inferring Semantic State Transitions During Telerobotic Manipulation
Abstract: Human teleoperation of robots and autonomous operations go hand in hand in today's service robots. While robot teleoperation is typically performed on low to medium levels of abstraction, automated planning has to take place on a higher abstraction level, i.e. by means of semantic reasoning. Accordingly, an abstract state of the world has to be maintained in order to enable an operator to switch seamlessly between both operational modes. We propose a novel approach that combines simulation based geometric tracking and semantic state inference by means of so called State Inference Entities to overcome this issue. We also demonstrate how Evolutionary Strategies can be employed to refine simulation parameters. All experiments are demonstrated in real-world experiments conducted with the humanoid robot Rollin' Justin.


Title: An Ungrounded Master Device for Tele-Microassembly
Abstract: Micro-assembly is a challenging issue for automation due to particularities of micro-world physics and limitations on sensors. Consequently, most applications are human-operated often with basic joystick-like interfaces. Beside being nonintuitive, these solutions do not provide their users with a meaningful insight into the microworld. This paper proposes a novel intuitive remote handling interface, using a classical hand-held assembly tool as a paradigm. The master device is a portable instrumented tweezers with one active degree of freedom. Its spatial motion, tracked by optical means, controls the slave kinematics while its pinch commands the slave robot's microgripper and provides haptic feedback. Different coupling strategies using position or speed variables are demonstrated.


Title: “Hammer: Robot Programming Interface for Common People”
Abstract: This video shows the main features of Hammer, a tablet-based end-user interface for industrial robot programming, in a real environment: a robotic cell created for the Hephestos European project. Hammer is an Android application that makes easier to program tasks for industrial robots like polishing, milling or grinding. It is based on the Scratch programming language, but specifically design and created for Android OS. It is a visual programming concept that allows non-skilled operators to create programs. The application allows to monitor the tasks while it is being executed by overlapping real time information through augmented reality. The application includes a teach pendant screen that can be customized according to the operator needs at every moment. The application is designed for online programming and reprogramming; easy use of learn-by-demonstration methods; easy connection with the robot control and sensors systems; and safety-system integration. It aims to be intuitive, easy to use, and simple. The application has four main parts: customized teach pendant, robot programming IDE and simulator, manual-guidance interface and augmented-reality-based-monitoring system.


Title: The Art of Manipulation: Learning to Manipulate Blindly
Abstract: Performing skillfull manipulation is a very challenging task for robots. So far, even experts could barely program them to e.g. perform the well known peg-in-hole problem in the real world. Autonomously acquiring such skills, let alone generalizing them to new tasks, is still a major challenge. Typically, manipulation learning is approached with the help of large computation power, very long learning times, or possibly both. However, the performance achieved up to now is still far from human performance. We show the results of our new paradigm to robot manipulation. It bridges and unifies basic motor control, simple and complex manipulation strategies and high-level manipulation planning. The robots show autonomous skill learning, intra-class and inter-class generalization of insertion skills at human-level performance.


Title: Toward the Next Generation of Robotic Waiters
Abstract: The gap between human waiters and state-of-the-art robot systems that try to serve something to drink is often embarrassing, with the former able to manipulate glasses and trays or glasses on trays with incredible dexterity and the latter that move at incredible slowness. In this video, we want to show that robots can do it better by moving a bottle or a tankard full of beer that are simply placed on a flat steel plate connected the flange of a robot manipulator. The robot tracks the trajectory defined by a human operator that moves its hand in the 3D space, with a motion capture system that acquires in real time the position. A feed-forward controller, placed between the user and the robot and based on the combination of a smoother and proper orientation compensation, counteracts the lateral accelerations and suppress sloshing phenomena of the liquids. Eventually a camera mounted on the robot arm provides a visual feedback to the operator with monitoring purposes. The challenge for the operator was to drop the carried object. will the feed-forward control be robust enough to avoid this event, even at high speed? Watch the video and find out!


Title: Human-Robot-Cooperation Real Time Robot Path Planning for Dynamic HRC-Applications
Abstract: Human-Robot shared workspace is a dynamic and unstructured environment. In such environment, pre-programmed robot paths might cause collisions or production disruptions. In order to solve this problem, motion planning framework has been proposed that adapts the robot's movement (path and speed)according to the human movement or any other dynamic obstacles in real time. Firstly, it defines the safety distance between robot and human or other obstacles. During run-time the 3D-Smart-Sensors capture the current position of human and other dynamic/static obstacles in human-robot shared workspace. The proposed framework plans and optimizes collision free robot trajectories with consideration for safety distance, path length and executing time. Once a new optimal trajectory is found, the framework controls the robot to adjust its movement paths. Moreover, the proposed framework can adjust the robot velocity based on the 3D-Zone Model of human-robot shared workspace. Therefore, the robot can reach its goal quickly and safely in a dynamic and unstructured environment.


Title: High Power Hand with Retention Mechanism
Abstract: When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.


Title: Excuse Me, May I Say Something? A Robot Facilitating Q&A for Lectures
Abstract: Hiroshi Ishiguro gave a lecture to a group of young students. We employed CommU, the desktop social robot, to manage the questions and answers for the talk. We encouraged the students to ask questions anytime. Half of the classroom was told to ask questions by raising their hand while the other half was shown an online messaging system developed for CommU, which allows the audience to post questions, which the robot would directly say. We had a gatekeeper to monitor for invalid sentences. In the middle of the presentation we asked the students to shift roles. The robot used a neural network based estimator of interruptibility to find the best time to speak. We did not expect too many questions, but the audience really embraced using the robot. They posted 44 questions to the presenter through CommU. On the other hand they asked 8 direct questions by raising their hands and standing up. Students thought that they gained more information from the lecturer using the robot than using the conventional method. In this instance we didnt stop the students from asking too many questions, but in a real-world application the gatekeeper will have to play an important role.


Title: Towards Autonomous Auto Calibration of Unregistered RGB-D Setups: The Benefit of Plane Priors
Abstract: In the last few years novel color and depth (RGB-D) sensors have greatly pushed robot perception. To enable a precise pixel-wise fusion of color and depth information good calibration is needed. The calibration determines the intrinsic parameters, the extrinsic parameters, and corrects for depth errors. While classic calibration approaches involve a dedicated calibration target and a trained expert, the autonomous calibration of such camera systems for robots operating in unknown environments is still an open problem. It demands for robust methods that do not need an expert to set up or tune the algorithm. Hence, we present a robust calibration algorithm that utilizes structure from motion (SfM) reconstructions as a calibration target and incorporates plane priors in the optimization to improve the convergence behavior and improve the calibration robustness. We evaluate our method against the state of the art performing over 300 experiments on ten different datasets, and show a significant improvement of the calibration accuracy.


Title: SCALAR - Simultaneous Calibration of 2D Laser and Robot's Kinematic Parameters Using Three Planar Constraints
Abstract: Industrial robots are increasingly used in various applications where the robot accuracy becomes very important, hence calibrations of the robot's kinematic parameters and the measurement system's extrinsic parameters are required. However, the existing calibration approaches are either too cumbersome or require another expensive external measurement system such as laser tracker or measurement spinarm. In this paper, we propose SCALAR, a calibration method to simultaneously improve the kinematic parameters of a 6-DoF robot and the extrinsic parameters of a 2D Laser Range Finder (LRF) that is attached to the robot. Three flat planes are placed around the robot, and for each plane the robot moves to several poses such that the LRF's ray intersect the respective plane. Geometric planar constraints are then used to optimize the calibration parameters using Levenberg-Marquardt nonlinear optimization algorithm. We demonstrate through simulations that SCALAR can reduce the average position and orientation errors of the robot system from 14.6 mm and 4.05° to 0.09 mm and 0.02°.


Title: Automated Tool Coordinate Calibration System of an Industrial Robot
Abstract: Due to the widespread use of industrial robots in market, its application has extended to welding, painting, and freight handling. And tool coordinate calibration is regularly modified after tool replacement due to collision accident or routine maintenance. After tool replacement, operators often rebuild tool coordinates. This is the traditional mode of operation in the current industrial practices. However, smart factory will make artificial intelligence method replace manual method. This paper presents a system independent method for automatic calibration of the tool coordinate system which is faster, simpler, cheaper and more effective than the manual method. The proposed method required images to be captured using two “eye to hand” cameras and one “eye in hand” camera. Tool position data is then acquired through CamShift and MeanShift algorithm for image trajectory tracking along with coordinate system conversion, several methods like PCA, LDA can deal with the vision data. Optimal Deep Neural Network (DNN) method error compensation of a robot allows the tool to automatically run with the calibration system functions. We have developed a 6 degrees of freedom(DoF) industrial robot for this experiment. Nine different kinds of DNN models are built and finally with suitable tool coordinate error compensation for the current robot, tool calibration can be achieved adaptively and efficiently.


Title: Robust Optimization-Based Calculation of Invariant Trajectory Representations for Point and Rigid-body Motion
Abstract: Invariant representations of demonstrated motion trajectories provide context-independent motion models that can be used in motion recognition and generalization applications such as robot programming by demonstration. In practice, the use of invariant representations is still limited because their numerical calculation from a demonstrated trajectory is complicated by sensitivity to measurement noise and singularities, yielding inaccurate invariant functions that do not correspond well with the original trajectory. This paper improves the calculation of invariant representations for point and rigid-body motions by reformulating their calculation as an optimization problem that minimizes the error between the trajectory reconstructed from the invariant representation and the measured trajectory. Robustness against noise and singularities is ensured through the addition of regularization terms on the invariants. Simulations and real motion experiments show that the accuracy of the calculated invariant representations greatly improves with respect to standard smoothing methods. These results encourage future developments of motion recognition and generalization applications based on invariant trajectory representations.


Title: Reducing the Computational Complexity of Mass-Matrix Calculation for High DOF Robots
Abstract: Increasingly, robots have more degrees of freedom (DOF), imposing a need for calculating more complex dynamics. As a result, better efficiency in carrying out dynamics computations is becoming more important. In this study, an efficient method for computing the joint space inertia matrix (JSIM) for high DOF serially linked robots is addressed. We call this method the Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ). GDAHJ is non-symbolic, preserve simple formulation, and it is convenient for numerical implementation. This is achieved by simplifying the way to recursively derive the mass-matrix exploiting the unique property of each column of the JSIM and minimizing the number of operations with O(n2) complexity. Results compare favorably with existing methods, achieving better performance over state-of-the-art by Featherstone when applied for robots with more than 13 DOF.


Title: Actuator and Friction Dynamics Formulation in Control of PKMs: From Design to Real-Time Experiments
Abstract: This paper deals with a new dynamic formulation of parallel manipulators incorporating the actuator and friction dynamics to be utilized in control. A model-based controller, PD with computed feedforward, is implemented for a parallel robot taking into consideration the formulated dynamics. The motivation behind this contribution is to enhance the control performance by compensating the unfavourable nonlinearities abundant extensively in PKMs. Those nonlinearities may increase considerably when operating at high-speed motions. The proposed feedforward part relies on the reference trajectories instead of the measured ones improving the control performance and the computational efforts. To validate our contribution, real-time experiments are conducted on a four degree-of-freedom parallel robot named VELOCE in different operating conditions.


Title: Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair
Abstract: In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.


Title: Reasoning Systems for Semantic Navigation in Mobile Robots
Abstract: Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.


Title: Hybrid Approach for Human Activity Recognition by Ubiquitous Robots
Abstract: One of the main objectives of ubiquitous robots is to proactively provide context-aware intelligent services to assist humans in their professional or daily living activities. One of the main challenges is how to automatically obtain a consistent and correct description of human context such as location, activities, emotions, etc. In this paper, a new hybrid approach for reasoning on the context is proposed. This approach focuses on human activity recognition and consists of machine-learning algorithms, an expressive ontology representation, and a reasoning system. The latter allows detecting the inconsistencies that may appear during the machine learning phase. The proposed approach can also correct automatically these inconsistencies by considering the context of the ongoing activity. The obtained results on the Opportunity dataset demonstrate the feasibility of the proposed method to enhance the performance of human activity recognition.


Title: Approaches for Action Sequence Representation in Robotics: A Review
Abstract: Robust representation of actions and its sequences for complex robotic tasks would transform robot's understanding to execute robotic tasks efficiently. The challenge is to understand action sequences for highly unstructured environments and to represent and construct action and action sequences. In this manuscript, we present a review of literature dealing with representation of action and action sequences for robot task planning and execution. The methodological review was conducted using Google Scholar and IEEE Xplore, searching the specific keywords. This manuscript gives an overview of current approaches for representing action sequences in robotics. We propose a classification of different methodologies used for action sequences representation and describe the most important aspects of the reviewed publications. This review allows the reader to understand several options that do exist in the research community, to represent and deploy such action representations in real robots.


Title: Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots
Abstract: We assume that an intuitive means for the specification, re-use, modification and transfer of synchronized motions-both regarding the two arms of a dual-arm robotic system, as well as regarding the coordination of a user and a robot-is key in interactive and collaborative settings as they are currently targeted for industrial applications. We show, how our knowledge based approach to end-user programming of synchronized motions and other generalizable, robot-agnostic skills can support such specification of coordinated actions between two robot arms and explain how that could be extended to include coordination with a human user. We describe the underlying ontologies and possibilities to populate those with an interface for intuitive programming, and show the generality of our approach through a task transfer between different kinematics (different robots), where the user is supported through underlying reasoning about the fulfillment of certain parameters or constraints for the involved skills.


Title: Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).
Abstract: This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.


Title: Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.
Abstract: Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.


Title: PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python
Abstract: A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.


Title: TSSD: Temporal Single-Shot Detector Based on Attention and LSTM
Abstract: Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.


Title: Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors
Abstract: Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.


Title: Speeding-Up Object Detection Training for Robotics with FALKON
Abstract: Latest deep learning methods for object detection provide remarkable performance, but have limits when used in robotic applications. One of the most relevant issues is the long training time, which is due to the large size and imbalance of the associated training sets, characterized by few positive and a large number of negative examples (i.e. background). Proposed approaches are based on end-to-end learning by back-propagation [22] or kernel methods trained with Hard Negatives Mining on top of deep features [8]. These solutions are effective, but prohibitively slow for on-line applications. In this paper we propose a novel pipeline for object detection that overcomes this problem and provides comparable performance, with a 60x training speedup. Our pipeline combines (i) the Region Proposal Network and the deep feature extractor from [22] to efficiently select candidate RoIs and encode them into powerful representations, with (ii) the FALKON [23] algorithm, a novel kernel-based method that allows fast training on large scale problems (millions of points). We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach. We assess the effectiveness of the approach on a standard Computer Vision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a real robotic scenario with the iCubWorld Transformations [18] dataset.


Title: Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels
Abstract: Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.


Title: Real-Time Segmentation with Appearance, Motion and Geometry
Abstract: Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at1.


Title: Efficient Absolute Orientation Revisited
Abstract: Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.


Title: Active Structure-from-Motion for 3d Straight Lines
Abstract: A reliable estimation of 3D parameters is a must for several applications like planning and control, in which is included Image-Based Visual Servoing. This control scheme depends directly on 3D parameters, e.g. depth of points, and/or depth and direction of 3D straight lines. Recently, a framework for Active Structure-from-Motion was proposed, addressing the former feature type. However, straight lines were not addressed. These are 1D objects, which allow for more robust detection, and tracking. In this work, the problem of Active Structure-from-Motion for 3D straight lines is addressed. An explicit representation of these features is presented, and a change of variables is proposed. The latter allows the dynamics of the line to respect the conditions for observability of the framework. A control law is used with the purpose of keeping the control effort reasonable, while achieving a desired convergence rate. The approach is validated first in simulation for a single line, and second using a real robot setup. The latter set of experiments are conducted first for a single line, and then for three lines.


Title: Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics
Abstract: This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.


Title: Towards Real-Time Unsupervised Monocular Depth Estimation on CPU
Abstract: Unsupervised depth estimation from a single image is a very attractive technique with several implications in robotic, autonomous navigation, augmented reality and so on. This topic represents a very challenging task and the advent of deep learning enabled to tackle this problem with excellent results. However, these architectures are extremely deep and complex. Thus, real-time performance can be achieved only by leveraging power-hungry GPUs that do not allow to infer depth maps in application fields characterized by low-power constraints. To tackle this issue, in this paper we propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image. Similarly to state-of-the-art, we train our network in an unsupervised manner casting depth estimation as an image reconstruction problem. Extensive experimental results on the KITTI dataset show that compared to the top performing approach our network has similar accuracy but a much lower complexity (about 6% of parameters) enabling to infer a depth map for a KITTI image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard CPU. Moreover, by trading accuracy for efficiency, our network allows to infer maps at about 2 Hz and 40 Hz respectively, still being more accurate than most state-of-the-art slower methods. To the best of our knowledge, it is the first method enabling such performance on CPUs paving the way for effective deployment of unsupervised monocular depth estimation even on embedded systems.


Title: A Plug-In Feed-Forward Control for Sloshing Suppression in Robotic Teleoperation Tasks
Abstract: In this paper, the problem of suppressing sloshing dynamics in liquid handling robotic systems has been faced by designing a dynamic filter that starting from the desired motion of the liquid container calculates the complete position/orientation trajectory for the robot end-effector. Specifically, a design philosophy mixing a filtering technique that suppresses the frequency contributions of the reference motion that may cause liquid oscillations and an active compensation of lateral accelerations by a proper container re-orientation has been adopted. In principle, the latter contribution requires the knowledge of acceleration of the reference trajectory, but because of the use of an harmonic smoother that performs a shaping of the original motion, it is possible to obtain the value of the acceleration in runtime. In this way, the proposed methods can be applied also to reference motions that are not known in advance, e.g. commands directly provided by a human operator. This possibility has been demonstrated by means of a number of experimental tests in which the user teleoperates the robot carrying the container with the liquid by simply moving in the free space its hand, whose 3D position is detected by a motion capture system.


Title: Elastic Structure Preserving Impedance (ESπ)Control for Compliantly Actuated Robots
Abstract: We present a new approach for Cartesian impedance control of compliantly actuated robots with possibly nonlinear spring characteristics. It reveals a remarkable stiffness and damping range in the experimental evaluation. The most interesting contribution, is the way the desired closed-loop dynamics is designed. Our control concept allows to add a desired stiffness and damping directly on the end-effector, while leaving the system structure intact. The intrinsic inertial and elastic properties of the system are preserved. This is achieved by introducing new motor coordinates that reflect the desired spring and damper terms. Theoretically, by means of additional motor inertia shaping it is possible to make the end-effector interaction behavior with respect to external loads approach, arbitrarily close, the interaction behavior that is achievable by classical Cartesian impedance control on rigid robots. The physically motivated design approach allows for an intuitive understanding of the resulting closed-loop dynamics. We perform a passivity and stability analysis on the basis of al physically motivated storage and Lyapunov function.


Title: An Efficient and Time-Optimal Trajectory Generation Approach for Waypoints Under Kinematic Constraints and Error Bounds
Abstract: This paper presents an approach to generate the time-optimal trajectory for a robot manipulator under certain kinematic constraints such as joint position, velocity, acceleration, and jerk limits. This problem of generating a trajectory that takes the minimum time to pass through specified waypoints is formulated as a nonlinear constraint optimization problem. Unlike prior approaches that model the motion of consecutive waypoints as a Cubic Spline, we model this motion with a seven-segment acceleration profile, as this trajectory results in a shorter overall motion time while staying within the bounds of the robot manipulator's constraints. The optimization bottleneck lies in the complexity that increases exponentially with the number of waypoints. To make the optimization scale well with the number of waypoints, we propose an approach that has linear complexity. This approach first divides all waypoints to consecutive batches, each with an overlap of two waypoints. The overlapping waypoints then act as a bridge to concatenate the optimization results of two consecutive batches. The whole trajectory is effectively optimized by successively optimizing every batch. We conduct experiments on practical scenarios and trajectories generated by motion planners to evaluate the effectiveness of our proposed approach over existing state-of-the-art approaches.


Title: Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments
Abstract: Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.


Title: A Self-Tuning Impedance Controller for Autonomous Robotic Manipulation
Abstract: Complex interactions with unstructured environments require the application of appropriate restoring forces in response to the imposed displacements. Impedance control techniques provide effective solutions to achieve this, however, their quasi-static performance is highly dependent on the choice of parameters, i.e. stiffness and damping. In most cases, such parameters are previously selected by robot programmers to achieve a desired response, which limits the adaptation capability of robots to varying task conditions. To improve the generality of interaction planning through task-dependent regulation of the parameters, this paper introduces a novel self-regulating impedance controller. The regulation of the parameters is achieved based on the robot's local sensory data, and on an interaction expectancy value. This value combines the interaction values from the robot state machine and visual feedback, to authorize the autonomous tuning of the impedance parameters in selective Cartesian axes. The effectiveness of the proposed method is validated experimentally in a debris removal task.


Title: Development of MR Clutch for a Prospective 5 DOF Robot* This work was supported in part by Canada Foundation for Innovation (CFI) and Natural Sciences and Engineering Research Council (NSERC) of Canada under grant No.25031 and RGPIN-346166.
Abstract: This paper presents an improved design approach for the construction of a Magneto-Rheological (MR) clutch intended to be used in a prospective 5 degrees of freedom robot. The MR clutch features embedded Hall sensors for intrinsic torque control. After a brief description of the MR clutch principles, the details of the mechanical design are discussed. Simulation and preliminary experimental results demonstrate the main characteristics and advantages of the proposed MR clutch.


Title: Embedded and controllable shape morphing with twisted-and-coiled actuators*
Abstract: Shape morphing, meaning a structure can first morph and then lock into another shape, can be applied to robot designs to endow robots with adaptive morphology for increased functionality and adaptivity. In this paper, we introduce a novel shape morphing scheme enabled by a new artificial muscle: twisted and coiled actuators (TCAs). This new actuator is purely soft, low cost, and electrically driven. Embedding a TCA and a thermoplastic material with variable stiffness into soft materials, we create a miniature shape-morphing link. We also establish a general model to predict the steady-state shape of the link given an input power applied to the TCA. Experiments are conducted to characterize parameters and verify the proposed model. Finally, we demonstrate this shape-morphing link can serve as a link in a mechanism to change the trajectory of its foot or endpoint. We envision that such a new shape-morphing scheme can enable robots to leverage the same mechanical design for different functions.


Title: Soft Robotic Burrowing Device with Tip-Extension and Granular Fluidization
Abstract: Mobile robots of all shapes and sizes move through the air, water, and over ground. However, few robots can move through the ground. Not only are the forces resisting movement much greater than in air or water, but the interaction forces are more complicated. Here we propose a soft robotic device that burrows through dry sand while requiring an order of magnitude less force than a similarly sized intruding body. The device leverages the principles of both tip-extension and granular fluidization. Like roots, the device extends from its tip; the principle of tip-extension eliminates skin drag on the sides of the body, because the body is stationary with respect to the medium. We implement this with an everting, pressure-driven thin film body. The second principle, granular fluidization, enables a granular medium to adopt a dynamic fluid-like state when pressurized fluid is passed through it, reducing the forces acting on an object moving through it. We realize granular fluidization with a flow of air through the core of the body that mixes with the medium at the tip. The proposed device could lead to applications such as search and rescue in mudslides or shallow subterranean exploration. Further, because it creates a physical conduit with its body, electrical lines, fluids, or even tools could be passed through this channel.


Title: Liquid Metal-Microelectronics Integration for a Sensorized Soft Robot Skin
Abstract: Progress in soft robotics depends on the integration of electronics for sensing, power regulation, and signal processing. Commercially available microelectronics satisfy these functions and are small enough to preserve the natural mechanics of the host system. Here, we present a method for incorporating microelectronic sensors and integrated circuits (ICs) into the elastomeric skin of a soft robot. The thin stretchable skin contains various solid-state electronics for orientation, pressure, proximity, and temperature sensing, and a microprocessor. The components are connected by thin-film copper traces wetted with eutectic gallium indium (EGaIn), a room temperature liquid metal alloy that allows the circuit to maintain conductivity as it deforms under mechanical loading. In this paper, we characterize the function of the individual sensors in air and water, discuss the integration of the microelectronic skin with a shape-memory actuated soft gripper, and demonstrate the sensorized soft gripper in conjunction with a 4 degree-of-freedom (DOF) robot arm.


Title: Development of a Hybrid Gripper with Soft Material and Rigid Structures
Abstract: For decades, various robotic grippers have been developed due to its necessity for the robotic manipulators. In case of the conventional robotic grippers with rigid components, an underactuated mechanism was required to satisfy gripping motion. Recently, soft grippers have been studied actively, which have realize bending motion with a simple morphological structure itself and inherent compliance to the environment. In this field of study, it has been rarely investigated to improve the fingertip force and actuation speed with specified design parameters. Thus, in this study, a hybrid gripper, which consists of both soft and rigid components, was suggested based on the key design principles: 1) the ratio of rigid parts against the soft chamber, 2) the cross-sectional shape of the chamber. The suggested principles were verified using the finite element methods (FEMs). As a result, the improved performance of the hybrid gripper was verified in terms of the fingertip force and the actuation speed, compared with the performance of the previously developed soft pneumatic actuators (SPAs). As an application, the three-fingered gripper was manufactured and tested by grasping different types of objects.


Title: Design for Control of a Soft Bidirectional Bending Actuator
Abstract: In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.


Title: Sliding-Layer Laminates: A Robotic Material Enabling Robust and Adaptable Undulatory Locomotion
Abstract: Continuum robots that move through undulatory actuation must be composed of body materials that can enable flexible movement yet also provide resistive forces to the surrounding fluid, granular, or solid environments. This need for “f1exible-yet-stiff” materials is notably important in robot designs that use passive propulsive elements such as tails and wings. Here we explore a laminate design paradigm for “f1exible-yet-stiff” robotic materials through sliding layer laminates (SLLs). We present design principles motivated by theory and experiment and illustrate a taxonomy of SLL enabled morphable materials capable of up to 7 fold change in stiffness. Lastly, we demonstrate the applicability of SLLs to undulatory continuum robots: a swimming robot with a passive tail. We target two desired robot locomotor behaviors: fast open water swimming, and steady swimming through narrow channels emulating underwater caverns and pipes. We demonstrate how tuning the stiffness of the robot tail maximizes thrust generation in these two locomotion modes. Soft tails are optimal in confined swimming because they generate short amplitude high wavenumber oscillations, while stiff tails in confined environments either collide with the walls or do not generate sufficient thrust. However, stiff tails are far better in unconfined environments which enable large stroke amplitudes requiring high stiffness. Through this demonstration we show that stiff or soft tail designs alone are incapable of effective locomotion in complex underwater environments challenge.


Title: Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor
Abstract: A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.


Title: Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).
Abstract: Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.


Title: Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling
Abstract: Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.


Title: Enhanced Explosive Motion for Torque Controlled Actuators Through Field Weakening Control
Abstract: This work presents a method to increase the peak output speed of surface permanent magnet synchronous machine (SPMSM) motor drives with application in robotics using field weakening control. Contrary to most existing works, the strategy is stateless and operates using only a motor torque reference as input, making it suitable for robotics applications in which reference torque and speed are continuously and rapidly changing. Based on the system dynamics and constraints, we obtain four different operating modes. The strategy is extensively validated using three different experiments, which show an increase in peak velocity of up to 33%. The results demonstrate that the proposed strategy is effective in extending the dynamic performance and explosive motion capabilities of robots.


Title: Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators
Abstract: Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H∞ control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat® 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.


Title: Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints
Abstract: In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.


Title: Continuously Shaping Projections and Operational Space Tasks
Abstract: Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.


Title: Dual-Arm Relative Tasks Performance Using Sparse Kinematic Control
Abstract: To make production lines more flexible, dual-arm robots are good candidates to be deployed in autonomous assembly units. In this paper, we propose a sparse kinematic control strategy, that minimizes the number of joints actuated for a coordinated task between two arms. The control strategy is based on a hierarchical sparse QP architecture. We present experimental results that highlight the capability of this architecture to produce sparser motions (for an assembly task) than those obtained with standard controllers.


Title: Jet-HR1: Stepping Posture Optimization for Bipedal Robot Over Large Ditch Based on a Ducted-fan Propulsion System*
Abstract: This paper reports the latest progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over a broad ditch with a height difference between the two sides. This work focuses on the methods of calculating the boundary and optimizing stepping posture to use less thrust and keep the robot balanced while stepping over the ditch. With the proposed methods and new two-dimensional gaits, the prototype robot, named Jet-HRl (Jet Humanoid Robot ver.l) was able to completely step over a broad ditch with 450mm in width (up to 97% of the robot's leg's length), and a height difference of 100mm between two sides.


Title: User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization
Abstract: In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.


Title: Passivity Based Iterative Learning of Admittance-Coupled Dynamic Movement Primitives for Interaction with Changing Environments
Abstract: Encoding desired motions into dynamic movement primitives (DMPs) is a common way for generating compact task representations that are able to handle sensor-based goal adaptations. At the same time, a robot should not only express adaptive motion capabilities at planning level, but use also contact wrench feedback in the adaptation and learning process of the DMP. Despite first approaches exist in this direction, no fully integrated approach has been proposed so far. In this paper, we introduce a new class of admittance-coupled DMPs that addresses environmental changes by including contact wrench feedback dynamics into the DMP formalism. Moreover, a novel iterative learning approach is devised that is based on monitoring the overall system passivity analysis in terms of reference power tracking. Simulations and experimental results with the Kuka LWR robot maintaining a non-rigid contact with the environment (wiping a surface) are shown for supporting the validity of our approach.


Title: Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints
Abstract: Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by leveraging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.


Title: Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives
Abstract: Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.


Title: Associative Skill Memory Models
Abstract: Associative Skill Memories (ASMs) were formulated to encode stereotypical movements along with their stereotypical sensory events to increase the robustness of underlying dynamic movement primitives (DMPs) against noisy perception and perturbations. In ASMs, the stored sensory trajectories, such as the haptic and tactile measurements, are used to compute how much a perturbed movement deviates from the desired one, and to correct the movement if possible. In our work, we extend ASMs: rather than using stored single sensory trajectory instances, our system generates sensory event models and exploits those models to correct the perturbed movements during executions with the aim of generalizing to novel configurations. In particular, measured force and the torque trajectories are modelled using Parametric Hidden Markov Models, and then reproduced by Gaussian Mixture Regression. With Baxter robot, we demonstrate that our proposed force feedback model can be used to correct a trajectory while pushing an object with a mass never experienced before, and which otherwise slips away from the gripper because of noise. In the end, we discuss how far this skill can be generalized using the force model and possible future improvements.


Title: Segmenting and Sequencing of Compliant Motions
Abstract: This paper proposes an approach for segmenting a task consisting of compliant motions into phases, learning a primitive for each segmented phase of the task, and reproducing the task by sequencing primitives online based on the learned model. As compliant motions can “probe” the environment, using the interaction between the robot and the environment to detect phase transitions can make the transitions less prone to positional errors. This intuition leads us to model a task with a non-homogeneous Hidden Markov Model (HMM), wherein hidden phase transition probabilities depend on the interaction with the environment (wrench measured by an F/T sensor). Expectation-maximization algorithm is employed in estimating the parameters of the HMM model. During reproduction, the phase changes of a task are detected online using the forward algorithm, with the parameters learned from demonstrations. Cartesian impedance controller parameters are learned from the demonstrations to reproduce each phase of the task. The proposed approach is studied with a KUKA LWR4+ arm in two setups. Experiments show that the method can successfully segment and reproduce a task consisting of compliant motions with one or more demonstrations, even when demonstrations do not have the same starting position and external forces occur from different directions. Finally, we demonstrate that the method can also handle rotational motions.


Title: An Uncertainty-Aware Minimal Intervention Control Strategy Learned from Demonstrations
Abstract: Motivated by the desire to have robots physically present in human environments, in recent years we have witnessed an emergence of different approaches for learning active compliance. Some of the most compelling solutions exploit a minimal intervention control principle, correcting deviations from a goal only when necessary, and among those who follow this concept, several probabilistic techniques have stood out from the rest. However, these approaches are prone to requiring several task demonstrations for proper gain estimation and to generating unpredictable robot motions in the face of uncertainty. Here we present a Programming by Demonstration approach for uncertainty-aware impedance regulation, aimed at making the robot compliant - and safe to interact with - when the uncertainty about its predicted actions is high. Moreover, we propose a data-efficient strategy, based on the energy observed during demonstrations, to achieve minimal intervention control, when the uncertainty is low. The approach is validated in an experimental scenario, where a human collaboratively moves an object with a 7-DoF torque-controlled robot.


Title: Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving
Abstract: Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.


Title: Evaluating Methods for End-User Creation of Robot Task Plans
Abstract: How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.


Title: A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching
Abstract: Suction is an effective method for picking various objects because it makes trajectory planning and control easy. However, suction has not been used due to misalignment and leakage of suction air when handling a variety of shapes. We therefore develop a hand to handle these characteristics. First, we model the vacuum pump and pad characteristics to allow evaluation of momentum and suction force in the case of leakage. Utilizing this, we select a configuration suitable for the items in the Amazon Robotics Challenge 2017. In addition, we design a mechanism for switching from suction to pinching for grasping items that cannot be sucked. Moreover, robust pinching is made possible by equipping the fingertips with a passive linear motion mechanism. In the Amazon Robotics Challenge 2017, it was shown possible to stably grasp items with irregularities and items with large moments. Furthermore, items that cannot be grasped by suction can also be grasped robustly by switching to the pinching mechanism.


Title: Mass Manufacturing of Self-Actuating Robots: Integrating Sensors and Actuators Using Flexible Electronics
Abstract: Currently, the manufacturing of self-actuating and self-sensing robots requires non-standard manufacturing techniques and assembly steps to integrate electrical and mechanical systems. In this work, we developed a novel manufacturing technique, where such robots can be produced at a flexible electronics factory. We developed the technique using standard industrial machines, processes, and materials. Using a lamination process, we were able to integrate air pouches or shape memory alloy (SMA) inside a polyamide-based flexible circuit to produce bending actuators. The bend angle of the actuators is sensed with a chain of inertial measurement units integrated on the actuator. Air-pouch actuators can produce a force of a 2.24N, and a maximum bend angle of 74 degrees. To demonstrate, we manufactured a five-legged robot with the developed actuators and bend sensors, with all the supporting electronics (e.g., microcontrollers, radio) directly integrated into the flexible printed circuit. Such robots are flat and lightweight (15 grams) and thus conveniently compact for transportation and storage. We believe that our technique can allow inexpensive and fast prototyping and deployment of self-actuating and self-sensing robots.


Title: Achieving Flexible Assembly Using Autonomous Robotic Systems
Abstract: Prefabrication of structures is currently used in a limited capacity, due to the lack of flexibility, despite the potential cost and speed advantages. Autonomous flexible reassembly enables structures to be developed which can be continuously and iteratively dis-assembled and re-assembled providing far more flexibility in comparison to single shot pre-fabrication methods. Dis-assembly of structures should be considered when assembling, due to the asymmetry of assembly and dis-assembly processes, to ensure structures can be recycled and re-assembled. This allows for agile development, significantly reducing the time and resource usage during the build process. In this work, a framework for flexible re-assembly is developed and a robotic platform is developed to implement and test this framework with simple Lego bricks. The tradeoffs in terms of time, resource use and probability of success of this new assembly method can be understood by using a cost function to compare to alternative fabrication methods.


Title: Human Pose Estimation in Presence of Occlusion Using Depth Camera Sensors, in Human-Robot Coexistence Scenarios
Abstract: Collaborative robotics over the last few years has gained increasing interest in the industrial scenario. Co-bots can be equipped with vision sensors and cognitive software layers, allowing the robot to figure out human intentions. To make this level of perception possible, human pose estimation algorithms are required. Several techniques have been already proposed to tackle this problem, which however present some weaknesses in particular when occlusions occur. This work proposes an algorithm for human pose estimation in the situations of partial occlusion, based on particle filter techniques. We have proved its validity in a realistic human-robot coexistence scenario, where a human and a dual arm robot have to perform tasks in a shared workspace.


Title: Feasibility of the UR5 Industrial Robot for Robotic Rehabilitation of the Upper Limbs After Stroke
Abstract: Robot-assisted therapy is an emerging form of rehabilitation treatment for motor recovery of the upper limbs after neurological injuries such as stroke or spinal cord injury. Robotic rehabilitation devices have the potential to reduce the physical strain put on therapists due to the high-effort one-to-one interactions between the therapist and patient involving repetitive high-intensity movements to restore arm and hand functions. Numerous custom robotic devices have been developed in recent years to aid in physical rehabilitation of stroke patients, but most commercially available systems are high-cost devices because of low production volumes and high development costs. In this paper, we analyse the safety and functionality of the UR5 collaborative industrial robot from universal Robots equipped with an external force/torque sensor in a real-time control system for typical rehabilitation exercises. The aim of the paper is to show that a new class of general-purpose industrial robots designed for human-robot collaboration may prove a viable alternative to custom designs. Experiments show that robotic rehabilitation of the upper limbs using a standard industrial robot manipulator UR5 may be feasible. Results have the potential to make robotic rehabilitation more available as a high-quality therapeutic treatment for more patients.


Title: Safety-Related Tasks Within the Set-Based Task-Priority Inverse Kinematics Framework
Abstract: In this paper we present a framework that allows the motion control of a robotic arm automatically handling different kinds of safety-related tasks. The developed controller is based on a Task-Priority Inverse Kinematics algorithm that allows the manipulator's motion while respecting constraints defined either in the joint or in the operational space in the form of equality-based or set-based tasks. This gives the possibility to define, among the others, tasks as joint-limits, obstacle avoidance or limiting the workspace in the operational space. Additionally, an algorithm for the real-time computation of the minimum distance between the manipulator and other objects in the environment using depth measurements has been implemented, effectively allowing obstacle avoidance tasks. Experiments with a Jaco2 manipulator, operating in an environment where an RGB-D sensor is used for the obstacles detection, show the effectiveness of the developed system.


Title: Model-Based Engineering, Safety Analysis and Risk Assessment for Personal Care Robots
Abstract: In this paper, we propose a method and associate platform to couple model-based system engineering and safety analysis at the early phases of robotic system (RS) life-cycle. The method is compatible with IEC12100 and ISO13482. The platform is based on Papyrus UML modeler and supports RobotML, a domain specific language for RSs, as well as tools for safety analysis and risk assessment, Sophia and Safety Architect. It includes an ability (a) to model architecture of RSs; (b) to automatically run safety analysis (e.g. failure mode and effects analysis, fault tree analysis, etc.); (c) to save and reuse safety artefacts; (d) to represent safety analysis results in the modeling environment. We illustrate the proposed method by considering a humanoid personal care robot from SoftBank Robotics developed in the scope of the ROMEO2 project.


Title: Computation of Safe Path Velocity for Collaborative Robots
Abstract: This paper presents a method for numerically computing the highest path velocity that a collaborative robot can attain, while complying with safety requirements. The safety requirements are obtained from ISO/TS 15066 that describes a collaborative method called power and force limiting, which specifies safe collisions between humans and robots. In particular, we assume that a path is given and compute the point-wise maximal path velocity that ensures a safe impact, i.e., the paper provides no considerations on the post impact safety.


Title: Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems
Abstract: This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.


Title: Evaluating Robotic Devices of Non-Wearable Transferring Aids Using Whole-Body Robotic Simulator of the Elderly
Abstract: This paper describes the development of a whole-body robotic simulator of an elderly person for evaluating robotics devices for nursing care. To improve the quality of life of the elderly persons, physical assistance such as transfer, movement, and bathroom assistance is important. It is also important to reduce the workload of caregivers in an aging society. In recent years, assistive robotic devices for nursing care have been developed and commercialized for such purposes. However, such devices have not become popular in the care facilities yet. One of the reasons is that it is still difficult to evaluate the effects of the devices on the care receivers and caregivers. In particular, it is necessary to quantitatively evaluate the effect of the devices on the human body from the viewpoint of safety and comfort. We have developed a whole-body robotic system to simulate the pose and motion of the elderly persons. The purpose of this system is to realize quantitative physical evaluation of robotics devices for nursing care of the human body. The experimental results of the preliminary evaluation of assistive robotic devices are also presented.


Title: Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery
Abstract: Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.


Title: Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface
Abstract: We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.


Title: Fabrication and Locomotion of Flexible Nanoswimmers
Abstract: Small-scale robots with soft joints and hinges have recently attracted interest because these components allow for more sophisticated locomotion mechanisms. Here, we investigate two different types of nanoscale swimmers as depicted in Figure 1. One consists of a rigid magnetic head linked to a semi-soft tail (1-link swimmer). Another consists of a rigid magnetic head and tail connected by a soft hinge (2-link swimmer). Both swimmers exhibit undulatory locomotion under an applied oscillating magnetic field. The speeds of the swimmers are assessed as a function of the oscillating magnetic field frequency and the sweeping angle. We find that a resonance-like frequency increases as the length decreases, and, in general, the speed increases as the sweeping angle increases. Last, we show that 2-link swimmers can also swim in a corkscrew-like pattern under rotating magnetic fields.


Title: Gait Learning for Soft Microrobots Controlled by Light Fields
Abstract: Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.


Title: Ceiling Effects for Surface Locomotion of Small Rotorcraft
Abstract: Motivated by the potential of bimodal aerial and surface locomotion as an energy saving strategy for small flying robots, we investigate the effects of a flat overhang surface in the vicinity of a spinning propeller. We employ the classical momentum theory and the blade element method to describe the “ceiling effects” in regards to the generated thrust, power, and rotational speed of the propeller in terms of a normalized distance between the ceiling and the propeller. Validating experiments were performed on a benchtop setup, and the results are in agreement with the proposed models. The presence of a ceiling was found to reduce the power consumption by more than a factor of three for the same thrust force. Overall, our findings show promise, paving the way for the use of perching maneuvers by small rotorcraft to extend their missions.


Title: Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
Abstract: This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.


Title: Incremental Learning-Based Adaptive Object Recognition for Mobile Robots
Abstract: 3D visual understanding of the surrounding environment is vital for successful mobile robotic tasks such as autonomous navigation or general object interaction. However, current systems have limited perceptual capabilities in the sense that they are not very well adaptable to unknown environments. Human operators, on the other hand, are experts in adapting to previously unknown information. Hence, human-robot teaming in which the human helps the robot to adapt to new environments and the robot assists in automated object recognition to efficiently feed the control environment of the operator is advantageous. In this work, we propose an object recognition and localization system for mobile robots, based on deep learning, and we study the adaptation of the resulting robotic perception to a new environment. We propose two methods to teach the robot a new object category: using prior knowledge and using limited operator input. We conducted several experiments to show the feasibility of proposed methods.


Title: Object Detection and Pose Estimation Based on Convolutional Neural Networks Trained with Synthetic Data
Abstract: Instance-based object detection and fine pose estimation is an active research problem in computer vision. While the traditional interest-point-based approaches for pose estimation are precise, their applicability in robotic tasks relies on controlled environments and rigid objects with detailed textures. CNN-based approaches, on the other hand, have shown impressive results in uncontrolled environments for more general object recognition tasks like category-based coarse pose estimation, but the need of large datasets of fully-annotated training images makes them unfavourable for tasks like instance-based pose estimation. We present a novel approach that combines the robustness of CNNs with a fine-resolution instance-based 3D pose estimation, where the model is trained with fully-annotated synthetic training data, generated automatically from the 3D models of the objects. We propose an experimental setup in which we can carefully examine how the model trained with synthetic data performs on real images of the objects. Results show that the proposed model can be trained only with synthetic renderings of the objects' 3D models and still be successfully applied on images of the real objects, with precision suitable for robotic tasks like object grasping. Based on the results, we present more general insights about training neural models with synthetic images for application on real-world images.


Title: Towards Event-Driven Object Detection with Off-the-Shelf Deep Learning
Abstract: Event cameras are an emerging technology in computer vision, offering extremely low latency and bandwidth, as well as a high temporal resolution and dynamic range. Inherent data compression is achieved as pixel data is only produced by contrast changes at the edges of moving objects. However, current trends in state-of-the-art visual algorithms rely on deep-learning with networks designed to process colour and intensity information contained in dense arrays, but are notoriously computationally heavy. While the combination of these visual technologies could lead to fast, efficient, and accurate detection and recognition algorithms, it is uncertain whether the compressed event-camera data actually contain the required information for these techniques to discriminate between objects and a cluttered background. This paper presents a pilot study in which off-the-shelf deep-learning is applied to visual events for object detection on the iCub robotic platform, and analyses the impact of temporal integration of the event data. We also present a novel pipeline that bootstraps event-based dataset annotation from mature frame-based algorithms, in order to more quickly generate the required datasets.


Title: Interactive Training of Object Detection Without ImageNet
Abstract: For many robotic tasks, particularly those of service robots operating in human environments, the scope of object detection needs is greater than the available data. Either public datasets do not contain the entire set of objects needed for the task, and/or it is a commercial application that cannot use public datasets for training. Instead of hiring people to hand-label more data to support the integration of new objects into robot perception, we propose an interactive training process requiring zero hand labeling. With as little as 4 minutes of interaction with the robot per object, we demonstrate 99% precision and 57% recall in stationary object detection tasks.


Title: Action Selection for Interactive Object Segmentation in Clutter
Abstract: Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter.


Title: Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation
Abstract: Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.


Title: Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges
Abstract: An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.


Title: Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality
Abstract: This paper introduces a method of structure inspection using mixed-reality headsets to reduce the human effort in reporting accurate inspection information such as fault locations in 3D coordinates. Prior to every inspection, the headset needs to be localized. While external pose estimation and fiducial marker based localization would require setup, maintenance, and manual calibration; marker-free self-localization can be achieved using the onboard depth sensor and camera. However, due to limited depth sensor range of portable mixed-reality headsets like Microsoft HoloLens, localization based on simple point cloud registration (sPCR) would require extensive mapping of the environment. Also, localization based on camera image would face same issues as stereo ambiguities and hence depends on viewpoint. We thus introduce a novel approach to Joint Point Cloud and Image-based Localization (JPIL) for mixed-reality headsets that uses visual cues and headset orientation to register small, partially overlapped point clouds and save significant manual labor and time in environment mapping. Our empirical results compared to sPCR show average 10 fold reduction of required overlap surface area that could potentially save on average 20 minutes per inspection. JPIL is not only restricted to inspection tasks but also can be essential in enabling intuitive human-robot interaction for spatial mapping and scene understanding in conjunction with other agents like autonomous robotic systems that are increasingly being deployed in outdoor environments for applications like structural inspection.


Title: Summarizing Large Scale 3D Mesh
Abstract: Recent progress in 3D sensor devices and in semantic mapping allows to build very rich HD 3D maps very useful for autonomous navigation and localization. However, these maps are particularly huge and require important memory capabilities as well computational resources. In this paper, we propose a new method for summarizing a 3D map (Mesh)as a set of compact spheres in order to facilitate its use by systems with limited resources (smartphones, robots, UAVs,...). This vision-based summarizing process is applied in a fully automatic way using jointly photometric, geometric and semantic information of the studied environment. The main contribution of this research is to provide a very compact map that maximizes the significance of its content while maintaining the full visibility of the environment. Experimental results in summarizing large-scale 3D map demonstrate the feasibility of our approach and evaluate the performance of the algorithm.


Title: A Robust Control Method for the Elbow of the Humanoid Robot TEO Based on a Fractional Order Controller
Abstract: This paper presents a novel method for the control of the elbow joint of the humanoid robot TEO, based on a fractional order PD controller. Due to the graphical nature of the proposed method, a few basic operations are enough to tune the controller, offering very competitive results compared to classic methods. The experiments show a robust performance of the system to mass changes at the tip of the humanoid right arm.


Title: FPGA-Based Velocity Estimation for Control of Robots with Low-Resolution Encoders
Abstract: Robot control algorithms often rely on measurements of robot joint velocities, which can be estimated by measuring the time between encoder edges. When encoder edges occur infrequently, such as at low velocities and/or with low resolution encoders, this measurement delay may affect the stability of closed-loop control. This is evident in both the joint position control and Cartesian impedance control of the da Vinci Research Kit (dVRK), which contains several low-resolution encoders. We present a hardware-based method that gives more frequent velocity updates and is not affected by common encoder imperfections such as non-uniform duty cycles and quadrature phase error. The proposed method measures the time between consecutive edges of the same type but, unlike prior methods, is implemented for the rising and falling edges of both channels. Additionally, it estimates acceleration to enable software compensation of the measurement delay. The method is shown to improve Cartesian impedance control of the dVRK.


Title: Underwater Modeling, Experiments and Control Strategies of FroBot
Abstract: FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.


Title: Feedback Linearizing Controller for a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
Abstract: Despite the benefits that the spring based gravity compensation mechanism has brought to the field of rigid robotic manipulators, there have been no substantial efforts toward transferring these developments to the field of flexible link robotics. In this paper, we present an input state feedback linearization controller for the tip positioning of a flexible link arm with a gravity compensation system based on springs. The controller is implemented into a double loop control scheme, in which the inner loop addresses the motor position control in presence of joint friction, and the outer loop deals with vibration cancellation and the tracking of fourth-order trajectories for the tip position of the flexible arm. Taking into considerations the interacting forces between the flexible link and the gravity compensation mechanism, and also the characteristics of the control law, we propose a sensory system to measure all the relevant signals. The proposed controller is tested on an experimental prototype built in our laboratory.


Title: System Identification and Closed-Loop Control of a Hydraulically Amplified Self-Healing Electrostatic (HASEL) Actuator
Abstract: This paper describes a system identification method and the development of a closed-loop controller for a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator. Our efforts focus on developing a reliable and consistent way to identify system models for these soft robotic actuators using high-speed videography based motion tracking. Utilizing a mass-spring-damper model we are able to accurately capture the behavior of a HASEL actuator. We use the resulting plant model to design a Proportional-Integral controller that demonstrates improved closed-loop tracking and steady-state error performance.


Title: Towards a Soft Fingertip with Integrated Sensing and Actuation
Abstract: Soft material robots are attractive for safe interaction with humans and unstructured environments due to their compliance and low intrinsic stiffness and mass. These properties enable new capabilities such as the ability to conform to environmental geometry for tactile sensing and to undergo large shape changes for actuation. Due to the complex coupling between sensing and actuation in high-dimensional nonlinear soft systems, prior work in soft robotics has primarily focused on either sensing or actuation. This paper presents SOFTcell, a novel controllable stiffness tactile device that incorporates both optical sensing and pneumatic actuation. We report details on the device's design and implementation and analyze results from characterization experiments on sensitivity and performance, which show that SOFTcell can controllably increase its effective modulus from 4.4kPa to 46.1kPa. Additionally, we demonstrate the utility of SOFTcell for grasping in a reactive control task in which tactile data is used to detect fingertip shear as a grasped object slips, and cell pressurization is used to prevent the slip without the need to adjust fingertip position.


Title: Learning Oscillator-Based Gait Controller for String-Form Soft Robots Using Parameter-Exploring Policy Gradients
Abstract: This paper presents a methodology to design mechanosensor feedback to oscillator-based controller for worm-like soft-bodied robots. A reinforcement learning technique, i.e., PEPG, is employed to embed appropriate mechanosensor feedback to harness global entrainment among the controller, the body dynamics, and the environment without explicitly designing the interaction between the oscillators. Another reinforcement learning, actor-critic, was applied to train the controller for the simulation models to analyze the effectiveness of PEPG in the system. Furthermore, the gait controller was trained under different body dynamics, i.e., the physical model of a caterpillar and an earthworm. We found that PEPG is suitable for the system probably because it does not add exploration noise to actions and it conducts episode based parameter updates. The simulation results show the proposed method can acquire distinct behavior, i.e., caterpillars' crawling, inching and earthworms' crawling, under different body dynamics. The outcome implies, that by utilizing appropriate learning method, desired functionality can be achieved in soft-bodied robots without explicitly designing their behavior.


Title: CLASH: Compliant Low Cost Antagonistic Servo Hands
Abstract: This paper presents the first two members of the new generation of CLASH hands, which exploit low cost actuation and rapid prototyping to create antagonistic modular and lightweight hands and grippers. The hands approach the robustness of the DLR Awiwi hand with a much lower complexity and cost. To reduce the number of required actuators, a differential coupling mechanism for underactuated fingers was developed, along with a new mechanism that uses variable stiffness actuation in order to increase the workspace of underactuated fingers. The hands provide a research platform for both hand-in-hand and robotic grasping. Design aspects are discussed, and an initial experimental validation verifies the hands' performance.


Title: Modeling and Trajectory Tracking Control of a New Parallel Flexible Link Robot
Abstract: A completely new compliant lightweight robot is presented with a kinematic loop and a highly flexible link. It is explained how to model such parallel robots accurately but still computationally efficient. The elastic deformations are described with the floating frame of reference approach. For the flexible components this allows to use linear finite element models, which can represent arbitrary geometries. These models are further reduced by modal truncation and a Component Mode Synthesis minimizing the number of elastic degrees of freedom, which is necessary for real-time control purposes. The obtained model of the underactuated robot is non-minimum phase for the end-effector as output. Thus, for the applied trajectory tracking controller which is based on servo constraints, the concept of stable inversion is used. The performance is compared to a relocated minimum phase output. Corresponding simulations are validated by first experimental results showing the need for and high accuracy of the flexible model and the trajectory tracking control.


Title: A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning
Abstract: Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.


Title: RG-Trees: Trajectory-Free Feedback Motion Planning Using Sparse Random Reference Governor Trees
Abstract: Sampling based methods resulted in feasible and effective motion planning algorithms for high dimensional configuration spaces and complex environments. A vast majority of such algorithms as well as their application rely on generating a set of open-loop trajectories first, which are then tracked by feedback control policies. However, controlling a dynamic robot to follow the planned path, while respecting the spatial constraints originating from the obstacles is still a challenging problem. There are some studies which combine statistical sampling techniques and feedback control methods which address this challenge using different approaches. From the feedback control theory perspective, Reference Governors proved to be a useful framework for constraint enforcement. Very recently, Arslan and Koditschek (2017) introduced a feedback motion planner that utilizes Reference Governors that provably solves the motion planning problem in simplified spherical worlds. In this context, here we propose a “trajectory-free” novel feedback motion planning algorithm which combines the two ideas: random trees and reference governors. Random tree part of the algorithm generates a collision-free region as a set of connected simple polygonal regions. Then, reference governor part navigates the dynamic robot from one region to the adjacent region in the tree structure, ensuring it stays inside the current region and asymptotically reaches to the connected region. Eventually, our algorithm robustly routes the robot from the start location to the goal location without collision. We demonstrate the validity and feasibility of the algorithm on simulation studies.


Title: Distributionally Robust Sampling-Based Motion Planning Under Uncertainty
Abstract: We propose a distributionally robust incremental sampling-based method for kinodynamic motion planning under uncertainty, which we call distributionally robust RRT (DR-RRT). In contrast to many approaches that assume Gaussian distributions for uncertain parameters, here we consider moment-based ambiguity sets of distributions with given mean and covariance. Chance constraints for obstacle avoidance and internal state bounds are then enforced under the worst-case distribution in the ambiguity set, which gives a coherent assessment of constraint violation risks. The method generates risk-bounded trajectories and feedback control laws for robots operating in dynamic, cluttered, and uncertain environments, explicitly incorporating localization error, stochastic process disturbances, unpredictable obstacle motion, and uncertain obstacle location. We show that the algorithm is probabilistically complete under mild assumptions. Numerical experiments illustrate the effectiveness of the algorithm.


Title: Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs
Abstract: This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.


Title: Kinodynamic Comfort Trajectory Planning for Car-Like Robots
Abstract: As personal autonomous mobility is getting to be more widely adopted, it is more important to consider comfortability of stuffs and persons carried by such mobility. In this work, we define the comfort of a trajectory as forces, specifically, translational force, received to objects carried by a robot while following the trajectory by measuring impulse. To maximize such a comfort, we propose a novel, kinodynamic comfort path planning method based on our definition of comfort. Our work is based on direct collocation method for handling our nonconvex objective function. We also introduce Bidirectional Obstacle Detection(BOD)that identifies the distances along the perpendicular directions to the trajectory. This is mainly designed for avoiding obstacles while minimizing forces causing discomfort. Our experimental results show that our method can compute trajectories whose comfort measures can be up to 18 times higher than those computed by prior related objectives, e.g., squared velocity used for generating smooth trajectory.


Title: Expert-Guided Kinodynamic RRT Path Planner for Non-Holonomic Robots
Abstract: In this paper, an Expert-Guided Kinodynamic RRT algorithm (EGK-RRT) is presented. It aims to consider how a human pilot would navigate a kinodynamic robot. One of the characteristics of this algorithm is the fact that, unlike the original RRT for kinodynamic systems, it generates deterministic control sequences which can be reproduced as long as the sequence of references (sampled states) are known. Here, the performance of the proposed algorithm is tested against the basic RRT, showing that the EGK-RRT greatly improves in terms of execution speed. In addition to this, the influence of using a visibility check and an inertia estimation in order to select the nearest neighbor is also analyzed, demonstrating that a combination of both factors leads to a better overall performance, both in execution speed and in quality of the generated path.


Title: Robot Imitation Through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments
Abstract: Continuous Goal-Directed Actions (CGDA)is a robot imitation framework that encodes actions as the changes they produce on the environment. While it presents numerous advantages with respect to other robot imitation frameworks in terms of generalization and portability, final robot joint trajectories for the execution of actions are not necessarily encoded within the model. This is studied as an optimization problem, and the solution is computed through evolutionary algorithms in simulated environments. Evolutionary algorithms require a large number of evaluations, which had made the use of these algorithms in real world applications very challenging. This paper presents online evolutionary strategies, as a change of paradigm within CGDA execution. Online evolutionary strategies shift and merge motor execution into the planning loop. A concrete online evolutionary strategy, Online Evolved Trajectories (OET), is presented. OET drastically reduces computational times between motor executions, and enables working in real world dynamic environments and/or with human collaboration. Its performance has been measured against Full Trajectory Evolution (FTE)and Incrementally Evolved Trajectories (IET), obtaining the best overall results. Experimental evaluations are performed on the TEO full-sized humanoid robot with “paint” and “iron” actions that together involve vision, kinesthetic and force features.


Title: Probabilistic Learning of Torque Controllers from Kinematic and Force Constraints
Abstract: When learning skills from demonstrations, one is often required to think in advance about the appropriate task representation (usually in either operational or configuration space). We here propose a probabilistic approach for simultaneously learning and synthesizing torque control commands which take into account task space, joint space and force constraints. We treat the problem by considering different torque controllers acting on the robot, whose relevance is learned probabilistically from demonstrations. This information is used to combine the controllers by exploiting the properties of Gaussian distributions, generating new torque commands that satisfy the important features of the task. We validate the approach in two experimental scenarios using 7- DoF torque-controlled manipulators, with tasks that require the consideration of different controllers to be properly executed.


Title: Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization
Abstract: Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.


Title: Incremental Skill Learning of Stable Dynamical Systems
Abstract: Efficient skill acquisition, representation, and online adaptation to different scenarios has become of fundamental importance for assistive robotic applications. In the past decade, dynamical systems (DS) have arisen as a flexible and robust tool to represent learned skills and to generate motion trajectories. This work presents a novel approach to incrementally modify the dynamics of a generic autonomous DS when new demonstrations of a task are provided. A control input is learned from demonstrations to modify the trajectory of the system while preserving the stability properties of the reshaped DS. Learning is performed incrementally through Gaussian process regression, increasing the robot's knowledge of the skill every time a new demonstration is provided. The effectiveness of the proposed approach is demonstrated with experiments on a publicly available dataset of complex motions.


Title: Deeply Informed Neural Sampling for Robot Motion Planning
Abstract: Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.


Title: Inverse Learning of Robot Behavior for Collaborative Planning
Abstract: Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.


Title: Integrating Path Planning and Pivoting
Abstract: In this work we propose a method for integrating motion planning and in-hand manipulation. Commonly addressed as a separate step from the final execution, in-hand manipulation allows the robot to reorient an object within the end-effector for the successful outcome of the goal task. A joint achievement of repositioning the object and moving the manipulator towards its desired final pose saves time in the execution and introduces more flexibility in the system. We address this problem using a pivoting strategy (i.e. in-hand rotation)for repositioning the object and we integrate this strategy with a path planner for the execution of a complex task. This method is applied on a Baxter robot and its efficacy is shown by experimental results.


Title: Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System
Abstract: The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.


Title: Contingent Contact-Based Motion Planning
Abstract: A robot with contact sensing capability can reduce uncertainty relative to the environment by deliberately moving into contact and matching the resulting contact measurement to different possible states in the world. We present a manipulation planner that finds and sequences these actions by reasoning explicitly about the uncertainty over the robot's state. The planner incrementally constructs a policy that covers all possible contact states during a manipulation and finds contingencies for each of them. In contrast to conformant planners (without contingencies), the planned contingent policies are more robust. We demonstrate this in simulated and real-world manipulation experiments. In contrast to POMDP-based planners, we show that our planner can be directly applied to high-dimensional configuration spaces.


Title: A Cable-Driven Redundant Spatial Manipulator with Improved Stiffness and Load Capacity
Abstract: With a light and slender body, a cable-driven redundant spatial manipulator (CRSM) has flexible manipulability and high maneuverability in confined environment. However, compared with revolute rigid manipulators, such type of manipulators generally has low stiffness and weak load capacity. In this paper, we propose a new mechanism design to improve the stiffness and load capacity without sacrificing the manipulator dexterity and the end-effector accuracy. The manipulator is composed of 3 active-passive-linkage segments and 1 active tool end-effector. Each active-passive segment has 2 degrees of freedom (DOFs) driven by three evenly distributed cables. Pretension mechanism and linkage cables are designed to keep strict equal angles of adjacent joints. A separable control box, which contains all the motors and cable transmission mechanisms is also designed with a quick release-and-lock mechanism. Therefore, the robotic arm can be easily removed and installed. Based on the equal angle characteristic, kinematic equations of manipulator are established with Denavit-Hartenberg (D-H) method and the Jacobian matrix is also simplified. Further analysis of the workspace supplies the guidance for the task design and motion planning. Finally, a prototype system is developed to perform the stiffness and load capacity experiments. Experimental results show that the developed CRSM has relatively high stiffness and load capacity.


Title: Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*
Abstract: This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.


Title: Assisted Telemanipulation: A Stack-Of-Tasks Approach to Remote Manipulator Control
Abstract: This article presents an approach for assisted teleoperation of a robot arm, formulated within a real-time stack-of-tasks (SoT)whole-body motion control framework. The approach leverages the hierarchical nature of the SoT framework to integrate operator commands with assistive tasks, such as joint limit and obstacle avoidance or automatic gripper alignment. Thereby some aspects of the teleoperation problem are delegated to the controller and carried out autonomously. The key contributions of this work are two-fold: the first is a method for unobtrusive integration of autonomy in a telemanip-ulation system; and the second is a user study evaluation of the proposed system in the context of teleoperated pick-and-place tasks. The proposed approach of assistive control was found to result in higher grasp success rates and shorter trajectories than achieved through manual control, without incurring additional cognitive load to the operator.


Title: Optimizing Sensor Placement: A Mixture Model Framework Using Stable Poses and Sparsely Precomputed Pose Uncertainty Predictions
Abstract: In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.


Title: Robust 6D Object Pose Estimation in Cluttered Scenes Using Semantic Segmentation and Pose Regression Networks
Abstract: Object pose estimation is a crucial prerequisite for robots to perform autonomous manipulation in clutter. Real-world bin-picking settings such as warehouses present additional challenges, e.g., new objects are added constantly. Most of the existing object pose estimation methods assume that 3D models of the objects is available beforehand. We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure. This work builds on previous work on semantic segmentation of cluttered bin-picking scenes to isolate individual objects in clutter. An additional network is trained on synthetic scenes to estimate object poses from a cropped object-centered encoding extracted from the segmentation results. The proposed method is evaluated on a synthetic validation dataset and cluttered realworld scenes.


Title: Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks
Abstract: Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.


Title: Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter
Abstract: Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.


Title: A Gripper for Object Search and Grasp Through Proximity Sensing
Abstract: Robots need to adapt themselves to various surroundings in order to achieve robust object search and grasp in unknown environments. For this adaptation, robot motions should be implemented as combination of primitive motions which are based on sensor reaction. Among various sensing methods, non contact sensing is required as a means of preventing operation failures such as pushing objects. Especially, proximity sensors have been proved effective in avoiding occlusion problems. In this paper, we first develop a gripper on which proximity sensors are mounted all around, and then calculate distance between the gripper and objects using proposed calibration method. This enables robots to recognize detailed shapes of objects surrounding the gripper. We also propose primitive motions for object search and grasp, and describe the contents of each motion. The motions are based on sensor information obtained from the gripper. We verify the effectiveness of our system through an experiment in which a real robot performs complex tasks by combination of the primitive motions.


Title: Exploring Vestibulo-Ocular Adaptation in a Closed-Loop Neuro-Robotic Experiment Using STDP. A Simulation Study
Abstract: Studying and understanding the computational primitives of our neural system requires for a diverse and complementary set of techniques. In this work, we use the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar adaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms located at the cerebellar molecular layer and the vestibular nuclei respectively. This simulation study adopts an experimental setup (rotatory VOR)widely used by neuroscientists to better understand the contribution of certain specific cerebellar properties (i.e. distributed STDP, neural properties, coding cerebellar topology, etc.)to r-VOR adaptation. The work proposes and describes an embodiment solution for which we endow a simulated humanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and we face the humanoid to an r-VOR task. The results validate the adaptive capabilities of the spiking cerebellar model (with STDP)in a perception-action closed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.


Title: Neurorobotic Approach to Study Huntington Disease Based on a Mouse Neuromusculoskeletal Model
Abstract: Motor functions of the biological system has been forged through 4 billion years evolution. From a neurorobotics view, it is important not only to know how well it works, but also how it fails. To quantitatively describe early onset symptoms of a neurodegenerative disease, we analyzed phenotypes of genetically engineered Huntington disease (HD) model mice, which reveal progressive impaired motor functions. We devised a simple yet sensitive paradigm called the crystalized motion profile (CMP), by which we successfully detected subtle difference between normal and abnormal mice in terms of whole-body level motor coordination. Our long-term objective is to remodel human mind and body to regain impaired motor and cognitive functions with ageing. To do so, we are developing a soft neurorobotic suit that provides integrated cognitive and physical interventions to users. Our analysis on the HD model mice is important as the first step to bridge between molecular mechanisms (altered genetic code) and the macroscopic neuro-musculoskeletal model. With this, we can extrapolate from knowledge of non-human mammals to human to derive the remodeling.


Title: Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks
Abstract: This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.


Title: Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles
Abstract: Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.


Title: Light-Weight Object Detection and Decision Making via Approximate Computing in Resource-Constrained Mobile Robots
Abstract: Most of the current solutions for autonomous flights in indoor environments rely on purely geometric maps (e.g., point clouds). There has been, however, a growing interest in supplementing such maps with semantic information (e.g., object detections) using computer vision algorithms. Unfortunately, there is a disconnect between the relatively heavy computational requirements of these computer vision solutions, and the limited computation capacity available on mobile autonomous platforms. In this paper, we propose to bridge this gap with a novel Markov Decision Process framework that adapts the parameters of the vision algorithms to the incoming video data rather than fixing them a priori. As a concrete example, we test our framework on a object detection and tracking task, showing significant benefits in terms of energy consumption without considerable loss in accuracy, using a combination of publicly available and novel datasets.


Title: The RobotriX: An Extremely Photorealistic and Very-Large-Scale Indoor Dataset of Sequences with Robot Trajectories and Interactions
Abstract: Enter the RobotriX, an extremely photorealistic indoor dataset designed to enable the application of deep learning techniques to a wide variety of robotic vision problems. The RobotriX consists of hyperrealistic indoor scenes which are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline using UnrealCV to generate raw data and ground truth labels. By taking this approach, we were able to generate a dataset of 38 semantic classes across 512 sequences totaling 8M stills recorded at +60 frames per second with full HD resolution. For each frame, RGB-D and 3D information is provided with full annotations in both spaces. Thanks to the high quality and quantity of both raw information and annotations, the RobotriX will serve as a new milestone for investigating 2D and 3D robotic vision tasks with large-scale data-driven techniques.


Title: Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information
Abstract: To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.


Title: Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization
Abstract: Camera relocalization plays a vital role in many robotics and computer vision applications, such as self-driving cars and virtual reality. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these point features are only sampled randomly in images, without considering geometric information such as lines, leading to large errors with the existence of poorly textured areas or in motion blur. Line segments are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.


Title: Hybrid Bayesian Eigenobjects: Combining Linear Subspace and Deep Network Methods for 3D Robot Vision
Abstract: We introduce Hybrid Bayesian Eigenobjects (HBEOs), a novel representation for 3D objects designed to allow a robot to jointly estimate the pose, class, and full 3D geometry of a novel object observed from a single viewpoint in a single practical framework. By combining both linear subspace methods and deep convolutional prediction, HBEOs efficiently learn nonlinear object representations without directly regressing into high-dimensional space. HBEOs also remove the onerous and generally impractical necessity of input data voxelization prior to inference. We experimentally evaluate the suitability of HBEOs to the challenging task of joint pose, class, and shape inference on novel objects and show that, compared to preceding work, HBEOs offer dramatically improved performance in all three tasks along with several orders of magnitude faster runtime performance.


Title: Active Object Perceiver: Recognition-Guided Policy Learning for Object Searching on Mobile Robots
Abstract: We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR)and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.


Title: A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control
Abstract: This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.


Title: Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks
Abstract: Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.


Title: Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction
Abstract: In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.


Title: Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring
Abstract: Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.


Title: Estimating an Articulated Tool's Kinematics via Visuo-Tactile Based Robotic Interactive Manipulation
Abstract: The usage of articulated tools for autonomous robots is still a challenging task. One of the difficulties is to automatically estimate the tool's kinematics model. This model cannot be obtained from a single passive observation, because some information, such as a rotation axis (hinge), can only be detected when the tool is being used. Inspired by a baby using its hands while playing with an articulated toy, we employ a dual arm robotic setup and propose an interactive manipulation strategy based on visual-tactile servoing to estimate the tool's kinematics model. In our proposed method, one hand is holding the tool's handle stably, and the other arm equipped with tactile finger flips the movable part of the articulated tool. An innovative visuo-tactile servoing controller is introduced to implement the flipping task by integrating the vision and tactile feedback in a compact control loop. In order to deal with the temporary invisibility of the movable part in camera, a data fusion method which integrates the visual measurement of the movable part and the fingertip's motion trajectory is used to optimally estimate the orientation of the tool's movable part. The important tool's kinematic parameters are estimated by geometric calculations while the movable part is flipped by the finger. We evaluate our method by flipping a pivoting cleaning head (flap) of a wiper and estimating the wiper's kinematic parameters. We demonstrate that the flap of the wiper is flipped robustly, even the flap is shortly invisible. The orientation of the flap is tracked well compared to the ground truth data. The kinematic parameters of the wiper are estimated correctly.


Title: Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels
Abstract: Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.


Title: ASPiC: An Acting System Based on Skill Petri Net Composition
Abstract: Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.


Title: Static Kinematics for an Antagonistically Actuated Robot Based on a Beam-Mechanics-Based Model
Abstract: Soft robotic structures might play a major role in the 4th industrial revolution. Researchers have successfully demonstrated advantages of soft robotics over traditional robots made of rigid links and joints in several application areas including manufacturing, healthcare and surgical interventions. However, soft robots have limited ability to exert higher forces when it comes to interaction with the environment, hence, change their stiffness on demand over a wide range. One stiffness mechanism embodies tendon-driven and pneumatic air actuation in an antagonistic way achieving variable stiffness values. In this paper, we apply a beam-mechanics-based model to this type of soft stiffness controllable robot. This mathematical model takes into account the various stiffness levels of the soft robotic manipulator as well as interaction forces with the environment at the tip of the manipulator. The analytical model is implemented into a robotic actuation system made of motorised linear rails with load cells (obtaining applied forces to the tendons) and a pressure regulator. Here, we present and analyse the performance and limitations of our model.


Title: Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration
Abstract: The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.


Title: On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints
Abstract: This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.


Title: Solving Markov Decision Processes with Reachability Characterization from Mean First Passage Times
Abstract: A new mechanism for efficiently solving the Markov decision processes (MDPs) is proposed in this paper. We introduce the notion of reachability landscape where we use the Mean First Passage Time (MFPT) as a means to characterize the reachability of every state in the state space. We show that such reachability characterization very well assesses the importance of states and thus provides a natural basis for effectively prioritizing states and approximating policies. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based Policy Iteration (MFPT-PI) - that have been modified from the state-of-the-art solution methods. To validate our design, we have performed numerical evaluations in robotic decision-making scenarios, by comparing the proposed new methods with corresponding classic baseline mechanisms. The evaluation results showed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art solutions in terms of both practical runtime and number of iterations. Aside from the advantage of fast convergence, this new solution method is intuitively easy to understand and practically simple to implement.


Title: Hybrid Bio-Inspired Architecture for Walking Robots Through Central Pattern Generators Using Open Source FPGAs
Abstract: In this paper we present a new robotic control approach inspired in the animal nervous system control. The system implements the binomial Brain-Peripheral Nervous System (CNS-PNS) combining the use of microprocessors as the high level control, or brain, and FPGAs as the low level control, or nervous system. Thanks to the new open source tools for FPGAs, we are able to apply them in the field of robotics in new ways that were impossible before. In this paper, we will demonstrate that our approach is not only able to control the movements of robots using digital circuits built inside an FPGA, but is also capable of generating, synthesizing and uploading them inside the FPGA in real time and on demand.


Title: Towards an Autonomous Robotic Dragonfly: At-Scale Lift Experiments Modeling Dragonfly Forewings
Abstract: We report on lift experiments conducted at scale for an artificial platform mimicking the dragonfly species: Sympetrum sanguineum. The platform, as well as the lift sensor, was custom designed and built. The flapping mechanism consisted of a piezoelectric bending-beam actuator, transmission using carbon-fiber elements and polymide-film joints, and wings constructed of polyester film with carbon-fiber support structure. The flapping kinematics of the Sympetrum san-guineum was replicated as closely as possible although only a pair of forewings were used in these experiments. The lift generated, when accounting for the addition of a pair of hindwings, is sufficient to allow for the hovering of a real-life dragonfly. The results, the first at-scale fully transient measurements of artificial dragonfly forewings, show that the lift curves quantitatively as well as qualitatively validate existing 2D and 3D computer simulations of dragonfly forewings.


Title: Ultrasonic and Electrostatic Self-Cleaning Microstructured Adhesives for Robotic Grippers
Abstract: This paper introduces electrostatic and ultrasonic techniques to clean dust and other contaminants from the surface of a gecko-like, microstrutured adhesive. The result is a non-destructive, non-contact cleaning method that will afford robotic grippers, climbing robots, and perching robots the ability to operate in real-world environments. Experimental results show that the cleaning efficiency for three different sizes of glass beads, 53-75 μm, 75-90 μm, and 90-106 μm, ranges between 75-99% when using a combination of electrostatic and ultrasonic cleaning. This is a far higher efficiency than when using electrostatic repulsion alone. Experiments also demonstrate an approximately 33% recovery in shear stress on a flat glass for a contaminated directional gecko-like adhesive after contact with a dusty table when electrostatic/ultrasonic cleaning was used. Finally, by applying this method on a robotic gripper, we observed an 18% recovery in normal adhesion on a flat glass substrate.


Title: Evolving a Sensory-Motor Interconnection for Dynamic Quadruped Robot Locomotion Behavior
Abstract: In this paper, we present a novel biologically inspired evolving neural oscillator for quadruped robot locomotion to minimize constraints during the locomotion process. The proposed sensory-motor coordination model is formed by the interconnection between motor and sensory neurons. The model utilizes Bacterial Programming to reconstruct the number of joints and neurons in each joint based on environmental conditions. Bacterial Programming is inspired by the evolutionary process of bacteria that includes bacterial mutation and gene transfer process. In this system, either the number of joints, the number of neurons, or the interconnection structure are changing dynamically depending on the sensory information from sensors equipped on the robot. The proposed model is simulated in computer for realizing the optimization process and the optimized structure is then applied to a real quadruped robot for locomotion process. The optimizing process is based on tree structure optimization to simplify the sensory-motor interconnection structure. The proposed model was validated by series of real robot experiments in different environmental conditions.


Title: Improving the Parallel Execution of Behavior Trees
Abstract: Behavior Trees (BTs) have become a popular framework for designing controllers of autonomous agents in the computer game and in the robotics industry. One of the key advantages of BTs lies in their modularity, where independent modules can be composed to create more complex ones. In the classical formulation of BTs, modules can be composed using one of the three operators: Sequence, Fallback, and Parallel. The Parallel operator is rarely used despite its strong potential against other control architectures such as Finite State Machines. This is due to the fact that concurrent actions may lead to unexpected problems similar to the ones experienced in concurrent programming. In this paper, we outline how to tackle the aforementioned problem by introducing Concurrent BTs (CBTs) as a generalization of BTs in which we include the notions of progress and resource usage. We show how CBTs allow safe concurrent executions of actions and we analyze the approach from a mathematical standpoint. To illustrate the use of CBTs, we provide a set of use cases in realistic robotics scenarios.


Title: Guess What I Attend: Interface-Free Object Selection Using Brain Signals
Abstract: Interpreting the brain activity to identify user goals or to ground a robot's hypotheses about them is a promising direction for non-intrusive and intuitive communication. Such a capability can be of particular relevance in the context of human-robot cooperation scenarios. This paper proposes a novel approach to utilize the natural brain responses to highlighted objects in the scene for object selection. By this, it circumvents the need for additional interfaces or user training. Our approach uses methods from information geometry to classify the target/non-target response of these event-related potentials. Online experiments carried out with a real robot demonstrate an accurate detection of target objects solely based on the user's attention.


Title: Mobile Continuum Robot with Unlimited Extensible Sections
Abstract: Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.


Title: Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World
Abstract: Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.


Title: Bimanual Assembly of Two Parts with Relative Motion Generation and Task Related Optimization
Abstract: Bimanual assembly of two parts require that a relative target pose is reached prior to the joining operation. Rather than utilizing one arm as a fixture for holding one of the parts while the other performs the assembly, motion generation in the relative end-effector frame is proposed that involves both arms. The proposed approach considers bimanual motion in a dynamic and uncertain environment addressing avoidance of collision with obstacles as well as the robot itself and the environment. Moreover, configurations that optimize the motion and force capabilities for the sucessful and efficient completion of the task are taken into account. A task priority strategy is adopted achieving online performance. Experimental results on the YuMi bimanual robot using the Stack-Of- Tasks hierarchical solver validate the performance of the proposed approach in a folding assembly task.


Title: Dual-Arm Coordinated Motion Planning and Compliance Control for Capturing Moving Objects with Large Momentum
Abstract: Capturing a moving object with large momentum by a dual-arm robot is especially challenging because of the requirement of dual-arm coordinated motion planning for tracking the moving object, and the operational force control for contact and momentum transfer. In this paper, we present a dual-arm coordinated motion planning and compliance control method with a unique null-space projected relative Jacobian and relative operational force between the two arms. The proposed method is able to plan dual-arm capturing motion and control the capturing force without disturbing the tracking motion. We have also adopted a direct collocation trajectory optimization method to generate optimal trajectory to decrease the object's momentum with minimum effort. Simulation and experiment of dual-arm robots picking up a moving box on a mobile platform are carried out to verify the proposed method.


Title: A Model Predictive Control Approach for Vision-Based Object Grasping via Mobile Manipulator
Abstract: This paper presents the design of a vision-based object grasping and motion control architecture for a mobile manipulator system. The optimal grasping areas of the object are estimated using the partial point cloud acquired from an onboard RGB-D sensor system. The reach-to-grasp motion of the mobile manipulator is handled via a Nonlinear Model Predictive Control scheme. The controller is formulated accordingly in order to allow the system to operate in a constrained workspace with static obstacles. The goal of the proposed scheme is to guide the robot's end-effector towards the optimal grasping regions with guaranteed input and state constraints such as occlusion and obstacle avoidance, workspace boundaries and field of view constraints. The performance of the proposed strategy is experimentally verified using an 8 Degrees of Freedom KUKA Youbot in different reach-to-grasp scenarios.


Title: A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
Abstract: This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.


Title: Coupling Mobile Base and End-Effector Motion in Task Space
Abstract: Dynamic systems are a practical alternative to motion planning in executing robot actions. They are of particular interest in Learning from Demonstration, as here we aim to carry out actions in a certain fashion, without a model or in-depth knowledge about the world, which might be difficult to achieve with a planner. Using model-based dynamic systems in task space enables robots to flexibly reproduce demonstrated actions. Nevertheless, when dealing with mobile manipulators, we face the challenge of including the kinematic constraints of the robot in the action models. In this paper we propose to couple robot base and end-effector motions generated by arbitrary dynamical systems modulating the base velocity, while respecting the robots kinematic design. To this end we learn an approximation of the inverse reachability in closed form. In real-world robot experiments we demonstrate that we are able to maintain kinematically feasible trajectories in the presence of obstacles and in configurations differing profoundly from the training scene.


Title: Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot
Abstract: One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.


Title: Capacitive Proximity Sensor Skin for Contactless Material Detection
Abstract: In this paper, we present a method for contactless material detection with capacitive proximity sensing skins. Our new approach extends the current state-of-the-art proximity and distance sensing methods and measures the characteristic impedance spectrum of an object to obtain material properties. By this, we gain further material information besides of the near field information in a contactless and non-destructive way. The measurement method requires sensors that provide absolute distance and frequency based capacitance measurement capabilities and can be applied to similar systems. The sensor system described in this paper measures proximity with a capacitance based sensor and absolute distance based on time-of-flight (ToF)sensors. Attached on a robot, we gain information about the robot's near field environment. The information is important not only for human- machine- interaction, but also for grasping and manipulation. We focus on signal processing and evaluate our method with measurements of numerous different materials and present a solution to differentiate between them.


Title: Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality
Abstract: We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.


Title: Efficient Pose Estimation from Single RGB-D Image via Hough Forest with Auto-Context
Abstract: We propose a high efficient learning approach to estimating 6D (Degree of Freedom) pose of the textured or texture-less objects for grasping purposes in a cluttered environment where the objects might be partially occluded. The method comprises three main steps. Given a single RGB-D image, we first deploy appropriate features and the random forest to deduce the object class probability and cast votes for the 6D pose in Hough space by joint regression and classification framework, adopting reservoir sampling and summarizing the pose distribution by clustering. Next, we integrate the auto-context into cascaded Hough forests to improve the efficiency of learning. Extensive experiments on various public datasets and robotic grasps indicate that our method presents some improvements over the state-of-art and reveals the capability for estimating poses in practical applications efficiently.


Title: Plenoptic Monte Carlo Object Localization for Robot Grasping Under Layered Translucency
Abstract: In order to fully function in human environments, robot perception needs to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL)as a method for localizing object poses in the presence of translucency using plenoptic (light-field)observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.


Title: Pose Estimation for Objects with Rotational Symmetry
Abstract: Pose estimation is a widely explored problem, enabling many robotic tasks such as grasping and manipulation. In this paper, we tackle the problem of pose estimation for objects that exhibit rotational symmetry, which are common in man-made and industrial environments. In particular, our aim is to infer poses for objects not seen at training time, but for which their 3D CAD models are available at test time. Previous work has tackled this problem by learning to compare captured views of real objects with the rendered views of their 3D CAD models, by embedding them in a joint latent space using neural networks. We show that sidestepping the issue of symmetry in this scenario during training leads to poor performance at test time. We propose a model that reasons about rotational symmetry during training by having access to only a small set of symmetry-labeled objects, whereby exploiting a large collection of unlabeled CAD models. We demonstrate that our approach significantly outperforms a naively trained neural network on a new pose dataset containing images of tools and hardware.


Title: Fully Convolutional Grasp Detection Network with Oriented Anchor Box
Abstract: In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.


Title: A Probabilistic Approach to Benchmarking and Performance Evaluation of Robot Systems
Abstract: Problem benchmarks are used in experimental science as a reference against which results of experiments using distinct approaches to solve the problem are compared and evaluated in relative terms. In Robotics, just formulating a general performance assessment problem is difficult per se, as robot systems are composed of very diverse subsystems (e.g., localisation, human-robot interaction, task planning, motion planning). This paper introduces a probabilistic approach to benchmarking and evaluating performance of robot systems, which uses probability theory as the common language to quantify the performance of distinct functionalities of a robot system and their impact on the performance of a task carried out by that system. The approach can be used to analyse the performance of a task plan from the performances if its composing functionalities, or to (re)plan when a performance degradation in functionality is predicted to cause performance degradation of the task plan beyond acceptable limits.


Title: Improving Repeatability of Experiments by Automatic Evaluation of SLAM Algorithms
Abstract: The development of good experimental methodologies for robotics takes often inspiration from general principles of experimental practice. Repeatability prescribes that experiments should involve several trials in order to guarantee that results are not achieved by chance, but are systematic, and statistically significant trends can be identified. In this paper, we propose an approach to improve the repeatability of experiments performed in robotics. In particular, we focus on the domain of SLAM (Simultaneous Localization And Mapping) and we introduce a system that exploits simulations to generate a large number of test data on which SLAM algorithms are automatically evaluated in order to obtain consistent results, according to the principle of repeatability.


Title: Fast Convergence for Object Detection by Learning how to Combine Error Functions
Abstract: In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.


Title: Towards Real-Time Physical Human-Robot Interaction Using Skeleton Information and Hand Gestures
Abstract: For successful physical human-robot interaction, the capability of a robot to understand its environment is imperative. More importantly, the robot should extract from the human operator as much information as possible. A reliable 3D skeleton extraction is essential for a robot to predict the intentions of the operator while s/he moves toward the robot or performs a meaningful gesture. For this purpose, we have integrated a time-of-flight depth camera with a state-of-the-art 2D skeleton extraction library namely Openpose, to obtain 3D skeletal joint coordinates reliably. We have also developed a robust and rotation invariant (in the coronal plane)hand gesture detector using a convolutional neural network. At run time (after having been trained)the detector does not require any pre-processing of the hand images. A complete pipeline for skeleton extraction and hand gesture recognition is developed and employed for real-time physical human-robot interaction, demonstrating the promising capability of the designed framework. This work establishes a firm basis and will be extended for the development of intelligent human intention detection in physical human-robot interaction scenarios, to efficiently recognize a variety of static as well as dynamic gestures.


Title: Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding
Abstract: In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds. Our edge detection method evaluates symmetry in a local neighborhood and uses an adaptive density based threshold to differentiate 3D edge points. We extend this algorithm to propose a novel corner detector that clusters curvature vectors and uses their geometrical statistics to classify a point as corner. We perform rigorous evaluation of the algorithms on RGB-D semantic segmentation and 3D washer models from the ShapeNet dataset and report higher precision and recall scores. Finally, we also demonstrate how our edge and corner detectors can be used as a novel approach towards automatic weld seam detection for robotic welding. We propose to generate weld seams directly from a point cloud as opposed to using 3D models for offline planning of welding paths. For this application, we show a comparison between Harris 3D and our proposed approach on a panel workpiece.


Title: Guaranteed Coverage with a Blind Unreliable Robot
Abstract: We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach.


Title: Single Leg Dynamic Motion Planning with Mixed-Integer Convex Optimization
Abstract: This paper proposes a mixed-integer convex programming formulation for dynamic motion planning. Many dynamic constraints such as the actuator torque constraint are nonlinear and non-convex due to the trigonometrical terms from the Jacobian matrix. This often causes the optimization problem to converge to local optima or even infeasible set. In this paper, we convexify the torque constraint by formulating a mixed-integer quadratically-constrained program (MIQCP). More specifically, the workspace is discretized into a union of disjoint polytopes and torque constraint is enforced upon a convex outer approximation of the torque ellipsoid, obtained by solving a semidefinite program (SDP). Bilinear terms are approximated by McCormick envelope convex relaxation. The proposed MIQCP framework could be solved efficiently to global optimum and the generated trajectories could exploit the rich features of the rough terrain without any initial guess from the designer. The demonstrated experiment results prove that this approach is currently capable of planning consecutive jumps that navigates a single-legged robot through challenging terrains.


Title: Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty
Abstract: In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.


Title: Efficient and Asymptotically Optimal Kinodynamic Motion Planning via Dominance-Informed Regions
Abstract: Motion planners have been recently developed that provide path quality guarantees for robots with dynamics. This work aims to improve upon their efficiency, while maintaining their properties. Inspired by informed search principles, one objective is to use heuristics. Nevertheless, comprehensive and fast spatial exploration of the state space is still important in robotics. For this reason, this work introduces Dominance-Informed Regions (DIR), which express both whether parts of the space are unexplored and whether they lies along a high quality path. Furthermore, to speed up the generation of a successful successor state, which involves collision checking or physics-based simulation, a proposed strategy generates the most promising successor in an informed way, while maintaing properties. Overall, this paper introduces a new informed and asymptotically optimal kinodynamic motion planner, the Dominance-Informed Region Tree (DIRT). The method balances exploration-exploitation tradeoffs without many explicit parameters. It is shown to outperform sampling-based and search-based methods for robots to significant dynamics.


Title: High-Speed and Intelligent Pre-Grasp Motion by a Robotic Hand Equipped with Hierarchical Proximity Sensors
Abstract: Quickness, preciseness and robustness are required in manipulation tasks of robotic hands for automation of manufacturing sites. Previous researches have found that sensing from fingertips equipped with proximity sensors is available for the requirements, because it complements blind areas of vision sensors. In this paper, we develop a novel optical proximity sensor for robot fingertips which provides two levels of proximity information with different purposes, sampling rates, information quantity and quality. The lower-level information from the sensor is for high-speed feedback control of a robotic hand, and the higher-level information is for recognizing the shape and size of an object. A prototype of the sensor with 5 × 5 matrix of photo detectors is presented, and its availability is shown through basic characteristic tests. A motion experiment using a robotic hand equipped with the prototype sensors is also conducted. The result confirms that the robotic hand can adjust the position and orientation of the fingertips to various objects and then correct the grasping form according to the object size within 1s.


Title: Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control
Abstract: This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.


Title: Optimal Input Waveform for an Indirectly Controlled Limit Cycle Walker
Abstract: Precisely manipulating the center of mass (CoM) of the underactuated locomotion robot can't be easily achieved by common control mechanisms which apply only joint torques. A novel and indirect method has been recently introduced using an active wobbling mass attached to limit cycle walkers. The next important issue is to design an optimal control input to reduce the forcing energy. In this paper, we use combined rimless wheels as a simplified example to apply our method, which is based on the theory of phase oscillators. First, we introduce the typical modeling and control of this underactuated robot. Second, we obtain the phase response curve by numerically applying perturbations at different phases of the walker's gait interval and calculating the deviations from the unperturbed. Third, we analytically derive an optimal forcing waveform for the wobbling mass to entrain the combined rimless wheel based on the phase response curve. As an ecological extension, an ideal forcing waveform for m: 1 entrainment was further generated. Finally, the proposed method was evaluated by locking range of the Arnold tongues. The results show that the optimal forcing waveform we derived achieves the best performance for 1:1 entrainment among all the candidates. One of the strongest advantages of our method is the easiness of its implementation, prompting its applicability to a wide variety of locomotion systems.


Title: Robust Humanoid Control Using a QP Solver with Integral Gains
Abstract: We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.


Title: Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence
Abstract: Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.


Title: A Biomimetic Soft Robot for Inspecting Pipeline with Significant Diameter Variation
Abstract: Navigation through tubular environment is fundamental in tasks such as pipeline inspection, gastrointestinal tract inspection, etc. Conventional pipeline inspection robots are mostly made by rigid materials and could not well adapt to the large size variation of the environment. Soft robots provide an additional solution for inspection of pipelines, especially with significant size variation. In this work, we present a soft robot for pipeline inspection, which consists of an earthworm-like soft robot and a Central Pattern Generator (CPG)-based control system. An analytical model is developed to predict the maximum pipe diameter that the robot could adapt to. For the current prototype, the robot could adapt to size change of three times. Experimental results show that this robot could navigate through pipelines with sharp turnings and with large diameter change.


Title: Continuum Manipulator with Redundant Backbones and Constrained Bending Curvature for Continuously Variable Stiffness
Abstract: Snake-like manipulators can navigate and perform manipulation in confined spaces. Their recent implementations in surgical robots attracted a lot of attentions. These slender manipulators usually possess either a hyper-redundant articulated vertebrate structure or a continuum one. Primary design considerations usually converge to a balance between proper workspace and acceptable stiffness. Efforts have hence been constantly made to achieve higher or adjustable stiffness for a manipulator to widen its applications. This paper presents a simple continuum manipulator design with variable stiffness based on redundantly arranged elastic backbones and continuously constrained bending curvature. The design concepts, kinematics, a preliminary formulation for stiffness adjustment, system construction and experimental characterizations are elaborated. The results showed that the manipulator's stiffness can be increased up to 4.71 times of the value without the curvature constraining rod, indicating the efficacy of the proposed idea.


Title: A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots
Abstract: This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.


Title: A Compact Wheeled Robot that Can Jump while Rolling
Abstract: In this paper, we study a compact wheeled robot that can jump while rolling. Some robots are capable of jumping or rolling, but as far as we know, those robots are not focused on jumping while rolling. We know that animals jump while running to escape from predators. Robots can move quickly by jumping while rolling. We consider a model of a robot jumping while rolling and evaluate the proposed robot. The proposed robot has two wheels and a jumping mechanism based on snap-through buckling of an elastic strip. The proposed robot can jump about 5.9 cm high and 22 cm wide on average while maintaining a traveling speed of about 1.2 m/s. The proposed robot can change the jumping angle without greatly decreasing the impulse for the moving speed.


Title: Soft LEGO: Bottom-Up Design Platform for Soft Robotics
Abstract: This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.


Title: Soft Snake Robots: Investigating the Effects of Gait Parameters on Locomotion in Complex Terrains
Abstract: Compliant materials used to create soft robots can better replicate biological structures than typical rigid materials. We can look to nature for developing locomotion strategies for these soft-bodied robots. In this work, snakes were used as inspiration to create an inextensible, soft robot which was used as a platform to test gaits in terrain composed of granular media ranging from fine sand to stone. Snakes vary the speed and amplitude of the traveling wave used in lateral undulation to navigate different environments. We used these gait parameters to develop and test a set of custom gaits that varied the phase offset of the sequence of waves as well as using the best performing gait to test how the amplitude of the wave effects locomotion over the selected terrains. These tests provide preliminary evidence that altering these parameters effects the robot's ability to traverse different terrains. The developed robot is also tested in environments specific to applications for snake robots to show how a soft snake robot can be potentially more effective in these environment. The highest performing gait-curvature combination was the half-activation gait (where the back actuator was activated half as long as the front)with a 135° swept angle. It reached a velocity of 2.2 mm/s or 0.011 body-lengths/s on paper, which was the best performing terrain.


Title: Inverse Error Function Trajectories for Image Reconstruction*This material is based upon work supported by the National Science Foundation under Grant No. 1662029
Abstract: Capturing clear images while a camera is moving fast, is integral to the development of mobile robots that can respond quickly and effectively to visual stimuli. This paper proposes to generate camera trajectories, with position and time constraints, that result in higher reconstructed image quality. The degradation in of an image captured during motion is known as motion blur. Three main methods exist for mitigating the effects of motion blur: (i) controlling optical parameters, (ii) controlling camera motion, and (iii) image reconstruction. Given control of a camera's motion, trajectories can be generated that result in an expected blur kernel or point-spread function. This work compares the motion blur effects and reconstructed image quality of three trajectories: (i) linear, (ii) polynomial, and (iii) inverse error. Where inverse error trajectories result in Gaussian blur kernels. Residence time analysis provides a basis for characterizing the motion blur effects of the trajectories.


Title: Faster Collision Checks for Car-Like Robot Motion Planning
Abstract: In this paper, we describe how collision checking for car-like robots can be sped up utilizing system knowledge. Their non-holonomic motion, while being a challenge for motion planning, is utilized here to place discs which are used as an approximation of the robot's shape in a predictive manner. For ease of comparison, we assume the robot to be rectangular, i. e., we use bounding boxes. Our algorithm is compared to a widely-used baseline and shows similar performance in terms of under- and oversampling while being approximately 20-40 % faster. Another feature of the algorithm is its predictive nature: with the frontal disc, we already check for collisions that would occur with the rear disc in the next sample, assuming near-constant curvature. While this might be conservative in some cases where large steering rates are necessary, in our evaluation even tight corridors could be navigated without negative effects.


Title: Skating with a Force Controlled Quadrupedal Robot
Abstract: Traditional legged robots are capable of traversing challenging terrain, but lack of energy efficiency when compared to wheeled systems operating on flat environments. The combination of both locomotion domains overcomes the trade-off between mobility and efficiency. Therefore, this paper presents a novel motion planner and controller which together enable a legged robot equipped with skates to perform skating maneuvers. These are achieved by an appropriate combination of planned reaction forces and gliding motions. Our novel motion controller formulates a Virtual Model Controller and an optimal contact force distribution which takes into account the nonholonomic constraints introduced by the skates. This approach has been tested on the torque-controllable robot ANY mal equipped with passive wheels and ice skates as end-effectors. We conducted experiments on flat and inclined terrain, whereby we show that skating motions reduces the cost of transport by up to 80 % with respect to traditional walking gaits.


Title: A Comparative Analysis of Contact Models in Trajectory Optimization for Manipulation*
Abstract: In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We consider three different approaches: (1)a contact model that is based on complementarity constraints, (2)a smooth contact model, and our proposed method (3) a variable smooth contact model. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time. In each case, the optimization process is initialized by setting all torque variables to zero, namely, without a meaningful initial guess. For simulations, we consider a pushing task with varying complexity for a 7 degrees-of-freedom robot arm. Our results demonstrate that the optimization based on the proposed variable smooth contact model provides a good trade-off between the physical fidelity and quality of motions at the cost of increased computation time.


Title: Combining Method of Alternating Projections and Augmented Lagrangian for Task Constrained Trajectory Optimization
Abstract: Motion planning for manipulators under task space constraints is difficult as it constrains the joint configurations to always lie on an implicitly defined manifold. It is possible to view task constrained motion planning as an optimization problem with non-linear equality constraints, which can be solved by general non-linear optimization techniques. In this paper, we present a novel custom optimizer which exploits the underlying structure present in many task constraints. At the core of our approach are some simple reformulations, which when coupled with the method of alternating projection, leads to an efficient convex optimization based routine for computing a feasible solution to the task constraints. We subsequently build on this result and use the concept of Augmented Lagrangian to guide the feasible solutions towards those that also minimize the user defined cost function. We show that the proposed optimizer is fully distributive and thus, can be easily parallelized. We validate our formulation on some common robotic benchmark problems. In particular, we show that the proposed optimizer achieves cyclic motion in the joint space corresponding to a similar nature trajectory in the task space. Furthermore, as a baseline, we compare the proposed optimizer with an off-the-shelf non-linear solver provide in open source package SciPy. We show that for similar task constraint residuals and smoothness cost, it can be upto more than three times faster than the SciPy alternative.


Title: A Software Framework for Planning Under Partial Observability
Abstract: Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.


Title: Adaptive Path Following of Snake Robot on Ground with Unknown and Varied Friction Coefficients
Abstract: This paper investigates the straight path following problem for a class of underactuated bio-inspired snake robots on ground with unknown and varied friction coefficients. Existing works usually design control input requiring the exact values of these friction coefficients, which however rely on the specific operating terrain and may not always be known a priori. By virtue of backstepping technique, we present a novel adaptive controller that can compensate for unknown and varied friction coefficients in real-time. Moreover, it is proved via LaSalle-Yoshizawa theorem that the path following errors converge to zero asymptotically and all the parameter estimates are bounded. Simulations and experiments on an 8-link snake robot are carried out to illustrate the effectiveness of the proposed controller.


Title: Analytical Model of Thermal Soaring: Towards Energy Efficient Path Planning for Flying Robots
Abstract: Developing analytical models of efficient locomotion in biology is one of the most interesting goals in bio- inspired robotics. This paper presents a mathematical framework in order to model one of the most energy efficient locomotion types in flying animals; i.e., thermal soaring. Unlike the legged locomotion, in flying, modeling the environmental effects on animals' behaviors is very important. In doing so, we develop our model by assuming thermals as bubbles of rising air. According to pieces of real evidence, this kind of modeling is more compatible with the nature of thermal soaring. Moreover, we present a simple hybrid control strategy for obtaining the optimal path in order to maximize benefit from the updraft of air-flow. By using this control strategy, the flying robot can plan a path for traveling between thermals without flapping; i.e., energy efficient flying. So as to investigate the compatibility of presented model and controller with reality, we set their parameters based on the biological evidences. As a result, in simulations, it is observed that the generated flying behavior is comparable with the thermal soaring behavior of real birds. This observation provides a confirmation for generality and applicability of the presented approach.


Title: Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).
Abstract: Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.


Title: PiRat: An Autonomous Framework for Studying Social Behaviour in Rats and Robots
Abstract: The use of robots, as a social stimulus, provides several advantages over using another animal. In particular, for rat-robot studies, robots can produce social behaviour that is reproducible across trials. In the current work, we outline a framework for rat-robot interaction studies, that consists of a novel rat-sized robot (PiRat), models of robotic behavior, and a position tracking system for both robot and rat. We present the design of the framework, including constraints on autonomy, latency, and control. We pilot tested our framework by individually running the robot rat with eight different rats, first through a habituation stage, and then with PiRat performing two different types of behaviour - avoiding and frequently approaching. We evaluate the performance of the framework on latency and autonomy, and on the ability to influence the behaviour of individual rats. We find that the framework performs well on its constraints, engages some of the rats (according to the number of meetings), and features a control scheme that produces reproducible behaviour in rats. These features represent a first demonstration of a closed-loop rat-robot framework.


Title: Tarzan: Design, Prototyping, and Testing of a Wire-Borne Brachiating Robot
Abstract: A novel brachiating robot design is presented for the purpose of traversing elevated wire networks. The robot is capable of moving along a single wire and between parallel wires, thereby enabling traversal of a two-dimensional space. Several novel features distinguish this design compared to previous brachiating robots. These include the ability to transition to and from both “rope” and “ladder” brachiation modes through an integrated wrist, a locking hand design for minimal power consumption, and distributed electronics packages that communicate wirelessly. A payload mounting point is installed, offering space for a variety of remote sensing packages. Experimental results using a prototype robot demonstrate that the system can reliably brachiate along a single wire, and can also reliably perform a swing-up maneuver after failed swing attempts or when transitioning between the rope and ladder locomotion modes. Energy expenditure for a single swing is quantified using experimental data. Overall, the proposed robot design is shown to provide a promising platform for traversal of wire networks in two dimensions.


Title: Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots
Abstract: Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.


Title: TacWhiskers: Biomimetic Optical Tactile Whiskered Robots
Abstract: Here we propose and investigate a novel vibrissal tactile sensor - the Tac Whisker array - based on modifying a 3D-printed optical cutaneous (fingertip) tactile sensor - the TacTip. Two versions are considered: a static Tac Whisker array analogous to immotile tactile vibrissae (e.g. rodent microvib-rissae) and a dynamic Tac Whisker array analogous to motile tactile vibrissae (e.g. rodent macrovibrissae). Performance is assessed on an active object localization task. The whisking motion of the dynamic Tac Whisker leads to millimetre-scale location perception, whereas perception with the static Tac Whisker array is relatively poor when making dabbing contacts. The dynamic sensor output is dominated by a self-generated motion signal, which can be compensated by comparing to a reference signal. Overall, the Tac Whisker arrays give a new class of tactile whiskered robots that benefit from being relatively inexpensive and customizable. Furthermore, the biomimetic basis for the Tac Whiskers fits well with building an embodied model of the rodent sensory system for investigating animal perception.


Title: Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot
Abstract: Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.


Title: An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory
Abstract: To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.


Title: Dynamic Dumbbell - Novel Muscle Training Robot with Programmable Exercise Load
Abstract: In this paper, Dynamic Dumbbell, a novel robotic device for advanced muscular exercise of upper limb is presented. The type of exercise load is classified and designed in terms of mechanical engineering to be implemented in Dynamic Dumbbell. The exercise load model, which is named as programmable exercise load, is realized by Dynamic Dumbbell. To generate the programmable exercise load, two of compact Planetary-geared Elastic Actuator, which is a rotary Series Elastic Actuator (SEA), are utilized in Dynamic Dumbbell. The SEAs are controlled using high performance force control algorithm. Experimental results verifies the effectiveness of the proposed Dynamic Dumbbell and programmable exercise load.


Title: Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People
Abstract: In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.


Title: Estimating Door Shape and Manipulation Model for Daily Assistive Robots Based on the Integration of Visual and Touch Information
Abstract: We propose a method for a robot to manipulate an unknown door based on a single user instruction. The primary contributions of this paper are (i) to reduce the user instruction to a single click and (ii) to develop an efficient method to estimate an appropriate shape and manipulation model for a target door by integrating visual and touch information obtained by a robot. The proposed method first detects door candidates using a 3-D camera and then estimates the manipulation model of each candidate based on prior learning results. During door manipulation, the system integrates visual and touch information to estimate the shape and manipulation model to generate an appropriate motion. We evaluated the proposed method experimentally, and the results prove that the proposed method is effective.


Title: Designing for Robust Movement in a Child-Friendly Robot
Abstract: Motion is a critical aspect of communication, required to create natural interactions between humans and robots. Robots for the classroom pose several constraints on motion, which make them challenging to design, including maintaining the safety of the child and the robot, responding in a timely fashion, and creating motions that are expressive and not scary. In this paper we present the mechanical design of a social robot and demonstrate that it is capable of safe motion within the proximity of children through analysis and empirical testing of the arms. The robot has a novel mechanical design for its two arms, which include torso-mounted, back-drivable, torque-limited stepper motors. The results suggest that our design succeeds at increasing safety levels while enabling the use of socially acceptable speeds of motion during the interaction. This study implies that the design of robotic agents for social interaction with children should consider the design of mechanical features that enable safe contact between the human and the robot while not limiting the robot to slow motions that would impair the timing of the interaction.


Title: Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test
Abstract: There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.


Title: Robot Artist Performs Cartoon Style Facial Portrait Painting
Abstract: This paper presents a face portrait with cartoon stylization painting and associated algorithms with the visual feedback system to paint like a human cartoonist. The robot cartoonist creates the artwork in two stages-cartoon style transformation and robot artist for colorful painting. In the cartoon style transformation stage, it transfers human portrait photos to cartoon style by face detection and alignment, which can effectively decompose the face into individual components then replace by cartoon facial components. In the second stage, the robot uses an eye-in-hand system to obtain five basic colors (cyan, magenta, yellow, white and black) to automatically mix a variety of colors automatically. For painting strategy, we start with the outline of the face, which we use non-photorealistic rendering (NPR) to generate hand-painted strokes. After that, the robot artist will implement painting the facial features. We also demonstrate the success of this proposed research.


Title: Robust Plant Phenotyping via Model-Based Optimization
Abstract: Plant phenotyping is the measurement of observable plant traits. Current methods for phenotyping in the field are labour intensive and error prone. High throughput plant phenotyping in an automated and noninvasive manner is crucial to accelerating plant breeding methods. Occlusions and non-ideal sensing conditions is a major problem for high throughput plant phenotyping with most state-of-the-art 3D phenotyping algorithms relying heavily on heuristics or hand-tuned parameters. To address this problem, we present a novel model-based optimization approach for estimating plant physical traits from plant units called phytomers. The proposed approach involves sampling parameterized 3D plant models from an underlying probability distribution. It then optimizes, making the mass of this probability distribution approach true parameters of the model. Reformulating the phenotyping objective as a search in the space of plant models lets us reason about the plant structure in a holistic manner without having to rely on hand-tuned parameters. This makes our approach robust to noise and occlusions as frequently encountered in real world environments. We evaluate our approach for plant units taken across simulated, greenhouse and field environments. This work furthers field-based robotic phenotyping capabilities paving the way for plant biologists to study the coupled effect of genetics and environment on improving crop yields.


Title: Design of an Autonomous Precision Pollination Robot
Abstract: Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named “BrambleBee”, which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.


Title: Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture
Abstract: Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.


Title: Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.
Abstract: The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.


Title: UNDERWORLDS: Cascading Situation Assessment for Robots
Abstract: We introduce UNDERWORLDS, a novel lightweight framework for cascading spatio-temporal situation assessment in robotics. UNDERWORLDS allows programmers to represent the robot's environment as real-time distributed data structures, containing both scene graphs (for representation of 3D geometries) and timelines (for representation of temporal events). UNDERWORLDS supports cascading representations: the environment is viewed as a set of worlds that can each have different spatial and temporal granularities, and may inherit from each other. UNDERWORLDS also provides a set of high-level client libraries and tools to introspect and manipulate the environment models. This article presents the design and architecture of this open-source tool, and explores some applications, along with examples of use.


Title: OpenSeqSLAM2.0: An Open Source Toolbox for Visual Place Recognition Under Changing Conditions
Abstract: Visually recognising a traversed route - regardless of whether seen during the day or night, in clear or inclement conditions, or in summer or winter - is an important capability for navigating robots. Since SeqSLAM was introduced in 2012, a large body of work has followed exploring how robotic systems can use the algorithm to meet the challenges posed by navigation in changing environmental conditions. The following paper describes OpenSeqSLAM2.0, a fully open-source toolbox for visual place recognition under changing conditions. Beyond the benefits of open access to the source code, OpenSeqSLAM2.0 provides a number of tools to facilitate exploration of the visual place recognition problem and interactive parameter tuning. Using the new open source platform, it is shown for the first time how comprehensive parameter characterisations provide new insights into many of the system components previously presented in ad hoc ways and provide users with a guide to what system component options should be used under what circumstances and why.


Title: HERO: Accelerating Autonomous Robotic Tasks with FPGA
Abstract: The Heterogeneous Extensible Robot Open (HERO) platform is designed for autonomous robotic research. While bringing in the flexible computational capacities by CPU and FPGA, it addresses the challenges of heterogeneous computing by embracing OpenCL programming. We propose heterogeneous computing approaches for three fundamental robotic tasks: simultaneous localization and mapping (SLAM), motion planning and convolutional neural network (CNN) inference. With FPGA acceleration, the SLAM and motion planning tasks are performed 2-4 times faster on the HERO platform against fine-tuned software implementation. For CNN inference, it can process 20-30 images per second with the network of VGG-16 or ResNet-50. We expect the open platform and the developing experiences shared in this paper can facilitate future robotic research, especially for those compute intensive tasks of perception, movement and manipulation.


Title: Procedurally Provisioned Access Control for Robotic Systems
Abstract: Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.


Title: XBotCloud: A Scalable Cloud Computing Infrastructure for XBot Powered Robots
Abstract: Limitations with the on-board computational resources installed on untethered robots such as humanoids and mobile robots in general affects significantly the performance and capabilities of these machines. An approach to address this issue is to make use of the cloud robotics concept and take advantage of the extensive computational resources of the cloud. XBotCloud is a recently developed component of the XBot framework. It tackles the above challenges by introducing the tools and mechanisms to enable users and robots to exploit the computational resources of the cloud allowing the execution of services with low, soft or hard Real-Time execution/communication performance. The latter is ensured thanks to the functionality provided by the XBotCore Real-Time cross-robot software component of the XBot framework. XBotCloud addresses also one of the main challenges related with cloud robotics: security. To avoid remote attacks it takes advantage of the Amazon Web Services (AWS)Cloud Security and it uses an internal VPN Network to handle the connectivity between the robot and the cloud server. The full implementation of the framework is presented and its functionality is demonstrated in realistic tasks involving pipelines that mix the execution of cloud services with moderate execution time constraints and Real-Time modules running on the robot local control unit. XBotCloud performances and cross-robot flexibility are experimentally validated on two different robotic platforms, the WALK-MAN humanoid and the CENTAURO upper body/full-body.


Title: Learning to Touch Objects Through Stage-Wise Deep Reinforcement Learning
Abstract: Learning complex behaviors through reinforcement learning is particularly challenging when reward is only available upon successful completion of the full behavior. In manipulation robotics, so-called shaping rewards are often used to overcome this problem. However, these usually require human engineering or (partial)world models describing, e.g., the kinematics of the robot or high-level modules for perception. Here we propose an alternative method to learn an object palm-touching task through a weakly-supervised and stagewise learning of simpler tasks. First, the robot learns to fixate the object with its cameras. Second, the robot learns eye-hand coordination by learning to fixate its end effector. Third, using the previously acquired skills an informative shaping reward can be computed which facilitates efficient learning of the object palm-touching task. We demonstrate in simulation that learning the full task with this shaping reward is comparable to learning with an informative supervised reward.


Title: Bayesian Information Recovery from CNN for Probabilistic Inference
Abstract: Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.


Title: Inertial Velocity and Attitude Estimation for Quadrotors
Abstract: This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.


Title: Quadtree-Accelerated Real-Time Monocular Dense Mapping
Abstract: In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.


Title: Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions
Abstract: Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L1 adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.


Title: Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator
Abstract: A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.


Title: Unsupervised Object Proposal Using Depth Boundary Density and Density Uniformity
Abstract: Object proposal that detects candidate bounding boxes of objects in images is an effective way of accelerating object recognition in the robot/computer vision area. We propose an accurate and fast object proposal method using depth images. Existing proposal methods can be roughly divided into two categories: window scoring and object region extraction. The window scoring methods usually have higher efficiency than object region extraction methods. The previous methods using RGB images detect an excessive number of boxes due to edges of texture objects. These methods also may misdetect overlapping objects as one candidate bounding box. To tackle these problems, we propose a novel and effective objectness measure using depth images. The proposed method evaluates objectness by using depth boundary density difference between inner and outer regions of a candidate bounding box. We also consider the uniformity of the outer boundary density in a candidate bounding box to divide overlapping objects into individual candidate bounding boxes. Our reasonable assumption here is that the depth boundary of an object has a closed loop. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging toy-dataset [1] of complex crowded scenes.


Title: PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap
Abstract: Point cloud registration is a popular research topic and has been widely used in many tasks, such as robot mapping and localization. It is a challenging problem when the overlap is small, or the rotation is large. The problem has not been well solved by existing methods such as the iterative closest point (ICP) and its variants. In this paper, a novel method named principal coordinate alignment with overlap tuning (PCAOT) is proposed based on the Manhattan world assumption. It solves two key problems together, the transformation estimation and the overlap estimation. The overlap is represented by a 3D cuboid and the transformation is computed only within the overlap region. Instead of finding point correspondence as in traditional methods, we estimate the rotation by principal coordinates alignment, which is faster and less sensitive than ICP and its variants to small overlaps and large rotations. Evaluations demonstrate that our method achieves much better results than the ICP and its variants when the overlap ratio is smaller than 50%, or the rotation angle is larger than 60°. Especially, it is effective when the overlap ratio is less than 30%, or the rotation angle is larger than 90°.


Title: Minimal Construct: Efficient Shortest Path Finding for Mobile Robots in Polygonal Maps
Abstract: With the advent of polygonal maps finding their way into the navigational software of mobile robots, the Visibility Graph can be used to search for the shortest collision-free path. The nature of the Visibility Graph-based shortest path algorithms is such that first the entire graph is computed in a relatively time-consuming manner. Then, the graph can be searched efficiently any number of times for varying start and target state combinations with the A* or the Dijkstra algorithm. However, real-world environments are typically too dynamic for a map to remain valid for a long time. With the goal of obtaining the shortest path quickly in an ever changing environment, we introduce a rapid path finding algorithm-Minimal Construct-that discovers only a necessary portion of the Visibility Graph around the obstacles that actually get in the way. Collision tests are computed only for lines that seem heuristically promising. This way, shortest paths can be found much faster than with a state-of-the-art Visibility Graph algorithm and as our experiments show, even grid-based A* searches are outperformed in most cases with the added benefit of smoother and shorter paths.


Title: Trajectory Planning for Heterogeneous Robot Teams
Abstract: We describe a trajectory planning method for heterogeneous mobile robot teams in known environments. We consider two core problems that arise with heterogeneous robot teams: asymmetric inter-robot collision constraints and varying dynamic limits. Asymmetric collision constraints are important for close-proximity flight of rotorcraft due to the downwash effect, which complicates spatial coordination. Varying dynamic limits complicate temporal coordination between robots and must be taken into account during planning. Our method builds upon a hybrid planner that combines graph-planning techniques with trajectory optimization and scales well to large homogeneous robot teams. We extend the hybrid planning approach to include the additional spatial and temporal coordination to support heterogeneous teams. Our method scales well with the number of robots and robot types and we demonstrate our approach on a team of 15 physical robots of 4 different types, including quadrotors and differential drive robots.


Title: A Motion Planning Approach for Marsupial Robotic Systems
Abstract: This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.


Title: Motion Planning and Goal Assignment for Robot Fleets Using Trajectory Optimization
Abstract: This paper is concerned with automating fleets of autonomous robots. This involves solving a multitude of problems, including goal assignment, motion planning, and coordination, while maximizing some performance criterion. While methods for solving these sub-problems have been studied, they address only a facet of the overall problem, and make strong assumptions on the use-case, on the environment, or on the robots in the fleet. In this paper, we formulate the overall fleet management problem in terms of Optimal Control. We describe a scheme for solving this problem in the particular case of fleets of non-holonomic robots navigating in an environment with obstacles. The method is based on a two-phase approach, whereby the first phase solves for fleet-wide boolean decision variables via Mixed Integer Quadratic Programming, and the second phase solves for real-valued variables to obtain an optimized set of trajectories for the fleet. Examples showcasing the features of the method are illustrated, and the method is validated experimentally.


Title: Re-Establishing Communication in Teams of Mobile Robots
Abstract: As communication is important for cooperation, teams of mobile robots need a way to re-establish a wireless connection if they get separated. We develop a method for mobile robots to maintain a belief of each other's positions using locally available information. They can use their belief to plan paths with high probabilities of reconnection. This approach also works for subteams cooperatively searching for a robot or group of robots that they would like to reconnect with. The problem is formulated as a constrained optimization problem which is solved using a branch-and-bound approach. We present simulation results showing the effectiveness of this strategy at reconnecting teams of up to five robots and compare the results to two other strategies.


Title: Multi-Agent Planning for Coordinated Robotic Weed Killing
Abstract: This work presents a strategy for coordinated multi-agent weeding under conditions of partial environmental information. The goal of this work is to demonstrate the feasibility of coordination strategies for improving the weeding performance of autonomous agricultural robots. We show that, given a sufficient number of agents, the algorithm can successfully weed fields with various initial seed bank densities, even when multiple days are allowed to elapse before weeding commences. Furthermore, the use of coordination between agents is demonstrated to strongly improve system performance as the number of agents increases, enabling the system to eliminate all the weeds in the field, as in the case of full environmental information, when the planner without coordination failed to do so. As a domain to test our algorithms, we have developed an open source simulation environment, Weed World, which allows real-time visualization of coordinated weeding policies, and includes realistic weed generation. In this work, experiments are conducted to determine the required number of agents and their required transit speed, for given initial seed bank densities and varying allowed days before the start of the weeding process.


Title: Intelligent Robotic IoT System (IRIS)Testbed
Abstract: We present the Intelligent Robotic IoT System (IRIS), a modular, portable, scalable, and open-source testbed for robotic wireless network research. There are two key features that separate IRIS from most of the state-of-the-art multi-robot testbeds. (1)Portability: IRIS does not require a costly static global positioning system such as a VICON system nor time-intensive vision-based SLAM for its operation. Designed with an inexpensive Time Difference of Arrival (TDoA)localization system with centimeter level accuracy, the IRIS testbed can be deployed in an arbitrary uncontrolled environment in a matter of minutes. (2)Programmable Wireless Communication Stack: IRIS comes with a modular programmable low-power IEEE 802.15.4 radio and IPv6 network stack on each node. For the ease of administrative control and communication, we also developed a lightweight publish-subscribe overlay protocol called ROMANO that is used for bootstrapping the robots (also referred to as the IRISbots), collecting statistics, and direct control of individual robots, if needed. We detail the modular architecture of the IRIS testbed design along with the system implementation details and localization performance statistics.


Title: SEAR: A Polynomial- Time Multi-Robot Path Planning Algorithm with Expected Constant-Factor Optimality Guarantee
Abstract: We study the labeled multi-robot path planning problem in continuous 2D and 3D domains in the absence of obstacles where robots must not collide with each other. For an arbitrary number of robots in arbitrary initial and goal arrangements, we derive a polynomial time, complete algorithm that produces solutions with constant-factor optimality guarantees on both makespan and distance optimality, in expectation, under the assumption that the robot labels are uniformly randomly distributed. Our algorithm only requires a small constant-factor expansion of the initial and goal configuration footprints for solving the problem, i.e., the problem can be solved in a fairly small bounded region. Beside theoretical guarantees, we present a thorough computational evaluation of the proposed solution. In addition to the baseline implementation, adapting an effective (but non-polynomial time) routing subroutine, we also provide a highly efficient implementation that quickly computes near-optimal solutions. Hardware experiments on the microMVP platform composed of non-holonomic robots confirms the practical applicability of our algorithmic pipeline.


Title: Towards Peak Torque Minimization for Modular Self-Folding Robots
Abstract: Modular self-folding robots are versatile systems that can change their own shape from two-dimensional patterns at instant commands. This reconfigurability is commonly restrained by power limitation in autonomous environments, The robotic systems with insufficient torque may lead to inaccurate movements and even transformation failures. This paper presents methodology for optimized reconfiguration planning with torque limitation in modular self-folding robots. We determine reconfiguration schemes with optimal initial pattern and robotic base that result in minimal peak torque by minimizing robotic inertia of the modular architecture. We present minimal bounding box and capacitated spanning tree heuristic algorithms to generate optimal initial patterns and propose 3 heuristic rules for robotic base selection. Our approach is demonstrated in simulation by applying the algorithms to the robotic concept of Mori, a modular origami robot. The simulation results show that the proposed algorithms yield reconfiguration schemes with low peak torque, thereby appropriate for real-time applications in modular robotic systems.


Title: Riding and Speed Governing for Parallel Two-Wheeled Scooter Based on Sequential Online Learning Control by Humanoid Robot
Abstract: The sequential online tuning for controller gains is required for the continuous action of the riding into parallel two-wheeled scooter and the speed governing after riding by humanoid robot. The implemented controllers are different between the riding and the speed governing, and these tuning strategies are also different. In particular, the riding requires the immediate tuning in the short riding phase and the speed governing requires the accurate tuning to regulate the speed of humanoid robot. To the above requirements, this paper proposes the Sequential Online Learning Control (SOLC)method composed of the cascade connection of SGD-based open-loop Learning Control (SLC)and Mini-batch-based closed-loop Learning Control (MLC). SLC contributes the damping gain online tuning for the foot torque control during execution of riding, and MLC contributes the PID gains online tuning for the speed governing control. Finally, we show the validity of SOLC through the sequential experiment of riding and speed governing for parallel two-wheeled scooter by life-sized humanoid robot HRP2-JSK.


Title: Dynamic Modelling and Motion Planning for the Nonprehensile Manipulation and Locomotion Tasks of the Quadruped Rsbot*This work is supported by the project of Robotics Innovation Based on Advanced Materials under Ritsumeikan Global Innovation Research Organization (R-GIRO)
Abstract: This paper presents the dynamic modelling and motion planning method for a quadruped robot that uses its legs for nonprehensile manipulation as well as locomotion. Three different working modes named Drive Mode, Inchworm Mode and Scoot Mode are proposed to enable the robot to move forward together with the object. We firstly introduce a universal model for these modes and deduce its dynamic equation. Then the contact force constraints are combined and mapped to the system state variables. Based on the acquired state acceleration constraints, the motion planning problem can be solved by designing system state paths in the phase space. After that, we described the mathematical problems within the three working modes and generate the robot motions accordingly. Finally, experimental results obtained through simulations and physical tests are reported to demonstrate the effectiveness of our method.


Title: Fuzzy-Based Feedback Control of a Tip-Mounted Module for Robot-Assisted Endoscopy
Abstract: Nascent endoscopic therapeutic procedures, such as endoscopic submucosal dissection, enable unparalleled access to and removal of mid-size cancerous neoplasia from within the gastrointestinal tract. However, the remote locations of these lesions often incur substantial distal dexterity which imparts appreciable cognitive loading on the clinician and opens up the possibility of adverse events such as intestinal perforation due to limited dexterity and a lack of sensory feedback. In this work, we introduce a mm-scale, tip-mounted robotic system, EndoMODRA (Endoscopic Module for On-Demand Robotic Assistance), which interfaces with commercially-available endoscopic tools and provides additional dexterity and feedback sensing using on-board actuators and sensors, decoupling tool motion from endoscope motion. Leveraging alternative high-energy-density actuation strategies and monolithic, printed-circuit-inspired manufacturing processes, all actuation and sensing is fully contained within the distally-mounted module, obviating the need for a continuous mechanical transmission to a proximal motor package. We develop a fuzzy-tuned PID/PWM controller for closing the loop distally to enable closed-loop position-controlled trajectory execution using onboard actuation and sensing, realizing fully -distal loop closure in an endoscope-mounted robotic module with no proximal actuation or sensing component. Controller performance is validated on a fully-integrated module with on-board sensing, demonstrating the ability to execute pre-determined trajectories as well as real-time rate-based teleoperation.


Title: A Real- Time Solver for Time-Optimal Control of Omnidirectional Robots with Bounded Acceleration
Abstract: We are interested in the problem of time-optimal control of omnidirectional robots with bounded acceleration (TOC-ORBA). While there exist approximate solutions for such problems, and exact solutions with unbounded acceleration, exact solvers to the TOC-ORBA problem have remained elusive until now. In this paper, we present a real-time solver for true time-optimal control of omnidirectional robots with bounded acceleration. We first derive the general parameterized form of the solution to the TOC-ORBA problem by application of Pontryagin's maximum principle. We then frame the boundary value problem of TOC-ORBA as an optimization problem over the parameterized control space. To overcome local minima and poor initial guesses to the optimization problem, we introduce a two-stage optimal control solver (TSOCS): The first stage computes an upper bound to the total time for the TOC-ORBA problem and holds the time constant while optimizing the parameters of the trajectory to approach the boundary value conditions. The second stage uses the parameters found by the first stage, and relaxes the constraint on the total time to solve for the parameters of the complete TOC-ORBA problem. Furthermore, we implement TSOCS as a closed loop controller to overcome actuation errors on real robots in realtime. We empirically demonstrate the effectiveness of TSOCS in simulation and on real robots, showing that 1) it runs in real time, generating solutions in less than 0.5ms on average; 2) it generates faster trajectories compared to an approximate solver; and 3) it is able to solve TOC-ORBA problems with nonzero final velocities that were previously unsolvable in real-time.


Title: A New Manufacturing Process for Soft Robots and Soft/Rigid Hybrid Robots
Abstract: We present a novel manufacturing process for creating monolithic, multi-chambered inflatable structures including both soft and rigid components. Specifically, our process involves stacking layers of textiles or plastics and thermal adhesive film, then bonding the structure with a heat press or in an oven. Several different ways of arranging textiles and thermal adhesive film in order to achieve airtight structures are presented. Since this process only uses materials that bend, but do not stretch, it permits the easy inclusion of rigid structures such as circuit boards, plates that constrain inflatable chambers to bend in specified locations, and rigid pieces that enable sections of a robot to be connected in a modular fashion. Additionally, the process permits folding layers before their assembly, leading to more complex geometries. We present three different possible seam types, and enumerate the different types of corners that can be constructed without leaking. We present measurements of the ability of these structures to support pressure and measurements of the strength of bonds between textiles and other materials. Finally, we present two examples of robots constructed using this manufacturing method, including a hybrid soft/rigid robotic arm and a soft robot that can roll along the ground.


Title: Magnetic-Field-Inspired Navigation for Soft Continuum Manipulator*This work was supported in part by King's College London, the EPSRC in the framework of the NCNR (National Centre for Nuclear Robotics) project (EP/R02572X/1), the STIFF-FLOP project grant from the European Communities Seventh Framework Programme under grant agreement 287728, and the Indonesia Endowment Fund for Education, Ministry of Finance Republic of Indonesia.
Abstract: Taking inspiration from the properties of magnetic fields, we propose a reactive navigation method for soft continuum manipulators operating in unknown environments. The proposed navigation method outperforms previous works since it is able to successfully achieve collision-free movements towards the goal in environments with convex obstacles without relying on a priori information of the obstacles' shapes and locations. Simulations for the kinematic model of a soft continuum manipulator and preliminary experiments with a 2-segments soft continuum arm are performed, showing promising results and the potential for our approach to be applied widely.


Title: Real-Time Shape Estimation of an Elastic Rod Using a Robot Manipulator Equipped with a Sense of Force
Abstract: This paper proposes a real-time method for estimating the shape of an elastic rod using a robot manipulator equipped with a sense of force. The proposed method does not use optical sensing devices, such as cameras or lasers, but relies only upon the sense of force in the manipulator. In the proposed method, the deformation of an elastic rod is calculated from the obtained force/torque information using the discretized Kirchhoff elastic rod model, and the three-dimensional shape of the rod is then estimated. Furthermore, by integrating the force information with the orientation of the manipulator end-effector, the proposed method can evaluate the effect of gravity on the shape estimation accurately. Experiments were carried out to verify the proposed method, where a thin elastic strip was employed as a typical elastic rod, attached to the end-effector of the robot manipulator, bent and twisted into various shapes. The results show that the proposed method that compensates for gravity is better than a method without gravity compensation, and it estimated the 142 mm length strip shape with a position error no greater than 7.76 mm and an average calculation time of 4.24 ms.


Title: Quotient-Space Motion Planning
Abstract: A motion planning algorithm computes the motion of a robot by computing a path through its configuration space. To improve the runtime of motion planning algorithms, we propose to nest robots in each other, creating a nested quotient-space decomposition of the configuration space. Based on this decomposition we define a new roadmap-based motion planning algorithm called the Quotient-space roadMap Planner (QMP). The algorithm starts growing a graph on the lowest dimensional quotient space, switches to the next quotient space once a valid path has been found, and keeps updating the graphs on each quotient space simultaneously until a valid path in the configuration space has been found. We show that this algorithm is probabilistically complete and outperforms a set of state-of-the-art algorithms implemented in the open motion planning library (OMPL).


Title: Computing a Collision-Free Path Using the Monogenic Scale Space
Abstract: Mobile robots have been used for various purposes with different functionalities which require them to freely move in environments containing both static and dynamic obstacles to accomplish given tasks. One of the most relevant capabilities in terms of navigating a mobile robot in such an environment is to find a safe path to a goal position. This paper shows that there exists an accurate solution to the Laplace equation which allows finding a collision-free path and that it can be efficiently calculated for a rectangular bounded domain such as a map which is represented as an image. This is accomplished by the use of the monogenic scale space resulting in a vector field which describes the attracting and repelling forces from the obstacles and the goal. The method is shown to work in reasonably convex domains and by the use of tessellation of the environment map for non-convex environments.


Title: Automatic Parameter Tuning of Motion Planning Algorithms
Abstract: Motion planning algorithms attempt to find a good compromise between planning time and quality of solution. Due to their heuristic nature, they are typically configured with several parameters. In this paper we demonstrate that, in many scenarios, the widely used default parameter values are not ideal. However, finding the best parameters to optimise some metric(s) is not trivial because the size of the parameter space can be large. We evaluate and compare the efficiency of four different methods (i.e. random sampling, AUC-Bandit, random forest, and bayesian optimisation) to tune the parameters of two motion planning algorithms, BKPIECE and RRT-connect. We present a table-top-reaching scenario where the seven degrees-of-freedom KUKA LWR robotic arm has to move from an initial to a goal pose in the presence of several objects in the environment. We show that the best methods for BKPIECE (AUC-Bandit) and RRT-Connect (random forest) improve the performance by 4.5x and 1.26x on average respectively. Then, we generate a set of random scenarios of increasing complexity, and we observe that optimal parameters found in simple environments perform well in more complex scenarios. Finally, we find that the time required to evaluate parameter configurations can be reduced by more than 2/3 with low error. Overall, our results demonstrate that for a variety of motion planning problems it is possible to find solutions that significantly improve the performance over default configurations while requiring very reasonable computation times.


Title: Perception-Driven Sparse Graphs for Optimal Motion Planning
Abstract: Most existing motion planning algorithms assume that a map (of some quality) is fully determined prior to generating a motion plan. In many emerging applications of robotics, e.g., fast-moving agile aerial robots with constrained embedded computational platforms and visual sensors, dense maps of the world are not immediately available, and they are computationally expensive to construct. We propose a new algorithm for generating plan graphs which couples the perception and motion planning processes for computational efficiency. In a nutshell, the proposed algorithm iteratively switches between the planning sub-problem and the mapping sub-problem, each updating based on the other until a valid trajectory is found. The resulting trajectory retains a provable property of providing an optimal trajectory with respect to the full (unmapped) environment, while utilizing only a fraction of the sensing data in computational experiments.


Title: Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization
Abstract: For socially assistive robots (SAR)to be accepted into complex and stochastic human environments, it is important to account for subtle social norms. In this paper, we propose a novel approach to socially-aware navigation (SAN)which garnered an immense interest in the Human-Robot Interaction (HRI)community. We use a multi-objective optimization tool called the Pareto Concavity Elimination Transformation (PaC-cET)to capture the non-linear human navigation behavior, a novel contribution to the community. A candidate point on a trajectory is scored (1)for its progress towards the goal, and (2)based on autonomously-sensed distance-based features that capture the social norms and associated social costs. Rather than use a finely-tuned linear combination of these costs, we use PaCcET to select an optimized future trajectory point, associated with a non-linear combination of the costs. Existing research in this domain concentrates on geometric reasoning, model-based, and learning approaches, which have their own pros and cons. This approach is distinct from prior work in this area. We showed in a simulation that the PaCcET-based trajectory planner not only is able to avoid collisions and reach the intended destination in static and dynamic environments but also considers a human's personal space i.e. rules of proxemics in the trajectory selection process.


Title: Ladder Climbing with a Snake Robot
Abstract: This paper presents a method that allows a snake robot to climb a ladder. We propose a ladder climbing method for a snake robot that has a smooth surface shape. We design a novel gait for the snake using a gait design method that configures the target form of the snake robot by connecting simple shapes. The climbing motion is executed via shift control and the corresponding motion required to catch the next step on the ladder. In addition, we developed a snake robot that has a smooth exterior body surface through construction of pectinate-shaped parts of the links. We demonstrated the effectiveness of both the proposed gait and the design of the snake robot experimentally.


Title: Modeling of Robotic Fish Propelled by a Servo/IPMC Hybrid Tail
Abstract: This paper presents modeling of robotic fish propelled by a hybrid tail with Servo and IPMC actuated two joints. The first joint is driven by a servo motor, which generates flapping motion for main propulsion. The second joint is actuated by a soft actuator, or ionic polymer-metal composite (IPMC) artificial muscle, which directs the propelled fluid for steering. A dynamic model is developed to capture the 2D motion dynamics of the robotic fish. The model fully captures the actuation dynamics of the IPMC soft actuator, two-link tail motion dynamics, and body motion dynamics. Experimental results have shown that the robotic fish is capable of swimming forward (up to 0.45 body length/second) and turning left and right (up to 40 degree/sec) with a small turning radius (less than half a body length). Finally, the dynamic model has been validated with experimental data, in terms of steady-state forward speed and turning speed versus the flapping frequency.


Title: Blade-Type Crawler Capable of Running on the Surface of Water as Bio-Inspired by a Basilisk Lizard
Abstract: For unmanned rescue, observation, and/or research, vehicles with high terrain adaptability, high speed, and high reliability are needed to reach hard-to-reach-locations. In order to extend the areas that can be explored, we propose a method and a robot capable of running on the surface of water without having to bypass the puddles and streams that exist on uneven terrain. The method that enables the robot to run on the water surface is bio-inspired by the basilisk lizard that can walk on the surface of water. We developed a blade-type crawler robot with a simple and reliable mechanism, capable of traversing uneven terrain at high speed. The robot with the method was tested on a real water surface and the result confirmed the ability of the robot to run on the water surface.


Title: Bio-Inspired Design of a Gliding-Walking Multi-Modal Robot
Abstract: Versatile multi-modal robots are advantageous for their wider operational environments. By taking design principles from observation of Pteromyini, commonly known as the flying squirrel, which shows balanced performances in both aerial and terrestrial locomotion, a novel robotic platform with the ability of gliding and walking is designed. The flexible membrane and gliding method of Pteromyini have been applied to the robot design. The legs of the robot were optimized to perform with regulated motor torques in both walking and gliding. The robot glided with an average gliding ratio of 1.88 and controlled its angle-of-attack for slowing down to land safely. The robot was able to walk utilizing different gait patterns. These results demonstrated our robot's balanced multi-modal locomotion of gliding and walking.


Title: Design of Lizard-Inspired Robot with Lateral Body Motion
Abstract: A new lizard-inspired robot is presented in this paper, which enables to maintain its moving direction by lateral body motions even during high-speed bipedal running. First, a dynamic model for lizard-inspired robot is derived to simulate the lateral body motion of real lizard. Based upon the simulation using dynamic model, the lizard-inspired robot is tactfully built so that its hind leg is optimally designed on a 4-bar mechanism and its body is simplified to consist of two body links and a tail connected by two revolute joints. The experiments verify that the proposed robot can maintain its moving direction via proper lateral motions during high-speed bipedal running similar to that of real lizard.


Title: Natural Dynamics Exploitation of Dynamic Soaring: Towards Bio-Inspired and Energy Efficient Flying Locomotion
Abstract: Albatross has an energy efficient flying pattern (dynamic soaring) among seabirds. This interesting point encourages us to exploit its flying natural dynamics so as to control the flying robots on energy efficient and robust gaits. In doing so, we study the albatross dynamic soaring from analytical and biological perspectives and realize that to generate the dynamic soaring instead of trajectory control, the mechanical energy should be regulated. Accordingly, the control objective is set to mechanical energy regulation, and the bank angle and lift coefficient are computed to satisfy this objective. The presented method is simulated on a standard albatross model and generates two different types of dynamic soaring; O-shaped and a-shaped patterns. In addition, by means of simulations, it is investigated that the presented method is robust in face of variations in initial conditions and unexpected disturbances in the environment's model; i.e., they cannot disturb the stability and cyclic behavior of the system. Moreover, the simulation results are compared with pieces of natural evidence from albatross and interesting similarities are observed.


Title: Development of High-Speed Type Peristaltic Crawling Robot for Long-Distance and Complex-Line Sewer Pipe Inspection
Abstract: Currently, serious accidents are caused frequently by the aging of sewer pipes. Therefore, to inspect sewer pipes, we developed a peristaltic crawling robot that reproduces the locomotion of an earthworm. This robot can drive for more than 100m, and it can be used for the maintenance of sewer pipes (100A pipes). However, the speed of the robot is low. There are two causes. First, the units of the previous robot have steps of artificial muscle fastening. These steps increase the diameter of the artificial muscles. A smaller diameter of the artificial muscles is advantageous for the speed of the robot inside the pipes. Second, the previous robot has slow air response. In this study, we used large-sized solenoid valves to overcome this drawback.


Title: Learning and Generation of Actions from Teleoperation for Domestic Service Robots*This work was supported by JST, CREST
Abstract: In this paper, we propose a method for motion learning aimed at the execution of autonomous household chores by service robots in real environments. For robots to act autonomously in a real environment, it is necessary to define the appropriate actions for the environment. However, it is difficult to define these actions manually. Therefore, body motions that are common to multiple actions are defined as motion primitives. Complex actions can then be learned by combining these motion primitives. For learning motion primitives, we propose a reference-point and object-dependent Gaussian process hidden semi-Markov model (RPOD-GP-HSMM). For verification, a robot is teleoperated to perform the actions included in several domestic household chores. The robot then learns the associated motion primitives from the robot's body information and object information.


Title: Proxemics and Approach Evaluation by Service Robot Based on User Behavior in Domestic Environment
Abstract: Intelligent service robots are used at a significant level to uplift the living standards of domestic users. These robots are expected to possess human-friendly interactive features. Service robots should be able to provide a variety of tasks to support independent living of users in domestic environments. Therefore, a service robot often needs to approach users to execute these services and the approach toward the users should be human friendly. In order to achieve this, proxemics planner of a service robot should be cable of deciding the approaching proxemics based on user behavior. This paper proposes a method to decide the approaching proxemics based on the behavior of the user. A fuzzy interference system has been designed to decide the proxemics based on the user behavior identified through body parameters. This leads to an effective interaction mechanism initiated by a robot in such a way that the approaching scenario looks more humanlike. The proposed concept has been implemented on MIRob platform and experiments were conducted in an artificially created domestic environment. The experimental results of the proposed system have been compared with results of a human study to evaluate the performance of the system.


Title: Robot Approaching and Engaging People in a Human-Robot Companion Framework
Abstract: This paper presents a new model to make robots capable of approaching and engaging people with a human-like behavior, while they are walking in a side-by-side formation with a person. This method extends our previous work [1], which allows the robot to adapt its navigation behaviour according to the person being accompanied and the dynamic environment. In the current work, the robot is able to predict the best encounter point between the human-robot group and the approached person. Then, in the encounter point the robot modifies its position to achieve an engagement with both people. The encounter point is computed using a gradient descent method that takes into account all people predictions. Moreover, we make use of the Extended Social Force Model (ESFM), and it is modified to include the dynamic goal. The method has been validated over several situations and in real-life experiments, in addition, a user study has been realized to reveal the social acceptability of the robot in this task.


Title: A 7-Dof Wire-Driven Lightweight Arm with Wide Wrist Motion Range
Abstract: Till date, various seven-degrees-of-freedom (7-DOF)robot arms have been developed globally. In general, the robot arms utilized in factories are required to possess speed, power, and accuracy. They are isolated from humans using a fence to ensure human safety. However, a home robot should work near humans at an appropriate speed without a fence. One approach to meeting this requirement involves the installation of various sensors on the robot to control and stop the robot safely even if a collision has occurred. However, a robot system is complicated and expensive. In order to give inherent safety to the robot, we should lighten the robot arm. In this study, a 7-DOF lightweight arm with a wide wrist-motion range is introduced. The weight of movable parts is approximately 2.87 kg. To achieve such properties, we propose the use of three mechanisms: a shoulder mechanism with hollow cylinders, a wrist mechanism with a wide workspace, and an integrated wrist and elbow mechanisms of high power. To verify its feasibility, a prototype of the robot is designed and developed. The experimental results demonstrate its powerful performance and wide workspace of the wrist.


Title: RAMCIP - A Service Robot for MCI Patients at Home
Abstract: This video features RAMCIP, a new service robot developed to provide proactive and discreet assistance to elderly with Mild Cognitive Impairments (MCI), supporting their daily activities at home. Starting with a thorough analysis of needs and requirements of the target population, the RAMCIP robot was developed as an integrated ensemble of advanced H/W and S/W components, realizing the robot skills of perception, cognition, safe navigation, grasping, manipulation, and human-robot communication, ample to operate in real, rather challenging domestic environments. The RAMCIP use-cases include proactive assistance provision to user's cooking, eating and medication activities, through discreet user monitoring and robot interventions by reminders and robotic manipulations., RAMCIP can bring the medicine, recognize fallen objects and electric appliance that has been forgotten turned on. It also recognizes the user walking in low-light conditions and turns on the light, as well as detects cases of emergency such as a fall. The robot provides also the user with cognitive training games and stimulates the user to contact with relatives through video-calls. Pilot trials of the RAMCIP robot have been performed in real homes of more than ten different users, in Barcelona, Spain; the video at hand exhibits the robot performing the target use cases.


Title: Nonlinear Analysis of an Indirectly Controlled Sliding Locomotion Robot
Abstract: With the purpose of achieving stable and energy efficient locomotion on the slippery road surface, a sliding locomotion robot without joint torque but indirectly controlled by an active wobbling mass is recently proposed. In this paper, we deepen the analysis of the mechanism of the indirectly controlled sliding locomotion for further optimization and generalization. First, we derive the equations of dynamics and control. Second, we estimate the natural frequency of the robot, the moving speed and energy efficiency are also evaluated with respect to forcing amplitude and frequency of the wobbling mass. Third, the Arnol'd tongue is introduced to analyze the relationship between achieving efficient locomotion and being entrained. In addition, phase oscillation and synchronization phenomenon are analyzed via hysteresis plot to further interpret the unusual shapes of the Arnol'd tongues. Finally, we analyze the entrained, however, inefficient locomotion by reconfirming the rolling constraints from the mechanical energy dissipation point of view. Our results help better understanding of the indirectly controlling mechanism, and the methods can be applied to other indirectly controlled locomotion robots.


Title: Planning Topological Navigation for Complex Indoor Environments
Abstract: The ability to move around the environment is one of the most important capabilities of a mobile robot. Although navigation is considered an already achieved capacity, there is still much work to be done to integrate navigation with high level reasoning and acting. Navigate in indoor environments also involve complex actions, such as opening doors, use elevators, and many others. We propose a topological navigation system based on Artificial Intelligence (AI) Planning. Starting from a symbolic representation of the environment, navigation tasks are divided into phases, in which different actions are required. This approach has demonstrated to be very effective to plan the operations of a robot at indoor environments. The final result is method compact, efficient and scalable. Our system has been successfully tested at European Robotics League in the humanoid robot Pepper.


Title: Joint Stem Detection and Crop-Weed Classification for Plant-Specific Treatment in Precision Farming
Abstract: Applying agrochemicals is the default procedure for conventional weed control in crop production, but has negative impacts on the environment. Robots have the potential to treat every plant in the field individually and thus can reduce the required use of such chemicals. To achieve that, robots need the ability to identify crops and weeds in the field and must additionally select effective treatments. While certain types of weed can be treated mechanically, other types need to be treated by (selective) spraying. In this paper, we present an approach that provides the necessary information for effective plant-specific treatment. It outputs the stem location for weeds, which allows for mechanical treatments, and the covered area of the weed for selective spraying. Our approach uses an end-to-end trainable fully convolutional network that simultaneously estimates stem positions as well as the covered area of crops and weeds. It jointly learns the class-wise stem detection and the pixel-wise semantic segmentation. Experimental evaluations on different real-world datasets show that our approach is able to reliably solve this problem. Compared to state-of-the-art approaches, our approach not only substantially improves the stem detection accuracy, i.e., distinguishing crop and weed stems, but also provides an improvement in the semantic segmentation performance.


Title: A Novel Autonomous Robot for Greenhouse Applications
Abstract: This paper presents a novel agricultural robot for greenhouse applications. In many greenhouses, including the greenhouse used in this work, sets of pipes run along the floor between plant rows. These pipes are components of the greenhouse heating system, and doubles as rails for trolleys used by workers. A flat surface separates the start of each rail set at the greenhouse headland. If a robot is to autonomously drive along plant rows, and also be able to move from one set of rails to the next, it must be able to locomote both on rails and on flat surfaces. This puts requirements on mechanical design and navigation, as the robot must cope with two very different operational environments. The robot presented in this paper has been designed to overcome these challenges and allows for autonomous operation both in open environments and on rails by using only low-cost sensors. The robot is assembled using a modular system created by the authors and tested in a greenhouse during ordinary operation. Using the robot, we map the environment and automatically determine the starting point of each rail in the map. We also show how we are able to identify rails and estimate the robots pose relative to theses using only a low-cost 3D camera. When a rail is located, the robot makes the transition from floor to rail and travels along the row of plants before it moves to the next rail set which it has identified in the map. The robot is used for UV treatment of cucumber plants.


Title: The use of dynamic sensing strategies to improve detection for a pepper harvesting robot
Abstract: This paper presents the use of dynamic sensing strategies to improve detection results for a pepper harvesting robot. The algorithm decides if an additional viewpoint is needed and selects the best-fit viewpoint location from a predefined set of locations based on the predicted profitability of such an action. The suggestion of a possible additional viewpoint is based on image analysis for fruit and occlusion level detection, prediction of the expected number of additional targets sensed from that viewpoint, and final decision if choosing the additional viewpoint is beneficial. The developed heuristic was applied on 96 greenhouse images of 30 sweet peppers and resulted in up to 19% improved detection. The harvesting utility cost function decreased by up to 10% compared to the conventional single viewpoint strategy.


Title: Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks
Abstract: We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).


Title: π-SoC: Heterogeneous SoC Architecture for Visual Inertial SLAM Applications
Abstract: In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles and robotics. One of the core technologies enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. Hence, performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. Previous attempts to optimize SLAM performance and energy efficiency usually involve optimizing one function and fail to approach the problem systematically. In this paper, we first study the characteristics of visual inertial SLAM workloads on existing heterogeneous SoCs. Then based on the initial findings, we propose π-SoC, a heterogeneous SoC design that systematically optimize the IO interface, the memory hierarchy, as well as the the hardware accelerator. We implemented this system on a Xilinx Zynq UltraScale MPSoC and was able to deliver over 60 FPS performance with average power less than 5 W.


Title: vTSL - A Formally Verifiable DSL for Specifying Robot Tasks
Abstract: Preprogramming of tasks still plays an important role in complex robotic systems despite the advances in automated planning and symbolic learning. Often, it is desired that end-users implement further tasks to adapt the robotic application to their needs. These user-defined tasks have to meet safety and integrity constraints for protecting the robotic platform and its users. We introduce a verifiable task specification language (vTSL) that enables to automatically prove that a task specification satisfies a set of predefined or task-specific constraints. We illustrate our approach using an example of a self-driving vehicle for intra-logistics and report experiences with two commercial applications.


Title: GPU-Accelerated Next-Best-View Coverage of Articulated Scenes
Abstract: Next-best-view algorithms are commonly used for covering known scenes, for example in search, maintenance, and mapping tasks. In this paper, we consider the problem of planning a strategy for covering articulated environments where the robot also has to manipulate objects to inspect obstructed areas. This problem is particularly challenging due to the many degrees of freedom resulting from the articulation. We propose to exploit graphics processing units present in many embedded devices to parallelize the computations of a greedy next-best-view approach. We implemented algorithms for costmap computation, path planning, as well as simulation and evaluation of viewpoint candidates in OpenGL for Embedded Systems and benchmarked the implementations on multiple device classes ranging from smartphones to multi-GPU servers. We introduce a heuristic for estimating a utility map from images rendered with strategically placed spherical cameras and show in simulation experiments that robots can successfully explore complex articulated scenes with our system.


Title: An Optimization-Based Approach to Dual-Arm Motion Planning with Closed Kinematics
Abstract: This paper addresses the optimization-based planning of collision-free motions for a dual-arm robot with kinematic constraints. Such problems arise, for example, when the robot has to move an object with both arms, whereby the two arms and the gripped object form a closed kinematic chain. Such constrained problems are hard to solve with sampling-based planners, because the probability that a random sample satisfies the closure constraint is practically zero. In contrast, the solution of optimization problems with equality constraints is a well-understood field of research. This paper formulates the motion planning task as optimization problem and proposes a numerical solution using the augmented Lagrangian method for handling constraints. The planner is compared to RRTs, CHOMP and TrajOpt on a set of randomly generated problems for a dual-arm robot with twelve degrees of freedom highlighting the advantages of optimization-based planning.


Title: Smooth Point-to-Point Trajectory Planning in $SE$ (3)with Self-Collision and Joint Constraints Avoidance
Abstract: In this paper we introduce a novel point-to-point trajectory planner for serial robotic structures that combines the ability to avoid self-collisions and to respect motion constraints, while complying with the requirement of being C4 continuous. The latter property makes our approach also suited for 4th order dynamics flexible joint robots, which gained significant practical relevance recently. In particular, we address the problem of generating a smooth, kinematically nearly time-optimal SE(3) trajectory while simultaneously avoiding potential collisions of the robot end-effector with its base as well as respecting the Cartesian unreachable states induced by the joint limits of the proximal kinematic structure.


Title: CROC: Convex Resolution of Centroidal Dynamics Trajectories to Provide a Feasibility Criterion for the Multi Contact Planning Problem
Abstract: We tackle the transition feasibility problem, that is the issue of determining whether there exists a feasible motion connecting two configurations of a legged robot. To achieve this we introduce CROC, a novel method for computing centroidal dynamics trajectories in multi-contact planning contexts. Our approach is based on a conservative and convex reformulation of the problem, where we represent the center of mass trajectory as a Bezier curve comprising a single free control point as a variable. Under this formulation, the transition problem is solved efficiently with a Linear Program (LP)of low dimension. We use this LP as a feasibility criterion, incorporated in a sampling-based contact planner, to discard efficiently unfeasible contact plans. We are thus able to produce robust contact sequences, likely to define feasible motion synthesis problems. We illustrate this application on various multi-contact scenarios featuring HRP2 and HyQ. We also show that we can use CROC to compute valuable initial guesses, used to warm-start non-linear solvers for motion generation methods. This method could also be used for the 0 and 1-Step capturability problem. The source code of CROC is available under an open source BSD-2 License.


Title: Variations on a Theme: “It's a Poor Sort of Memory that Only Works Backwards”
Abstract: Adapting the perceptual capabilities of mobile robots to new objects or new environments can be a time consuming task. In this paper we focus on specializing perceptual capabilities of mobile robots to new objects through a knowledge based, virtual scene rendering approach. Episodic memories of a robotic agent, gathered during the execution of a task are considered to be the main "theme". Variations of this theme are then generated based on background knowledge about the objects and data gathered with the purpose of learning new models for detection and recognition. We demonstrate the applicability of our approach by adapting the perceptual capabilities of a mobile robot performing pick and place tasks, to recognize new sets of objects.


Title: Attitude Estimation from Polarimetric Cameras
Abstract: In the robotic field, navigation and path planning applications benefit from a wide range of visual systems (e.g, perspective cameras, depth cameras, catadioptric cameras, etc.). In outdoor conditions, these systems capture information in which sky regions cover a major segment of the images acquired. However, sky regions are discarded and are not considered as visual cue in vision applications. In this paper, we propose to estimate attitude of Unmanned Aerial Vehicle (UAV) from sky information using a polarimetric camera. Theoretically, we provide a framework estimating the attitude from the skylight polarized patterns. We showcase this formulation on both simulated and real-word data sets which proved the benefit of using polarimetric sensors along with other visual sensors in robotic applications.


Title: Towards a Context Enhanced Framework for Multi Object Tracking in Human Robot Collaboration
Abstract: In a goal-oriented Human Robot Collaborative (HRC) scenario, where the goal is to complete an assembly process, a robust object tracker might not necessarily fulfill its functional role due to the dynamic nature of HRC. Moreover, for an efficient HRC, the functional role of the object tacker should not only be limited to localizing and tracking objects for robotic manipulation. It should also help to determine the current state of the assembly process and verify if the chosen action has been successfully performed and thus to enable an uninterrupted completion of an HRC assembly process. We present a Context Enhanced Framework for Multi Object Tracking, that i) allows uninterrupted completion of an assembly process, ii) improves the overall functional accuracy of the object tracker from 49 percent to 96 percent, and iii) enables the object tracker to handle multiple instance of multiple objects in a HRC setting.


Title: Real-time 3D Reconstruction Using a Combination of Point-Based and Volumetric Fusion
Abstract: Real-time 3D reconstruction using low-cost commodity sensors like Kinect or Xtion has been successfully applied in a wide range of fields like augmented reality, robotic teleoperation, and medical diagnosis. Due to the assumption of static scene, popular 3D reconstruction technologies such as KinectFusion and KinFu, find truthful reconstruction with fast motion camera or segmenting a moving object to be a challenge. In this paper, we propose a weighted iterative closest point (ICP) algorithm that uses both depth and RGB information to enhance the stability of camera tracking. Additionally, a GPU-based region growing method that combines depth, normal and intensity level as similarity criteria, is also applied to segment foreground moving objects accurately. For real-time processing and GPU memory efficiency, we also design a combination of point-based and volumetric representation to reconstruct moving objects and static scene, respectively. Both qualitative and quantitative results show that our proposed method improves real-time 3D reconstruction on the performance of camera tracking and segmentation of moving objects with reduced computational complexity.


Title: First Experimental Results on Motion Planning for Transportation in Aerial Long-Reach Manipulators with Two Arms
Abstract: This paper presents the motion planning of a novel aerial robotic system with a long-bar extension and two arms for long-reach manipulation in cluttered environments. The novel aerial long-reach manipulator includes a passive revolute joint between the aerial platform and the dual arm. This feature minimises the torque induced to the aerial system in case of unexpected collisions of the manipulator. The motion planning problem is addressed considering jointly the complete set of configuration variables for the aerial platform and the dual arm. Furthermore, the planner has been built over the fundamentals of RRT* algorithms in order to optimise the performance of the trajectories in terms of energy and time. The proposed planning method has been experimentally validated in a realistic industrial scenario, the transportation of a long bar through a cluttered environment consisting of several pipe structures.


Title: Sparse 3D Topological Graphs for Micro-Aerial Vehicle Planning
Abstract: Micro-Aerial Vehicles (MAVs) have the advantage of moving freely in 3D space. However, creating compact and sparse map representations that can be efficiently used for planning for such robots is still an open problem. In this paper, we take maps built from noisy sensor data and construct a sparse graph containing topological information that can be used for 3D planning. We use a Euclidean Signed Distance Field, extract a 3D Generalized Voronoi Diagram (GVD), and obtain a thin skeleton diagram representing the topological structure of the environment. We then convert this skeleton diagram into a sparse graph, which we show is resistant to noise and changes in resolution. We demonstrate global planning over this graph, and the orders of magnitude speed-up it offers over other common planning methods. We validate our planning algorithm in real maps built onboard an MAV, using RGB-D sensing.


Title: Motion Planning for a UAV with a Straight or Kinked Tether
Abstract: This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.


Title: Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots
Abstract: There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.


Title: Lightweight Collision Avoidance for Resource-Constrained Robots
Abstract: One of the safest and most reliable strategies for vehicle's collision avoidance is embedded control at low level to guarantee safe motion in all situations using on-board sensors. In this paper, we propose a novel lightweight collision avoidance strategy that can be implemented as a low level motion control to achieve safe motion while simultaneously tracking the robot's reference control input. This strategy is designed to be general so that it can be easily integrated with most control designs, with the primary target of resource-constrained robot swarms that act in real-time, dynamic environments. The main advantages of our approach are a very simple structure and low computational requirements. We verified the effectiveness of the proposed collision avoidance strategy through two simulated scenarios and with physical robots. We believe our design can be directly used in many areas, such as autonomous driving, intelligent transportation and planetary exploration.


Title: An Improved Formulation for Model Predictive Control of Legged Robots for Gait Planning and Feedback Control
Abstract: Predictive control methods for walking commonly use low dimensional models, such as a Linear Inverted Pendulum Model (LIPM), for simplifying the complex dynamics of legged robots. This paper identifies the physical limitations of the modeling methods that do not account for external disturbances, and then analyzes the issues of numerical stability of Model Predictive Control (MPC)using different models with variable receding horizons. We propose a new modeling formulation that can be used for both gait planning and feedback control in an MPC scheme. The advantages are the improved numerical stability for long prediction horizons and the robustness against various disturbances. Benchmarks were rigorously studied to compare the proposed MPC scheme with the existing ones in terms of numerical stability and disturbance rejection. The effectiveness of the controller is demonstrated in both MATLAB and Gazebo simulations.


Title: Cable-Driven Actuation for Highly Dynamic Robotic Systems
Abstract: This paper presents the design and experimental evaluations of an articulated robotic limb called Capler-Leg. The key element of Capler-Leg is its single-stage cable-pulley transmission combined with a high-gap radius motor. Our cable-pulley system is designed to be as light-weight as possible and to additionally serve as the primary cooling element, thus significantly increasing the power density and efficiency of the overall system. The total weight of active elements on the leg, i.e. the stators and the rotors, contribute more than 60 % of the total leg weight, which is an order of magnitude higher than most existing robots. The resulting robotic leg has low inertia, high torque transparency, low manufacturing cost, no backlash, and a low number of parts. The Capler-Leg system itself, serves as an experimental setup for evaluating the proposed cable-pulley design in terms of robustness and efficiency. A continuous jump experiment shows a remarkable 96.5 % recuperation rate, measured at the battery output. This means that almost all the mechanical energy output during push-off is returned back to the battery during touch-down.


Title: A Control Architecture with Online Predictive Planning for Position and Torque Controlled Walking of Humanoid Robots
Abstract: A common approach to the generation of walking patterns for humanoid robots consists in adopting a layered control architecture. This paper proposes an architecture composed of three nested control loops. The outer loop exploits a robot kinematic model to plan the footstep positions. In the mid layer, a predictive controller generates a Center of Mass trajectory according to the well-known table-cart model. Through a whole-body inverse kinematics algorithm, we can define joint references for position controlled walking. The outcomes of these two loops are then interpreted as inputs of a stack-of-task QP-based torque controller, which represents the inner loop of the presented control architecture. This resulting architecture allows the robot to walk also in torque control, guaranteeing higher level of compliance. Real world experiments have been carried on the humanoid robot iCub.


Title: Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks
Abstract: Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.


Title: Virtual Borders: Accurate Definition of a Mobile Robot's Workspace Using Augmented Reality
Abstract: We address the problem of interactively controlling the workspace of a mobile robot to ensure a human-aware navigation. This is especially of relevance for non-expert users living in human-robot shared spaces, e.g. home environments, since they want to keep the control of their mobile robots, such as vacuum cleaning or companion robots. Therefore, we introduce virtual borders that are respected by a robot while performing its tasks. For this purpose, we employ a RGB-D Google Tango tablet as human-robot interface in combination with an augmented reality application to flexibly define virtual borders. We evaluated our system with 15 non-expert users concerning accuracy, teaching time and correctness and compared the results with other baseline methods based on visual markers and a laser pointer. The experimental results show that our method features an equally high accuracy while reducing the teaching time significantly compared to the baseline methods. This holds for different border lengths, shapes and variations in the teaching process. Finally, we demonstrated the correctness of the approach, i.e. the mobile robot changes its navigational behavior according to the user-defined virtual borders.


Title: Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System
Abstract: Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.


Title: A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments
Abstract: Robots deployed in large human-populated indoor environments such as shopping malls, airports etc., inadvertently communicate via wireless networks for enhanced perception and decision making capabilities. Owing to highly dynamic signal attenuation characteristics in such environments, connectivity issues may arise during robotic navigation, leading to disruption in information flow causing potential danger. Exact modeling of signal propagation for estimating spatial signal variation is usually challenging. Moreover, the presence of dynamic humans also add a layer of temporal signal variation complexities. Thus, this paper introduces a generative approach for embedding radio signal strength constraints within networked service/social robot navigation in large human-populated environments. Initially, we propose a Gaussian Process based online spatio-temporal signal strength prediction model that, as opposed to the current state of the art, also aims to take into account the temporal fading arising due to the presence of human crowds. We then devise a transient-goal driven navigation strategy to realize a sub-optimal path towards a goal, that is aimed at resolving both communication-aware and human-aware planning constraints. Evaluations of the proposed signal prediction model demonstrate the advantages of our approach with respect to the current state of the art. The efficacy of the navigation strategy in also demonstrated simulations and using hardware experiments conducted on a robotic wheelchair operating in a large shopping mall.


Title: Optimizing Contextual Ergonomics Models in Human-Robot Interaction
Abstract: Current ergonomic assessment procedures require observation and manual annotation of postures by an expert, after which ergonomic scores are inferred from these annotations. Our aim is to automate this procedure and to enable robots to optimize their behavior with respect to such scores. A particular challenge is that ergonomic scoring requires accurate biomechanical simulations which are computationally too expensive to use in robot control loops or optimization. To address this, we learn Contextual Ergonomics Models, which are Gaussian Process Latent Variable Models that have been trained with full musculoskeletal simulations for specific tasks contexts. Contextual Ergonomics Models enable search in a low-dimensional latent space, whilst the cost function can be defined in terms of the full high-dimensional musculoskeletal model, which can be quickly reconstructed from the latent space. We demonstrate how optimizing Contextual Ergonomics Models leads to significantly reduced muscle activation in an experiment with eight subjects performing a drilling task.


Title: Drivers' Manoeuvre Prediction for Safe HRI
Abstract: Machines with high levels of autonomy such as robots and our growing need to interact with them creates challenges to ensure safe operation. The recent interest to create autonomous vehicles through the integration of control and decision-making systems makes such vehicles robots too. We therefore applied estimation and decision-making mechanisms currently investigated for human-robot interaction to human-vehicle interaction. In other words, we define the vehicle as an autonomous agent with which the human driver interacts, and focus on understanding the human intentions and decision-making processes. These are then integrated into the ro-bot`s/vehicle's own control and decision-making system not only to understand human behaviour while it occurs but to predict the next actions. To obtain knowledge about the human's intentions, this work relies heavily on the use of motion tracking data (i.e. skeletal tracking, body posture)gathered from drivers whilst driving. We use a data-driven approach to both classify current driving manoeuvres and predict future manoeuvres, by using a fixed prediction window and augmenting a standard set of manoeuvres. Results are validated against drivers of different sizes, seat preferences and levels of driving expertise to evaluate the robustness of the methods; precision and recall metrics higher than 95% for manoeuvre classification and 90% for manoeuvre prediction with time-windows of up to 1.3 seconds are obtained. The idea of prediction adds a highly novel aspect to human-robot/human-vehicle interaction, allowing for decision and control at a later point.


Title: Human Gaze Following for Human-Robot Interaction
Abstract: Gaze provides subtle informative cues to aid fluent interactions among people. Incorporating human gaze predictions can signify how engaged a person is while interacting with a robot and allow the robot to predict a human's intentions or goals. We propose a novel approach to predict human gaze fixations relevant for human-robot interaction tasks-both referential and mutual gaze-in real time on a robot. We use a deep learning approach which tracks a human's gaze from a robot's perspective in real time. The approach builds on prior work which uses a deep network to predict the referential gaze of a person from a single 2D image. Our work uses an interpretable part of the network, a gaze heat map, and incorporates contextual task knowledge such as location of relevant objects, to predict referential gaze. We find that the gaze heat map statistics also capture differences between mutual and referential gaze conditions, which we use to predict whether a person is facing the robot's camera or not. We highlight the challenges of following a person's gaze on a robot in real time and show improved performance for referential gaze and mutual gaze prediction.


Title: A Natural Adaptive Control Law for Robot Manipulators
Abstract: Existing adaptive robot control laws typically require an engineering choice of a constant adaptation gain matrix, which often involves repeated and time-consuming trial and error. Moreover, physical consistency of the estimated inertial parameters or the uniform positive definiteness of the estimated robot mass matrix cannot in general be guaranteed without nonsmooth corrections, e.g., projection to the boundary of the feasible parameter set. In this paper we present a natural adaptive control law that mitigates many of these difficulties, by exploiting the coordinate-invariant differential geometric structure of the space of physically consistent inertial parameters. Our approach provides a more generalizable and physically consistent adaptation law for the robot parameters without significant additional computations compared to existing methods. Simulation results showing markedly improved tracking error convergence over existing adaptive control laws are provided as validation.


Title: Map-based Deep Imitation Learning for Obstacle Avoidance
Abstract: Making an optimal decision to avoid obstacles while heading to the goal is one of the fundamental challenges for mobile robots equipped with limited computational resources. In this paper, we present a deep imitation learning algorithm that develops a computationally efficient obstacle avoidance policy based on egocentric local occupancy maps. The trained model embedded with a variant of the value iteration networks is able to provide near-optimal continuous action commands through fast feed-forward inferences and generalize well to unseen planning-based scenarios. To improve the policy robustness, we augment the training data set with artificially generated maps, which effectively alleviates the shortage of catastrophic samples in normal demonstrations. Extensive experiments on a Segway robot show the effectiveness of the proposed approach in terms of solution optimality, robustness as well as computation time.


Title: Wireframe Mapping for Resource-Constrained Robots
Abstract: This paper presents a novel wireframe map structure for resource-constrained robots operating in a rectilinear 2D environment. The wireframe representation compactly represents geometry, in addition to transient situations such as occlusions and boundaries of unexplored regions. We formulate a particle filter to suit this sparse wireframe map structure. Functions for calculating the likelihood of scans, merging wireframes, and resampling are developed to accommodate this map representation. The wireframe structure with the particle filter allows for severe discrete map errors to be corrected, leading to accurate maps with small storage requirements. We show in a simulation study that the algorithm attains a map of an environment with 1 % error, compared to an occupancy grid map obtained with GMapping which attained 23% error with the same storage requirements. A simulation mapping a large environment demonstrates the algorithms scalability.


Title: PH Model-Based Shape Reconstruction of Heterogeneous Continuum Closed Loop Kinematic Chain: An Application to Skipping Rope
Abstract: Soft robotics is a swiftly growing research area these days. Modeling continuum robots accurately is still a demanding field. The paper aims to propose a shape reconstruction method and the estimation of the kinematic behavior of heterogeneous continuum robot in closed loop kinematic configuration, by using Pythagorean Hodograph (PH) curves. The validation of the model approach has been tested on cooperative continuum robots, namely Compact Bionic Handling Arms (CBHA), driving an intermediate flexible rope (a passive flexible link), by using a 3D tracking system. Experimental comparison of the proposed approach with the existing approaches is performed in terms of accuracy as well as the time cost.


Title: Optimal Feedback Control Based on Analytical Linear Models Extracted from Neural Networks Trained for Nonlinear Systems
Abstract: A number of researches have been focusing on the development and control of robots with soft structures such as flexible musculoskeletal systems. Thus far, it has been reported that these robots can achieve high adaptability to environments despite their extremely simple controllers. However, because these robots are difficult to model mathematically, there is still no systematic design policy, in which control theory has been playing a role in conventional robotics, for constituting simple controllers. To tackle this problem, we propose a new approach using a neural network to obtain mathematical models. In particular, with this method, the control theory is applied to linear system models extracted from a network trained to express the forward dynamics of a robot. Through simulations, the validity and advantage of the proposed method was successfully confirmed.


Title: Learning to Grasp by Extending the Peri-Personal Space Graph
Abstract: We present a robot model of early reach and grasp learning, inspired by infant learning without prior knowledge of the geometry, kinematics, or dynamics of the arm. Human infants at reach onset are capable of using a sequence of jerky submotions to bring the hand to the position of a nearby object. A robotic learning agent can produce qualitatively similar behavior by using a graph representation to encode a set of safe, potentially useful arm states and feasible moves between them. These observations show that the Peri-Personal Space (PPS) Graph model is sufficient for early reaching and suggest that infants may use analogous models during this phase. In this paper, we show that the PPS Graph, with a simulated Palmar reflex (a reflex in infants that closes the fingers when the palm is touched), allows accidental grasps to occur during continued reaching practice. Given these occasional events, the agent can bootstrap to a simple deliberate grasp action. In particular, the agent must learn three new necessary conditions for a grasp: the hand should be open as the grasp begins, the final motion of the hand should be led by the gripper opening so that it reaches the target first, and the wrist must be oriented such that the gripper fingers may close around the target object, often requiring the opening to be perpendicular to the object's major axis. Combined with the existing capability to reach and interact with target objects, knowledge of these conditions allows the agent to learn increasingly reliable purposeful grasps. The first two conditions are addressed in this paper, and allow 45% of grasps to succeed. This work contributes toward the larger goal of foundational robot learning after the model of infant learning, with minimal prior knowledge of its own anatomy or its environment. The ability to grasp will allow the agent to control the motion and position of objects, providing a richer representation for its environment and new experiences to learn from.


Title: Impedance Control of a High Performance Twisted-Coiled Polymer Actuator
Abstract: This paper presents a 1-link robotic arm that is antagonistically driven by one pair of a high performance super-coiled polymer actuators with an embedded controller. The actuator which is made from Spandex and nylon fibers is low-cost, easy to fabricate and light-weight. Moreover, it can generate large displacement and provide Joule heating capability. The main contribution of the paper is the model-based impedance controller, which enables position control of the antagonistic joint with variable stiffness and damping. The impedance control is a torque-based law, which in turn depends on a proposed backstepping control law to control the force of each actuator. The control system is proved to be stable using dissipativity stability theory and verified through experiments. Experimental results show that our system can track the angular position reference with the worst position error of 0.43deg and root-mean squared error of 0.16deg at steady state for sinusoidal waveform tracking (with the frequency of 0.1Hz), and the worst position error of 0.2deg for set-point regulation.


Title: Jumping Motion Generation of a Humanoid Robot Utilizing Human-Like Joint Elasticity
Abstract: To improve the movement ability of humanoid robots, instead of traditional methods dependent on only power of actuators, there is possibility that utilizing elasticity inspired from collaboration of muscle and tendon of human is effective to achieve high-power movement. In this study, we aimed to realize a jumping motion that accumulates energy more appropriately in spring by combining active joint driving with spring behavior like human tendons and muscles. We proposed a countermovement jump method using the resonance with the leg's active pushing-off movement and leg stiffness. To achieve active pushing-off and joint stiffness, we developed a new joint mechanism using leaf springs and an actuator unit with a worm gear. We then performed experiments to evaluate the effectiveness of the proposed mechanism and methods. Finally, the robot achieved a countermovement jump using active kicking and leg's elasticity.


Title: Secure Data Recording and Bio-Inspired Functional Integrity for Intelligent Robots
Abstract: As modern robots become more intelligent, also their use will broaden in public and professional areas. While the aim is to make robots beneficial to humans and society, using those complex machines in complex environments will eventually lead to incidents. To enable forensic investigations, ethical evaluations and transparent function of intelligent robots in a society, we contribute the concept of a secure robot data recorder that is similar to a flight data recorder in airplanes. However, since robots work in a highly networked and uncontrolled environment, our concept pays special attention to security and tamper proofness. In addition, we extend the concept with an approach inspired by cockroaches to increase the functional integrity of the robot. We present a prototype implementation along with discussions on the required properties and limits of secure data recording.


Title: Master-Slave Coordination Using Virtual Constraints for a Redundant Dual-Arm Haptic Interface
Abstract: Programming robots for tasks involving force interaction is difficult, since both the knowledge of the task and the dynamics of the robots are necessary. An immersive haptic interface for task demonstration is proposed, where the operator can sense and act through the robot. This is achieved by coupling two robotic systems with virtual constraints such that they have the same coordinates in the operational space disregarding a fixed offset. Limitations caused by the singular configurations or the reach of the robots are naturally reflected to either side as haptic feedback.


Title: Gaussian Process Dynamic Programming for Optimizing Ungrounded Haptic Guidance
Abstract: Adapting robot actions to human motions can make human-robot interactions (HRI) more effective. Here, we aim to optimize guidance from haptic devices based on a user's response to produce better task performance. We used Gaussian processes to model the motions a human user made in response to applied torques from an ungrounded control moment gyroscope haptic device. We then used Gaussian process dynamic programming to generate optimized haptic cues to guide the user to rotate the device toward 3D targets. We compared the performance of naive and optimized policies in simulations and with a human user, and found that dynamic programming can significantly improve haptic guidance in cases where human responses are highly variable or inconsistent with the cued haptic direction.


Title: A Novel Input Device for Robotic Prosthetic Hand: Design and Preliminary Results
Abstract: In this paper, we propose a novel input device for a robotic prosthetic hand based on capacitance change. The proposed device can sense the deformation of the skin due to the activity of the muscle by measuring the capacitance change between the skin and the electrode. Therefore, it can be used as a sensor for estimating a user's intention through medical electrodiagnostic techniques such as electromyogram (EMG)and force myography (FMG). The proposed device can acquire data in a non-invasive way and is advantageous with easier data processing than that for an EMG signal. Moreover, it is resistant to the impedance change of skin because the capacitance is measured in a non-contact manner, unlike the existing methods which work with direct contact with the skin such as EMG. Additionally, unlike FMG, the device is lightly attached to the skin without being strongly fixed with velcro, which offsets problems that occur while re-wearing the device. To demonstrate the feasibility of the proposed idea, three of the newly developed input devices were used to classify four hand movements (fist, scissors, paper, and rest)using a multilayer perceptron (MLP). As a result, the classification success rates for the fist, paper, scissor, and rest motions were obtained as 99.3%, 98.3%, 98.4%, and 99.1%, respectively.


Title: Continuous State-Action-Observation POMDPs for Trajectory Planning with Bayesian Optimisation
Abstract: Decision making under uncertainty is a challenging task, especially when dealing with complex robotics scenarios. The Partially Observable Markov Decision Process (POMDP) framework, designed to solve this problem, was subject to much work lately. Most POMDP solvers, however, focus on planning in discrete state, action and/or observations spaces, which does not truly reflect the complexity of most real world problems. This paper addresses the issue by devising a method for solving POMDPs with continuous state, action and observations spaces. The proposed planner, Continuous Belief Tree Search (CBTS), uses Bayesian Optimisation (BO) to dynamically sample promising actions while constructing a belief tree. This dynamic sampling allows for richer action selection than offline action discretisation. CBTS is complemented by a novel trajectory generation technique, relying on the theory of Reproducing Kernel Hilbert Spaces (RKHS), yielding trajectories amenable for robotics applications. The resulting trajectory planner kCBTS outperforms other continuous planners on space modelling and robot parking problems.


