total paper: 300
Title: Real-time Convolutional Networks for Depth-based Human Pose Estimation
Key Words: convolutional neural nets  feature extraction  human-robot interaction  image colour analysis  inference mechanisms  learning (artificial intelligence)  pose estimation  convolutional neural networks models  human robot interaction  depth-based human pose estimation  pose inference  residual blocks  body landmark localization  depth imaging  human bodies  human detection  RGB images  Feature extraction  Pose estimation  Computational modeling  Three-dimensional displays  Shape  Detectors  Cameras 
Abstract: We propose to combine recent Convolutional Neural Networks (CNN) models with depth imaging to obtain a reliable and fast multi-person pose estimation algorithm applicable to Human Robot Interaction (HRI) scenarios. Our hypothesis is that depth images contain less structures and are easier to process than RGB images while keeping the required information for human detection and pose inference, thus allowing the use of simpler networks for the task. Our contributions are threefold. (i) we propose a fast and efficient network based on residual blocks (called RPM) for body landmark localization from depth images; (ii) we created a public dataset DIH comprising more than 170k synthetic images of human bodies with various shapes and viewpoints as well as real (annotated) data for evaluation; (iii) we show that our model trained on synthetic data from scratch can perform well on real data, obtaining similar results to larger models initialized with pre-trained networks. It thus provides a good trade-off between performance and computation. Experiments on real data demonstrate the validity of our approach.


Title: Estimating Metric Poses of Dynamic Objects Using Monocular Visual-Inertial Fusion
Key Words: augmented reality  cameras  feature extraction  image fusion  image sequences  mobile robots  object detection  object tracking  pose estimation  robot vision  state estimation  metric pose estimation  state estimation  3D tracking performance  tracking accuracy  correlation analysis-based metric scale estimator  2D object tracker  monocular camera  visual-inertial system  monocular sensing suite  scale observability  fixed multicamera  visual-inertial tracking system  arbitrary dynamic object  monocular 3D object tracking system  monocular visual-inertial fusion  dynamic objects  Cameras  Three-dimensional displays  Visualization  Estimation  Two dimensional displays  Tracking 
Abstract: A monocular 3D object tracking system generally has only up-to-scale pose estimation results without any prior knowledge of the tracked object. In this paper, we propose a novel idea to recover the metric scale of an arbitrary dynamic object by optimizing the trajectory of the objects in the world frame, without motion assumptions. By introducing an additional constraint in the time domain, our monocular visual-inertial tracking system can obtain continuous six degree of freedom (6-DoF) pose estimation without scale ambiguity. Our method requires neither fixed multi-camera nor depth sensor settings for scale observability, instead, the IMU inside the monocular sensing suite provides scale information for both camera itself and the tracked object. We build the proposed system on top of our monocular visual-inertial system (VINS) to obtain accurate state estimation of the monocular camera in the world frame. The whole system consists of a 2D object tracker, an object region-based visual bundle adjustment (BA), VINS and a correlation analysis-based metric scale estimator. Experimental comparisons with ground truth demonstrate the tracking accuracy of our 3D tracking performance while a mobile augmented reality (AR) demo shows the feasibility of potential applications.


Title: A modular framework for model-based visual tracking using edge, texture and depth features
Key Words: feature extraction  image colour analysis  image sensors  object tracking  modular framework  confidence index  multiple vision sensors  depth map  textured points  edge points  real-time model-based visual tracker  depth features  model-based visual tracking using edge  Cameras  Visualization  Solid modeling  Image edge detection  Three-dimensional displays  Sensors  Robustness 
Abstract: We present in this paper a modular real-time model-based visual tracker. It is able to fuse different types of measurement, that is, edge points, textured points, and depth map, provided by one or multiple vision sensors. A confidence index is also proposed for determining if the outputs of the tracker are reliable or not. As expected, experimental results show that the more various measurements are combined, the more accurate and robust is the tracker. The corresponding C++ source code is available for the community in the ViSP library.


Title: Optimized Contrast Enhancements to Improve Robustness of Visual Tracking in a SLAM Relocalisation Context
Key Words: cameras  feature extraction  image colour analysis  image enhancement  image representation  mobile robots  robot vision  SLAM (robots)  video signal processing  optimized contrast enhancements  visual tracking  SLAM relocalisation context  indirect SLAM techniques  robotics community  feature points  multilayered image representation  contrast enhanced version  tracking process  detection  matching  dynamic contrast enhancements  dynamic light changing conditions  ORB-SLAM  light changed condition  reference video  Mutual information  Lighting  Robustness  Simultaneous localization and mapping  Cameras  Entropy  Visualization 
Abstract: Robustness of indirect SLAM techniques to light changing conditions remains a central issue in the robotics community. With the change in the illumination of a scene, feature points are either not extracted properly due to low contrasts, or not matched due to large differences in descriptors. In this paper, we propose a multi-layered image representation (MLI) in which each layer holds a contrast enhanced version of the current image in the tracking process in order to improve detection and matching. We show how Mutual Information can be used to compute dynamic contrast enhancements on each layer. We demonstrate how this approach dramatically improves the robustness in dynamic light changing conditions on both synthetic and real environments compared to default ORB-SLAM. This work focalises on the specific case of SLAM relocalisation in which a first pass on a reference video constructs a map, and a second pass with a light changed condition relocalizes the camera in the map.


Title: Key-frame Selection for Multi-robot Simultaneous Localization and Tracking in Robot Soccer Field
Key Words: entropy  mobile robots  multi-robot systems  robot vision  SLAM (robots)  traditional key-frame selection algorithms  temporal relationship  spatial relationship  pre-defined field  information entropy  selection ratio  key-frames  localization results  robot soccer field  optical images  extensive computation resources  key-frame selection algorithm  multiple robots simultaneous localization  multirobot soccer games  Entropy  Robot sensing systems  Object detection  Sports  Cameras  Legged locomotion 
Abstract: Optical images provide rich features but require extensive computation resources to process for SLAM. When there are limited computation resources on the robots, it becomes a heavy burden to process the images in real-time. This paper presents the design and implementation of key-frame selection algorithm for multiple robots simultaneous localization and tracking on the multi-robot soccer games which have pre-defined field and objects. Compared to traditional key-frame selection algorithms, this work makes use of the temporal and spatial relationship among objects on the pre-defined field to compute the information entropy. The selection ratio can be adjusted by two parameters: entropy threshold and the maximum moving distance. The experimental results show that the developed method can effectively detect the change of scene using selected key-frames. And comparing with the localization results using all the images, using less than 20% of all images after walking 11,203mm it only increase up to 0.87% trajectory errors.


Title: Efficient Long-term Mapping in Dynamic Environments
Key Words: graph theory  mobile robots  robot vision  SLAM (robots)  mapping problem  longterm SLAM datasets  graph coherency  intra-session loop closure detections  out-dated nodes  graph complexity  nonstatic entities  merging procedure  efficient ICP-based alignment  up-to-date state  2D point cloud data  local maps  graph SLAM paradigm  multiple mapping sessions  single mapping sessions  SLAM system  autonomous robots  dynamic environments  long-term robot operation  Simultaneous localization and mapping  Cloud computing  Three-dimensional displays  Two dimensional displays  Merging  Optimization 
Abstract: As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.


Title: “Oh! I am so sorry!”: Understanding User Physiological Variation while Spoiling a Game Task
Key Words: computer games  human-robot interaction  psychology  Jenga game  galvanic skin response  psychological questionnaires  multiple GSR parameters  user physiological variation  game task  tower fall down  Poles and towers  Games  Collision avoidance  Physiology  Robot sensing systems 
Abstract: This paper investigates how individuals react in a situation when an experimenter (human or robot) either tells them to stop in the middle of playing the Jenga game, or accidentally bumps into a table and makes the tower fall down. The mood of the participants and different physiological parameters (i.e., galvanic skin response (GSR) and facial temperature variation) are extracted and analysed based on the condition, experimenter, and psychological questionnaires (i.e., TEQ, TEIQ, RST-PQ). This study was a between participants study with 23 participants. Our results show that multiple GSR parameters (e.g., latency, amplitude, number of peaks) differ significantly based on the condition and the experimenter the participants interacted with. The temperature variation in three regions of interest (i.e., forehead, left, and right periorbital regions) are good indicators of how ready an individual is to react in an unforeseen situation.


Title: An Extended Bayesian User Model (BUM) for Capturing Cultural Attributes with a Social Robot
Key Words: Bayes methods  belief networks  decision making  human-robot interaction  pattern classification  pattern clustering  service robots  user modelling  human-robot interaction  extended Bayesian User Model  social robotics  culture-awareness  specific subtleties  highly accurate classification framework  share similar attributes  n-dimensional semantic attribute space  capture unitary attributes  Bayesian classifiers  robotic technologies  latest advances  heterogeneous information  unified representation  cultural attributes  Robot sensing systems  Cultural differences  Bayes methods  Statistics  Indexes  Computational modeling  Culture Aware Social Robots  Robot Perception  Multimodal Human-Robot Interaction  User Models 
Abstract: In this work we propose a Bayesian User Model which is able capture a unified representation of cultural attributes from heterogeneous information in the context of Human-Robot Interaction. Despite the latest advances in robotic technologies, virtually no robots are able to cope with the specificities of the “modus vivendi” of different cultures. We start by proposing Bayesian classifiers to capture unitary attributes of different users, clustering them in a n-dimensional semantic attribute space, aggregating groups of persons that share similar attributes. Results show a highly accurate classification framework, both capable of detecting specific subtleties in user's properties, and generalizing them into representative profiles. We then discuss its application towards adapting the actions of a robot and its potential impact on culture-awareness, demonstrating how the proposed framework can enable culture-awareness, exploring this new frontier in social robotics.


Title: Trait-based Culture and its Organization: Developing a Culture Enabler for Artificial Agents
Key Words: artificial intelligence  multi-agent systems  social sciences computing  software agents  trait-based culture  culture enabler  artificial agent  human interests  human culture  trait types  trait module  Cultural differences  Global communication  Organizations  Knowledge based systems  Standards organizations  Intelligent robots  Buildings 
Abstract: Artificial agents might not understand human interests and actions if these agents cannot anticipate how a person understands a situation and, based on this, what could be his/her expectations. In many cases, understanding, expectations and behaviors are constrained, if not driven, by culture. Can we provide human culture to an artificial agent? Can we provide formal representations of different cultures? In this paper we discuss the (elusive) notion of culture and propose an approach based on the notion of trait which, we argue, allows building formal modules suitable to represent culture (broadly understood). We distinguish the trait types (knowledge, rule, behavior, interpretation) that such modules should contain and briefly discuss how they could be organized. Finally, we exemplify the role of a trait module in the flow of information internal to an agent highlighting surprising potentialities.


Title: CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism
Key Words: cultural aspects  face recognition  human-robot interaction  learning (artificial intelligence)  medical disorders  medical robotics  paediatrics  patient treatment  deep learning model  cultural backgrounds  image data  target culture  multicultural data  child-dependent settings  across-culture evaluations  target task  deep architecture  robot-assisted autism therapy  video data  automated engagement estimation  deep learning models  neu-rotypical peers  autism spectrum  engagement intensity estimation  face images  cultural differences  individual differences  estimation performance  model learning  target children  target engagement levels  poor estimation  child-independent models  Face  Autism  Deep learning  Estimation  Cultural differences  Task analysis  Robots 
Abstract: Many children on autism spectrum have atypical behavioral expressions of engagement compared to their neu-rotypical peers. In this paper, we investigate the performance of deep learning models in the task of automated engagement estimation from face images of children with autism. Specifically, we use the video data of 30 children with different cultural backgrounds (Asia vs. Europe) recorded during a single session of a robot-assisted autism therapy. We perform a thorough evaluation of the proposed deep architectures for the target task, including within- and across-culture evaluations, as well as when using the child-independent and child-dependent settings. We also introduce a novel deep learning model, named CultureNet, which efficiently leverages the multi-cultural data when performing the adaptation of the proposed deep architecture to the target culture and child. We show that due to the highly heterogeneous nature of the image data of children with autism, the child-independent models lead to overall poor estimation of target engagement levels. On the other hand, when a small amount of data of target children is used to enhance the model learning, the estimation performance on the held-out data from those children increases significantly. This is the first time that the effects of individual and cultural differences in children with autism have empirically been studied in the context of deep learning performed directly from face images.


Title: In pixels we trust: From Pixel Labeling to Object Localization and Scene Categorization
Key Words: image classification  image segmentation  object detection  pixels  image pixel labeling  object detection  pixel labeling  scene understanding  semantic segmentation mask  Semantics  Labeling  Image segmentation  Task analysis  Object detection  Histograms  Kernel 
Abstract: While there has been significant progress in solving the problems of image pixel labeling, object detection and scene classification, existing approaches normally address them separately. In this paper, we propose to tackle these problems from a bottom-up perspective, where we simply need a semantic segmentation of the scene as input. We employ the DeepLab architecture, based on the ResNet deep network, which leverages multi-scale inputs to later fuse their responses to perform a precise pixel labeling of the scene. This semantic segmentation mask is used to localize the objects and to recognize the scene, following two simple yet effective strategies. We evaluate the benefits of our solutions, performing a thorough experimental evaluation on the NYU Depth V2 dataset. Our approach achieves a performance that beats the leading results by a significant margin, defining the new state of the art in this benchmark for the three tasks comprising the scene understanding: semantic segmentation, object detection and scene categorization.


Title: Online inference of human belief for cooperative robots
Key Words: belief networks  cognition  cognitive systems  cooperative systems  human-robot interaction  inference mechanisms  interactive systems  mobile robots  multi-robot systems  online inference  natural interaction  human-human cooperation  model-based belief filter  human action  cognitive processes  perception  action selection  double inference process  environmental state  human-robot cooperation experiment  situation awareness  cognitive states  Task analysis  Robots  Manufacturing  Collaboration  Probability distribution  Estimation  Mathematical model 
Abstract: For human-robot cooperation, inferring a hu-man's cognitive state is very important for an efficient and natural interaction. Similar to human-human cooperation, understanding what the partner plans and knowing, if he is situation aware, is necessary to prevent collisions, offer support at the right time, correct mistakes before they happen or choose the best actions for oneself as early as possible. We propose a model-based belief filter to extract relevant aspects of a human's mental state online during cooperation. It performs inference based on human actions and its own task knowledge, modeling cognitive processes like perception and action selection. In contrast to most prior work, we explicitly estimate the human belief instead of inferring only a single mode or intention. Since this is a double inference process, we focus on representing the human estimates of environmental state and task as well as corresponding uncertainties. We designed a human-robot cooperation experiment that allowed for a variety of cognitive states of both agents and collected data to test and evaluate the proposed belief filter. The results are promising, as our system can be used to provide reasonable predictions of the human action and insights into his situation awareness. At the same time it is inferring interpretable information about the underlying cognitive states - A belief about the human's belief about the environment.


Title: An Omnidirectional Jumper with Expanded Movability via Steering, Self-Righting and Take-off Angle Adjustment
Key Words: biomechanics  mobile robots  steering shares  modified active triggering mechanism  jumping performance  expanded locomotion capabilities  angle adjustment  self-righting  expanded movability  omnidirectional jumper  Robots  Couplings  Gears  Windings  Pulleys  Wheels  Energy storage 
Abstract: In this paper, we propose an omnidirectional jumper with expanded locomotion capabilities. The mechanisms for four functions-jumping, steering, self-righting and take-off angle adjustment-are designed using only two motors to maximize the jumping performance. Jumping uses the modified active triggering mechanism with one motor. Steering shares this motor and uses the wheel touching the ground. The take-off angle is adjusted by changing the angle between the body and the foot using another motor. Self-righting is possible by utilizing combinations of the movements that occur in the energy storing and angle adjustment processes. With these four functions, the robot is capable of jumping in all directions and can jump anywhere in between the maximum height and maximum distance. It can also jump multiple times by self-righting. The robot, with a mass of 64.4 g, jumps up to 113 cm in vertical height, and 170 cm in horizontal distance. This robot can be deployed to explore various environments. Moreover, the design method to implement more functions than the number of motors can be applied to design other small-scale robots.


Title: An Origami-Inspired Flexible Pneumatic Actuator
Key Words: architecture  hinges  mechanical testing  plates (structures)  pneumatic actuators  prototypes  rapid prototyping (industrial)  shear modulus  three-dimensional printing  prototype  origami-inspired flexible pneumatic actuator design  multimaterial additive manufacturing process  mechanical testing  airtight chamber  flexible origami-inspired architecture  short stroke displacements  material resistance  flexible hinges  rigid plates  Actuators  Geometry  Prototypes  Shape  Soft robotics  Three-dimensional printing 
Abstract: This paper presents a new actuator designed to produce forces under short stroke displacements. Two variants of the prototype have been manufactured using Multi-Material Additive Manufacturing process, based on a flexible origami-inspired architecture. The structure consists of an airtight chamber constituted by rigid plates combined with flexible hinges and surfaces in order to allow the generation of motion. We propose several insights on integration issues such as limited material resistance and maximum range of motion. Both versions of the prototype are then tested to assess their performances for single strokes and cyclic loading.


Title: Design and Development of Biaxial Active Nozzle with Flexible Flow Channel for Air Floating Active Scope Camera
Key Words: buckling  cameras  deformation  design engineering  jets  mobile robots  motion control  nozzles  pneumatic actuators  position control  service robots  shapes (structures)  flexible robot  shape deformation  air floating active scope camera  pneumatic actuators  geometric parameters  ASC  rescue operations  reaction force direction  flexible air tube  air jet direction  head motion  flexible flow channel  biaxial active nozzle  Electron tubes  Robots  Force  Shape  Cameras  Strain  Pneumatic systems 
Abstract: Long flexible continuum robots have a high potential for search and rescue operations that explore deep layered debris. A general problem of these robots is in the control of the head motion because their thin bodies limit the space available to mount multiple actuators. This paper develops a biaxial active nozzle which can rotate the air jet direction along a roll and pitch axis in order to control the direction of reaction force and the head motion of a long flexible robot. A major challenge is how to change the air jet direction without a large resistance to the flow, which reduces the reaction force induced by the air jet. We propose a nozzle whose outlet is connected with a flexible air tube. The direction of the air jet is controlled by the smooth shape deformation of the tube. The nozzle should be compact enough to be installed on a thin robot, although the shape deformation of the tube may cause buckling. The flexible tube is modeled and simulated by a multiple link model used to derive the geometric parameters of the nozzle so that the nozzle is compact and the tube does not buckle. Based on the derived parameters, the biaxial active nozzle was developed. A basic performance experiment shows that the nozzle can change the reaction force direction by deforming the tube shape, while the magnitude of the reaction force is almost constant. We integrated the proposed nozzle with a conventional Active Scope Camera (ASC). The range where the robot can look around in a vertical exploration was significantly improved, which was three times larger than the previous ASC whose head was controlled by pneumatic actuators. The rubble field test demonstrates that the integrated ASC could move over rubble (maximum height of 200 mm) and steer the course.


Title: A Unified Controller for Region-reaching and Deforming of Soft Objects
Key Words: cameras  closed loop systems  deformation  end effectors  manipulators  mobile robots  robot vision  stability  uncertain deformation model  active deformable object manipulation  unified controller  soft objects  robotic manipulation  robot control  region reaching  region deforming  uncalibrated cameras  closed-loop system stability  end-effector  Strain  Deformable models  Cameras  End effectors  Robot vision systems  Adaptation models 
Abstract: Emerging applications of robotic manipulation of deformable objects have opened up new challenges in robot control. While several control techniques have been developed to manipulate deformable objects, the performance of existing methods is commonly limited by two issues: 1) implicit assumption that the physical contact between the end-effector and the object is always maintained, and 2) requirements of exact parameters of deformation model, which are difficult to obtain. This paper presents a new control scheme for robotic manipulation of deformable objects, which allows the robot to automatically contact then actively deform the deformable object by assessing the status of deformation in real time. Instead of designing multiple controllers and switching among them, the proposed method smoothly and stably integrates two control phases (i.e. region reaching and active deforming) into a single controller. The stability of the closed-loop system is rigorously proved with the consideration of the uncertain deformation model and uncalibrated cameras. Hence, the proposed control scheme enhances the autonomous capability of active deformable object manipulation. Experimental studies are conducted with different initial conditions to demonstrate the performance of the proposed controller.


Title: Dual-arm robotic manipulation of flexible cables
Key Words: cables (mechanical)  deformation  Fourier series  manipulator dynamics  manipulators  mobile robots  multi-robot systems  position control  velocity control  arm robotic manipulation  flexible cables  trivial task  multiple robot manipulators  local deformation model  shape parameters  dual-arm manipulator  cable shape manipulation  Shape  Strain  Power cables  Deformable models  Manipulators  Task analysis 
Abstract: Deforming a cable to a desired (reachable) shape is a trivial task for a human to do without even knowing the internal dynamics of the cable. This paper proposes a framework for cable shapes manipulation with multiple robot manipulators. The shape is parameterized by a Fourier series. A local deformation model of the cable is estimated on-line with the shape parameters. Using the deformation model, a velocity control law is applied on the robot to deform the cable into the desired shape. Experiments on a dual-arm manipulator are conducted to validate the framework.


Title: Capturing Deformations of Interacting Non-rigid Objects Using RGB-D Data
Key Words: computational geometry  finite element analysis  image colour analysis  image registration  image segmentation  image sequences  segmented point clouds  collision detection  joint registration framework  RGB-D sensor  point cloud data  elastic deformations  RGB-D data  interacting nonrigid objects  FEM elastic model  geometrical point-to-point correspondences  ICP algorithm  rigid transformations  RGB images  visual segmentation  Strain  Three-dimensional displays  Finite element analysis  Deformable models  Computational modeling  Collision avoidance  Visualization 
Abstract: This paper presents a method for tracking multiple interacting deformable objects undergoing rigid motions, elastic deformations and contacts, using image and point cloud data provided by an RGB-D sensor. A joint registration frame-work is proposed, based on physical Finite Element Method (FEM) elastic and interaction models. It first relies on a visual segmentation of the considered objects in the RGB images. The different segmented point clouds are then processed to estimate rigid transformations with on an ICP algorithm, and to determine geometrical point-to-point correspondences with the meshes. External forces resulting from these correspondences and between the current and the rigidly transformed mesh can then be derived. It provides both non-rigid and rigid data cues. A classical collision detection and response model is also integrated, giving contact forces between the objects. The deformations of the objects are estimated by solving a dynamic system balancing these external and contact forces with the internal or regularization forces computed through the FEM elastic model. This approach has been here tested on different scenarios involving two or three interacting deformable objects of various shapes, with promising results.


Title: A Series Elastic Tactile Sensing Array for Tactile Exploration of Deformable and Rigid Objects
Key Words: elasticity  manipulators  position control  tactile sensors  deformable objects  rigid objects  series elastic elements  sixteen compliant sensing elements  position-controlled robot manipulator  series elastic tactile array  contact location  tactile arrays  multiple sensing elements  vision-based sensors  robotic systems  tactile sensing arrays  tactile exploration  series elastic tactile sensing array  Magnetic sensors  Pins  Tactile sensors  Saturation magnetization 
Abstract: Tactile sensing arrays are used to detect contacts of robotic systems with the environment. They are particularly useful for scenarios in which vision-based sensors cannot be used. Thanks to the presence of multiple sensing elements, tactile arrays also provide spatial information about the contact location. In this work, we present our series elastic tactile array to enable tactile exploration for position-controlled robot manipulators. Sixteen compliant sensing elements are arranged as a 4×4 array. This allows the position-controlled robot to explore objects via palpation. Tactile sensing was accomplished by measuring the change of the magnetic field caused by neodymium magnets embedded into the series elastic elements. We demonstrate the efficacy of our sensor with two sets of experiments involving physical interaction scenarios. Firstly, we show that the sensor can be used to differentiate between rigid and deformable objects. Secondly, we show that point clouds of objects can be generated quickly with our sensor module attached to a position-controlled robot manipulator as an end-effector.


Title: City-Scale Road Audit System using Deep Learning
Key Words: Global Positioning System  image segmentation  learning (artificial intelligence)  roads  traffic engineering computing  image tagging  GPS  multistep deep learning  road networks  city-scale road audit system  label hierarchy  road defects  semantic segmentation  Roads  Image segmentation  Semantics  Deep learning  Global Positioning System  Cameras  Real-time systems 
Abstract: Road networks in cities are massive and is a critical component of mobility. Fast response to defects, that can occur not only due to regular wear and tear but also because of extreme events like storms, is essential. Hence there is a need for an automated system that is quick, scalable and cost-effective for gathering information about defects. We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation. For building and benchmarking the system, we curated a dataset which has annotations required for road defects. However, many of the labels required for road audit have high ambiguity which we overcome by proposing a label hierarchy. We also propose a multi-step deep learning model that segments the road, subdivide the road further into defects, tags the frame for each defect and finally localizes the defects on a map gathered using GPS. We analyze and evaluate the models on image tagging as well as segmentation at different levels of the label hierarchy.


Title: Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  closed loop systems  computational complexity  hydrophones  inertial navigation  marine navigation  mobile robots  particle filtering (numerical methods)  position control  localization  autonomous underwater vehicles  Doppler velocity log  positional error  acoustic beacon  DVL-aided INS  LBL system  SandShark AUV  underwater navigation  computational complexity  phased-array beamforming  closed-loop operation  particle filter  vehicle-mounted passive hydrophone receiver-array  multiAUV operations  power requirements  inertial navigation system  robotic vehicle  Acoustics  Navigation  Array signal processing  Receivers  Acoustic measurements  Transponders  Time-frequency analysis 
Abstract: Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.


Title: Unscented Kalman Filter on Lie Groups for Visual Inertial Odometry
Key Words: distance measurement  Kalman filters  Lie groups  nonlinear filters  SLAM (robots)  state estimation  stereo image processing  unscented Kalman filter  Lie groups  visual information  inertial measurements  state estimation  robust estimation  computational efficiency  low-cost aerial vehicles  processor power  innovative filter  stereo visual inertial odometry building  invariant filtering theory  computational complexity  stereo multistate constraint Kalman filter  EuRoC dataset  MAV outdoor dataset  Cameras  Kalman filters  Visualization  Computational modeling  Uncertainty  Robustness  Noise measurement  Lie groups  unscented Kalman filter  visual inertial odometry  aerial vehicle  localization 
Abstract: Fusing visual information with inertial measurements for state estimation has aroused major interests in recent years. However, combining a robust estimation with computational efficiency remains challenging, specifically for low-cost aerial vehicles in which the quality of the sensors and the processor power are constrained by size, weight and cost. In this paper, we present an innovative filter for stereo visual inertial odometry building on: (i) the recently introduced stereo multistate constraint Kalman filter; (ii) the invariant filtering theory; and (iii) the unscented Kalman filter (UKF) on Lie groups. Our solution combines accuracy, robustness and versatility of the UKF. We then compare our approach to state-of-art solutions in terms of accuracy, robustness and computational complexity on the EuRoC dataset and a challenging MAV outdoor dataset.


Title: A Multi-Position Joint Particle Filtering Method for Vehicle Localization in Urban Area
Key Words: distance measurement  image matching  mobile robots  particle filtering (numerical methods)  path planning  probability  robot vision  flexible multiposition joint particle filtering  position error  anchor point  curving roads  ego-trajectory  probabilistic filtering method  flexible road map  long range navigation  error accumulation  visual odometry  traditional visual localization methods  autonomous vehicles  robust localization  urban area  vehicle localization  dense parallel road branches  Roads  Trajectory  Filtering  Urban areas  Wheels  Simultaneous localization and mapping  Navigation 
Abstract: Robust localization is a prerequisite for autonomous vehicles. Traditional visual localization methods like visual odometry suffer error accumulation on long range navigation. In this paper, a flexible road map based probabilistic filtering method is proposed to tackle this problem. To effectively match the ego-trajectory to various curving roads in map, a new representation based on anchor point (AP) which captures the main curving points on the trajectory is presented. Based on APs of the map and trajectory, a flexible Multi-Position Joint Particle Filtering (MPJPF) framework is proposed to correct the position error. The method features the capability of adaptively estimating a series of APs jointly and only updates the estimation at situations with low uncertainty. It explicitly avoids the drawbacks of obliging to determine the current position at large uncertain situations such as dense parallel road branches. The experiments carried out on KITTI benchmark demonstrate our success.


Title: Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP
Key Words: automobiles  cameras  iterative methods  laser ranging  mobile robots  motion estimation  optical scanners  pose estimation  sensor fusion  SLAM (robots)  joint ego-motion estimation  laser scanner  monocular camera  autonomous vehicles  SLAM algorithms  sensor suite  laser range finder  3D point clouds  iterative closest point problem  sensor modality  orientation estimation  autonomous cars  pose estimation  autonomous robots  1-DoF ICP  data association  Cameras  Iterative closest point algorithm  Lasers  Three-dimensional displays  Robot vision systems  Image color analysis 
Abstract: Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.


Title: Unsupervised Trajectory Segmentation and Promoting of Multi-Modal Surgical Demonstrations
Key Words: feature extraction  image segmentation  medical robotics  robot kinematics  surgery  unsupervised learning  video signal processing  wavelet transforms  multimodal surgical demonstrations  surgical trajectory segmentation  robot learning  robot-assisted minimally invasive surgery  kinematic data  over-segmentation issue  unsupervised deep learning network  convolutional auto-encoder  videos  unsupervised trajectory segmentation method  JIGSAWS dataset  wavelet transform  feature extraction  Kinematics  Feature extraction  Surgery  Trajectory  Convolution  Visualization  Wavelet transforms 
Abstract: To improve the efficiency of surgical trajectory segmentation for robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. Unsupervised deep learning network, stacking convolutional auto-encoder, is employed to extract more discriminative features from videos in an effective way. To further improve the accuracy of segmentation, on one hand, wavelet transform is used to filter out the noises existed in the features from video and kinematic data. On the other hand, the segmentation result is promoted by identifying the adjacent segments with no state transition based on the predefined similarity measurements. Extensive experiments on a public dataset JIGSAWS show that our method achieves much higher accuracy of segmentation than state-of-the-art methods in the shorter time.


Title: Autonomous Localization, Navigation and Haustral Fold Detection for Robotic Endoscopy
Key Words: biological organs  biomedical optical imaging  cancer  endoscopes  medical image processing  medical robotics  surgery  autonomous localization  Haustral fold detection  robotic endoscopy  capsule endoscopes  minimally invasive devices  gastrointestinal abnormalities  colorectal cancer  real-time navigation system  observational devices  autonomous navigation  single minimally invasive device  vision system  autonomous lumen center tracking  haustral fold identification  multiple haustral folds  robotic endoscope platform  active simulator  real-time localization  center tracking algorithm  colonoscopy  in vivo video  surgical tools  mobility system  Endoscopes  Robot sensing systems  Colon  Navigation  Wheels  In vivo 
Abstract: Capsule endoscopes have gained popularity over the last decade as minimally invasive devices for diagnosing gastrointestinal abnormalities such as colorectal cancer. While this technology offers a less invasive and more convenient alternative to traditional scopes, these capsules are only able to provide observational capabilities due to their passive nature. With the addition of a reliable mobility system and a real-time navigation system, capsule endoscopes could transform from observational devices into active surgical tools, offering biopsy and therapeutic capabilities and even autonomous navigation in a single minimally invasive device. In this work, a vision system is developed to allow for autonomous lumen center tracking and haustral fold identification and tracking during colonoscopy. This system is tested for its ability to accurately identify and track multiple haustral folds across many frames in both simulated and in vivo video, and the lumen center tracking is tested onboard a robotic endoscope platform (REP) within an active simulator to demonstrate autonomous navigation. In addition, real-time localization is demonstrated using open source ORB-SLAM2. The vision system successfully identified 95.6% of Haustral folds in simulator frames and 70.6% in in vivo frames and false positives occurred in less than 1% of frames. The center tracking algorithm showed in vivo center estimates within a mean error of 6.6% of physician estimates and allowed for the REP to traverse 2 m of the active simulator in 6 minutes without intervention.


Title: Modeling Supervisor Safe Sets for Improving Collaboration in Human-Robot Teams
Key Words: cognition  human-robot interaction  mobile robots  multi-robot systems  optimisation  reachability analysis  human-robot teams  human supervisor collaborates  optimization  reachability theory  robots dynamic  robot behavior  human behavior  cognitive resources  Robots  Safety  Trajectory  Level set  Noise measurement  Optimal control  Optimization 
Abstract: When a human supervisor collaborates with a team of robots, the human's attention is divided, and cognitive resources are at a premium. We aim to optimize the distribution of these resources and the flow of attention. To this end, we propose the model of an idealized supervisor to describe human behavior. Such a supervisor employs a potentially inaccurate internal model of the the robots' dynamics to judge safety. We represent these safety judgements by constructing a safe set from this internal model using reachability theory. When a robot leaves this safe set, the idealized supervisor will intervene to assist, regardless of whether or not the robot remains objectively safe. False positives, where a human supervisor incorrectly judges a robot to be in danger, needlessly consume supervisor attention. In this work, we propose a method that decreases false positives by learning the supervisor's safe set and using that information to govern robot behavior. We prove that robots behaving according to our approach will reduce the occurrence of false positives for our idealized supervisor model. Furthermore, we empirically validate our approach with a user study that demonstrates a significant (p = 0.0328) reduction in false positives for our method compared to a baseline safety controller.


Title: PRISM: Pose Registration for Integrated Semantic Mapping
Key Words: mobile robots  multi-robot systems  navigation  pose estimation  service robots  SLAM (robots)  computer science department  modern SLAM algorithms  map data  tedious manual process  automatically generated maps  PRISM  semantic markup  pose registration  integrated semantic  robotics applications  hotel  room service  hospital  medication  patient  UT Austin  autonomous mobile robots  BWIBots  building-wide intelligence project  Robots  Semantics  Three-dimensional displays  Cameras  Two dimensional displays  Computational modeling  Navigation 
Abstract: Many robotics applications involve navigating to positions specified in terms of their semantic significance. A robot operating in a hotel may need to deliver room service to a named room. In a hospital, it may need to deliver medication to a patient's room. The Building-Wide Intelligence Project at UT Austin has been developing a fleet of autonomous mobile robots, called BWIBots, which perform tasks in the computer science department. Tasks include guiding a person, delivering a message, or bringing an object to a location such as an office, lecture hall, or classroom. The process of constructing a map that a robot can use for navigation has been simplified by modern SLAM algorithms. The attachment of semantics to map data, however, remains a tedious manual process of labeling locations in otherwise automatically generated maps. This paper introduces a system called PRISM to automate a step in this process by enabling a robot to localize door signs - a semantic markup intended to aid the human occupants of a building - and to annotate these locations in its map.


Title: 3D Deep Object Recognition and Semantic Understanding for Visually-Guided Robotic Service
Key Words: Bayes methods  convolutional neural nets  feature extraction  image reconstruction  learning (artificial intelligence)  neurocontrollers  object recognition  ontologies (artificial intelligence)  robot vision  service robots  semantic understanding  visually-guided robotic service  visually-guided robotic errand service  visual environments  deep learning architecture  FER-CNN  layer-wise independent feedback connections  reconstructed features  object categories  3D daily-life objects  recognition rate  ontology  feature extraction  3D deep object recognition  adaptive Bayesian recognition framework  Three-dimensional displays  Bayes methods  Robots  Object recognition  Deep learning  Feature extraction  Two dimensional displays 
Abstract: For the success of visually-guided robotic errand service, it is critical to ensure dependability under various ill-conditioned visual environments. To this end, we have developed Adaptive Bayesian Recognition Framework in which in-situ selection of multiple sets of optimal features or evidences as well as proactive collection of sufficient evidences are proposed to implement the principle of dependability. The framework has shown excellent performance with a limited number of objects in a scene. However, there arises a need to extend the framework for handling a larger number of objects without performance degradation, while avoiding difficulty in feature engineering. To this end, a novel deep learning architecture, referred to here as FER-CNN, is introduced and integrated into the Adaptive Bayesian Recognition Framework. FER-CNN has capability of not only extracting but also reconstructing a hierarchy of features with the layer-wise independent feedback connections that can be trained. Reconstructed features representing parts of 3D objects then allow them to be semantically linked to ontology for exploring object categories and properties. Experiments are conducted in a home environment with real 3D daily-life objects as well as with the standard ModelNet dataset. In particular, it is shown that FER-CNN allows the number of objects and their categories to be extended by 10 and 5 times, respectively, while registering the recognition rate for ModelNet10 and ModelNet40 by 97% and 89.5%, respectively.


Title: A Differential Elastic Joint for Multi-linked Pipeline Inspection Robots
Key Words: actuators  elasticity  inspection  mobile robots  pipelines  pipes  rubber  service robots  springs (mechanical)  bi-directional series elasticity  series elastic actuators  slippery inner surfaces  vertical pipes  pipe wall  multilinked pipeline inspection robots  differential elastic joint  differential elastic actuator  active joint  in-pipe inspections  Springs  Gears  Torque  Robots  Wheels  Inspection  Actuators 
Abstract: This study presents a differential elastic joint for use in multi-linked pipeline inspection robots. Active joints to stretch against the pipe wall are essential for adapting robots to use in vertical pipes and slippery inner surfaces where a large traction force is required. Series elastic actuators with a high reduction system have typically been used to sense force/torque in such applications. However, compactness, power, and bi-directional series elasticity are required to conduct in-pipe inspections. In this study, we propose an active joint using a differential elastic actuator with a rubber spring for decreasing the size and increasing the stiffness of the joint. After describing the configuration of the differential elastic actuator that is suitable for our robot and the design theory of the rubber spring cross-section, we conducted experiments to verify its torque property.


Title: A Novel Design of Extended Coaxial Spherical Joint Module for a New Modular Type-Multiple DOFs Robotic Platform
Key Words: actuators  biomechanics  motion control  robot dynamics  robot kinematics  torque  design constraints  mechanical impedance reduction effect  E-CoSMo  extended coaxial spherical joint module  robot platform  coaxial spherical parallel mechanism  universal joint mechanism  mechanical performance  modular type-multiple DOFs robotic platform  single actuator  Conferences  Intelligent robots 
Abstract: In this study, we propose an extended coaxial spherical joint module (E-CoSMo) with three to four degrees of freedom (DOFs) for a multi-DOF robot platform. The E-CoSMo consists of a coaxial spherical parallel mechanism (CSPM) with three DOFs and one extended DOF based on a universal joint mechanism (UJM) coaxially connected to the CSPM. This structure enables the application of serial link configuration (such as shoulder-elbow) with wide and universal ROMs while allowing all four actuators to be placed in the base. This makes the inertia of the moving link part to be dramatically reduced and thus contributes to decreasing the mechanical impedance of the multi-DOF robot system. In addition, through the effective design of the coaxial spherical joint module, the output rotational torque in a specific axial direction reaches approximately three times then the torque of a single actuator. To optimally implement this, we applied an optimal design approach that considers the mechanical performance and design constraints. The mechanical impedance reduction effect through the proposed module is discussed. The feasibility of the E-CoSMo is also verified through a dynamic simulation. Finally, the proposed mechanism is verified using a fabricated prototype.


Title: Stopper Angle Design for a Multi-link Articulated Wheeled In-pipe Robot with Underactuated Twisting Joints
Key Words: actuators  design engineering  drives  gears  mobile robots  motion control  pipes  robot kinematics  wheels  roll joint  single actuator  drive wheel  miter-geared differential mechanism  rear wheels  joint movement  helical movement  kinematic model  multilink articulated wheeled in-pipe robot  underactuated twisting joints  stopper angle design  roll angle  Mobile robots  Wheels  Robot kinematics  Kinematics  Pipelines  Actuators 
Abstract: In this paper, we present a multi-link articulated wheeled in-pipe robot that can drive the wheel and roll joint by using only a single actuator installed in each link. The proposed mechanism enables the robot to move forward or backward and helically in pipes owing to rotation of the drive wheel and twisting of the body. These two movements are generated by a miter-geared differential mechanism installed in each joint, and the magnitudes of these movements depend on the load applied to the wheels and roll joints. However, controlling of two outputs independently and aligning the rotation of the roll joints as desired are extremely challenging. Therefore, in this study, we switch those two movements by driving the rear wheels and the front wheels of the robot alternately. In addition, a stopper is used to constrain the roll joint movement. By calculating the angle of elevation of the robot's helical movement in the pipe by using a kinematic model, we can design a stopper to precisely adjust the roll angle. We verified that the robot can twist using the differential mechanism, and we validated experimentally the effectiveness of the stopper.


Title: Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning
Key Words: aerospace computing  aerospace robotics  aircraft control  control engineering computing  gradient methods  helicopters  learning (artificial intelligence)  mobile robots  robot vision  visual servoing  deep reinforcement learning algorithm  deep deterministic policy gradients  image-based visual servoing controller  IBVS policy  linear velocity commands  multirotor aerial robots  simulated flight scenarios  Gazebo-based simulation scenario  RL-IBVS controller  Visual servoing  Reinforcement learning  Unmanned aerial vehicles  Task analysis  Detectors  Cameras 
Abstract: In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.


Title: A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform
Key Words: attitude control  autonomous aerial vehicles  continuous systems  helicopters  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  robot vision  state-space methods  deep learning techniques  deep deterministic policy gradients algorithm  motion control  deep Q- learning  active domain  robotics-related tasks  multirotor control  attitude control  state space  continuous action space  deep reinforcement learning technique  vision-based autonomous multirotor landing maneuver  continuous state  continuous action domain  moving platform  Reinforcement learning  Unmanned aerial vehicles  Robots  Cameras  Aerospace electronics  Neural networks  Task analysis 
Abstract: Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.


Title: Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning
Key Words: autonomous aerial vehicles  collision avoidance  learning (artificial intelligence)  mobile robots  traditional motion planning algorithms  precise maps  fast reactive navigation algorithm  multirotor aerial robots  2D-laser range measurements  Gazebo-based simulation scenario  artificial potential field formulation  laser-based reactive navigation  collision avoidance capabilities  reactive navigation behavior  deep reinforcement learning  dynamic obstacles  static obstacles  Navigation  Robots  Unmanned aerial vehicles  Lasers  Heuristic algorithms  Reinforcement learning  Planning 
Abstract: Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.


Title: Drone Detection Using Depth Maps
Key Words: autonomous aerial vehicles  collision avoidance  image sensors  learning (artificial intelligence)  mobile robots  object detection  static obstacle avoidance  dynamic objects  field-of-view requirements  on-board small UAVs  relative altitude  azimuth  depth map-based approach  collision avoidance  depth map sequences  unmanned aerial vehicle navigation  collision-free path planning  FOV  deep learning-based drone detection model  sensing technologies  3D localization  Drones  Cameras  Three-dimensional displays  Atmospheric modeling  Sensors  Neural networks  Two dimensional displays 
Abstract: Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV) navigation. While solutions have been proposed for static obstacle avoidance, systems enabling avoidance of dynamic objects, such as drones, are hard to implement due to the detection range and field-of-view (FOV) requirements, as well as the constraints for integrating such systems on-board small UAVs. In this work, a dataset of 6k synthetic depth maps of drones has been generated and used to train a state-of-the-art deep learning-based drone detection model. While many sensing technologies can only provide relative altitude and azimuth of an obstacle, our depth map-based approach enables full 3D localization of the obstacle. This is extremely useful for collision avoidance, as 3D localization of detected drones is key to perform efficient collision-free path planning. The proposed detection technique has been validated in several real depth map sequences, with multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7 %, an average recall of 74.7 % and a record detection range of 9.5 meters.


Title: Leveraging Convolutional Pose Machines for Fast and Accurate Head Pose Estimation
Key Words: face recognition  feature extraction  feedforward neural nets  learning (artificial intelligence)  multilayer perceptrons  object detection  pose estimation  appearance information  keypoint relationships  convolutional neural networks  multilayer perceptrons  keypoint detection model  CPM  head pose estimation  facial keypoint features  estimation framework  convolutional pose machines  Magnetic heads  Pose estimation  Face  Feature extraction  Nose  Ear 
Abstract: We propose a head pose estimation framework that leverages on a recent keypoint detection model. More specifically, we apply the convolutional pose machines (CPMs) to input images, extract different types of facial keypoint features capturing appearance information and keypoint relationships, and train multilayer perceptrons (MLPs) and convolutional neural networks (CNNs) for head pose estimation. The benefit of leveraging on the CPMs (which we apply anyway for other purposes like tracking) is that we can design highly efficient models for practical usage. We evaluate our approach on the Annotated Facial Landmarks in the Wild (AFLW) dataset and achieve competitive results with the state-of-the-art.


Title: Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision
Key Words: autonomous aerial vehicles  convolutional neural nets  image classification  learning (artificial intelligence)  mobile robots  path planning  probability  random processes  robot vision  target tracking  online search tasks  multitarget environments  dynamic targets  UAV-like vision  deep learning  dynamic search  strategic explorational agency  single deep network  navigational actions  dual-stream classification paradigm  sensory processing  agent location  static evolutions  dynamic evolutions  probabilistic placement  fully random target walks  herd-inspired behaviours  dual-stream architecture  unmanned aerial vehicle  convolutional neural network  multitarget behaviour classes  optimal navigational decision samples  long term map memory  Navigation  Robot sensing systems  Task analysis  History  Visualization  Vehicle dynamics  Reinforcement learning 
Abstract: This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish3 key source code and associated models.


Title: Hybrid Multi-camera Visual Servoing to Moving Target
Key Words: cameras  image sensors  position control  robot vision  stereo image processing  tracking  visual servoing  hybrid multicamera visual servoing  moving target  robotics  multiple visual sources  visual servoing approach  hybrid multicamera input data  robot arm  RGBD sensors  arm-mounted stereo camera  Eye-in-Hand  EtoH cameras  EinH sensor  EtoH sensors  adaptive visual input data  eye-to-hand visual input  Three-dimensional displays  Cameras  Visualization  Robot vision systems 
Abstract: Visual servoing is a well-known task in robotics. However, there are still challenges when multiple visual sources are combined to accurately guide the robot or occlusions appear. In this paper we present a novel visual servoing approach using hybrid multi-camera input data to lead a robot arm accurately to dynamically moving target points in the presence of partial occlusions. The approach uses four RGBD sensors as Eye-to-Hand (EtoH) visual input, and an arm-mounted stereo camera as Eye-in-Hand (EinH). A Master supervisor task selects between using the EtoH or the EinH, depending on the distance between the robot and target. The Master also selects the subset of EtoH cameras that best perceive the target. When the EinH sensor is used, if the target becomes occluded or goes out of the sensor's view-frustum, the Master switches back to the EtoH sensors to re-track the object. Using this adaptive visual input data, the robot is then controlled using an iterative planner that uses position, orientation and joint configuration to estimate the trajectory. Since the target is dynamic, this trajectory is updated every time-step. Experiments show good performance in four different situations: tracking a ball, targeting a bulls-eye, guiding a straw to a mouth and delivering an item to a moving hand. The experiments cover both simple situations such as a ball that is mostly visible from all cameras, and more complex situations such as the mouth which is partially occluded from some of the sensors.


Title: Detecting and Picking of Folded Objects with a Multiple Sensor Integrated Robot Hand
Key Words: control engineering computing  dexterous manipulators  image recognition  object detection  pressure sensors  robot vision  folded object  robotic picking  Suction Pinching Hand  proximity sensors  multiple sensor integrated robot hand  trial-and-error picking system  suction grasp  flex sensors  air pressure sensor  image recognition  Robot sensing systems  Uncertainty  Image recognition  Grippers  Hardware 
Abstract: Robotic picking of folded objects such as books is required for picking various objects. As a folded object is easily unfolded, it is difficult to carry it stably and place it in a desired pose due to its dangling part. For overcoming this difficulty, we propose a trial-and-error picking system using our Suction Pinching Hand, which can push the dangling part up with pinch grasp until the object lifted with suction grasp is folded. That system utilizes proximity sensors on the hand to predict whether folding will succeed with a current hand pose and decide whether to retry with another pose. Also, proximity sensors, flex sensors and an air pressure sensor are used to deal with uncertainty of the image recognition, the hand hardware and suction grasp. We evaluate our proposed system with experiments of picking and placing folded objects. It is confirmed that our proposed system realizes picking with the ability of our Suction Pinching Hand to carry folded objects stably and place them in desired poses. It is also proved that our proposed system is robust against the uncertainty.


Title: Towards Robust Visual Odometry with a Multi-Camera System
Key Words: cameras  distance measurement  image sampling  minimisation  photometry  pose estimation  position measurement  stereo image processing  robust visual odometry algorithm  robust VO algorithm  current pose tracker estimation  photometric error minimisation  plane-sweeping stereo cameras  near-infrared illumination  NIR illumination  single stereo configuration  multicamera setup  sliding window optimizer  sampled feature points  local mapper  multicamera system  Cameras  Tracking  Lighting  Visual odometry  Robot vision systems  Robustness  Simultaneous localization and mapping 
Abstract: We present a visual odometry (VO) algorithm for a multi-camera system and robust operation in challenging environments. Our algorithm consists of a pose tracker and a local mapper. The tracker estimates the current pose by minimizing photometric errors between the most recent keyframe and the current frame. The mapper initializes the depths of all sampled feature points using plane-sweeping stereo. To reduce pose drift, a sliding window optimizer is used to refine poses and structure jointly. Our formulation is flexible enough to support an arbitrary number of stereo cameras. We evaluate our algorithm thoroughly on five datasets. The datasets were captured in different conditions: daytime, night-time with near-infrared (NIR) illumination and nighttime without NIR illumination. Experimental results show that a multi-camera setup makes the VO more robust to challenging environments, especially night-time conditions, in which a single stereo configuration fails easily due to the lack of features.


Title: A robust pose graph approach for city scale LiDAR mapping
Key Words: graph theory  image filtering  image reconstruction  Kalman filters  mobile robots  nonlinear filters  optical radar  optimisation  pose estimation  radar imaging  robot vision  SLAM (robots)  map quality  quantitative experimental results  robust optimization strategy  systematical initialization bias  factor graph  refined structure  urban environments  multitask acquisitions  scan-matching factors  graph optimization  cumulative drift  city scale LiDAR mapping  robust pose graph approach  Optimization  Three-dimensional displays  Laser radar  Global Positioning System  Feature extraction  Sensors  Urban areas 
Abstract: This paper presents a method for reconstructing globally consistent 3D High-Definition (HD) maps at city scale. Current approaches for eliminating cumulative drift are mainly based on the pose graph optimization under the constraint of scan-matching factors. The misaligned edges in the graph may have negative impacts on the results. To address this problem and further handle inconsistency caused by multi-task acquisitions in urban environments, we introduce a refined structure of the factor graph considering systematical initialization bias, where the scan-matching factors are twice validated through a novel classifier and a robust optimization strategy. In addition, we incorporate a multi-hypothesis extended Kalman filter (MH-EKF) to remove dynamic objects. Quantitative experimental results demonstrate that the proposed method outperforms state-of-the-art techniques in terms of map quality.


Title: Structure preserving Multi-Contact Balance Control for Series-Elastic and Visco-Elastic Humanoid Robots
Key Words: actuators  elasticity  humanoid robots  legged locomotion  predictive control  robot dynamics  visco-elastic humanoid robots  actuator control  multicontact balancing  force distribution problem  actuator dynamics  dynamically consistent force distribution  model predictive controller  contact force  actuator constraints  multicontact balance control  series-elastic humanoid robos  structure preservation control concept  locomotion  Force  Actuators  Robot kinematics  Dynamics  Task analysis  Humanoid robots 
Abstract: This paper proposes an integration of multi-body and actuator control for multi-contact balancing for robots with highly elastic joints. Inspired by the structure preserving control concept for series-elastic fixed-base robots, the presented approach aims to minimize the control effort by keeping the system structure intact. Balancing on multiple contacts requires to solve the force distribution problem. In locomotion, contacts change quickly, requiring a swift redistribution of contact forces. This is a challenge for elastic robots as the actuator dynamics and limits prevent instantaneous changes of contact forces. The proposed dynamically consistent force distribution is implemented as a model predictive controller which resolves redundancy while complying with contact force and actuator constraints.


Title: Towards Automatic 3D Shape Instantiation for Deployed Stent Grafts: 2D Multiple-class and Class-imbalance Marker Segmentation with Equally-weighted Focal U-Net
Key Words: blood vessels  cardiovascular system  image registration  image segmentation  medical image processing  mobile robots  path planning  stents  focal loss function  fluoroscopy projection  robot-assisted fenestrated endovascular aortic repair  automatic 3D shape instantiation  focal u-net  multiple class marker segmentation  multiple class marker center determination  robust perspective-S-point method  tensorflow codes  mean intersection over union  weighted u-net  network architecture  graft gap interpolation  stent graft  semiautomatic 3D shape instantiation method  FEVAR  class-imbalance marker segmentation  initial marker segmentation  fluoroscopy projections  Image segmentation  Shape  Three-dimensional displays  Aneurysm  Training  Two dimensional displays  Testing 
Abstract: Robot-assisted Fenestrated Endovascular Aortic Repair (FEVAR) is currently navigated by 2D fluoroscopy which is insufficiently informative. Previously, a semi-automatic 3D shape instantiation method was developed to instantiate the 3D shape of a main, deployed, and fenestrated stent graft from a single fluoroscopy projection in real-time, which could help 3D FEVAR navigation and robotic path planning. This proposed semi-automatic method was based on the Robust Perspective-S-Point (RP5P) method, graft gap interpolation and semiautomatic multiple-class marker center determination. In this paper, an automatic 3D shape instantiation could be achieved by automatic multiple-class marker segmentation and hence automatic multiple-class marker center determination. Firstly, the markers were designed into five different shapes. Then, Equally-weighted Focal U-Net was proposed to segment the fluoroscopy projections of customized markers into five classes and hence to determine the marker centers. The proposed Equally-weighted Focal U-Net utilized U-Net as the network architecture, equally-weighted loss function for initial marker segmentation, and then equally-weighted focal loss function for improving the initial marker segmentation. This proposed network outperformed traditional Weighted U-Net on the class-imbalance segmentation in this paper with reducing one hyperparameter - the weight. An overall mean Intersection over Union (mIoU) of 0.6943 was achieved on 78 testing images, where 81.01 % markers were segmented with a center position error <; 1.6mm. Comparable accuracy of 3D shape instantiation was also achieved and stated. The data, trained models and TensorFlow codes are available on-line.


Title: A 3D Laparoscopic Imaging System Based on Stereo-Photogrammetry with Random Patterns
Key Words: image reconstruction  image sensors  lenses  medical image processing  photogrammetry  stereo image processing  surgery  high frame rate image acquisition  stereo-photogrammetry  coded structured patterns projection  stereo matching  3D surface reconstruction  stereo vision feedback  novel 3D laparoscopic imaging system  frequency 4.0 kHz  Three-dimensional displays  Laparoscopes  Lenses  Imaging  Probes  Image resolution  Surface reconstruction 
Abstract: In this paper, we propose a novel 3D laparoscopic imaging system based on stereo-photogrammetry which is assisted by projecting patterns on the tissue surface. The proposed laparoscopic imaging system has three optic channels, two of which are responsible for stereo vision feedback and the other one is used for coded structured patterns projection. The projected patterns provide the robustness to homogeneous tissue surface since they add more features that can be relied on in the stereo matching. Image fiber bundles (100k pixels) and Gradient-index (GRIN) lenses are utilized to facilitate the remote image acquisition and miniaturization of the laparoscopic probe. Moreover, we adopt a digital micromirror device (DMD) and high-speed cameras to achieve fast pattern switching (up to 4 kHz) and high frame rate image acquisition. The system configuration allows for implementation of the time multiplexing pattern codification strategy in the 3D laparoscopic imaging system to enhance the reliability and resolution of the 3D surface reconstruction. A prototype is established, and various experiments are conducted. Comparative experimental results prove the advantages of our system design. The static and dynamic 3D reconstruction results validate the performance of the proposed 3D laparoscopic imaging system quantitatively and qualitatively.


Title: Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties
Key Words: expectation-maximisation algorithm  Gaussian distribution  image registration  matrix algebra  optimisation  anisotropic positional uncertainties  E-step  correspondence probabilities  M-step  transformation matrix  constrained optimization problem  expectation conditional maximization framework  multivariate Gaussian distribution  positional error  generalized point cloud registration problem  computer-assisted surgery  medical robotics  robust generalized point cloud registration  Three-dimensional displays  Hidden Markov models  Covariance matrices  Surgery  Optimization  Mixture models  Linear programming 
Abstract: Alignment of two point clouds is an essential problem in medical robotics and computer-assisted surgery. In this paper, we first formally formulate the generalized point cloud registration problem in a probabilistic manner. Specifically, not only positional but also the orientational information are incorporated into registration. Notably, the positional error is assumed to obey a multivariate Gaussian distribution to accommodate anisotropic cases. Expectation conditional maximization framework is utilized to solve the problem. In E-step, the correspondence probabilities between points in two generalized point clouds are computed. In M -step, the constrained optimization problem with respect to the transformation matrix is re-formulated as an unconstrained one. Extensive experiments are conducted to compare the proposed algorithm with the state-of-the-art registration methods. The experimental results demonstrate the algorithm's robustness to noise and outliers, fast convergence speed.


Title: A Sliding Mode Control Architecture for Human-Manipulator Cooperative Surface Treatment Tasks
Key Words: control engineering computing  deburring  end effectors  force sensors  industrial manipulators  industrial robots  mobile robots  motion control  multi-robot systems  position control  variable structure systems  redundant 7R manipulator  robotic surface treatment  novel collaborative controller  robot motion  robotic tool  conditioning task  robot end-effector  surface treatment tool  nonconventional sliding mode control  task prioritization  control scheme  autonomous physical agent  human operator propioceptive abilities  shared strategy effectively couples  robotic manipulator partner  physical strength  surface treatment tasks  human-manipulator  sliding mode control architecture  Robot sensing systems  Surface treatment  Task analysis  Tools  Surface morphology  Manipulators 
Abstract: This paper presents a control architecture readily suitable for surface treatment tasks such as polishing, grinding, finishing or deburring as carried out by a human operator, with the added benefit of accuracy, recurrence and physical strength as administered by a robotic manipulator partner. The shared strategy effectively couples the human operator propioceptive abilities and fine skills through his interactions with the autonomous physical agent. The novel proposed control scheme is based on task prioritization and a non-conventional sliding mode control, which is considered to benefit from its inherent robustness and low computational cost. The system relies on two force sensors, one located between the last link of the robot and the surface treatment tool, and the other located in some place of the robot end-effector: the former is used to suitably accomplish the conditioning task, while the latter is used by the operator to manually guide the robotic tool. When the operator chooses to cease guiding the tool, the robot motion safely switches back to an automatic reference tracking. The paper presents the theories for the novel collaborative controller, whilst its effectiveness for robotic surface treatment is substantiated by experimental results using a redundant 7R manipulator and a mock-up conditioning tool.


Title: Variable Admittance Control for Human-Robot Collaboration based on Online Neural Network Training
Key Words: backpropagation  feedforward neural nets  human-robot interaction  manipulators  motion control  neurocontrollers  variable admittance control  human-robot collaboration  online neural network training  human-robot cooperation  multilayer feedforward neural network  Cartesian velocity  admittance controller  error backpropagation algorithm  KUKA LWR robot  virtual damping  point-to-point cooperative motion  Admittance  Artificial neural networks  Damping  Trajectory  Robot kinematics  Training  Variable Admittance Control  Neural Networks  Error Backpropagation  Minimum Jerk Trajectory 
Abstract: In this paper, a method for variable admittance control in human-robot cooperation is proposed. A multilayer feedforward neural network is designed using the Cartesian velocity of the robot and the applied force by the operator as its inputs to modify online the virtual damping of the admittance controller. The neural network is trained online using the error backpropagation algorithm based on the error between the velocity of the minimum jerk trajectory model and the measured velocity of the robot. The performance of the proposed controller and the NN generalization ability are evaluated by conducting a point-to-point cooperative motion with multiple subjects using the KUKA LWR robot.


Title: Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  design engineering  drag  mobile robots  optimal control  pitch control (position)  robot dynamics  active pitch control strategy  center-of-mass location  morphological intelligence  optimal control strategy  collapsible airfoils  nonsteady-state gliding performance  gliding robots  drag coefficients  aerodynamic complexities  Robots  Automotive components  Aerodynamics  Optimization  Atmospheric modeling  Trajectory  Springs 
Abstract: Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.


Title: Active Range and Bearing-based Radiation Source Localization
Key Words: cameras  image sensors  radioactive sources  static step size  radiation mapping approach  active source localization approach  adaptive step size  localization time  3D radiation source localization  bearing sensor  Compton gamma camera  image radiation  source locations  active source localization framework  Fisher Information  bearing-based radiation source localization  passive source localization  size 0.26 m  Sensors  Cameras  Photonics  Three-dimensional displays  Image sensors  Position measurement  Two dimensional displays 
Abstract: 3D radiation source localization is a common task across applications such as decommissioning, disaster response, and security, but traditional count-based sensors struggle to efficiently disambiguate between symmetries in sensor, source, and environment configurations. Recent works have demonstrated successful passive source localization using a bearing sensor called the Compton gamma camera that can image radiation. This paper first presents an approach to mapping the spatial distribution of radiation with a gamma camera to estimate source locations. An active source localization framework is then developed that greedily selects new waypoints that maximize the Fisher Information provided by the camera's range and bearing observations for source localization. Finally the common assumption of a static step size in between waypoints is relaxed to allow step sizes to adapt online to the observed information. The proposed radiation mapping approach is evaluated in 5×4 m2 and 14×6 m2 laboratory environments, where multiple point sources were localized to within an average of 0.26 m or 0.6% of the environment dimensions. The active source localization approach is evaluated in simulation and an adaptive step size yields a 27% decrease in the localization time and a 16% decrease in the distance traveled to localize a source in a 15×15×15 m3 environment.


Title: Design and Performance Evaluation of an Infotaxis-Based Three-Dimensional Algorithm for Odor Source Localization
Key Words: electronic noses  gases  mobile robots  probability  wind tunnels  gaseous leak source  high wind speeds  environmental conditions  environmental parameters  multiple algorithmic parameters  wind tunnel  probabilistic Infotaxis algorithm  odor source localization  infotaxis-based three-dimensional algorithm  Robots  Entropy  Atmospheric modeling  Mathematical model  Probabilistic logic  Numerical models  Probability 
Abstract: In this paper we tackle the problem of finding the source of a gaseous leak with a robot in a three-dimensional (3-D) physical space. The proposed method extends the operational range of the probabilistic Infotaxis algorithm [1] into 3-D and makes multiple improvements in order to increase its performance in such settings. The method has been tested systematically through high-fidelity simulations and in a wind tunnel emulating realistic conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments. The algorithm shows good performance in various environmental conditions, particularly in high wind speeds and different source release rates.


Title: UX 1 system design - A robotic system for underwater mining exploration
Key Words: cameras  control system synthesis  innovation management  mining  mobile robots  robot vision  sonar  underwater vehicles  UX 1 system design  underwater mining exploration  UX-1 underwater mine exploration robotic system  UNEXMIN project  international innovation action  EU H2020 program  flooded underground mines  UX-1 robot prototype  recovery system  post-processing computational infrastructure  spherical robot  rotating laser line structured light systems  comprehensive mine model  robot design  UV-light  natural gamma-ray detector  multi-spectral camera  electro-conductivity  magnetic field sensors  high resolution imagery  Robot sensing systems  Sonar  Cameras  Payloads  Three-dimensional displays 
Abstract: This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.


Title: Automation in sensing and raw material characterization - a conceptual framework
Key Words: hyperspectral imaging  image fusion  image sensors  infrared spectra  infrared spectroscopy  statistical analysis  raw material characterization  material identification process  technological maturity  data fusion  sensor combinations approach  sensors signals  sensor technologies  real-time mining project concept  red green blue imaging  short wave infrared hyperspectral imaging  sensing automation  sensor signal  sensor data combinations  RTM  RGB imaging  visible near infrared hyperspectral imaging  VNIR  SWIR  Fourier-transform infrared spectroscopy  FTIR  laser induced breakdown spectroscopy  LIBS  multi-variate statistical interpretation  Minerals  Data integration  Automation  Robot sensing systems  Hyperspectral imaging  Raw materials  sensors data  data fusion  automation  material characterization  polymetallic sulphides 
Abstract: The use of sensor technologies for material characterization is rapidly growing and innovative advancement is observed. However, the use of sensor combinations for a raw material characterization in mining is very limited and automation of the material identification process using a combined sensor signal is not defined. Potential sensor technologies for raw material characterization were evaluated based on the applicability and technological maturity. To ensure a rapid implementation of the Real-time mining (RTM) project concept, mature technologies such as Red Green Blue (RGB) imaging, Visible Near Infrared (VNIR) hyperspectral imaging, Short Wave Infrared (SWIR) hyperspectral imaging, Fourier-Transform Infrared Spectroscopy (FTIR), Laser Induced Breakdown Spectroscopy (LIBS) and Raman were selected. Each selected technology was assessed for automation in sensing and applicability (for characterization of the test case materials). Based on the results the sensor data were further considered for data fusion. The proposed sensor combinations approach encompasses three levels of data fusion: low-level, mid-level and high-level. The data of the different sensors are fused together in order to acquire a wide range of mineral properties within each lithotype and an improved classification and predictive models. The preferred level of data fusion and preferred sensor data combinations will be used to develop a multi-variate statistical interpretation rule which relates combination of sensors signals with raw material properties. Thus a tool which integrates the combined sensor signal with materials properties will be developed and used to automate the material characterization process.


Title: ίVAMOS! Underwater Mining Machine Navigation System
Key Words: autonomous underwater vehicles  Kalman filters  mining  mining equipment  mobile robots  nonlinear filters  satellite navigation  sensor fusion  underwater acoustic communication  underwater mining machine navigation system  data fusion approach  sensor information  extended kalman filter  EKF  ¡VAMOS  multiple antenna GNSS system  inverted ultra-short baseline  surface vessel  underwater mining vehicle  multiple vehicle underwater localization solution  Position measurement  Global navigation satellite system  Receivers  Transponders  Accelerometers  Data mining  Gravity 
Abstract: Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.


Title: Multi-Agent Imitation Learning for Driving Simulation
Key Words: intelligent transportation systems  learning (artificial intelligence)  multi-agent systems  multiagent Imitation Learning  human drivers  multiagent setting  PS-GAIL method  single-agent GAIL policies  curriculum learning  multiple agents  test time  multiagent driving scenarios  single-agent environments  representative human driver models  Generative Adversarial Imitation Learning  autonomous vehicles  appealing option  Vehicles  Training  Trajectory  Optimization  Biological system modeling  Testing  Markov processes 
Abstract: Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.


Title: Learning Actionable Representations from Visual Observations
Key Words: learning (artificial intelligence)  video coding  learning task-agnostic representations  continuous control tasks  multiple frames  single frame  self-supervised approach  reinforcement learning setting  random actions  continuous control policies  Proximal Policy Optimization  learned embeddings  real-world Pouring dataset  single-frame baseline  learning actionable representations  time-contrastive networks  Task analysis  Robots  Visualization  Reinforcement learning  Aerospace electronics  Solid modeling  Semantics 
Abstract: In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.


Title: Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids
Key Words: biomechanics  bone  data acquisition  humanoid robots  muscle  robot vision  body tissue  joint-muscle model  muscle-route change model  geometric model  tendon-driven musculoskeletal humanoid Kengoro  muscle routes  tendon-driven musculoskeletal humanoids  flexible spine  body complexity  muscle lengths  muscle route changes  internal muscle tension  online self-body image acquisition  multiple degrees of freedom  controllability  neural network  Muscles  Robot sensing systems  Humanoid robots  Solid modeling  Training 
Abstract: Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.


Title: Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
Key Words: feature extraction  inference mechanisms  learning (artificial intelligence)  legged locomotion  motion control  path planning  robot vision  terrain mapping  multilegged robot  crawled terrain  hexapod robot  legged robot  terrain features inference  aerial scan  robot locomotion  incremental learning  geometrical data  visual data  terrain learning  extraterrestrial missions  robot deployment  robot motion planning  cost of transport estimation  terrain descriptors  mechanical properties  Robots  Feature extraction  Image color analysis  Estimation  Unmanned aerial vehicles  Three-dimensional displays  Visualization 
Abstract: The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.


Title: Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots
Key Words: biomedical optical imaging  diseases  endoscopes  image sequences  medical image processing  medical robotics  motion estimation  unsupervised learning  single-view depth estimation network  passive capsule endoscopes  minimally invasive diagnostic technology  realtime odometry  monocular endoscopic capsule robots  multiview pose estimation  endoscopic capsule robots  disease detection  drug delivery  gastrointestinal tract  reprojection minimization  unsupervised odometry  depth learning  biopsy-like operations  ex-vivo porcine stomach datasets  motion estimation  Cameras  Robots  Endoscopes  Reliability  Sensors  Pose estimation 
Abstract: In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.


Title: Multibeam Data Processing for Underwater Mapping
Key Words: image segmentation  oceanographic techniques  sonar  sonar detection  sonar imaging  underwater vehicles  balanced trade-off  underwater mapping literature  underwater mapping literature  local thresholding techniques  subsea structures  multibeam data processing  DIDSON imaging sonar  map accuracy  sonar-based underwater mapping  sonar artifacts  range measurements  occupied regions  free regions  received acoustic echos  sonars output  underwater mapping platforms  primary sensor  multibeam sonars  Sonar measurements  Robot sensing systems  Acoustic beams  Image segmentation  Mathematical model  Acoustics 
Abstract: From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.


Title: A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
Key Words: autonomous underwater vehicles  bridges (structures)  inspection  multi-robot systems  path planning  underwater structures  DSCPP  smooth paths  spiral path  popular boustrophedon-based coverage approach  intervention autonomous underwater vehicle  deformable spiral coverage path planning algorithm  smooth coverage path planning  deformable spiral-based algorithm  Spirals  Cleaning  Path planning  Fatigue  Underwater structures  Manipulators  Poles and towers 
Abstract: Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.


Title: Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots
Key Words: ethical aspects  geriatrics  medical robotics  CARESSES robot  ethical thinking  VSD  international multidisciplinary project  culturally competent SAR  ethical concepts  value sensitive design  culturally competent socially assistive robots  Robots  Task analysis  Ethics  Guidelines  Cultural differences  Assistive technology  Medical services 
Abstract: Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.


Title: Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction
Key Words: emotion recognition  human-robot interaction  learning (artificial intelligence)  multiculture society  incremental learning model  habitual emotional behaviors  social robot  emotional bodily expressions  imitated robot motions  cultural background  culturally competent robots  long term human-robot interaction  Robot kinematics  Neurons  Self-organizing feature maps  Trajectory  Training  Collision avoidance 
Abstract: Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.


Title: A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*
Key Words: bending  blood vessels  catheters  finite element analysis  medical image processing  force estimation accuracy  endovascular intervention procedures  multiple catheter  sensor-less catheter contact force estimation approach  vessel wall  embolization  navigation process safety  robotic vascular interventions  sensor-less sensing solution  multiple contact point forces  image feedback  catheter-vessel interaction  real-time image processing algorithms  interaction contact points  image-based deflection measurement  nonlinear finite element beam model  three-point-bending tests  catheter-guidewire-vessel interaction contact forces  catheter-guidewire manipulation  bending modulus property  under-actuated catheter-guidewire  catheter-guidewire-vessel interaction  Catheters  Force  Robot sensing systems  Estimation  Force measurement  Phantoms  Finite element analysis 
Abstract: Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.


Title: Mechatronic fingernail with static and dynamic force sensing
Key Words: force control  force sensors  manipulators  mechatronics  motion control  compact working prototype  multicell tactile fingertip sensor  distal phalange  robotic hand  mechatronic fingernail  static force sensing  dynamic force sensing  sensorized fingernail  mechatronic hands  static interaction forces  dynamic interaction forces  Nails  Robot sensing systems  Force  Force measurement  Delays 
Abstract: Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.


Title: Precise Localization in High-Definition Road Maps for Urban Regions
Key Words: cameras  image resolution  Kalman filters  nonlinear filters  road vehicles  satellite navigation  stereo image processing  traffic engineering computing  high-resolution road maps  road borders  Unscented Kalman Filter  narrow urban roads  highly automated driving  precise localization  high-definition road maps  sensor specific feature layers  stereo camera  vehicle odometry  low-cost GNSS module  size 5.0 km  size 0.08 m  Roads  Global navigation satellite system  Simultaneous localization and mapping  Semantics  Urban areas  Receivers 
Abstract: The future of automated driving in urban areas will most probably rely on highly accurate road maps. However, the necessary precision of a localization in such maps has so far only been reached using extra, sensor specific feature layers for localization. In this paper we want to show that it is possible to achieve sufficient accuracy without a separate localization layer. Instead, elements are used that are already contained in high-resolution road maps, such as markings and road borders. For this, we introduce a modular approach in which detections from different detection algorithms are associated with elements in the map and then fused to an absolute pose using an Unscented Kalman Filter. We evaluate our approach using a sensor setup that employs a stereo camera, vehicle odometry and a low-cost GNSS module on a 5km test route covering both narrow urban roads and multi-lane main roads under varying weather conditions. The results show that this approach is capable to be used for highly automated driving, showing an accuracy of 0.08m in typical road scenarios and a is available 98% of the time.


Title: Decentralized Localization Framework using Heterogeneous Map-matchings
Key Words: decentralised control  mobile robots  road vehicles  sensor fusion  stability  stochastic processes  decentralized localization framework  heterogeneous map-matchings  system stability  localization methods  map matchings  stochastic situational analysis model  heterogeneous map-matching sources  dissimilar sensors  fusion methods  multienvironment sensors  single environmental sensor  autonomous driving applications  robust real-time localization  Roads  Laser radar  Three-dimensional displays  Cameras  Feature extraction  Sensor fusion 
Abstract: Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.


Title: MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot
Key Words: actuators  gait analysis  legged locomotion  motion control  robot dynamics  robust control  control architecture  legged locomotion  abduction-adduction degrees  gait modification  cost of transport  CoT  proprioceptive actuation  leg design  mechanical design  dynamic quadruped robot  robust robot  MIT cheetah 3  Legged locomotion  Actuators  Torque  Force  Knee  Robot sensing systems 
Abstract: This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.


Title: Magneto: A Versatile Multi-Limbed Inspection Robot
Key Words: actuators  design engineering  inspection  legged locomotion  manipulator kinematics  quadruped climbing robot  high dimensional system design  human entry portholes  three degrees of freedom actuated limbs  3-DOF compliant magnetic foot  locomotion  complex 3-D structures  industrial confined spaces  body shape  multilimbed inspection robot  legged climbing robots  confined space openings  manipulation mode mid-climb  limb function  Magneto  compact foot design  Adhesives  Legged locomotion  Magnetic separation  Foot  Inspection  Soft magnetic materials 
Abstract: In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.


Title: Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton with Hemiplegia Patients
Key Words: adaptive control  dynamic programming  gait analysis  handicapped aids  iterative methods  learning (artificial intelligence)  medical robotics  motion control  multi-agent systems  patient rehabilitation  hemiplegia patient  lower limb exoskeleton  learning-based walking assistance control strategy  paraplegia patients  leader-follower multi-agent system  LF-MAS  reinforcement learning framework  policy iteration adaptive dynamic programming algorithm  PI-ADP algorithm  tracking control  Legged locomotion  Exoskeletons  Reinforcement learning  Control systems  Heuristic algorithms  Multi-agent systems  Cost function  Walking Assistance Strategy  Leader-Follower Multi-Agent System  Reinforcement Learning  Lower Exoskeleton  Hemiplegia 
Abstract: Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.


Title: A Phase Variable Approach to Volitional Control of Powered Knee-Ankle Prostheses
Key Words: artificial limbs  finite state machines  gait analysis  legged locomotion  medical robotics  motion control  trajectory control  volitional control  powered knee-ankle prostheses  multijoint prosthetic legs  periodic walking  piecewise holonomic phase variable  finite state machine  nominal reference gait trajectory  high-speed walking  backward walking  phase variable approach  volitional leg motions  Legged locomotion  Thigh  Trajectory  Task analysis  Prosthetics  Sensors  Foot 
Abstract: Although there has been recent progress in control of multi-joint prosthetic legs for periodic tasks such as walking, volitional control of these systems for non-periodic maneuvers is still an open problem. In this paper, we develop a new controller that is capable of both periodic walking and common volitional leg motions based on a piecewise holonomic phase variable through a finite state machine. The phase variable is constructed by measuring the thigh angle, and the transitions in the finite state machine are formulated through sensing foot contact together with attributes of a nominal reference gait trajectory. The controller was implemented on a powered knee-ankle prosthesis and tested with a transfemoral amputee subject, who successfully performed a wide range of periodic and non-periodic tasks, including low- and high-speed walking, quick start and stop, backward walking, walking over obstacles, and kicking a soccer ball. The proposed approach is expected to provide better understanding of volitional motions and lead to more reliable control of multi-joint prostheses for a wider range of tasks.


Title: Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform
Key Words: biomechanics  force control  medical robotics  patient rehabilitation  position control  robotic device interacts  pre-clinical validation  upper-limb rehabilitation robotic platform  UHP multifunctional upper-limb rehabilitation robot  rehabilitation therapies  UHP rehabilitation robot  multifunctional device  robotized therapies  advanced position-force control approaches  Rehabilitation robotics  Training  Games  Software  Robot sensing systems  Elbow 
Abstract: Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.


Title: A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *
Key Words: audio signal processing  audio-visual systems  avatars  humanoid robots  learning (artificial intelligence)  motion control  crossmodal conflict resolution  robot sensorimotor coupling  swift behaviour  robust behaviour  neurorobotic experiment  iCub robot exhibits  complex crossmodal environment  multisensory conflicts  behavioural study  audio-visual cues  visual bias  discrete behavioural response  complex environments  incongruent dynamic audio-visual cues  human-like responses  environmental statistics  stereophonic sound processing  facial features  body motion  deep learning model  animated avatars  Avatars  Visualization  Robot sensing systems  Lips  Task analysis  Spatial resolution 
Abstract: Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.


Title: A Rationale-Driven Team Plan Representation for Autonomous Intra-Robot Replanning*
Key Words: mobile robots  multi-robot systems  path planning  rationale-driven team plan representation  autonomous multirobot teams  autonomous intrarobot replanning  team planner  intrarobot replanning algorithm  Robots  Oceans  Task analysis  Prediction algorithms  Planning  Satellites  Global Positioning System 
Abstract: For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.


Title: Stochastic Optimization for Autonomous Vehicles with Limited Control Authority
Key Words: gradient methods  greedy algorithms  mobile robots  optimisation  state-space methods  stochastic processes  SGA  multivehicle information gathering  action space representation  stochastic optimization scheme  perturbed action sequences  state space information function  sequential greedy allocation  autonomous vehicles  stochastic gradient ascent algorithm  vehicle control authority  navy coastal ocean model  NCOM  Gulf of Mexico  GoM  Monte Carlo tree search method  MCTS  Oceans  Optimization  Stochastic processes  Approximation algorithms  Trajectory  Aerospace electronics  Robots 
Abstract: In this work, we present a Stochastic Gradient Ascent (SGA) algorithm for multi-vehicle information gathering that accounts for limitations on a vehicle's control authority caused by external forces. By representing vehicle paths using a novel action space representation, rather than a state space representation, we remove the need to perform feasibility calculations on the vehicle's path. Our algorithm uses a stochastic optimization scheme by sampling perturbed action sequences around the current best known sequence to estimate the gradient of a state space information function with respect to the action sequence. Additionally, we use sequential greedy allocation to plan for multiple vehicles. Results are shown using a Navy Coastal Ocean Model (NCOM) for the Gulf of Mexico (GoM). SGA shows improvement in the amount of information gained over a greedy baseline. Additionally, we compare to Monte Carlo Tree Search (MCTS) Method, which is able to gather competitive amounts of information but is more computationally intensive than our approach.


Title: A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints
Key Words: redundant manipulators  multiple kinematic chains  hard joint  reverse priority framework  kinematic control  redundant robots  reverse priority method  robotic systems  bilateral constraints  unilateral constraints  multitask priority framework  joint priorities  Cartesian constraints  Task analysis  Kinematics  Jacobian matrices  Redundancy  End effectors 
Abstract: This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.


Title: Failure Detection Using Proprioceptive, Auditory and Visual Modalities
Key Words: computerised monitoring  humanoid robots  manipulators  robot vision  sensor fusion  failure detection  continuous execution monitoring  multimodal failure monitoring  single sensor modality  high level proprioceptive  auditory predicates  visual predicates  humanoid robot  tabletop manipulation scenarios  safety handling  multimodal fusion  Robot sensing systems  Hidden Markov models  Monitoring  Visualization  Task analysis  Grasping 
Abstract: Handling safety is crucial to achieve lifelong autonomy for robots. Unsafe situations might arise during manipulation in unstructured environments due to noises in sensory feedback, improper action parameters, hardware limitations or external factors. In order to assure safety, continuous execution monitoring and failure detection procedures are mandatory. To this end, we present a multimodal failure monitoring and detection system to detect manipulation failures. Rather than relying only on a single sensor modality, we consider integration of different modalities to get better detection performance in different failure cases. In our system, high level proprioceptive, auditory and visual predicates are extracted by processing each modality separately. Then, the extracted predicates are fused. Experiments on a humanoid robot for tabletop manipulation scenarios indicate that the contribution of each modality is different depending on the action in execution and multimodal fusion results in an overall performance increase in detecting failures compared to the performance attained by unimodal processing.


Title: Multi-timescale Feature-extraction Architecture of Deep Neural Networks for Acoustic Model Training from Raw Speech Signal
Key Words: acoustic signal processing  feature extraction  neural nets  speech recognition  robot audition  normalization-free processing  speech features  multitimescale architecture  speech signals  low-latency speech recognition  utterance-wise mean subtraction  acoustic models  raw speech signal  acoustic model training  deep neural networks  multitimescale feature-extraction architecture  Feature extraction  Acoustics  Artificial neural networks  Splicing  Robots  Filter banks  Training 
Abstract: This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.


Title: Tracking a moving sound source from a multi-rotor drone
Key Words: acoustic signal processing  audio signal processing  autonomous aerial vehicles  cameras  feature extraction  helicopters  humanoid robots  particle filtering (numerical methods)  signal denoising  spatial filters  time-frequency analysis  ground-truth trajectory  noisy estimations  direction of arrival  ego-noise  human speaker  multirotor drone  moving sound source  moving source  short audio segments  time-frequency spatial filter  specific drone  propellers  motors  emergency whistle  Drones  Time-frequency analysis  Direction-of-arrival estimation  Microphone arrays  Loudspeakers  Propellers 
Abstract: We propose a method to track from a multi-rotor drone a moving source, such as a human speaker or an emergency whistle, whose sound is mixed with the strong ego-noise generated by rotating motors and propellers. The proposed method is independent of the specific drone and does not need pre-training nor reference signals. We first employ a time-frequency spatial filter to estimate, on short audio segments, the direction of arrival of the moving source and then we track these noisy estimations with a particle filter. We quantitatively evaluate the results using a ground-truth trajectory of the sound source obtained with an on-board camera and compare the performance of the proposed method with baseline solutions.


Title: Apple Counting using Convolutional Neural Networks
Key Words: agricultural products  convolutional neural nets  Gaussian processes  horticulture  image classification  object detection  horticultural studies  logistics planning  Gaussian mixture model  convolutional neural network  yield estimate  per-image accuracy  fruit counting  fruit detection  vegetable counts  apple counting  Image color analysis  Yield estimation  Agriculture  Image segmentation  Clustering algorithms  Task analysis  Vegetation 
Abstract: Estimating accurate and reliable fruit and vegetable counts from images in real-world settings, such as orchards, is a challenging problem that has received significant recent attention. Estimating fruit counts before harvest provides useful information for logistics planning. While considerable progress has been made toward fruit detection, estimating the actual counts remains challenging. In practice, fruits are often clustered together. Therefore, methods that only detect fruits fail to offer general solutions to estimate accurate fruit counts. Furthermore, in horticultural studies, rather than a single yield estimate, finer information such as the distribution of the number of apples per cluster is desirable. In this work, we formulate fruit counting from images as a multi-class classification problem and solve it by training a Convolutional Neural Network. We first evaluate the per-image accuracy of our method and compare it with a state of the art method based on Gaussian Mixture Models over four test datasets. Even though the parameters of the Gaussian Mixture Model based method are specifically tuned for each dataset, our network outperforms it in three out of four datasets with a maximum of 94% accuracy. Next, we use the method to estimate the yield for two datasets for which we have ground truth. Our method achieved 96-97% accuracies. For additional details please see our video here: https://www.youtube.com/watch?v=Le0mb5P-SYc.


Title: Object Recognition Through Active Sensing Using a Multi-Fingered Robot Hand with 3D Tactile Sensors
Key Words: control engineering computing  convolutional neural nets  dexterous manipulators  object recognition  recurrent neural nets  tactile sensors  time series  multifingered robot hand  triaxial force vector measurements  3D tactile sensors  distributed force vector measurements  feedforward neural network  recurrent neural network  time-series training  active object sensing  Allegro Hand  uSkin tactile sensors  tactile object recognition  time series data  Force  Force measurement  Object recognition  Tactile sensors 
Abstract: This paper investigates tactile object recognition with relatively densely distributed force vector measurements and evaluates what kind of tactile information is beneficial for object recognition. The uSkin tactile sensors are embedded in an Allegro Hand, and provide 240 triaxial force vector measurements in total in all fingers. Active object sensing is used to gather time-series training and testing data. A simple feedforward, a recurrent, and a convolutional neural network are used for recognizing objects. Evaluations with different number of employed measurements, static vs. time series data and force vector vs. only normal force vector measurements show that the high-dimensional information provided by the sensors is indeed beneficial. An object recognition rate of up to 95% for 20 objects was achieved.


Title: Efficient Map Representations for Multi-Dimensional Normal Distributions Transforms
Key Words: mobile robots  Monte Carlo methods  normal distribution  probability  robot vision  stereo image processing  transforms  indoor environments  outdoor environments  driving flying robots  fast approach  accurate approach  indexed kd-trees  free space  occupancy probabilities  map consistency  large-scale environments  mapping efficiency  efficient map representations  3D map representations  static environments  dynamic environments  multidimensional normal distributions transforms  3D normal distributions transform mapping  Three-dimensional displays  Robot sensing systems  Gaussian distribution  Two dimensional displays  Task analysis  Transforms 
Abstract: Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.


Title: Modeling and Control of an Articulated Tail for Maneuvering a Reduced Degree of Freedom Legged Robot
Key Words: actuators  feedback  hardware-in-the loop simulation  legged locomotion  linearisation techniques  motion control  robot dynamics  leg mechanisms  quadruped robot  dynamic tail motions  robotic system design  outer loop controller  articulated tail mechanism  inner loop controller  tail prototype  dynamic modeling control  articulated robotic tail  maneuvering  legged robotic systems  reduced degree of freedom legged robot  hardware-in-the-loop experiments  quadruped platform simulation  feedback linearization maps  Legged locomotion  Robot kinematics  Foot  Dynamics  Task analysis  Manipulators 
Abstract: This paper presents dynamic modeling and control of an articulated robotic tail to maneuver and stabilize a reduced degree-of-freedom (DOF) quadruped robot. Conventional legged robotic systems consist of leg mechanisms that provide simultaneous propulsion, maneuvering and stabilization. However, in nature animals have been observed to utilize their tails to assist the legs in multiple tasks. Similarly, by incorporating an articulated tail onboard a quadruped robot, dynamic tail motions can be used to aid maneuvering. Therefore, tail implementation can potentially lead to simplifications in design and control of the legged robot since the legs will be responsible for only propulsion tasks. In this paper, a robotic system design consisting of an articulated tail and quadruped robot system is presented. Dynamic models are derived to analyze an optimal tail mass and length ratio to enhance inertial adjustment applications and develop an outer loop controller to plan tail trajectories for desired maneuvering applications. Results of analytical optimization are corroborated with measured data from biological animals. To decouple the dynamics of the articulated tail mechanism an inner loop controller using feedback linearization maps the desired behavior to the actuator inputs. This approach is validated using hardware-in-the-loop experiments with tail prototype in conjunction with simulated quadruped platform. Results demonstrate the capabilities of the articulated tail in enabling precise left and right turning (maneuvering).


Title: Modeling and Fuzzy Control of One-legged Somersaulting Robot
Key Words: fuzzy control  legged locomotion  motion control  robot dynamics  robot kinematics  springs (mechanical)  flight phases  hybrid dynamic model  challenging control issue  one-legged hopping robots  springy leg  fuzzy logic control  one-legged somersaulting robot  multilegged ones  hopping motion  SLIP robots  Legged locomotion  Actuators  Mathematical model  Torque  Wheels 
Abstract: Research on legged robots has developed rapidly in the recent decades. One-legged robots, unlike multi-legged ones, have only one type of motion, called hopping. Hopping motion is generally divided into stance and flight phases. Switching between these two phases represents a hybrid dynamic model. Dynamic stabilization of hopping motion is a challenging control issue. Most of one-legged hopping robots studied in the past are able to hop with their one springy leg. In this paper, a novel one-legged robot is introduced and studied with two springs on the two sides. The one-legged somersaulting robot is able to hop with both springy sides. This ability causes lower energy consumption in passing obstacles and a longer step length in comparison with well-known SLIP robots with hopping motion stemming from the fact that it only has one rotary actuator. Fuzzy logic control is applied to achieve a stable limit cycle in the robot's somersaulting motion.


Title: SLIP-Model-Based Dynamic Motion Transition Between Different Fixed Points in One Stride in a Leg-Wheel Transformable Robot
Key Words: force control  legged locomotion  motion control  nonlinear control systems  pendulums  stable running motion  stable fixed-point trajectories  ordinary SLIP model  passive spring  leg-spring stiffness  fixed-point trajectory  multistride transition  leg-wheel transformable robot  SLIP-model-based dynamic motion transition  motion generation strategy  force control  TurboQuad  Legged locomotion  Springs  Robot kinematics  Mathematical model  Dynamics  DC motors 
Abstract: We report on the development of a motion generation strategy that allows the robot to transit from one stable running motion to another in one stride by actively changing leg stiffness in real time. Stable motion of the robot is generated based on the stable fixed-point trajectories of the spring-loaded inverted pendulum (SLIP) model. While the transition of the ordinary SLIP model with fixed parameters gradually converges if stable, a robot that uses force control to simulate the passive spring of the SLIP can actively modulate leg-spring stiffness. This enables the robot to switch instantly to another fixed-point trajectory of the SLIP model without going through multi-stride transition. The proposed method is implemented on a leg-wheel transformable robot, TurboQuad, and is evaluated experimentally. The results confirm that the robot can successfully transit between different fixed-point trajectories.


Title: Slip Avoidance in Dual-Arm Manipulation
Key Words: aerospace robotics  force control  friction  manipulator dynamics  manipulators  mobile robots  motion control  position control  stability  slip avoidance  dual-arm manipulation  multifinger  multiarm grasping  friction contacts  contact slippage  space robotics  stable grasp  static conditions  grasp stability  safe force closure condition  specified motion trajectory  estimated inertial force  required squeeze force  inertial force component  motion-induced disturbance force  slip prevention strategy  dual-arm transportation  dual-arm robot  dynamic squeeze adjustment  robot-load motion  Force  Manipulators  Satellites  Grasping  Collision avoidance  Friction 
Abstract: In multi-finger or multi-arm grasping with friction contacts, maintaining force closure during motion is critical. Violation of this condition would cause contact slippage and possibly loss of grasp. This issue is of particular importance in space robotics, where the loss of grasp could lead to catastrophic consequences. There has been ample literature on stable grasp and force closure under static conditions. This paper investigates multi-arm grasping during motion, where the inertial force from the load could adversely affect grasp stability. Our approach dynamically adjusts the squeeze force and commanded robot/load motion to maintain a safe force closure condition. For a specified motion trajectory, the squeeze force is updated to prevent slippage based on the estimated inertial force. When the required squeeze force is beyond what the manipulators can safely apply, the trajectory will be scaled to reduce the inertial force component. In addition to motion-induced disturbance force, contact between the load and other objects in the environment can also cause slippage. The slip prevention strategy is extended to this case as well. The application scenario is based on the dual-arm transportation and berthing of a load in a micro-gravity environment. For laboratory testing, we use a fixed-base dual-arm robot to grasp, transport, and berth an object on a planar air bearing table. We also extend the transportation tests to a more general spatial setting, and use the dynamic squeeze adjustment to grasp, lift, and transport an object. Experimental results show the proposed method is effective at avoiding contact slippage during motion and when the object is in contact with the environment.


Title: Relative and inertial attitude determination in three-vehicle long formations
Key Words: attitude control  attitude measurement  inertial navigation  mobile robots  multi-robot systems  inertial attitude  three-vehicle long formations  attitude determination problem  three-vehicle formation  independent inertial measurement  attitude relations  relative attitude  inertial candidates  constrained formations  sensor noise  Position measurement  Sensors  Extraterrestrial measurements  Visualization  Estimation  Space vehicles  Navigation 
Abstract: This paper addresses a new attitude determination problem for formations. It considers a three-vehicle formation with relative and inertial measurements from sensors, where Constraints limit the relative measurements, which are not available between two of the vehicles, also known as deputies. The other vehicle is called the chief and does not have any limitation. Furthermore, each of the vehicles has an independent inertial measurement, whose references are known. The goal is to determine all attitude relations, both inertial and relative. The solution for this problem is divided into different stages. First, the relative attitude between the chief and the deputies is assessed, which results in two candidates for each of these relations. Then, each candidate yields a candidate for the inertial attitude of the chief. Next, comparing the four inertial candidates gives the solution for their respective relations and consequently for the relative relations as well. The remaining relations derive directly from those already known. The paper also provides some early insights about degeneracies, possible particular cases of the solution, and the effect of sensor noise. Finally, the solution is validated with a simulation, whose results are similar to attitude determination problems in constrained formations.


Title: Affordance Wayfields for Task and Motion Planning
Key Words: gradient methods  manipulators  path planning  manipulation affordances  affordance wayfields  motion planning  gradient descent  Michigan Progress Fetch mobile manipulator  Planning  Task analysis  End effectors  Trajectory  Cost function 
Abstract: Affordances provide a natural means for a robot to describe its agency as actions it can perform on objects. Further, affordances can enable robots to reason complicated, multi-step tasks that involve proper use of a diversity of objects. This paper proposes the concept of affordance wayfields for representing manipulation affordances as objective functions in configuration space. Affordance wayfields quantify how well a path, or sequence of motions, will accomplish an afforded action on an object. Paths that enact affordances can be located by performing a randomized form of gradient descent over affordance wayfields. Incorporating obstacles, or other constraints into wayfields allows our method to adaptively generate valid motions for executing afforded actions. We demonstrate that affordance wayfields can enable robots, such as the Michigan Progress Fetch mobile manipulator, to solve complex real-world tasks such as assembling a table, or loading and unloading objects from a storage chest.


Title: Accelerating Learning in Constructive Predictive Frameworks with the Successor Representation
Key Words: computer aided instruction  learning (artificial intelligence)  mobile robots  robot programming  unstructured environments  dynamic environments  reinforcement learning  predictive questions  massive network  interconnected GVFs  interdependent GVFs  SR  continual learning  physical robot arm  constructive predictive frameworks  constructive knowledge system  general value functions  successor representation  accelerated learning  Robots  Prediction algorithms  Function approximation  Acceleration  Approximation algorithms  Standards  Adaptation models 
Abstract: We propose using the Successor Representation (SR) to accelerate learning in a constructive knowledge system based on General Value Functions (GVFs). In real-world settings, like robotics for unstructured and dynamic environments, it is impossible to model all meaningful aspects of a system and its environment by hand. Instead, robots must learn and adapt to changes in their environment and task, incrementally constructing models from their own experience. GVFs, taken from the field of reinforcement learning (RL), are a way of modeling the world as predictive questions. One approach to such models proposes a massive network of interconnected and interdependent GVFs, which are incrementally added over time. It is reasonable to expect that new, incrementally added predictions can be learned more swiftly if the learning process leverages knowledge gained from past experience. The SR provides a means of capturing regularities that can be reused across multiple GVFs by separating the dynamics of the world from the prediction targets. As a primary contribution of this work, we show that using the SR can improve sample efficiency and learning speed of GVFs in a continual learning setting where new predictions are incrementally added and learned over time. We analyze our approach in a grid-world and then demonstrate its potential on data from a physical robot arm.


Title: Generative Modeling of Multimodal Multi-Human Behavior
Key Words: approximation theory  behavioural sciences computing  bin packing  human-robot interaction  learning (artificial intelligence)  mobile robots  multi-agent systems  statistical distributions  deep learning approximations  probabilistic graphical models  candidate future agent behavior  crowded environments  human-driven vehicles  human-robot collaborative bin packing  multimodal probability distribution  multihuman interactions  basketball player trajectories  multimodal multihuman behavior  self-driving cars  warehouse  autoencoders  response dynamics  robotic applications  proxy  Trajectory  Predictive models  Analytical models  Deep learning  Ground penetrating radar  Data models  Robots 
Abstract: This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.


Title: Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs
Key Words: convolutional neural nets  image fusion  learning (artificial intelligence)  convolutional network  part affordances  object affordances  affordance detection network  physical properties  geometrical structures  two-stream fully convolutional network  potential affordances  multimodal encoding  geometrical properties  abstract rich photometrical properties  depth images  powerful discriminative features  decoding stream  encoding streams  RGB-D data  Feature extraction  Encoding  Task analysis  Robots  Streaming media  Decoding  Fuses  Affordance detection network (ADNet)  fully convolutional network (FCN) 
Abstract: For a robot to manipulate an object, it has to understand the functions and the actions that can be subjected to the object. This set of information is known as affordance of the object. Affordances are generally defined by the geometrical structures and physical properties of the objects. In this paper, we present an affordance detection network (ADNet) for detecting object affordances using multimodal input i.e., RGB-D data. The method is based on the state-of-the-art fully convolutional network with two encoding streams and one decoding stream. In the presented formulation, the network learns powerful discriminative features independently from the RGB and depth images, which enables it to abstract rich photometrical and geometrical properties of the objects. The multimodal encoding is combined at multiple stages of the network using the late-fusion strategy and used is for predicting the potential affordances of the objects.


Title: Deep Multi-Sensor Lane Detection
Key Words: driver information systems  image sensors  neural nets  object detection  optical radar  road traffic  multisensor lane detection  reliable lane detection  accurate lane detection  long-standing problem  autonomous driving  image space  accurate image estimates  precise 3D lane boundaries  modern motion planning algorithms  deep neural network  camera sensors  accurate estimates  LiDAR  Cameras  Three-dimensional displays  Laser radar  Sensors  Roads  Task analysis  Reliability 
Abstract: Reliable and accurate lane detection has been a long-standing problem in the field of autonomous driving. In recent years, many approaches have been developed that use images (or videos) as input and reason in image space. In this paper we argue that accurate image estimates do not translate to precise 3D lane boundaries, which are the input required by modern motion planning algorithms. To address this issue, we propose a novel deep neural network that takes advantage of both LiDAR and camera sensors and produces very accurate estimates directly in 3D space. We demonstrate the performance of our approach on both highways and in cities, and show very accurate estimates in complex scenarios such as heavy traffic (which produces occlusion), fork, merges and intersections.


Title: Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments
Key Words: learning (artificial intelligence)  legged locomotion  path planning  robot vision  wheels  navigation skills  navigation behaviors  action policies training  height-map image observations  motor commands  dynamic environments  mobile robot navigation  complex environments  deep reinforcement learning  wheel-legged robots  Training  Task analysis  Navigation  Mobile robots  Trajectory  Robot sensing systems 
Abstract: Mobile robot navigation in complex and dynamic environments is a challenging but important problem. Reinforcement learning approaches fail to solve these tasks efficiently due to reward sparsities, temporal complexities and high-dimensionality of sensorimotor spaces which are inherent in such problems. We present a novel approach to train action policies to acquire navigation skills for wheel-legged robots using deep reinforcement learning. The policy maps height-map image observations to motor commands to navigate to a target position while avoiding obstacles. We propose to acquire the multifaceted navigation skill by learning and exploiting a number of manageable navigation behaviors. We also introduce a domain randomization technique to improve the versatility of the training samples. We demonstrate experimentally a significant improvement in terms of data-efficiency, success rate, robustness against irrelevant sensory data, and also the quality of the maneuver skills.


Title: Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network
Key Words: convolutional neural nets  learning (artificial intelligence)  object detection  robot vision  statistical analysis  support vector machines  patched convolutional neural network  semantic-aware patch-level convolutional neural network  statistical features  multiclass support vector machine  deep learning framework  robotic applications  vision systems  shadow detection methods  Image color analysis  Image edge detection  Support vector machines  Robots  Image segmentation  Training  Time complexity 
Abstract: In recent years, various shadow detection methods from a single image have been proposed and used in vision systems; however, most of them are not appropriate for the robotic applications due to the expensive time complexity. This paper introduces a fast shadow detection method using a deep learning framework, with a time cost that is appropriate for robotic applications. In our solution, we first obtain a shadow prior map with the help of multi-class support vector machine using statistical features. Then, we use a semantic-aware patch-level Convolutional Neural Network that efficiently trains on shadow examples by combining the original image and the shadow prior map. Experiments on benchmark datasets demonstrate the proposed method significantly decreases the time complexity of shadow detection, by one or two orders of magnitude compared with state-of-the-art methods, without losing accuracy.


Title: Heterogeneous Sensor-Robot Team Positioning and Mixed Strategy Scheduling
Key Words: game theory  multi-robot systems  scheduling  sensor placement  simulated annealing  heterogeneous sensor-robot team positioning  mixed strategy scheduling  effector robots  anticipated arrival traffic  adversarial game  sensor positions  anticipated potential arrival paths  uniform power schedule  adaptive simulated annealing  Robot sensing systems  Schedules  Robot kinematics  Games  Linear programming 
Abstract: We are faced with the problem of optimally placing a heterogeneous team of sensors and effector robots in an area while taking into account the environment, anticipated arrival traffic, and desired power consumption of the team. We stage the problems of anticipating arrival traffic and determining a proper power schedule as an adversarial game, incorporating our analysis of the game in the objective function which evaluates sensor positions. We obtain the set of sensor positions which performs best at the desired power consumption, evaluating the mixed strategy of sensor activity that best counters the anticipated potential arrival paths. To determine an approximate global optima for a large number of heterogeneous nodes, we employ Adaptive Simulated Annealing (ASA) to ensure our algorithm is flexible over a varied range of scenarios. We compare the proposed algorithm to a gradient-based greedy placement algorithm with a uniform power schedule within simulation.


Title: Robotic Subsurface Pipeline Mapping with a Ground-penetrating Radar and a Camera
Key Words: buried object detection  geophysical image processing  geophysical techniques  ground penetrating radar  image reconstruction  maximum likelihood estimation  pipelines  radar detection  radar imaging  robot vision  pipeline groups  hyperbola response  GPR sensing process  Ground Penetrating Radar scans  subsurface pipeline mapping method  robotic subsurface pipeline mapping  subsurface pipes  representative pipeline configurations  maximum likelihood estimation  J-Linkage method  hyperbolas  GPR scans  mapping outputs  visual simultaneous localization  nonperpendicular angles  general scanning  size 4.69 cm  Ground penetrating radar  Pipelines  Cameras  Three-dimensional displays  Trajectory  Robot sensing systems 
Abstract: We propose a novel subsurface pipeline mapping method by fusing Ground Penetrating Radar (GPR) scans and camera images. To facilitate the simultaneous detection of multiple pipelines, we model the GPR sensing process and prove hyperbola response for general scanning with non-perpendicular angles. Furthermore, we fuse visual simultaneous localization and mapping outputs, encoder readings with GPR scans to classify hyperbolas into different pipeline groups. We extensively apply the J-Linkage method and maximum likelihood estimation to improve algorithm robustness and accuracy. As the result, we optimally estimate the radii and locations of all pipelines. We have implemented our method and tested it in physical experiments with representative pipeline configurations. The results show that our method successfully reconstructs all subsurface pipes. Moreover, the average localization error is 4.69cm.


Title: Octree map based on sparse point cloud and heuristic probability distribution for labeled images
Key Words: calibration  cameras  convolutional neural nets  image recognition  object recognition  octrees  probability  stereo image processing  semantic octree maps  probabilistic octree framework  single lidar scans  octree map building algorithm  labeled lidar scan  camera-lidar calibration parameters  convolutional neural network  accurate driving maneuvers  automated vehicle  urban roads  labeled images  heuristic probability distribution  sparse point cloud  Three-dimensional displays  Semantics  Laser radar  Uncertainty  Octrees  Cameras  Buildings 
Abstract: To navigate through urban roads, an automated vehicle must be able to perceive and recognize objects in a three-dimensional environment. A high level contextual understanding of the surroundings is necessary to execute accurate driving maneuvers. This paper presents a novel approach to build three dimensional semantic octree maps from lidar scans and the output of a convolutional neural network (CNN) to obtain the labels of the environment. We present a heuristic method to associate uncertainties to the labels from the images based on a combination of the labels themselves, score maps retrieved by the CNN and the raw images. These uncertainties and the camera-lidar calibration parameters for multiple cameras are considered in the projection of the labels and their uncertainties into the point cloud. Every labeled lidar scan works as an input to an octree map building algorithm that calculates and updates the label probabilities of the voxels in the map. This paper also presents a qualitative and quantitative evaluation of accuracy, analyzing projection in single lidar scans and complete maps built with our probabilistic octree framework.


Title: A B-Spline Mapping Framework for Long-Term Autonomous Operations
Key Words: image representation  image sensors  mobile robots  navigation  path planning  robot vision  SLAM (robots)  splines (mathematics)  landmark-based maps  robotics community  high frequency sensor  B-spline curves  B-spline maps  mapping algorithm  2D B-spline mapping framework  outdoor long-term autonomous operations  simultaneous localization and mapping  SLAM algorithm  software-in-the-loop simulations  Splines (mathematics)  Simultaneous localization and mapping  Three-dimensional displays  Robot kinematics  Two dimensional displays 
Abstract: This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.


Title: Adaptive Baseline Monocular Dense Mapping with Inter-Frame Depth Propagation
Key Words: image matching  image reconstruction  image sequences  stereo image processing  monocular dense mapping methods  frame-to-frame propagated depth filter  wide-baseline observations  sequential input images  adaptive baseline matching cost computation  sequential depth estimation  multibaseline observations  separate multiview stereo problems  image sequence  inter-frame depth propagation  adaptive baseline monocular dense mapping  Estimation  Cameras  Probabilistic logic  Adaptive systems  Image sequences  Real-time systems  Robot vision systems 
Abstract: State-of-the-art monocular dense mapping methods usually divide the image sequence into several separate multi-view stereo problems thus have limited utilization of the information in multi-baseline observations and sequential depth estimations. In this paper, two core contributions are proposed to improve the mapping performance by exploiting the information. The first is an adaptive baseline matching cost computation that uses the sequential input images to provide each pixel with wide-baseline observations. The second is a frame-to-frame propagated depth filter which integrates the sequential depth estimation of the same physical point in a robust probabilistic manner. Two contributions are integrated into a monocular dense mapping system that generates the depth maps in real-time for both pinhole and fisheye cameras. Our system is fully parallelized and can run at more than 25 fps on a Nvidia Jetson TX2. We compare our work with state-of-the-art methods on the public dataset. Onboard UAV mapping and handhold experiments are also used to demonstrate the performance of our method. For the benefit of the community, we make the implementation open source.


Title: Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
Key Words: collision avoidance  human-robot interaction  mobile robots  optical radar  path planning  probability  directional grid maps  occupancy map  mobile robot  robotic arm  static environments  dynamic objects  safer navigation  human-robot interaction  directional statistics  robotic mapping  model circular data  angular motion  probability measure-field  angular variations  indoor environments  outdoor environments  dynamic environments  grid maps  multimodal angular uncertainty  Vehicle dynamics  Robot sensing systems  Data models  Uncertainty  Navigation 
Abstract: Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.


Title: Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick
Key Words: biomechanics  bone  humanoid robots  kinematics  mobile robots  motion control  muscle  swimming style  musculoskeletal humanoid robot  Triton  flexible spine  erector spinae muscles  stiffness adjustment system  lumbar joints  musculoskeletal body  multijoint coordination  pneumatic muscles  lightweight properties  inherently waterproof properties  human swimming  musculoskeletal swimming robot  joint angle  thrust force  biomechanical research  underwater dolphin kick  Muscles  Dolphins  Force  Legged locomotion  Sports 
Abstract: The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.


Title: Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)
Key Words: humanoid robots  hydraulic control equipment  hydraulic systems  legged locomotion  magnetorheology  robust control  vibration control  wheels  magnetorheological fluid-based damper  hydraulic wheel-legged robot  terrain environments  direct-drive wheels  hydraulic system  environmental adaptability  mobile abilities  innovative design  robustness  humanoid structural design  multimodal locomotion  wheel-legged hybrid robot  WLR  Conferences  Intelligent robots 
Abstract: Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.


Title: Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study
Key Words: biomechanics  medical robotics  motion control  robot dynamics  robot kinematics  shock absorbers  viscoelasticity  wearable robots  lower-extremity wearable link mechanism  exoskeleton robot  shock absorbing exoskeleton  human skeletal system  human-exoskeleton coupled system  vertical mobility system  dynamic models  kinematic models  multielement viscoelastic model  Exoskeletons  Electric shock  Muscles  Joints  Bones  Force  Injuries 
Abstract: The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.


Title: Human Motion Prediction Under Social Grouping Constraints
Key Words: Markov processes  mobile robots  motion control  multi-robot systems  planning (artificial intelligence)  probability  random processes  human motion prediction  social grouping constraints  long-term prediction  social relations  social norms  surrounding agents  MDP planning problem  social forces  social grouping information  prediction process  soft formation constraints  mobile robots  Force  Task analysis  Trajectory  Predictive models  Computational modeling  Tracking  Planning 
Abstract: Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.


Title: Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans
Key Words: human-robot interaction  Kalman filters  mobile robots  multi-robot systems  path planning  risk analysis  trajectory control  risk-based human-aware multirobot coordination  dynamic environments  human-populated environments  Kalman filter  position estimation  MRTA problem  human trajectory prediction  multirobot task allocation problem  human-aware navigation  risk-based bids  risk-based human-aware planning  human-agnostic planning  prediction error  Robot kinematics  Task analysis  Navigation  Planning  Uncertainty  Estimation 
Abstract: In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.


Title: Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
Key Words: collision avoidance  emergency management  mobile robots  motion control  multi-robot systems  trajectory control  safe navigation  safe motion controls  emergency trajectory candidates  just-in-time emergency trajectories  autonomous navigation  vehicle operation  safe system state  MHTP  moving horizon trajectory planner  safety requirements  vehicle's local control system  differential-drive mobile agent  nonstatic environment  robot  Trajectory  Safety  Navigation  Robots  Vehicle dynamics  Planning  Collision avoidance 
Abstract: Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.


Title: PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
Key Words: feature extraction  mobile robots  optical radar  path planning  local views  sliding window fashion  matching current  old features  map representation  local maps  off-road environments  single localization failure  distinctive features  coined PoseMap  dynamic environments  robotic systems  long-term localization  multienvironment 3D LiDAR localization  frequency 8.0 Hz  time 18.0 month  Simultaneous localization and mapping  Three-dimensional displays  Laser radar  Optimization  Feature extraction 
Abstract: Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.


Title: Domain Randomization and Generative Models for Robotic Grasping
Key Words: grippers  learning (artificial intelligence)  neural nets  planning (artificial intelligence)  probability  domain randomization  generative models  deep learning-based robotic grasping  significant progress thanks  algorithmic improvements  increased data availability  state-of-the-art models  unique object instances  result generalization  novel data generation pipeline  deep neural network  successful grasps  autoregressive grasp planning model  probability distribution  possible grasps  sample grasps  test time  model architecture  unseen realistic objects  random objects  real-world grasp  random simulated objects  Grasping  Training  Data models  Computational modeling  Robot sensing systems  Neural networks 
Abstract: Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.


Title: Robust Exploration with Multiple Hypothesis Data Association
Key Words: image fusion  mobile robots  robot vision  SLAM (robots)  target tracking  tree searching  joint compatibility branch  simultaneous localization and mapping  map accuracy  diverse hypotheses  multiple hypothesis tracking  robust back-ends  catastrophic failure  single false positive assignment  rich features  autonomous exploration  SLAM  ambiguous data association problem  multiple hypothesis data association  robust exploration  Simultaneous localization and mapping  Trajectory  Noise measurement  State estimation  Optimization  Measurement uncertainty 
Abstract: We study the ambiguous data association problem confronting simultaneous localization and mapping (SLAM), specifically for the autonomous exploration of environments lacking rich features. In such environments, a single false positive assignment might lead to catastrophic failure, which even robust back-ends may be unable to resolve. Inspired by multiple hypothesis tracking, we present a novel approach to effectively manage multiple hypotheses (MH) of data association inherited from traditional joint compatibility branch and bound (JCBB), which entails the generation, ordering and elimination of hypotheses. We analyze the performance of MHJCBB in two particular situations, one applying it to SLAM over a predefined trajectory and the other showing its applicability in exploring unknown environments. Statistical results demonstrate that MHJCBB's maintenance of diverse hypotheses under ambiguous conditions significantly improves map accuracy.


Title: Simultaneous Task Allocation and Planning Under Uncertainty
Key Words: control engineering computing  formal verification  iterative methods  Markov processes  mobile robots  multi-robot systems  operating systems (computers)  path planning  resource allocation  robot programming  temporal logic  simultaneous task allocation  uncertain environments  individual robot behaviour  linear temporal logic  multirobot policies  simultaneous task planning  Markov decision processes  formal verification  multirobot operating systems  Task analysis  Planning  Robot kinematics  Resource management  Uncertainty  Probabilistic logic 
Abstract: We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.


Title: Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment
Key Words: backpropagation  collision avoidance  error compensation  fusion reactor design  fusion reactor instrumentation  high energy physics instrumentation computing  manipulator kinematics  neural nets  physical instrumentation control  plasma toroidal confinement  Tokamak devices  nuclear fusion environment  Experimental Advanced Superconducting Tokamak  noncircular cross-section  real-time detection  plasma discharges  EAMA system design  vacuum-available design scheme  error prediction  EAST articulated maintenance arm  repair operations  internal components  high temperature environments  flexible robot arms  error compensation  flexible multijoint manipulator  EAST ultrahigh vacuum condition  inverse kinematics  obstacle avoidance strategy  back-propagation neural network  integrated control strategy  temperature 80.0 degC to 120.0 degC  Manipulators  Kinematics  Predictive models  Load modeling  Error compensation  Strain 
Abstract: Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10-5Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.


Title: End to End Vehicle Lateral Control Using a Single Fisheye Camera
Key Words: automobiles  cameras  collision avoidance  convolutional neural nets  mobile robots  robot vision  steering systems  label augmentation  short range fisheye camera  open road driving  single fisheye camera  convolutional neural networks  steering angle  autonomous cars  end-to-end control evaluation  end-to-end vehicle lateral control  urban road  sharp turns  obstacle avoidance  data augmentation  Automobiles  Cameras  Roads  Training  Neural networks  Testing 
Abstract: Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.


Title: Game-Theoretic Cooperative Lane Changing Using Data-Driven Models
Key Words: game theory  learning (artificial intelligence)  Markov processes  multi-agent systems  road traffic  data-driven models  self-driving vehicles  autonomous driving  road-bound multivehicle systems  DRL  game theory  proactive-passive lane changing framework  Markov game  multiagent autonomous vehicle tasks  deep reinforcement learning  single-agent RL setting  Games  Markov processes  Merging  Reinforcement learning  Autonomous vehicles  Neural networks  Space vehicles 
Abstract: Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.


Title: Modular Sensor Fusion for Semantic Segmentation
Key Words: image segmentation  learning (artificial intelligence)  sensor fusion  statistical analysis  training sets  single modality segmentation results  statistical models  competitive performance  statistical fusion approaches  aligned multisensor training data  specific architecture  semantic segmentation approaches  current multisensor deep learning  real-world operations  perceptual range  robotic systems  fundamental process  modular sensor fusion  Semantics  Image segmentation  Robot sensing systems  Training  Fuses  Computer architecture 
Abstract: Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.


Title: Robust Visual-Inertial State Estimation with Multiple Odometries and Efficient Mapping on an MAV with Ultra-Wide FOV Stereo Vision
Key Words: autonomous aerial vehicles  cameras  distance measurement  estimation theory  image fusion  image sensors  inertial navigation  motion estimation  motion measurement  state estimation  stereo image processing  visual perception  wide-angle stereo cameras  multicopter system  inertial measurement unit  virtual pinhole cameras  independent visual odometry  vision system  sensor fusion  robust visual-inertial state estimation  ultrawide FOV stereo vision  MAV  IMU  robust visual-inertial navigation  omnidirectional 3D mapping pipeline experiment  field of view  synthesized pinhole stereo systems  motion estimation fusion  image processing  multiVO approach  Cameras  Distortion  Image resolution  Computational modeling  Navigation  Visual odometry  Hardware 
Abstract: The here presented flying system uses two pairs of wide-angle stereo cameras and maps a large area of interest in a short amount of time. We present a multicopter system equipped with two pairs of wide-angle stereo cameras and an inertial measurement unit (IMU) for robust visual-inertial navigation and time-efficient omni-directional 3D mapping. The four cameras cover a 240 degree stereo field of view (FOV) vertically, which makes the system also suitable for cramped and confined environments like caves. In our approach, we synthesize eight virtual pinhole cameras from four wide-angle cameras. Each of the resulting four synthesized pinhole stereo systems provides input to an independent visual odometry (VO). Subsequently, the four individual motion estimates are fused with data from an IMU, based on their consistency with the state estimation. We describe the configuration and image processing of the vision system as well as the sensor fusion and mapping pipeline on board the MAV. We demonstrate the robustness of our multi-VO approach for visual-inertial navigation and present results of a 3D-mapping experiment.


Title: Plugo: A Scalable Visible Light Communication System Towards Low-Cost Indoor Localization
Key Words: free-space optical communication  indoor communication  photodiodes  Plugo  novel VLC system  cheap photodiode receiver  VLC-based localization techniques  location-aware applications  scalable visible light communication system  preliminary localization result  VLC signals  low-cost offthe-shelf components  compact VLC-compatible  dedicated wireless access points  conventional RF-based approaches  low-cost indoor localization  random multiple access  Light emitting diodes  Receivers  Wireless communication  Optical transmitters  Encoding  Frequency modulation 
Abstract: Indoor localization is critical to many location-aware applications, however, a low-cost solution with guaranteed accuracies has not yet come. Visible Light Communication (VLC-) based localization techniques are very promising to fill this gap. In this paper, we propose Plugo, a novel VLC system with random multiple access towards low-cost indoor localization. Compared to conventional RF-based approaches that rely on dedicated wireless access points as location beacons, the proposed system has the potential to deliver better accuracies with reduced cost. Specifically, we build a handful of compact VLC-compatible LED bulbs out of low-cost offthe-shelf components (around $10 total cost for each assembly) and recover VLC signals using a cheap photodiode receiver. The basic framed slotted Additive Links On-line Hawaii Area (ALOHA) is exploited to achieve random multiple access over the shared optical medium. We show its effectiveness in beacon broadcasting by experiments, and further, demonstrate a preliminary localization result with sound accuracy by using fingerprinting-based methods in a customized testbed.


Title: Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates
Key Words: convergence  mobile robots  multi-robot systems  composition strategy  mobile robots  multirobot systems  efficient solution  low-level tasks  high-level missions  single behavior  requisite expressiveness  provably correct composition  terminal configuration  valid initial configuration  nominal control inputs  control barrier certificates  finite-time convergence control barrier functions  information-exchange network  Convergence  Robot kinematics  Task analysis  Multi-robot systems  Mobile robots  Robot sensing systems 
Abstract: In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.


Title: Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization
Key Words: learning (artificial intelligence)  mobile robots  multi-robot systems  oceanographic equipment  optimisation  underwater equipment  unsupervised learning  distributed spatiotemporal topic models  real seabed imagery  multirobot underwater terrain characterization  local robot topic distributions  local topic model  multirobot distributed learning  marine robots  multirobot teams  multiple robots  single-robot topic models  learned models  unsupervised models  raw data  latent structure  Bayesian topic models  unsupervised learning techniques  multirobot terrain characterization  Adaptation models  Robot sensing systems  Spatiotemporal phenomena  Data models  Visualization  Mathematical model 
Abstract: Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.


Title: On the Use of Energy Tanks for Multi-Robot Interconnection
Key Words: mobile robots  multi-robot systems  robust control  energy tank  multirobot systems passive interconnections  robustly stable cooperative behavior  passivity constraint  novel generalized interconnection  passive systems  coupled system  Couplings  Damping  Robots  Multi-robot systems  Robust stability  Buildings  Nonlinear dynamical systems 
Abstract: In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.


Title: A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications
Key Words: database management systems  multi-robot systems  multirobot applications  robots  log files  querying features  scaling capabilities  modern databases  multirobot systems  robotic use cases  benchmarking scenarios  networked multirobot architectures  extensible workbench  benchmarking databases  Databases  Robot sensing systems  Benchmark testing  Containers  Systems architecture 
Abstract: Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.


Title: Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks
Key Words: mobile robots  multi-robot systems  self-assembly  robots measure  frame-work  infinitesimally shape-similar frameworks  shape-similarity matrix  differential-drive robots  formation control strategies  multirobot team  infinitesimal shape-similarity  Robot sensing systems  Transmission line matrix methods  Self-assembly  Shape  Trajectory  Multi-Robot Systems 
Abstract: Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.


Title: Optimal Redeployment of Multirobot Teams for Communication Maintenance
Key Words: approximation theory  computational complexity  human-robot interaction  integer programming  linear programming  mobile robots  multi-robot systems  optimal redeployment  multirobot teams  communication maintenance  mobile robots  communication relays  computational complexity  Integer Linear Programming formulation  approximation hardness  Maintenance engineering  Relays  Task analysis  Complexity theory  Linear programming  Mobile robots 
Abstract: In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.


Title: Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
Key Words: aerospace robotics  dynamic programming  integer programming  linear programming  mobile robots  multi-robot systems  path planning  visibility-based monitoring  heterogeneous robot team  terrain path  aerial robots  route planning  dynamic programming approach  integer linear programming solution  ground robots  Unmanned aerial vehicles  Robot sensing systems  Educational robots  Monitoring  Dynamic programming  Integrated circuits 
Abstract: We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.


Title: Algorithms for Task Allocation in Homogeneous Swarm of Robots
Key Words: control system synthesis  decentralised control  feedback  Markov processes  mobile robots  multi-robot systems  task allocation  homogeneous swarm  homogeneous robots  Markov chain  agent converges  local-decentralized controllers  controller design  local-feedback  Task analysis  Markov processes  Robot kinematics  Kernel  Probabilistic logic  Q measurement 
Abstract: In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.


Title: Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform
Key Words: humanoid robots  legged locomotion  manipulators  robot dynamics  autonomous legged personal helper robot  enhanced dynamics  multimodal legged robotic platform  versatile 3D ZMP trajectory optimization algorithm  stable locomotion  multimodal robotic platform  2D zero moment point trajectory optimization  manipulation  light weight robotic system  Legged locomotion  Foot  Trajectory  Heuristic algorithms  Task analysis 
Abstract: This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.


Title: Leg Design to Enable Dynamic Running and Climbing on BOBCAT
Key Words: legged locomotion  manipulator dynamics  robot kinematics  design tool  leg configuration  multimodal platform BOBCAT  leg design  design process  leg morphology  manipulator community  dynamic workspace  template dynamics  dynamic climbing  dynamic running  Legged locomotion  Dynamics  Couplings  Force  Kinematics  Foot 
Abstract: The design process for leg morphology has taken much of its inspiration from the manipulator community, including the concept of maximizing the workspace of a design. In this paper, we define the concept of Effective Dynamic Workspace, which examines the subset of the overall workspace capable of achieving the desired template dynamics. With this new design tool, the leg configuration of a new multi-modal platform BOBCAT is examined and refined. With the refined design, BOBCAT is able to achieve speeds of 2m/s while running and 0.17m/s while climbing a vertical wall.


Title: Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors
Key Words: biomedical optical imaging  blood vessels  brain  collision avoidance  Doppler measurement  image motion analysis  laser applications in medicine  medical image processing  medical robotics  needles  pose estimation  steering systems  surgery  percutaneous procedures  hemorrhage  vessel motion  tissue bulk motion  Doppler signals  multiple forward looking sensors  preoperative imaging modalities  vessel pose estimation  needle steering systems  robotic assisted needle insertion process  vessel detection  biologically inspired steerable needle  laser Doppler flowmetry  life threatening complications  percutaneous interventions  needle steering surgery  obstacle avoidance  Needles  Probes  Phantoms  Sensors  Doppler effect  Gold  Grey matter 
Abstract: During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.


Title: ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery
Key Words: biomedical optical imaging  cameras  endoscopes  image sensors  Kalman filters  medical image processing  medical robotics  orthopaedics  SLAM (robots)  surgery  image feedback  ArthroSLAM  Simultaneous Localisation and Mapping system  SLAM system  external camera  robotic arm  minimally invasive arthroscopic surgery  minimally invasive orthopedic surgery  robotic orthopedic surgical assistant  knee section  human cadaver knee joint  Extended Kalman Filter framework  arthroscope holder  intraarticular space  Cameras  Robot vision systems  Visualization  Reliability 
Abstract: Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.


Title: Recursive Bayesian Human Intent Recognition in Shared-Control Robotics
Key Words: Bayes methods  control engineering computing  human-robot interaction  inference mechanisms  mobile robots  telerobotics  recursive Bayesian human intent recognition  shared-control robotics  human-robot collaboration  mathematical formulation  assistive teleoperation  recursive Bayesian filtering approach models  nonverbal observations  contextual observations  goal-directed actions  human inference  robot motion  autonomy intent inference performance  shared-control operation  probabilistic reasoning  human intent recognition  human agents behavior  probabilistic fusion  Robots  Bayes methods  Task analysis  Hidden Markov models  Uncertainty  Mathematical model  Probabilistic logic 
Abstract: Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.


Title: Robot Identification and Localization with Pointing Gestures
Key Words: distance measurement  gesture recognition  mobile robots  multi-robot systems  pose estimation  robot vision  SLAM (robots)  mobile robot  multirobot scenarios  robot identification and localization  gesture pointing  robot odometry frame  inertial measurement unit  IMU  Robot sensing systems  Robot kinematics  Solid modeling  Manipulators  Drones  Three-dimensional displays 
Abstract: We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.


Title: Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions
Key Words: cameras  computer vision  image motion analysis  image segmentation  image sensors  image sequences  motion estimation  object detection  object tracking  stereo image processing  dynamic scene  multimotion visual odometry pipeline  MVO  dynamic objects  motion capture system  simultaneous estimation  third-party motions  computer vision  previous work  moving camera  largely static environment  segment  tracking-by-detection  motion constraints  planar motion  SE motion  scene flow  unconstrained motions  camera motions  object tracking  stereo/RGB-D camera  multimodal visual odometry pipeline  Cameras  Motion segmentation  Tracking  Dynamics  Trajectory  Estimation  Image segmentation 
Abstract: Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.


Title: An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication
Key Words: cooperative communication  inspection  mobile robots  protocols  automatic tracked robot chain system  gas pipeline inspection  wireless relay communication  wireless signal attenuation  relay communication node  wireless application layer communication protocol  relay transmission efficiency  RSSI-based coordinated movement  Robot sensing systems  Robot kinematics  Pipelines  Relays  Wireless communication  Wireless sensor networks 
Abstract: Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.


Title: Multi-Level Bayesian Decision-Making for Safe and Flexible Autonomous Navigation in Highway Environment
Key Words: Bayes methods  control engineering computing  decision making  navigation  probability  road safety  road traffic control  road vehicles  traffic engineering computing  TSLDN  driving situation assessment  vehicle navigation task  control architecture  probabilistic decision-making  safe navigation  flexible autonomous navigation  highway environment  MCA  multi-level Bayesian decision-making  multi-controller architecture  two-sequential level decision network  Extended Time-To-Collision metric  ETTC metric  Predicted Inter-Distance Profile  Safety  Decision making  Navigation  Trajectory  Road transportation  Uncertainty  Probabilistic logic 
Abstract: This paper proposes an overall Multi-Controller Architecture (MCA) for safe and flexible navigation of autonomous navigation, under uncertainties in highway use-cases. In addition to the details given about the main modules (and their interactions) composing the proposed MCA, an important focus of the paper is made on the definition of a robust Two-Sequential Level Decision Network (TSLDN), which uses both: Extended Time-To-Collision (ETTC) metric and a new definition of a specific Predicted Inter-Distance Profile (PIDP, between vehicles during lane changes maneuvers) in order to estimate the maneuvers risks. The TSLDN is utilized for: the driving situation assessment, decision-making and for safety retrospection over the current maneuver risk. It allows us to have the best decision to achieve the vehicle navigation task while maximizing its safety. Several simulation results show the good performance of the overall proposed control architecture, mainly in terms of efficiency to handle probabilistic decision-making even for very risky scenarios.


Title: FEM-Based Deformation Control for Dexterous Manipulation of 3D Soft Objects
Key Words: control engineering computing  dexterous manipulators  elasticity  finite element analysis  force sensors  mobile robots  robot vision  solid modelling  finite element method  Lagrange multipliers  elasticity parameters  3D soft objects  dexterous manipulation  FEM-based deformation control  soft cylindrical object  manipulation task  underactuated anthropomorphic hand  force sensor  contact points  in-hand manipulation  anthropomorphic device  Strain  Finite element analysis  Robots  Deformable models  Three-dimensional displays  Biological system modeling  Estimation 
Abstract: In this paper, a method for dexterous manipulation of 3D soft objects for real-time deformation control is presented, relying on Finite Element modelling. The goal is to generate proper forces on the fingertips of an anthropomorphic device during in-hand manipulation to produce desired displacements of selected control points on the object. The desired motions of the fingers are computed in real-time as an inverse solution of a Finite Element Method (FEM), the forces applied by the fingertips at the contact points being modelled by Lagrange multipliers. The elasticity parameters of the model are preliminarly estimated using a vision system and a force sensor. Experimental results are shown with an underactuated anthropomorphic hand that performs a manipulation task on a soft cylindrical object.


Title: Real-Time Grasp Planning for Multi-Fingered Hands by Finger Splitting
Key Words: grippers  iterative methods  learning (artificial intelligence)  optimisation  time grasp planning  multifingered hands  traditional planning methods  optimal parallel grasps  dual-stage iterative optimization  contact point optimization  finger splitting  Optimization  Planning  Grippers  Search problems  Grasping  Databases  Real-time systems 
Abstract: Grasp planning for multi-fingered hands is computationally expensive due to the joint-contact coupling, surface nonlinearities and high dimensionality, thus is generally not affordable for real-time implementations. Traditional planning methods by optimization, sampling or learning work well in planning for parallel grippers but remain challenging for multi-fingered hands. This paper proposes a strategy called finger splitting, to plan precision grasps for multi-fingered hands starting from optimal parallel grasps. The finger splitting is optimized by a dual-stage iterative optimization including a contact point optimization (CPO) and a palm pose optimization (PPO), to gradually split fingers and adjust both the contact points and the palm pose. The dual-stage optimization is able to consider both the object grasp quality and hand manipulability, address the nonlinearities and coupling, and achieve efficient convergence within one second. Simulation results demonstrate the effectiveness of the proposed approach. The simulation video is available at [1].


Title: Adaptive Robot Body Learning and Estimation Through Predictive Coding
Key Words: actuators  adaptive control  Bayes methods  Gaussian processes  humanoid robots  human-robot interaction  learning (artificial intelligence)  manipulator kinematics  mobile robots  regression analysis  sensor fusion  nonlinear actuators  noisy sensory information  computational perceptual model  predictive processing  arbitrary sensors  Gaussian additive noise  Gaussian process regression  robot body configuration belief  sensory prediction errors  multisensory robotic arm  additive errors  adaptive robot body learning  predictive coding  predictive functions  sensorimotor integration  human-robot interaction  sensor modalities contributions  sensory visuo-tactile perturbations  Robot sensing systems  Visualization  Estimation  Computational modeling  Adaptation models  Bio-inspired perception  body-schema  predictive processing  embodied artificial intelligence  learning and adaptive systems  humanoid robotics 
Abstract: The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.


Title: Cost Adaptation for Robust Decentralized Swarm Behaviour
Key Words: computer games  control engineering computing  decentralised control  learning (artificial intelligence)  multi-agent systems  multi-robot systems  optimisation  robot dynamics  cost adaptation  decentralized receding horizon control  multiagent settings  meta-learning process  mesh-networked swarm agents  adaptation mechanism  safer task completion  Unity3D game engine  D-RHC  robust decentralized swarm behaviour  Task analysis  Delays  Decision making  Cost function  Mesh networks  Control systems 
Abstract: Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multiagent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process - cost adaptation - which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.


Title: An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge
Key Words: dexterous manipulators  grippers  motion control  tactile sensors  vibrations  extrinsic dexterity approach  IROS 2018 fan robotic challenge  Spanish folding fan  dexterous manipulation  robotic systems  external dexterity  high DoF grippers  3D-printed adaptation  multimodal tactile sensor  Fans  Grippers  Robot kinematics  Service robots  Task analysis  End effectors 
Abstract: The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.


Title: A Universal Controller for Unmanned Aerial Vehicles
Key Words: aerodynamics  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  helicopters  mobile robots  UAVs  agile fixed-wing aircraft  control logic  unmanned aerial vehicles  tilt-rotor  vehicle flight envelope  single physics-based controller  multicopters  autonomous flight  quadrotor  Force  Aircraft  Quaternions  Attitude control  Actuators 
Abstract: Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.


Title: MMAC Height Control System of a Quadrotor for Constant Unknown Load Transportation
Key Words: adaptive control  control system synthesis  helicopters  Kalman filters  linear quadratic control  motion sensors  quadrotor  multimodel adaptive controller  LQR  IMU  motion sensors  state variables  constant unknown load transportation  MMAC height control system  ultrasound height sensor  Kalman filter  Gravity  Estimation  Sensors  Kalman filters  Computational modeling  Control systems  Transportation 
Abstract: This paper presents a methodology for height control of a quadrotor that transports a constant unknown load, given the estimates on both weight and state variables, based on measurements from motion sensors installed on-board. The proposed control and estimation framework is a Multi-Model Adaptive Controller using LQR with integrative action and Kalman filter with integrative component. The control system obtained is validated both in simulation and experimentally, resorting to an off-the-shelf commercially available quadrotor equipped with an IMU, an ultrasound height sensor, and a barometer, among other sensors.


Title: Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System
Key Words: aerospace robotics  decentralised control  helicopters  Lyapunov methods  materials handling  mobile robots  motion control  multi-robot systems  optical tracking  stability  energetic passivity property  drone on-board IMUs  Lyapunov analysis  optical tracking systems  three-drone payload transport system  motion stability  cable-suspended payload  multiple conventional quadcopters  cabled-based multidrone load transport system  decentralized motion control  Payloads  Drones  Force  Stability analysis  Trajectory 
Abstract: A provably stable decentralized control scheme is proposed to allow multiple conventional quadcopters carry a cable-suspended payload. The method exploits a fundamental energetic passivity property of the combined drones, cables, and payload system to stably move the payload from its origin to destination. This is achieved without making any assumption about the status of the cables tension during the flight, and any measurement from the payload. The controller is decentralized in the sense that inter-drone communication of feedback measurements is not required. Motion stability is demonstrated via a Lyapunov analysis. The proposed controller is successfully implemented on a three-drone payload transport system in an indoor environment, using measurement from an optical tracking systems and the drones on-board IMUs.


Title: SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors
Key Words: aircraft control  autonomous aerial vehicles  human-robot interaction  microrobots  multi-robot systems  path planning  tactile sensors  trajectory control  impedance controlled swarm  nanoquadrotors  novel interaction strategy  human-swarm communication  human operator guides  quadrotors  impedance control  human hand velocity  formation shape  Crazyflie 2.0 quadrotor platform  control algorithm  tactile patterns  controllability  complex life-like formation  tactile sensation  drone formation  human-swarm interaction  swarm navigation  Impedance  Drones  Robots  Mathematical model  Shape  Force  Safety 
Abstract: We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.


Title: Design and Implementation of a Novel Aerial Manipulator with Tandem Ducted Fans
Key Words: aerospace testing  aircraft control  autonomous aerial vehicles  compensation  control system synthesis  fans  feedforward  helicopters  manipulator dynamics  stability  vehicle dynamics  aerial vehicle dynamics  manipulator dynamics  tandem ducted fans  trafficability  comprehensive integrated dynamic model  aerial manipulator  loading  multirotor  multilayer composite controller  feedforward compensation  flight tests  Manipulator dynamics  Fans  Payloads  Helicopters  Ducts 
Abstract: This paper proposes a novel aerial manipulator with tandem ducted fans, which takes both trafficability and effective loading into account. The aerial manipulator is particularly suitable for grasping in complex and narrow environment, in which traditional multi-rotor and helicopter would be inaccessible. The comprehensive integrated dynamic model is established by taking the aerial vehicle dynamics and manipulator dynamics as a whole. On this basis, a multilayer composite controller with feedforward compensation is designed, considering the mutual reactive influence between the aerial vehicle and the manipulator to improve the stability of the system under the motion of the manipulator. The simulation and actual flight tests verify the effectiveness of the design and show good stability and tracking performance of the system.


Title: Real-Time Light Field Processing for Autonomous Robotics
Key Words: calibration  cameras  image sensors  mobile robots  optical radar  robot vision  telerobotics  autonomous robotics systems  LIDAR sensors  time light field processing  simple linear arrays  high frequency vibrations  light fields  autonomous cars  light field imaging system  field-of-view  software framework  Cameras  Robot vision systems  Vibrations  Calibration  Three-dimensional displays 
Abstract: Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.


Title: Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model
Key Words: cameras  image filtering  image motion analysis  image reconstruction  image sequences  spatiotemporal phenomena  video signal processing  video motion capture  part confidence maps  inverted motions  two-time inverse kinematics computations  human skeleton  human motion analysis  human motion data  spatiotemporal filter  camera image  human skeletal model  spatiotemporal filtering  multicamera images  Phase change materials  Three-dimensional displays  Cameras  Computational modeling  Optical imaging  Adaptive optics  Spatiotemporal phenomena 
Abstract: This paper discusses video motion capture, namely, 3D reconstruction of human motion from multi-camera images. After the Part Confidence Maps are computed from each camera image, the proposed spatiotemporal filter is applied to deliver the human motion data with accuracy and smoothness for human motion analysis. The spatiotemporal filter uses the human skeleton and mixes temporal smoothing in two-time inverse kinematics computations. The experimental results show that the mean per joint position error was 26.1mm for regular motions and 38.8mm for inverted motions.


Title: Towards Material Classification of Scenes Using Active Thermography
Key Words: image classification  infrared imaging  learning (artificial intelligence)  temperature measurement  multimaterial scene  varying distances  multiclass classification  heating intensity  material classification  variable distances  relatively large surface areas  modern machine learning methods  data-driven approach  signal variations  thermal camera  heat lamp  size 20.0 cm  size 40.0 cm  size 30.0 cm  time 4.0 s  time 5.0 s  time 1.0 s  Heating systems  Cameras  Heat transfer  Robot sensing systems  Surface treatment 
Abstract: By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.


Title: Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis
Key Words: mobile robots  multi-robot systems  self-adjusting systems  self-assembly  trees (mathematics)  complex patterns  programmable systems  similar complexity  role model  natural plants  environmental conditions  dynamic environments  patterned formation  vascular tissue  aggregated robots  dynamic environment  robot swarm experiments  Legged locomotion  Robot sensing systems  Collision avoidance  Self-assembly  Shape  Resource management 
Abstract: Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.


Title: $\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms
Key Words: aggregation  fuzzy control  fuzzy set theory  image colour analysis  mobile robots  multi-robot systems  pheromone diffusion  BEECLUST algorithm  pheromone-based communication  pheromone-based aggregation method  ΦClust  artificial pheromone  BEECLUST method  pheromone evaporation  robotic swarms  Robot sensing systems  Biological system modeling  Aggregates  Swarm robotics  Temperature sensors  Swarm Robotics  Aggregation  Pheromone  Bio-inspired 
Abstract: In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.


Title: Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms
Key Words: collision avoidance  decentralised control  mobile robots  multi-robot systems  robots  trees (mathematics)  physics-based simulations  logical tree  robot network  spatially distributed targets  robot swarm  large-scale robot  decentralized connectivity-preserving deployment  real-robot experiments  tree root  connectivity constraints  physical network  logical tree topology  Robot kinematics  Topology  Heuristic algorithms  Network topology  Switches  Task analysis 
Abstract: We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.


Title: A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems
Key Words: collision avoidance  logistics  mobile robots  multi-agent systems  multi-robot systems  control scheme  collaborative transportation  bar-like shaped loads  robot-teams  collaborative object transportation task  precision farming setting  distributed swarm aggregation algorithm  bar shaped multiagent systems  state space  aggregate state  collision avoidance  angular consensus  segment-to-segment distance definition  control law  autonomous tractors  Bars  Multi-agent systems  Robot kinematics  Collision avoidance  Aggregates  Load modeling 
Abstract: In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.


Title: Resilient Active Information Gathering with Mobile Robots
Key Words: mobile robots  multi-robot systems  information acquisition tasks  failure-prone  resilient design problems  submodular approximation algorithms  active robots  mobile robots  resilient active information gathering  multirobot target tracking  active information gathering scenario  denial-of-service attacks  system-wide resiliency  minimal communication  Robot sensing systems  Target tracking  Mobile robots  Robot kinematics  Task analysis 
Abstract: Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.


Title: Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams
Key Words: decision making  multi-robot systems  probability  rescue robots  robust control  state estimation  computationally-efficient manner  feasible baseline approaches  context-dependent policies  robot rescue decision-making  multirobot teams  scalable policy synthesis framework  parallelizable policy synthesis framework  time-varying  stochastic mission conditions  physics-based simulations  probability minimization  state estimation  Robots  Task analysis  Computational modeling  State estimation  Probabilistic logic  Switches  Navigation 
Abstract: We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.


Title: Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution
Key Words: actuators  closed loop systems  design engineering  force control  gears  industrial robots  legged locomotion  manipulator kinematics  motion control  torque control  wearable robots  force control  PPE loads  extra robotic legs system  hazardous material emergency  gear reductions  XRL system  power systems  closed-loop kinematic chain  actuator loads  personal protective equipment  robotic human augmentation system  torque redistribution  Legged locomotion  Payloads  Kinematics  Force  Torque  Actuators  Human Augmentation  Supernumerary Robotic Limbs  Exoskeletons  Mechanism Design  Industrial Robotics 
Abstract: We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.


Title: Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis
Key Words: end effectors  friction  legged locomotion  climbing region  feasibility region analysis  multilimbed climbing robots  slide failure mode  over-torque failure mode  pure friction end effectors  walls  hexapod robot  robot deformation  climbing failure  robots  stiffness matrices  statically indeterminate forces  static indeterminacy modeling  multilimbed robot vertical two wall climbing  Strain  Mathematical model  Friction  Force  Robot kinematics  Manipulators 
Abstract: This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.


Title: Collaborative Planning for Mixed-Autonomy Lane Merging
Key Words: control engineering computing  decision making  driver information systems  game theory  mobile robots  multi-agent systems  path planning  road traffic  road vehicles  collaborative planning  social activity  mixed-autonomy traffic  Human-driven Vehicle  HV  Autonomous Vehicle drive  AV  planning framework  two-lane highway  double lane merging  collaborative decision making  mixed-autonomy lane merging  Automobiles  Planning  Merging  Collaboration  Robots  Autonomous vehicles 
Abstract: Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.


Title: The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity
Key Words: human-robot interaction  multi-robot systems  navigation  path planning  simulated robot-human interaction scenarios  entitative robots  strong emotional reactions  socially invisible robot navigation  robot entitativity  data-driven algorithm  navigational algorithms  trajectory computation  multirobot systems  Trajectory  Navigation  Psychology  Computational modeling  Surveillance  Robot kinematics 
Abstract: We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.


Title: Search-Based Optimal Motion Planning for Automated Driving
Key Words: mobile robots  optimisation  path planning  road vehicles  search problems  trajectory control  automated driving  fast motion planning  robust motion planning  real-time computation  urban conditions  convenient geometrical representation  search space  driving constraints  classical path planning approach  exact cost-to-go map  optimal motion trajectory  time horizons  fast driving conditions  slow driving conditions  search-based optimal motion planning  Planning  Vehicle dynamics  Trajectory  Dynamics  Roads  Search problems  Automation  motion planning  automated driving  lane change  multi-lane driving  traffic lights  A* search  MPC 
Abstract: This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.


Title: Vehicle Rebalancing for Mobility-on-Demand Systems with Ride-Sharing
Key Words: integer programming  linear programming  road traffic  road vehicles  scheduling  vehicle routing  historical taxi data  integer linear programming  idle vehicle redistribution  MoD systems  urban transportation  mobility-on-demand systems  real-time demand estimate  fleet operating area  MoD fleet  vehicle routes  road vehicles  ride-sharing  vehicle rebalancing  average waiting time  rebalancing regions  time 13.7 s  Schedules  Real-time systems  Delays  Partitioning algorithms  Public transportation  Automobiles 
Abstract: Recent developments in Mobility-on-Demand (MoD) systems have demonstrated the potential of road vehicles as an efficient mode of urban transportation Newly developed algorithms can compute vehicle routes in real-time for batches of requests and allow for multiple requests to share vehicles. These algorithms have primarily focused on optimally producing vehicle schedules to pick up and drop off requests. The redistribution of idle vehicles to areas of high demand, known as rebalancing, on the contrary has received little attention in the context of ride-sharing. In this paper, we present a method to rebalance idle vehicles in a ride-sharing enabled MoD fleet. This method consists of an algorithm to optimally partition the fleet operating area into rebalancing regions, an algorithm to determine a real-time demand estimate for every region using incoming requests, and an algorithm to optimize the assignment of idle vehicles to these rebalancing regions using an integer linear program. Evaluation with historical taxi data from Manhattan shows that we can service 99.8% of taxi requests in Manhattan using 3000 vehicles with an average waiting time of 57.4 seconds and an average in-car delay of 13.7 seconds. Moreover, we can achieve a higher service rate using 2000 vehicles than prior work achieved with 3000. Furthermore, with a fleet of 3000 vehicles, we reduce the average travel delay by 86%, the average waiting time by 37%, and the amount of ignored requests by 95% compared to earlier work at the expense of an increased distance travelled by the fleet.


Title: The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm
Key Words: assembling  design engineering  dexterous manipulators  grippers  industrial manipulators  manipulator kinematics  bimanual manipulation  electromechanical devices  classic dual arm manipulation  classic industrial robotic arms kinematics  general purpose grasping  KIT swiss knife gripper  disassembly tasks  robotic gripper design  dexterous in-hand manipulation  Grippers  Tools  Task analysis  Grasping  Manipulators  Service robots 
Abstract: This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.


Title: Composable Learning with Sparse Kernel Representations
Key Words: collision avoidance  Hilbert spaces  learning (artificial intelligence)  mobile robots  sparse matrices  stochastic processes  obstacle-avoidance policies  Reproducing kernel Hilbert space  NAF  2D environment  sparse kernel representations  normalized advantage function  state-action function  nonparametric controllers  reinforcement learning algorithm  composable learning  Kernel  Stochastic processes  Hilbert space  Data models  Training  Complexity theory  Robots 
Abstract: We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.


Title: Setting up a Reinforcement Learning Task with a Real-World Robot
Key Words: learning (artificial intelligence)  manipulators  multi-robot systems  hard-to-engineer adaptive solutions  complex tasks  diverse robotic tasks  reinforcement learning research  learning task  real-world robot  effective learning  learning performance  task setup  UR5 robotic arm  Task analysis  Robot sensing systems  Instruction sets  Delays  Reinforcement learning  Robot kinematics 
Abstract: Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.


Title: Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training
Key Words: computer games  control engineering computing  haptic interfaces  medical computing  medical robotics  patient rehabilitation  user experience  virtual reality  game experience  Haptic Kitchen game  haptic guidance  haptic interaction  haptic performance balancing algorithm  spouse-controlled haptic support  patients post-stroke  robot-supported multiplayer rehabilitation  haptically linked patient-spouse training  robot-aided rehabilitation  multiplayer games  Air Hockey game  Games  Haptic interfaces  Training  Robots  Damping  Trajectory  Sports 
Abstract: Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.


Title: A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model
Key Words: actuators  biocontrol  biomechanics  bone  gait analysis  legged locomotion  medical robotics  mobile robots  muscle  springs (mechanical)  underlying biological mechanisms  wearable robot  wearable robotic device  human locomotion mechanics  wearable robotics  soft-exosuit enables multiscale analysis  bipedal animal model  biological system interface  Kinematics  Springs  Tendons  Robots  Birds  Fixtures 
Abstract: Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.


Title: Towards Aerial Recovery of Parachute-Deployed Payloads
Key Words: aerospace robotics  aircraft control  mobile robots  position control  parachute-deployed payloads  sensor payloads  atmospheric profiling applications  inaccessible regions  multirotor unmanned aerial system  parachute-payload system  long-term payload transportation systems  aerial recovery  Payloads  Target tracking  Cameras  Robot sensing systems  Vehicle dynamics  Aerodynamics 
Abstract: Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.


Title: Airborne Docking for Multi-Rotor Aerial Manipulations
Key Words: autonomous aerial vehicles  mobile robots  multirotor aerial robots  transport multirotor UAV  winch mechanism  onboard locolization  mobile manipulation system  airborne docking method  IMU data  multirotor aerial manipulations  Winches  Bars  Cameras  Robot vision systems  DC motors  Propellers 
Abstract: We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.


Title: Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
Key Words: aerospace control  aerospace robotics  aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  path planning  robot dynamics  stability  multilinked model  near-hover condition  motion sequence  improved dynamics derivation  flight control method  flight stability  small opening  flight motion  transformable multilinked aerial robot  multilinked robot  transformable aerial robot  under-actuated multirotors  aggressive maneuvering  necessary condition  crucial problems  unknown obstacle  multirotor  robot body  Unmanned aerial vehicles  Rotors  Collision avoidance  Path planning  Stability analysis  Robot sensing systems 
Abstract: In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).


Title: Learning a Local Feature Descriptor for 3D LiDAR Scans
Key Words: convolutional neural nets  feature extraction  image matching  image representation  learning (artificial intelligence)  robot vision  SLAM (robots)  learned feature descriptor  3D local descriptors  local feature descriptor  3D LiDAR scans  robust data association  scan alignment algorithms  handcrafted feature descriptors  metric learning network  local surface patches  convolutional neural network  ground-truth correspondences  SLAM system  CNN  Siamese network  Three-dimensional displays  Measurement  Laser radar  Feature extraction  Streaming media  Task analysis  Gray-scale 
Abstract: Robust data association is necessary for virtually every SLAM system and finding corresponding points is typically a preprocessing step for scan alignment algorithms. Traditionally, handcrafted feature descriptors were used for these problems but recently learned descriptors have been shown to perform more robustly. In this work, we propose a local feature descriptor for 3D LiDAR scans. The descriptor is learned using a Convolutional Neural Network (CNN). Our proposed architecture consists of a Siamese network for learning a feature descriptor and a metric learning network for matching the descriptors. We also present a method for estimating local surface patches and obtaining ground-truth correspondences. In extensive experiments, we compare our learned feature descriptor with existing 3D local descriptors and report highly competitive results for multiple experiments in terms of matching accuracy and computation time.


Title: Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder
Key Words: image sensors  object detection  optical radar  optical scanners  scan homogeneity  3D sensor homogeneity  spherical formulation  HDL-32 sensors  building full-3D lidars  robotics research  constant pitch angles  rolling DOF  RMBLs  complex 3D scan measurement distributions  spherical FOV  high-resolution scans  rotating multibeam lidars  degree-of-freedom  vertical resolution  high data rates  accessible 3D sensors  MBL  multibeam lidar scanners  multibeam Velodyne range-finder  Three-dimensional displays  Laser radar  Indexes  Kinematics  Robot sensing systems 
Abstract: Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.


Title: Laser Map Aided Visual Inertial Localization in Changing Environment
Key Words: cameras  geometry  optical radar  optimisation  robot vision  SLAM (robots)  map optimization  changing environment  bi-directional tasks  LiDAR-built map  online visual inertial odometry system  laser map aided visual inertial localization  geometry information  crossmodal data association  multisession laser  Visualization  Lasers  Bundle adjustment  Laser radar  Robots  Cameras 
Abstract: Long-term visual localization in outdoor environment is a challenging problem, especially faced with the cross-seasonal, bi-directional tasks and changing environment. In this paper we propose a novel visual inertial localization framework that localizes against the LiDAR-built map. Based on the geometry information of the laser map, a hybrid bundle adjustment framework is proposed, which estimates the poses of the cameras with respect to the prior laser map as well as optimizes the state variables of the online visual inertial odometry system simultaneously. For more accurate crossmodal data association, the laser map is optimized using multisession laser and visual data to extract the salient and stable subset for visual localization. To validate the efficiency of the proposed method, we collect data in south part of our campus in different seasons, along the same and opposite-direction route. In all sessions of localization data, our proposed method gives satisfactory results, and shows the superiority of the hybrid bundle adjustment and map optimization1.


Title: Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping
Key Words: mobile robots  multi-robot systems  optimisation  path planning  probability  decentralised mission monitoring  spatiotemporal optimal stopping  multirobot variant  mission monitoring problem  multiple tracker robots  single target robot  multirobot systems  task performance  marine robotics missions  single-robot paths  probabilistic representation  decentralised scheme  useful analytical properties  planned trajectories  probabilistic motion  observation models  mission monitoring systems  Monitoring  Trajectory  Target tracking  Robot kinematics  Probabilistic logic  Predictive models 
Abstract: We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.


Title: Uncertain Local Leader Selection in Distributed Formations
Key Words: collision avoidance  control engineering computing  mobile robots  multi-robot systems  virtual local leader  accurate local leader  formation accuracy  individual robot  sensory uncertainty  distributed setting  optimal multirobot formation control  uncertain environment  desired formation  specific formation  desired destination  single robot  local leaders  specific predefined angle  hierarchical form  Leader-Follower  distributed formations  uncertain local leader selection  visible robots  Robot sensing systems  Reliability  Shape  Uncertainty  Task analysis 
Abstract: Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.


Title: Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm
Key Words: approximation theory  distributed control  embedded systems  large-scale systems  mobile robots  multi-robot systems  tree searching  asynchronous distributed embedded systems  distributed system coordination  approximation algorithm  memory per node  neighboring modules  lattice structure  resource-constrained identical modules  distributed modular robotic ensembles  huge modular robot  large-scale systems  hardware modular robots  approximate-center node  k-BFS SumSweep algorithm  Approximation algorithms  Robot kinematics  Voting  Heuristic algorithms  Probabilistic logic  Embedded systems  Distributed algorithm  Modular robots  Center election 
Abstract: Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.


Title: A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
Key Words: mobile robots  multi-agent systems  multi-robot systems  position control  trajectory control  multiagent systems  classification task  conventional centered wheel  distance-bearing formations  unicycle robots  distance-bearing constraints  macro-robot  regular convex polygon  trajectory-tracking control problem  Mobile robots  Wheels  Robot kinematics  Kinematics  Vehicle dynamics  Axles 
Abstract: In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.


Title: Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
Key Words: aerospace robotics  manipulators  mobile robots  multi-robot systems  vibration control  MAGMaS  load flexibility  heterogeneous system  aerial robot  rigid load manipulation  load weight holding  long-slender object manipulation  multiple aerial-ground manipulator system  flexible load-tip pose tracking  vibration suppression controllability  Unmanned aerial vehicles  Manipulators  Load modeling  Vibrations  Mathematical model  Shape 
Abstract: The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.


Title: Determining Effective Swarm Sizes for Multi-Job Type Missions
Key Words: multi-agent systems  multi-robot systems  optimisation  particle swarm optimisation  queueing theory  sensitivity analysis  vehicle routing  sensitivity analysis  M/M/k/k queuing model  swarm search and service mission  SSS mission  swarm sizes  DVR  dynamic vehicle routing  multijob type missions  multiagent framework  balancing vehicle allocation  human operators  Robot sensing systems  Routing  Time factors  Planning  Task analysis 
Abstract: Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.


Title: Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment
Key Words: collision avoidance  hierarchical systems  multi-robot systems  stability  switching systems (control)  trees (mathematics)  multirobot virtual structure switching  formation changing strategy  region-based shape controller  swarm-robotic framework  traditional obstacle-avoidance problem  virtual structure methodology  triangular formation  shrinking phenomena  variable structure  two-layer hierarchical control strategy  inter-agent formation  spanning-tree-assisted-shape-matching algorithm  stability analysis  Shape  Robots  Switches  Convergence  Simulation  Stability analysis 
Abstract: This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.


Title: Distributed Sensing Subject to Temporal Logic Constraints
Key Words: entropy  formal specification  greedy algorithms  multi-agent systems  optimisation  temporal logic  distributed sensing subject  temporal logic constraints  temporal logic specifications  local objective functions  motion plans  objective function  information entropy  unassigned agents  satisfaction guarantees  optimality loss  local greedy minimization  TL constraints  specification complexity  TL specification  product automaton based approach  Robot sensing systems  Linear programming  Task analysis  Planning  Automata 
Abstract: This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.


Title: Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics
Key Words: digital control  mechanical stability  micromanipulators  micromechanical devices  microrobots  robot dynamics  mechanical stability  complex control strategies  bistable modules  mechanism size  repeatability analysis  multistable module  DiMiBot robots  digital microrobotics  complex systems  multistable prototype  multiple modules  reproducibility analysis  miniaturized structure  discrete stable positions  Clamps  Actuators  Prototypes  Task analysis  Switches  Silicon  Micromechanical devices 
Abstract: The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.


Title: Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage
Key Words: closed loop systems  controllability  dexterous manipulators  end effectors  force control  linear motors  microactuators  microrobots  ultrasonic motors  miniature robot finger  microrobot hands  microlinear ultrasonic motor prototype  closed-loop six-bar-linkage mechanism  microfabrication  Acoustics  Stators  Robots  Couplings  Actuators  Electrodes  Vibrations 
Abstract: To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.


Title: Transparency-Optimal Passivity Layer Design for Time-Domain Control of Multi-DoF Haptic-Enabled Teleoperation
Key Words: haptic interfaces  optimisation  telerobotics  time-domain scheme  optimization problem  optimization-based passivity control algorithm  virtual teleoperated environment  real-time implementation  optimal transparency  energy-bounding control  haptic-enabled bilateral teleoperation systems  multiDoF  time-domain control  transparency-optimal passivity layer design  Force  Task analysis  Computer architecture  Robots  Indexes  Time-domain analysis  Haptic interfaces 
Abstract: This paper presents a novel optimization-based passivity control algorithm for haptic-enabled bilateral teleoperation systems involving multiple degrees of freedom. In particular, in the context of energy-bounding control, the contribution focuses on the implementation of a passivity layer for an existing time-domain scheme, ensuring optimal transparency of the interaction along subsets of the environment space which are preponderant for the given task, while preserving the energy bounds required for passivity. The involved optimization problem is convex and amenable to real-time implementation. The effectiveness of the proposed design is validated via an experiment performed on a virtual teleoperated environment.


Title: Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction
Key Words: control engineering computing  helmet mounted displays  human-robot interaction  intelligent robots  mobile robots  multi-robot systems  service robots  user interfaces  virtual reality  multimodal heading  pointing gestures  human operator  co-located robots  head-mounted-display  HRI situations  enormous potential  MR human-robot collaboration system  industrial robot arm  multimodal HRI techniques  heading-based interaction techniques  multirobot system  current robot programming  human-robot interaction scenarios  virtual information  pick-and-place scenarios  potential robot actions  co-located mixed reality human-robot interaction  Microsoft HoloLens  Virtual reality  Service robots  Task analysis  Collaboration  Visualization  Manipulators 
Abstract: Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.


Title: Visual-Inertial Teach and Repeat Powered by Google Tango
Key Words: automatic optical inspection  autonomous aerial vehicles  collision avoidance  control engineering computing  Global Positioning System  mobile robots  pose estimation  robot vision  trajectory control  human operator  visual inspection task  autonomous aerial vehicle  Google Tango visual-inertial mapping framework  pose estimates  GPS-denied environments  inspection points  feature-based localization map  industrial facilities  multicopters  visual-inertial teach  hedge maze  Robots  Inspection  Task analysis  Collision avoidance  Google  Autonomous systems  Visualization 
Abstract: Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.


Title: Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
Key Words: aircraft control  distributed algorithms  mobile robots  multi-robot systems  tracking  trajectory control  multirobot systems  geometric parameters  distributed algorithm  tracking controller  robots position  distributed trajectory generator  mini aerial vehicles  distributed reconfigurable formation generator  Generators  Intelligent robots  Trajectory  Multi-robot systems  Distributed algorithms 
Abstract: This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.


Title: Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure
Key Words: autonomous aerial vehicles  collision avoidance  image reconstruction  inspection  Kalman filters  mobile robots  robot vision  wind turbines  UAVs  Aerial inspection  aerial tool  autonomous cooperative coverage  multiple Unmanned Aerial Vehicles  onboard computer  sensory system  autonomous navigation  localization system  Ultra Wideband  aerial team  realistic wind turbine inspection experiments  dense 3D reconstruction  inspected structures  state Kalman filter  3D infrastructure  large scale aging infrastructure  Inspection  Three-dimensional displays  Tools  Intelligent robots  Aging  Unmanned aerial vehicles  Robot sensing systems 
Abstract: This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.


Title: Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
Key Words: autonomous aerial vehicles  collision avoidance  convolutional neural nets  feature extraction  indoor navigation  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  regression analysis  robot vision  sensor fusion  velocity control  indoor flights  unmanned aerial vehicles  civilian applications  indoor-flight dataset  agent distance-to-collision prediction  drone safe deployment  on-board monocular camera  external sensors  spatio-temporal feature extraction  static appearance information  motion information  robot distance estimation  linear velocity  navigation policy learning  real-distance labels  raw visual input  regression CNN  real-time obstacle avoidance  indoor robot navigation  autonomous navigation methods  UAV  self-supervised CNN-based approach  navigation policy  Robots  Navigation  Sensors  Drones  Cameras  Task analysis  Trajectory 
Abstract: Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.


Title: Angle-Encoded Swarm Optimization for UAV Formation Path Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  particle swarm optimisation  angle-encoded particle swarm optimization  3DR solo drones  mission planner  Internet-of- Things  UAV formation path planning  triangular formation maintenance  swarm convergence  multiple-objective optimisation algorithm  unmanned aerial vehicles  feasible path planning technique  Trajectory  Collision avoidance  Unmanned aerial vehicles  Task analysis  Cost function  Shape  Quadcopter  θ-PSO  path planning  loT  triangular formation  collision avoidance 
Abstract: This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.


Title: Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*
Key Words: distributed control  mobile robots  multi-robot systems  multirobot teams  heterogeneous sensing capabilities  coverage algorithm  multirobot systems  qualitatively different sensing modalities  required sensing modalities  particular sensory capability  distributed control algorithm  robotic platform  Robot sensing systems  Robot kinematics  Monitoring  Temperature sensors  Density functional theory 
Abstract: This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.


Title: Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure
Key Words: finite state machines  mobile robots  multi-robot systems  spatiotemporal phenomena  computation-free robots  emergent behavioural structure  finite state machine  minimal robots  nonholonomic robots  self-healing circle formations  frontal binary sensor  grid-search method  computation-free behaviour  spatio-temporal dynamics  Robot sensing systems  Mobile robots  Robot kinematics  Apertures  Standards  Computational modeling 
Abstract: In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.


Title: Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning
Key Words: Bayes methods  Markov processes  Monte Carlo methods  Pareto optimisation  path planning  implicit uniform distribution  Pareto-frontier  progressive objective evaluation  objective functions  Pareto-optimal trajectories  multiobjective motion planning  multiobjective motion-planning problems  sampling trajectories  Pareto-optimal set  Markov chain Monte Carlo method  Trajectory  Markov processes  Planning  Monte Carlo methods  Sociology  Optimization 
Abstract: In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.


Title: Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms
Key Words: game theory  preferred task allocations  competitive algorithm  game theoretical algorithms  described scenario  relevant question  partial information  disaster area  drone swarms  task allocation  game theory  Task analysis  Robots  Resource management  Games  Drones  Nash equilibrium  Genetic algorithms 
Abstract: Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.


Title: A Multi-Rate State Observer for Visual Tracking of Magnetic Micro-Agents Using 2D Slow Medical Imaging Modalities
Key Words: biological tissues  biomedical optical imaging  biomedical ultrasonics  cameras  Kalman filters  medical image processing  object tracking  observers  sampling methods  surgery  multirate state observer  visual tracking  magnetic microagents  Luenberger state estimators  minimally invasive surgery  tracking error  ultrasound microscope  ultrasound machine  electromagnetic coils  Kalman state estimator  multirate state estimation  medical imaging modality  multirate sampling methods  Visualization  Tracking  Biomedical imaging  Jacobian matrices  Two dimensional displays  State estimation  Magnetic resonance imaging 
Abstract: Minimally invasive surgery can benefit greatly from utilizing micro-agents. These miniaturized agents need to be clearly visualized and precisely controlled to ensure the success of the surgery. Since medical imaging modalities suffer from low acquisition rate, multi-rate sampling methods can be used to estimate the intersample states of micro-agents. Hence, the sampling rate of the controller can be virtually increased even if the position data is acquired using a slow medical imaging modality. This study presents multi-rate Luenberger and Kalman state estimators for visual tracking of micro-agents. The micro-agents are tracked using sum of squared differences and normalized cross correlation based visual tracking. Further, the outputs of the two methods are merged to minimize the tracking error and prevent tracking failures. During the experiments, the micro-agents with different geometrical shapes and sizes are imaged using a 2D ultrasound machine and a microscope, and manipulated using electromagnetic coils. The multi-rate state estimation accuracy is measured using a high speed camera. The precision of the tracking and multi-rate state estimation are verified experimentally under challenging conditions. For this purpose, an elliptical shaped magnetic micro-agent with a length of 48 pixels is used. Maximum absolute error in x and y axes are 2.273 and 2.432 pixels for an 8-fold increase of the sample rate (25 frames per second), respectively. During the experiments, it was observed that the micro-agents could be tracked more reliably using normalized cross correlation based visual tracking and inters ample states could be estimated more accurately using Kalman state estimator. Experimental results show that the proposed method could be used to track micro-agents in medical imaging modalities and estimate system states at intermediate time instants in real-time.


Title: Human Motion Classification Based on Multi-Modal Sensor Data for Lower Limb Exoskeletons
Key Words: biomechanics  force sensors  gait analysis  hidden Markov models  image motion analysis  learning (artificial intelligence)  medical robotics  patient rehabilitation  pattern classification  wearable computers  human motion classification  multimodal sensor data  lower limb exoskeletons  intuitive exoskeleton control  improved user acceptance  wearability comfort  exoskeleton control system  online classification  lower-limb exoskeleton  defined motion patterns  recent sensor measurements  sliding window approach  training data  passive exoskeleton  3D-force sensors  3 inertial measurement units  correct classification  generalization performance  hidden Markov models  Exoskeletons  Hidden Markov models  Robot sensing systems  Legged locomotion  Force  Force sensors  Thigh 
Abstract: Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.


Title: Soft Fabric Actuator for Robotic Applications
Key Words: electroactive polymer actuators  fabrics  microactuators  polymer fibres  polymers  wearable robots  weaving  coiled soft actuators  STCA multiple fabrication method  continuous fabrication method  actuation test  soft fabric actuator  actuation strain  robotic applications  twisted and coiled soft actuators  Spandex TCA  Nylon TCA  human arm size mannequin  angle control  Actuators  Fabrics  Fabrication  Strain  Weaving  Yarn  Connectors 
Abstract: This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.


Title: Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)
Key Words: augmented reality  dexterous manipulators  haptic interfaces  human computer interaction  telerobotics  augmented teleoperation System  robot operating system  rugged robots  resource sharing  system integration  telerobotic system  operator interface  virtual fixture generation  current technology basis  human operator  complex robotic systems  telerobotic operation  enhanced teleoperator interface incorporating multimodal  current telerobotics technology  complex manipulation  dexterous manipulation  severe task requirements  unstructured nuclear environment  remote systems  ROS  Three-dimensional displays  Robot sensing systems  Telerobotics  Haptic interfaces  Fixtures 
Abstract: Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.


Title: Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance
Key Words: force feedback  human computer interaction  human-robot interaction  manipulators  mobile robots  object recognition  robot vision  telerobotics  velocity control  human-robot interface  tracking experiments  metallic parts  vision-based control system  robotic arm  monochromatic objects  metallic connectors  metallic plates  featureless objects  teleoperation loop  tracking system  object recognition  higher-level applications  safer system  interaction modalities  force feedback  bilateral teleoperation  low level interaction methods  multimodal interactions  robotic operator  harsh environments  safe robotic interventions  robotic guidance  metallic pieces  depth estimation  Cameras  Estimation  Robot vision systems  Correlation  Object recognition  Target tracking 
Abstract: In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.


Title: High Power Hand with Retention Mechanism
Key Words: biomechanics  dexterous manipulators  disasters  motion control  plates (structures)  power system control  retention mechanism  electrical power supply  electrical power saving  high power hand  multifingered robot hand  power manipulation  dexterous motion  Robots  Thumb  Power supplies  Force  Mechanical engineering  Conferences 
Abstract: When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.


Title: Automatic Calibration of Multiple Cameras and Depth Sensors with a Spherical Target
Key Words: calibration  cameras  sensor fusion  spatial variables measurement  automatic calibration  multisensor calibration  spherical calibration target  subresolution detection accuracy  camera  depth sensor  Calibration  Cameras  Image edge detection  Laser radar  Three-dimensional displays  Detectors 
Abstract: In this work we present a novel approach for multi-sensor calibration that significantly outperforms current state-of-the-art. We introduce a new spherical calibration target which has major benefits over existing targets. Those are subresolution detection accuracy in both camera and depth sensor, view invariance and applicability to a wider range of sensor setups than current approaches. With our method a single person achieves high quality calibration in less than a minute. No preparations for setting up the environment for calibration is needed. Our method is fast, easy to use and fully automatic. We evaluate our method in simulation and show high accuracy with an error of less than 3mm in translation and 0.1 0 in rotation on real data.


Title: A Robust Time-Stepping Scheme for Quasistatic Rigid Multibody Systems
Key Words: grippers  integer programming  manipulator kinematics  quadratic programming  robust control  torque  robust time-stepping scheme  quasistatic rigid multibody systems  quasistatic physics  linear complementarity problems  grasping velocity command  small-to-medium-sized systems  manipulation  motion primitive  LCP  optimization problem  mixed-integer quadratic program  torque  Grippers  Friction  Force  Kinematics  Grasping  Manipulators 
Abstract: An effective scheme to simulate low-speed, contact-rich manipulation tasks is to assume quasistatic physics and advance system states by solving linear complementarity problems (LCPs). However, the existing LCP-based quasistatic time-stepping scheme fails to simulate grasping-an essential motion primitive in manipulation-due to two drawbacks specific to quasistatic systems. Firstly, inputs to quasistatic systems are velocity commands instead of torques. This can lead to penetration, and thus an infeasible LCP, when two rigid bodies in contact are commanded to push against each other. Secondly, as multiple force solutions exist for a given velocity command, a grasping velocity command is not guaranteed to generate sufficient grasping forces. In this paper, we reformulate the quasistatic time-stepping scheme as an optimization problem with complementarity constraints and a quadratic objective. By minimizing the difference between actual and commanded velocities, linearized non-penetration constraints can always be satisfied. Moreover, undesirable solutions with insufficient normal forces can be removed by considering elasticity, which is modeled by comparing actual and commanded velocities. The resulting optimization problem is a mixed-integer quadratic program, which can be solved reasonably quickly for small-to-medium-sized systems. The effectiveness of the proposed reformulation is validated by simulation results of systems with different levels of complexity.


Title: Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair
Key Words: aerodynamics  aircraft maintenance  end effectors  industrial robots  inspection  mechatronics  suspensions (mechanical components)  slender dual-structure continuum robot  In-Situ Aeroengine Repair  in-situ aeroengine maintenance works  end-effector  aeroengine combustion chamber  configuration-cable kinematics  Maintenance engineering  Kinematics  Inspection  Shape  End effectors  Task analysis 
Abstract: In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.


Title: Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.
Key Words: disasters  emergency management  emergency services  multi-agent systems  rescue robots  wireless sensor networks  search and rescue missions  wireless sensor networks  robots  mobile node  heterogeneous agents  multiagent team  natural disasters  human disasters  emergency response  information gathering  wireless sensor network  canine agent  Dogs  Wireless sensor networks  Receivers  Mobile nodes  Transmitters  Databases 
Abstract: Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.


Title: Any-Time Trajectory Planning for Safe Emergency Landing
Key Words: aerospace components  aerospace engineering  aircraft control  aircraft landing guidance  path planning  trajectory control  landing site selection  safest emergency landing trajectory  multiple landing sites  any-time property  time trajectory planning  safe emergency landing  critical situation  human pilots  landing trajectories  aircraft  Trajectory  Aircraft  Planning  Turning  Drag  Atmospheric modeling  Force 
Abstract: Loss of thrust is a critical situation for human pilots of fixed-wing aircraft which force them to select a landing site in the nearby range and perform an emergency landing. The time for the landing site selection is limited by the actual altitude of the aircraft, and it may be fatal if the correct decision is not chosen fast enough. Therefore, we propose a novel RRT* -based planning algorithm for finding the safest emergency landing trajectory towards a given set of possible landing sites. Multiple landing sites are evaluated simultaneously during the flight even before any mechanical issue occurs, and the roadmap of possible landing trajectories is updated permanently. Thus, the proposed algorithm has the any-time property and provides the best emergency landing trajectory almost instantly.


Title: Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles
Key Words: aerospace robotics  collision avoidance  inspection  optical sensors  power overhead lines  sensor placement  collision avoidance  optical sensors  sensor placement  fixed energy infrastructure  aerial inspection  multirotor platform  assisted control technology  aerial vehicles  semiautonomous power infrastructure inspection  proximity inspection tasks  assisted control approach  Inspection  Wires  Measurement  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles  Task analysis 
Abstract: This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.


Title: Bidirectional Thrust for Multirotor MAVs with Fixed-Pitch Propellers
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  helicopters  propellers  fixed-pitch propellers  multirotor MicroAerial Vehicles  bidirectional thrust vector  dedicated motor controllers  controller design  control allocation approach  static thrust test  inverted flight  multirotor MAV  unidirectional thrust vehicles  Propellers  Rotors  Torque  Resource management  Force  Attitude control  Trajectory 
Abstract: This paper is devoted to the study of multirotor Micro Aerial Vehicles (MAVs) with fixed-pitch propellers and bidirectional thrust vector. The latter is realized by using dedicated motor controllers, which allow to invert the propellers' direction of rotation during flight (so-called 3D mode), and almost or fully symmetric propellers. We present a unified modeling, controller design, and control allocation approach that accounts for bidirectional thrust. Suitable propellers with the ability to produce thrust and torque in both directions are compared and their parameters are identified through a static thrust test. Furthermore, we discuss applications of bidirectional thrust, like inverted flight or surface slip reduction, which are impossible to realize with common unidirectional thrust vehicles. We generate suitable flight trajectories and evaluate our unified approach in experiments with a custom-built quadrotor.


Title: Joint 3D Proposal Generation and Object Detection from View Aggregation
Key Words: image classification  image colour analysis  image fusion  mobile robots  neural nets  object detection  optical radar  radar detection  regression analysis  road vehicle radar  robot vision  high resolution feature maps  reliable 3D object proposals  multiple object classes  category classification  second stage detection network  AVOD  KITTI 3D object detection  autonomous vehicles  3D bounding box regression  multimodal feature fusion  RPN  region proposal network  RGB images  LIDAR point clouds  neural network architecture  autonomous driving scenarios  Aggregate View Object Detection network  joint 3D proposal generation  Three-dimensional displays  Feature extraction  Proposals  Computer architecture  Agriculture  Object detection  Two dimensional displays 
Abstract: We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.


Title: TSSD: Temporal Single-Shot Detector Based on Attention and LSTM
Key Words: feature extraction  object detection  robot vision  video signal processing  convolutional long short-term memory  creative temporal analysis unit  multiscale feature maps  high-level ConvLSTM unit  pyramidal feature hierarchy  attention mechanism  real-time online approaches  video detection task  robotic vision  rich temporal information  temporal object detection  temporal single-shot detector  developed TSSD  attention-aware features  scale suppression  background suppression  ConvLSTM-based attention  attention-based ConvLSTM  Feature extraction  Detectors  Robots  Task analysis  Visualization  Lenses  Proposals 
Abstract: Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.


Title: Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors
Key Words: computer vision  image segmentation  image sensors  Kalman filters  object detection  pattern clustering  target tracking  event-based sensors  computer vision applications  robust tracking  object detection  segmentation  real-time clustering technique  event-based vision sensors  mean-shift clustering method  asynchronous events  multitarget tracking application  clustering accuracy  frame-based method  Sensors  Shape  Real-time systems  Kalman filters  Target tracking  Robots 
Abstract: Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.


Title: Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels
Key Words: image annotation  image segmentation  learning (artificial intelligence)  image modalities  sparse labeling data  human interaction reduction  environment monitoring data  sparse annotation augmentation  dense ground-truth  label augmentation  adaptive superpixel segmentation propagation  dense semantic segmentation models  pixel level labeling  life applicability  common deep learning models  deep learning approaches  image pixel  multilevel superpixels  effective learning  Image segmentation  Semantics  Labeling  Training  Biological system modeling  Monitoring  Deep learning 
Abstract: Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.


Title: Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments
Key Words: collision avoidance  convergence  humanoid robots  mobile robots  Newton method  trajectory control  problem encoding  warm-starting trajectory optimization  motion planner  local minima  motion planning  near-optimal warm-start initializations  global convergence  quasiNewton solvers  probabilistic inference solvers  NASA Valkyrie robot  Task analysis  Collision avoidance  Planning  Robots  Trajectory optimization 
Abstract: Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.


Title: Real-Time Quad-Rotor Path Planning for Mobile Obstacle Avoidance Using Convex Optimization
Key Words: attitude control  collision avoidance  convex programming  helicopters  propellers  mobile obstacle avoidance  on-board convex-optimization-based path planning  multirotors  fixed-pitch propellers  fixed-pitch actuators  uni-directional thrust  commanded total thrust  sufficient independent attitude control authority  indoor flight demonstration  second-order cone programming problems  real-time quad-rotor path planning  real-time 3-dimensional path planning  Trajectory  Real-time systems  Software  Acceleration  Vehicle dynamics  Attitude control 
Abstract: In this paper, we employ convex optimization to perform real-time 3-dimensional path planning on-board a quad-rotor and demonstrate its real-time capabilities. Building on our previous work, we make the following modifications: (1)we assume the obstacles are mobile, and (2)we introduce a simple framework to continuously recompute and update the trajectory. The contribution of this paper is to demonstrate the feasibility of real-time on-board convex-optimization-based path planning. For multi-rotors with fixed-pitch propellers, this path planning problem has two sources of non-convexity. First, since fixed-pitch actuators produce uni-directional thrust, the commanded total thrust must be maintained above a non-zero minimum in order to retain sufficient independent attitude control authority. The second source of non-convexity is due to the keep-out zones that envelop each obstacle. To circumvent the non-convexities introduced by these control and state constraints, we employ lossless and successive con-vexification, respectively. Consequently, we cast the original problem as a sequence of Second-Order Cone Programming problems, which can be solved quickly and reliably on-board. We conclude by presenting indoor flight demonstration and timing results of a scenario with three mobile obstacles. In this scenario, our algorithm assumes that the obstacles move with constant acceleration, and is re-executed regularly to account for uncertainties in the motion of the obstacles. The results show that new trajectories can be computed at rates in excess of 10 Hz, quickly enough to adapt to the uncertainty introduced in our flight demonstration.


Title: Design for Control of a Soft Bidirectional Bending Actuator
Key Words: bending  capacitive sensors  closed loop systems  finite element analysis  pneumatic actuators  strain sensors  sensor effectiveness  design evaluation process  simple control strategies  closed-loop control  soft bidirectional bending actuator  SCAPAs  controllable design  antagonistic actuators  embedded capacitive strain sensors  sensor-controlled antagonistic pneumatic actuators  soft robotic actuators  manufacturing processes  finite element analysis  state reconstruction  single conductive fabric sheet  Actuators  Capacitive sensors  Fabrics  Strain  Robot sensing systems  Sensor systems  soft material robotics  hydraulic/pneumatic actuators  sensor-based control 
Abstract: In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.


Title: Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor
Key Words: bending  dexterous manipulators  feedback  medical robotics  pipelines  pneumatic control equipment  pneumatic systems  position control  sensors  tactile sensors  vibrations  flexible material  flexible angle estimation sensor  flexible sensor  pneumatically driven flexible finger  Robot sensing systems  Optical sensors  Cameras  Optical fiber amplifiers  Voltage measurement  Three-dimensional displays  Printers 
Abstract: A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.


Title: Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).
Key Words: compliant mechanisms  continuum mechanics  finite element analysis  manipulator dynamics  shear modulus  large deformation continuum surfaces  soft continuum robotic arms  3D integrated surface-arm model  lumped-mass methodology  soft robotics  Mathematical model  Robots  Load modeling  Deformable models  Strain  Actuators  Springs 
Abstract: Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.


Title: Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling
Key Words: control engineering computing  industrial robots  motion control  robot programming  trees (mathematics)  programming complexity  industrial robots  complex motions  self-contained primitive blocks  semantic skill  concurrent motion primitives  modeling skills  motion generators  behavior trees  task level programming  Task analysis  Generators  Robot kinematics  Force  Planning  Grippers  industrial robots  skills  reactive system  behavior tress  motio generators  assembly 
Abstract: Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.


Title: Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints
Key Words: force control  friction  humanoid robots  legged locomotion  mechanical contact  quadratic programming  robot dynamics  robust control  centroidal momentum dynamics  computationally-robust whole-body controller  quadratic program  passive-ankle bipedal robot  dynamic locomotion behaviors  smooth contact transitions  friction cone constraints  task accelerations  computational robustness  floating base dynamics  internal force constraints  contact reaction forces  operational task priorities  algorithmic computations  prioritized whole-body controllers  humanoid robots  multiobjective control  contact constraints  Task analysis  Null space  Dynamics  Acceleration  Robots  Force  Torque 
Abstract: In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.


Title: Continuously Shaping Projections and Operational Space Tasks
Key Words: least squares approximations  robots  projection operators  multiobjective robot control  dynamic task priority rearrangement  projection shaping  damped least squares  idempotent projectors  shaping operators  stack-of-tasks prioritization scheme  single task dimensions continuous priority rearrangement  Task analysis  Aerospace electronics  Jacobian matrices  Robots  Interference  Torque  Nickel 
Abstract: Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.


Title: User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization
Key Words: assisted living  gait analysis  geriatrics  human-robot interaction  intelligent robots  laser ranging  medical robotics  multi-robot systems  stability  state estimation  on-line gait characterization  robotic MAD  IMM-PDA-PF  intelligent robotic mobility assistive device  human-robot formation controller  gait cycle  pathological gait parametrization  human gait phases  on-line estimation  single laser-range-finder  user-adaptive human-robot system  pathological gait characterization  augmented human state estimation  intelligent robotic walker  user-adaptive human-robot formation control  Legged locomotion  Pathology  State estimation  Robot sensing systems  Robot kinematics  Real-time systems 
Abstract: In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.


Title: Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives
Key Words: augmented reality  iterative methods  learning (artificial intelligence)  mobile robots  motion control  regression analysis  robot dynamics  robot programming  telerobotics  human motor dynamics  kernel-based regression approach  inverse human-dynamics response  human-in-the-loop demonstrator  kernel-based human-dynamics inversion  precision robot motion-primitives  human demonstrator  robot controller  multiple iterations  assisted teleoperation  augmented reality display  Task analysis  Robots  Trajectory  Gaussian processes  Biological system modeling  Kernel  Estimation 
Abstract: Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.


Title: Towards Intelligent Arbitration of Diverse Active Learning Queries
Key Words: decision theory  learning (artificial intelligence)  multi-agent systems  query processing  diverse active learning queries  optimal queries  learning agent  active learner  decision-theoretic arbitration strategies  decision-theoretic strategy  intelligent arbitration  rule-based arbitration strategies  passive learning  Task analysis  Training  Grounding  Robots  Feature extraction  Hafnium  Uncertainty 
Abstract: Active learning literature has explored the selection of optimal queries by a learning agent with respect to given criteria, but prior work in classification has focused only on obtaining labels for queried samples. In contrast, proficient learners, like humans, integrate multiple forms of information during learning. This work seeks to enable an active learner to reason about multiple query types concurrently, aimed at soliciting both instance and feature information from the teacher, and to autonomously arbitrate between queries of different types. We contribute the design of rule-based and decision-theoretic arbitration strategies and evaluate all against baselines of more traditional passive and active learning. Our findings show that all arbitration strategies lead to more efficient learning, compared to the baselines. Moreover, given a dynamically changing environment and constrained questioning budget (typical in human settings), the decision-theoretic strategy statistically outperforms all other methods since it reasons about both what query to make and when to make a query, in order to most effectively utilize its questioning budget.


Title: Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving
Key Words: control engineering computing  decision trees  fasteners  industrial robots  pattern classification  production engineering computing  robotic assembly  sensors  support vector machines  technical challenges  affordable intelligent screwdriving system  online stage  result classification  state transition graph  labeled screwdriving dataset  multiple sensor signals  classification algorithms  sensor reduction  accurate result classifiers  linear discriminant analysis  feature subset selection  optimal feature subset  corresponding sensor signals  stage classifier  optimal sensor subset  sensor selection  stage & result classifications  automated miniature screwdriving  consumer electronics industry every year  screwdriving process  challenging tasks  robotic threaded fastening systems  system cost  Robot sensing systems  Fasteners  Joining processes  Fault detection  Torque  Reliability 
Abstract: Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.


Title: Evaluating Methods for End-User Creation of Robot Task Plans
Key Words: manipulators  multi-robot systems  path planning  end-user creation  perception-driven task plans  collaborative robots  generalizable robot task plans  behavior tree-based CoSTAR system  pick-and-place assembly tasks  SmartMove  Task analysis  Planning  User interfaces  Service robots  Grippers  Collaboration 
Abstract: How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.


Title: Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems
Key Words: control engineering computing  direction-of-arrival estimation  multi-robot systems  networked control systems  security of data  statistical analysis  networked multirobot systems  parametric statistical tool  wireless network  DoA-aided attack detection scheme  multirobot testbed  distributed direction of arrival estimation-aided cyberattack detection  Direction-of-arrival estimation  Robot sensing systems  Multi-robot systems  Antenna measurements  Robot kinematics 
Abstract: This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.


Title: Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery
Key Words: cellular transport  collision avoidance  fluorescence  goods distribution  microrobots  mobile robots  nanoparticles  particle swarm optimisation  path planning  position control  quantum dots  tracking  trajectory control  Mag-Spore  fluorescence microscopy  fluorescence imaging  observer-based trajectory tracking controller  multifunctional magnetic Spores  microrobotic cargo delivery possesses  complex environmental conditions  obstructed optical feedback  automated control approach  microrobotic cargo carrier  multifunctional magnetic spore  Magnetic resonance imaging  Automation  Magnetic multilayers  Carbon  Stem cells  Optimization 
Abstract: Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.


Title: Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface
Key Words: microrobots  mobile robots  microchannels  pairwise interactions  local interactions  collective behaviors  mobile microrobot collectives  multiple spinning microrafts  air-water interface  object manipulation  spinning mobile microrobots  size 100.0 mum  Conferences  Intelligent robots 
Abstract: We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.


Title: Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
Key Words: autonomous aerial vehicles  biomimetics  control system synthesis  helicopters  manipulators  mobile robots  path planning  robot vision  sensors  AGRASP  multirotor aerial vehicles  robotics perception  vision-based path planning  highly-constrained sensor  autonomous grasping robotic aerial system for perching  biomimetically-inspired manipulation  perch structures  innovative manipulator design  active grasp  passive grip  quadrotor autonomously detection  onboard sensing  onboard processing  Manipulators  Tendons  Robot sensing systems  Bars  Grasping  Three-dimensional displays 
Abstract: This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.


Title: Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation
Key Words: control engineering computing  image reconstruction  image segmentation  industrial manipulators  man-machine systems  mobile robots  object recognition  real-time systems  robot vision  telerobotics  virtual reality  model segmentation  autonomous mobile robot systems  human-machine interfaces  virtual reality-technologies  mixed reality-technologies  multimodal teleoperation  real-time remote control  noise-reduced visualization  object recognition  operator-supporting teleoperation  real-time feedback  industrial articulated robotic arm  real-time environment reconstruction  VR-based teleoperation  known object segmentation  point-cloud visualization  long distance UDP/IP communication  Cameras  Calibration  Solid modeling  Robot vision systems  Task analysis 
Abstract: Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.


Title: DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance
Key Words: collision avoidance  graph theory  image segmentation  image sensors  mobile robots  motion control  neural nets  robot vision  stereo image processing  multiple disparity images  C-space expansion  disparity space representation  generic obstacles  wire pixels  confidence map  semantic segmentation paradigm  convolutional neural network  monocular wire detection  generic obstacle avoidance  robust autonomous aerial vehicles  depth estimation  DROAN - disparity-space representation  Wires  Robot sensing systems  Three-dimensional displays  Cameras  Trajectory  Uncertainty 
Abstract: Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.


Title: Robocentric Visual-Inertial Odometry
Key Words: distance measurement  inertial navigation  Kalman filters  mobile robots  Monte Carlo methods  motion estimation  nonlinear filters  position measurement  SLAM (robots)  robocentric EKF-based VINS  standard world-centric frameworks  R-VIO  real-world experiments  state-of-the-art VINS  robocentric visual-inertial odometry  visual-inertial navigation systems  consistent localization  challenging environments  monocular vision  moving local frame  standard world-centric VINS  global gravity vector  multistate constraint Kalman filter framework  visual-inertial odometry algorithm  global pose  high-accuracy relative motion  robocentric formulation  Robot sensing systems  Three-dimensional displays  Computational efficiency  Navigation  Standards  Gravity  Quaternions 
Abstract: In this paper, we propose a novel robocentric formulation of visual-inertial navigation systems (VINS)within a multi-state constraint Kalman filter (MSCKF)framework and develop an efficient, lightweight, robocentric visual-inertial odometry (R-VIO)algorithm for consistent localization in challenging environments using only monocular vision. The key idea of the proposed approach is to deliberately reformulate the 3D VINS with respect to a moving local frame (i.e., robocentric), rather than a fixed global frame of reference as in the standard world-centric VINS, and instead utilize high-accuracy relative motion estimates for global pose update. As an immediate advantage of using this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align its orientation with the global gravity vector. More importantly, we analytically show that the proposed robocentric EKF-based VINS does not undergo the observability mismatch issue as in the standard world-centric frameworks which was identified as the main cause of inconsistency of estimation. The proposed R-VIO is extensively tested through both Monte Carlo simulations and real-world experiments using different sensor platforms in different environments and shown to achieve competitive performance with the state-of-the-art VINS algorithms in terms of consistency, accuracy and efficiency.


Title: Deep Sequential Models for Sampling-Based Planning
Key Words: collision avoidance  computational geometry  learning (artificial intelligence)  mobile robots  multi-agent systems  path planning  sampling methods  deep sequential models  sequence model  sampling-based planner  efficient plans  planner state  neural-network-based models  fewer rejected samples  multiagent environments  graphical models  Hidden Markov models  Computational modeling  Planning  Adaptation models  Space exploration  Uncertainty  Sensors 
Abstract: We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.


Title: A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning
Key Words: mobile robots  path planning  sampling methods  topology  homotopic similarity  homotopy equivalence  naive application  local planning  sampling-based motion planning  topologically distinct portions  topologically distinct paths  robotic motion planning  homotopy classes  topology-based path similarity metric  path deformation roadmaps  multiple homotopically distinct paths  Measurement  Planning  Strain  Algorithms  Merging  Manipulators 
Abstract: Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.


Title: Real-Time Motion Planning in Changing Environments Using Topology-Based Encoding of Past Knowledge
Key Words: collision avoidance  encoding  graph theory  mobile robots  reachability analysis  topology  approximate Reeb graph  BKPIECE algorithms  topology-based encoding  trajectory planning  complex environments  DRM-connect algorithm  dynamic reachability maps  lazy collision checking  fallback strategy  RRT-connect algorithm  sparser roadmaps  motion planning  changing environments  Task analysis  Trajectory  Planning  Heuristic algorithms  Robots  Topology  Maintenance engineering 
Abstract: Trajectory planning and replanning in complex environments often reuses very little information from the previous solutions. This is particularly evident when the motion is repeated multiple times with only a limited amount of variation between each run. To address this issue, we propose the DRM-connect algorithm, a combination of dynamic reachability maps (DRM) with lazy collision checking and a fallback strategy based on the RRT-connect algorithm which is used to repair the roadmap through further exploration. This fallback allows us to use much sparser roadmaps. Furthermore, we investigate using an approximate Reeb graph to capture the topology-persistent features of the past solutions of the problem utilising this sparsity. We evaluate DRM-connect with a Reeb graph on reaching tasks, and we compare it to state-of-the-art methods. We show that the proposed method outperforms both RRT-connect and BKPIECE algorithms in the number of collision checks required and we show that our method has the potential to scale to systems with higher number degrees of freedom.


Title: Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs
Key Words: collision avoidance  end effectors  trees (mathematics)  path planning problems  C-space planners  configuration space  robot end-effector  collision-free paths  workspace information  global planner  task-space RRTs  workspace decomposition  hierarchical path planner  Task analysis  Path planning  End effectors  Partitioning algorithms  Collision avoidance 
Abstract: This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.


Title: Deeply Informed Neural Sampling for Robot Motion Planning
Key Words: collision avoidance  computational complexity  feedforward neural nets  geometry  learning (artificial intelligence)  mobile robots  sampling methods  obstacle geometry  computational complexity  configuration space  optimal path solution  hand-crafted heuristics  high-dimensional spaces  neural network-based adaptive sampler  raw point cloud data  workspace encoding  collision-free optimal paths  point-mass robot  6-link robotic manipulator  dropout-based stochastic deep feedforward neural network  DeepSMPs neural architecture  deep sampling-based motion planner  robot motion planning  deeply informed neural sampling  contractive autoencoder  rigid-body  Planning  Robots  Encoding  Three-dimensional displays  Convergence  Switched mode power supplies  Transforms 
Abstract: Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.


Title: Inverse Learning of Robot Behavior for Collaborative Planning
Key Words: behavioural sciences computing  decision making  learning (artificial intelligence)  mobile robots  multi-robot systems  optimisation  planning (artificial intelligence)  robots decision making  TurtleBots  Phantom X arms  line robots behavior  collaborative planning problem  colored-ball sorting task  unripe fruit  ripe fruit  IRL  inverse reinforcement learning  Task analysis  Planning  Robot kinematics  Sorting  Teamwork 
Abstract: Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.


Title: Multi-Cable Rolling Locomotion with Spherical Tensegrities Using Model Predictive Control and Deep Learning
Key Words: actuators  cables (mechanical)  differential equations  feedback  learning (artificial intelligence)  open loop systems  predictive control  robust control  trajectory control  generated optimal MPC trajectories  supervised deep learning  contextual policy  benchmark single-cable policy performance  resulting multicable state-action trajectories  dynamic rolling  multicable actuation trajectories  Class-1 tensegrity systems  structured dynamics  spherical tensegrity topology  robust control policies  model-based approach  model predictive control  spherical tensegrities  multicable rolling locomotion  end-to-end feedback policy  Mathematical model  Predictive control  Topology  Robot kinematics  Dynamics  Optimization 
Abstract: This work presents a model-based approach for creating robust control policies for rolling locomotion with a spherical tensegrity topology. Utilizing the structured dynamics of Class-1 tensegrity systems, we turn to model predictive control (MPC) to generate optimal multi-cable actuation trajectories for dynamic rolling. Although the resulting multi-cable state-action trajectories successfully outperform the benchmark single-cable policy performance in speed, computational constraints prevent MPC from being applied in real-time. To address this, we demonstrate that a contextual policy trained using supervised deep learning on the generated optimal MPC trajectories can be used as an end-to-end feedback policy for real-time directed rolling locomotion.


Title: Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System
Key Words: dexterous manipulators  manipulator dynamics  robot vision  continuous high-speed operation  one-face turn motion  high-speed multifingered hand  high-speed vision system  Rubiks cube handling  robotic hand regrasping function  time 1.0 s  time 10.0 s  Gravity  Face  Robot sensing systems  Turning  Trajectory  Orbits 
Abstract: The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.


Title: A Lightweight Redundant Manipulator with High Stable Wireless Communication and Compliance Control
Key Words: compliance control  control engineering computing  dexterous manipulators  force control  intelligent manufacturing systems  motion control  position control  production engineering computing  protocols  redundant manipulators  servomechanisms  wireless sensor networks  Zigbee  7-DOF manipulator  application layer protocol  ZigBee  absolute magnetic encoder  incremental magnetic encoder  hall sensors  Industry 4.0  distributed networked-manufacturing system  joint servo controllers  intelligent manufacturing system  manipulator body  high stable wireless communication link  motion controller  lightweight redundant manipulator  wireless impedance control experiments  electrical cables  wireless compliance control frame  force control requirements  communication stability  wireless communication module  central controller  communication cables  Manipulators  ZigBee  Wireless communication  Servomotors  Wireless sensor networks  Impedance  Sensors  7-DOF manipulator  Multilevel control system  ZigBee  Wireless compliance Control 
Abstract: For traditional manipulators, there is a large number of electrical cables between the motion controller and the joint servo controllers. It is very inconvenient for maintenance, update, and safe operation. In this paper, we develop a lightweight redundant manipulator with high stable wireless communication link and compliance control. The motion controller, servo controller, and communication link are taken as a whole system to be optimized. The manipulator body and the motion controller are physically separated. It is very helpful for building distributed networked-manufacturing system or intelligent manufacturing system for Industry 4.0. The control system can be quickly updated by changing the object's identification without reconnect the communication cables. The mechanical part of the manipulator contains modular joints and links. Each joint is integrated with hall sensors, an incremental magnetic encoder, an absolute magnetic encoder and current sensors. The electrical part includes a central controller, seven joint servo controllers, and a wireless communication module based on ZigBee. By designing the application layer protocol, the communication stability is improved. In order to achieve the force control requirements in fine operation like assembly. A wireless compliance control frame is then designed. The compliance control method is realized on the central controller, by which the generated control commands are sent to the joint servo controllers through a wireless link. The problems caused by large electrical cables are then solved. Finally, the prototype and the experimental system are developed. Some experiments are carried out, including wireless communication test, trajectory tracking experiments, load carrying experiments, and wireless impedance control experiments. Results verify the functions and performance of the developed 7-DOF manipulator.


Title: Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*
Key Words: legged locomotion  manipulators  mobile robots  motion control  path planning  position control  system states  system trajectory  nonprehensile  manipulation strategies  multilimb robot  control strategy  point contacts  contact velocity constraint  force constraint  system forces  system dynamic models  Robot kinematics  Force  Acceleration  Humanoid robots  Legged locomotion  Friction 
Abstract: This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.


Title: Proprioception-Based Grasping for Unknown Objects Using a Series-Elastic-Actuated Gripper
Key Words: actuators  dexterous manipulators  elasticity  force control  grippers  mechanoception  MIMO systems  motion control  series-elastic-actuated gripper  stable fingertip grasps  proprioceptive gripper  proprioception-based grasping  multi-input-multi-output control  MIMO control  sensors  Robot sensing systems  Grippers  Grasping  Pulleys  Springs  Sea measurements 
Abstract: Grasping unknown objects has been an active research topic for decades. Approaches range from using various sensors (e.g. vision, tactile) to gain information about the object, to building passively compliant hands that react appropriately to contacts. In this paper, we focus on grasping unknown objects using proprioception (the combination of joint position and torque sensing). Our hypothesis is that proprioception alone can be the basis for versatile performance, including multiple types of grasps for objects with multiple shapes and sizes, and transitions between grasps. Using a series-elastic-actuated gripper, we propose a method for performing stable fingertip grasps for unknown objects with unknown contacts, formulated as multi-input-multi-output (MIMO) control. We also show that the proprioceptive gripper can perform enveloping grasps, as well as the transition from fingertip grasps to enveloping grasps.


Title: Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter
Key Words: Bayes methods  Kalman filters  manipulators  particle filtering (numerical methods)  quadratic programming  state estimation  RBPF  contact states  Kalman filters  constrained Rao-Blackwellized Particle Filter  robotic sensors  robotic manipulation task  multibody dynamic system  Bayesian filtering methods  state estimation  quadratic programming problem  Robot sensing systems  Mathematical model  Kalman filters  State estimation  Dynamics 
Abstract: Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.


Title: Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks
Key Words: aerospace robotics  force control  manipulator kinematics  mobile robots  motion control  rotors  whole body locomotion  tactile perception  finite state automaton  aerial robot peg-in-hole insertion tasks  impedance based force control  dual arm multidegree of freedom manipulator  kinematic constraints  dual arm manipulator  multirotor base  multistage strategy  impedance control  peg-in-hole approach  multirotor platform  canonical peg-in-hole manipulation task  Force  Impedance  Task analysis  Manipulator dynamics  Rotors  Kinematics 
Abstract: This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.


Title: Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations
Key Words: actuators  autonomous aerial vehicles  feedback  industrial manipulators  inspection  manipulator dynamics  manipulator kinematics  mobile robots  motion control  pendulums  position control  torque control  inspection operations  multirotor blades  environmental obstacles  inspection tasks  long reach aerial manipulator  hexarotor platform  compliant joint arm  one-meter-length link  passive pendulum configuration  force/torque estimation-control  joint deflection  visual inspection  wearable exoskeleton interface  aerial manipulator kinematics  aerial manipulator dynamics  Manipulator dynamics  Inspection  Robot sensing systems  Visualization  Exoskeletons  Cameras 
Abstract: The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.


Title: Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles
Key Words: autonomous aerial vehicles  collision avoidance  feedback  mobile robots  multi-robot systems  predictive control  state feedback  trajectory control  prediction horizon  decentralized collision avoidance system  fast nonlinear feedback  virtual UAV  translational dynamics  nonlinear state feedback  linear model predictive controller  optimal trajectory tracking  unmanned aerial vehicles  model predictive trajectory tracking  priority-based collision resolution strategy  tracking mechanism  in-advance collision-free planning  linear MPC  Trajectory  Collision avoidance  Unmanned aerial vehicles  Robot kinematics  Planning  Robot sensing systems 
Abstract: We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.


Title: Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information
Key Words: learning (artificial intelligence)  mobile robots  object recognition  object category learning  learning recognition  evaluation approaches  recognition approaches  multicontext scenarios  recognition methods  unconstrained human environments  autonomous robots  object categories  human-centric environment  explicit context information  open-ended object recognition  context change  Robots  Visualization  Protocols  Histograms  Context modeling  Three-dimensional displays  Training 
Abstract: To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.


Title: Attention-Aware Cross-Modal Cross-Level Fusion Network for RGB-D Salient Object Detection
Key Words: convolutional neural nets  feature extraction  image colour analysis  image fusion  object detection  geometric saliency cues  selection module  public datasets  attention-aware cross-modal cross-level fusion block  RGB-D fusion network  informative cross-modal cross-level combination  multimodal fusion stage  depth features/decisions  depth information  RGB-D sensors  convolutional neural networks  RGB-D salient object detection  attention-aware cross-modal cross-level fusion network  Object detection  Feature extraction  Fuses  Task analysis  Computer architecture  Visualization  Adaptation models 
Abstract: Convolutional neural networks have achieved wide success in RGB saliency detection. Recently, the advent of RGB-D sensors such as Kinect provide additional geometric saliency cues. However, the key challenge for RGB-D salient object detection that how to fuse RGB and depth information sufficiently is still under-studied. Traditional works mainly follow the two-stream architecture and combine RGB and depth features/decisions in an early or late point. The multi-modal fusion stage is performed by directly concatenating the features from two modalities without selection. In this work, we address this question by proposing a novel network with a distinguished insight: A selection module is significantly helpful for more informative and sufficient cross-modal cross-level combination. To this end, we introduce a top-down RGB-D fusion network which integrates an attention-aware cross-modal cross-level fusion block in each level to select discriminative features from each level and each modality. Extensive experiments on public datasets show that the proposed network is able to solve the key problems in RGB-D fusion and achieves state-of-the-art performance on RGB-D salient object detection.


Title: Incremental Object Database: Building 3D Models from Multiple Partial Observations
Key Words: feature extraction  image colour analysis  image reconstruction  image representation  image segmentation  mobile agents  object detection  solid modelling  multiple partial observations  incremental object database  indoor scenes  merged models  object model  observed instances  segmented RGB-D images  global segmentation map  3D models  mobile agent  Image segmentation  Databases  Three-dimensional displays  GSM  Shape  Image reconstruction  Solid modeling 
Abstract: Collecting 3D object data sets involves a large amount of manual work and is time consuming. Getting complete models of objects either requires a 3D scanner that covers all the surfaces of an object or one needs to rotate it to completely observe it. We present a system that incrementally builds a database of objects as a mobile agent traverses a scene. Our approach requires no prior knowledge of the shapes present in the scene. Object-like segments are extracted from a global segmentation map, which is built online using the input of segmented RGB-D images. These segments are stored in a database, matched among each other, and merged with other previously observed instances. This allows us to create and improve object models on the fly and to use these merged models to reconstruct also unobserved parts of the scene. The database contains each (potentially merged) object model only once, together with a set of poses where it was observed. We evaluate our pipeline with one public dataset, and on a newly created Google Tango dataset containing four indoor scenes with some of the objects appearing multiple times, both within and across scenes.


Title: A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control
Key Words: closed loop systems  computational complexity  iterative methods  linear quadratic control  nonlinear control systems  predictive control  iterative algorithms  unconstrained nonlinear optimal control  iLQR algorithm  closed-loop forward integration  linear complexity  multiple shooting algorithms  nonlinear model predictive control applications  computational complexity  high-dimensional underactuated robot  iterative Gauss-Newton shooting methods  Optimal control  Trajectory  Heuristic algorithms  Prediction algorithms  Robots  System dynamics  Convergence  Numerical Optimal Control  Trajectory Optimization  Multiple Shooting  Quadrupedal Robots  Nonlinear Model Predictive Control  Differential Dynamic Programming 
Abstract: This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.


Title: Controller Synthesis for Discrete-Time Polynomial Systems via Occupation Measures
Key Words: computational complexity  control system synthesis  convex programming  discrete time systems  linear programming  Liouville equation  multidimensional systems  nonlinear control systems  reachability analysis  set theory  stability  state feedback  discrete-time polynomial systems  occupation measures  discrete-time polynomial dynamical systems  occupation measure approach  discrete-time controlled Liouville equation  controller synthesis problem  infinite-dimensional linear programming problem  finite-dimensional semidefinite programming problems  sums-of-squares polynomials  nonlinear controllers  relaxed problems  convex problems  discrete-time autonomous polynomial systems  controllable set  nonlinear state feedback controllers  state feedback control laws  controller design  computational complexity  backward reachable set  Volume measurement  Trajectory  State feedback  Mathematical model  Topology  Aerospace electronics 
Abstract: In this paper, we design nonlinear state feedback controllers for discrete-time polynomial dynamical systems via the occupation measure approach. We propose the discrete-time controlled Liouville equation, and use it to formulate the controller synthesis problem as an infinite-dimensional linear programming problem on measures, which is then relaxed as finite-dimensional semidefinite programming problems on moments of measures and their duals on sums-of-squares polynomials. Nonlinear controllers can be extracted from the solutions to the relaxed problems. The advantage of the occupation measure approach is that we solve convex problems instead of generally non-convex problems, and the computational complexity is polynomial in the state and input dimensions, and hence the approach is more scalable. In addition, we show that the approach can be applied to over-approximating the backward reachable set of discrete-time autonomous polynomial systems and the controllable set of discrete-time polynomial systems under known state feedback control laws. We illustrate our approach on several dynamical systems.


Title: Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks
Key Words: iterative methods  learning (artificial intelligence)  minimax techniques  mobile robots  neurocontrollers  nonlinear control systems  model mismatch  model uncertainties  high-risk scenarios  robustness capacity  minimax iterative dynamic game  robust policies  carefully designed deep neural network policy  policy robustness  adversarial disturbances  ocally robust optimal multistage policy  nonlinear robot control tasks  multistage decision policies  high-dimensional state spaces  complex control tasks  meta-learning-deep policies  Robustness  Heuristic algorithms  Trajectory  Games  Task analysis  Uncertainty  Approximation algorithms 
Abstract: Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.


Title: Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring
Key Words: end effectors  fault diagnosis  fault tolerant control  force control  industrial manipulators  robotic assembly  trajectory control  multimodal environment dynamics  interactive robots  environmental uncertainty  contact force  subtask completion  task monitoring approach  complex assembly tasks  discrete environment dynamic modes  semistructured environments  interactive tasks  impedance control  admittance controlled robots  force/position measurements  admittance controlled robot  gear assembly task  fault detection  force trajectories  position trajectories  end-effector physical compliance  Dynamics  Task analysis  Force  Robot sensing systems  Admittance  Estimation 
Abstract: Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.


Title: Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration
Key Words: grippers  intelligent robots  learning (artificial intelligence)  mobile robots  pose estimation  robot vision  solid modelling  complex processing tasks  current robot learning policies  consistent learning policy  skilled operators  robotic automation  variable outcomes  tedious nature  laborious nature  human operators  food industries  ocean space  huge demand  mechanical structures  complex geometrical 3D shapes  high biological variation  deformable food raw materials  compliant food raw materials  robotic handling  complex 3D shapes  compliant food objects  inconsistent demonstrations  LfD learning policy  effective robot handling  gripper finger configuration  RGB-D images  food compliant objects  robotic grasping  robust learning policy  Grasping  Visualization  Service robots  Task analysis  Robot sensing systems  Three-dimensional displays  Compliant food objects  Learning from Demonstration  Robotic handling  Multifingered gripper 
Abstract: The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.


Title: Soft Biomimetic Prosthetic Hand: Design, Manufacturing and Preliminary Examination
Key Words: artificial limbs  biomechanics  biomimetics  manipulators  human hand  complex mechanical structure  prosthetic devices  handled object  mechanical compliance  synergistic finger movement  current control system  soft biomimetic prosthetic hand  Actuators  Exoskeletons  Manufacturing  Shape  Thumb  Joints  Sensors 
Abstract: The human hand is a complex structure. It is strong but precise. It consists of a very complex mechanical structure that enables the hand to adapt and efficiently handle objects of various shapes, weights and textures. Today's prosthetic devices, struggling to provide similar functions, become overly complex and expensive. They are composed of multiple, precise parts, including miniaturised actuators and sensors as well as complex control, to satisfy the manipulation tasks required. In this paper we propose a soft pneumatic hand that adapts passively to the handled object due to its mechanical compliance. It is pressure driven and enables individual fingers to be controlled independently for dexterity or in groups when a synergistic finger movement is needed. The hand has a truly anatomical shape, is easy to replace and cheap in production. The design can be easily adjusted in terms of shape and size in order to fit each individual user. The paper presents the design, manufacturing technology, current control system and preliminary tests of the hand's capabilities.


Title: On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints
Key Words: humanoid robots  interpolation  path planning  polynomials  position control  splines (mathematics)  spline trajectories  time curves  quaternion coefficients  unitariness condition  quaternion representation  on-line update mechanism  anthropomorphic robot upper-body  real-time compatibility  constrained angular velocity  orientation planning algorithms  task space trajectory generation  robotics applications  continuous acceleration profiles  realtime implementation  Quaternions  Interpolation  Acceleration  Robots  Splines (mathematics)  Trajectory  Planning 
Abstract: This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.


Title: Mobile Continuum Robot with Unlimited Extensible Sections
Key Words: bending  buckling  DC motors  force control  gears  mobile robots  motion control  pulleys  typical continuum robots  restricted section length  locomotion  mobile continuum robot design  virtually unlimited extensible sections  driving unit  gear  long flexible tube  traveling distance  multiple driving units  DC motors  crawling locomotion performance  3D printer  helical groove  tendon-driven robots  Electron tubes  DC motors  Gears  Trajectory  Springs  End effectors 
Abstract: Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.


Title: Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World
Key Words: control engineering computing  convolutional neural nets  humanoid robots  learning (artificial intelligence)  manipulators  robot vision  selective dual-arm grasping  pruning grasping points  robot experience  robot grasping  dual-arm robots  humanoid robots  dual-arm manipulation  single-arm limitation  multistage learning method  self-supervised approach  convolutional neural networks  CNN  semantic segmentation  automatic annotation  Grasping  Semantics  Image segmentation  Manipulators  Task analysis  Learning systems 
Abstract: Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.


Title: A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
Key Words: Bayes methods  image fusion  image sensors  Kalman filters  mobile robots  nonlinear filters  object detection  probability  remotely operated vehicles  robot vision  mobile robot  multistage Bayesian approaches  multistage localization approach  global coordinate frame  multistage target observation approach  target engagement  multiple sensors  Bayesian framework  simultaneous robot localization  sensors on-board  target detection  associated detection probability  extended Kalman filter  unmanned ground vehicle  Robot kinematics  Robot sensing systems  Bayes methods  Mobile robots  Uncertainty 
Abstract: This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.


Title: Motion Planning for an Underwater Mobile Manipulator by Exploiting Loose Coupling
Key Words: autonomous underwater vehicles  manipulators  motion control  path planning  trajectory control  intervention autonomous underwater vehicle  MR-MHA *  multirepresentation multiheuristic A*  realistic simulated underwater intervention environment  intervention mission  generated trajectories  high-dimensional underwater manipulator  search-based planner  motion coordination  complex manipulation tasks  floating-based intervention  task-priority redundancy control framework  GIRONA 500  SAUVIM  autonomous manipulation skills  I-AUV  underwater mobile manipulator  motion planning  Task analysis  Planning  Manipulators  Search problems  Trajectory  Kinematics 
Abstract: Intervention Autonomous Underwater Vehicle or I-AUV has recently started to grab researchers attention in the last 20 years. Only three I-AUVs have demonstrated autonomous manipulation skills: ALIVE, SAUVIM and GIRONA 500. While prior systems rely on variations of the task-priority redundancy control framework, our recent research showed preliminary results using motion planning for floating-based intervention in the presence of obstacles. With the increasing need for autonomously performing more complex manipulation tasks, two main challenges need to be addressed: the high-dimensionality of the system, and the motion coordination between the mobile base and the working arm. The latter challenge is of high importance if accurate execution is required, especially considering the floating nature of the AUV and the control challenges that come with it. Our approach relies on exploiting the loose coupling between the AUV and the arm. In particular we present an approach based on MR-MHA * (Multi-Representation, Multi-Heuristic A*), and we show how it can generate efficient trajectories by exploiting decoupling. We show for the first time the use of a search-based planner on a high-dimensional underwater manipulator. In addition, we support our claims with experimental analysis of the generated trajectories with respect to various metrics in different environments. Furthermore, we demonstrate the ability of our approach to conduct a full intervention mission in a realistic simulated underwater intervention environment.


Title: Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot
Key Words: collision avoidance  hospitals  manipulator dynamics  medical robotics  mobile robots  predictive control  probability  PAM robot  probabilistic method  2-wheel walker  autonomous learning  fall prevention  maneuvers mobility aids  patient assistant mobile robot  dynamic model learning  collision-free manipulation  4-legged walker  hybrid MPC-based manipulation planning algorithm  one-wheel point-mass model  hybrid control system  motion interactions  minimal force  approximate dynamic model  Legged locomotion  Dynamics  Planning  Manipulator dynamics  Grippers 
Abstract: One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.


Title: Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality
Key Words: convolutional neural nets  grippers  learning (artificial intelligence)  mobile robots  pose estimation  virtual reality  teaching  gripper  domain randomization approach  depth imaging  3D occupancy grid  robot imitation learning  deep 3D convolutional neural network  virtual robot  grasp real fish  virtual reality  human supervisor  Robots  Task analysis  Three-dimensional displays  Grippers  Grasping  Cameras  Virtual reality 
Abstract: We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.


Title: Fully Convolutional Grasp Detection Network with Oriented Anchor Box
Key Words: feature extraction  feedforward neural nets  grippers  human-robot interaction  image classification  image colour analysis  image matching  inference mechanisms  learning (artificial intelligence)  object detection  object recognition  regression analysis  robot vision  parallel-plate robotic gripper  RGB images  oriented anchor box mechanism  matching strategy  end-to-end fully convolutional neural network  feature extractor  deep convolutional neural network  multigrasp predictor regresses  predefined oriented rectangles  anchor boxes  standard Cornell Grasp Dataset  image-wise split  object-wise split  latest state-of-the-art approach  grasping poses  convolutional grasp detection network  Feature extraction  Robots  Computational modeling  Grippers  Solid modeling  Computer architecture  Predictive models 
Abstract: In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.


Title: Fast Convergence for Object Detection by Learning how to Combine Error Functions
Key Words: image segmentation  learning (artificial intelligence)  mobile robots  multi-robot systems  neural nets  object detection  union metric  estimated pickup rate  convergence time  optimally weighted Euclidean distance loss  object detection network  robotic pickup operation  approximate measure  detecting objects  fully convolutional segmentation network  RoboCup@Work challenge environment  on-line trained auxiliary network  dependent loss metrics  Converge-fast-auxnet  object detection neural networks  convergence speed  error functions  fast convergence  Object detection  Training  Convergence  Task analysis  Mathematical model  Euclidean distance 
Abstract: In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.


Title: Multi-Layer Coverage Path Planner for Autonomous Structural Inspection of High-Rise Structures
Key Words: autonomous aerial vehicles  inspection  path planning  structural engineering  travelling salesman problems  autonomous structural inspection  high-rise structures  buildings  towers  unmanned aerial vehicle  multi-layer coverage path planner  3D coverage path planning  traveling salesman problem  Inspection  Three-dimensional displays  Path planning  Planning  Unmanned aerial vehicles  Solid modeling  Spirals 
Abstract: In this paper, a novel 3D coverage path planning method, which is efficient and practical for inspection of high-rise structures such as buildings or towers, using an unmanned aerial vehicle (UAV) is presented. Our approach basically focuses on developing a model-based path planner for structural inspection with a prior map, which is opposite to a non-model based exploration. The proposed method uses a volumetric map which is made before the path planning. With the map, the whole structure is divided into several layers for efficient path planning. Firstly, in each layer, a set of the normal vectors of the center point of every voxel is calculated, and then the opposing vectors become viewpoints. Due to too many viewpoints and an overlapped inspection surface, we down-sample them with a voxel grid filter. Then, the shortest tour connecting the reduced viewpoints must be computed with the Traveling Salesman Problem (TSP) solver. Lastly, all the paths in each layer are combined to form the complete path. The results are verified using simulations with a rotary wing UAV and compared with other state-of-the-art algorithm. It is proven that our method performs much better for structural inspection with respect to computation time as well as the coverage completeness.


Title: Robust Humanoid Control Using a QP Solver with Integral Gains
Key Words: humanoid robots  Lyapunov methods  quadratic programming  robot dynamics  robust control  torque control  low-frequency bounded disturbances  Lyapunov-stable torque control  dynamical model  dynamic constraints  QP solver  kinetic joint friction  robust humanoid control  torque controlled humanoid robots  multiobjective weighted tasks  optimal dynamically-feasible reference  exponential convergence  joint torque feedback  nonmodelled torque bias  quadratic programming  HRP-5P robot  Torque  Humanoid robots  Convergence  Acceleration  Torque control  Task analysis  Robust control  Torque control  Passivity  Quadratic programming  Humanoid robots 
Abstract: We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.


Title: Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence
Key Words: intelligent sensors  nearest neighbour methods  recurrent neural nets  skin  tactile sensors  recurrent neural network  Preisach model  multiple contact locations  k-nearest neighbors algorithm  artificial neural network  machine learning techniques  soft robotics applications  soft artificial skin sensors  artificial intelligence  soft tactile sensors  Sensors  Force  Hysteresis  Microchannels  Estimation  Wires  Real-time systems 
Abstract: Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.


Title: A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots
Key Words: cantilevers  electroactive polymer actuators  manipulator kinematics  polymers  millicontinuum soft robots  active flexible polymer actuator  multisegment robot  3D arrangement  robot capability  three-segment CSR  two-segment CSR  single segment robot  multiphysics model  millimeter-size Continuum Soft Robot  multisegment electro-active polymer  Strain  Nonhomogeneous media  Soft robotics  Fabrication  Deformable models  Microactuators 
Abstract: This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.


Title: Soft LEGO: Bottom-Up Design Platform for Soft Robotics
Key Words: assembling  bending  design engineering  finite element analysis  grippers  mobile robots  pneumatic actuators  rapid prototyping (industrial)  Taguchi methods  three-dimensional printing  soft LEGO bricks  soft robotics  pneumatically inflatable soft brick  assembled soft bricks  bottom-up design platform  flexible bending brick  air channel brick  Taguchi method  finite-element analysis  multimaterial 3-dimensional printer  Soft robotics  Hoses  Actuators  Pins  Toy manufacturing industry  Joining processes 
Abstract: This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.


Title: C-MPDM: Continuously-Parameterized Risk-Aware MPDM by Quickly Discovering Contextual Policies
Key Words: decision making  gradient methods  operations research  optimisation  continuously-parameterized risk-aware MPDM  on-line forward roll-out process  computational cost  continuous-valued parameters  iterative gradient-based algorithm  multipolicy decision making systems  social environment  promising policy parameters  contextual policies  Robots  Cost function  Real-time systems  Trajectory  Decision making  Backpropagation 
Abstract: Risk-aware Multi-Policy Decision Making (MPDM)is a powerful framework for reliable navigation in a dynamic social environment where rather than evaluating individual trajectories, a “library” of policies (reactive controllers)is evaluated by anticipating potentially dangerous future outcomes using an on-line forward roll-out process. There is a core tension in Multi-Policy Decision Making (MPDM)systems - it is desirable to add more policies to the system for flexibility in finding good policies, however, this increases computational cost. As a result, MPDM was limited to small (perhaps 5-10)discrete policies - a significant performance bottleneck. In this paper, we radically enhance the expressivity of MPDM by allowing policies to have continuous-valued parameters, while simultaneously satisfying real-time constraints by quickly discovering promising policy parameters through a novel iterative gradient-based algorithm. Our evaluation includes results from extensive simulation and real-world experiments in semi-crowded environments.


Title: Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).
Key Words: microactuators  microrobots  mobile robots  muscle  robot dynamics  stimulation frequency  atmospheric-operable walking robot  maximum walking speed  bio actuated walker  biological microbio-actuator  grants-in-aid  output force  stimulation voltage  muscle-tissue of earthworm  Japan society  atmospheric-operable 3d printed walking bio-robot  control property  Legged locomotion  Force  Muscles  Actuators  Strain measurement  Force measurement 
Abstract: Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.


Title: Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots
Key Words: accelerometers  gait analysis  legged locomotion  motion control  position control  terrain mapping  interrupt mode  hexapod walking robot  inertial measurements  multilegged walking robots  proprioceptive terrain sensing  terrain irregularities  inertial data  online foot strike detection  foot strike event detector  data processing  accelerometers  terrain traversal  Legged locomotion  Robot sensing systems  Accelerometers  Servomotors  Reliability 
Abstract: Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.


Title: Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot
Key Words: image classification  image colour analysis  learning (artificial intelligence)  mobile robots  object detection  object tracking  optical radar  probability  radar tracking  robot vision  service robots  stereo image processing  online transfer learning  3D LiDAR-based human detection  mobile robot  service robots  multisensor tracking system  2D LiDAR  human trajectory  3D LiDAR-based human classification  trajectory probability  RGB-D camera  Three-dimensional displays  Laser radar  Detectors  Robot sensing systems  Cameras 
Abstract: Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.


Title: Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People
Key Words: human-robot interaction  image recognition  mobile robots  navigation  path planning  robot vision  sensors  path-planning  sensor characteristics  autonomous navigation  sensor data  human recognition reliability  human-robot interaction  multiple people  initiate interaction  multimodal potential field  Robot sensing systems  Reliability  Task analysis  Character recognition  Robot kinematics  Cameras 
Abstract: In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.


Title: Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test
Key Words: home computing  manipulators  mobile robots  motion control  multi-robot systems  wheels  international competition  aging population  intelligent sensing  household work  actual home environment  HSR users  technical knowledge  standard platform  international robot competitions  HSR's development background  omnidirectional mobile base  domestic mobile manipulator  human support robot  whole body motion control system  field test  quality of life  intelligent software  World Robot Summit  dual-wheel caster-drive mechanism  RoboCup@Home  HSR's operational movement  Robot kinematics  Manipulators  Task analysis  Sensors  Software  Hardware 
Abstract: There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.


Title: Registering Reconstructions of the Two Sides of Fruit Tree Rows
Key Words: agricultural products  feature extraction  image reconstruction  image registration  three dimensionalreconstructions  reconstruction registeration  partial reconstructions  side-views  measuring traits  yield mapping  orchard rows  fruit tree  Image reconstruction  Three-dimensional displays  Vegetation  Principal component analysis  Shape  Semantics  Cameras 
Abstract: We consider the problem of building accurate three dimensional (3D)reconstructions of orchard rows. This problem arises in many applications including yield mapping and measuring traits (e.g. trunk diameters)for phenotyping. While 3D reconstructions of side views can be obtained using standard methods, merging the two side-views is difficult due to the lack of overlap between the two partial reconstructions. We present a novel method that utilizes global features to constrain the solution. Specifically, we use information from the silhouettes and the ground plane for alignment. The method is evaluated using multiple simulated and real datasets. For additional information and demonstration of experimental results please see https://www.youtube.com/watch?v=6mGMF2gFv4M.


Title: Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.
Key Words: neural nets  object detection  optical radar  pedestrians  road safety  high visibility clothing  neural networksresearch  detection methods  lidar range data  lidar intensity data  lidar sensor  pedestrian detection  strong cue  retro-reflective strips  contract UOAX1414  business innovation  new zealand ministry  3D lidar sensors  industrial environments  pedestrian safety  Laser radar  Safety  Sensors  Neural networks  Three-dimensional displays  Clothing  Strips 
Abstract: The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.


Title: Bayesian Information Recovery from CNN for Probabilistic Inference
Key Words: Bayes methods  Gaussian distribution  image classification  image fusion  learning (artificial intelligence)  mobile robots  navigation  neural nets  pose estimation  probability  robot vision  target tracking  probabilistic inference approach  light conditions  trajectory estimation  simulated unreal engine environment  uncertainty covariance  robot localization problem  robot pose  hidden state mean prediction  high-level state information  inference task  CNN feature likelihood  Bayesian framework  spatially-varying Gaussian distribution  generative viewpoint-dependent model  CNN classifier  visual observations  system hidden state  combinatorial data association  hand-engineered image features  high-dimensional visual measurements  Bayesian information recovery  Robots  Trajectory  Cameras  Bayes methods  Estimation  Uncertainty  Neural networks 
Abstract: Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.


Title: Quadtree-Accelerated Real-Time Monocular Dense Mapping
Key Words: autonomous aerial vehicles  image fusion  image motion analysis  image reconstruction  image resolution  mobile robots  path planning  quadtrees  robot vision  stereo image processing  real-time monocular dense mapping  truncated signed distance function  dense 3D maps  resolution depth maps  pixels  dynamic belief propagation  pixel selection  depth map  intensity image  quadtree structure  single localized moving camera  high-quality dense depth maps  robotic navigation  Cameras  Three-dimensional displays  Belief propagation  Estimation  Optimization  Real-time systems  Image resolution 
Abstract: In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.


Title: Nonlinear Adaptive Control of Quadrotor Multi-Flipping Maneuvers in the Presence of Time-Varying Torque Latency
Key Words: adaptive control  aerodynamics  aircraft control  closed loop systems  control nonlinearities  control system synthesis  delays  helicopters  least squares approximations  linear systems  nonlinear control systems  position control  robust control  time-varying systems  torque control  recursive least-squares algorithm  high-performance linear controller  adaptive controller  nonlinear adaptive control scheme  linear time-varying model  linear time-invariant model  backstepping-based control scheme  LTV latency model  time-varying angular speed  torque delay  backstepping-based nonlinear controller  controller synthesis methods  high-speed multiflips  aerobatic maneuvers  closed-loop control schemes  stability robustness  time-varying torque  quadrotor multiflipping maneuvers  Torque  Aerodynamics  Linear systems  Adaptation models  Vehicle dynamics  Angular velocity  Propellers 
Abstract: The dynamics of quadrotors are affected by time-varying torque latency, which can greatly alter the stability robustness and performance of the closed-loop control schemes employed for flight; this issue is especially relevant during the execution of aerobatic maneuvers such as high-speed multi-flips. To address this problem, we propose two controller synthesis methods associated with two different modeling approaches. In the first approach, we describe torque latency with a linear time-invariant (LTI)model, identified through ground experiments, which is then used to design a backstepping-based nonlinear controller. In the second approach, we employ an improved linear time-varying (LTV)model with a priori unknown parameters, which is used to synthesize and implement a novel nonlinear adaptive control scheme updated in real time using the recursive least-squares (RLS)algorithm. Empirical observations suggest that the torque delay affecting the system depends on the time-varying angular speed of the flyer and its derivative. This phenomenon is explained by the fact that the aerodynamic forces produced by, and acting on, the rotating propellers vary with the local velocity of the incident flows. Hence, in the proposed adaptive structure, we define the parameters of the LTV latency model as linear functions of the angular speed reference and its derivative. Experimental results compellingly demonstrate the efficacy of the methods introduced in this paper; compared to the highperformance linear controller in [1]-[3], the backstepping-based control scheme and adaptive controller decrease the average root mean square (RMS)value of the control error by 17.82 % and 38.42 %, respectively.


Title: A Motion Planning Approach for Marsupial Robotic Systems
Key Words: graph theory  mobile robots  multi-robot systems  path planning  free-space regions  topological graph planning  high-level motion plan  low-level path planner  motion planning approach  marsupial robotic systems  automatic coordination  heterogeneous multirobot teams  marsupial-based subset  carrier robots  passenger robots  high-level watershed segmentation  Robot kinematics  Planning  Trajectory  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles 
Abstract: This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.


Title: Motion Planning and Goal Assignment for Robot Fleets Using Trajectory Optimization
Key Words: integer programming  mobile robots  multi-robot systems  optimal control  path planning  quadratic programming  mixed integer quadratic programming  autonomous robots  automating fleets  trajectory optimization  robot fleets  fleet-wide boolean decision variables  phase solves  two-phase approach  nonholonomic robots  Optimal Control  fleet management problem  performance criterion  motion planning  goal assignment  Robot kinematics  Collision avoidance  Aerospace electronics  Indexes  Trajectory  Geometry 
Abstract: This paper is concerned with automating fleets of autonomous robots. This involves solving a multitude of problems, including goal assignment, motion planning, and coordination, while maximizing some performance criterion. While methods for solving these sub-problems have been studied, they address only a facet of the overall problem, and make strong assumptions on the use-case, on the environment, or on the robots in the fleet. In this paper, we formulate the overall fleet management problem in terms of Optimal Control. We describe a scheme for solving this problem in the particular case of fleets of non-holonomic robots navigating in an environment with obstacles. The method is based on a two-phase approach, whereby the first phase solves for fleet-wide boolean decision variables via Mixed Integer Quadratic Programming, and the second phase solves for real-valued variables to obtain an optimized set of trajectories for the fleet. Examples showcasing the features of the method are illustrated, and the method is validated experimentally.


Title: Re-Establishing Communication in Teams of Mobile Robots
Key Words: mobile robots  multi-robot systems  optimisation  path planning  probability  tree searching  wireless connection  constrained optimization problem  branch-and-bound approach  locally available information  belief  mobile robots  Task analysis  Robot kinematics  Search problems  Mobile robots  Markov processes 
Abstract: As communication is important for cooperation, teams of mobile robots need a way to re-establish a wireless connection if they get separated. We develop a method for mobile robots to maintain a belief of each other's positions using locally available information. They can use their belief to plan paths with high probabilities of reconnection. This approach also works for subteams cooperatively searching for a robot or group of robots that they would like to reconnect with. The problem is formulated as a constrained optimization problem which is solved using a branch-and-bound approach. We present simulation results showing the effectiveness of this strategy at reconnecting teams of up to five robots and compare the results to two other strategies.


Title: Multi-Agent Planning for Coordinated Robotic Weed Killing
Key Words: agriculture  crops  environmental factors  industrial robots  mobile robots  multi-agent systems  path planning  multiagent planning  coordinated robotic Weed killing  coordinated multiagent weeding  partial environmental information  coordination strategies  weeding performance  autonomous agricultural robots  system performance  Weed World  coordinated weeding policies  realistic weed generation  initial seed bank densities  weeding process  required number  Agriculture  Robot kinematics  Optimization  Immune system  Chemicals  Soil 
Abstract: This work presents a strategy for coordinated multi-agent weeding under conditions of partial environmental information. The goal of this work is to demonstrate the feasibility of coordination strategies for improving the weeding performance of autonomous agricultural robots. We show that, given a sufficient number of agents, the algorithm can successfully weed fields with various initial seed bank densities, even when multiple days are allowed to elapse before weeding commences. Furthermore, the use of coordination between agents is demonstrated to strongly improve system performance as the number of agents increases, enabling the system to eliminate all the weeds in the field, as in the case of full environmental information, when the planner without coordination failed to do so. As a domain to test our algorithms, we have developed an open source simulation environment, Weed World, which allows real-time visualization of coordinated weeding policies, and includes realistic weed generation. In this work, experiments are conducted to determine the required number of agents and their required transit speed, for given initial seed bank densities and varying allowed days before the start of the weeding process.


Title: Intelligent Robotic IoT System (IRIS)Testbed
Key Words: Global Positioning System  intelligent robots  IP networks  middleware  mobile radio  mobile robots  multi-robot systems  personal area networks  protocols  robot vision  SLAM (robots)  wireless LAN  IPv6 network stack  individual robots  system implementation details  Intelligent robotic IoT system  modular source testbed  portable source testbed  open-source testbed  robotic wireless network research  IRIS  Time Difference of Arrival localization system  Time Difference of Arrival localization system  static global positioning system  multirobot testbeds  multirobot testbeds  Programmable Wireless Communication Stack  scalable source testbed  lightweight publish-subscribe overlay protocol  ROMANO  modular architecture  Iris recognition  Iris  Robot kinematics  Protocols  Transceivers  Ultrasonic imaging 
Abstract: We present the Intelligent Robotic IoT System (IRIS), a modular, portable, scalable, and open-source testbed for robotic wireless network research. There are two key features that separate IRIS from most of the state-of-the-art multi-robot testbeds. (1)Portability: IRIS does not require a costly static global positioning system such as a VICON system nor time-intensive vision-based SLAM for its operation. Designed with an inexpensive Time Difference of Arrival (TDoA)localization system with centimeter level accuracy, the IRIS testbed can be deployed in an arbitrary uncontrolled environment in a matter of minutes. (2)Programmable Wireless Communication Stack: IRIS comes with a modular programmable low-power IEEE 802.15.4 radio and IPv6 network stack on each node. For the ease of administrative control and communication, we also developed a lightweight publish-subscribe overlay protocol called ROMANO that is used for bootstrapping the robots (also referred to as the IRISbots), collecting statistics, and direct control of individual robots, if needed. We detail the modular architecture of the IRIS testbed design along with the system implementation details and localization performance statistics.


Title: SEAR: A Polynomial- Time Multi-Robot Path Planning Algorithm with Expected Constant-Factor Optimality Guarantee
Key Words: computational complexity  graph theory  mobile robots  multi-robot systems  optimisation  path planning  statistical distributions  polynomial-time multirobot path planning algorithm  expected constant-factor optimality guarantee  arbitrary initial goal arrangements  continuous 2D domains  continuous 3D domains  uniformly randomly distributed  microMVP platform  nonholonomic robots  near-optimal solutions  nonpolynomial time  initial goal configuration footprints  constant-factor expansion  Robots  Path planning  Collision avoidance  Labeling  Routing  Pipelines  Planning 
Abstract: We study the labeled multi-robot path planning problem in continuous 2D and 3D domains in the absence of obstacles where robots must not collide with each other. For an arbitrary number of robots in arbitrary initial and goal arrangements, we derive a polynomial time, complete algorithm that produces solutions with constant-factor optimality guarantees on both makespan and distance optimality, in expectation, under the assumption that the robot labels are uniformly randomly distributed. Our algorithm only requires a small constant-factor expansion of the initial and goal configuration footprints for solving the problem, i.e., the problem can be solved in a fairly small bounded region. Beside theoretical guarantees, we present a thorough computational evaluation of the proposed solution. In addition to the baseline implementation, adapting an effective (but non-polynomial time) routing subroutine, we also provide a highly efficient implementation that quickly computes near-optimal solutions. Hardware experiments on the microMVP platform composed of non-holonomic robots confirms the practical applicability of our algorithmic pipeline.


Title: A New Manufacturing Process for Soft Robots and Soft/Rigid Hybrid Robots
Key Words: adhesion  adhesives  design engineering  inflatable structures  robots  textiles  multichambered inflatable structures  thermal adhesive film  heat press  bond strength  soft-rigid hybrid robotic arm  Conferences  Intelligent robots 
Abstract: We present a novel manufacturing process for creating monolithic, multi-chambered inflatable structures including both soft and rigid components. Specifically, our process involves stacking layers of textiles or plastics and thermal adhesive film, then bonding the structure with a heat press or in an oven. Several different ways of arranging textiles and thermal adhesive film in order to achieve airtight structures are presented. Since this process only uses materials that bend, but do not stretch, it permits the easy inclusion of rigid structures such as circuit boards, plates that constrain inflatable chambers to bend in specified locations, and rigid pieces that enable sections of a robot to be connected in a modular fashion. Additionally, the process permits folding layers before their assembly, leading to more complex geometries. We present three different possible seam types, and enumerate the different types of corners that can be constructed without leaking. We present measurements of the ability of these structures to support pressure and measurements of the strength of bonds between textiles and other materials. Finally, we present two examples of robots constructed using this manufacturing method, including a hybrid soft/rigid robotic arm and a soft robot that can roll along the ground.


Title: Computing a Collision-Free Path Using the Monogenic Scale Space
Key Words: collision avoidance  Laplace equations  mobile robots  multi-robot systems  position control  static obstacles  dynamic obstacles  mobile robot  safe path  goal position  Laplace equation  collision-free path  rectangular bounded domain  monogenic scale space  environment map  nonconvex environments  functionalities  Kernel  Laplace equations  Mathematical model  Mobile robots  Magnetic domains  Magnetic resonance imaging 
Abstract: Mobile robots have been used for various purposes with different functionalities which require them to freely move in environments containing both static and dynamic obstacles to accomplish given tasks. One of the most relevant capabilities in terms of navigating a mobile robot in such an environment is to find a safe path to a goal position. This paper shows that there exists an accurate solution to the Laplace equation which allows finding a collision-free path and that it can be efficiently calculated for a rectangular bounded domain such as a map which is represented as an image. This is accomplished by the use of the monogenic scale space resulting in a vector field which describes the attracting and repelling forces from the obstacles and the goal. The method is shown to work in reasonably convex domains and by the use of tessellation of the environment map for non-convex environments.


Title: Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization
Key Words: human-robot interaction  iterative methods  learning (artificial intelligence)  mobile robots  Pareto optimisation  path planning  nonlinear multiobjective optimization  socially assistive robots  complex environments  stochastic human environments  subtle social norms  socially-aware navigation  multiobjective optimization tool  PaC-cET  nonlinear human navigation behavior  autonomously-sensed distance-based features  social costs  finely-tuned linear combination  optimized future trajectory point  PaCcET-based trajectory planner  human-robot interaction community  Pareto concavity elimination transformation  model-based approaches  Navigation  Trajectory  Optimization  Robot sensing systems  Reinforcement learning 
Abstract: For socially assistive robots (SAR)to be accepted into complex and stochastic human environments, it is important to account for subtle social norms. In this paper, we propose a novel approach to socially-aware navigation (SAN)which garnered an immense interest in the Human-Robot Interaction (HRI)community. We use a multi-objective optimization tool called the Pareto Concavity Elimination Transformation (PaC-cET)to capture the non-linear human navigation behavior, a novel contribution to the community. A candidate point on a trajectory is scored (1)for its progress towards the goal, and (2)based on autonomously-sensed distance-based features that capture the social norms and associated social costs. Rather than use a finely-tuned linear combination of these costs, we use PaCcET to select an optimized future trajectory point, associated with a non-linear combination of the costs. Existing research in this domain concentrates on geometric reasoning, model-based, and learning approaches, which have their own pros and cons. This approach is distinct from prior work in this area. We showed in a simulation that the PaCcET-based trajectory planner not only is able to avoid collisions and reach the intended destination in static and dynamic environments but also considers a human's personal space i.e. rules of proxemics in the trajectory selection process.


Title: Bio-Inspired Design of a Gliding-Walking Multi-Modal Robot
Key Words: aerospace robotics  design engineering  legged locomotion  Pteromyini  multimodal robot gliding  multimodal robot walking  multimodal locomotion robot  regulated motor torques  robot design  flexible membrane  terrestrial locomotion  aerial locomotion  flying squirrel  bio-inspired design  Legged locomotion  Aerodynamics  Muscles  Drag  Stability analysis  Thermal stability 
Abstract: Versatile multi-modal robots are advantageous for their wider operational environments. By taking design principles from observation of Pteromyini, commonly known as the flying squirrel, which shows balanced performances in both aerial and terrestrial locomotion, a novel robotic platform with the ability of gliding and walking is designed. The flexible membrane and gliding method of Pteromyini have been applied to the robot design. The legs of the robot were optimized to perform with regulated motor torques in both walking and gliding. The robot glided with an average gliding ratio of 1.88 and controlled its angle-of-attack for slowing down to land safely. The robot was able to walk utilizing different gait patterns. These results demonstrated our robot's balanced multi-modal locomotion of gliding and walking.


Title: Learning and Generation of Actions from Teleoperation for Domestic Service Robots*This work was supported by JST, CREST
Key Words: Gaussian processes  hidden Markov models  home automation  intelligent robots  mobile robots  motion control  service robots  telerobotics  autonomous household chores  body motions  object-dependent Gaussian process  domestic household chores  domestic service robots  motion primitives  teleoperation  motion learning  reference-point Gaussian process  hidden semiMarkov model  Task analysis  Trajectory  Motion segmentation  Service robots  End effectors 
Abstract: In this paper, we propose a method for motion learning aimed at the execution of autonomous household chores by service robots in real environments. For robots to act autonomously in a real environment, it is necessary to define the appropriate actions for the environment. However, it is difficult to define these actions manually. Therefore, body motions that are common to multiple actions are defined as motion primitives. Complex actions can then be learned by combining these motion primitives. For learning motion primitives, we propose a reference-point and object-dependent Gaussian process hidden semi-Markov model (RPOD-GP-HSMM). For verification, a robot is teleoperated to perform the actions included in several domestic household chores. The robot then learns the associated motion primitives from the robot's body information and object information.


Title: Planning Topological Navigation for Complex Indoor Environments
Key Words: humanoid robots  mobile robots  multi-robot systems  planning (artificial intelligence)  artificial intelligence planning  topological navigation planning  symbolic representation  European Robotics League  humanoid robot Pepper  high level acting  high level reasoning  mobile robot  complex indoor environments  Navigation  Planning  Task analysis  Measurement  Robot kinematics  Indoor environments 
Abstract: The ability to move around the environment is one of the most important capabilities of a mobile robot. Although navigation is considered an already achieved capacity, there is still much work to be done to integrate navigation with high level reasoning and acting. Navigate in indoor environments also involve complex actions, such as opening doors, use elevators, and many others. We propose a topological navigation system based on Artificial Intelligence (AI) Planning. Starting from a symbolic representation of the environment, navigation tasks are divided into phases, in which different actions are required. This approach has demonstrated to be very effective to plan the operations of a robot at indoor environments. The final result is method compact, efficient and scalable. Our system has been successfully tested at European Robotics League in the humanoid robot Pepper.


Title: Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks
Key Words: autonomous aerial vehicles  autonomous underwater vehicles  control engineering computing  public domain software  software packages  specification languages  unmanned aerial vehicles  task orchestration language  autonomous vehicle networks  extensible programming language  Dolphin program  orchestrated execution  multiple vehicles  one-vehicle tasks  event-based task flow  Dolphin language  autonomous vehicles  unmanned underwater vehicles  Groovy DSL  software packages  robotic toolkits  open-source toolchain  Task analysis  Dolphins  DSL  Autonomous vehicles  Engines  Runtime  Java 
Abstract: We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).


Title: GPU-Accelerated Next-Best-View Coverage of Articulated Scenes
Key Words: embedded systems  graphics processing units  mobile robots  path planning  rendering (computer graphics)  robot vision  costmap computation  path planning  simulation  viewpoint candidates  multiple device classes  multiGPU servers  utility map  robots  complex articulated scenes  GPU-accelerated next-best-view coverage  next-best-view algorithms  mapping tasks  articulated environments  obstructed areas  degrees of freedom  embedded devices  next-best-view approach  embedded systems  graphics processing units  OpenGL  Graphics processing units  Task analysis  Cameras  Robot sensing systems  Planning  Solid modeling 
Abstract: Next-best-view algorithms are commonly used for covering known scenes, for example in search, maintenance, and mapping tasks. In this paper, we consider the problem of planning a strategy for covering articulated environments where the robot also has to manipulate objects to inspect obstructed areas. This problem is particularly challenging due to the many degrees of freedom resulting from the articulation. We propose to exploit graphics processing units present in many embedded devices to parallelize the computations of a greedy next-best-view approach. We implemented algorithms for costmap computation, path planning, as well as simulation and evaluation of viewpoint candidates in OpenGL for Embedded Systems and benchmarked the implementations on multiple device classes ranging from smartphones to multi-GPU servers. We introduce a heuristic for estimating a utility map from images rendered with strategically placed spherical cameras and show in simulation experiments that robots can successfully explore complex articulated scenes with our system.


Title: CROC: Convex Resolution of Centroidal Dynamics Trajectories to Provide a Feasibility Criterion for the Multi Contact Planning Problem
Key Words: approximation theory  computational geometry  legged locomotion  linear programming  motion control  path planning  sampling methods  trajectory control  CROC  feasibility criterion  multicontact planning problem  transition feasibility problem  legged robot  conservative reformulation  convex reformulation  Bezier curve  transition problem  sampling-based contact planner  motion generation methods  center of mass trajectory  convex resolution of centroidal dynamics trajectories  free control point  contact sequences  motion synthesis problems  linear program  Trajectory  Dynamics  Planning  Acceleration  Legged locomotion  Kinematics 
Abstract: We tackle the transition feasibility problem, that is the issue of determining whether there exists a feasible motion connecting two configurations of a legged robot. To achieve this we introduce CROC, a novel method for computing centroidal dynamics trajectories in multi-contact planning contexts. Our approach is based on a conservative and convex reformulation of the problem, where we represent the center of mass trajectory as a Bezier curve comprising a single free control point as a variable. Under this formulation, the transition problem is solved efficiently with a Linear Program (LP)of low dimension. We use this LP as a feasibility criterion, incorporated in a sampling-based contact planner, to discard efficiently unfeasible contact plans. We are thus able to produce robust contact sequences, likely to define feasible motion synthesis problems. We illustrate this application on various multi-contact scenarios featuring HRP2 and HyQ. We also show that we can use CROC to compute valuable initial guesses, used to warm-start non-linear solvers for motion generation methods. This method could also be used for the 0 and 1-Step capturability problem. The source code of CROC is available under an open source BSD-2 License.


Title: Towards a Context Enhanced Framework for Multi Object Tracking in Human Robot Collaboration
Key Words: human-robot interaction  manipulators  object detection  object tracking  robot vision  uninterrupted completion  functional accuracy  multiple objects  HRC setting  robust object tracker  functional role  object tacker  robotic manipulation  HRC assembly process  multiobject tracking  goal-oriented human robot collaborative scenario  context enhanced framework  Robot kinematics  Cognition  Task analysis  Object tracking  Three-dimensional displays 
Abstract: In a goal-oriented Human Robot Collaborative (HRC) scenario, where the goal is to complete an assembly process, a robust object tracker might not necessarily fulfill its functional role due to the dynamic nature of HRC. Moreover, for an efficient HRC, the functional role of the object tacker should not only be limited to localizing and tracking objects for robotic manipulation. It should also help to determine the current state of the assembly process and verify if the chosen action has been successfully performed and thus to enable an uninterrupted completion of an HRC assembly process. We present a Context Enhanced Framework for Multi Object Tracking, that i) allows uninterrupted completion of an assembly process, ii) improves the overall functional accuracy of the object tracker from 49 percent to 96 percent, and iii) enables the object tracker to handle multiple instance of multiple objects in a HRC setting.


Title: Motion Planning for a UAV with a Straight or Kinked Tether
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  motion control  multi-robot systems  robot vision  confined environment  cluttered environment  tethered aerial vehicles  tethered agent  nonfree space  motion planning frameworks  motion planning strategies  motion planning algorithms  UAV  robotic locomotion  reachable configuration space  marsupial heterogeneous robotic teams  Fotokite Pro  Planning  Visualization  Casting  Cameras  Robot sensing systems  Unmanned aerial vehicles 
Abstract: This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.


Title: Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots
Key Words: aerospace robotics  integer programming  linear programming  multi-robot systems  path planning  tree searching  terrain  persistent monitoring  heterogeneous team  aerial robots  ground robots  MILP formulation  branch-and-cut framework  separation algorithm  Fuels  Monitoring  Unmanned aerial vehicles  Routing  Robot sensing systems  Kernel 
Abstract: There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.


Title: A Mobility Model Based on Improved Artificial Potential Fields for Swarms of UAVs
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  path planning  remotely operated vehicles  information sharing  path planning  obstacles avoidance  mobility model  swarms  UAV  involved UAVs collaborate  mobility strategies  autonomous UAVs  collaborative tasks  multiple platforms  artificial potential fields principle  APF principle  Path planning  Sensors  Adaptation models  Collaboration  Task analysis  Laser radar  Collision avoidance 
Abstract: A combination of several autonomous UAVs can be used to perform collaborative tasks. Such a combination is referred to as a swarm of drones. The use of multiple platforms can extend the system global capacities thanks to the resulting variety of embedded sensors and to information sharing. In this case, path planning and thus obstacles avoidance is still a major task. To deal with this issue, mobility models have to be implemented. Our contribution presented in this paper is a mobility model for swarms of UAVs based on the Artificial Potential Fields (APF) principle. In our model, the involved UAVs collaborate by sharing data about the obstacles that they detected. By doing so, a UAV which is not close enough to an obstacle to detect it thanks to its own sensors will still have the proper data to take this obstacle into account in its path planning. To validate our mobility strategies with realistic constraints we simulate the performances of existing sensors and transmitters, and consider real-world environment.


Title: UAV/UGV Search and Capture of Goal-Oriented Uncertain Targets*This research was supported in part by ISF grant #1337/15 and part by a grant from MOST, Israel and the JST Japan
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  optimisation  probability  remotely operated vehicles  UAV/UGV collaborative efforts  stochastic-temporal belief  attacker capture  defender real-time algorithmic framework  probability optimization  goal-oriented uncertain targets  UAV/UGV search  Games  Uncertainty  Search problems  Real-time systems  Task analysis  Mathematical model  Roads 
Abstract: This paper considers a new, complex problem of UAV/UGV collaborative efforts to search and capture attackers under uncertainty. The goal of the defenders (UAV/UGV team) is to stop all attackers as quickly as possible, before they arrive at their selected goal. The uncertainty considered is twofold: the defenders do not know the attackers' location and destination, and there is also uncertainty in the defenders' sensing. We suggest a real-time algorithmic framework for the defenders, combining entropy and stochastic-temporal belief, that aims at optimizing the probability of a quick and successful capture of all of the attackers. We have empirically evaluated the algorithmic framework, and have shown its efficiency and significant performance improvement compared to other solutions.


Title: Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks
Key Words: control engineering computing  human-robot interaction  recurrent neural nets  proactive robot assistants  freeform collaborative tasks  multimodal recognition  generic subtasks  successful human-robot collaboration  shared understanding  current goals  nonlinear tasks  freeform tasks  explicit task model  robot partners  meaningful task knowledge  multimodal recurrent neural networks  short-term memory units  real-time subtask recognition  context-aware assistance  generic assembly tasks  specific subtasks  individual modalities  high-level representations  nonlinear connection layer  multimodal subtask recognition system  predictive assistance  human partner  human-robot team  assembly task  similar subtasks  freeform assembly scenario  RNN  Task analysis  Robot kinematics  Fasteners  Feature extraction  Activity recognition  Recurrent neural networks 
Abstract: Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.


Title: Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System
Key Words: human computer interaction  human-robot interaction  interactive systems  learning (artificial intelligence)  robot programming  linear decay system  seamless learning  multimodal robot apprenticeship  imitation learning  linearly decayed DMP  human-robot dialogue system  robot learning  robots  single demonstration modality  multimodal learning approach  natural interaction modalities  Task analysis  Trajectory  Ontologies  Convergence  Robot learning  Kernel 
Abstract: Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.


Title: Improving Trajectory Optimization Using a Roadmap Framework
Key Words: mobile robots  optimisation  path planning  sampling methods  trajectory control  trajectory optimization process  sampling-based planners  motion planning system  multiquery roadmap  sparse roadmap framework  optimization-based motion planners  Planning  Trajectory optimization  Robots  Dynamics  Task analysis  Collision avoidance 
Abstract: We present an evaluation of several representative sampling-based and optimization-based motion planners, and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimization into a sparse roadmap framework. Through experiments in 4 common application scenarios with 5000 test cases each, we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge, this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art motion planners, which are based on a significant amount of experiments. We then combine different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior performance over other standard sampling-based planners' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem, our approach allows for extensions such as persistent control policy information associated with a trajectory across planning problems. Also, the sub-optimality resulting from the sparsity of roadmap, as well as the unexpected disturbances from the environment, can both be overcome by the real-time trajectory optimization process.


Title: A Novel Input Device for Robotic Prosthetic Hand: Design and Preliminary Results
Key Words: biomechanics  biomedical electrodes  electromyography  medical robotics  medical signal processing  multilayer perceptrons  prosthetics  signal classification  medical electrodiagnostic techniques  EMG signal  impedance change  skin  noncontact manner  hand movements  novel input device  robotic prosthetic hand  capacitance change  data processing  deformation  electrode  sensor  multilayer perceptron  classification success rates  Skin  Electrodes  Capacitance  Muscles  Robot sensing systems  Electromyography  Input devices 
Abstract: In this paper, we propose a novel input device for a robotic prosthetic hand based on capacitance change. The proposed device can sense the deformation of the skin due to the activity of the muscle by measuring the capacitance change between the skin and the electrode. Therefore, it can be used as a sensor for estimating a user's intention through medical electrodiagnostic techniques such as electromyogram (EMG)and force myography (FMG). The proposed device can acquire data in a non-invasive way and is advantageous with easier data processing than that for an EMG signal. Moreover, it is resistant to the impedance change of skin because the capacitance is measured in a non-contact manner, unlike the existing methods which work with direct contact with the skin such as EMG. Additionally, unlike FMG, the device is lightly attached to the skin without being strongly fixed with velcro, which offsets problems that occur while re-wearing the device. To demonstrate the feasibility of the proposed idea, three of the newly developed input devices were used to classify four hand movements (fist, scissors, paper, and rest)using a multilayer perceptron (MLP). As a result, the classification success rates for the fist, paper, scissor, and rest motions were obtained as 99.3%, 98.3%, 98.4%, and 99.1%, respectively.


