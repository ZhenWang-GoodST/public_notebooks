TY  - CONF
TI  - [Front cover]
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 1
PY  - 2018
DO  - 10.1109/IROS.2018.8593956
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents the front cover or splash screen of the proceedings record.
ER  - 

TY  - CONF
TI  - Program at a Glance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4
EP  - 4
PY  - 2018
DO  - 10.1109/IROS.2018.8594269
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides a schedule of conference events and a listing of which papers were presented in each session.
ER  - 

TY  - CONF
TI  - Welcome message
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 11
EP  - 12
PY  - 2018
DO  - 10.1109/IROS.2018.8593673
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
ER  - 

TY  - CONF
TI  - 3. Conference Application
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6
EP  - 10
PY  - 2018
DO  - 10.1109/IROS.2018.8594286
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - IROS 2018 Proceedings will be given in electronic iProceeding or eProceeding format, based on availability, to every full-registered person in the conference.
ER  - 

TY  - CONF
TI  - Organizing Committee
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 13
EP  - 21
PY  - 2018
DO  - 10.1109/IROS.2018.8594191
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides a listing of current committee members and society officers.
ER  - 

TY  - CONF
TI  - About Madrid
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 26
EP  - 32
PY  - 2018
DO  - 10.1109/IROS.2018.8593784
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents information on the conference venue.
ER  - 

TY  - CONF
TI  - Sponsors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 33
EP  - 37
PY  - 2018
DO  - 10.1109/IROS.2018.8593949
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The conference organizers greatly appreciate the support of the various corporate sponsors listed.
ER  - 

TY  - CONF
TI  - Plenary sessions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 38
EP  - 54
PY  - 2018
KW  - Artificial intelligence
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Collaboration
KW  - Biographies
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594490
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides an abstract for each of the plenary presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
ER  - 

TY  - CONF
TI  - Forums
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 55
EP  - 65
PY  - 2018
KW  - Service robots
KW  - Artificial intelligence
KW  - Companies
KW  - Europe
KW  - Smart cities
DO  - 10.1109/IROS.2018.8594044
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides an abstract for each of the Forum presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
ER  - 

TY  - CONF
TI  - Workshops
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 68
EP  - 90
PY  - 2018
KW  - Conferences
KW  - Service robots
KW  - Diseases
KW  - Task analysis
KW  - Grasping
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593620
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides an abstract for each of the workshop presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
ER  - 

TY  - CONF
TI  - IROS 2018 Technical Program
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 12
PY  - 2018
DO  - 10.1109/IROS.2018.8593782
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Provides a schedule of conference events and a listing of which papers were presented in each session.
ER  - 

TY  - CONF
TI  - Content List
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 118
PY  - 2018
DO  - 10.1109/IROS.2018.8593802
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents the table of contents/splash page of the proceedings record.
ER  - 

TY  - CONF
TI  - IROS 2018 Author Index
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 41
PY  - 2018
DO  - 10.1109/IROS.2018.8594323
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents an index of the authors whose articles are published in the conference proceedings record.
ER  - 

TY  - CONF
TI  - Index of papers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 31
PY  - 2018
DO  - 10.1109/IROS.2018.8593509
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Presents the table of contents/splash page of the proceedings record.
ER  - 

TY  - CONF
TI  - Real-time Convolutional Networks for Depth-based Human Pose Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 41
EP  - 47
AU  - A. Martínez-González
AU  - M. Villamizar
AU  - O. Canévet
AU  - J. Odobez
PY  - 2018
KW  - convolutional neural nets
KW  - feature extraction
KW  - human-robot interaction
KW  - image colour analysis
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - convolutional neural networks models
KW  - human robot interaction
KW  - depth-based human pose estimation
KW  - pose inference
KW  - residual blocks
KW  - body landmark localization
KW  - depth imaging
KW  - human bodies
KW  - human detection
KW  - RGB images
KW  - Feature extraction
KW  - Pose estimation
KW  - Computational modeling
KW  - Three-dimensional displays
KW  - Shape
KW  - Detectors
KW  - Cameras
DO  - 10.1109/IROS.2018.8593383
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose to combine recent Convolutional Neural Networks (CNN) models with depth imaging to obtain a reliable and fast multi-person pose estimation algorithm applicable to Human Robot Interaction (HRI) scenarios. Our hypothesis is that depth images contain less structures and are easier to process than RGB images while keeping the required information for human detection and pose inference, thus allowing the use of simpler networks for the task. Our contributions are threefold. (i) we propose a fast and efficient network based on residual blocks (called RPM) for body landmark localization from depth images; (ii) we created a public dataset DIH comprising more than 170k synthetic images of human bodies with various shapes and viewpoints as well as real (annotated) data for evaluation; (iii) we show that our model trained on synthetic data from scratch can perform well on real data, obtaining similar results to larger models initialized with pre-trained networks. It thus provides a good trade-off between performance and computation. Experiments on real data demonstrate the validity of our approach.
ER  - 

TY  - CONF
TI  - Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 48
EP  - 53
AU  - S. Breuers
AU  - L. Beyer
AU  - U. Rafi
AU  - B. Leibel
PY  - 2018
KW  - feature extraction
KW  - human-robot interaction
KW  - image filtering
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - DetTA pipeline
KW  - people detection
KW  - dynamic information
KW  - social robot-person interaction
KW  - fully modular detection-tracking-analysis pipeline
KW  - temporal filtering
KW  - person attribute
KW  - track ID
KW  - person analysis
KW  - GPU-memory
KW  - power consumption
KW  - head pose
KW  - skeleton pose
KW  - deep learning methods
KW  - Robots
KW  - Pipelines
KW  - Skeleton
KW  - Head
KW  - Estimation
KW  - Detectors
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594335
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.
ER  - 

TY  - CONF
TI  - 3D Human Pose Estimation on a Configurable Bed from a Pressure Image
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 54
EP  - 61
AU  - H. M. Clever
AU  - A. Kapusta
AU  - D. Park
AU  - Z. Erickson
AU  - Y. Chitalia
AU  - C. C. Kemp
PY  - 2018
KW  - convolutional neural nets
KW  - manipulators
KW  - Monte Carlo methods
KW  - pose estimation
KW  - stereo image processing
KW  - single pressure image
KW  - convolutional neural networks
KW  - flat beds
KW  - pressure-sensing mat
KW  - bedding materials
KW  - robots
KW  - configurable bed
KW  - 3D human pose estimation
KW  - estimated kinematic model
KW  - pressure mat
KW  - mean joint position error
KW  - bed configurations
KW  - limb lengths
KW  - 3D joint positions
KW  - size 77.0 mm
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Kinematics
KW  - Skeleton
KW  - Robot sensing systems
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593545
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots have the potential to assist people in bed, such as in healthcare settings, yet bedding materials like sheets and blankets can make observation of the human body difficult for robots. A pressure-sensing mat on a bed can provide pressure images that are relatively insensitive to bedding materials. However, prior work on estimating human pose from pressure images has been restricted to 2D pose estimates and flat beds. In this work, we present two convolutional neural networks to estimate the 3D joint positions of a person in a configurable bed from a single pressure image. The first network directly outputs 3D joint positions, while the second outputs a kinematic model that includes estimated joint angles and limb lengths. We evaluated our networks on data from 17 human participants with two bed configurations: supine and seated. Our networks achieved a mean joint position error of 77 mm when tested with data from people outside the training set, outperforming several baselines. We also present a simple mechanical model that provides insight into ambiguity associated with limbs raised off of the pressure mat, and demonstrate that Monte Carlo dropout can be used to estimate pose confidence in these situations. Finally, we provide a demonstration in which a mobile manipulator uses our network's estimated kinematic model to reach a location on a person's body in spite of the person being seated in a bed and covered by a blanket.
ER  - 

TY  - CONF
TI  - Estimating Metric Poses of Dynamic Objects Using Monocular Visual-Inertial Fusion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 62
EP  - 68
AU  - K. Qiu
AU  - T. Qin
AU  - H. Xie
AU  - S. Shen
PY  - 2018
KW  - augmented reality
KW  - cameras
KW  - feature extraction
KW  - image fusion
KW  - image sequences
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - state estimation
KW  - metric pose estimation
KW  - state estimation
KW  - 3D tracking performance
KW  - tracking accuracy
KW  - correlation analysis-based metric scale estimator
KW  - 2D object tracker
KW  - monocular camera
KW  - visual-inertial system
KW  - monocular sensing suite
KW  - scale observability
KW  - fixed multicamera
KW  - visual-inertial tracking system
KW  - arbitrary dynamic object
KW  - monocular 3D object tracking system
KW  - monocular visual-inertial fusion
KW  - dynamic objects
KW  - Cameras
KW  - Three-dimensional displays
KW  - Visualization
KW  - Estimation
KW  - Two dimensional displays
KW  - Tracking
DO  - 10.1109/IROS.2018.8593748
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A monocular 3D object tracking system generally has only up-to-scale pose estimation results without any prior knowledge of the tracked object. In this paper, we propose a novel idea to recover the metric scale of an arbitrary dynamic object by optimizing the trajectory of the objects in the world frame, without motion assumptions. By introducing an additional constraint in the time domain, our monocular visual-inertial tracking system can obtain continuous six degree of freedom (6-DoF) pose estimation without scale ambiguity. Our method requires neither fixed multi-camera nor depth sensor settings for scale observability, instead, the IMU inside the monocular sensing suite provides scale information for both camera itself and the tracked object. We build the proposed system on top of our monocular visual-inertial system (VINS) to obtain accurate state estimation of the monocular camera in the world frame. The whole system consists of a 2D object tracker, an object region-based visual bundle adjustment (BA), VINS and a correlation analysis-based metric scale estimator. Experimental comparisons with ground truth demonstrate the tracking accuracy of our 3D tracking performance while a mobile augmented reality (AR) demo shows the feasibility of potential applications.
ER  - 

TY  - CONF
TI  - Geometric-based Line Segment Tracking for HDR Stereo Sequences
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 69
EP  - 74
AU  - R. Gomez-Ojeda
AU  - J. Gonzalez-Jimenez
PY  - 2018
KW  - compressed sensing
KW  - convex programming
KW  - image matching
KW  - image segmentation
KW  - image sequences
KW  - stereo image processing
KW  - video signal processing
KW  - robust tracking
KW  - art techniques
KW  - appearance-based methods
KW  - High Dynamic Range environments
KW  - HDR stereo sequences
KW  - geometric-based line segment tracking
KW  - stereo streams
KW  - appearance-based matching techniques
KW  - video sequences
KW  - Image segmentation
KW  - Lighting
KW  - Tracking
KW  - Feature extraction
KW  - Video sequences
KW  - Motion segmentation
KW  - Simultaneous localization and mapping
DO  - 10.1109/IROS.2018.8593646
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we propose a purely geometrical approach for the robust matching of line segments for challenging stereo streams with severe illumination changes or High Dynamic Range (HDR) environments. To that purpose, we exploit the univocal nature of the matching problem, i.e. every observation must be corresponded with a single feature or not corresponded at all. We state the problem as a sparse, convex, ℓ1-minimization of the matching vector regularized by the geometric constraints. This formulation allows for the robust tracking of line segments along sequences where traditional appearance-based matching techniques tend to fail due to dynamic changes in illumination conditions. Moreover, the proposed matching algorithm also results in a considerable speed-up of previous state of the art techniques making it suitable for real-time applications such as Visual Odometry (VO). This, of course, comes at expense of a slightly lower number of matches in comparison with appearance-based methods, and also limits its application to continuous video sequences, as it is rather constrained to small pose increments between consecutive frames. We validate the claimed advantages by first evaluating the matching performance in challenging video sequences, and then testing the method in a benchmarked point and line based VO algorithm.
ER  - 

TY  - CONF
TI  - Adversarial Transfer Networks for Visual Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 75
EP  - 81
AU  - L. Liu
AU  - J. Lu
AU  - J. Zhou
PY  - 2018
KW  - learning (artificial intelligence)
KW  - object tracking
KW  - video signal processing
KW  - visual tracking
KW  - domain-specific information
KW  - target-domain samples
KW  - adversarial transfer networks
KW  - unmanned systems
KW  - offline video training data
KW  - ATNet
KW  - source-domain samples
KW  - adversarial transfer learning
KW  - Target tracking
KW  - Videos
KW  - Training
KW  - Visualization
KW  - Task analysis
KW  - Feature extraction
KW  - Learning systems
DO  - 10.1109/IROS.2018.8593585
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual tracking plays an important role in unmanned systems. In many cases, the system needs to keep track of targets it has never seen before, and the only training sample available is the specified object in the initial frame. In this paper, we propose a deep architecture called adversarial transfer networks (ATNet), which aims to make well use of offline video training data and solve the problem of lacking training samples in visual tracking. Different from most existing trackers which neglect significant differences between videos and gulp the training data all together, our method utilizes the special nature of tracking problem and concentrates on transferring domain-specific information across similar tracking tasks. We first propose an efficient way to select a training video that is most similar to online tracking task and regard it as source domain. With the labeled data in the selected source domain, we apply adversarial transfer learning to make the feature distribution of source-domain samples and target-domain samples as similar as possible. Therefore, the transferred source-domain samples can provide various possible appearance of tracked target for training and boost the tracking performance. Experimental results on three OTB tracking benchmarks show that our method outperforms the state-of-the-art trackers in both accuracy and robustness.
ER  - 

TY  - CONF
TI  - Predicting Out-of-View Feature Points for Model-Based Camera Pose Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 82
EP  - 88
AU  - O. Moolan-Feroze
AU  - A. Calway
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - inspection
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object tracking
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - recurrent neural nets
KW  - rich feature information
KW  - recurrent neural network architecture
KW  - network training
KW  - autonomous inspection robots
KW  - model-based tracking
KW  - input image
KW  - object feature points
KW  - deep learning
KW  - model-based camera pose estimation
KW  - out-of-view feature points
KW  - optimisation based tracker
KW  - Cameras
KW  - Heating systems
KW  - Feature extraction
KW  - Pose estimation
KW  - Computational modeling
KW  - Two dimensional displays
KW  - Predictive models
DO  - 10.1109/IROS.2018.8594297
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we present a novel framework that uses deep learning to predict object feature points that are out-of-view in the input image. This system was developed with the application of model-based tracking in mind, particularly in the case of autonomous inspection robots, where only partial views of the object are available. Out-of-view prediction is enabled by applying scaling to the feature point labels during network training. This is combined with a recurrent neural network architecture designed to provide the final prediction layers with rich feature information from across the spatial extent of the input image. To show the versatility of these out-of-view predictions, we describe how to integrate them in both a particle filter tracker and an optimisation based tracker. To evaluate our work we compared our framework with one that predicts only points inside the image. We show that as the amount of the object in view decreases, being able to predict outside the image bounds adds robustness to the final pose estimation.
ER  - 

TY  - CONF
TI  - A modular framework for model-based visual tracking using edge, texture and depth features
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 89
EP  - 96
AU  - S. Trinh
AU  - F. Spindler
AU  - E. Marchand
AU  - F. Chaumette
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image sensors
KW  - object tracking
KW  - modular framework
KW  - confidence index
KW  - multiple vision sensors
KW  - depth map
KW  - textured points
KW  - edge points
KW  - real-time model-based visual tracker
KW  - depth features
KW  - model-based visual tracking using edge
KW  - Cameras
KW  - Visualization
KW  - Solid modeling
KW  - Image edge detection
KW  - Three-dimensional displays
KW  - Sensors
KW  - Robustness
DO  - 10.1109/IROS.2018.8594003
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present in this paper a modular real-time model-based visual tracker. It is able to fuse different types of measurement, that is, edge points, textured points, and depth map, provided by one or multiple vision sensors. A confidence index is also proposed for determining if the outputs of the tracker are reliable or not. As expected, experimental results show that the more various measurements are combined, the more accurate and robust is the tracker. The corresponding C++ source code is available for the community in the ViSP library.
ER  - 

TY  - CONF
TI  - FSG: A statistical approach to line detection via fast segments grouping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 97
EP  - 102
AU  - I. Suárez
AU  - E. Muñoz
AU  - J. M. Buenaposada
AU  - L. Baumela
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - robot vision
KW  - fast segments grouping
KW  - line segment detection algorithms
KW  - segment grouping methods
KW  - vanishing points detection
KW  - statistical approach
KW  - high level robot localization task
KW  - plausible line candidates
KW  - robust line detection algorithm
KW  - FSG
KW  - low textured scenes
KW  - visual robotic tasks
KW  - line extraction
KW  - Image segmentation
KW  - Probabilistic logic
KW  - Estimation
KW  - Simultaneous localization and mapping
KW  - Task analysis
KW  - Detection algorithms
DO  - 10.1109/IROS.2018.8594434
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Line extraction is a preliminary step in various visual robotic tasks performed in low textured scenes such as city and indoor settings. Several efficient line segment detection algorithms such as LSD and EDLines have recently emerged. However, the state of the art segment grouping methods are not robust enough or not amenable for detecting lines in real-time. In this paper we present FSG, a fast and robust line detection algorithm. It is based on two independent components. A proposer that greedily cluster segments suggesting plausible line candidates and a probabilistic model that decides if a group of segments is an actual line. In the experiments we show that our procedure is more robust and faster than the best methods in the literature and achieves state-of-the art performance in a high level robot localization task such as vanishing points detection.
ER  - 

TY  - CONF
TI  - Optimized Contrast Enhancements to Improve Robustness of Visual Tracking in a SLAM Relocalisation Context
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 103
EP  - 108
AU  - X. Wang
AU  - M. Christie
AU  - E. Marchand
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image colour analysis
KW  - image enhancement
KW  - image representation
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - optimized contrast enhancements
KW  - visual tracking
KW  - SLAM relocalisation context
KW  - indirect SLAM techniques
KW  - robotics community
KW  - feature points
KW  - multilayered image representation
KW  - contrast enhanced version
KW  - tracking process
KW  - detection
KW  - matching
KW  - dynamic contrast enhancements
KW  - dynamic light changing conditions
KW  - ORB-SLAM
KW  - light changed condition
KW  - reference video
KW  - Mutual information
KW  - Lighting
KW  - Robustness
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Entropy
KW  - Visualization
DO  - 10.1109/IROS.2018.8593366
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robustness of indirect SLAM techniques to light changing conditions remains a central issue in the robotics community. With the change in the illumination of a scene, feature points are either not extracted properly due to low contrasts, or not matched due to large differences in descriptors. In this paper, we propose a multi-layered image representation (MLI) in which each layer holds a contrast enhanced version of the current image in the tracking process in order to improve detection and matching. We show how Mutual Information can be used to compute dynamic contrast enhancements on each layer. We demonstrate how this approach dramatically improves the robustness in dynamic light changing conditions on both synthetic and real environments compared to default ORB-SLAM. This work focalises on the specific case of SLAM relocalisation in which a first pass on a reference video constructs a map, and a second pass with a light changed condition relocalizes the camera in the map.
ER  - 

TY  - CONF
TI  - Key-frame Selection for Multi-robot Simultaneous Localization and Tracking in Robot Soccer Field
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 109
EP  - 116
AU  - W. Fu
AU  - K. Lin
AU  - C. Shih
PY  - 2018
KW  - entropy
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - SLAM (robots)
KW  - traditional key-frame selection algorithms
KW  - temporal relationship
KW  - spatial relationship
KW  - pre-defined field
KW  - information entropy
KW  - selection ratio
KW  - key-frames
KW  - localization results
KW  - robot soccer field
KW  - optical images
KW  - extensive computation resources
KW  - key-frame selection algorithm
KW  - multiple robots simultaneous localization
KW  - multirobot soccer games
KW  - Entropy
KW  - Robot sensing systems
KW  - Object detection
KW  - Sports
KW  - Cameras
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8593785
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Optical images provide rich features but require extensive computation resources to process for SLAM. When there are limited computation resources on the robots, it becomes a heavy burden to process the images in real-time. This paper presents the design and implementation of key-frame selection algorithm for multiple robots simultaneous localization and tracking on the multi-robot soccer games which have pre-defined field and objects. Compared to traditional key-frame selection algorithms, this work makes use of the temporal and spatial relationship among objects on the pre-defined field to compute the information entropy. The selection ratio can be adjusted by two parameters: entropy threshold and the maximum moving distance. The experimental results show that the developed method can effectively detect the change of scene using selected key-frames. And comparing with the localization results using all the images, using less than 20% of all images after walking 11,203mm it only increase up to 0.87% trajectory errors.
ER  - 

TY  - CONF
TI  - Weighted Total Least Squares based Online Calibration Method for RSS based Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 117
EP  - 122
AU  - J. Kim
AU  - D. Kim
PY  - 2018
KW  - calibration
KW  - distance measurement
KW  - error compensation
KW  - least squares approximations
KW  - regression analysis
KW  - linear regression model
KW  - partial input elements
KW  - weighted total least squares techniques
KW  - WTLS techniques
KW  - received signal strength based localization algorithm
KW  - RSS-to-distance based localization algorithm
KW  - improved online model-based calibration approach
KW  - distance estimation
KW  - error compensation
KW  - Calibration
KW  - Linear regression
KW  - Estimation
KW  - Shadow mapping
KW  - Measurement uncertainty
KW  - Taylor series
KW  - Convergence
DO  - 10.1109/IROS.2018.8594416
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the received signal strength (RSS) based localization, a model-based calibration approach has been usually done by relating RSS-to-distance among anchor nodes. In this paper, an improved calibration method is proposed. For that purpose, RSS and estimated distance between any pairs of an-chor/unknown nodes is considered under the linear regression model. Unfortunately in this model, partial input elements are erroneous due to the inaccurate localization of unknown nodes. To obtain its solution under consideration of such an error, the weighted total least squares (WTLS) techniques are employed here. With the help of the WTLS techniques, several errors involved in the model can be effectively compensated. To show the efficiency of the proposed calibration, it is combined with several localization algorithms and its performance is verified by various simulations. The results show that the proposed calibration can give a very similar localization performance to that of each localization algorithm when true model parameters are known.
ER  - 

TY  - CONF
TI  - LIPS: LiDAR-Inertial 3D Plane SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 123
EP  - 130
AU  - P. Geneva
AU  - K. Eckenhoff
AU  - Y. Yang
AU  - G. Huang
PY  - 2018
KW  - graph theory
KW  - image representation
KW  - mobile robots
KW  - optical radar
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - inertial preintegratation measurement
KW  - LiDAR-inertial 3D plane SLAM
KW  - simultaneous localization and mapping
KW  - singularity free plane factor
KW  - closest point plane representation
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Optimization
KW  - Lips
DO  - 10.1109/IROS.2018.8594463
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the formalization of the closest point plane representation and an analysis of its incorporation in 3D indoor simultaneous localization and mapping (SLAM). We present a singularity free plane factor leveraging the closest point plane representation, and demonstrate its fusion with inertial preintegratation measurements in a graph-based optimization framework. The resulting LiDAR-inertial 3D plane SLAM (LIPS) system is validated both on a custom made LiDAR simulator and on a real-world experiment.
ER  - 

TY  - CONF
TI  - Scan Similarity-based Pose Graph Construction method for Graph SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 131
EP  - 136
AU  - W. Yoo
AU  - H. Kim
AU  - H. Hong
AU  - B. H. Lee
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - scan similarity-based pose graph construction method
KW  - constructed graph
KW  - loop closure detection method
KW  - real world dataset
KW  - benchmark dataset
KW  - odometry estimation process
KW  - error accumulation phenomenon
KW  - pose graph SLAM
KW  - scan similarity computation method
KW  - graph accuracy
KW  - high quality graph
KW  - Simultaneous localization and mapping
KW  - Lasers
KW  - Estimation
KW  - Heuristic algorithms
KW  - Optimization
DO  - 10.1109/IROS.2018.8593605
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Scan similarity-based pose graph construction method for graph SLAM is proposed. To perform delicate pose graph SLAM, front-end that constructs a graph as well as back-end that optimizes the constructed graph is an important task. Generally, there is an error accumulation phenomenon during the odometry estimation process. This paper focuses on the method of creating a high quality graph by suggesting ways to improve the graph accuracy since the accumulated errors in the graph might degrade the performance of the entire graph SLAM. We deal with one of our previous works, dynamic keyframe selection technique, based on scan similarity computation method more precisely and suggest a loop closure detection method by exploiting previously proposed 2-D laser scan descriptor. To verify objective performance of the proposed method, the experimental results of the odometry estimation are shown by using the benchmark dataset and the real world dataset. Additionally, results of the pose graph SLAM are shown for the real world dataset which include the loop clorues.
ER  - 

TY  - CONF
TI  - Egocentric Spatial Memory
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 137
EP  - 144
AU  - M. Zhang
AU  - K. T. Ma
AU  - S. Yen
AU  - J. H. Lim
AU  - Q. Zhao
AU  - J. Feng
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurophysiology
KW  - recurrent neural nets
KW  - robot vision
KW  - place recognition
KW  - robotic control
KW  - 3D virtual mazes
KW  - deep learning based mapping system
KW  - ESM network
KW  - external memory
KW  - recurrent neural network
KW  - spatially extended environment
KW  - 2D global maps
KW  - integrated deep neural network architecture
KW  - egocentric perspective
KW  - spatial information
KW  - memory system
KW  - egocentric spatial memory
KW  - Computer architecture
KW  - Cameras
KW  - Navigation
KW  - Microprocessors
KW  - Sensors
KW  - Task analysis
KW  - Motion measurement
DO  - 10.1109/IROS.2018.8593435
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Egocentric spatial memory (ESM) defines a memory system with encoding, storing, recognizing and recalling the spatial information about the environment from an egocentric perspective. We introduce an integrated deep neural network architecture for modeling ESM. It learns to estimate the occupancy state of the world and progressively construct top-down 2D global maps from egocentric views in a spatially extended environment. During the exploration, our proposed ESM model updates belief of the global map based on local observations using a recurrent neural network. It also augments the local mapping with a novel external memory to encode and store latent representations of the visited places over longterm exploration in large environments which enables agents to perform place recognition and hence, loop closure. Our proposed ESM network contributes in the following aspects: (1) without feature engineering, our model predicts free space based on egocentric views efficiently in an end-to-end manner; (2) different from other deep learning-based mapping system, ESMN deals with continuous actions and states which is vitally important for robotic control in real applications. In the experiments, we demonstrate its accurate and robust global mapping capacities in 3D virtual mazes and realistic indoor environments by comparing with several competitive baselines.
ER  - 

TY  - CONF
TI  - Predicting Objective Function Change in Pose-Graph Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 145
EP  - 152
AU  - F. Bai
AU  - T. Vidal-Calleja
AU  - S. Huang
AU  - R. Xiong
PY  - 2018
KW  - graph theory
KW  - optimisation
KW  - SLAM (robots)
KW  - outlier detection
KW  - robust online incremental SLAM applications
KW  - graph pruning
KW  - information-theoretic metrics
KW  - pose-graph optimization scheme
KW  - Linear programming
KW  - Optimization
KW  - Simultaneous localization and mapping
KW  - Measurement errors
KW  - Noise measurement
KW  - Reliability
DO  - 10.1109/IROS.2018.8594248
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust online incremental SLAM applications require metrics to evaluate the impact of current measurements. Despite its prevalence in graph pruning, information-theoretic metrics solely are insufficient to detect outliers. The optimal value of the objective function is a better choice to detect outliers but cannot be computed unless the problem is solved. In this paper, we show how the objective function change can be predicted in an incremental pose-graph optimization scheme, without actually solving the problem. The predicted objective function change can be used to guide online decisions or detect outliers. Experiments validate the accuracy of the predicted objective function, and an application to outlier detection is also provided, showing its advantages over M-estimators.
ER  - 

TY  - CONF
TI  - Efficient Long-term Mapping in Dynamic Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 153
EP  - 160
AU  - M. T. Lázaro
AU  - R. Capobianco
AU  - G. Grisetti
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - mapping problem
KW  - longterm SLAM datasets
KW  - graph coherency
KW  - intra-session loop closure detections
KW  - out-dated nodes
KW  - graph complexity
KW  - nonstatic entities
KW  - merging procedure
KW  - efficient ICP-based alignment
KW  - up-to-date state
KW  - 2D point cloud data
KW  - local maps
KW  - graph SLAM paradigm
KW  - multiple mapping sessions
KW  - single mapping sessions
KW  - SLAM system
KW  - autonomous robots
KW  - dynamic environments
KW  - long-term robot operation
KW  - Simultaneous localization and mapping
KW  - Cloud computing
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Merging
KW  - Optimization
DO  - 10.1109/IROS.2018.8594310
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.
ER  - 

TY  - CONF
TI  - Localization of Classified Objects in SLAM using Nonparametric Statistics and Clustering
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 161
EP  - 168
AU  - A. Iqbal
AU  - N. R. Gans
PY  - 2018
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonparametric statistics
KW  - object detection
KW  - pattern clustering
KW  - robot vision
KW  - SLAM (robots)
KW  - statistical analysis
KW  - nonparametric statistical approach
KW  - data association
KW  - mapping process
KW  - object detection
KW  - machine learning
KW  - semantic information
KW  - nonparametric statistics
KW  - classified objects
KW  - locating objects
KW  - SLAM
KW  - unsupervised clustering method
KW  - detected objects
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Object detection
KW  - Cameras
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593541
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Traditional Simultaneous Localization and Mapping (SLAM) approaches build maps based on points, lines or planes. These maps visually resemble the environment but without any semantic or information about the objects in the environment. Recent advancements in machine learning have made object detection highly accurate and reliable with large set of objects. Object detection can effectively help SLAM to incorporate semantics in the mapping process. One of the main obstacles is data association between detected objects over time. We demonstrate a nonparametric statistical approach to solve the data association between detected objects over consecutive frames. Then we use an unsupervised clustering method to identify the existence of objects in the map. The complete process can be run in parallel with SLAM. The performance of our algorithm is demonstrated on several public datasets, which shows promising results in locating objects in SLAM.
ER  - 

TY  - CONF
TI  - A distributed vision-based consensus model for aerial-robotic teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 169
EP  - 176
AU  - F. Poiesi
AU  - A. Cavallaro
PY  - 2018
KW  - autonomous aerial vehicles
KW  - geometry
KW  - mobile robots
KW  - object detection
KW  - position control
KW  - robot vision
KW  - target tracking
KW  - target position
KW  - PID-controlled steering responses
KW  - autonomous aerial robots
KW  - aerial-robotic teams
KW  - distributed vision-based consensus model
KW  - noisy detections
KW  - steering commands
KW  - ego-centric view
KW  - geometric constraints
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Cameras
KW  - Task analysis
KW  - Noise measurement
DO  - 10.1109/IROS.2018.8593388
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a distributed model for a team of autonomous aerial robots to collaboratively track a target without external control. The model uses distributed consensus to coordinate actions and to maintain formation via geometric constraints. Each robot uses its ego-centric view of a target and the relative distance from its two closest neighbors to infer its steering commands. To account for noisy and missing target detections, the robots exchange their estimated target position and formation configuration through shared PID-controlled steering responses. We show that the proposed model enables the team to maintain the view of a maneuvering target with varying acceleration under noisy detections and failures up to situations when all robots but one lose the target from their field of view.
ER  - 

TY  - CONF
TI  - Fast Kinodynamic Bipedal Locomotion Planning with Moving Obstacles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 177
EP  - 184
AU  - J. Ahn
AU  - O. Campbell
AU  - D. Kim
AU  - L. Sentis
PY  - 2018
KW  - collision avoidance
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - pendulums
KW  - robot dynamics
KW  - robot kinematics
KW  - wheels
KW  - moving obstacles
KW  - bipedal robot
KW  - complex environments
KW  - footstep planning algorithms
KW  - footstep locations
KW  - biped dynamics
KW  - temporal duration
KW  - dynamically consistent description
KW  - PSP
KW  - collision-free route
KW  - nonholonomic wheeled robots
KW  - kinematic constraints
KW  - bipedal motion
KW  - body dynamic walking behavior
KW  - 3D physics-based simulation
KW  - linear inverted pendulum model dynamics
KW  - dynamic constraints
KW  - kinodynamic bipedal locomotion planning
KW  - sampling-based kino-dynamic planning
KW  - LIPM
KW  - phase space planner
KW  - steering method
KW  - Planning
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594156
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a sampling-based kino-dynamic planning framework for a bipedal robot in complex environments. Unlike other footstep planning algorithms which typically plan footstep locations and the biped dynamics in separate steps, we handle both simultaneously. Three primary advantages of this approach are (1) the ability to differentiate alternate routes while selecting footstep locations based on the temporal duration of the route as determined by the Linear Inverted Pendulum Model (LIPM) dynamics, (2) the ability to perform collision checking through time so that collisions with moving obstacles are prevented without avoiding their entire trajectory, and (3) the ability to specify a minimum forward velocity for the biped. To generate a dynamically consistent description of the walking behavior, we exploit the Phase Space Planner (PSP) [1] [2]. To plan a collision-free route toward the goal, we adapt planning strategies from non-holonomic wheeled robots to gather a sequence of inputs for the PSP. This allows us to efficiently approximate dynamic and kinematic constraints on bipedal motion, to apply a sampling-based planning algorithm such as RRT or RRT*, and to use the Dubin's path [3] as the steering method to connect two points in the configuration space. The results of the algorithm are sent to a Whole Body Controller [1] to generate full body dynamic walking behavior. Our planning algorithm is tested in a 3D physics-based simulation of the humanoid robot Valkyrie.
ER  - 

TY  - CONF
TI  - Artificial Invariant Subspace for Humanoid Robot Balancing in Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 185
EP  - 192
AU  - X. Deng
AU  - D. D. Lee
PY  - 2018
KW  - damping
KW  - feedback
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - robot dynamics
KW  - stability
KW  - humanoid robots
KW  - biped robots
KW  - swing foot
KW  - damped harmonic oscillators
KW  - continuous feedback control
KW  - nominal walking cycle
KW  - rigid body dynamics
KW  - NAO robot
KW  - artificial invariant subspace
KW  - locomotion
KW  - compliant actuators
KW  - damping
KW  - nonlinear controller
KW  - robustness
KW  - bio-inspired legged robots
KW  - predictive foot stepping
KW  - asymptotic convergence
KW  - flat terrains
KW  - Legged locomotion
KW  - Foot
KW  - Humanoid robots
KW  - Orbits
KW  - Perturbation methods
KW  - Robustness
DO  - 10.1109/IROS.2018.8594423
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Legged robots that make use of compliant actuators have demonstrated greater robustness of locomotion than their rigid counterparts. Stiffness and damping are key parameters that characterize the adaptation to perturbations. In this work, by drawing inspirations from controllable compliance and damping in existing soft and bio-inspired legged robots, we propose an approach to design a nonlinear controller for the balancing of humanoid robots with rigid bodies. Existing literature has proposed simplified dynamical models of biped robots in order to predict the timing and placement of swing foot for walking without falling. We further employ the properties of invariance to perturbations in damped harmonic oscillators and formulate continuous feedback control in combination with predictive foot stepping in order to achieve continuous adaptive recoveries of the nominal walking cycle from unexpected physical disturbances. Our method allows asymptotic convergence of the rigid body dynamics to a subspace with the desired energy level. We demonstrate the robustness of the proposed algorithm base on extensive push recovery experiments on a NAO robot on flat terrains.
ER  - 

TY  - CONF
TI  - Classification of EEG signals for a hypnotrack BCI system
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 240
EP  - 245
AU  - M. Alimardani
AU  - S. Keshmiri
AU  - H. Sumioka
AU  - K. Hiraki
PY  - 2018
KW  - electroencephalography
KW  - feature extraction
KW  - medical signal processing
KW  - neurophysiology
KW  - patient treatment
KW  - signal classification
KW  - support vector machines
KW  - hypnotrack BCI system
KW  - EEG signals
KW  - clustering-based feature refinement strategy
KW  - support vector machine
KW  - clinical hypnotherapy sessions
KW  - electroencephalography signals
KW  - hypnosis intervention
KW  - Electroencephalography
KW  - Entropy
KW  - Electrodes
KW  - Brain
KW  - Feature extraction
KW  - Support vector machines
KW  - Medical treatment
DO  - 10.1109/IROS.2018.8594136
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - People's responses to a hypnosis intervention is diverse and unpredictable. A system that predicts user's level of susceptibility from their electroencephalography (EEG) signals can be helpful in clinical hypnotherapy sessions. In this paper, we extracted differential entropy (DE) of the recorded EEGs from two groups of subjects with high and low hypnotic susceptibility and built a support vector machine on these DE features for the classification of susceptibility trait. Moreover, we proposed a clustering-based feature refinement strategy to improve the estimation of such trait. Results showed a high classification performance in detection of subjects' level of susceptibility before and during hypnosis. Our results suggest the usefulness of this classifier in development of future Bel systems applied in the domain of therapy and healthcare.
ER  - 

TY  - CONF
TI  - Real-time Control of Whole-body Robot Motion and Trajectory Generation for Physiotherapeutic Juggling in VR
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 270
EP  - 277
AU  - P. Mohammadi
AU  - M. Malekzadeh
AU  - J. Kodl
AU  - A. Mukovskiy
AU  - D. L. Wigand
AU  - M. Giese
AU  - J. J. Steil
PY  - 2018
KW  - brain
KW  - control engineering computing
KW  - diseases
KW  - humanoid robots
KW  - medical computing
KW  - medical robotics
KW  - motion control
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - quadratic programming
KW  - trajectory control
KW  - virtual reality
KW  - whole-body robot motion
KW  - trajectory generation
KW  - physiotherapeutic juggling
KW  - motor rehabilitation
KW  - functional motor impairments
KW  - cerebellar ataxia
KW  - Parkinson's disease
KW  - juggling physiotherapy
KW  - brain plasticity
KW  - physical strain
KW  - juggling games
KW  - throwing motions
KW  - whole-body motion
KW  - real-time architecture
KW  - controller device
KW  - VR setting
KW  - physiotherapeutic robotic juggling
KW  - real-time operation
KW  - physical robot
KW  - virtual reality
KW  - humanoid robot COMAN wrist
KW  - quadratic program
KW  - real-time control
KW  - Trajectory
KW  - Real-time systems
KW  - Robot kinematics
KW  - Task analysis
KW  - Medical treatment
KW  - Switches
DO  - 10.1109/IROS.2018.8593632
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motor rehabilitation is in increasingly high demand to deal with minor functional motor impairments resulting from stroke, cerebellar ataxia, or Parkinson's disease. Juggling physiotherapy has shown to induce brain plasticity and to improve coordination and balance in this context. The physiotherapy, however, relies on large number of repetitions to be effective which prompts to deploy robots to release the burden on therapists both in terms of time as well as physical strain. This paper provides a framework to enable juggling games for patients in interacting with robots through Virtual Reality (VR). A set of throwing motions is recorded from the therapist and is retargeted to the humanoid robot COMAN's wrist. The respective whole-body motion is then solved in a stack of Quadratic Programs (QP) in a real-time architecture that integrates OROCOS and Gazebo. The resulting motion is finally streamed to VR for animation of the robot and the thrown ball, which the user can catch in VR using a controller device. We regard the VR setting as an essential step towards physiotherapeutic robotic juggling, because it ensures safety of the patients and effective testing of the methods and already has potential for actual therapeutic intervention. The control framework, however, is already validated in this paper for switching to full real-time operation on the physical robot.
ER  - 

TY  - CONF
TI  - A Novel Fabrication of PDMS Chip using Atmospheric Pressure Plasma Jet: Hydrophobicity Modification and Feasibility Test
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 278
EP  - 283
AU  - Y. Yu
AU  - L. Kuo
AU  - M. Wu
AU  - J. Wu
AU  - C. D. Tsai
PY  - 2018
KW  - bioMEMS
KW  - cellular biophysics
KW  - hydrophobicity
KW  - lab-on-a-chip
KW  - microchannel flow
KW  - microfabrication
KW  - optimisation
KW  - plasma jets
KW  - plasma materials processing
KW  - polymers
KW  - Taguchi methods
KW  - plasma parameters
KW  - microfluidic channels
KW  - PDMS chip
KW  - atmospheric pressure plasma jet
KW  - hydrophobicity modification
KW  - feasibility test
KW  - polydimethylsiloxane surface
KW  - microfluidic chips
KW  - simple cost method
KW  - low-cost method
KW  - fluidic system fabrication
KW  - optimization
KW  - regenerative medicine
KW  - cultured cells
KW  - Taguchi method
KW  - Plasmas
KW  - Surface treatment
KW  - Optimization
KW  - Argon
KW  - Power supplies
KW  - Plasma measurements
KW  - Fabrication
DO  - 10.1109/IROS.2018.8594446
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a new application of atmospheric pressure plasma jet (APPJ) aiming for fabricating a microfluidic system on a polydimethylsiloxane (PDMS) surface. While PDMS is widely used for microfluidic chips, the fabrication of a chip requires different instruments which are not easily accessible for small-scale companies or laboratories. Therefore, we are motivated to develop a simple and low-cost method for such a fluidic system fabrication. The idea of this work is to directly pattern a fluidic channel on a PDMS surface with a plasma jet, which is known for its capability of modifying the hydrophobicity on a surface. The feasibility test first showed that fluid only flows in plasma-treated regions as having physical walls. The plasma parameters were then optimized using Taguchi method based on experiments. The optimization significantly reduce the required plasma treating time from more than 30 treating rounds to only 3 treating rounds, over ten times improved. Methods for further improving the resolution to micrometer-scale have been discussed. In addition to the advantages of fast and low-cost of the proposed method, making microfluidic channels on the surfaces of PDMS chip is also convenient for recollecting cultured cells on a chip in the field of regenerative medicine.
ER  - 

TY  - CONF
TI  - Deep Neural Object Analysis by Interactive Auditory Exploration with a Humanoid Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 284
EP  - 289
AU  - M. Eppe
AU  - M. Kerzel
AU  - E. Strahl
AU  - S. Wermter
PY  - 2018
KW  - audio signal processing
KW  - humanoid robots
KW  - neural net architecture
KW  - signal classification
KW  - signal denoising
KW  - deep neural object analysis
KW  - interactive auditory exploration
KW  - humanoid robot
KW  - interactive auditory object analysis
KW  - robot elicits sensory information
KW  - robotic ears
KW  - neural network architecture
KW  - audio signals
KW  - microphone
KW  - material classification
KW  - weight prediction
KW  - Robot sensing systems
KW  - Humanoid robots
KW  - Robot kinematics
KW  - Mel frequency cepstral coefficient
KW  - Microsoft Windows
KW  - Plastics
DO  - 10.1109/IROS.2018.8593838
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel approach for interactive auditory object analysis with a humanoid robot. The robot elicits sensory information by physically shaking visually indistinguishable plastic capsules. It gathers the resulting audio signals from microphones that are embedded into the robotic ears. A neural network architecture learns from these signals to analyze properties of the contents of the containers. Specifically, we evaluate the material classification and weight prediction accuracy and demonstrate that the framework is fairly robust to acoustic real-world noise.
ER  - 

TY  - CONF
TI  - Cloud services for robotic nurses? Assessing legal and ethical issues in the use of cloud services for healthcare robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 290
EP  - 296
AU  - E. Fosch-Villaronga
AU  - H. Felzmann
AU  - M. Ramos-Montero
AU  - T. Mahler
PY  - 2018
KW  - cloud computing
KW  - ethical aspects
KW  - health care
KW  - legislation
KW  - medical robotics
KW  - mobile robots
KW  - security of data
KW  - cyber- aspects
KW  - data protection requirements
KW  - data security
KW  - healthcare cloud robotics
KW  - ethical issues
KW  - legal issues
KW  - robotic nurses
KW  - Cloud computing
KW  - Medical services
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Law
DO  - 10.1109/IROS.2018.8593591
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper explores ethical and legal implications arising from the intertwinement of cloud services, healthcare and robotics. It closes an existing gap in the literature by highlighting the distinctive ethical and legal concerns associated with the inter-dependence of the cyber- and the physical aspects of healthcare cloud robotics. The identified core concerns include uncertainties with regard to data protection requirements; distributed responsibilities for unintended harm; achievement of transparency and consent for cloud robot services especially for vulnerable robot users; secondary uses of cloud data derived from robot activities; data security; and wider social issues. The paper aims to raise awareness and stimulate reflection of the legal and ethical impacts on different stakeholders arising from the use of cloud services in healthcare robotics. We show that due to the complexity of these concerns the design and implementation of such robots in healthcare requires an interdisciplinary development and impact assessment process. In light of legal requirements and ethical responsibilities towards end-users and other stakeholders, we draw practical considerations for engineers developing cloud services for robots in healthcare.
ER  - 

TY  - CONF
TI  - Towards Norm Realization in Institutions Mediating Human-Robot Societies
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 297
EP  - 304
AU  - A. Wasik
AU  - S. Tomic
AU  - A. Saffiotti
AU  - F. Pecora
AU  - A. Martinoli
AU  - P. U. Lima
PY  - 2018
KW  - human-robot interaction
KW  - social sciences computing
KW  - human-robot societies
KW  - norm realization
KW  - social interactions
KW  - robotic systems
KW  - robotic language
KW  - human language
KW  - human society
KW  - social norms
KW  - Robot kinematics
KW  - Grounding
KW  - Art
KW  - Cognition
KW  - Decision making
KW  - Semantics
DO  - 10.1109/IROS.2018.8594079
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Social norms are the understandings that govern the behavior of members of a society. As such, they regulate communication, cooperation and other social interactions. Robots capable of reasoning about social norms are more likely to be recognized as an extension of our human society. However, norms stated in a form of the human language are inherently vague and abstract. This allows for applying norms in a variety of situations, but if the robots are to adhere to social norms, they must be capable of translating abstract norms to the robotic language. In this paper we use a notion of institution to realize social norms in real robotic systems. We illustrate our approach in a case study, where we translate abstract norms into concrete constraints on cooperative behaviors of humans and robots. We investigate the feasibility of our approach and quantitatively evaluate the performance of our framework in 30 real experiments with user-based evaluation with 40 participants.
ER  - 

TY  - CONF
TI  - “Oh! I am so sorry!”: Understanding User Physiological Variation while Spoiling a Game Task
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 313
EP  - 319
AU  - R. Agrigoroaie
AU  - A. Cruz-Maya
AU  - A. Tapus
PY  - 2018
KW  - computer games
KW  - human-robot interaction
KW  - psychology
KW  - Jenga game
KW  - galvanic skin response
KW  - psychological questionnaires
KW  - multiple GSR parameters
KW  - user physiological variation
KW  - game task
KW  - tower fall down
KW  - Poles and towers
KW  - Games
KW  - Collision avoidance
KW  - Physiology
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593395
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates how individuals react in a situation when an experimenter (human or robot) either tells them to stop in the middle of playing the Jenga game, or accidentally bumps into a table and makes the tower fall down. The mood of the participants and different physiological parameters (i.e., galvanic skin response (GSR) and facial temperature variation) are extracted and analysed based on the condition, experimenter, and psychological questionnaires (i.e., TEQ, TEIQ, RST-PQ). This study was a between participants study with 23 participants. Our results show that multiple GSR parameters (e.g., latency, amplitude, number of peaks) differ significantly based on the condition and the experimenter the participants interacted with. The temperature variation in three regions of interest (i.e., forehead, left, and right periorbital regions) are good indicators of how ready an individual is to react in an unforeseen situation.
ER  - 

TY  - CONF
TI  - An Extended Bayesian User Model (BUM) for Capturing Cultural Attributes with a Social Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 320
EP  - 325
AU  - L. Santos
AU  - G. S. Martins
AU  - J. Dias
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - decision making
KW  - human-robot interaction
KW  - pattern classification
KW  - pattern clustering
KW  - service robots
KW  - user modelling
KW  - human-robot interaction
KW  - extended Bayesian User Model
KW  - social robotics
KW  - culture-awareness
KW  - specific subtleties
KW  - highly accurate classification framework
KW  - share similar attributes
KW  - n-dimensional semantic attribute space
KW  - capture unitary attributes
KW  - Bayesian classifiers
KW  - robotic technologies
KW  - latest advances
KW  - heterogeneous information
KW  - unified representation
KW  - cultural attributes
KW  - Robot sensing systems
KW  - Cultural differences
KW  - Bayes methods
KW  - Statistics
KW  - Indexes
KW  - Computational modeling
KW  - Culture Aware Social Robots
KW  - Robot Perception
KW  - Multimodal Human-Robot Interaction
KW  - User Models
DO  - 10.1109/IROS.2018.8593970
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we propose a Bayesian User Model which is able capture a unified representation of cultural attributes from heterogeneous information in the context of Human-Robot Interaction. Despite the latest advances in robotic technologies, virtually no robots are able to cope with the specificities of the “modus vivendi” of different cultures. We start by proposing Bayesian classifiers to capture unitary attributes of different users, clustering them in a n-dimensional semantic attribute space, aggregating groups of persons that share similar attributes. Results show a highly accurate classification framework, both capable of detecting specific subtleties in user's properties, and generalizing them into representative profiles. We then discuss its application towards adapting the actions of a robot and its potential impact on culture-awareness, demonstrating how the proposed framework can enable culture-awareness, exploring this new frontier in social robotics.
ER  - 

TY  - CONF
TI  - Culturally aware Planning and Execution of Robot Actions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 326
EP  - 332
AU  - A. A. Khaliq
AU  - U. Köckemann
AU  - F. Pecora
AU  - A. Saffiotti
AU  - B. Bruno
AU  - C. T. Recchiuto
AU  - A. Sgorbissa
AU  - H. Bui
AU  - N. Y. Chong
PY  - 2018
KW  - cultural aspects
KW  - mobile robots
KW  - path planning
KW  - robot actions
KW  - cultural group
KW  - cultural adaptation
KW  - interpersonal distance
KW  - robot plans generation
KW  - cultural preferences
KW  - CARESSES project
KW  - assistive robots
KW  - culturally aware planning
KW  - Cultural differences
KW  - Robot sensing systems
KW  - Planning
KW  - Knowledge based systems
KW  - Computer architecture
KW  - Cognition
DO  - 10.1109/IROS.2018.8593570
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The way in which humans behave, speak and interact is deeply influenced by their culture. For example, greeting is done differently in France, in Sweden or in Japan; and the average interpersonal distance changes from one cultural group to the other. In order to successfully coexist with humans, robots should also adapt their behavior to the culture, customs and manners of the persons they interact with. In this paper, we deal with an important ingredient of cultural adaptation: how to generate robot plans that respect given cultural preferences, and how to execute them in a way that is sensitive to those preferences. We present initial results in this direction in the context of the CARESSES project, a joint EU-Japan effort to build culturally competent assistive robots.
ER  - 

TY  - CONF
TI  - Trait-based Culture and its Organization: Developing a Culture Enabler for Artificial Agents
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 333
EP  - 338
AU  - S. Borgo
AU  - E. Blanzieri
PY  - 2018
KW  - artificial intelligence
KW  - multi-agent systems
KW  - social sciences computing
KW  - software agents
KW  - trait-based culture
KW  - culture enabler
KW  - artificial agent
KW  - human interests
KW  - human culture
KW  - trait types
KW  - trait module
KW  - Cultural differences
KW  - Global communication
KW  - Organizations
KW  - Knowledge based systems
KW  - Standards organizations
KW  - Intelligent robots
KW  - Buildings
DO  - 10.1109/IROS.2018.8593369
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Artificial agents might not understand human interests and actions if these agents cannot anticipate how a person understands a situation and, based on this, what could be his/her expectations. In many cases, understanding, expectations and behaviors are constrained, if not driven, by culture. Can we provide human culture to an artificial agent? Can we provide formal representations of different cultures? In this paper we discuss the (elusive) notion of culture and propose an approach based on the notion of trait which, we argue, allows building formal modules suitable to represent culture (broadly understood). We distinguish the trait types (knowledge, rule, behavior, interpretation) that such modules should contain and briefly discuss how they could be organized. Finally, we exemplify the role of a trait module in the flow of information internal to an agent highlighting surprising potentialities.
ER  - 

TY  - CONF
TI  - CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 339
EP  - 346
AU  - O. Rudovic
AU  - Y. Utsumi
AU  - J. Lee
AU  - J. Hernandez
AU  - E. C. Ferrer
AU  - B. Schuller
AU  - R. W. Picard
PY  - 2018
KW  - cultural aspects
KW  - face recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - medical disorders
KW  - medical robotics
KW  - paediatrics
KW  - patient treatment
KW  - deep learning model
KW  - cultural backgrounds
KW  - image data
KW  - target culture
KW  - multicultural data
KW  - child-dependent settings
KW  - across-culture evaluations
KW  - target task
KW  - deep architecture
KW  - robot-assisted autism therapy
KW  - video data
KW  - automated engagement estimation
KW  - deep learning models
KW  - neu-rotypical peers
KW  - autism spectrum
KW  - engagement intensity estimation
KW  - face images
KW  - cultural differences
KW  - individual differences
KW  - estimation performance
KW  - model learning
KW  - target children
KW  - target engagement levels
KW  - poor estimation
KW  - child-independent models
KW  - Face
KW  - Autism
KW  - Deep learning
KW  - Estimation
KW  - Cultural differences
KW  - Task analysis
KW  - Robots
DO  - 10.1109/IROS.2018.8594177
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many children on autism spectrum have atypical behavioral expressions of engagement compared to their neu-rotypical peers. In this paper, we investigate the performance of deep learning models in the task of automated engagement estimation from face images of children with autism. Specifically, we use the video data of 30 children with different cultural backgrounds (Asia vs. Europe) recorded during a single session of a robot-assisted autism therapy. We perform a thorough evaluation of the proposed deep architectures for the target task, including within- and across-culture evaluations, as well as when using the child-independent and child-dependent settings. We also introduce a novel deep learning model, named CultureNet, which efficiently leverages the multi-cultural data when performing the adaptation of the proposed deep architecture to the target culture and child. We show that due to the highly heterogeneous nature of the image data of children with autism, the child-independent models lead to overall poor estimation of target engagement levels. On the other hand, when a small amount of data of target children is used to enhance the model learning, the estimation performance on the held-out data from those children increases significantly. This is the first time that the effects of individual and cultural differences in children with autism have empirically been studied in the context of deep learning performed directly from face images.
ER  - 

TY  - CONF
TI  - Object Assembly Guidance in Child-Robot Interaction using RGB-D based 3D Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 347
EP  - 354
AU  - J. Hadfield
AU  - P. Koutras
AU  - N. Efthymiou
AU  - G. Potamianos
AU  - C. S. Tzafestas
AU  - P. Maragos
PY  - 2018
KW  - gesture recognition
KW  - human computer interaction
KW  - humanoid robots
KW  - human-robot interaction
KW  - image colour analysis
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - object tracking
KW  - particle filtering (numerical methods)
KW  - verbal response
KW  - 3D object tracking algorithm
KW  - RGB-D data
KW  - object assembly task
KW  - autonomous humanoid robot
KW  - RGB-D based 3D
KW  - object assembly guidance
KW  - resulting Child-Robot Interaction scenario
KW  - assembly state estimation
KW  - gestural response
KW  - assembly part
KW  - degrees-of-freedom
KW  - depth data stream
KW  - particle filter
KW  - image plane
KW  - color stream
KW  - tracking-by-detection scheme
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Robotic assembly
KW  - Robot kinematics
KW  - Tracking
KW  - Streaming media
DO  - 10.1109/IROS.2018.8594187
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work examines how and to what benefit an autonomous humanoid robot can supervise a child in an object assembly task. In order to understand the child's actions, a novel 3D object tracking algorithm for RGB-D data is employed. The tracker consists of two stages: the first performs a tracking-by-detection scheme on the color stream, to locate the objects on the image plane, while the second uses a particle filter that operates on the depth data stream to refine the first stage output and infer the objects' rotations. Given the six degrees-of-freedom of the assembly part poses, the system is able to recognize which connections have been completed at any given time. This information is then used to select an appropriate verbal or gestural response for the robot. Experimental results show that (a) the tracking algorithm is accurate, fast and robust to severe occlusions and fast movements, (b) the proposed method of assembly state estimation is indeed effective, and (c) the resulting Child-Robot Interaction scenario is educational and enjoyable for the children involved.
ER  - 

TY  - CONF
TI  - In pixels we trust: From Pixel Labeling to Object Localization and Scene Categorization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 355
EP  - 361
AU  - C. Herranz-Perdiguero
AU  - C. Redondo-Cabrera
AU  - R. J. López-Sastre
PY  - 2018
KW  - image classification
KW  - image segmentation
KW  - object detection
KW  - pixels
KW  - image pixel labeling
KW  - object detection
KW  - pixel labeling
KW  - scene understanding
KW  - semantic segmentation mask
KW  - Semantics
KW  - Labeling
KW  - Image segmentation
KW  - Task analysis
KW  - Object detection
KW  - Histograms
KW  - Kernel
DO  - 10.1109/IROS.2018.8593736
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - While there has been significant progress in solving the problems of image pixel labeling, object detection and scene classification, existing approaches normally address them separately. In this paper, we propose to tackle these problems from a bottom-up perspective, where we simply need a semantic segmentation of the scene as input. We employ the DeepLab architecture, based on the ResNet deep network, which leverages multi-scale inputs to later fuse their responses to perform a precise pixel labeling of the scene. This semantic segmentation mask is used to localize the objects and to recognize the scene, following two simple yet effective strategies. We evaluate the benefits of our solutions, performing a thorough experimental evaluation on the NYU Depth V2 dataset. Our approach achieves a performance that beats the leading results by a significant margin, defining the new state of the art in this benchmark for the three tasks comprising the scene understanding: semantic segmentation, object detection and scene categorization.
ER  - 

TY  - CONF
TI  - Self-Supervised Learning of the Drivable Area for Autonomous Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 362
EP  - 369
AU  - J. Mayr
AU  - C. Unger
AU  - F. Tombari
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - stereo image processing
KW  - road segmentation
KW  - automatic labeling pipeline
KW  - deterministic stereo-based approach
KW  - ground plane detection
KW  - KITTI dataset
KW  - semantic segmentation
KW  - good segmentation results
KW  - self-supervised learning
KW  - autonomous vehicles
KW  - training data
KW  - drivable area segmentation
KW  - deep neural networks
KW  - impressive progress
KW  - deep learning
KW  - traditional machine learning
KW  - deterministic algorithms
KW  - large-scale datasets
KW  - associated ground truth labels
KW  - expensive labor-intensive problem
KW  - off-the-shelf DNN
KW  - Image segmentation
KW  - Training data
KW  - Labeling
KW  - Generators
KW  - Histograms
KW  - Training
KW  - Cameras
DO  - 10.1109/IROS.2018.8594480
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a new approach for generating training data for the task of drivable area segmentation with deep neural networks (DNN). The impressive progress of deep learning in recent years demonstrated a superior performance of DNNs over traditional machine learning and deterministic algorithms for various tasks. Nevertheless, the acquisition of large-scale datasets with associated ground truth labels still poses an expensive and labor-intensive problem. We contribute to the solution of this problem for the task of road segmentation by proposing an automatic labeling pipeline which leverages a deterministic stereo-based approach for ground plane detection to create large datasets suitable for training neural networks. Based on the popular Cityscapes [1] and KITTI dataset [2] and two off-the-shelf DNNs for semantic segmentation, we show that we can achieve good segmentation results on monocular images, which substantially exceed the performance of the algorithm employed for automatic labeling without the need of any manual annotation.
ER  - 

TY  - CONF
TI  - Reachset Conformance of Forward Dynamic Models for the Formal Analysis of Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 370
EP  - 376
AU  - S. B. Liu
AU  - M. Althoff
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - program testing
KW  - reachability analysis
KW  - safety-critical software
KW  - human-robot co-existence scenario
KW  - robots
KW  - formal analysis
KW  - forward dynamic models
KW  - reachset conformance
KW  - reachability analysis
KW  - robotic models
KW  - model-based testing
KW  - safety-critical applications
KW  - classical robotic applications
KW  - design flaws
KW  - robotic systems
KW  - model-based design
KW  - Friction
KW  - Uncertainty
KW  - Manipulators
KW  - Mathematical model
KW  - Computational modeling
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593975
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Model-based design of robotic systems has many advantages, among them faster development cycles and reduced costs due to early detections of design flaws. Approximate models are sufficient for many classical robotic applications; however, they no longer suffice for safety-critical applications. For instance, a dangerous situation which has not been detected by model-based testing might occur in a human-robot co-existence scenario since models do not exactly replicate behaviors of real systems-this problem arises no matter how accurate a model is, since even disturbances and sensor noise can cause a mismatch. We address this issue by adding non-determinism to robotic models and by computing the whole set of possible behaviors using reachability analysis. By using reachset conformance, we automatically adjust the required non-determinism so that all recorded behaviors are captured. For the first time this approach is demonstrated for a real robot.
ER  - 

TY  - CONF
TI  - Timestamp Offset Calibration for an IMU-Camera System Under Interval Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 377
EP  - 384
AU  - R. Voges
AU  - B. Wagner
PY  - 2018
KW  - calibration
KW  - cameras
KW  - data acquisition
KW  - inertial systems
KW  - measurement uncertainty
KW  - time measurement
KW  - orientation estimation determination
KW  - data acqusition
KW  - sensors
KW  - robotics applications
KW  - IMU-camera system
KW  - timestamp offset calibration
KW  - calibration data
KW  - bounded-error approach
KW  - interval uncertainty
KW  - time 20.0 ms
KW  - Cameras
KW  - Calibration
KW  - Uncertainty
KW  - Sensor fusion
KW  - Electron tubes
KW  - Sensor systems
DO  - 10.1109/IROS.2018.8594237
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To properly fuse IMU and camera information for robotics applications, the relative timestamp offset between both sensors' data streams has to be considered. However, finding the exact timestamp offset is often impossible. Thus, it is necessary to additionally consider the offset's uncertainty if we want to produce reliable results. In order to find the offset and its uncertainty, we determine orientation estimates from IMU and camera under interval uncertainty. Subsequently, these intervals are used as a common representation for our bounded-error approach that finds an interval enclosing the true offset while also modeling the uncertainty. Calibration data can be acquired in a few seconds using a simple setup of IMU, camera and camera target. Results using both simulated and real data demonstrate that we are able to determine the offset to an accuracy of 20 ms with a computation time that is suitable for future online applications. Here, our approach could be used to monitor the timestamp offset in a guaranteed way. Additionally, our method can be adapted to determine an interval for the rotation between both sensors. While this increases the computation time drastically, it also enhances the accuracy of the timestamp offset to less than 10 ms.
ER  - 

TY  - CONF
TI  - Fast and Accurate Semantic Mapping through Geometric-based Incremental Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 385
EP  - 392
AU  - Y. Nakajima
AU  - K. Tateno
AU  - F. Tombari
AU  - H. Saito
PY  - 2018
KW  - image segmentation
KW  - probability
KW  - SLAM (robots)
KW  - stereo image processing
KW  - SLAM framework
KW  - NYUv2 dataset
KW  - computational efficiency
KW  - frame-wise segmentation result
KW  - computationally intensive stages
KW  - segmentation label
KW  - updating class probabilities
KW  - processing components
KW  - geometric-based segmentation method
KW  - geometric-based incremental segmentation
KW  - Semantics
KW  - Three-dimensional displays
KW  - Image segmentation
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Real-time systems
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593993
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose an efficient and scalable method for incrementally building a dense, semantically annotated 3D map in real-time. The proposed method assigns class probabilities to each region, not each element (e.g., surfel and voxel), of the 3D map which is built up through a robust SLAM framework and incrementally segmented with a geometric-based segmentation method. Differently from all other approaches, our method has a capability of running at over 30Hz while performing all processing components, including SLAM, segmentation, 2D recognition, and updating class probabilities of each segmentation label at every incoming frame, thanks to the high efficiency that characterizes the computationally intensive stages of our framework. By utilizing a specifically designed CNN to improve the frame-wise segmentation result, we can also achieve high accuracy. We validate our method on the NYUv2 dataset by comparing with the state of the art in terms of accuracy and computational efficiency, and by means of an analysis in terms of time and space complexity.
ER  - 

TY  - CONF
TI  - Semantic Monocular SLAM for Highly Dynamic Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 393
EP  - 400
AU  - N. Brasch
AU  - A. Bozic
AU  - J. Lallemand
AU  - F. Tombari
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image motion analysis
KW  - image sequences
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - static environment
KW  - semantic monocular SLAM framework
KW  - semantic information
KW  - explicit probabilistic model
KW  - dynamic environments
KW  - Virtual KITTI
KW  - Synthia datasets
KW  - pose estimation
KW  - Semantics
KW  - Simultaneous localization and mapping
KW  - Feature extraction
KW  - Dynamics
KW  - Cameras
KW  - Pose estimation
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593828
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent advances in monocular SLAM have enabled real-time capable systems which run robustly under the assumption of a static environment, but fail in presence of dynamic scene changes and motion, since they lack an explicit dynamic outlier handling. We propose a semantic monocular SLAM framework designed to deal with highly dynamic environments, combining feature-based and direct approaches to achieve robustness under challenging conditions. The proposed approach exploits semantic information extracted from the scene within an explicit probabilistic model, which maximizes the probability for both tracking and mapping to rely on those scene parts that do not present a relative motion with respect to the camera. We show more stable pose estimation in dynamic environments and comparable performance to the state of the art on static sequences on the Virtual KITTI and Synthia datasets.
ER  - 

TY  - CONF
TI  - Path-Following through Control Funnel Functions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 401
EP  - 408
AU  - H. Ravanbakhsh
AU  - S. Aghli
AU  - C. Heckman
AU  - S. Sankaranarayanan
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - road vehicles
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - vehicle dynamics
KW  - control feedback laws
KW  - control funnel functions
KW  - path following
KW  - reference trajectory
KW  - autonomous vehicles
KW  - robustness
KW  - timing law
KW  - mathematical model
KW  - vehicle dynamics
KW  - demonstration-based learning algorithm
KW  - autonomous vehicle
KW  - Parkour car
KW  - trajectory tracking
KW  - Trajectory
KW  - Robustness
KW  - Autonomous vehicles
KW  - Timing
KW  - Vehicle dynamics
KW  - Automobiles
KW  - Trajectory tracking
DO  - 10.1109/IROS.2018.8593637
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an approach to path following using so-called control funnel functions. Synthesizing controllers to “robustly” follow a reference trajectory is a fundamental problem for autonomous vehicles. Robustness, in this context, requires our controllers to handle a specified amount of deviation from the desired trajectory. Our approach considers a timing law that describes how fast to move along a given reference trajectory and a control feedback law for reducing deviations from the reference. We synthesize both feedback laws using “control funnel functions” that jointly encode the control law as well as its correctness argument over a mathematical model of the vehicle dynamics. We adapt a previously described demonstration-based learning algorithm to synthesize a control funnel function as well as the associated feedback law. We implement this law on top of a 1/8th scale autonomous vehicle called the Parkour car. We compare the performance of our path following approach against a trajectory tracking approach by specifying trajectories of varying lengths and curvatures. Our experiments demonstrate the improved robustness obtained from the use of control funnel functions.
ER  - 

TY  - CONF
TI  - Online inference of human belief for cooperative robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 409
EP  - 415
AU  - M. C. Buehler
AU  - T. H. Weisswange
PY  - 2018
KW  - belief networks
KW  - cognition
KW  - cognitive systems
KW  - cooperative systems
KW  - human-robot interaction
KW  - inference mechanisms
KW  - interactive systems
KW  - mobile robots
KW  - multi-robot systems
KW  - online inference
KW  - natural interaction
KW  - human-human cooperation
KW  - model-based belief filter
KW  - human action
KW  - cognitive processes
KW  - perception
KW  - action selection
KW  - double inference process
KW  - environmental state
KW  - human-robot cooperation experiment
KW  - situation awareness
KW  - cognitive states
KW  - Task analysis
KW  - Robots
KW  - Manufacturing
KW  - Collaboration
KW  - Probability distribution
KW  - Estimation
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594076
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For human-robot cooperation, inferring a hu-man's cognitive state is very important for an efficient and natural interaction. Similar to human-human cooperation, understanding what the partner plans and knowing, if he is situation aware, is necessary to prevent collisions, offer support at the right time, correct mistakes before they happen or choose the best actions for oneself as early as possible. We propose a model-based belief filter to extract relevant aspects of a human's mental state online during cooperation. It performs inference based on human actions and its own task knowledge, modeling cognitive processes like perception and action selection. In contrast to most prior work, we explicitly estimate the human belief instead of inferring only a single mode or intention. Since this is a double inference process, we focus on representing the human estimates of environmental state and task as well as corresponding uncertainties. We designed a human-robot cooperation experiment that allowed for a variety of cognitive states of both agents and collected data to test and evaluate the proposed belief filter. The results are promising, as our system can be used to provide reasonable predictions of the human action and insights into his situation awareness. At the same time it is inferring interpretable information about the underlying cognitive states - A belief about the human's belief about the environment.
ER  - 

TY  - CONF
TI  - An Omnidirectional Jumper with Expanded Movability via Steering, Self-Righting and Take-off Angle Adjustment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 416
EP  - 421
AU  - S. Yim
AU  - S. Baek
AU  - G. Jung
AU  - K. Cho
PY  - 2018
KW  - biomechanics
KW  - mobile robots
KW  - steering shares
KW  - modified active triggering mechanism
KW  - jumping performance
KW  - expanded locomotion capabilities
KW  - angle adjustment
KW  - self-righting
KW  - expanded movability
KW  - omnidirectional jumper
KW  - Robots
KW  - Couplings
KW  - Gears
KW  - Windings
KW  - Pulleys
KW  - Wheels
KW  - Energy storage
DO  - 10.1109/IROS.2018.8594372
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose an omnidirectional jumper with expanded locomotion capabilities. The mechanisms for four functions-jumping, steering, self-righting and take-off angle adjustment-are designed using only two motors to maximize the jumping performance. Jumping uses the modified active triggering mechanism with one motor. Steering shares this motor and uses the wheel touching the ground. The take-off angle is adjusted by changing the angle between the body and the foot using another motor. Self-righting is possible by utilizing combinations of the movements that occur in the energy storing and angle adjustment processes. With these four functions, the robot is capable of jumping in all directions and can jump anywhere in between the maximum height and maximum distance. It can also jump multiple times by self-righting. The robot, with a mass of 64.4 g, jumps up to 113 cm in vertical height, and 170 cm in horizontal distance. This robot can be deployed to explore various environments. Moreover, the design method to implement more functions than the number of motors can be applied to design other small-scale robots.
ER  - 

TY  - CONF
TI  - Delineating boundaries of feasibility between robot designs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 422
EP  - 429
AU  - S. Ghasemlou
AU  - J. M. O'Kane
AU  - D. A. Shell
PY  - 2018
KW  - decision trees
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pattern classification
KW  - planning (artificial intelligence)
KW  - sensors
KW  - actuators
KW  - classic search methods
KW  - planning problem
KW  - actuator resources
KW  - effective robots
KW  - robot designs
KW  - delineating boundaries
KW  - domain knowledge
KW  - design space
KW  - interactive tools
KW  - interactive process
KW  - boundary subject
KW  - compact implicit representation
KW  - decision tree learning method
KW  - discriminatory features
KW  - Robot sensing systems
KW  - Planning
KW  - Actuators
KW  - Task analysis
KW  - Tools
KW  - Decision trees
DO  - 10.1109/IROS.2018.8593811
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motivated by the need for tools to aid in the design of effective robots, we examine how to determine the role that particular sensing and actuator resources play in enabling a robot to achieve useful ends. Rather than merely asking “will this sensor suffice?” we classify general modifications to the set of sensors and actuators based on the feasibility of accomplishing given tasks using these sets. The goal is to probe the boundary between modifications that are destructive on a given planning problem, and modifications that are not. Since this boundary itself can be impractically large, classic search methods are of no avail to summarize discriminatory features on this boundary. Instead, we propose a decision tree learning method to efficiently construct a compact implicit representation of the boundary. The idea is to allow the designer to use prior knowledge to constrain the search, then use the tool to probe the boundary subject to those constraints, gaining insight into the information necessary for a robot to ensure task achievement. Ultimately we envision a interactive process where additional constraints are repeatedly included as new light is shed. We aim to pave the way for interactive tools that help the roboticist navigate the complexities of the design space. We describe an implementation of this approach along with experimental results that show that the method can construct decision trees with explanatory value. Our experiments suggest that some domain knowledge (specifically picking features that emphasize monotonicity) substantially improves running-time with only negligible reduction in accuracy.
ER  - 

TY  - CONF
TI  - Discrete Configuration Space Methods for Determining Modular Connector Area of Acceptance in Higher Dimensions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 430
EP  - 435
AU  - N. Eckenstein
AU  - M. Yim
PY  - 2018
KW  - collision avoidance
KW  - discrete systems
KW  - mobile robots
KW  - discrete configuration space methods
KW  - physical connectors
KW  - docking process
KW  - robotic control systems
KW  - automatic control systems
KW  - robotic self-reconfiguration
KW  - air-to-air refueling
KW  - configuration space obstacle model
KW  - modular connector area of acceptance
KW  - self-aligning geometry
KW  - Meyer's flooding algorithm
KW  - Connectors
KW  - Geometry
KW  - Robots
KW  - Contacts
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594072
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Physical connectors with self-aligning geometry aid in the docking process for many robotic and automatic control systems such as robotic self-reconfiguration and air-to-air refueling. This self-aligning geometry provides a wider range of acceptable error tolerance in relative pose between the two rigid objects, increasing successful docking chances. We present a new method for computing the error range (or area of acceptance) for a pair of rigid connector objects with self-aligning geometry capable of higher dimensional analysis which was previously limited to three. The method is based on the configuration space obstacle model, which gives us a representation of the space of contact states between the two objects. Using an approach direction as analogous to gravity, and assuming the target docked configuration is stable, the set of misaligned points that lead to docking is the target configuration's watershed for an arbitrarily dimensioned configuration space obstacle. It is well known that the watershed of a height map on a discrete grid can be found using any number of algorithms from image segmentation. We present an implementation based on Meyer's flooding algorithm to determine this watershed and measure the AA for simple connectors in 2D and 3D. Results are presented for systems including unconstrained motion in SE(2) and motion constrained to four dimensions (ie. x,y,z,pitch) in SE(3).
ER  - 

TY  - CONF
TI  - An Origami-Inspired Flexible Pneumatic Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 436
EP  - 441
AU  - F. Schmitt
AU  - O. Piccin
AU  - L. Barbé
AU  - B. Bayle
PY  - 2018
KW  - architecture
KW  - hinges
KW  - mechanical testing
KW  - plates (structures)
KW  - pneumatic actuators
KW  - prototypes
KW  - rapid prototyping (industrial)
KW  - shear modulus
KW  - three-dimensional printing
KW  - prototype
KW  - origami-inspired flexible pneumatic actuator design
KW  - multimaterial additive manufacturing process
KW  - mechanical testing
KW  - airtight chamber
KW  - flexible origami-inspired architecture
KW  - short stroke displacements
KW  - material resistance
KW  - flexible hinges
KW  - rigid plates
KW  - Actuators
KW  - Geometry
KW  - Prototypes
KW  - Shape
KW  - Soft robotics
KW  - Three-dimensional printing
DO  - 10.1109/IROS.2018.8593423
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a new actuator designed to produce forces under short stroke displacements. Two variants of the prototype have been manufactured using Multi-Material Additive Manufacturing process, based on a flexible origami-inspired architecture. The structure consists of an airtight chamber constituted by rigid plates combined with flexible hinges and surfaces in order to allow the generation of motion. We propose several insights on integration issues such as limited material resistance and maximum range of motion. Both versions of the prototype are then tested to assess their performances for single strokes and cyclic loading.
ER  - 

TY  - CONF
TI  - Design and Development of Biaxial Active Nozzle with Flexible Flow Channel for Air Floating Active Scope Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 442
EP  - 449
AU  - A. Ishii
AU  - Y. Ambe
AU  - Y. Yamauchi
AU  - H. Ando
AU  - M. Konyo
AU  - K. Tadakuma
AU  - S. Tadokoro
PY  - 2018
KW  - buckling
KW  - cameras
KW  - deformation
KW  - design engineering
KW  - jets
KW  - mobile robots
KW  - motion control
KW  - nozzles
KW  - pneumatic actuators
KW  - position control
KW  - service robots
KW  - shapes (structures)
KW  - flexible robot
KW  - shape deformation
KW  - air floating active scope camera
KW  - pneumatic actuators
KW  - geometric parameters
KW  - ASC
KW  - rescue operations
KW  - reaction force direction
KW  - flexible air tube
KW  - air jet direction
KW  - head motion
KW  - flexible flow channel
KW  - biaxial active nozzle
KW  - Electron tubes
KW  - Robots
KW  - Force
KW  - Shape
KW  - Cameras
KW  - Strain
KW  - Pneumatic systems
DO  - 10.1109/IROS.2018.8594437
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Long flexible continuum robots have a high potential for search and rescue operations that explore deep layered debris. A general problem of these robots is in the control of the head motion because their thin bodies limit the space available to mount multiple actuators. This paper develops a biaxial active nozzle which can rotate the air jet direction along a roll and pitch axis in order to control the direction of reaction force and the head motion of a long flexible robot. A major challenge is how to change the air jet direction without a large resistance to the flow, which reduces the reaction force induced by the air jet. We propose a nozzle whose outlet is connected with a flexible air tube. The direction of the air jet is controlled by the smooth shape deformation of the tube. The nozzle should be compact enough to be installed on a thin robot, although the shape deformation of the tube may cause buckling. The flexible tube is modeled and simulated by a multiple link model used to derive the geometric parameters of the nozzle so that the nozzle is compact and the tube does not buckle. Based on the derived parameters, the biaxial active nozzle was developed. A basic performance experiment shows that the nozzle can change the reaction force direction by deforming the tube shape, while the magnitude of the reaction force is almost constant. We integrated the proposed nozzle with a conventional Active Scope Camera (ASC). The range where the robot can look around in a vertical exploration was significantly improved, which was three times larger than the previous ASC whose head was controlled by pneumatic actuators. The rubble field test demonstrates that the integrated ASC could move over rubble (maximum height of 200 mm) and steer the course.
ER  - 

TY  - CONF
TI  - Design and Implementation of Programmable Drawing Automata based on Cam Mechanisms for Representing Spatial Trajectory
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 450
EP  - 455
AU  - T. Takahashi
AU  - H. G. Okuno
PY  - 2018
KW  - cams (mechanical)
KW  - computer animation
KW  - data visualisation
KW  - graphical user interfaces
KW  - spatial trajectory representation
KW  - RSSR linkage
KW  - revolute-spherical-S-R linkage
KW  - user-specified 2D/3D trajectory
KW  - GUI
KW  - 3D animation
KW  - user programs PDA-0
KW  - PDA-0 programmable
KW  - programmable drawing automaton
KW  - cam mechanisms
KW  - programmable drawing automata
KW  - Automata
KW  - Couplings
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Shape
KW  - Animation
KW  - Kinematics
DO  - 10.1109/IROS.2018.8594443
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and implementation of a preliminary version of a programmable drawing automaton (PDA-0) that draws a user-specified 3D trajectory. PDA-0 is strongly inspired by Jaquet Droz's a programmable drawing automaton built in the 1770s using 6,000 moving parts, which was hand-coded. PDA-0 consists of RSSR (Revolute-Spherical-S-R) linkage and cam mechanisms with three interchangeable cams. Interchangeable cams make PDA-0 programmable because a user-specified 2D/3D trajectory is encoded into the set of three cams. The user programs PDA-0 by specifying a trajectory via a GUI or 3D animation. Subsequently, the compiler estimates a 3D trajectory mathematically from the user-specified 2D/3D trajectory and calculates the shape of the three cams, i.e., a code for PDA-0 by solving kinematic constraints. Finally, PDA-0 with the 3D-printed cams executes the code to draw the user-specified trajectory. The current PDA-0 with three cams demonstrates drawing simple trajectories such as letters and symbols.
ER  - 

TY  - CONF
TI  - Auxetic Sleeves for Soft Actuators with Kinematically Varied Surfaces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 464
EP  - 471
AU  - A. Sedal
AU  - M. Fisher
AU  - J. Bishop-Moser
AU  - A. Wineman
AU  - S. Kota
PY  - 2018
KW  - actuators
KW  - auxetics
KW  - bending
KW  - Poisson ratio
KW  - prototypes
KW  - robot kinematics
KW  - radial expansion
KW  - bending
KW  - prototypes
KW  - auxetic sleeves
KW  - representative auxetic element
KW  - kinematic model
KW  - Poisson's ratio
KW  - RAE-based design scheme
KW  - RAE-patterned actuators
KW  - soft robots
KW  - soft actuator
KW  - Actuators
KW  - Auxetic materials
KW  - Kinematics
KW  - Finite element analysis
KW  - Shape
KW  - Strain
KW  - Stress
DO  - 10.1109/IROS.2018.8594212
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft actuators with auxetic, or negative Poisson's ratio (NPR), behavior offer a way to create soft robots with novel kinematic behavior. This paper presents an original framework for reinforcement of a soft actuator using a generalized NPR element, called a Representative Auxetic Element (RAE), and an experimental validation of the kinematic behavior that it enables. We build a generalized kinematic model that enables the design of RAE-patterned actuators and reveal the distinct auxetic behavior of RAE actuators with comparable model accuracy to the legacy McKibben actuators. A simple, reproducible way of designing and fabricating RAE actuators is described and varied prototypes are shown. This RAE-based design scheme can be used to create actuators with specified kinematics like bending, extension, and radial expansion, which can also vary across the actuator's surface both circumferentially and axially in a tractable, scalable manner.
ER  - 

TY  - CONF
TI  - A Unified Controller for Region-reaching and Deforming of Soft Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 472
EP  - 478
AU  - Z. Wang
AU  - X. Li
AU  - D. Navarro-Alarcon
AU  - Y. Liu
PY  - 2018
KW  - cameras
KW  - closed loop systems
KW  - deformation
KW  - end effectors
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - stability
KW  - uncertain deformation model
KW  - active deformable object manipulation
KW  - unified controller
KW  - soft objects
KW  - robotic manipulation
KW  - robot control
KW  - region reaching
KW  - region deforming
KW  - uncalibrated cameras
KW  - closed-loop system stability
KW  - end-effector
KW  - Strain
KW  - Deformable models
KW  - Cameras
KW  - End effectors
KW  - Robot vision systems
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8593543
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Emerging applications of robotic manipulation of deformable objects have opened up new challenges in robot control. While several control techniques have been developed to manipulate deformable objects, the performance of existing methods is commonly limited by two issues: 1) implicit assumption that the physical contact between the end-effector and the object is always maintained, and 2) requirements of exact parameters of deformation model, which are difficult to obtain. This paper presents a new control scheme for robotic manipulation of deformable objects, which allows the robot to automatically contact then actively deform the deformable object by assessing the status of deformation in real time. Instead of designing multiple controllers and switching among them, the proposed method smoothly and stably integrates two control phases (i.e. region reaching and active deforming) into a single controller. The stability of the closed-loop system is rigorously proved with the consideration of the uncertain deformation model and uncalibrated cameras. Hence, the proposed control scheme enhances the autonomous capability of active deformable object manipulation. Experimental studies are conducted with different initial conditions to demonstrate the performance of the proposed controller.
ER  - 

TY  - CONF
TI  - Dual-arm robotic manipulation of flexible cables
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 479
EP  - 484
AU  - J. Zhu
AU  - B. Navarro
AU  - P. Fraisse
AU  - A. Crosnier
AU  - A. Cherubini
PY  - 2018
KW  - cables (mechanical)
KW  - deformation
KW  - Fourier series
KW  - manipulator dynamics
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - velocity control
KW  - arm robotic manipulation
KW  - flexible cables
KW  - trivial task
KW  - multiple robot manipulators
KW  - local deformation model
KW  - shape parameters
KW  - dual-arm manipulator
KW  - cable shape manipulation
KW  - Shape
KW  - Strain
KW  - Power cables
KW  - Deformable models
KW  - Manipulators
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593780
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deforming a cable to a desired (reachable) shape is a trivial task for a human to do without even knowing the internal dynamics of the cable. This paper proposes a framework for cable shapes manipulation with multiple robot manipulators. The shape is parameterized by a Fourier series. A local deformation model of the cable is estimated on-line with the shape parameters. Using the deformation model, a velocity control law is applied on the robot to deform the cable into the desired shape. Experiments on a dual-arm manipulator are conducted to validate the framework.
ER  - 

TY  - CONF
TI  - Towards vision-based manipulation of plastic materials
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 485
EP  - 490
AU  - A. Cherubini
AU  - J. Leitner
AU  - V. Ortenzi
AU  - P. Corke
PY  - 2018
KW  - deformation
KW  - manipulators
KW  - object tracking
KW  - plastic products
KW  - robot vision
KW  - vision-based manipulation
KW  - plastic materials
KW  - object deformation
KW  - visual tracking
KW  - visual error
KW  - deformable objects
KW  - kinetic sand shaping
KW  - Task analysis
KW  - Robots
KW  - Shape
KW  - Plastics
KW  - Visualization
KW  - Deformable models
KW  - Strain
KW  - Manipulation
KW  - visual servoing
KW  - human studies
KW  - learning
DO  - 10.1109/IROS.2018.8594108
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper represents a step towards vision-based manipulation of plastic materials. Manipulating deformable objects is made challenging by: 1) the absence of a model for the object deformation, 2) the inherent difficulty of visual tracking of deformable objects, 3) the difficulty in defining a visual error and 4) the difficulty in generating control inputs to minimise the visual error. We propose a novel representation of the task of manipulating deformable objects. In this preliminary case study, the shaping of kinetic sand, we assume a finite set of actions: pushing, tapping and incising. We consider that these action types affect only a subset of the state, i.e., their effect does not affect the entire state of the system (specialized actions). We report the results of a user study to validate these hypotheses and release the recorded dataset. The actions (pushing, tapping and incising) are clearly adopted during the task, although it is clear that 1) participants use also mixed actions and 2) actions' effects can marginally affect the entire state, requesting a relaxation of our specialized actions hypothesis. Moreover, we compute task errors and corresponding control inputs (in the image space) using image processing. Finally, we show how machine learning can be applied to infer the mapping from error to action on the data extracted from the user study.
ER  - 

TY  - CONF
TI  - Capturing Deformations of Interacting Non-rigid Objects Using RGB-D Data
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 491
EP  - 497
AU  - A. Petit
AU  - S. Cotin
AU  - V. Lippiello
AU  - B. Siciliano
PY  - 2018
KW  - computational geometry
KW  - finite element analysis
KW  - image colour analysis
KW  - image registration
KW  - image segmentation
KW  - image sequences
KW  - segmented point clouds
KW  - collision detection
KW  - joint registration framework
KW  - RGB-D sensor
KW  - point cloud data
KW  - elastic deformations
KW  - RGB-D data
KW  - interacting nonrigid objects
KW  - FEM elastic model
KW  - geometrical point-to-point correspondences
KW  - ICP algorithm
KW  - rigid transformations
KW  - RGB images
KW  - visual segmentation
KW  - Strain
KW  - Three-dimensional displays
KW  - Finite element analysis
KW  - Deformable models
KW  - Computational modeling
KW  - Collision avoidance
KW  - Visualization
DO  - 10.1109/IROS.2018.8593756
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a method for tracking multiple interacting deformable objects undergoing rigid motions, elastic deformations and contacts, using image and point cloud data provided by an RGB-D sensor. A joint registration frame-work is proposed, based on physical Finite Element Method (FEM) elastic and interaction models. It first relies on a visual segmentation of the considered objects in the RGB images. The different segmented point clouds are then processed to estimate rigid transformations with on an ICP algorithm, and to determine geometrical point-to-point correspondences with the meshes. External forces resulting from these correspondences and between the current and the rigidly transformed mesh can then be derived. It provides both non-rigid and rigid data cues. A classical collision detection and response model is also integrated, giving contact forces between the objects. The deformations of the objects are estimated by solving a dynamic system balancing these external and contact forces with the internal or regularization forces computed through the FEM elastic model. This approach has been here tested on different scenarios involving two or three interacting deformable objects of various shapes, with promising results.
ER  - 

TY  - CONF
TI  - Contact Detection and Size Estimation Using a Modular Soft Gripper with Embedded Flex Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 498
EP  - 503
AU  - K. Elgeneidy
AU  - G. Neumann
AU  - S. Pearson
AU  - M. Jackson
AU  - N. Lohse
PY  - 2018
KW  - bending
KW  - biomechanics
KW  - deformation
KW  - elastomers
KW  - feedback
KW  - grippers
KW  - mechanical contact
KW  - pneumatic actuators
KW  - pressure sensors
KW  - sensors
KW  - time series
KW  - modular soft gripper
KW  - utilizing interchangeable soft pneumatic actuators
KW  - embedded flex sensors
KW  - simple sensory feedback
KW  - pressure sensors
KW  - contact state
KW  - grasped object size
KW  - contact type
KW  - final flex sensor
KW  - object weight
KW  - soft fingers
KW  - flex sensor readings
KW  - soft elastomers
KW  - deformable objects
KW  - contact forces
KW  - contact feedback
KW  - Grippers
KW  - Sensors
KW  - Flexible printed circuits
KW  - Grasping
KW  - Thumb
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593399
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grippers made from soft elastomers are able to passively and gently adapt to their targets allowing deformable objects to be grasped safely without causing bruise or damage. However, it is difficult to regulate the contact forces due to the lack of contact feedback for such grippers. In this paper, a modular soft gripper is presented utilizing interchangeable soft pneumatic actuators with embedded flex sensors as fingers of the gripper. The fingers can be assembled in different configurations using 3D printed connectors. The paper investigates the potential of utilizing the simple sensory feedback from the flex and pressure sensors to make additional meaningful inferences regarding the contact state and grasped object size. We study the effect of the grasped object size and contact type on the combined feedback from the embedded flex sensors of opposing fingers. Our results show that a simple linear relationship exists between the grasped object size and the final flex sensor reading at fixed input conditions, despite the variation in object weight and contact type. Additionally, by simply monitoring the time series response from the flex sensor, contact can be detected by comparing the response to the known free-bending response at the same input conditions. Furthermore, by utilizing the measured internal pressure supplied to the soft fingers, it is possible to distinguish between power and pinch grasps, as the contact type affects the rate of change in the flex sensor readings against the internal pressure.
ER  - 

TY  - CONF
TI  - Online Shape Estimation based on Tactile Sensing and Deformation Modeling for Robot Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 504
EP  - 511
AU  - J. Sanchez
AU  - C. M. Mateo
AU  - J. A. Corrales
AU  - B. Bouzgarrou
AU  - Y. Mezouar
PY  - 2018
KW  - dexterous manipulators
KW  - force control
KW  - image sensors
KW  - tactile sensors
KW  - deformation model
KW  - tactile sensor
KW  - deformable object
KW  - sensor model
KW  - online shape estimation
KW  - tactile sensing
KW  - deformation modeling
KW  - visual sensing
KW  - soft object
KW  - robot manipulation
KW  - shadow dexterous hand
KW  - BioTac sensors
KW  - RGB-D sensor
KW  - Strain
KW  - Robot sensing systems
KW  - Deformable models
KW  - Force
KW  - Shape
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594314
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precise robot manipulation of deformable objects requires an accurate and fast estimation of their shape as they deform. So far, visual sensing has been mostly used to solve this issue, but vision sensors are sensitive to occlusions, which might be inevitable when manipulating an object with robot. To address this issue, we present a modular pipeline to track the shape of a soft object in an online manner by coupling tactile sensing with a deformation model. Using a model of a tactile sensor, we compute the magnitude and location of a contact force and apply it as an external force to the deformation model. The deformation model then updates the nodal positions of a mesh that describes the shape of the deformable object. The proposed sensor model and pipeline, are evaluated using a Shadow Dexterous Hand equipped with BioTac sensors on its fingertips and an RGB-D sensor.
ER  - 

TY  - CONF
TI  - Accounting for Directional Rigidity and Constraints in Control for Manipulation of Deformable Objects without Physical Simulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 512
EP  - 519
AU  - M. Ruan
AU  - D. McConachie
AU  - D. Berenson
PY  - 2018
KW  - biomechanics
KW  - collision avoidance
KW  - deformation
KW  - finite element analysis
KW  - grippers
KW  - motion control
KW  - physiological models
KW  - shear modulus
KW  - springs (mechanical)
KW  - stress analysis
KW  - directional rigidity
KW  - deformable objects
KW  - physical simulation
KW  - physical models
KW  - control loop
KW  - practical controller
KW  - deformable object manipulation
KW  - effective controller
KW  - accurate geometric model
KW  - gripper motion
KW  - novel stretching avoidance constraint
KW  - physical robot
KW  - Grippers
KW  - Deformable models
KW  - Computational modeling
KW  - Robots
KW  - Predictive models
KW  - Finite element analysis
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594520
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deformable objects like cloth and rope are challenging to manipulate because it is difficult to predict the state of the object given a motion of the gripper(s) holding it. In much previous work, physical models (such as Mass-Spring or Finite-Element) have been used to model such affects. However, these models often require significant parameter tuning for each scenario and can be expensive to simulate inside a control loop. Furthermore, it is difficult to create a practical controller for deformable object manipulation that preserves constraints, especially avoiding overstretching the object. In this paper, we developed a more effective controller than previous work by (1) constructing a more accurate geometric model of how the direction of gripper motion and obstacles affect deformable objects; and (2) specifying a novel stretching avoidance constraint to prevent the object from being overstretched by the robot. Experiments comparing our new method to the previous method in simulation and on a physical robot suggest that our new model captures the behavior of the object more accurately. We also find that our controller is able to prevent tearing that would occur when using the previous method.
ER  - 

TY  - CONF
TI  - A Series Elastic Tactile Sensing Array for Tactile Exploration of Deformable and Rigid Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 520
EP  - 525
AU  - Z. Kappassov
AU  - D. Baimukashev
AU  - O. Adiyatov
AU  - S. Salakchinov
AU  - Y. Massalin
AU  - H. A. Varol
PY  - 2018
KW  - elasticity
KW  - manipulators
KW  - position control
KW  - tactile sensors
KW  - deformable objects
KW  - rigid objects
KW  - series elastic elements
KW  - sixteen compliant sensing elements
KW  - position-controlled robot manipulator
KW  - series elastic tactile array
KW  - contact location
KW  - tactile arrays
KW  - multiple sensing elements
KW  - vision-based sensors
KW  - robotic systems
KW  - tactile sensing arrays
KW  - tactile exploration
KW  - series elastic tactile sensing array
KW  - Magnetic sensors
KW  - Pins
KW  - Tactile sensors
KW  - Saturation magnetization
DO  - 10.1109/IROS.2018.8593755
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tactile sensing arrays are used to detect contacts of robotic systems with the environment. They are particularly useful for scenarios in which vision-based sensors cannot be used. Thanks to the presence of multiple sensing elements, tactile arrays also provide spatial information about the contact location. In this work, we present our series elastic tactile array to enable tactile exploration for position-controlled robot manipulators. Sixteen compliant sensing elements are arranged as a 4×4 array. This allows the position-controlled robot to explore objects via palpation. Tactile sensing was accomplished by measuring the change of the magnetic field caused by neodymium magnets embedded into the series elastic elements. We demonstrate the efficacy of our sensor with two sets of experiments involving physical interaction scenarios. Firstly, we show that the sensor can be used to differentiate between rigid and deformable objects. Secondly, we show that point clouds of objects can be generated quickly with our sensor module attached to a position-controlled robot manipulator as an end-effector.
ER  - 

TY  - CONF
TI  - Learning Symbolic Representations for Planning with Parameterized Skills
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 526
EP  - 533
AU  - B. Ames
AU  - A. Thackston
AU  - G. Konidaris
PY  - 2018
KW  - control engineering computing
KW  - humanoid robots
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - critical capability
KW  - generally intelligent robot behavior
KW  - goal-directed planning
KW  - black-box motor skills
KW  - intelligent robots
KW  - parametrized motor skills
KW  - simple discrete abstract representation
KW  - fixed plan
KW  - abstract symbolic representation
KW  - robot manipulation task
KW  - angry birds
KW  - virtual domain
KW  - Planning
KW  - Task analysis
KW  - Probabilistic logic
KW  - Intelligent robots
KW  - Birds
KW  - Computer science
DO  - 10.1109/IROS.2018.8594313
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A critical capability required for generally intelligent robot behavior is the ability to sequence motor skills to reach a goal. This requires a (typically abstract) representation that supports goal-directed planning, which raises the question of how to construct such a representation. Previous work has addressed this question in the context of simple black-box motor skills, which are insufficiently flexible to support the wide range of behavior required of intelligent robots. We now extend that work to include parametrized motor skills, where a robot must both select an action to execute and also decide how to parametrize it. We show how to construct a representation suitable for planning with parametrized motor skills, and specify conditions which are sufficient to separate the selection of motor skills from the parametrization of those skills. Our method results in a simple discrete abstract representation for planning followed by a parameter selection process that operates on a fixed plan. We first demonstrate learning this representation in a virtual domain based on Angry Birds and then learn an abstract symbolic representation for a robot manipulation task.
ER  - 

TY  - CONF
TI  - Regularizing Reinforcement Learning with State Abstraction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 534
EP  - 539
AU  - R. Akrour
AU  - F. Veiga
AU  - J. Peters
AU  - G. Neumann
PY  - 2018
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - pattern clustering
KW  - deep reinforcement learning performance
KW  - optimal sub-policies
KW  - state space clustering
KW  - hierarchical reinforcement learning algorithm
KW  - near-optimal policy
KW  - state cluster
KW  - abstract state
KW  - continuous action reinforcement learning
KW  - similar optimal action
KW  - discrete reinforcement
KW  - state abstraction
KW  - learned policy
KW  - Reinforcement learning
KW  - Complexity theory
KW  - Convergence
KW  - Shape
KW  - Clustering algorithms
KW  - Task analysis
KW  - Partitioning algorithms
DO  - 10.1109/IROS.2018.8594201
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - State abstraction in a discrete reinforcement learning setting clusters states sharing a similar optimal action to yield an easier to solve decision process. In this paper, we generalize the concept of state abstraction to continuous action reinforcement learning by defining an abstract state as a state cluster over which a near-optimal policy of simple shape exists. We propose a hierarchical reinforcement learning algorithm that is able to simultaneously find the state space clustering and the optimal sub-policies in each cluster. The main advantage of the proposed framework is to provide a straightforward way of regularizing reinforcement learning by controlling the behavioral complexity of the learned policy. We apply our algorithm on several benchmark tasks and a robot tactile manipulation task and show that we can match state-of-the-art deep reinforcement learning performance by combining a small number of linear policies.
ER  - 

TY  - CONF
TI  - CReaM: Condensed Real-time Models for Depth Prediction using Convolutional Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 540
EP  - 547
AU  - A. Spek
AU  - T. Dharmasiri
AU  - T. Drummond
PY  - 2018
KW  - convolutional neural nets
KW  - image classification
KW  - image segmentation
KW  - mobile robots
KW  - neurocontrollers
KW  - robot vision
KW  - CNNs
KW  - robotic vision community
KW  - semantic segmentation
KW  - surface curvature
KW  - robotic society
KW  - real-time structure prediction framework
KW  - NVIDIA-TX2
KW  - CReaM
KW  - real-time models
KW  - depth prediction
KW  - convolutional neural networks
KW  - classification
KW  - mobile platform
KW  - condensed model architectures
KW  - Real-time systems
KW  - Predictive models
KW  - Robots
KW  - Training
KW  - Modeling
KW  - Task analysis
KW  - Semantics
DO  - 10.1109/IROS.2018.8594243
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30 frames per second on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a “from teacher to student” style knowledge transfer.
ER  - 

TY  - CONF
TI  - Generating Adaptive Attending Behaviors using User State Classification and Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 548
EP  - 555
AU  - Y. Kohari
AU  - J. Miura
AU  - S. Oishi
PY  - 2018
KW  - behavioural sciences computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pattern classification
KW  - deep deterministic policy gradient
KW  - user state classification
KW  - deep reinforcement learning
KW  - user information
KW  - adaptive attending behavior generation
KW  - DDPG
KW  - mobile robots
KW  - Legged locomotion
KW  - Reinforcement learning
KW  - Two dimensional displays
KW  - Cameras
KW  - Acceleration
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594427
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a method of generating attending behaviors adaptively to the user state. The method classifies the user state based on user information such as the relative position and the orientation. For each classified state, the method executes the corresponding policy for behavior generation, which has been trained using a deep reinforcement learning, namely DDPG (deep deterministic policy gradient). We use as a state space of DDPG a distance-transformed local map with person information, and define reward functions suitable for respective user states. We conducted attending experiments both in a simulated and a real environment to show the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - A Bio-inspired Reinforcement Learning Rule to Optimise Dynamical Neural Networks for Robot Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 556
EP  - 561
AU  - T. Wei
AU  - B. Webb
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - neurocontrollers
KW  - recurrent neural nets
KW  - back-propagation
KW  - 2D bipedal walking simulation
KW  - biological neural circuits
KW  - robot control
KW  - optimise dynamical neural networks
KW  - bio-inspired reinforcement
KW  - bio-inspired central pattern generator layer
KW  - recurrent neural network
KW  - learning rule
KW  - network weights
KW  - biological synapses
KW  - reinforcement learning approach
KW  - Neurons
KW  - Robots
KW  - Synapses
KW  - Oscillators
KW  - Task analysis
KW  - Biological neural networks
DO  - 10.1109/IROS.2018.8594017
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most approaches for optimisation of neural networks are based on variants of back-propagation. This requires the network to be time invariant and differentiable; neural networks with dynamics are thus generally outside the scope of these methods. Biological neural circuits are highly dynamic yet clearly able to support learning. We propose a reinforcement learning approach inspired by the mechanisms and dynamics of biological synapses. The network weights undergo spontaneous fluctuations, and a reward signal modulates the centre and amplitude of fluctuations to converge to a desired network behaviour. We test the new learning rule on a 2D bipedal walking simulation, using a control system that combines a recurrent neural network, a bio-inspired central pattern generator layer and proportional-integral control, and demonstrate the first successful solution to this benchmark task.
ER  - 

TY  - CONF
TI  - Teaching Robots to Predict Human Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 562
EP  - 567
AU  - L. Gui
AU  - K. Zhang
AU  - Y. Wang
AU  - X. Liang
AU  - J. M. F. Moura
AU  - M. Veloso
PY  - 2018
KW  - human-robot interaction
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - robot vision
KW  - deep learning
KW  - superior prediction performance
KW  - human moves
KW  - human motion
KW  - teaching robots
KW  - motion GAN model
KW  - predicted sequence
KW  - generative adversarial networks
KW  - forecasting algorithms
KW  - high-level fidelity validation
KW  - motion predictor
KW  - historical sequence
KW  - OpenPose library
KW  - robot camera
KW  - computer vision techniques
KW  - prediction ability
KW  - human-robot interaction
KW  - historical human movements
KW  - Robots
KW  - Gallium nitride
KW  - Generative adversarial networks
KW  - Predictive models
KW  - Cameras
KW  - Skeleton
KW  - Decoding
DO  - 10.1109/IROS.2018.8594452
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Teaching a robot to predict and mimic how a human moves or acts in the near future by observing a series of historical human movements is a crucial first step in human-robot interaction and collaboration. In this paper, we instrument a robot with such a prediction ability by leveraging recent deep learning and computer vision techniques. First, our system takes images from the robot camera as input to produce the corresponding human skeleton based on real-time human pose estimation obtained with the OpenPose library. Then, conditioning on this historical sequence, the robot forecasts plausible motion through a motion predictor, generating a corresponding demonstration. Because of a lack of high-level fidelity validation, existing forecasting algorithms suffer from error accumulation and inaccurate prediction. Inspired by generative adversarial networks (GANs), we introduce a global discriminator that examines whether the predicted sequence is smooth and realistic. Our resulting motion GAN model achieves superior prediction performance to state-of-the-art approaches when evaluated on the standard H3.6M dataset. Based on this motion GAN model, the robot demonstrates its ability to replay the predicted motion in a human-like manner when interacting with a person.
ER  - 

TY  - CONF
TI  - Variational Autoencoder for End-to-End Control of Autonomous Driving with Novelty Detection and Training De-biasing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 568
EP  - 575
AU  - A. Amini
AU  - W. Schwarting
AU  - G. Rosman
AU  - B. Araki
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - traffic engineering computing
KW  - variational autoencoder
KW  - end-to-end control
KW  - autonomous driving
KW  - novelty detection
KW  - end-to-end training
KW  - deep neural networks
KW  - DNN training
KW  - sufficient training data
KW  - trained models
KW  - insufficient training data
KW  - biased training data
KW  - self-supervised learning
KW  - latent variables
KW  - insufficiently trained situations
KW  - training data imbalance
KW  - latent distributions
KW  - training pipeline
KW  - full-scale autonomous vehicle
KW  - end-to-end controller
KW  - Training
KW  - Autonomous vehicles
KW  - Aerospace electronics
KW  - Image reconstruction
KW  - Training data
KW  - Data models
KW  - Robots
DO  - 10.1109/IROS.2018.8594386
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a new method for end-to-end training of deep neural networks (DNNs) and evaluates it in the context of autonomous driving. DNN training has been shown to result in high accuracy for perception to action learning given sufficient training data. However, the trained models may fail without warning in situations with insufficient or biased training data. In this paper, we propose and evaluate a novel architecture for self-supervised learning of latent variables to detect the insufficiently trained situations. Our method also addresses training data imbalance, by learning a set of underlying latent variables that characterize the training data and evaluate potential biases. We show how these latent distributions can be leveraged to adapt and accelerate the training pipeline by training on only a fraction of the total dataset. We evaluate our approach on a challenging dataset for driving. The data is collected from a full-scale autonomous vehicle. Our method provides qualitative explanation for the latent variables learned in the model. Finally, we show how our model can be additionally trained as an end-to-end controller, directly outputting a steering control command for an autonomous vehicle.
ER  - 

TY  - CONF
TI  - Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 576
EP  - 582
AU  - M. L. Iuzzolino
AU  - M. E. Walker
AU  - D. Szafir
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pattern classification
KW  - virtual-to-real-world transfer learning
KW  - deep learning models
KW  - virtual environments
KW  - model training
KW  - real-world trail data
KW  - robots
KW  - wilderness trails
KW  - outdoor trails
KW  - classification models
KW  - Cameras
KW  - Robot vision systems
KW  - Deep learning
KW  - Training
KW  - Navigation
KW  - Data collection
DO  - 10.1109/IROS.2018.8593883
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots hold promise in many scenarios involving outdoor use, such as search-and-rescue, wildlife management, and collecting data to improve environment, climate, and weather forecasting. However, autonomous navigation of outdoor trails remains a challenging problem. Recent work has sought to address this issue using deep learning. Although this approach has achieved state-of-the-art results, the deep learning paradigm may be limited due to a reliance on large amounts of annotated training data. Collecting and curating training datasets may not be feasible or practical in many situations, especially as trail conditions may change due to seasonal weather variations, storms, and natural erosion. In this paper, we explore an approach to address this issue through virtual-to-real-world transfer learning using a variety of deep learning models trained to classify the direction of a trail in an image. Our approach utilizes synthetic data gathered from virtual environments for model training, bypassing the need to collect a large amount of real images of the outdoors. We validate our approach in three main ways. First, we demonstrate that our models achieve classification accuracies upwards of 95% on our synthetic data set. Next, we utilize our classification models in the control system of a simulated robot to demonstrate feasibility. Finally, we evaluate our models on real-world trail data and demonstrate the potential of virtual-to-real-world transfer learning.
ER  - 

TY  - CONF
TI  - High-frame-rate Target Tracking with CNN-based Object Recognition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 599
EP  - 606
AU  - M. Jiang
AU  - Y. Gu
AU  - T. Takaki
AU  - I. Ishii
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object recognition
KW  - object tracking
KW  - target tracking
KW  - tracking
KW  - vision platform
KW  - visual feedback
KW  - pre-learned objects
KW  - tracking performance
KW  - pan-tilt active vision system
KW  - complex-shaped target
KW  - hybridized tracking algorithm
KW  - prototype intelligent mechanical tracking system
KW  - deep learning-based recognition algorithm
KW  - fast tracking method
KW  - intelligent tracking method
KW  - CNN-based object recognition
KW  - high-frame-rate target tracking
KW  - frequency 500.0 Hz
KW  - Target tracking
KW  - Correlation
KW  - Visualization
KW  - Cameras
KW  - Object recognition
KW  - Deep learning
DO  - 10.1109/IROS.2018.8594300
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an intelligent and fast tracking method for robust trackability against appearance changes. The method hybridizes a correlation-based tracking algorithm operating at hundreds of frames per second (fps) with a deep learning-based recognition algorithm operating at dozens of fps. A prototype intelligent mechanical tracking system was developed by implementing our hybridized tracking algorithm on a 500-fps vision platform. A complex-shaped target can be robustly tracked at the center of the camera view in real time by controlling a pan-tilt active vision system with 500 Hz visual feedback. The tracking performance of our proposed algorithm was verified by showing several experimental results for pre-learned objects, which were quickly manipulated against complex backgrounds.
ER  - 

TY  - CONF
TI  - Real-Time Edge Template Tracking via Homography Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 607
EP  - 612
AU  - X. Qin
AU  - S. He
AU  - Z. Zhang
AU  - M. Dehghan
AU  - J. Jin
AU  - M. Jagersand
PY  - 2018
KW  - edge detection
KW  - feature extraction
KW  - image sampling
KW  - image sequences
KW  - image texture
KW  - target tracking
KW  - transforms
KW  - video signal processing
KW  - homography estimation
KW  - planar edge templates
KW  - homography transformations
KW  - sampled edge pixels
KW  - Lucas-Kanade-like algorithm
KW  - low textured targets
KW  - edge template tracking
KW  - nonLambertian objects
KW  - video sequences
KW  - Image edge detection
KW  - Target tracking
KW  - Real-time systems
KW  - Video sequences
KW  - Cost function
KW  - Transforms
DO  - 10.1109/IROS.2018.8593551
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel real-time method for tracking planar edge templates. This method tracks an edge template by estimating its homography transformations with respect to the sampled edge pixels detected from the incoming frames. Particularly, we define a cost function based on a new feature map of the to-be-tracked edge template and optimize it by a Lucas-Kanade-like algorithm. The feature map is defined as the fourth root of the distance transform. Our method operates on just edges so that it is good at tracking those low textured targets, such as hollow targets (mug rim), thin targets (cable, ring) and non-Lambertian objects (disc). We validate and compare our method with four other methods on five newly collected real-world video sequences. The results achieves the lowest overall average error (1.58 pixels) and also outperforms others in terms of success rate. The per frame processing time of about 30 ms proves that our method is acceptable in realtime applications. The code and dataset are publicly available at: http://webdocs.cs.ualberta.ca/~xuebin/.
ER  - 

TY  - CONF
TI  - Robust Model-Predictive Deformation Control of a Soft Object by Using a Flexible Continuum Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 613
EP  - 618
AU  - B. Ouyang
AU  - H. Mo
AU  - H. Chen
AU  - Y. Liu
AU  - D. Sun
PY  - 2018
KW  - deformation
KW  - Jacobian matrices
KW  - manipulators
KW  - mobile robots
KW  - nonlinear control systems
KW  - predictive control
KW  - robust control
KW  - surgery
KW  - robust model-predictive deformation control
KW  - soft object
KW  - flexible continuum robot
KW  - soft tissues
KW  - prediction horizon-based controller
KW  - Strain
KW  - Jacobian matrices
KW  - Force
KW  - Deformable models
KW  - Uncertainty
KW  - End effectors
DO  - 10.1109/IROS.2018.8593880
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flexible continuum robots have exhibited unique advantages in working in an unstructured environment. Many applications require robots to actively control the deformation of soft objects, such as soft tissues in surgery. Thus, this study presents a robust model-predictive deformation control of a soft object using a flexible continuum robot. A linear approximation model for mapping from actuation space of a continuum robot to deformation space of a soft object is established. Jacobian matrix is estimated online by using a robust Geman-McClure estimator. Then, the deformation of the soft object is regulated by using a prediction horizon-based controller with exponential weighting for model uncertainty. The proposed control approach is effective in manipulating a soft object with a flexible continuum robot that is in contact with obstacles.
ER  - 

TY  - CONF
TI  - Closed form solution for Rotation Estimation using Photometric Spherical Moments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 627
EP  - 634
AU  - H. Hadj-Abdelkader
AU  - O. Tahri
AU  - H. Benseddik
PY  - 2018
KW  - cameras
KW  - motion estimation
KW  - photometry
KW  - 3D rotation estimation
KW  - geometrical features
KW  - catadioptric camera
KW  - synthetic images
KW  - cost function
KW  - spherical moment properties
KW  - spherical images
KW  - photometric spherical moments
KW  - Cameras
KW  - Estimation
KW  - Three-dimensional displays
KW  - Visual servoing
KW  - Closed-form solutions
KW  - Motion estimation
DO  - 10.1109/IROS.2018.8593920
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents new schemes to estimate 3D rotation from spherical images. Unlike existing approaches, spherical moment properties are exploited to obtain a closed form solution without iteratively mimimizing a cost function. Actually, three methods using spherical moments are proposed: two of them can be classified as dense approaches, while the third one is hybrid combining geometrical features with dense ones. Experimental results using both synthetic images and acquired images using catadioptric cameras with different scenarios show the effectiveness of our approach.
ER  - 

TY  - CONF
TI  - City-Scale Road Audit System using Deep Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 635
EP  - 640
AU  - S. Yarram
AU  - G. Varma
AU  - C. V. Jawahar
PY  - 2018
KW  - Global Positioning System
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - roads
KW  - traffic engineering computing
KW  - image tagging
KW  - GPS
KW  - multistep deep learning
KW  - road networks
KW  - city-scale road audit system
KW  - label hierarchy
KW  - road defects
KW  - semantic segmentation
KW  - Roads
KW  - Image segmentation
KW  - Semantics
KW  - Deep learning
KW  - Global Positioning System
KW  - Cameras
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594363
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Road networks in cities are massive and is a critical component of mobility. Fast response to defects, that can occur not only due to regular wear and tear but also because of extreme events like storms, is essential. Hence there is a need for an automated system that is quick, scalable and cost-effective for gathering information about defects. We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation. For building and benchmarking the system, we curated a dataset which has annotations required for road defects. However, many of the labels required for road audit have high ambiguity which we overcome by proposing a label hierarchy. We also propose a multi-step deep learning model that segments the road, subdivide the road further into defects, tags the frame for each defect and finally localizes the defects on a map gathered using GPS. We analyze and evaluate the models on image tagging as well as segmentation at different levels of the label hierarchy.
ER  - 

TY  - CONF
TI  - Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 641
EP  - 648
AU  - N. R. Rypkema
AU  - E. M. Fischel
AU  - H. Schmidt
PY  - 2018
KW  - autonomous underwater vehicles
KW  - closed loop systems
KW  - computational complexity
KW  - hydrophones
KW  - inertial navigation
KW  - marine navigation
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - position control
KW  - localization
KW  - autonomous underwater vehicles
KW  - Doppler velocity log
KW  - positional error
KW  - acoustic beacon
KW  - DVL-aided INS
KW  - LBL system
KW  - SandShark AUV
KW  - underwater navigation
KW  - computational complexity
KW  - phased-array beamforming
KW  - closed-loop operation
KW  - particle filter
KW  - vehicle-mounted passive hydrophone receiver-array
KW  - multiAUV operations
KW  - power requirements
KW  - inertial navigation system
KW  - robotic vehicle
KW  - Acoustics
KW  - Navigation
KW  - Array signal processing
KW  - Receivers
KW  - Acoustic measurements
KW  - Transponders
KW  - Time-frequency analysis
DO  - 10.1109/IROS.2018.8593626
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.
ER  - 

TY  - CONF
TI  - Unscented Kalman Filter on Lie Groups for Visual Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 649
EP  - 655
AU  - M. Brossard
AU  - S. Bonnabel
AU  - A. Barrau
PY  - 2018
KW  - distance measurement
KW  - Kalman filters
KW  - Lie groups
KW  - nonlinear filters
KW  - SLAM (robots)
KW  - state estimation
KW  - stereo image processing
KW  - unscented Kalman filter
KW  - Lie groups
KW  - visual information
KW  - inertial measurements
KW  - state estimation
KW  - robust estimation
KW  - computational efficiency
KW  - low-cost aerial vehicles
KW  - processor power
KW  - innovative filter
KW  - stereo visual inertial odometry building
KW  - invariant filtering theory
KW  - computational complexity
KW  - stereo multistate constraint Kalman filter
KW  - EuRoC dataset
KW  - MAV outdoor dataset
KW  - Cameras
KW  - Kalman filters
KW  - Visualization
KW  - Computational modeling
KW  - Uncertainty
KW  - Robustness
KW  - Noise measurement
KW  - Lie groups
KW  - unscented Kalman filter
KW  - visual inertial odometry
KW  - aerial vehicle
KW  - localization
DO  - 10.1109/IROS.2018.8593627
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fusing visual information with inertial measurements for state estimation has aroused major interests in recent years. However, combining a robust estimation with computational efficiency remains challenging, specifically for low-cost aerial vehicles in which the quality of the sensors and the processor power are constrained by size, weight and cost. In this paper, we present an innovative filter for stereo visual inertial odometry building on: (i) the recently introduced stereo multistate constraint Kalman filter; (ii) the invariant filtering theory; and (iii) the unscented Kalman filter (UKF) on Lie groups. Our solution combines accuracy, robustness and versatility of the UKF. We then compare our approach to state-of-art solutions in terms of accuracy, robustness and computational complexity on the EuRoC dataset and a challenging MAV outdoor dataset.
ER  - 

TY  - CONF
TI  - A Multi-Position Joint Particle Filtering Method for Vehicle Localization in Urban Area
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 656
EP  - 662
AU  - S. Gu
AU  - Z. Xiang
AU  - Y. Zhang
AU  - Q. Qian
PY  - 2018
KW  - distance measurement
KW  - image matching
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - path planning
KW  - probability
KW  - robot vision
KW  - flexible multiposition joint particle filtering
KW  - position error
KW  - anchor point
KW  - curving roads
KW  - ego-trajectory
KW  - probabilistic filtering method
KW  - flexible road map
KW  - long range navigation
KW  - error accumulation
KW  - visual odometry
KW  - traditional visual localization methods
KW  - autonomous vehicles
KW  - robust localization
KW  - urban area
KW  - vehicle localization
KW  - dense parallel road branches
KW  - Roads
KW  - Trajectory
KW  - Filtering
KW  - Urban areas
KW  - Wheels
KW  - Simultaneous localization and mapping
KW  - Navigation
DO  - 10.1109/IROS.2018.8593781
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust localization is a prerequisite for autonomous vehicles. Traditional visual localization methods like visual odometry suffer error accumulation on long range navigation. In this paper, a flexible road map based probabilistic filtering method is proposed to tackle this problem. To effectively match the ego-trajectory to various curving roads in map, a new representation based on anchor point (AP) which captures the main curving points on the trajectory is presented. Based on APs of the map and trajectory, a flexible Multi-Position Joint Particle Filtering (MPJPF) framework is proposed to correct the position error. The method features the capability of adaptively estimating a series of APs jointly and only updates the estimation at situations with low uncertainty. It explicitly avoids the drawbacks of obliging to determine the current position at large uncertain situations such as dense parallel road branches. The experiments carried out on KITTI benchmark demonstrate our success.
ER  - 

TY  - CONF
TI  - Courteous Autonomous Cars
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 663
EP  - 670
AU  - L. Sun
AU  - W. Zhan
AU  - M. Tomizuka
AU  - A. D. Dragan
PY  - 2018
KW  - automobiles
KW  - road traffic
KW  - traffic engineering computing
KW  - courteous autonomous cars
KW  - driving quality
KW  - cost function
KW  - purely selfish cost
KW  - interactive drivers
KW  - autonomous car
KW  - courtesy term
KW  - robot car
KW  - human behavior
KW  - courteous robot cars
KW  - human driver behavior
KW  - Autonomous automobiles
KW  - Vehicles
KW  - Cost function
KW  - Planning
KW  - Robot kinematics
KW  - Safety
DO  - 10.1109/IROS.2018.8593969
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.
ER  - 

TY  - CONF
TI  - Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 671
EP  - 677
AU  - K. Huang
AU  - C. Stachniss
PY  - 2018
KW  - automobiles
KW  - cameras
KW  - iterative methods
KW  - laser ranging
KW  - mobile robots
KW  - motion estimation
KW  - optical scanners
KW  - pose estimation
KW  - sensor fusion
KW  - SLAM (robots)
KW  - joint ego-motion estimation
KW  - laser scanner
KW  - monocular camera
KW  - autonomous vehicles
KW  - SLAM algorithms
KW  - sensor suite
KW  - laser range finder
KW  - 3D point clouds
KW  - iterative closest point problem
KW  - sensor modality
KW  - orientation estimation
KW  - autonomous cars
KW  - pose estimation
KW  - autonomous robots
KW  - 1-DoF ICP
KW  - data association
KW  - Cameras
KW  - Iterative closest point algorithm
KW  - Lasers
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Image color analysis
DO  - 10.1109/IROS.2018.8593965
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.
ER  - 

TY  - CONF
TI  - LandmarkBoost: Efficient visualContext Classifiers for Robust Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 677
EP  - 684
AU  - M. Dymczyk
AU  - I. Gilitschenski
AU  - J. Nieto
AU  - S. Lynen
AU  - B. Zeisl
AU  - R. Siegwart
PY  - 2018
KW  - image capture
KW  - image classification
KW  - image matching
KW  - image retrieval
KW  - nearest neighbour methods
KW  - pose estimation
KW  - search problems
KW  - stereo image processing
KW  - metric pose retrieval algorithms
KW  - image plane
KW  - state-of-the-art descriptor matching methods
KW  - visualContext classifiers
KW  - binary descriptors
KW  - robust localization
KW  - Landmark-Boost
KW  - boosting framework
KW  - contextual information
KW  - landmark observations
KW  - boosted classifier
KW  - landmark classification task
KW  - 2D-3D matching methods
KW  - visual context
KW  - mobile platforms
KW  - nearest neighbor search
KW  - reliable pose retrieval algorithms
KW  - Visualization
KW  - Feature extraction
KW  - Measurement
KW  - Robots
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Context modeling
DO  - 10.1109/IROS.2018.8594100
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The growing popularity of autonomous systems creates a need for reliable and efficient metric pose retrieval algorithms. Currently used approaches tend to rely on nearest neighbor search of binary descriptors to perform the 2D-3D matching and guarantee realtime capabilities on mobile platforms. These methods struggle, however, with the growing size of the map, changes in viewpoint or appearance, and visual aliasing present in the environment. The rigidly defined descriptor patterns only capture a limited neighborhood of the keypoint and completely ignore the overall visual context. We propose LandmarkBoost - an approach that, in contrast to the conventional 2D-3D matching methods, casts the search problem as a landmark classification task. We use a boosted classifier to classify landmark observations and directly obtain correspondences as classifier scores. We also introduce a formulation of visual context that is flexible, efficient to compute, and can capture relationships in the entire image plane. The original binary descriptors are augmented with contextual information and informative features are selected by the boosting framework. Through detailed experiments, we evaluate the retrieval quality and performance of Landmark-Boost, demonstrating that it outperforms common state-of-the-art descriptor matching methods.
ER  - 

TY  - CONF
TI  - Fire-Aware Planning of Aerial Trajectories and Ignitions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 685
EP  - 692
AU  - E. Beachly
AU  - C. Detweiler
AU  - S. Elbaum
AU  - B. Duncan
AU  - C. Hildebrandt
AU  - D. Twidwell
AU  - C. Allen
PY  - 2018
KW  - aerospace computing
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - computer simulation
KW  - helicopters
KW  - ignition
KW  - path planning
KW  - trajectory control
KW  - wildfires
KW  - fire-aware planning
KW  - aerial trajectories
KW  - fire vectors
KW  - fire simulation
KW  - fire-aware planner
KW  - fire simulator predictions
KW  - ignition spheres
KW  - unmanned aerial system for prescribed fires
KW  - helicopter
KW  - UAS-Rx Android application
KW  - Ignition
KW  - Robots
KW  - Computational modeling
KW  - Planning
KW  - Sensors
KW  - Mathematical model
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593568
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Prescribed fires can lessen wildfire severity and control invasive species, but they can also be risky and costly. Unmanned aerial systems can reduce those drawbacks by, for example, dropping ignition spheres to ignite the most hazardous areas. Existing systems, however, lack awareness of the fire vectors to operate autonomously, safely, and efficiently. In this work we address that limitation, introducing an approach that integrates a lightweight fire simulator and a planner for trajectories and ignition sphere drop waypoints. Both components are unique in that they are amenable to input from the system's sensors and the fire crew to increase fire awareness. We conducted a preliminary study that confirms that such inputs improve the accuracy of the fire simulation to counter the unpredictability of the target environment. The field study of the system showed that the fire-aware planner generated safe trajectories with effective ignitions leveraging the fire simulator predictions.
ER  - 

TY  - CONF
TI  - Embedding Temporally Consistent Depth Recovery for Real-time Dense Mapping in Visual-inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 693
EP  - 698
AU  - H. Cheng
AU  - Z. Zheng
AU  - J. He
AU  - C. Chen
AU  - K. Wang
AU  - L. Lin
PY  - 2018
KW  - distance measurement
KW  - image reconstruction
KW  - interpolation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - real-time dense mapping
KW  - visual-inertial odometry
KW  - dense scene information
KW  - fast self-localization
KW  - VIO-based SLAM systems
KW  - VIO depth estimations
KW  - subspace-based stabilization scheme
KW  - temporal consistency
KW  - edge-preserving depth interpolation
KW  - simultaneous localization and mapping
KW  - learning-based methods
KW  - embedding temporally consistent depth recovery
KW  - Simultaneous localization and mapping
KW  - Real-time systems
KW  - Feature extraction
KW  - Pipelines
KW  - Interpolation
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593917
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dense mapping is always the desire of simultaneous localization and mapping (SLAM), especially for the applications that require fast and dense scene information. Visual-inertial odometry (VIO) is a light-weight and effective solution to fast self-localization. However, VIO-based SLAM systems have difficulty in providing dense mapping results due to the spatial sparsity and temporal instability of the VIO depth estimations. Although there have been great efforts on real-time mapping and depth recovery from sparse measurements, the existing solutions for VIO-based SLAM still fail to preserve sufficient geometry details in their results. In this paper, we propose to embed depth recovery into VIO-based SLAM for real-time dense mapping. In the proposed method, we present a subspace-based stabilization scheme to maintain the temporal consistency and design a hierarchical pipeline for edge-preserving depth interpolation to reduce the computational burden. Numerous experiments demonstrate that our method can achieve an accuracy improvement of up to 49.1 cm compared to state-of-the-art learning-based methods for depth recovery and reconstruct sufficient geometric details in dense mapping when only 0.07% depth samples are available. Since a simple CPU implementation of our method already runs at 10-20 fps, we believe our method is very favorable for practical SLAM systems with critical computational requirements.
ER  - 

TY  - CONF
TI  - Fractional-Order Trajectory-Following Control for Two-Legged Dynamic Walking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 699
EP  - 704
AU  - K. Leyden
AU  - B. Goodwine
PY  - 2018
KW  - control system synthesis
KW  - energy conservation
KW  - legged locomotion
KW  - motion control
KW  - PD control
KW  - position control
KW  - robot dynamics
KW  - simulated walker
KW  - two-legged dynamic walking
KW  - walking robots
KW  - energy consumption
KW  - energy efficiency
KW  - fractional-order trajectory-following control
KW  - proportional-derivative architecture
KW  - Legged locomotion
KW  - Mathematical model
KW  - Gravity
KW  - Aerodynamics
KW  - PD control
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593749
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This research seeks greater efficiency for walking robots. Efficiency can be improved in two ways: better performance (i.e., less wasted motion) and reduced energy consumption. Fractional-order control is a pathway to both of these improvements because of the flexibility it offers in designing a control strategy. Compared to the existing proportional-derivative architecture, changing the order of the derivative - the number of derivatives taken - to real numbers other than 1 has yielded both types of improvement for a simulated walker. The evidence of better performance is the leg angles' improvement in maintaining a desired relationship with respect to one another. Depending on the controller chosen, the walker can also be made to achieve the original level of performance with reduced control signals and less torque delivered to the hip joint, implying greater energy efficiency.
ER  - 

TY  - CONF
TI  - Walking on a Steep Slope Using a Rope by a Life-Size Humanoid Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 705
EP  - 712
AU  - M. Bando
AU  - M. Murooka
AU  - S. Nozawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - friction
KW  - humanoid robots
KW  - least squares approximations
KW  - mobile robots
KW  - motion control
KW  - friction force
KW  - linear least-square problem
KW  - life-size humanoid robot HRP-2
KW  - rope
KW  - steep slope
KW  - Legged locomotion
KW  - Friction
KW  - Robot kinematics
KW  - Humanoid robots
KW  - Force
KW  - Foot
DO  - 10.1109/IROS.2018.8594292
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose methods for walking on a steep slope using a rope by a humanoid robot. There are two difficulties for walking on a steep slope without a rope. First, range of motion of ankle joints get limited. Second, feet of a robot slip on a steep slope. For these problems, using a rope is effective solution because the robot can receive enough friction force from the slope and walk on a steep slope by pulling a rope with proper tension. In addition, the robot pulling a rope on a slope can relax limitations of ankle joints. Therefore, we propose methods to determine tension of a grasped rope by solving a linear least-square problem considering deformability of a rope. With these methods, a life-size humanoid robot HRP-2 could walk on a steep slope which angle is 40 degree.
ER  - 

TY  - CONF
TI  - Perception Based Locomotion System for a Humanoid Robot with Adaptive Footstep Compensation under Task Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 713
EP  - 719
AU  - I. Kumagai
AU  - M. Morisawa
AU  - S. Nakaoka
AU  - T. Sakaguchi
AU  - H. Kaminaga
AU  - K. Kaneko
AU  - F. Kanehiro
PY  - 2018
KW  - adaptive control
KW  - collision avoidance
KW  - humanoid robots
KW  - interpolation
KW  - legged locomotion
KW  - path planning
KW  - task constraints
KW  - humanoid robot
KW  - adaptive footstep compensation
KW  - adaptive locomotion system
KW  - local error correction
KW  - perception based locomotion system
KW  - locomotion error
KW  - locomotion planning
KW  - point cloud
KW  - environmental measurements
KW  - plane estimation
KW  - space interpolation
KW  - collision avoidance
KW  - laser scans
KW  - Humanoid robots
KW  - Task analysis
KW  - Planning
KW  - Foot
KW  - Three-dimensional displays
KW  - Estimation
DO  - 10.1109/IROS.2018.8593553
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to accurately reach a target position while executing a task which imposes occlusion or constraints of the posture, a humanoid robot requires an adaptive locomotion system, which can comprehensively integrate localization, environmental mapping, global locomotion planning and local error correction. In this paper, we propose a method of constructing a perception based locomotion system for a humanoid robot. The major contribution of this paper is solving a problem of the locomotion error caused by the task constraints, by locally compensating footsteps and assessing the need for global footstep re-planning online based on environmental measurements. The proposed system provides an accurate and dense ground point cloud, called HeightField, using plane estimation and space interpolation, and obstacle point cloud for frequent collision avoidance by accumulating laser scans. This environmental perception enables a humanoid robot to plan footsteps globally even in the situation where the sight of the robot is limited and compensate footsteps while estimating landing state during locomotion online with the localization result. We evaluated the practicality of the proposed system by applying it to our humanoid robot carrying a heavy object in a construction site and confirmed that the proposed system contributed to improved locomotion abilities of a humanoid robot engaging in heavy-duty or dangerous tasks.
ER  - 

TY  - CONF
TI  - Adaptive step rotation in biped walking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 720
EP  - 725
AU  - N. Bohórquez
AU  - P. Wieber
PY  - 2018
KW  - legged locomotion
KW  - predictive control
KW  - quadratic programming
KW  - adaptive step rotation
KW  - biped walking
KW  - fixed feet rotation
KW  - nonlinear solvers
KW  - safe linear constraints
KW  - model predictive control schemes
KW  - robot walking
KW  - sequential quadratic program
KW  - Legged locomotion
KW  - Foot
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Dynamics
KW  - Predictive control
DO  - 10.1109/IROS.2018.8594431
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We want to enable the robot to reorient its feet in order to face its direction of motion. Model Predictive Control schemes for biped walking usually assume fixed feet rotation since adapting them online leads to a nonlinear problem. Nonlinear solvers do not guarantee the satisfaction of nonlinear constraints at every iterate and this can be problematic for the real-time operation of robots. We propose to define safe linear constraints that are always inside the intersection of the nonlinear constraints. We make simulations of the robot walking on a crowd and compare the performance of the proposed method with respect to the original nonlinear problem solved as a Sequential Quadratic Program.
ER  - 

TY  - CONF
TI  - Implementing Full-body Torque Control in Humanoid Robot with High Gear Ratio Using Pulse Width Modulation Voltage
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 726
EP  - 732
AU  - K. Lee
AU  - O. Sim
AU  - H. Jeong
AU  - J. Oh
AU  - H. Bae
AU  - S. Hong
AU  - J. Oh
PY  - 2018
KW  - electric current control
KW  - gears
KW  - humanoid robots
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot dynamics
KW  - torque control
KW  - voltage control
KW  - full-body torque control
KW  - high gear ratio
KW  - pulse width modulation voltage
KW  - motor torque
KW  - current control
KW  - joint torque control
KW  - robot dynamics
KW  - humanoid robot
KW  - position control
KW  - legged robots
KW  - Torque
KW  - Robots
KW  - Resistance
KW  - Aerodynamics
KW  - Temperature sensors
KW  - Modeling
KW  - Torque control
DO  - 10.1109/IROS.2018.8593908
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most state-of-the-art torque control-based legged robots show excellent performance, exceeding that of conventional position control-based robots. Many conventional position control-based legged robots have high gear ratios, but do not have joint torque sensors. In addition, some robots cannot generate current for controlling the motor torque. To apply torque control-based walking algorithms to a position control-based humanoid robot, we proposed current control using a motor thermal model and realized joint torque control by compensating for the joint dynamics and robot dynamics. We conducted experiments to verify the performance of the Hubo2 platform developed in 2008 by applying a full-body dynamics control framework. The results confirmed the possibility of using torque control algorithms with existing position-based robots.
ER  - 

TY  - CONF
TI  - Towards Minimal Intervention Control with Competing Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 733
EP  - 738
AU  - Y. Huang
AU  - J. Silvério
AU  - D. G. Caldwell
PY  - 2018
KW  - control engineering computing
KW  - control system synthesis
KW  - learning (artificial intelligence)
KW  - linear quadratic control
KW  - optimal control
KW  - robot programming
KW  - trajectory control
KW  - task execution
KW  - trajectory constraints
KW  - information-theory
KW  - finite horizon linear quadratic regulator
KW  - Cartesian space
KW  - pure trajectory generation
KW  - imitation learning algorithms
KW  - simulated robot
KW  - robot null space
KW  - optimal control
KW  - minimal intervention control strategy
KW  - Aerospace electronics
KW  - Trajectory
KW  - Null space
KW  - Task analysis
KW  - Probabilistic logic
KW  - End effectors
DO  - 10.1109/IROS.2018.8594235
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As many imitation learning algorithms focus on pure trajectory generation in either Cartesian space or joint space, the problem of considering competing trajectory constraints from both spaces still presents several challenges. In particular, when perturbations are applied to the robot, the underlying controller should take into account the importance of each space for the task execution, and compute the control effort accordingly. However, no such controller formulation exists. In this paper, we provide a minimal intervention control strategy that simultaneously addresses the problems of optimal control and competing constraints between Cartesian and joint spaces. In light of the inconsistency between Cartesian and joint constraints, we exploit the robot null space from an information-theory perspective so as to reduce the corresponding conflict. An optimal solution to the aforementioned controller is derived and furthermore a connection to the classical finite horizon linear quadratic regulator (LQR) is provided. Finally, a writing task in a simulated robot verifies the effectiveness of our approach.
ER  - 

TY  - CONF
TI  - Design and Evaluation of Torque Based Bipedal Walking Control System That Prevent Fall Over by Impulsive Disturbance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 739
EP  - 746
AU  - T. Shirai
AU  - Y. Nagamatsu
AU  - H. Suzuki
AU  - S. Nozawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - torque control
KW  - torque based bipedal walking control system
KW  - impulsive disturbance
KW  - bipedal robot control system
KW  - robust online walking controller
KW  - leg sweep disturbance
KW  - distributed system
KW  - sensorless whole body torque control method
KW  - Robot sensing systems
KW  - Torque
KW  - Legged locomotion
KW  - Actuators
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594334
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we develop a bipedal robot control system that has an ability to perform instantaneous high power and flexibility to absorb an impulsive disturbance. We utilize a sensor-less whole body torque control method executed in a high responsive realtime distributed system. This system also includes a robust online walking controller that can avoid fall over caused by a strong collision with the robot's legs. We evaluated the proposed control system by hitting a rubber ball or adding a leg sweep disturbance and verified the functionality of the absorbing motion and the balance restoring motion.
ER  - 

TY  - CONF
TI  - Humanoid Robot COM Kinematics Estimation based on Compliant Inverted Pendulum Model and Robust State Estimator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 747
EP  - 753
AU  - H. Bae
AU  - H. Jeong
AU  - J. Oh
AU  - K. Lee
AU  - J. Oh
PY  - 2018
KW  - elastic constants
KW  - estimation theory
KW  - humanoid robots
KW  - mobile robots
KW  - pendulums
KW  - robot kinematics
KW  - state estimation
KW  - mechanical deformation
KW  - damper
KW  - limited structural stiffness
KW  - humanoid robot COM kinematics estimation
KW  - center of mass
KW  - sing-mass model
KW  - robust state estimator
KW  - compliant inverted pendulum model
KW  - Humanoid robots
KW  - Mathematical model
KW  - State estimation
KW  - Kinematics
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593966
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work proposes a humanoid robot center of mass (COM) estimation framework based on the compliant inverted pendulum model and the robust estimator. Humanoids' limited structural stiffness and relatively long legs result in undesired flexibility, and this undesired motion hinders the state estimation. The models used in previous studies were either not suitable for estimation or too simple to express these key characteristics of humanoid robots. Here, to enhance the estimation performance, the compliant inverted pendulum model, which is developed by attaching a spring and damper to the original pendulum, is adopted. The additional elements can represent the mechanical deformation and undesired flexibility. This model can reflect the important characteristics of the humanoid robot while taking advantage of the merits of the sing-mass model. In addition, a robust state estimator that was proposed in our previous work is adopted to compensate for an estimation error caused by a modeling error. Using these two factors, an improved COM kinematics estimates could be obtained.
ER  - 

TY  - CONF
TI  - Robotic Sewing and Knot Tying for Personalized Stent Graft Manufacturing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 754
EP  - 760
AU  - Y. Hu
AU  - L. Zhang
AU  - W. Li
AU  - G. Yang
PY  - 2018
KW  - closed loop systems
KW  - medical robotics
KW  - robot vision
KW  - servomechanisms
KW  - stents
KW  - surgery
KW  - textile technology
KW  - visual servoing
KW  - robotic system
KW  - stitch size planning
KW  - 3D industrial sewing
KW  - successive knot
KW  - tension control
KW  - thread management
KW  - thread manipulator
KW  - stitch sizes
KW  - sewing accuracy
KW  - automated knot tying
KW  - closed-loop visual servoing control
KW  - customized robotic sewing device
KW  - 3D structured object
KW  - personalized stent graft manufacturing
KW  - size 2.0 mm to 5.0 mm
KW  - Needles
KW  - Robot kinematics
KW  - Cameras
KW  - Yarn
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8594021
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a versatile robotic system for sewing a 3D structured object. Leveraging on using a customized robotic sewing device and closed-loop visual servoing control, an all-in-one solution for sewing personalized stent graft is demonstrated. Stitch size planning and automated knot tying are proposed as two key functions of the system. By using effective stitch size planning, sub-millimetre sewing accuracy is achieved for stitch sizes ranging from 2mm to 5mm. In addition, a thread manipulator for thread management and tension control is also proposed to perform successive knot tying to secure each stitch. Detailed laboratory experiments have been performed to evaluate the proposed instruments and allied algorithms. The proposed framework can be generalised to a wide range of applications including 3D industrial sewing, as well as transferred to other clinical areas such as surgical suturing.
ER  - 


TY  - CONF
TI  - Estimation of Interaction Forces in Robotic Surgery using a Semi-Supervised Deep Neural Network Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 761
EP  - 768
AU  - A. Marban
AU  - V. Srinivasan
AU  - W. Samek
AU  - J. Fernández
AU  - A. Casals
PY  - 2018
KW  - force feedback
KW  - image reconstruction
KW  - image representation
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - neural nets
KW  - surgery
KW  - unsupervised learning
KW  - video signal processing
KW  - interaction forces
KW  - force estimation task
KW  - LSTM network
KW  - RGB frame
KW  - CAE
KW  - Convolutional Auto-Encoder
KW  - Long-Short Term Memory network
KW  - encoder network
KW  - SemiSupervised Learning framework
KW  - SL techniques
KW  - UL
KW  - Unsupervised Learning method
KW  - video frame
KW  - compact representation
KW  - unlabeled video sequences
KW  - video sequence
KW  - Supervised Learning setting
KW  - Vision-Based Force Sensing
KW  - current Robot-Assisted Minimally Invasive Surgery systems
KW  - force feedback
KW  - semisupervised deep neural network model
KW  - robotic surgery
KW  - Video sequences
KW  - Force
KW  - Tools
KW  - Robot sensing systems
KW  - Surgery
KW  - Estimation
KW  - Vision Based Force Sensing
KW  - Robotic Surgery
KW  - Deep Neural Networks
KW  - Semi-Supervised Learning
DO  - 10.1109/IROS.2018.8593701
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Providing force feedback as a feature in current Robot-Assisted Minimally Invasive Surgery systems still remains a challenge. In recent years, Vision-Based Force Sensing (VBFS) has emerged as a promising approach to address this problem. Existing methods have been developed in a Supervised Learning (SL) setting. Nonetheless, most of the video sequences related to robotic surgery are not provided with ground-truth force data, which can be easily acquired in a controlled environment. A powerful approach to process unlabeled video sequences and find a compact representation for each video frame relies on using an Unsupervised Learning (UL) method. Afterward, a model trained in an SL setting can take advantage of the available ground-truth force data. In the present work, UL and SL techniques are used to investigate a model in a Semi-Supervised Learning (SSL) framework, consisting of an encoder network and a Long-Short Term Memory (LSTM) network. First, a Convolutional Auto-Encoder (CAE) is trained to learn a compact representation for each RGB frame in a video sequence. To facilitate the reconstruction of high and low frequencies found in images, this CAE is optimized using an adversarial framework and a L1-loss, respectively. Thereafter, the encoder network of the CAE is serially connected with an LSTM network and trained jointly to minimize the difference between ground-truth and estimated force data. Datasets addressing the force estimation task are scarce. Therefore, the experiments have been validated in a custom dataset. The results suggest that the proposed approach is promising.
ER  - 

TY  - CONF
TI  - Cross-Scene Suture Thread Parsing for Robot Assisted Anastomosis based on Joint Feature Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 769
EP  - 776
AU  - Y. Gu
AU  - Y. Hu
AU  - L. Zhang
AU  - J. Yang
AU  - G. Yang
PY  - 2018
KW  - feature extraction
KW  - manipulators
KW  - medical computing
KW  - medical robotics
KW  - object detection
KW  - surgery
KW  - unsupervised learning
KW  - joint feature learning framework
KW  - background adaptation
KW  - surgical suture thread detection
KW  - unsupervised domain adaptation
KW  - labelled training data
KW  - partially labelled target domain
KW  - organs
KW  - adversarial learning
KW  - cross-scene suture thread parsing
KW  - task autonomy
KW  - robot-assisted anastomosis
KW  - automatic thread detection
KW  - surgical robots
KW  - robot manipulation
KW  - surgical settings
KW  - foreground adaptation
KW  - semisupervised domain adaptation
KW  - detection model learning
KW  - semantic identity
KW  - Yarn
KW  - Task analysis
KW  - Instruction sets
KW  - Adaptation models
KW  - Image segmentation
KW  - Surgery
KW  - Splines (mathematics)
DO  - 10.1109/IROS.2018.8593622
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Task autonomy is an important consideration for the development of future surgical robots. For robot-assisted anastomosis, suture thread detection is a prerequisite for subsequent robot manipulation. Previous works on automatic thread detection are focused on the learning of the models with specific surgical settings that are poorly generalisable to generic settings. In this paper, we propose a joint feature learning framework that caters for the foreground and background adaptation for surgical suture thread detection. The proposed method is developed in the context of semi-supervised and unsupervised domain adaptation, leveraging the labelled training data from the source domain to learn the detection model for unlabelled or partially labelled target domain, which can also be from different types of threads or organs. Based on adversarial learning, we further preserve the semantic identity and introduce curriculum adaptation to generate synthetic data. Experiments on four domain adaptation tasks for suture thread detection demonstrate the strength of the proposed method being able to generate good quality synthetic data and transfer between specific domains with limited or even no labelled data of the target domain.
ER  - 

TY  - CONF
TI  - Unsupervised Trajectory Segmentation and Promoting of Multi-Modal Surgical Demonstrations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 777
EP  - 782
AU  - Z. Shao
AU  - H. Zhao
AU  - J. Xie
AU  - Y. Qu
AU  - Y. Guan
AU  - J. Tan
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - medical robotics
KW  - robot kinematics
KW  - surgery
KW  - unsupervised learning
KW  - video signal processing
KW  - wavelet transforms
KW  - multimodal surgical demonstrations
KW  - surgical trajectory segmentation
KW  - robot learning
KW  - robot-assisted minimally invasive surgery
KW  - kinematic data
KW  - over-segmentation issue
KW  - unsupervised deep learning network
KW  - convolutional auto-encoder
KW  - videos
KW  - unsupervised trajectory segmentation method
KW  - JIGSAWS dataset
KW  - wavelet transform
KW  - feature extraction
KW  - Kinematics
KW  - Feature extraction
KW  - Surgery
KW  - Trajectory
KW  - Convolution
KW  - Visualization
KW  - Wavelet transforms
DO  - 10.1109/IROS.2018.8593379
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To improve the efficiency of surgical trajectory segmentation for robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. Unsupervised deep learning network, stacking convolutional auto-encoder, is employed to extract more discriminative features from videos in an effective way. To further improve the accuracy of segmentation, on one hand, wavelet transform is used to filter out the noises existed in the features from video and kinematic data. On the other hand, the segmentation result is promoted by identifying the adjacent segments with no state transition based on the predefined similarity measurements. Extensive experiments on a public dataset JIGSAWS show that our method achieves much higher accuracy of segmentation than state-of-the-art methods in the shorter time.
ER  - 

TY  - CONF
TI  - Autonomous Localization, Navigation and Haustral Fold Detection for Robotic Endoscopy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 783
EP  - 790
AU  - J. M. Prendergast
AU  - G. A. Formosa
AU  - C. R. Heckman
AU  - M. E. Rentschler
PY  - 2018
KW  - biological organs
KW  - biomedical optical imaging
KW  - cancer
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - surgery
KW  - autonomous localization
KW  - Haustral fold detection
KW  - robotic endoscopy
KW  - capsule endoscopes
KW  - minimally invasive devices
KW  - gastrointestinal abnormalities
KW  - colorectal cancer
KW  - real-time navigation system
KW  - observational devices
KW  - autonomous navigation
KW  - single minimally invasive device
KW  - vision system
KW  - autonomous lumen center tracking
KW  - haustral fold identification
KW  - multiple haustral folds
KW  - robotic endoscope platform
KW  - active simulator
KW  - real-time localization
KW  - center tracking algorithm
KW  - colonoscopy
KW  - in vivo video
KW  - surgical tools
KW  - mobility system
KW  - Endoscopes
KW  - Robot sensing systems
KW  - Colon
KW  - Navigation
KW  - Wheels
KW  - In vivo
DO  - 10.1109/IROS.2018.8594106
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Capsule endoscopes have gained popularity over the last decade as minimally invasive devices for diagnosing gastrointestinal abnormalities such as colorectal cancer. While this technology offers a less invasive and more convenient alternative to traditional scopes, these capsules are only able to provide observational capabilities due to their passive nature. With the addition of a reliable mobility system and a real-time navigation system, capsule endoscopes could transform from observational devices into active surgical tools, offering biopsy and therapeutic capabilities and even autonomous navigation in a single minimally invasive device. In this work, a vision system is developed to allow for autonomous lumen center tracking and haustral fold identification and tracking during colonoscopy. This system is tested for its ability to accurately identify and track multiple haustral folds across many frames in both simulated and in vivo video, and the lumen center tracking is tested onboard a robotic endoscope platform (REP) within an active simulator to demonstrate autonomous navigation. In addition, real-time localization is demonstrated using open source ORB-SLAM2. The vision system successfully identified 95.6% of Haustral folds in simulator frames and 70.6% in in vivo frames and false positives occurred in less than 1% of frames. The center tracking algorithm showed in vivo center estimates within a mean error of 6.6% of physician estimates and allowed for the REP to traverse 2 m of the active simulator in 6 minutes without intervention.
ER  - 

TY  - CONF
TI  - Towards to a Robotic Assisted System for Percutaneous Nephrolithotomy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 791
EP  - 797
AU  - H. Li
AU  - I. Paranawithana
AU  - Z. H. Chau
AU  - L. Yang
AU  - T. S. K. Lim
AU  - S. Foong
AU  - F. C. Ng
AU  - U. Tan
PY  - 2018
KW  - biomedical ultrasonics
KW  - kidney
KW  - medical robotics
KW  - needles
KW  - skin
KW  - surgery
KW  - ultrasonic therapy
KW  - target kidney stone
KW  - surgeon
KW  - robotic assisted system
KW  - percutaneous nephrolithotomy
KW  - recommended treatment method
KW  - kidney stone removal
KW  - percutaneous access
KW  - targeted calyx
KW  - flank skin
KW  - surgical performance
KW  - ultrasound probe
KW  - respiratory motion
KW  - percutaneous target
KW  - Surgery
KW  - Needles
KW  - Probes
KW  - Robot sensing systems
KW  - Force
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593689
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Percutaneous Nephrolithotomy is a recommended treatment method for large kidney stone removal. However, the first and most important step, i.e., getting the percutaneous access to create the tract between the targeted calyx and the flank skin, is challenging as the surgeon is often occupied by several tasks at a given time. Therefore, in this paper, we propose a robotic assisted system that collaborates with the surgeon and provides assistance in order for the surgeons to focus on more critical jobs resulting in better surgical performance. A procedure for this robot including three working stages is described. This procedure allows the surgeon to choose a suitable percutaneous target using an ultrasound probe based on his or her experience and the robot will track the respiratory motion of the target kidney stone and insert the needle automatically after the surgeon releases the probe. Experiments are conducted to demonstrate the procedure with the proposed assisted robot for PCNL.
ER  - 

TY  - CONF
TI  - On Muscle Activation for Improving Robotic Rehabilitation after Spinal Cord Injury
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 798
EP  - 805
AU  - R. Cheng
AU  - Y. Sui
AU  - D. Sayenko
AU  - J. W. Burdick
PY  - 2018
KW  - biomechanics
KW  - electromyography
KW  - injuries
KW  - medical robotics
KW  - neuromuscular stimulation
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - motor activation patterns
KW  - improved standing ability
KW  - SCI patients
KW  - healthy activity
KW  - improving robotic rehabilitation
KW  - spinal cord stimulation
KW  - motor complete spinal cord injury
KW  - recovered motor activity
KW  - motor training
KW  - spinal stimulation
KW  - bipedal standing
KW  - spinal rehabilitation therapies
KW  - healthy subjects
KW  - muscle activation patterns
KW  - SCI patient motor activity
KW  - healthy motor activity
KW  - healthy standing muscle activity
KW  - patient stand training
KW  - Electromyography
KW  - Muscles
KW  - Training
KW  - Electrical stimulation
KW  - Robot sensing systems
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593973
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Spinal cord stimulation (SCS) has recently enabled humans with motor complete spinal cord injury (SCI) to independently stand and recover some lost autonomic function. However, the nature of the recovered motor activity and the interplay between SCS and motor training are not well understood. Understanding the effect of stand training and spinal stimulation on motor activity during bipedal standing is important for designing spinal rehabilitation therapies that seek to combine spinal stimulation and rehabilitative robots. In this study, we examined electromyography (EMG) data gathered from two SCI patients and six healthy subjects as they attempted standing. We analyzed the muscle activation patterns and EMG waveform shape to quantify both the changes in SCI patient motor activity with training, and the differences between healthy motor activity and SCI patient motor activity under stimulation. We also looked for correlations between the similarity in SCI patients' motor activity to healthy subjects and their overall standing ability. We found that good standing in SCI patients does not emulate healthy standing muscle activity. Furthermore, patient stand training heavily influenced motor activation patterns, but not in ways that improved standing ability. These results indicate that current training techniques do not optimally influence motor activity, and robotic rehabilitation strategies for SCI patients should target essential features of motor activity to optimize functional performance, rather than emulate healthy activity.
ER  - 

TY  - CONF
TI  - Printing Strain Gauges on Intuitive Surgical da Vinci Robot End Effectors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 806
EP  - 812
AU  - R. Peña
AU  - M. J. Smith
AU  - N. P. Ontiveros
AU  - F. L. Hammond
AU  - R. J. Wood
PY  - 2018
KW  - biomedical equipment
KW  - biomedical measurement
KW  - end effectors
KW  - force feedback
KW  - medical robotics
KW  - needles
KW  - strain gauges
KW  - surgery
KW  - printing strain gauges
KW  - robotic surgery
KW  - strain gauge printing method
KW  - da Vinci surgical robot end effectors
KW  - additive deposition-based sensor fabrication method
KW  - vapor-deposition-based sensor fabrication method
KW  - sensor performance
KW  - minimally invasive procedures
KW  - Sensors
KW  - Surface treatment
KW  - End effectors
KW  - Shafts
KW  - Strain
KW  - Strain measurement
KW  - Surgery
DO  - 10.1109/IROS.2018.8594517
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Force feedback during robotic surgery is critical in order to minimize potential injury to the patient and decrease recovery time from surgical procedures. Here we describe the use of a novel strain gauge printing method to apply low profile, low cost sensors directly to the surface of da Vinci surgical robot end effectors (Intuitive Surgical, Inc.) to sense deflection and provide force feedback. This additive, vapor-deposition-based sensor fabrication method is used to deposit strain gauges directly onto the surfaces of the end effectors with minimal disruption to the device and without the need for adhesives or machining operations. Initial experiments characterize sensor performance and indicate the applicability of the proposed approach for force feedback during minimally invasive procedures.
ER  - 

TY  - CONF
TI  - Group emotion recognition strategies for entertainment robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 813
EP  - 818
AU  - S. Cosentino
AU  - E. I. S. Randria
AU  - J. Lin
AU  - T. Pellegrini
AU  - S. Sessa
AU  - A. Takanishi
PY  - 2018
KW  - affective computing
KW  - cloud computing
KW  - emotion recognition
KW  - face recognition
KW  - humanoid robots
KW  - mobile robots
KW  - face API
KW  - human perceptions
KW  - assistive robotics
KW  - emotion API
KW  - Microsoft Azure cognitive services
KW  - Waseda entertainment robots
KW  - computer science
KW  - Ekman's extended Big Six emotional model
KW  - group emotion recognition strategies
KW  - affective computing
KW  - cloud-computing based solution
KW  - facial expression analysis
KW  - Face
KW  - Emotion recognition
KW  - Entertainment industry
KW  - Cameras
KW  - Humanoid robots
KW  - Mood
KW  - humanoid robot
KW  - entertainment robot
KW  - assistive robotics
KW  - emotion recognition
DO  - 10.1109/IROS.2018.8593503
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a system to determine the emotion of a group of people via facial expression analysis is proposed for the Waseda Entertainment Robots. General models and standard methods for emotion definition and recognition are briefly described, as well as strategies for computing the group global emotion, knowing the individual emotions of group members. This work is based on Ekman's extended “Big Six” emotional model, popular in Computer Science and Affective Computing. Emotion recognition via facial expression analysis is performed with a cloud-computing based solution, using Microsoft Azure Cognitive services. First, the performances of both the Face API to detect faces, and Emotion API, to compute emotion via face expression analysis, are tested. After that, a solution to compute the emotion of a group of people has been implemented and its performances compared to human perceptions. This work presents concepts and strategies which can be generalized for applications within the scope of assistive robotics and, more broadly, affective computing, wherever it will be necessary to determine the emotion of a group of people.
ER  - 

TY  - CONF
TI  - Learning How Pedestrians Navigate: A Deep Inverse Reinforcement Learning Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 819
EP  - 826
AU  - M. Fahad
AU  - Z. Chen
AU  - Y. Guo
PY  - 2018
KW  - collision avoidance
KW  - feature extraction
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - trajectory control
KW  - mobile robots
KW  - human robot interaction
KW  - robot navigation algorithms
KW  - human navigation behaviors
KW  - maximum entropy deep inverse reinforcement learning
KW  - nonlinear reward function
KW  - deep neural network approximation
KW  - social affinity map
KW  - human motion trajectories
KW  - learned reward function
KW  - natural social navigation behaviors
KW  - deep inverse reinforcement learning approach
KW  - pedestrian trajectories
KW  - MEDIRL algorithm
KW  - feature extraction
KW  - collision avoidance
KW  - pedestrians navigation
KW  - Navigation
KW  - Robots
KW  - Trajectory
KW  - Reinforcement learning
KW  - Collision avoidance
KW  - Neural networks
KW  - Entropy
DO  - 10.1109/IROS.2018.8593438
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humans and mobile robots will be increasingly cohabiting in the same environments, which has lead to an increase in studies on human robot interaction (HRI). One important topic in these studies is the development of robot navigation algorithms that are socially compliant to humans navigating in the same space. In this paper, we present a method to learn human navigation behaviors using maximum entropy deep inverse reinforcement learning (MEDIRL). We use a large open dataset of pedestrian trajectories collected in an uncontrolled environment as the expert demonstrations. Human navigation behaviors are captured by a nonlinear reward function through deep neural network (DNN) approximation. The developed MEDIRL algorithm takes feature inputs including social affinity map (SAM) that are extracted from human motion trajectories. We perform simulation experiments using the learned reward function, and the performance is evaluated comparing it with the real measured pedestrian trajectories in the dataset. The evaluation results show that the proposed method has acceptable prediction accuracy compared to other state-of-the-art methods, and it can generate pedestrian trajectories similar to real human trajectories with natural social navigation behaviors such as collision avoidance, leader-follower, and split-and-rejoin.
ER  - 

TY  - CONF
TI  - Situated Human–Robot Collaboration: predicting intent from grounded natural language
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 827
EP  - 833
AU  - J. Brawer
AU  - O. Mangin
AU  - A. Roncone
AU  - S. Widder
AU  - B. Scassellati
PY  - 2018
KW  - human-robot interaction
KW  - interactive systems
KW  - mobile robots
KW  - natural language processing
KW  - context models
KW  - collaborator
KW  - collaborative construction task
KW  - autonomous robot
KW  - task representations
KW  - naturalistic data sets
KW  - human-robot collaboration
KW  - grounded natural language
KW  - human teamwork
KW  - fluent interactions
KW  - nonverbal cues
KW  - robotic platforms
KW  - explicit commands
KW  - unequivocal representations
KW  - human partners
KW  - naturalistic speech
KW  - action selection
KW  - human-robot collaborative activities
KW  - separate speech
KW  - Task analysis
KW  - Collaboration
KW  - Context modeling
KW  - Natural languages
KW  - Tools
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593942
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Research in human teamwork shows that a key element of fluid and fluent interactions is the interpretation of implicit verbal and non-verbal cues in context. This poses an issue to robotic platforms, however, as they have historically worked best when controlled through explicit commands that have employed structured, unequivocal representations of the external world and their human partners. In this work, we present a framework for effectively grounding situated and naturalistic speech to action selection during human-robot collaborative activities. This is accomplished by maintaining and incrementally updating separate “speech” and “context” models that jointly classify a collaborator's utterance. We evaluate the efficacy of the system on a collaborative construction task with an autonomous robot and human participants. We first demonstrate that our system is capable of acquiring and deploying new task representations from limited and naturalistic data sets, and without any prior domain knowledge of language or the task itself. Finally, we show that our system is capable of significantly improving performance on an unfamiliar task after a one-shot exposure.
ER  - 

TY  - CONF
TI  - Social Coordination for Looking-Together Situations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 834
EP  - 841
AU  - S. Akita
AU  - S. Satake
AU  - M. Shiomi
AU  - M. Imai
AU  - T. Kanda
PY  - 2018
KW  - telerobotics
KW  - social coordination
KW  - looking-together situations
KW  - utility-maximizing behavior
KW  - joint utility
KW  - joint-utility computation
KW  - utility-yielding behavior
KW  - utility model
KW  - teleoperated robot
KW  - Robot kinematics
KW  - Wheelchairs
KW  - Legged locomotion
KW  - Computational modeling
KW  - Human-robot interaction
DO  - 10.1109/IROS.2018.8594141
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - People engage in social coordination without explicitly communicating when they are conflicting over spatial resources, e.g., a shop clerk who yields to customers the best place to view products. In this study, we proposed a method that achieves such social coordination with a robot. Our idea is that the social coordination between two agents can be represented as utility-maximizing behavior for joint utility rather than just by a single agent utility. That is, given that each agent's reasonable behavior can be represented as utility-maximizing behavior for single agent utility, we model each agent's plans for himself as well as for the partner agent. Moreover, superiority relationships exist in this joint-utility computation. Since each agent knows such superiority relationships, social coordination can be modeled as utility-yielding behavior based on informed superiority. We specifically focus on looking-together situations for which we developed a utility model. With simulations, we investigate whether the above joint-utility-based modeling successfully reproduces social coordination in looking-together situations. We conducted an experiment in a situation where a tele-operated robot and a customer together look at products in a shop environment. Our experimental results show that our proposed method enables the robot to socially coordinate spatial resources, yielding significantly more thoughtful, less-self-centered, and appropriate impressions than the alternate robot.
ER  - 

TY  - CONF
TI  - Policy Shaping with Supervisory Attention Driven Exploration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 842
EP  - 847
AU  - T. K. Faulkner
AU  - E. S. Short
AU  - A. L. Thomaz
PY  - 2018
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - policy shaping
KW  - robots
KW  - human supervision
KW  - human teacher
KW  - information-gathering actions
KW  - interactive reinforcement learning
KW  - interactive RL
KW  - Reinforcement learning
KW  - Task analysis
KW  - Negative feedback
KW  - Markov processes
KW  - Prediction algorithms
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8594312
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots deployed for long periods of time need to be able to explore and learn from their environment. One approach to this problem has been reinforcement learning (RL), in which robots receive rewards from the environment that allow them to choose optimal actions. To speed learning when human supervision is available, interactive reinforcement learning solicits feedback from a human teacher. However, this approach typically assumes that learning takes place under continuous supervision, which is unlikely to hold in long-term scenarios. We propose an extension to a method of interactive reinforcement learning, policy shaping, that takes into account human attention. Our approach enables better performance while unattended by favoring information-gathering actions when attended and actions that have received positive feedback when unattended. We test our approach in both simulation and on a robot, finding that our method learns faster than policy shaping and performs more safely than policy shaping while no one is paying attention to the robot.
ER  - 

TY  - CONF
TI  - Friendly Motion Learning towards Sustainable Human Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 848
EP  - 853
AU  - S. Sato
AU  - H. Kamide
AU  - Y. Mae
AU  - M. Kojima
AU  - T. Arai
PY  - 2018
KW  - convolutional neural nets
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - sustainable human robot interaction
KW  - interaction motion features
KW  - machine learning technique
KW  - convolution neural network
KW  - interaction behavior
KW  - human impression
KW  - friendly motion learning
KW  - Robots
KW  - Convolution
KW  - Neural networks
KW  - Decoding
KW  - Feature extraction
KW  - Mathematical model
KW  - Human-robot interaction
DO  - 10.1109/IROS.2018.8593432
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For generating interactive behavior of robot to build a long-term relationship between humans and robots, we focus on the difference in familiarity of the human behaviors during conversation. It is difficult to extract interaction motion features correlated to such familiarity as a model in manual. Therefore, we use a machine learning technique: convolution neural network to learn and generate interaction behavior with different familiarity. In the evaluation experiment, we generated interaction behavior using a convolution neural network, which learned from the behaviors of friendship and unknown relationship, who have high and low familiarity respectively. We evaluated how much such interaction behavior affect the human impression by questionnaire survey.
ER  - 

TY  - CONF
TI  - On the Robustness of Speech Emotion Recognition for Human-Robot Interaction with Deep Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 854
EP  - 860
AU  - E. Lakomkin
AU  - M. A. Zamani
AU  - C. Weber
AU  - S. Magg
AU  - S. Wermter
PY  - 2018
KW  - emotion recognition
KW  - humanoid robots
KW  - human-robot interaction
KW  - neural nets
KW  - speech recognition
KW  - acoustic events
KW  - iCub robot platform
KW  - neural approaches
KW  - speech emotion recognition
KW  - deep neural networks
KW  - human-robot collaboration
KW  - research community
KW  - neural network-based architectures
KW  - neural SER models
KW  - in-domain data
KW  - noisy conditions
KW  - state-of-the-art neural acoustic emotion recognition models
KW  - human-robot interaction scenarios
KW  - room conditions
KW  - Robots
KW  - Training
KW  - Emotion recognition
KW  - Data models
KW  - Speech recognition
KW  - Acoustics
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593571
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Speech emotion recognition (SER) is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.
ER  - 

TY  - CONF
TI  - Modeling Supervisor Safe Sets for Improving Collaboration in Human-Robot Teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 861
EP  - 868
AU  - D. L. McPherson
AU  - D. R. R. Scobee
AU  - J. Menke
AU  - A. Y. Yang
AU  - S. S. Sastry
PY  - 2018
KW  - cognition
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - reachability analysis
KW  - human-robot teams
KW  - human supervisor collaborates
KW  - optimization
KW  - reachability theory
KW  - robots dynamic
KW  - robot behavior
KW  - human behavior
KW  - cognitive resources
KW  - Robots
KW  - Safety
KW  - Trajectory
KW  - Level set
KW  - Noise measurement
KW  - Optimal control
KW  - Optimization
DO  - 10.1109/IROS.2018.8593865
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When a human supervisor collaborates with a team of robots, the human's attention is divided, and cognitive resources are at a premium. We aim to optimize the distribution of these resources and the flow of attention. To this end, we propose the model of an idealized supervisor to describe human behavior. Such a supervisor employs a potentially inaccurate internal model of the the robots' dynamics to judge safety. We represent these safety judgements by constructing a safe set from this internal model using reachability theory. When a robot leaves this safe set, the idealized supervisor will intervene to assist, regardless of whether or not the robot remains objectively safe. False positives, where a human supervisor incorrectly judges a robot to be in danger, needlessly consume supervisor attention. In this work, we propose a method that decreases false positives by learning the supervisor's safe set and using that information to govern robot behavior. We prove that robots behaving according to our approach will reduce the occurrence of false positives for our idealized supervisor model. Furthermore, we empirically validate our approach with a user study that demonstrates a significant (p = 0.0328) reduction in false positives for our method compared to a baseline safety controller.
ER  - 

TY  - CONF
TI  - Deep Semantic Lane Segmentation for Mapless Driving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 869
EP  - 875
AU  - A. Meyer
AU  - N. O. Salscheider
AU  - P. F. Orzechowski
AU  - C. Stiller
PY  - 2018
KW  - automobiles
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - path planning
KW  - road traffic
KW  - robot vision
KW  - deep semantic lane segmentation
KW  - autonomous driving systems
KW  - automated cars
KW  - sensor system
KW  - urban scenarios
KW  - deep neural network
KW  - lane semantics
KW  - road scene
KW  - mapless autonomous driving
KW  - street scenes
KW  - RGB images
KW  - lane detection
KW  - cityscapes dataset
KW  - Roads
KW  - Semantics
KW  - Neural networks
KW  - Image segmentation
KW  - Autonomous vehicles
KW  - Three-dimensional displays
KW  - Pipelines
DO  - 10.1109/IROS.2018.8594450
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In autonomous driving systems a strong relation to highly accurate maps is taken to be inevitable, although street scenes change frequently. However, a preferable system would be to equip the automated cars with a sensor system that is able to navigate urban scenarios without an accurate map. We present a novel pipeline using a deep neural network to detect lane semantics and topology given RGB images. On the basis of this classification, the information about the road scene can be extracted just from the sensor setup supporting mapless autonomous driving. In addition to superseding the huge effort of creating and maintaining highly accurate maps, our system reduces the need for precise localization. Using an extended Cityscapes dataset, we show accurate ego lane detection including lane semantics on challenging scenarios for autonomous driving.
ER  - 

TY  - CONF
TI  - Closed-Loop Robot Task Planning Based on Referring Expressions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 876
EP  - 881
AU  - D. Kuhner
AU  - J. Aldinger
AU  - F. Burget
AU  - M. Göbelbecker
AU  - W. Burgard
AU  - B. Nebel
PY  - 2018
KW  - adaptive control
KW  - closed loop systems
KW  - mobile robots
KW  - path planning
KW  - planning (artificial intelligence)
KW  - user interfaces
KW  - fetch-and-carry tasks
KW  - autonomous robots accessibility
KW  - user friendly
KW  - closed-loop robot task planning
KW  - complex task
KW  - automated planning
KW  - robotic systems
KW  - domain-independent planning system
KW  - goal formulation
KW  - referring expressions
KW  - adaptive control interface
KW  - manipulable objects
KW  - dynamic environments
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Natural languages
KW  - Graphical user interfaces
KW  - Glass
DO  - 10.1109/IROS.2018.8593371
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Increasing the accessibility of autonomous robots also for inexperienced users requires user-friendly and high-level control opportunities of robotic systems. While automated planning is able to decompose a complex task into a sequence of steps which reaches an intended goal, it is difficult to formulate such a goal without knowing the internals of the planning system and the exact capabilities of the robot. This becomes even more important in dynamic environments in which manipulable objects are subject to change. In this paper, we present an adaptive control interface which allows users to specify goals based on an internal world model by incrementally building referring expressions to the objects in the world. We consider fetch-and-carry tasks and automatically deduce potential high-level goals from the world model to make them available to the user. Based on its perceptions our system can react to changes in the environment by adapting the goal formulation within the domain-independent planning system.
ER  - 

TY  - CONF
TI  - Learning Robotic Grasping Strategy Based on Natural-Language Object Descriptions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 882
EP  - 887
AU  - A. B. Rao
AU  - K. Krishnan
AU  - H. He
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - robotic grasping strategy
KW  - natural-language object descriptions
KW  - anthropomorphic robotic hand
KW  - natural-language descriptions
KW  - learning-based approach
KW  - natural language description
KW  - object features
KW  - natural-language processing technique
KW  - grasp type
KW  - human grasping taxonomy
KW  - AR10 robotic hand
KW  - Robots
KW  - Grasping
KW  - Taxonomy
KW  - Shape
KW  - Natural language processing
KW  - Kinematics
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593886
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Given the description of an object, s physical attributes, humans can determine a proper strategy and grasp an object. This paper proposes an approach to determine grasping strategy for an anthropomorphic robotic hand simply based on natural-language descriptions of an object. A learning-based approach is proposed to help a robotic hand learn suitable grasp poses starting from the natural language description of the object. Object features are parsed from natural-language descriptions by using a customized natural-language processing technique. The most likely grasp type for the given object is learned from the human grasping taxonomy based on the parsed features. The grasping strategy generated by the proposed approach is evaluated both by simulation study and execution of the grasps on an AR10 robotic hand.
ER  - 

TY  - CONF
TI  - Semantic Grid Estimation with a Hybrid Bayesian and Deep Neural Network Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 888
EP  - 895
AU  - Ö. Erkent
AU  - C. Wolf
AU  - C. Laugier
AU  - D. S. Gonzalez
AU  - V. R. Cano
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - image colour analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - optical radar
KW  - particle filtering (numerical methods)
KW  - semantic grid estimation
KW  - hybrid Bayesian
KW  - deep neural network
KW  - autonomous vehicle setting
KW  - high-level semantic information
KW  - grid cell
KW  - semantic label
KW  - hybrid approach
KW  - semantic segmentation
KW  - monocular RGB images
KW  - supervised learning
KW  - labeled groundtruth data
KW  - occupancy grids
KW  - LIDAR data
KW  - generative Bayesian particle filter
KW  - geometric information
KW  - RGB data
KW  - Semantics
KW  - Image segmentation
KW  - Bayes methods
KW  - Laser radar
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Sensors
DO  - 10.1109/IROS.2018.8593434
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In an autonomous vehicle setting, we propose a method for the estimation of a semantic grid, i.e. a bird's eye grid centered on the car's position and aligned with its driving direction, which contains high-level semantic information about the environment and its actors. Each grid cell contains a semantic label with divers classes, as for instance {Road, Vegetation, Building, Pedestrian, Car...}. We propose a hybrid approach, which combines the advantages of two different methodologies: we use Deep Learning to perform semantic segmentation on monocular RGB images with supervised learning from labeled groundtruth data. We combine these segmentations with occupancy grids calculated from LIDAR data using a generative Bayesian particle filter. The fusion itself is carried out with a deep neural network, which learns to integrate geometric information from the LIDAR with semantic information from the RGB data. We tested our method on two datasets, namely the KITTI dataset, which is publicly available and widely used, and our own dataset obtained with our own platform, equipped with a LIDAR and various sensors. We largely outperform baselines which calculate the semantic grid either from the RGB image alone or from LIDAR output alone, showing the interest of this hybrid approach.
ER  - 

TY  - CONF
TI  - PRISM: Pose Registration for Integrated Semantic Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 896
EP  - 902
AU  - J. W. Hart
AU  - R. Shah
AU  - S. Kirmani
AU  - N. Walker
AU  - K. Baldauf
AU  - N. John
AU  - P. Stone
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - pose estimation
KW  - service robots
KW  - SLAM (robots)
KW  - computer science department
KW  - modern SLAM algorithms
KW  - map data
KW  - tedious manual process
KW  - automatically generated maps
KW  - PRISM
KW  - semantic markup
KW  - pose registration
KW  - integrated semantic
KW  - robotics applications
KW  - hotel
KW  - room service
KW  - hospital
KW  - medication
KW  - patient
KW  - UT Austin
KW  - autonomous mobile robots
KW  - BWIBots
KW  - building-wide intelligence project
KW  - Robots
KW  - Semantics
KW  - Three-dimensional displays
KW  - Cameras
KW  - Two dimensional displays
KW  - Computational modeling
KW  - Navigation
DO  - 10.1109/IROS.2018.8593681
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many robotics applications involve navigating to positions specified in terms of their semantic significance. A robot operating in a hotel may need to deliver room service to a named room. In a hospital, it may need to deliver medication to a patient's room. The Building-Wide Intelligence Project at UT Austin has been developing a fleet of autonomous mobile robots, called BWIBots, which perform tasks in the computer science department. Tasks include guiding a person, delivering a message, or bringing an object to a location such as an office, lecture hall, or classroom. The process of constructing a map that a robot can use for navigation has been simplified by modern SLAM algorithms. The attachment of semantics to map data, however, remains a tedious manual process of labeling locations in otherwise automatically generated maps. This paper introduces a system called PRISM to automate a step in this process by enabling a robot to localize door signs - a semantic markup intended to aid the human occupants of a building - and to annotate these locations in its map.
ER  - 

TY  - CONF
TI  - 3D Deep Object Recognition and Semantic Understanding for Visually-Guided Robotic Service
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 903
EP  - 910
AU  - S. Lee
AU  - A. M. Naguib
AU  - N. U. Islam
PY  - 2018
KW  - Bayes methods
KW  - convolutional neural nets
KW  - feature extraction
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - object recognition
KW  - ontologies (artificial intelligence)
KW  - robot vision
KW  - service robots
KW  - semantic understanding
KW  - visually-guided robotic service
KW  - visually-guided robotic errand service
KW  - visual environments
KW  - deep learning architecture
KW  - FER-CNN
KW  - layer-wise independent feedback connections
KW  - reconstructed features
KW  - object categories
KW  - 3D daily-life objects
KW  - recognition rate
KW  - ontology
KW  - feature extraction
KW  - 3D deep object recognition
KW  - adaptive Bayesian recognition framework
KW  - Three-dimensional displays
KW  - Bayes methods
KW  - Robots
KW  - Object recognition
KW  - Deep learning
KW  - Feature extraction
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593985
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For the success of visually-guided robotic errand service, it is critical to ensure dependability under various ill-conditioned visual environments. To this end, we have developed Adaptive Bayesian Recognition Framework in which in-situ selection of multiple sets of optimal features or evidences as well as proactive collection of sufficient evidences are proposed to implement the principle of dependability. The framework has shown excellent performance with a limited number of objects in a scene. However, there arises a need to extend the framework for handling a larger number of objects without performance degradation, while avoiding difficulty in feature engineering. To this end, a novel deep learning architecture, referred to here as FER-CNN, is introduced and integrated into the Adaptive Bayesian Recognition Framework. FER-CNN has capability of not only extracting but also reconstructing a hierarchy of features with the layer-wise independent feedback connections that can be trained. Reconstructed features representing parts of 3D objects then allow them to be semantically linked to ontology for exploring object categories and properties. Experiments are conducted in a home environment with real 3D daily-life objects as well as with the standard ModelNet dataset. In particular, it is shown that FER-CNN allows the number of objects and their categories to be extended by 10 and 5 times, respectively, while registering the recognition rate for ModelNet10 and ModelNet40 by 97% and 89.5%, respectively.
ER  - 

TY  - CONF
TI  - Semantic Mapping with Simultaneous Object Detection and Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 911
EP  - 918
AU  - Z. Zeng
AU  - Y. Zhou
AU  - O. C. Jenkins
AU  - K. Desingh
PY  - 2018
KW  - image sensors
KW  - mobile robots
KW  - object detection
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - semantic mapping problem
KW  - CT-Map method
KW  - six degree-of-freedom pose
KW  - pose estimation
KW  - RGB-D sensor
KW  - Michigan progress fetch robot
KW  - particle filtering algorithm
KW  - CRF
KW  - conditional random field
KW  - contextual temporal mapping
KW  - object localization
KW  - object detection
KW  - Semantics
KW  - Object detection
KW  - Context modeling
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Simultaneous localization and mapping
DO  - 10.1109/IROS.2018.8594205
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a filtering-based method for semantic mapping to simultaneously detect objects and localize their 6 degree-of-freedom pose. For our method, called Contextual Temporal Mapping (or CT-Map), we represent the semantic map as a belief over object classes and poses across an observed scene. Inference for the semantic mapping problem is then modeled in the form of a Conditional Random Field (CRF). CT-Map is a CRF that considers two forms of relationship potentials to account for contextual relations between objects and temporal consistency of object poses, as well as a measurement potential on observations. A particle filtering algorithm is then proposed to perform inference in the CT-Map model. We demonstrate the efficacy of the CT-Map method with a Michigan Progress Fetch robot equipped with a RGB-D sensor. Our results demonstrate that the particle filtering based inference of CT-Map provides improved object detection and pose estimation with respect to baseline methods that treat observations as independent samples of a scene.
ER  - 

TY  - CONF
TI  - Optimization-based Design and Analysis of Planar Rotary Springs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 927
EP  - 934
AU  - N. Georgiev
AU  - J. Burdick
PY  - 2018
KW  - actuators
KW  - finite element analysis
KW  - optimisation
KW  - robots
KW  - springs (mechanical)
KW  - torque
KW  - torsion
KW  - rotary series elastic actuator springs
KW  - rapid torsional loading
KW  - FEA
KW  - mechanical testing
KW  - planar rotary springs
KW  - optimization-based design method
KW  - robotics applications
KW  - Springs
KW  - Strain
KW  - Stress
KW  - Mathematical model
KW  - Robots
KW  - Actuators
KW  - Optimization
DO  - 10.1109/IROS.2018.8594186
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper develops new methods to design high performance rotary series elastic actuator springs for robotics applications. The approach is based on a spring arm mathematical model that was previously introduced by the authors. The key contribution is the development of an optimization-based design method which maximizes the springs' overall torque density through optimization of the arm profile. An improved analysis algorithm allows for rapid torsional loading response simulation with possible internal contacts between the spring arms. The proposed design and analysis algorithms are validated through FEA and prototype mechanical testing.
ER  - 

TY  - CONF
TI  - Quaternion Joint: Dexterous 3-DOF Joint Representing Quaternion Motion for High-Speed Safe Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 935
EP  - 942
AU  - Y. Kim
AU  - J. Kim
AU  - W. Jang
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - quaternion joint
KW  - wrist mechanism
KW  - tendon-driven mechanism
KW  - dexterous 3-DOF joint
KW  - quaternion motion
KW  - forward kinematics
KW  - inverse kinematics
KW  - lightweight manipulators
KW  - Wires
KW  - Wrist
KW  - Manipulators
KW  - Quaternions
KW  - Pulleys
KW  - Kinematics
DO  - 10.1109/IROS.2018.8594301
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a dexterous three degree-of-freedom (3-DOF) wrist mechanism with a large range of motion and uniform manipulability without singular points throughout the entire range of motion. It has a 2-DOF spherical pure rolling joint surrounded by two pairs of actuating wires, the motions of which directly represent the quaternion values of the joint; this joint is therefore named the quaternion joint. Based on this property, it has simple and clear forward and inverse kinematics and high manipulability. By adding a 1-DOF rotation joint at the distal end of the quaternion joint, it can be extended to a 3-DOF joint mechanism. To precisely approximate the spherical pure rolling motion in a confined central space, a novel parallel mechanism composed of three identical supporting linkages was introduced. Unlike conventional parallel mechanisms, it has a compact and simple structure with no interference among the supporting linkages. Because the wrist mechanism is a tendon-driven mechanism, and is thus suitable for lightweight manipulators, it is mounted to a low-inertia manipulator with high stiffness and strength, namely, LIMS2-AMBIDEX, which is an improved version of the authors' previous research. The basic concept and thorough theoretical analysis of the wrist mechanism are described herein, and the simulations and experiments conducted for a quantitative validation are presented.
ER  - 

TY  - CONF
TI  - Design of a 2 Motor 2 Degrees-of-Freedom Coupled Tendon-driven Joint Module
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 943
EP  - 948
AU  - W. Li
AU  - P. Chen
AU  - D. Bai
AU  - X. Zhu
AU  - S. Togo
AU  - H. Yokoi
AU  - Y. Jiang
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - design engineering
KW  - mobile robots
KW  - position control
KW  - hybrid-actuated structure
KW  - internally-separately-actuated structure
KW  - internally-coaxially-actuated structure
KW  - externally-actuated structure
KW  - tendon coupling
KW  - torque reallocation
KW  - 2 motor 2 degrees-of-freedom coupled tendon-driven joint module
KW  - anthropomorphic robot arm
KW  - 2M2D coupled tendon-driven joint module
KW  - motor position
KW  - Pulleys
KW  - Tendons
KW  - Torque
KW  - Manipulators
KW  - Couplings
KW  - Routing
DO  - 10.1109/IROS.2018.8594080
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A 2 motor 2 degrees-of-freedom (2M2D) coupled tendon driven joint module is proposed as a basic component for robot arms. Torque reallocation via tendon coupling can enhance the output torque of one single joint. According to the motor position, the joint module is classified into four types: the externally-actuated structure, the internally-coaxially-actuated structure, the internally-separately-actuated structure, and the hybrid-actuated structure. The four structures are analyzed and compared, and their implementation design examples are given. Experiments comparing the proposed joint module with directly-actuated traditional joint suggested that the 2M2D coupled tendon-driven joint module can obtain high control accuracy, and the torque reallocation via tendon coupling is effective to improve output torque. Additionally, an anthropomorphic robot arm with low weight and high payload was developed to show the utility of the proposed joint module.
ER  - 

TY  - CONF
TI  - A Differential Elastic Joint for Multi-linked Pipeline Inspection Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 949
EP  - 954
AU  - A. Kakogawa
AU  - S. Ma
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - inspection
KW  - mobile robots
KW  - pipelines
KW  - pipes
KW  - rubber
KW  - service robots
KW  - springs (mechanical)
KW  - bi-directional series elasticity
KW  - series elastic actuators
KW  - slippery inner surfaces
KW  - vertical pipes
KW  - pipe wall
KW  - multilinked pipeline inspection robots
KW  - differential elastic joint
KW  - differential elastic actuator
KW  - active joint
KW  - in-pipe inspections
KW  - Springs
KW  - Gears
KW  - Torque
KW  - Robots
KW  - Wheels
KW  - Inspection
KW  - Actuators
DO  - 10.1109/IROS.2018.8593872
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study presents a differential elastic joint for use in multi-linked pipeline inspection robots. Active joints to stretch against the pipe wall are essential for adapting robots to use in vertical pipes and slippery inner surfaces where a large traction force is required. Series elastic actuators with a high reduction system have typically been used to sense force/torque in such applications. However, compactness, power, and bi-directional series elasticity are required to conduct in-pipe inspections. In this study, we propose an active joint using a differential elastic actuator with a rubber spring for decreasing the size and increasing the stiffness of the joint. After describing the configuration of the differential elastic actuator that is suitable for our robot and the design theory of the rubber spring cross-section, we conducted experiments to verify its torque property.
ER  - 

TY  - CONF
TI  - A Novel Design of Extended Coaxial Spherical Joint Module for a New Modular Type-Multiple DOFs Robotic Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 955
EP  - 960
AU  - J. Lee
AU  - J. Noh
AU  - J. Yang
AU  - W. Yang
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - torque
KW  - design constraints
KW  - mechanical impedance reduction effect
KW  - E-CoSMo
KW  - extended coaxial spherical joint module
KW  - robot platform
KW  - coaxial spherical parallel mechanism
KW  - universal joint mechanism
KW  - mechanical performance
KW  - modular type-multiple DOFs robotic platform
KW  - single actuator
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593687
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this study, we propose an extended coaxial spherical joint module (E-CoSMo) with three to four degrees of freedom (DOFs) for a multi-DOF robot platform. The E-CoSMo consists of a coaxial spherical parallel mechanism (CSPM) with three DOFs and one extended DOF based on a universal joint mechanism (UJM) coaxially connected to the CSPM. This structure enables the application of serial link configuration (such as shoulder-elbow) with wide and universal ROMs while allowing all four actuators to be placed in the base. This makes the inertia of the moving link part to be dramatically reduced and thus contributes to decreasing the mechanical impedance of the multi-DOF robot system. In addition, through the effective design of the coaxial spherical joint module, the output rotational torque in a specific axial direction reaches approximately three times then the torque of a single actuator. To optimally implement this, we applied an optimal design approach that considers the mechanical performance and design constraints. The mechanical impedance reduction effect through the proposed module is discussed. The feasibility of the E-CoSMo is also verified through a dynamic simulation. Finally, the proposed mechanism is verified using a fabricated prototype.
ER  - 

TY  - CONF
TI  - A Novel Cable Actuation Mechanism for 2-DOF Hyper-redundant Bending Robot Composed of Pulleyless Rolling Joints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 961
EP  - 966
AU  - J. Suh
PY  - 2018
KW  - actuators
KW  - buckling
KW  - cables (mechanical)
KW  - catheters
KW  - endoscopes
KW  - fixtures
KW  - medical robotics
KW  - motion control
KW  - production engineering computing
KW  - pulleys
KW  - redundant manipulators
KW  - surgery
KW  - three-dimensional printing
KW  - hyper-redundant bending robot composed
KW  - pulleyless rolling joint
KW  - surgical robots
KW  - wire cables
KW  - robot joints
KW  - miniature joint structure
KW  - cable driver design
KW  - 3D printing
KW  - steerable endoscopes
KW  - Joints
KW  - Mechanical cables
KW  - Pulleys
KW  - Fasteners
KW  - Robots
KW  - Muscles
KW  - Hysteresis
DO  - 10.1109/IROS.2018.8593890
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many surgical robots are remotely actuated by means of wire cables. In the past, the cables wound around circular pulleys at the robot joints did not constitute a problem of the cable driver structure. However, the pulleys inside the joints are removed recently in order to miniaturize the joints, so a specially designed cable driver suitable for the miniature joint structure is required for stable driving. In this paper, we propose a novel cable driver design for driving a pulleyless rolling joint and extend it to 2-DOF structure. Then, the proposed cable driver is manufactured using 3D printing with the 2-DOF bending joint, and an experiment is performed to evaluate them using the prototype. The cable driver proposed in this paper can drive pulleyless rolling joints stably with low cable tension. In addition, it can decouple yaw and pitch motion of the joints completely, therefore it can be applied to a variety of thin robots and instruments including steerable endoscopes and surgical robots.
ER  - 

TY  - CONF
TI  - Design of Robotic Gripper with Constant Transmission Ratio Based on Twisted String Actuator: Concept and Evaluation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 967
EP  - 972
AU  - S. Nedelchev
AU  - I. Gaponov
AU  - J. Ryu
PY  - 2018
KW  - actuators
KW  - grippers
KW  - industrial robots
KW  - materials handling
KW  - mobile robots
KW  - robots
KW  - twisted string actuator
KW  - robotic systems
KW  - object handling
KW  - manipulation
KW  - modern engineering
KW  - robustness
KW  - gripper design
KW  - exhibits nearly-constant transmission ratio
KW  - efficient robotic gripper
KW  - practical gripper
KW  - designed device
KW  - Grippers
KW  - Force
KW  - Actuators
KW  - Kinematics
KW  - Mathematical model
KW  - Service robots
DO  - 10.1109/IROS.2018.8593794
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic systems for object handling and manipulation are hugely important for modern engineering and industry, with their efficiency, agility and robustness often depending on gripper design and performance. In this work, we investigate a gripper design that, when driven by a twisted string actuator, exhibits nearly-constant transmission ratio throughout its motion range. This allows for design of a highly-compact, modular and efficient robotic gripper driven by a low-power motor. We investigate kinematics of the device, experimentally verify developed models with a practical gripper testbed, and analyze transmission ratio and efficiency of the designed device. The resulting system has a nearly-constant transmission ratio of 550, with the constancy coefficient of 0.985.
ER  - 

TY  - CONF
TI  - Stopper Angle Design for a Multi-link Articulated Wheeled In-pipe Robot with Underactuated Twisting Joints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 973
EP  - 978
AU  - Y. Oka
AU  - A. Kakogawa
AU  - S. Ma
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - drives
KW  - gears
KW  - mobile robots
KW  - motion control
KW  - pipes
KW  - robot kinematics
KW  - wheels
KW  - roll joint
KW  - single actuator
KW  - drive wheel
KW  - miter-geared differential mechanism
KW  - rear wheels
KW  - joint movement
KW  - helical movement
KW  - kinematic model
KW  - multilink articulated wheeled in-pipe robot
KW  - underactuated twisting joints
KW  - stopper angle design
KW  - roll angle
KW  - Mobile robots
KW  - Wheels
KW  - Robot kinematics
KW  - Kinematics
KW  - Pipelines
KW  - Actuators
DO  - 10.1109/IROS.2018.8594208
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a multi-link articulated wheeled in-pipe robot that can drive the wheel and roll joint by using only a single actuator installed in each link. The proposed mechanism enables the robot to move forward or backward and helically in pipes owing to rotation of the drive wheel and twisting of the body. These two movements are generated by a miter-geared differential mechanism installed in each joint, and the magnitudes of these movements depend on the load applied to the wheels and roll joints. However, controlling of two outputs independently and aligning the rotation of the roll joints as desired are extremely challenging. Therefore, in this study, we switch those two movements by driving the rear wheels and the front wheels of the robot alternately. In addition, a stopper is used to constrain the roll joint movement. By calculating the angle of elevation of the robot's helical movement in the pipe by using a kinematic model, we can design a stopper to precisely adjust the roll angle. We verified that the robot can twist using the differential mechanism, and we validated experimentally the effectiveness of the stopper.
ER  - 

TY  - CONF
TI  - Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 979
EP  - 986
AU  - C. Sampedro
AU  - A. Rodriguez-Ramos
AU  - I. Gil
AU  - L. Mejias
AU  - P. Campoy
PY  - 2018
KW  - aerospace computing
KW  - aerospace robotics
KW  - aircraft control
KW  - control engineering computing
KW  - gradient methods
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - visual servoing
KW  - deep reinforcement learning algorithm
KW  - deep deterministic policy gradients
KW  - image-based visual servoing controller
KW  - IBVS policy
KW  - linear velocity commands
KW  - multirotor aerial robots
KW  - simulated flight scenarios
KW  - Gazebo-based simulation scenario
KW  - RL-IBVS controller
KW  - Visual servoing
KW  - Reinforcement learning
KW  - Unmanned aerial vehicles
KW  - Task analysis
KW  - Detectors
KW  - Cameras
DO  - 10.1109/IROS.2018.8594249
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.
ER  - 

TY  - CONF
TI  - Perspective Correcting Visual Odometry for Agile MAVs using a Pixel Processor Array
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 987
EP  - 994
AU  - C. Greatwood
AU  - L. Bose
AU  - T. Richardson
AU  - W. Mayol-Cuevas
AU  - J. Chen
AU  - S. J. Carey
AU  - P. Dudek
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - distance measurement
KW  - image motion analysis
KW  - image sensors
KW  - sensor arrays
KW  - SCAMP-5 vision chip
KW  - Pixel Processor Array camera
KW  - visual odometry approach
KW  - agile MAVs
KW  - traditional image sensors
KW  - low frame rates
KW  - significant motion blur
KW  - motion capture system
KW  - direct comparison
KW  - PPA based approach
KW  - MAV
KW  - image alignment based odometry
KW  - perspective correction
KW  - HDR edge detection
KW  - computer vision tasks
KW  - Visual odometry
KW  - Cameras
KW  - Robot sensing systems
KW  - Arrays
KW  - Parallel processing
KW  - Visualization
KW  - Performance evaluation
DO  - 10.1109/IROS.2018.8594500
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a visual odometry approach using a Pixel Processor Array (PPA) camera, specifically, the SCAMP-5 vision chip. In this device, each pixel is capable of storing data and performing computation, enabling a variety of computer vision tasks to be carried out directly upon the sensor itself. In this work the PPA performs HDR edge detection, perspective correction and image alignment based odometry, allowing the position and heading of a MAV to be tracked at several hundred frames per second. We evaluate our PPA based approach by direct comparison with a motion capture system for a variety of trajectories. These include rapid accelerations that would incur significant motion blur at low frame rates, and lighting conditions that would typically lead to under or over exposure of image detail. Such challenging conditions would often lead to unusable images when relying on traditional image sensors.
ER  - 

TY  - CONF
TI  - C-blox: A Scalable and Consistent TSDF-based Dense Mapping Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 995
EP  - 1002
AU  - A. Millane
AU  - Z. Taylor
AU  - H. Oleynikova
AU  - J. Nieto
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image reconstruction
KW  - image sensors
KW  - robot vision
KW  - SLAM (robots)
KW  - truncated signed distance field
KW  - TSDF subvolumes
KW  - lightweight micro aerial vehicle
KW  - scalable maps
KW  - map growth
KW  - bundle adjustment
KW  - feature-based camera tracking
KW  - dense 3D mapping
KW  - map consistency
KW  - delayed loop closure
KW  - accumulated camera tracking error
KW  - precise dense 3D maps
KW  - higher level decision making
KW  - robotic platforms
KW  - consistent dense map
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593427
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In many applications, maintaining a consistent dense map of the environment is key to enabling robotic platforms to perform higher level decision making. Several works have addressed the challenge of creating precise dense 3D maps from visual sensors providing depth information. However, during operation over longer missions, reconstructions can easily become inconsistent due to accumulated camera tracking error and delayed loop closure. Without explicitly addressing the problem of map consistency, recovery from such distortions tends to be difficult. We present a novel system for dense 3D mapping which addresses the challenge of building consistent maps while dealing with scalability. Central to our approach is the representation of the environment as a collection of overlapping Truncated Signed Distance Field (TSDF) subvolumes. These subvolumes are localized through feature-based camera tracking and bundle adjustment. Our main contribution is a pipeline for identifying stable regions in the map, and to fuse the contributing subvolumes. This approach allows us to reduce map growth while still maintaining consistency. We demonstrate the proposed system on a publicly available dataset and simulation engine, and demonstrate the efficacy of the proposed approach for building consistent and scalable maps. Finally we demonstrate our approach running in real-time onboard a lightweight Micro Aerial Vehicle (MAV).
ER  - 

TY  - CONF
TI  - Challenges of Autonomous Flight in Indoor Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1003
EP  - 1009
AU  - G. De Croon
AU  - C. De Wagter
PY  - 2018
KW  - aircraft navigation
KW  - autonomous aerial vehicles
KW  - Global Positioning System
KW  - indoor navigation
KW  - sensors
KW  - indoor environments
KW  - GPS
KW  - velocity estimates
KW  - global navigation systems
KW  - drone research
KW  - indoor navigation
KW  - autonomous flight
KW  - onboard sensors
KW  - Indoor environments
KW  - Drones
KW  - Robots
KW  - Measurement
KW  - Global Positioning System
KW  - Collision avoidance
KW  - Cameras
DO  - 10.1109/IROS.2018.8593704
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor navigation has been a major focus of drone research over the last few decades. The main reason for the term “indoor” came from the fact that in outdoor environments, drones could rely on global navigation systems such as GPS for their position and velocity estimates. By focusing on unknown indoor environments, the research had to focus on solutions using onboard sensors and processing. In this article, we present an overview of the state of the art and remaining challenges in this area, with a focus on small drones.
ER  - 

TY  - CONF
TI  - A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1010
EP  - 1017
AU  - A. Rodriguez-Ramos
AU  - C. Sampedro
AU  - H. Bavle
AU  - I. G. Moreno
AU  - P. Campoy
PY  - 2018
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - continuous systems
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - robot vision
KW  - state-space methods
KW  - deep learning techniques
KW  - deep deterministic policy gradients algorithm
KW  - motion control
KW  - deep Q- learning
KW  - active domain
KW  - robotics-related tasks
KW  - multirotor control
KW  - attitude control
KW  - state space
KW  - continuous action space
KW  - deep reinforcement learning technique
KW  - vision-based autonomous multirotor landing maneuver
KW  - continuous state
KW  - continuous action domain
KW  - moving platform
KW  - Reinforcement learning
KW  - Unmanned aerial vehicles
KW  - Robots
KW  - Cameras
KW  - Aerospace electronics
KW  - Neural networks
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594472
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.
ER  - 

TY  - CONF
TI  - Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1018
EP  - 1023
AU  - H. Bavle
AU  - S. Manthe
AU  - P. de la Puente
AU  - A. Rodriguez-Ramos
AU  - C. Sampedro
AU  - P. Campoy
PY  - 2018
KW  - distance measurement
KW  - image colour analysis
KW  - image segmentation
KW  - indoor environment
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - indoor environments
KW  - particle filter localization approach
KW  - semantic information
KW  - mini-aerial robots
KW  - stereo VO algorithm
KW  - semantic measurements
KW  - pre-trained deep learning based object detector
KW  - 3D point clouds
KW  - visual SLAM approach
KW  - stereo visual odometry
KW  - semantics based localization
KW  - DL
KW  - RGB spectrum
KW  - drift free pose estimation
KW  - Semantics
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Robots
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Prediction algorithms
DO  - 10.1109/IROS.2018.8593426
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we propose a particle filter localization approach, based on stereo visual odometry (VO) and semantic information from indoor environments, for mini-aerial robots. The prediction stage of the particle filter is performed using the 3D pose of the aerial robot estimated by the stereo VO algorithm. This predicted 3D pose is updated using inertial as well as semantic measurements. The algorithm processes semantic measurements in two phases; firstly, a pre-trained deep learning (DL) based object detector is used for real time object detections in the RGB spectrum. Secondly, from the corresponding 3D point clouds of the detected objects, we segment their dominant horizontal plane and estimate their relative position, also augmenting a prior map with new detections. The augmented map is then used in order to obtain a drift free pose estimate of the aerial robot. We validate our approach in several real flight experiments where we compare it against ground truth and a state of the art visual SLAM approach.
ER  - 

TY  - CONF
TI  - Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1024
EP  - 1031
AU  - C. Sampedro
AU  - H. Bavle
AU  - A. Rodriguez-Ramos
AU  - P. de la Puente
AU  - P. Campoy
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - traditional motion planning algorithms
KW  - precise maps
KW  - fast reactive navigation algorithm
KW  - multirotor aerial robots
KW  - 2D-laser range measurements
KW  - Gazebo-based simulation scenario
KW  - artificial potential field formulation
KW  - laser-based reactive navigation
KW  - collision avoidance capabilities
KW  - reactive navigation behavior
KW  - deep reinforcement learning
KW  - dynamic obstacles
KW  - static obstacles
KW  - Navigation
KW  - Robots
KW  - Unmanned aerial vehicles
KW  - Lasers
KW  - Heuristic algorithms
KW  - Reinforcement learning
KW  - Planning
DO  - 10.1109/IROS.2018.8593706
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.
ER  - 

TY  - CONF
TI  - Drone Detection Using Depth Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1034
EP  - 1037
AU  - A. Carrio
AU  - S. Vemprala
AU  - A. Ripoll
AU  - S. Saripalli
AU  - P. Campoy
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - static obstacle avoidance
KW  - dynamic objects
KW  - field-of-view requirements
KW  - on-board small UAVs
KW  - relative altitude
KW  - azimuth
KW  - depth map-based approach
KW  - collision avoidance
KW  - depth map sequences
KW  - unmanned aerial vehicle navigation
KW  - collision-free path planning
KW  - FOV
KW  - deep learning-based drone detection model
KW  - sensing technologies
KW  - 3D localization
KW  - Drones
KW  - Cameras
KW  - Three-dimensional displays
KW  - Atmospheric modeling
KW  - Sensors
KW  - Neural networks
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593405
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV) navigation. While solutions have been proposed for static obstacle avoidance, systems enabling avoidance of dynamic objects, such as drones, are hard to implement due to the detection range and field-of-view (FOV) requirements, as well as the constraints for integrating such systems on-board small UAVs. In this work, a dataset of 6k synthetic depth maps of drones has been generated and used to train a state-of-the-art deep learning-based drone detection model. While many sensing technologies can only provide relative altitude and azimuth of an obstacle, our depth map-based approach enables full 3D localization of the obstacle. This is extremely useful for collision avoidance, as 3D localization of detected drones is key to perform efficient collision-free path planning. The proposed detection technique has been validated in several real depth map sequences, with multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7 %, an average recall of 74.7 % and a record detection range of 9.5 meters.
ER  - 

TY  - CONF
TI  - Real-Time Dance Generation to Music for a Legged Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1038
EP  - 1044
AU  - T. Bi
AU  - P. Fankhauser
AU  - D. Bellicoso
AU  - M. Hutter
PY  - 2018
KW  - feedback
KW  - feedforward
KW  - humanoid robots
KW  - image motion analysis
KW  - legged locomotion
KW  - Markov processes
KW  - motion control
KW  - music
KW  - robot vision
KW  - synchronisation
KW  - music tempo
KW  - dance generation
KW  - feedforward delay controller
KW  - Markov chain
KW  - quadrupedal robot
KW  - robot whole-body controller reference input
KW  - feedback delay controller
KW  - time-shifting
KW  - delays
KW  - picked dance motion
KW  - base motions
KW  - stepping motions
KW  - dance motions
KW  - user-generated dance motion library
KW  - dance choreography
KW  - onboard microphone
KW  - live music
KW  - external stimuli
KW  - legged robot
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Music
KW  - Delays
KW  - Trajectory
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593983
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The development of robots that can dance has received considerable attention. However, they are often either limited to a pre-defined set of movements and music or demonstrate little variance when reacting to external stimuli, such as microphone or camera input. In this paper, we contribute with a novel approach allowing a legged robot to listen to live music while dancing in synchronization with the music in a diverse fashion. This is achieved by extracting the beat from an onboard microphone in real-time, and subsequently creating a dance choreography by picking from a user-generated dance motion library at every new beat. Dance motions include various stepping and base motions. The process of picking from the library is defined by a probabilistic model, namely a Markov chain, that depends on the previously picked dance motion and the current music tempo. Finally, delays are determined online by time-shifting a measured signal and a reference signal, and minimizing the least squares error with the time-shift as parameter. Delays are then compensated for by using a combined feedforward and feedback delay controller which shifts the robot whole-body controller reference input in time. Results from experiments on a quadrupedal robot demonstrate the fast convergence and synchrony to the perceived music.
ER  - 

TY  - CONF
TI  - Robust Fruit Counting: Combining Deep Learning, Tracking, and Structure from Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1045
EP  - 1052
AU  - X. Liu
AU  - S. W. Chen
AU  - S. Aditya
AU  - N. Sivakumar
AU  - S. Dcunha
AU  - C. Qu
AU  - C. J. Taylor
AU  - J. Das
AU  - V. Kumar
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image classification
KW  - image colour analysis
KW  - image motion analysis
KW  - image segmentation
KW  - image sequences
KW  - Kalman filters
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - video signal processing
KW  - Motion algorithm
KW  - double counted fruit tracks
KW  - ground-truth human-annotated visual counts
KW  - fruit counting pipeline
KW  - fruit counting pipeline
KW  - tracking process
KW  - Kanade-Lucas-Tomasi Tracker
KW  - Hungarian Algorithm
KW  - nonfruit pixels
KW  - segment video frame images
KW  - image streams
KW  - pipeline works
KW  - visible fruits
KW  - frame tracking
KW  - deep segmentation
KW  - deep learning
KW  - robust fruit counting
KW  - counting accuracy
KW  - image sequences
KW  - Image segmentation
KW  - Tracking
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Image sequences
KW  - Deep learning
KW  - Cameras
DO  - 10.1109/IROS.2018.8594239
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel fruit counting pipeline that combines deep segmentation, frame to frame tracking, and 3D localization to accurately count visible fruits across a sequence of images. Our pipeline works on image streams from a monocular camera, both in natural light, as well as with controlled illumination at night. We first train a Fully Convolutional Network (FCN) and segment video frame images into fruit and non-fruit pixels. We then track fruits across frames using the Hungarian Algorithm where the objective cost is determined from a Kalman Filter corrected Kanade-Lucas-Tomasi (KLT) Tracker. In order to correct the estimated count from tracking process, we combine tracking results with a Structure from Motion (SfM) algorithm to calculate relative 3D locations and size estimates to reject outliers and double counted fruit tracks. We evaluate our algorithm by comparing with ground-truth human-annotated visual counts. Our results demonstrate that our pipeline is able to accurately and reliably count fruits across image sequences, and the correction step can significantly improve the counting accuracy and robustness. Although discussed in the context of fruit counting, our work can extend to detection, tracking, and counting of a variety of other stationary features of interest such as leaf-spots, wilt, and blossom.
ER  - 

TY  - CONF
TI  - Towards View-Invariant Intersection Recognition from Videos using Deep Network Ensembles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1053
EP  - 1060
AU  - A. Kumar
AU  - G. Gupta
AU  - A. Sharma
AU  - K. M. Krishna
PY  - 2018
KW  - data mining
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object recognition
KW  - video signal processing
KW  - recognition accuracy
KW  - road segments
KW  - LSTM based Siamese style deep network
KW  - meeting point
KW  - deep network ensembles
KW  - videos
KW  - view-invariant intersection recognition
KW  - video recognition
KW  - Videos
KW  - Trajectory
KW  - Visualization
KW  - Task analysis
KW  - Roads
KW  - Image recognition
KW  - Training
DO  - 10.1109/IROS.2018.8594449
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper strives to answer the following question: Is it possible to recognize an intersection when seen from different road segments that constitute the intersection? An intersection or a junction typically is a meeting point of three or four road segments. Its recognition from a road segment that is transverse to or 180 degrees apart from its previous sighting is an extremely challenging and yet a very relevant problem to be addressed from the point of view of both autonomous driving as well as loop detection. This paper formulates this as a problem of video recognition and proposes a novel LSTM based Siamese style deep network for video recognition. For what is indeed a challenging problem and the limited annotated dataset available we show competitive results of recognizing intersections when approached from diverse viewpoints or road segments. Specifically, we tabulate effective recognition accuracy even as the approaches to the intersection being compared are disparate both in terms of viewpoints and weather/illumination conditions. We show competitive results on both synthetic yet highly realistic data mined from the gaming platform GTA as well as on real world data made available through Mapillary.
ER  - 

TY  - CONF
TI  - Semantically Meaningful View Selection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1061
EP  - 1066
AU  - J. Guérin
AU  - O. Gibaru
AU  - E. Nyiri
AU  - S. Thieryl
AU  - B. Boots
PY  - 2018
KW  - feature extraction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - object recognition
KW  - pattern clustering
KW  - pose estimation
KW  - robot vision
KW  - meaningful view selection
KW  - high-level abstract tasks
KW  - lower-level concrete tasks
KW  - deep learning
KW  - image understanding
KW  - object recognition
KW  - robot sorting tasks
KW  - fixed top-down view
KW  - viewing angle
KW  - semantically informative view
KW  - semantic view selection
KW  - semantic knowledge
KW  - observed object
KW  - image dataset
KW  - semantic score
KW  - view image
KW  - camera
KW  - Cameras
KW  - Semantics
KW  - Robot vision systems
KW  - Task analysis
KW  - Feature extraction
KW  - Measurement
DO  - 10.1109/IROS.2018.8593524
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An understanding of the nature of objects could help robots to solve both high-level abstract tasks and improve performance at lower-level concrete tasks. Although deep learning has facilitated progress in image understanding, a robot's performance in problems like object recognition often depends on the angle from which the object is observed. Traditionally, robot sorting tasks rely on a fixed top-down view of an object. By changing its viewing angle, a robot can select a more semantically informative view leading to better performance for object recognition. In this paper, we introduce the problem of semantic view selection, which seeks to find good camera poses to gain semantic knowledge about an observed object. We propose a conceptual formulation of the problem, together with a solvable relaxation based on clustering. We then present a new image dataset consisting of around 10k images representing various views of 144 objects under different poses. Finally we use this dataset to propose a first solution to the problem by training a neural network to predict a “semantic score” from a top view image and camera pose. The views predicted to have higher scores are then shown to provide better clustering results than fixed top-down views.
ER  - 

TY  - CONF
TI  - Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1067
EP  - 1074
AU  - R. N. Haksar
AU  - M. Schwager
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - dynamic programming
KW  - fires
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - Monte Carlo methods
KW  - optimal control
KW  - rescue robots
KW  - distributed deep reinforcement learning based strategy
KW  - UAVs
KW  - Markov decision process
KW  - deep RL approach
KW  - deep RL policy
KW  - forest sizes
KW  - simulated forest fire
KW  - unmanned aerial vehicles
KW  - aerial robots
KW  - Vegetation
KW  - Forestry
KW  - Sensors
KW  - Retardants
KW  - Monitoring
KW  - Lattices
KW  - Unmanned aerial vehicles
DO  - 10.1109/IROS.2018.8593539
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.
ER  - 

TY  - CONF
TI  - Tree Species Identification from Bark Images Using Convolutional Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1075
EP  - 1081
AU  - M. Carpentier
AU  - P. Giguère
AU  - J. Gaudreault
PY  - 2018
KW  - feature extraction
KW  - forestry
KW  - geophysical image processing
KW  - image classification
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - vegetation mapping
KW  - bark images
KW  - tree individual number
KW  - high-resolution bark images
KW  - species recognition
KW  - tree diameters
KW  - tree bark species classification
KW  - standard vision problems
KW  - deep learning
KW  - forestry related tasks
KW  - convolutional neural networks
KW  - tree species identification
KW  - Vegetation
KW  - Forestry
KW  - Deep learning
KW  - Feature extraction
KW  - Training
KW  - Cameras
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593514
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tree species identification using bark images is a challenging problem that could prove useful for many forestry related tasks. However, while the recent progress in deep learning showed impressive results on standard vision problems, a lack of datasets prevented its use on tree bark species classification. In this work, we present, and make publicly available, a novel dataset called BarkNet 1.0 containing more than 23,000 high-resolution bark images from 23 different tree species over a wide range of tree diameters. With it, we demonstrate the feasibility of species recognition through bark images, using deep learning. More specifically, we obtain an accuracy of 93.88% on single crop, and an accuracy of 97.81% using a majority voting approach on all of the images of a tree. We also empirically demonstrate that, for a fixed number of images, it is better to maximize the number of tree individuals in the training database, thus directing future data collection efforts.
ER  - 

TY  - CONF
TI  - UnDEMoN: Unsupervised Deep Network for Depth and Ego-Motion Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1082
EP  - 1088
AU  - V. Madhu Babu
AU  - K. Das
AU  - A. Majumdar
AU  - S. Kumar
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image reconstruction
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - motion estimation
KW  - pose estimation
KW  - stereo image processing
KW  - unsupervised learning
KW  - unsupervised deep network
KW  - ego-motion estimation
KW  - unsupervised visual odometry system
KW  - monocular view
KW  - objective function
KW  - temporally alligned sequences
KW  - monocular images
KW  - disparity-based depth estimation network
KW  - dense depth map
KW  - UnDEMoN
KW  - binocular stereo image pairs
KW  - temporal reconstruction losses
KW  - pose estimation network
KW  - 6DoF camera pose estimation
KW  - Image reconstruction
KW  - Cameras
KW  - Pose estimation
KW  - Training
KW  - Meters
KW  - Linear programming
DO  - 10.1109/IROS.2018.8593864
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a deep network based unsupervised visual odometry system for 6-DoF camera pose estimation and finding dense depth map for its monocular view. The proposed network is trained using unlabeled binocular stereo image pairs and is shown to provide superior performance in depth and ego-motion estimation compared to the existing state-of-the-art. This is achieved by introducing a novel objective function and training the network using temporally alligned sequences of monocular images. The objective function is based on the Charbonnier penalty applied to spatial and bi-directional temporal reconstruction losses. The overall novelty of the approach lies in the fact that the proposed deep framework combines a disparity-based depth estimation network with a pose estimation network to obtain absolute scale-aware 6-DoF camera pose and superior depth map. According to our knowledge, such a framework with complete unsupervised end-to-end learning has not been tried so far, making it a novel contribution in the field. The effectiveness of the approach is demonstrated through performance comparison with the state-of-the-art methods on KITTI driving dataset.
ER  - 

TY  - CONF
TI  - Leveraging Convolutional Pose Machines for Fast and Accurate Head Pose Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1089
EP  - 1094
AU  - Y. Cao
AU  - O. Canévet
AU  - J. Odobez
PY  - 2018
KW  - face recognition
KW  - feature extraction
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - multilayer perceptrons
KW  - object detection
KW  - pose estimation
KW  - appearance information
KW  - keypoint relationships
KW  - convolutional neural networks
KW  - multilayer perceptrons
KW  - keypoint detection model
KW  - CPM
KW  - head pose estimation
KW  - facial keypoint features
KW  - estimation framework
KW  - convolutional pose machines
KW  - Magnetic heads
KW  - Pose estimation
KW  - Face
KW  - Feature extraction
KW  - Nose
KW  - Ear
DO  - 10.1109/IROS.2018.8594223
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a head pose estimation framework that leverages on a recent keypoint detection model. More specifically, we apply the convolutional pose machines (CPMs) to input images, extract different types of facial keypoint features capturing appearance information and keypoint relationships, and train multilayer perceptrons (MLPs) and convolutional neural networks (CNNs) for head pose estimation. The benefit of leveraging on the CPMs (which we apply anyway for other purposes like tracking) is that we can design highly efficient models for practical usage. We evaluate our approach on the Annotated Facial Landmarks in the Wild (AFLW) dataset and achieve competitive results with the state-of-the-art.
ER  - 

TY  - CONF
TI  - Conceptualization of Object Compositions Using Persistent Homology
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1095
EP  - 1102
AU  - C. A. Mueller
AU  - A. Birk
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - shape recognition
KW  - topology
KW  - topological shape analysis
KW  - shape commonalities
KW  - spatial topology analysis
KW  - point cloud segment constellations
KW  - description space
KW  - object segment decompositions
KW  - persistent homology
KW  - Shape
KW  - Three-dimensional displays
KW  - Visualization
KW  - Topology
KW  - Dictionaries
KW  - Prototypes
KW  - Training
DO  - 10.1109/IROS.2018.8594516
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A topological shape analysis is proposed and utilized to learn concepts that reflect shape commonalities. Our approach is two-fold: i) a spatial topology analysis of point cloud segment constellations within objects. Therein constellations are decomposed and described in an hierarchical manner - from single segments to segment groups until a single group reflects an entire object. ii) a topology analysis of the description space in which segment decompositions are exposed in. Inspired by Persistent Homology, hidden groups of shape commonalities are revealed from object segment decompositions. Experiments show that extracted persistent groups of commonalities can represent semantically meaningful shape concepts. We also show the generalization capability of the proposed approach considering samples of external datasets.
ER  - 

TY  - CONF
TI  - Kitting in the Wild through Online Domain Adaptation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1103
EP  - 1109
AU  - M. Mancini
AU  - H. Karaoguz
AU  - E. Ricci
AU  - P. Jensfelt
AU  - B. Caputo
PY  - 2018
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - robot vision
KW  - visual perception
KW  - online adaptation algorithm
KW  - standard domain adaptation algorithms
KW  - batch-normalization layers
KW  - deep models
KW  - robot visual recognition algorithms
KW  - standard object recognition datasets
KW  - visual dataset
KW  - robotic kitting
KW  - vision systems
KW  - online domain adaptation
KW  - Robots
KW  - Adaptation models
KW  - Task analysis
KW  - Training
KW  - Data models
KW  - Visualization
KW  - Standards
DO  - 10.1109/IROS.2018.8593862
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Technological developments call for increasing perception and action capabilities of robots. Among other skills, vision systems that can adapt to any possible change in the working conditions are needed. Since these conditions are unpredictable, we need benchmarks which allow to assess the generalization and robustness capabilities of our visual recognition algorithms. In this work we focus on robotic kitting in unconstrained scenarios. As a first contribution, we present a new visual dataset for the kitting task. Differently from standard object recognition datasets, we provide images of the same objects acquired under various conditions where camera, illumination and background are changed. This novel dataset allows for testing the robustness of robot visual recognition algorithms to a series of different domain shifts both in isolation and unified. Our second contribution is a novel online adaptation algorithm for deep models, based on batch-normalization layers, which allows to continuously adapt a model to the current working conditions. Differently from standard domain adaptation algorithms, it does not require any image from the target domain at training time. We benchmark the performance of the algorithm on the proposed dataset, showing its capability to fill the gap between the performances of a standard architecture and its counterpart adapted offline to the given target domain.
ER  - 

TY  - CONF
TI  - CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial Transformer Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1110
EP  - 1117
AU  - G. Iyer
AU  - R. K. Ram
AU  - J. K. Murthy
AU  - K. M. Krishna
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image processing
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - optical radar
KW  - extrinsic calibration parameters
KW  - underlying geometric problem
KW  - photometric consistency
KW  - geometric consistency
KW  - camera calibration matrix K
KW  - LiDAR point cloud
KW  - calibration efforts
KW  - rigid body transformation
KW  - geometrically supervised deep network capable
KW  - calibration targets
KW  - calibration techniques
KW  - meaningful data
KW  - sensor rig
KW  - 3D LiDAR
KW  - 3D spatial transformer networks
KW  - geometrically supervised extrinsic calibration
KW  - Calibration
KW  - Three-dimensional displays
KW  - Cameras
KW  - Laser radar
KW  - Robot sensing systems
KW  - Training
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593693
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D LiDARs and 2D cameras are increasingly being used alongside each other in sensor rigs for perception tasks. Before these sensors can be used to gather meaningful data, however, their extrinsics (and intrinsics) need to be accurately calibrated, as the performance of the sensor rig is extremely sensitive to these calibration parameters. A vast majority of existing calibration techniques require significant amounts of data and/or calibration targets and human effort, severely impacting their applicability in large-scale production systems. We address this gap with CalibNet: a geometrically supervised deep network capable of automatically estimating the 6-DoF rigid body transformation between a 3D LiDAR and a 2D camera in real-time. CalibNet alleviates the need for calibration targets, thereby resulting in significant savings in calibration efforts. During training, the network only takes as input a LiDAR point cloud, the corresponding monocular image, and the camera calibration matrix K. At train time, we do not impose direct supervision (i.e., we do not directly regress to the calibration parameters, for example). Instead, we train the network to predict calibration parameters that maximize the geometric and photometric consistency of the input images and point clouds. CalibNet learns to iteratively solve the underlying geometric problem and accurately predicts extrinsic calibration parameters for a wide range of mis-calibrations, without requiring retraining or domain adaptation. The project page is hosted at https://epiception.github.io/CalibNet.
ER  - 

TY  - CONF
TI  - Compact & Comprehensive Canonical Appearances Discovered Autonomously
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1118
EP  - 1123
AU  - K. Türksoy
AU  - H. Iṣll Bozma
PY  - 2018
KW  - decision making
KW  - image representation
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - exploration approach
KW  - autonomous ground robot
KW  - depth sensor
KW  - bubble space representation
KW  - exploration path length
KW  - topological mapping
KW  - canonical appearances
KW  - appearance-based learning
KW  - Robot sensing systems
KW  - Decision making
KW  - Robot kinematics
KW  - Cognition
KW  - Lasers
KW  - Measurement
DO  - 10.1109/IROS.2018.8593544
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an exploration approach for discovering canonical appearances in unknown environments using an autonomous ground robot equipped with a depth sensor. This approach is based on the previously proposed two-stage algorithm that alternates between local and global decision making for efficient topological mapping based on bubble space representation. Differing from it, the approach aims to identify vantage viewpoints with characterizing views for subsequent appearance-based learning as well as achieving complete coverage. This is demonstrated by a series of experiments using an outdoor benchmark data set including a comparative study with evaluation metrics including the exploration path length and number of canonical appearances discovered.
ER  - 

TY  - CONF
TI  - Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1124
EP  - 1131
AU  - W. Andrew
AU  - C. Greatwood
AU  - T. Burghardt
PY  - 2018
KW  - autonomous aerial vehicles
KW  - convolutional neural nets
KW  - image classification
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - random processes
KW  - robot vision
KW  - target tracking
KW  - online search tasks
KW  - multitarget environments
KW  - dynamic targets
KW  - UAV-like vision
KW  - deep learning
KW  - dynamic search
KW  - strategic explorational agency
KW  - single deep network
KW  - navigational actions
KW  - dual-stream classification paradigm
KW  - sensory processing
KW  - agent location
KW  - static evolutions
KW  - dynamic evolutions
KW  - probabilistic placement
KW  - fully random target walks
KW  - herd-inspired behaviours
KW  - dual-stream architecture
KW  - unmanned aerial vehicle
KW  - convolutional neural network
KW  - multitarget behaviour classes
KW  - optimal navigational decision samples
KW  - long term map memory
KW  - Navigation
KW  - Robot sensing systems
KW  - Task analysis
KW  - History
KW  - Visualization
KW  - Vehicle dynamics
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593751
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish3 key source code and associated models.
ER  - 

TY  - CONF
TI  - Hybrid Multi-camera Visual Servoing to Moving Target
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1132
EP  - 1137
AU  - H. Cuevas-Velasquez
AU  - N. Li
AU  - R. Tylecek
AU  - M. Saval-Calvo
AU  - R. B. Fisher
PY  - 2018
KW  - cameras
KW  - image sensors
KW  - position control
KW  - robot vision
KW  - stereo image processing
KW  - tracking
KW  - visual servoing
KW  - hybrid multicamera visual servoing
KW  - moving target
KW  - robotics
KW  - multiple visual sources
KW  - visual servoing approach
KW  - hybrid multicamera input data
KW  - robot arm
KW  - RGBD sensors
KW  - arm-mounted stereo camera
KW  - Eye-in-Hand
KW  - EtoH cameras
KW  - EinH sensor
KW  - EtoH sensors
KW  - adaptive visual input data
KW  - eye-to-hand visual input
KW  - Three-dimensional displays
KW  - Cameras
KW  - Visualization
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593652
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual servoing is a well-known task in robotics. However, there are still challenges when multiple visual sources are combined to accurately guide the robot or occlusions appear. In this paper we present a novel visual servoing approach using hybrid multi-camera input data to lead a robot arm accurately to dynamically moving target points in the presence of partial occlusions. The approach uses four RGBD sensors as Eye-to-Hand (EtoH) visual input, and an arm-mounted stereo camera as Eye-in-Hand (EinH). A Master supervisor task selects between using the EtoH or the EinH, depending on the distance between the robot and target. The Master also selects the subset of EtoH cameras that best perceive the target. When the EinH sensor is used, if the target becomes occluded or goes out of the sensor's view-frustum, the Master switches back to the EtoH sensors to re-track the object. Using this adaptive visual input data, the robot is then controlled using an iterative planner that uses position, orientation and joint configuration to estimate the trajectory. Since the target is dynamic, this trajectory is updated every time-step. Experiments show good performance in four different situations: tracking a ball, targeting a bulls-eye, guiding a straw to a mouth and delivering an item to a moving hand. The experiments cover both simple situations such as a ball that is mostly visible from all cameras, and more complex situations such as the mouth which is partially occluded from some of the sensors.
ER  - 

TY  - CONF
TI  - Detecting and Picking of Folded Objects with a Multiple Sensor Integrated Robot Hand
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1138
EP  - 1145
AU  - S. Hasegawa
AU  - K. Wada
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - image recognition
KW  - object detection
KW  - pressure sensors
KW  - robot vision
KW  - folded object
KW  - robotic picking
KW  - Suction Pinching Hand
KW  - proximity sensors
KW  - multiple sensor integrated robot hand
KW  - trial-and-error picking system
KW  - suction grasp
KW  - flex sensors
KW  - air pressure sensor
KW  - image recognition
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Image recognition
KW  - Grippers
KW  - Hardware
DO  - 10.1109/IROS.2018.8593398
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic picking of folded objects such as books is required for picking various objects. As a folded object is easily unfolded, it is difficult to carry it stably and place it in a desired pose due to its dangling part. For overcoming this difficulty, we propose a trial-and-error picking system using our Suction Pinching Hand, which can push the dangling part up with pinch grasp until the object lifted with suction grasp is folded. That system utilizes proximity sensors on the hand to predict whether folding will succeed with a current hand pose and decide whether to retry with another pose. Also, proximity sensors, flex sensors and an air pressure sensor are used to deal with uncertainty of the image recognition, the hand hardware and suction grasp. We evaluate our proposed system with experiments of picking and placing folded objects. It is confirmed that our proposed system realizes picking with the ability of our Suction Pinching Hand to carry folded objects stably and place them in desired poses. It is also proved that our proposed system is robust against the uncertainty.
ER  - 

TY  - CONF
TI  - Information Sparsification in Visual-Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1146
EP  - 1153
AU  - J. Hsiung
AU  - M. Hsiao
AU  - E. Westman
AU  - R. Valencia
AU  - M. Kaess
PY  - 2018
KW  - computational complexity
KW  - distance measurement
KW  - graph theory
KW  - mobile robots
KW  - SLAM (robots)
KW  - information sparsification
KW  - tightly couple visual measurements
KW  - inertial measurements
KW  - fixed-lag visual-inertial odometry framework
KW  - bound computational complexity
KW  - fixed-lag smoothers
KW  - densely connected linear
KW  - information-theoretic perspective
KW  - dense marginalization step
KW  - information content
KW  - nonlinear factor graph
KW  - information loss
KW  - information sparsity
KW  - VIO methods
KW  - EuRoC visual-inertial dataset
KW  - structural similarity
KW  - nonlinearity
KW  - computational complexity
KW  - Optimization
KW  - Markov processes
KW  - Microsoft Windows
KW  - Computational complexity
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Visualization
DO  - 10.1109/IROS.2018.8594007
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a novel approach to tightly couple visual and inertial measurements in a fixed-lag visual-inertial odometry (VIO) framework using information sparsification. To bound computational complexity, fixed-lag smoothers typically marginalize out variables, but consequently introduce a densely connected linear prior which significantly deteriorates accuracy and efficiency. Current state-of-the-art approaches account for the issue by selectively discarding measurements and marginalizing additional variables. However, such strategies are sub-optimal from an information-theoretic perspective. Instead, our approach performs a dense marginalization step and preserves the information content of the dense prior. Our method sparsifies the dense prior with a nonlinear factor graph by minimizing the information loss. The resulting factor graph maintains information sparsity, structural similarity, and nonlinearity. To validate our approach, we conduct real-time drone tests and perform comparisons to current state-of-the-art fixed-lag VIO methods in the EuRoC visual-inertial dataset. The experimental results show that the proposed method achieves competitive and superior accuracy in almost all trials. We include a detailed run-time analysis to demonstrate that the proposed algorithm is suitable for real-time applications.
ER  - 

TY  - CONF
TI  - Towards Robust Visual Odometry with a Multi-Camera System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1154
EP  - 1161
AU  - P. Liu
AU  - M. Geppert
AU  - L. Heng
AU  - T. Sattler
AU  - A. Geiger
AU  - M. Pollefeys
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - image sampling
KW  - minimisation
KW  - photometry
KW  - pose estimation
KW  - position measurement
KW  - stereo image processing
KW  - robust visual odometry algorithm
KW  - robust VO algorithm
KW  - current pose tracker estimation
KW  - photometric error minimisation
KW  - plane-sweeping stereo cameras
KW  - near-infrared illumination
KW  - NIR illumination
KW  - single stereo configuration
KW  - multicamera setup
KW  - sliding window optimizer
KW  - sampled feature points
KW  - local mapper
KW  - multicamera system
KW  - Cameras
KW  - Tracking
KW  - Lighting
KW  - Visual odometry
KW  - Robot vision systems
KW  - Robustness
KW  - Simultaneous localization and mapping
DO  - 10.1109/IROS.2018.8593561
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a visual odometry (VO) algorithm for a multi-camera system and robust operation in challenging environments. Our algorithm consists of a pose tracker and a local mapper. The tracker estimates the current pose by minimizing photometric errors between the most recent keyframe and the current frame. The mapper initializes the depths of all sampled feature points using plane-sweeping stereo. To reduce pose drift, a sliding window optimizer is used to refine poses and structure jointly. Our formulation is flexible enough to support an arbitrary number of stereo cameras. We evaluate our algorithm thoroughly on five datasets. The datasets were captured in different conditions: daytime, night-time with near-infrared (NIR) illumination and nighttime without NIR illumination. Experimental results show that a multi-camera setup makes the VO more robust to challenging environments, especially night-time conditions, in which a single stereo configuration fails easily due to the lack of features.
ER  - 

TY  - CONF
TI  - Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1162
EP  - 1167
AU  - P. Yin
AU  - L. Xu
AU  - Z. Liu
AU  - L. Li
AU  - H. Salman
AU  - Y. He
AU  - W. Xu
AU  - H. Wang
AU  - H. Choset
PY  - 2018
KW  - entropy
KW  - feature extraction
KW  - geometry
KW  - image matching
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - octrees
KW  - optical radar
KW  - robot vision
KW  - unsupervised learning
KW  - Generative Adversarial Network
KW  - adversarial feature
KW  - place recognition
KW  - global geometry map
KW  - Conditional Entropy Reduction module
KW  - unsupervised place feature
KW  - local 2D maps
KW  - dynamic octree mapping module
KW  - core modules
KW  - LiDAR inputs
KW  - end-to-end feature
KW  - geometry matching
KW  - traditional methods
KW  - LiDAR-based place recognition
KW  - unsupervised feature learning
KW  - feature size
KW  - place recognition task
KW  - North Campus Long-Term LiDAR dataset
KW  - feature learning process
KW  - place feature learning
KW  - Octrees
KW  - Laser radar
KW  - Task analysis
KW  - Decoding
KW  - Simultaneous localization and mapping
KW  - Generative adversarial networks
DO  - 10.1109/IROS.2018.8593562
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.
ER  - 

TY  - CONF
TI  - DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1168
EP  - 1174
AU  - C. Yu
AU  - Z. Liu
AU  - X. Liu
AU  - F. Xie
AU  - Y. Yang
AU  - Q. Wei
AU  - Q. Fei
PY  - 2018
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - high-dynamic environments
KW  - ORB-SLAM2
KW  - dense semantic octo-tree map
KW  - dynamic objects
KW  - DS-SLAM combines semantic segmentation network
KW  - dense semantic map creation
KW  - local mapping
KW  - robust semantic visual SLAM
KW  - impressed SLAM systems
KW  - Semantics
KW  - Simultaneous localization and mapping
KW  - Image segmentation
KW  - Feature extraction
KW  - Heuristic algorithms
KW  - Three-dimensional displays
KW  - Optical flow
DO  - 10.1109/IROS.2018.8593691
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Simultaneous Localization and Mapping (SLAM) is considered to be a fundamental capability for intelligent mobile robots. Over the past decades, many impressed SLAM systems have been developed and achieved good performance under certain circumstances. However, some problems are still not well solved, for example, how to tackle the moving objects in the dynamic environments, how to make the robots truly understand the surroundings and accomplish advanced tasks. In this paper, a robust semantic visual SLAM towards dynamic environments named DS-SLAM is proposed. Five threads run in parallel in DS-SLAM: tracking, semantic segmentation, local mapping, loop closing and dense semantic map creation. DS-SLAM combines semantic segmentation network with moving consistency check method to reduce the impact of dynamic objects, and thus the localization accuracy is highly improved in dynamic environments. Meanwhile, a dense semantic octo-tree map is produced, which could be employed for high-level tasks. We conduct experiments both on TUM RGB-D dataset and in real-world environment. The results demonstrate the absolute trajectory accuracy in DS-SLAM can be improved one order of magnitude compared with ORB-SLAM2. It is one of the state-of-the-art SLAM systems in high-dynamic environments.
ER  - 

TY  - CONF
TI  - A robust pose graph approach for city scale LiDAR mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1175
EP  - 1182
AU  - S. Yang
AU  - X. Zhu
AU  - X. Nian
AU  - L. Feng
AU  - X. Qu
AU  - T. Ma
PY  - 2018
KW  - graph theory
KW  - image filtering
KW  - image reconstruction
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - optical radar
KW  - optimisation
KW  - pose estimation
KW  - radar imaging
KW  - robot vision
KW  - SLAM (robots)
KW  - map quality
KW  - quantitative experimental results
KW  - robust optimization strategy
KW  - systematical initialization bias
KW  - factor graph
KW  - refined structure
KW  - urban environments
KW  - multitask acquisitions
KW  - scan-matching factors
KW  - graph optimization
KW  - cumulative drift
KW  - city scale LiDAR mapping
KW  - robust pose graph approach
KW  - Optimization
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Global Positioning System
KW  - Feature extraction
KW  - Sensors
KW  - Urban areas
DO  - 10.1109/IROS.2018.8593754
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a method for reconstructing globally consistent 3D High-Definition (HD) maps at city scale. Current approaches for eliminating cumulative drift are mainly based on the pose graph optimization under the constraint of scan-matching factors. The misaligned edges in the graph may have negative impacts on the results. To address this problem and further handle inconsistency caused by multi-task acquisitions in urban environments, we introduce a refined structure of the factor graph considering systematical initialization bias, where the scan-matching factors are twice validated through a novel classifier and a robust optimization strategy. In addition, we incorporate a multi-hypothesis extended Kalman filter (MH-EKF) to remove dynamic objects. Quantitative experimental results demonstrate that the proposed method outperforms state-of-the-art techniques in terms of map quality.
ER  - 

TY  - CONF
TI  - Good Feature Selection for Least Squares Pose Optimization in VO/VSLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1183
EP  - 1189
AU  - Y. Zhao
AU  - P. A. Vela
PY  - 2018
KW  - computational complexity
KW  - control engineering computing
KW  - feature extraction
KW  - least squares approximations
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - least squares pose optimization
KW  - pose estimation
KW  - pose tracking
KW  - NP-hard Max-logDet problem
KW  - feature selection
KW  - VO-VSLAM
KW  - integrating Max-logDet feature selection
KW  - Feature extraction
KW  - Optimization
KW  - Pose estimation
KW  - Simultaneous localization and mapping
KW  - Measurement uncertainty
KW  - Approximation algorithms
DO  - 10.1109/IROS.2018.8593641
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper aims to select features that contribute most to the pose estimation in VO/VSLAM. Unlike existing feature selection works that are focused on efficiency only, our method significantly improves the accuracy of pose tracking, while introducing little overhead. By studying the impact of feature selection towards least squares pose optimization, we demonstrate the applicability of improving accuracy via good feature selection. To that end, we introduce the Max-logDet metric to guide the feature selection, which is connected to the conditioning of least squares pose optimization problem. We then describe an efficient algorithm for approximately solving the NP-hard Max-logDet problem. Integrating Max-logDet feature selection into a state-of-the-art visual SLAM system leads to accuracy improvements with low overhead, as demonstrated via evaluation on a public benchmark.
ER  - 

TY  - CONF
TI  - Dynamic Scaling Factors of Covariances for Accurate 3D Normal Distributions Transform Registration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1190
EP  - 1196
AU  - H. Hong
AU  - B. H. Lee
PY  - 2018
KW  - covariance analysis
KW  - image registration
KW  - iterative methods
KW  - normal distribution
KW  - stereo image processing
KW  - transforms
KW  - NDT-D2D
KW  - 3D normal distributions transform registration
KW  - distribution-to-distribution normal distributions transform
KW  - PNDT-D2D
KW  - distribution-to-distribution probabilistic NDT
KW  - objective function
KW  - fast point set registrations
KW  - dynamic scaling factors
KW  - Linear programming
KW  - Gaussian distribution
KW  - Correlation
KW  - Probabilistic logic
KW  - Three-dimensional displays
KW  - Transforms
KW  - Robots
DO  - 10.1109/IROS.2018.8593839
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Distribution-to-distribution normal distributions transform (NDT-D2D) is one of the fast point set registrations. Since the normal distributions transform (NDT) is a set of normal distributions generated by discrete and regular cells, local minima of the objective function is an issue of NDT-D2D. Also, we found that the objective function based on L2 distance between distributions has a negative correlation with rotational alignment. To overcome the problems, we present a method using dynamic scaling factors of covariances to improve the accuracy of NDT-D2D. Two scaling factors are defined for the preceding and current NDTs respectively, and they are dynamically varied in each iteration of NDT-D2D. We implemented the proposed method based on conventional NDT-D2D and probabilistic NDT-D2D and compared to the NDT-D2D with fixed scaling factors using KITTI benchmark data set. Also, we experimented estimating odometry with an initial guess as an application of distribution-to-distribution probabilistic NDT (PNDT-D2D) with the proposed method. As a result, the proposed method improves both translational and rotational accuracy of the NDT-D2D and PNDT-D2D.
ER  - 

TY  - CONF
TI  - HMAPs - Hybrid Height- Voxel Maps for Environment Representation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1197
EP  - 1203
AU  - L. Garrote
AU  - C. Premebida
AU  - D. Silva
AU  - U. J. Nunes
PY  - 2018
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - 2.5D representation
KW  - Microsoft Kinect One
KW  - SLAM approach
KW  - complex elements
KW  - Velodyne VLP-16 LiDAR
KW  - updated grid representation
KW  - complex environments
KW  - reliable method
KW  - occupied space
KW  - free space
KW  - HVoxel
KW  - height-voxel elements
KW  - 3D point-clouds
KW  - mobile robot
KW  - grid-based mapping approach
KW  - environment representation
KW  - hybrid height- voxel maps
KW  - HMAP
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Pipelines
KW  - Ray tracing
KW  - Planning
KW  - Indexing
DO  - 10.1109/IROS.2018.8594113
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.
ER  - 

TY  - CONF
TI  - Kalman Filter Based Observer for an External Force Applied to Medium-sized Humanoid Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1204
EP  - 1211
AU  - L. Hawley
AU  - R. Rahem
AU  - W. Suleiman
PY  - 2018
KW  - force sensors
KW  - humanoid robots
KW  - Kalman filters
KW  - legged locomotion
KW  - medium-sized humanoid robot
KW  - external force observer
KW  - force/torque sensors
KW  - small robots
KW  - medium-sized humanoid robots
KW  - robot structure
KW  - Kalman filter formulation
KW  - force components
KW  - robot hardware
KW  - robot inertial measurement unit
KW  - Nao humanoid robot
KW  - external force
KW  - force-sensing resistors
KW  - Force
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Observers
KW  - Force measurement
DO  - 10.1109/IROS.2018.8593610
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - External force observer for humanoid robots has been widely studied in the literature. However, most of the proposed approaches generally rely on information from six-axis force/torque sensors, which the small or medium-sized humanoid robots usually do not have. As a result, those approaches cannot be applied to this category of humanoid robots, which is widely used nowadays in education or research. In this paper, we improve the external force observer in [1] to handle the case of an external force applied in any direction and at an arbitrary point of the robot structure. The new observer is based on Kalman filter formulation and it allows the estimation of the three force components. The observer is simple to implement and can easily run in real time using the embedded processor of a medium-sized humanoid robot such as Nao or Darwin-OP. Moreover, the observer does not require any change to the robot hardware as it only uses measurements from the available force-sensing resistors (FSR) inserted under the feet of the humanoid robot and from the robot inertial measurement unit (IMU). The proposed observer was extensively validated on a Nao humanoid robot. In all conducted experiments, the observer successfully estimated the external force within a reasonable margin of error.
ER  - 

TY  - CONF
TI  - CPG-based Controllers can Generate Both Discrete and Rhythmic Movements
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1212
EP  - 1217
AU  - M. Jouaiti
AU  - P. Henaff
PY  - 2018
KW  - human-robot interaction
KW  - motion control
KW  - neural net architecture
KW  - neurocontrollers
KW  - three-term control
KW  - CPG-based controllers
KW  - discrete movements
KW  - rhythmic movements
KW  - bio-inspired robot controller
KW  - oscillating neurons
KW  - PID controller
KW  - handshaking
KW  - Task analysis
KW  - Neurons
KW  - Oscillators
KW  - Manipulators
KW  - Grippers
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593889
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Complex tasks require the combination of both discrete and rhythmic movements. Though scientists do not yet agree on the neural architecture involved in both types and in the transition from one to the other, the importance of having robot controllers able to behave rhythmically and discretely is universally recoanized. In this paper, a bio-inspired robot controller based on oscillating neurons is proposed to realize both discrete and rhythmic movements and easily transition from one to the other. It is shown that, under certain parameter conditions, the CPG controller behaves like a PID controller. In order to demonstrate the feasibility of controlling both discrete and rhythmic movements, the CPG is applied to the initiation of handshaking, namely, reach towards the human hand and start to shake it. Results show that this architecture is suitable for both discrete and rhythmic movements and can easily transition from one to the other.
ER  - 

TY  - CONF
TI  - A 3D Template Model for Healthy and Impaired Walking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1218
EP  - 1225
AU  - M. A. Sharbafi
AU  - M. Zadravec
AU  - Z. Matjačić
AU  - A. Seyfarth
PY  - 2018
KW  - biomechanics
KW  - elasticity
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - muscle
KW  - nonlinear control systems
KW  - pendulums
KW  - robot dynamics
KW  - springs (mechanical)
KW  - 3D template model
KW  - modeling studies
KW  - neuromuscular control
KW  - impaired unperturbed gaits
KW  - human strategies
KW  - lateral asymmetries
KW  - experimental studies
KW  - stance time relations
KW  - stroke patients
KW  - bipedal SLIP
KW  - spring-loaded inverted pendulum
KW  - pathologic gaits
KW  - modulated compliant hip
KW  - VBLA model
KW  - velocity based leg adjustment
KW  - asymmetric leg
KW  - control parameters
KW  - similar gait patterns
KW  - hip stiffness
KW  - rest angles
KW  - FMCH models
KW  - Legged locomotion
KW  - Three-dimensional displays
KW  - Mathematical model
KW  - Solid modeling
KW  - Hip
KW  - Biological system modeling
KW  - Springs
DO  - 10.1109/IROS.2018.8594013
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Several modeling studies, which address neuromuscular control in impaired unperturbed gaits, were performed to predict human strategies to cope with lateral asymmetries in the body. Experimental studies show different step length and stance time relations between limbs in walking of stroke patients. By extension of a bipedal SLIP (spring-loaded inverted pendulum) based model and the corresponding controllers to 3D space, we focus on different features of the pathologic gaits. The introduced model is based on an extension of the FMCH (force modulated compliant hip) and VBLA (velocity based leg adjustment) model to 3D space. With the proposed model, asymmetric leg and control parameters can result in similar gait patterns as observed in experiments. These parameters comprise hip stiffness and rest angles in FMCH models and the tuning parameter of VBLA for foot placement. It is shown that asymmetries in muscle properties (e.g. stiffness) and leg adjustment can play an important role in generating pathologic gaits.
ER  - 

TY  - CONF
TI  - Exploiting Friction in Torque Controlled Humanoid Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1226
EP  - 1232
AU  - G. Nava
AU  - D. Ferigo
AU  - D. Pucci
PY  - 2018
KW  - friction
KW  - humanoid robots
KW  - motion control
KW  - robot dynamics
KW  - stability
KW  - torque control
KW  - torque controlled humanoid robots
KW  - common architecture
KW  - nested loops
KW  - joint/motor torques
KW  - joint friction phenomena
KW  - high level control objectives
KW  - joint task space control
KW  - humanoid robot iCub
KW  - stabilizing property
KW  - Friction
KW  - Brushless motors
KW  - Humanoid robots
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594505
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A common architecture for torque controlled humanoid robots consists in two nested loops. The outer loop generates desired joint/motor torques, and the inner loop stabilizes these desired values. In doing so, the inner loop usually compensates for joint friction phenomena, thus removing their inherent stabilizing property that may be also beneficial for high level control objectives. This paper shows how to exploit friction for joint and task space control of humanoid robots. Experiments are carried out on the humanoid robot iCub.
ER  - 

TY  - CONF
TI  - Structure preserving Multi-Contact Balance Control for Series-Elastic and Visco-Elastic Humanoid Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1233
EP  - 1240
AU  - A. Werner
AU  - B. Henze
AU  - M. Keppler
AU  - F. Loeffl
AU  - S. Leyendecker
AU  - C. Ott
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - humanoid robots
KW  - legged locomotion
KW  - predictive control
KW  - robot dynamics
KW  - visco-elastic humanoid robots
KW  - actuator control
KW  - multicontact balancing
KW  - force distribution problem
KW  - actuator dynamics
KW  - dynamically consistent force distribution
KW  - model predictive controller
KW  - contact force
KW  - actuator constraints
KW  - multicontact balance control
KW  - series-elastic humanoid robos
KW  - structure preservation control concept
KW  - locomotion
KW  - Force
KW  - Actuators
KW  - Robot kinematics
KW  - Dynamics
KW  - Task analysis
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8593596
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an integration of multi-body and actuator control for multi-contact balancing for robots with highly elastic joints. Inspired by the structure preserving control concept for series-elastic fixed-base robots, the presented approach aims to minimize the control effort by keeping the system structure intact. Balancing on multiple contacts requires to solve the force distribution problem. In locomotion, contacts change quickly, requiring a swift redistribution of contact forces. This is a challenge for elastic robots as the actuator dynamics and limits prevent instantaneous changes of contact forces. The proposed dynamically consistent force distribution is implemented as a model predictive controller which resolves redundancy while complying with contact force and actuator constraints.
ER  - 

TY  - CONF
TI  - Feedback Control For Cassie With Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1241
EP  - 1246
AU  - Z. Xie
AU  - G. Berseth
AU  - P. Clary
AU  - J. Hurst
AU  - M. van de Panne
PY  - 2018
KW  - feedback
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - Markov processes
KW  - motion control
KW  - robot dynamics
KW  - velocity control
KW  - Cassie
KW  - deep reinforcement learning
KW  - bipedal locomotion skills
KW  - local linearization
KW  - reduced-order abstractions
KW  - tractable solutions
KW  - model-based control strategies
KW  - torque limits
KW  - joint limits
KW  - nonlinearities
KW  - control computations
KW  - DRL
KW  - machine learning literature
KW  - ad-hoc simulation models
KW  - realizable bipedal robots
KW  - feedback control problem
KW  - robust walking controllers
KW  - controller robustness
KW  - model-free approach
KW  - Legged locomotion
KW  - Reinforcement learning
KW  - Computational modeling
KW  - Aerospace electronics
KW  - Feedback control
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593722
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Bipedal locomotion skills are challenging to develop. Control strategies often use local linearization of the dynamics in conjunction with reduced-order abstractions to yield tractable solutions. In these model-based control strategies, the controller is often not fully aware of many details, including torque limits, joint limits, and other non-linearities that are necessarily excluded from the control computations for simplicity. Deep reinforcement learning (DRL) offers a promising model-free approach for controlling bipedal locomotion which can more fully exploit the dynamics. However, current results in the machine learning literature are often based on ad-hoc simulation models that are not based on corresponding hardware. Thus it remains unclear how well DRL will succeed on realizable bipedal robots. In this paper, we demonstrate the effectiveness of DRL using a realistic model of Cassie, a bipedal robot. By formulating a feedback control problem as finding the optimal policy for a Markov Decision Process, we are able to learn robust walking controllers that imitate a reference motion with DRL. Controllers for different walking speeds are learned by imitating simple time-scaled versions of the original reference motion. Controller robustness is demonstrated through several challenging tests, including sensory delay, walking blindly on irregular terrain and unexpected pushes at the pelvis. We also show we can interpolate between individual policies and that robustness can be improved with an interpolated policy.
ER  - 

TY  - CONF
TI  - Robust and Stretched-Knee Biped Walking Using Joint-Space Motion Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1247
EP  - 1254
AU  - K. Nguyen
AU  - S. Noda
AU  - Y. Kojio
AU  - F. Sugai
AU  - S. Nozawa
AU  - Y. Kakiuchi
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - robot kinematics
KW  - robust control
KW  - IK based motion control
KW  - kinematics singularity problem
KW  - motion optimization method
KW  - human-like walking motion
KW  - SIMBICON
KW  - inverse kinematics
KW  - joint-space motion control
KW  - stretched-knee biped walking
KW  - walking robustness
KW  - simple biped locomotion control
KW  - Legged locomotion
KW  - Foot
KW  - Torque
KW  - Optimization
KW  - Robustness
KW  - Knee
DO  - 10.1109/IROS.2018.8594440
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Comparing to IK (Inverse Kinematics) based motion control, joint-space motion control is more advantageous in terms of not being restricted by kinematics singularity problem. In this paper, we start with SIMBICON (Simple Biped Locomotion Control) based controller, a joint-space motion control method, extend it for enhancing walking's robustness and versatility. We propose a motion optimization method considering walking robustness, desired walking velocity and energy efficient minimization for walking motion generation. This method enables us to achieve human-like walking motion, which has stretched-knee posture and robust to large push disturbances. We also apply our proposed method to a life-sized biped robot and validate its effectiveness with push recovery and walking on unknown debris experiments.
ER  - 

TY  - CONF
TI  - Public perception of android robots: Indications from an analysis of YouTube comments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1255
EP  - 1260
AU  - E. Vlachos
AU  - Z. Tan
PY  - 2018
KW  - control engineering computing
KW  - data mining
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - public administration
KW  - social networking (online)
KW  - text analysis
KW  - end-users
KW  - Youtube comments
KW  - social perception indication
KW  - machine learning
KW  - text mining
KW  - rendering interactions
KW  - textual reactions
KW  - video stimuli
KW  - technical specification
KW  - science fiction valley
KW  - public perception
KW  - human-robot relationships
KW  - robotic society
KW  - quantitative content analysis
KW  - android robots
KW  - YouTube
KW  - Videos
KW  - Androids
KW  - Humanoid robots
KW  - Clustering algorithms
KW  - Text mining
DO  - 10.1109/IROS.2018.8594058
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The public perception of android robots is a field of growing applied relevance. Currently, most androids are confined within controlled environments rendering interactions between potential end-users, and robots challenging. Even more challenging is for researchers to investigate end-users' perception of androids. We exploit pre-existing YouTube comments as artifacts for quantitative content analysis to gain an indication of social perception on androids. We perform a content analysis of 10301 YouTube comments from four different videos, and reflect on the textual reactions to video stimuli of four extremely human-like android robots. We use text mining and machine learning techniques to process and analyze our corpus. Our findings reveal three equally important topics that should be considered for paving the way towards a robotic society: human-robot relationships, technical specifications, and the science fiction valley. Considering people's attitudes, fears and wishes towards androids, researchers can increase citizen awareness, and engagement.
ER  - 

TY  - CONF
TI  - Towards Automatic 3D Shape Instantiation for Deployed Stent Grafts: 2D Multiple-class and Class-imbalance Marker Segmentation with Equally-weighted Focal U-Net
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1261
EP  - 1267
AU  - X. Zhou
AU  - C. Riga
AU  - S. Lee
AU  - G. Yang
PY  - 2018
KW  - blood vessels
KW  - cardiovascular system
KW  - image registration
KW  - image segmentation
KW  - medical image processing
KW  - mobile robots
KW  - path planning
KW  - stents
KW  - focal loss function
KW  - fluoroscopy projection
KW  - robot-assisted fenestrated endovascular aortic repair
KW  - automatic 3D shape instantiation
KW  - focal u-net
KW  - multiple class marker segmentation
KW  - multiple class marker center determination
KW  - robust perspective-S-point method
KW  - tensorflow codes
KW  - mean intersection over union
KW  - weighted u-net
KW  - network architecture
KW  - graft gap interpolation
KW  - stent graft
KW  - semiautomatic 3D shape instantiation method
KW  - FEVAR
KW  - class-imbalance marker segmentation
KW  - initial marker segmentation
KW  - fluoroscopy projections
KW  - Image segmentation
KW  - Shape
KW  - Three-dimensional displays
KW  - Aneurysm
KW  - Training
KW  - Two dimensional displays
KW  - Testing
DO  - 10.1109/IROS.2018.8594178
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot-assisted Fenestrated Endovascular Aortic Repair (FEVAR) is currently navigated by 2D fluoroscopy which is insufficiently informative. Previously, a semi-automatic 3D shape instantiation method was developed to instantiate the 3D shape of a main, deployed, and fenestrated stent graft from a single fluoroscopy projection in real-time, which could help 3D FEVAR navigation and robotic path planning. This proposed semi-automatic method was based on the Robust Perspective-S-Point (RP5P) method, graft gap interpolation and semiautomatic multiple-class marker center determination. In this paper, an automatic 3D shape instantiation could be achieved by automatic multiple-class marker segmentation and hence automatic multiple-class marker center determination. Firstly, the markers were designed into five different shapes. Then, Equally-weighted Focal U-Net was proposed to segment the fluoroscopy projections of customized markers into five classes and hence to determine the marker centers. The proposed Equally-weighted Focal U-Net utilized U-Net as the network architecture, equally-weighted loss function for initial marker segmentation, and then equally-weighted focal loss function for improving the initial marker segmentation. This proposed network outperformed traditional Weighted U-Net on the class-imbalance segmentation in this paper with reducing one hyperparameter - the weight. An overall mean Intersection over Union (mIoU) of 0.6943 was achieved on 78 testing images, where 81.01 % markers were segmented with a center position error <; 1.6mm. Comparable accuracy of 3D shape instantiation was also achieved and stated. The data, trained models and TensorFlow codes are available on-line.
ER  - 

TY  - CONF
TI  - A Confidence-Based Shared Control Strategy for the Smart Tissue Autonomous Robot (STAR)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1268
EP  - 1275
AU  - H. Saeidi
AU  - J. D. Opfermann
AU  - M. Kam
AU  - S. Raghunathan
AU  - S. Leonard
AU  - A. Krieger
PY  - 2018
KW  - biological tissues
KW  - blood
KW  - medical robotics
KW  - mobile robots
KW  - surgery
KW  - confidence-based shared control strategy
KW  - STAR
KW  - surgery systems
KW  - robotic accuracy
KW  - surgical procedures
KW  - complex surgical environments
KW  - surgical scenarios
KW  - cutting pattern
KW  - robotic electrocautery tool
KW  - surgical task
KW  - confidence models
KW  - confidence-based control allocation function
KW  - autonomous robot controller
KW  - smart tissue autonomous robot
KW  - autonomous robotic assisted surgery
KW  - 2D pattern cutting
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Surgery
KW  - Human factors
KW  - Cameras
KW  - Blood
DO  - 10.1109/IROS.2018.8594290
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous robotic assisted surgery (RAS) systems aim to reduce human errors and improve patient outcomes leveraging robotic accuracy and repeatability during surgical procedures. However, full automation of RAS in complex surgical environments is still not feasible and collaboration with the surgeon is required for safe and effective use. In this work, we utilize our Smart Tissue Autonomous Robot (STAR) to develop and evaluate a shared control strategy for the collaboration of the robot with a human operator in surgical scenarios. We consider 2D pattern cutting tasks with partial blood occlusion of the cutting pattern using a robotic electrocautery tool. For this surgical task and RAS system, we i) develop a confidence-based shared control strategy, ii) assess the pattern tracking performances of manual and autonomous controls and identify the confidence models for human and robot as well as a confidence-based control allocation function, and iii) experimentally evaluate the accuracy of our proposed shared control strategy. In our experiments on porcine fat samples, by combining the best elements of autonomous robot controller with complementary skills of a human operator, our proposed control strategy improved the cutting accuracy by 6.4%, while reducing the operator work time to 44% compared to a pure manual control.
ER  - 

TY  - CONF
TI  - A 3D Laparoscopic Imaging System Based on Stereo-Photogrammetry with Random Patterns
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1276
EP  - 1282
AU  - C. Sui
AU  - Z. Wang
AU  - Y. Liu
PY  - 2018
KW  - image reconstruction
KW  - image sensors
KW  - lenses
KW  - medical image processing
KW  - photogrammetry
KW  - stereo image processing
KW  - surgery
KW  - high frame rate image acquisition
KW  - stereo-photogrammetry
KW  - coded structured patterns projection
KW  - stereo matching
KW  - 3D surface reconstruction
KW  - stereo vision feedback
KW  - novel 3D laparoscopic imaging system
KW  - frequency 4.0 kHz
KW  - Three-dimensional displays
KW  - Laparoscopes
KW  - Lenses
KW  - Imaging
KW  - Probes
KW  - Image resolution
KW  - Surface reconstruction
DO  - 10.1109/IROS.2018.8593733
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel 3D laparoscopic imaging system based on stereo-photogrammetry which is assisted by projecting patterns on the tissue surface. The proposed laparoscopic imaging system has three optic channels, two of which are responsible for stereo vision feedback and the other one is used for coded structured patterns projection. The projected patterns provide the robustness to homogeneous tissue surface since they add more features that can be relied on in the stereo matching. Image fiber bundles (100k pixels) and Gradient-index (GRIN) lenses are utilized to facilitate the remote image acquisition and miniaturization of the laparoscopic probe. Moreover, we adopt a digital micromirror device (DMD) and high-speed cameras to achieve fast pattern switching (up to 4 kHz) and high frame rate image acquisition. The system configuration allows for implementation of the time multiplexing pattern codification strategy in the 3D laparoscopic imaging system to enhance the reliability and resolution of the 3D surface reconstruction. A prototype is established, and various experiments are conducted. Comparative experimental results prove the advantages of our system design. The static and dynamic 3D reconstruction results validate the performance of the proposed 3D laparoscopic imaging system quantitatively and qualitatively.
ER  - 

TY  - CONF
TI  - Magnetic- Visual Sensor Fusion-based Dense 3D Reconstruction and Localization for Endoscopic Capsule Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1283
EP  - 1289
AU  - M. Turan
AU  - Y. Almalioglu
AU  - E. P. Ornek
AU  - H. Araujo
AU  - M. F. Yanik
AU  - M. Sitti
PY  - 2018
KW  - biomedical optical imaging
KW  - cameras
KW  - endoscopes
KW  - image fusion
KW  - image reconstruction
KW  - medical image processing
KW  - medical robotics
KW  - robot vision
KW  - visual sensor fusion-based dense 3D reconstruction
KW  - real-time 3D reconstruction
KW  - actively controlled capsule endoscopic robots
KW  - minimally invasive diagnostic technology
KW  - therapeutic technology
KW  - gastrointestinal tract
KW  - intraoperative map fusion approach
KW  - actively controlled endoscopic capsule robot applications
KW  - magnetic vision-based localization
KW  - nonrigid deformations
KW  - frame-to-model map fusion
KW  - ex-vivo porcine stomach models
KW  - root mean square surface reconstruction errors
KW  - endoscopic camera
KW  - Magnetic resonance imaging
KW  - Robot sensing systems
KW  - Magnetic separation
KW  - Three-dimensional displays
KW  - Cameras
KW  - Endoscopes
DO  - 10.1109/IROS.2018.8594485
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable and real-time 3D reconstruction and localization functionality is a crucial prerequisite for the navigation of actively controlled capsule endoscopic robots as an emerging, minimally invasive diagnostic and therapeutic technology for use in the gastrointestinal (GI) tract. In this study, we propose a fully dense, non-rigidly deformable, strictly real-time, intraoperative map fusion approach for actively controlled endoscopic capsule robot applications which combines magnetic and vision-based localization, with non-rigid deformations based frame-to-model map fusion. The performance of the proposed method is evaluated using four different ex-vivo porcine stomach models. Across different trajectories of varying speed and complexity, and four different endoscopic cameras, the root mean square surface reconstruction errors vary from 1.58 to 2.17 cm.
ER  - 

TY  - CONF
TI  - Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1290
EP  - 1297
AU  - Z. Min
AU  - J. Wang
AU  - S. Song
AU  - M. Q. -. Meng
PY  - 2018
KW  - expectation-maximisation algorithm
KW  - Gaussian distribution
KW  - image registration
KW  - matrix algebra
KW  - optimisation
KW  - anisotropic positional uncertainties
KW  - E-step
KW  - correspondence probabilities
KW  - M-step
KW  - transformation matrix
KW  - constrained optimization problem
KW  - expectation conditional maximization framework
KW  - multivariate Gaussian distribution
KW  - positional error
KW  - generalized point cloud registration problem
KW  - computer-assisted surgery
KW  - medical robotics
KW  - robust generalized point cloud registration
KW  - Three-dimensional displays
KW  - Hidden Markov models
KW  - Covariance matrices
KW  - Surgery
KW  - Optimization
KW  - Mixture models
KW  - Linear programming
DO  - 10.1109/IROS.2018.8593558
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Alignment of two point clouds is an essential problem in medical robotics and computer-assisted surgery. In this paper, we first formally formulate the generalized point cloud registration problem in a probabilistic manner. Specifically, not only positional but also the orientational information are incorporated into registration. Notably, the positional error is assumed to obey a multivariate Gaussian distribution to accommodate anisotropic cases. Expectation conditional maximization framework is utilized to solve the problem. In E-step, the correspondence probabilities between points in two generalized point clouds are computed. In M -step, the constrained optimization problem with respect to the transformation matrix is re-formulated as an unconstrained one. Extensive experiments are conducted to compare the proposed algorithm with the state-of-the-art registration methods. The experimental results demonstrate the algorithm's robustness to noise and outliers, fast convergence speed.
ER  - 

TY  - CONF
TI  - Vision-Based Surgical Tool Pose Estimation for the da Vinci® Robotic Surgical System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1298
EP  - 1305
AU  - R. Hao
AU  - O. Özgüner
AU  - M. C. Çavuşoğlu
PY  - 2018
KW  - Bayes methods
KW  - computer vision
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - robot vision
KW  - stereo image processing
KW  - surgery
KW  - virtual reality
KW  - robot endoscopes
KW  - defined tool geometry
KW  - virtual images
KW  - silhouette rendering algorithm
KW  - Bayesian state estimation
KW  - computer vision techniques
KW  - robot kinematics
KW  - stereo vision
KW  - vision-based Surgical tool pose estimation
KW  - surgical robotic system
KW  - surgical tool tracking
KW  - endoscopic stereo image streams
KW  - virtual rendering method
KW  - Tools
KW  - Solid modeling
KW  - Rendering (computer graphics)
KW  - Robots
KW  - Cameras
KW  - Bayes methods
KW  - Geometry
DO  - 10.1109/IROS.2018.8594471
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an approach to surgical tool tracking using stereo vision for the da Vinci® Surgical Robotic System. The proposed method is based on robot kinematics, computer vision techniques and Bayesian state estimation. The proposed method employs a silhouette rendering algorithm to create virtual images of the surgical tool by generating the silhouette of the defined tool geometry under the da Vinci® robot endoscopes. The virtual rendering method provides the tool representation in image form, which makes it possible to measure the distance between the rendered tool and real tool from endoscopic stereo image streams. Particle Filter algorithm employing the virtual rendering method is then used for surgical tool tracking. The tracking performance is evaluated on an actual da Vinci® surgical robotic system and a ROS/Gazebo-based simulation of the da Vinci® system.
ER  - 

TY  - CONF
TI  - A Parallel Robotic Mechanism for the Stabilization and Guidance of an Endoscope Tip in Laser Osteotomy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1306
EP  - 1311
AU  - M. Eugster
AU  - P. C. Cattin
AU  - A. Zam
AU  - G. Rauter
PY  - 2018
KW  - bone
KW  - endoscopes
KW  - laser applications in medicine
KW  - medical robotics
KW  - orthopaedics
KW  - surgery
KW  - parallel robotic mechanism
KW  - laser osteotomy
KW  - endoscope tip stabilization
KW  - robot-assisted minimally invasive laser osteotome
KW  - robust platform
KW  - sub-millimeter range
KW  - endoscope tip motion
KW  - Endoscopes
KW  - Bones
KW  - Laser beam cutting
KW  - Rails
KW  - Kinematics
KW  - End effectors
DO  - 10.1109/IROS.2018.8594188
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a parallel robotic mechanism for endoscope tip stabilization and guidance for a robot-assisted minimally invasive laser osteotome. The mechanism attaches to the bone of the patient, providing a stable and robust platform for the laser integrated in the endoscope tip which has to be moved precisely in the sub-millimeter range along a preoperatively planned path. This method is only possible because cutting bone with laser instead of using conventional bone drills and saws involves considerably lower interaction forces. The design, kinematics, control, and motion performance of the concept are presented for an upscaled prototype. The obtained deviation of the endoscope tip motion from the reference path lies in the sub-millimeter range. This result allows us to conclude that the concept is more than promising. Furthermore, we expect that the herein presented principle will influence the way osteotomies will be performed in the future.
ER  - 

TY  - CONF
TI  - RoboTracker: Collaborative robotic assistant device with electromechanical patient tracking for spinal surgery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1312
EP  - 1317
AU  - A. Amarillo
AU  - J. Oñativia
AU  - E. Sanchez
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - medical robotics
KW  - neurophysiology
KW  - orthopaedics
KW  - surgery
KW  - RoboTracker
KW  - electromechanical patient tracking
KW  - spinal surgery
KW  - neural damage
KW  - spinal surgical procedures
KW  - pedicle screw fixation
KW  - technological improvements
KW  - surgeons
KW  - optical tracking navigation
KW  - stringent limitation
KW  - tracked elements
KW  - miniature robot
KW  - novel robotic assisted surgery system
KW  - surgical instruments
KW  - patient motion
KW  - electromechanical tracking device
KW  - collaborative robotic assistant device
KW  - Fasteners
KW  - Tracking
KW  - Surgery
KW  - Robot kinematics
KW  - Kinematics
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594467
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Due to the risks of muscle, bone and neural damage in spinal surgical procedures that require pedicle screw fixation, technological improvements have appeared to help surgeons perform the procedures with higher accuracy. Systems based on optical tracking navigation impose a stringent limitation in the workflow of surgeons since a clear line of sight has to be kept between the cameras and the tracked elements. Other solutions are based on mounting a miniature robot on the spine of the patient, which is very invasive and entails some risks. For these reasons, a novel robotic assisted surgery system capable to guide surgical instruments with minimal deviations compensating patient motion is being developed. This paper presents the system and the electromechanical tracking device used to sense patient motion.
ER  - 

TY  - CONF
TI  - A Sliding Mode Control Architecture for Human-Manipulator Cooperative Surface Treatment Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1318
EP  - 1325
AU  - L. Gracia
AU  - J. E. Solanes
AU  - P. Muñoz-Benavent
AU  - J. V. Miro
AU  - C. Perez-Vidal
AU  - J. Tornero
PY  - 2018
KW  - control engineering computing
KW  - deburring
KW  - end effectors
KW  - force sensors
KW  - industrial manipulators
KW  - industrial robots
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - position control
KW  - variable structure systems
KW  - redundant 7R manipulator
KW  - robotic surface treatment
KW  - novel collaborative controller
KW  - robot motion
KW  - robotic tool
KW  - conditioning task
KW  - robot end-effector
KW  - surface treatment tool
KW  - nonconventional sliding mode control
KW  - task prioritization
KW  - control scheme
KW  - autonomous physical agent
KW  - human operator propioceptive abilities
KW  - shared strategy effectively couples
KW  - robotic manipulator partner
KW  - physical strength
KW  - surface treatment tasks
KW  - human-manipulator
KW  - sliding mode control architecture
KW  - Robot sensing systems
KW  - Surface treatment
KW  - Task analysis
KW  - Tools
KW  - Surface morphology
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593444
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a control architecture readily suitable for surface treatment tasks such as polishing, grinding, finishing or deburring as carried out by a human operator, with the added benefit of accuracy, recurrence and physical strength as administered by a robotic manipulator partner. The shared strategy effectively couples the human operator propioceptive abilities and fine skills through his interactions with the autonomous physical agent. The novel proposed control scheme is based on task prioritization and a non-conventional sliding mode control, which is considered to benefit from its inherent robustness and low computational cost. The system relies on two force sensors, one located between the last link of the robot and the surface treatment tool, and the other located in some place of the robot end-effector: the former is used to suitably accomplish the conditioning task, while the latter is used by the operator to manually guide the robotic tool. When the operator chooses to cease guiding the tool, the robot motion safely switches back to an automatic reference tracking. The paper presents the theories for the novel collaborative controller, whilst its effectiveness for robotic surface treatment is substantiated by experimental results using a redundant 7R manipulator and a mock-up conditioning tool.
ER  - 

TY  - CONF
TI  - Human Intention Estimation based on Neural Networks for Enhanced Collaboration with Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1326
EP  - 1333
AU  - D. Nicolis
AU  - A. M. Zanchettin
AU  - P. Rocco
PY  - 2018
KW  - damping
KW  - force sensors
KW  - human-robot interaction
KW  - industrial robots
KW  - motion control
KW  - recurrent neural nets
KW  - sensors
KW  - stability
KW  - trajectory control
KW  - recurrent neural networks
KW  - RNNs
KW  - force sensor
KW  - human-robot collaboration
KW  - human intention estimation
KW  - ABB IRB140 industrial robot
KW  - model-based generated data
KW  - proactive robot behavior
KW  - variable impedance controllers
KW  - admittance behavior
KW  - stability requirements
KW  - Trajectory
KW  - Task analysis
KW  - Robot sensing systems
KW  - Neural networks
KW  - Damping
KW  - Estimation
DO  - 10.1109/IROS.2018.8594415
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In human-robot collaboration, the robot is required to provide assistance to the user by facilitating task execution. However, due to stability requirements, a well-damped admittance behavior of the robot is necessary during interaction, thus inducing fatigue in the operator. While available schemes involve variable impedance controllers to mitigate this effect, here we propose an alternative approach entailing a proactive robot behavior that assists in the cooperative execution of trajectories towards desired goals, by estimating the user intention. To this end, we make use of Recurrent Neural Networks (RNNs) to predict and classify cooperative motions, on the basis of a set of predefined goals in the workspace and model-based generated data of human movements. Manual guidance validation experiments are conducted on a 6 d.o.f. ABB IRB140 industrial robot equipped with a force sensor.
ER  - 

TY  - CONF
TI  - Variable Admittance Control for Human-Robot Collaboration based on Online Neural Network Training
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1334
EP  - 1339
AU  - A. Sharkawy
AU  - P. N. Koustournpardis
AU  - N. Aspragathos
PY  - 2018
KW  - backpropagation
KW  - feedforward neural nets
KW  - human-robot interaction
KW  - manipulators
KW  - motion control
KW  - neurocontrollers
KW  - variable admittance control
KW  - human-robot collaboration
KW  - online neural network training
KW  - human-robot cooperation
KW  - multilayer feedforward neural network
KW  - Cartesian velocity
KW  - admittance controller
KW  - error backpropagation algorithm
KW  - KUKA LWR robot
KW  - virtual damping
KW  - point-to-point cooperative motion
KW  - Admittance
KW  - Artificial neural networks
KW  - Damping
KW  - Trajectory
KW  - Robot kinematics
KW  - Training
KW  - Variable Admittance Control
KW  - Neural Networks
KW  - Error Backpropagation
KW  - Minimum Jerk Trajectory
DO  - 10.1109/IROS.2018.8593526
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a method for variable admittance control in human-robot cooperation is proposed. A multilayer feedforward neural network is designed using the Cartesian velocity of the robot and the applied force by the operator as its inputs to modify online the virtual damping of the admittance controller. The neural network is trained online using the error backpropagation algorithm based on the error between the velocity of the minimum jerk trajectory model and the measured velocity of the robot. The performance of the proposed controller and the NN generalization ability are evaluated by conducting a point-to-point cooperative motion with multiple subjects using the KUKA LWR robot.
ER  - 

TY  - CONF
TI  - Online Human Muscle Force Estimation for Fatigue Management in Human-Robot Co-Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1340
EP  - 1346
AU  - L. Peternel
AU  - C. Fang
AU  - N. Tsagarakis
AU  - A. Ajoudani
PY  - 2018
KW  - electromyography
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - medical computing
KW  - medical robotics
KW  - muscle
KW  - arm configurations
KW  - human-robot comanipulation
KW  - optimisation
KW  - online human muscle force estimation
KW  - human operator
KW  - robot sensory system
KW  - task force
KW  - specific fatigued muscles
KW  - task execution
KW  - fatigue management system
KW  - muscle fatigue levels
KW  - model-based estimation
KW  - estimated muscle forces
KW  - endpoint interaction forces
KW  - online predictions
KW  - machine learning technique
KW  - human arm
KW  - less-fatigued muscles
KW  - anticipatory robotic responses
KW  - individual muscle group
KW  - excessive fatigue levels
KW  - selective management
KW  - Muscles
KW  - Force
KW  - Fatigue
KW  - Task analysis
KW  - Robot sensing systems
KW  - Optimization
DO  - 10.1109/IROS.2018.8593705
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel method for selective management of muscle fatigue in human-robot co-manipulation. The proposed framework enables the detection of excessive fatigue levels of an individual muscle group while executing a certain task, and provides anticipatory robotic responses to distribute the effort among less-fatigued muscles of human arm. Our approach uses a machine learning technique to enable online predictions of muscle forces in different arm configurations and endpoint interaction forces. The estimated muscle forces are then used for the model-based estimation of muscle fatigue levels. Through optimisation, the fatigue management system can alter the task execution in a way that specific fatigued muscles are offloaded, while at the same time enables the production of task force using muscles with lower levels of fatigue. The main advantage of the proposed method is that it can operate online, and that all the measurements are performed by the robot sensory system, which can significantly increase the applicability in real-world scenarios. To validate the proposed method, we performed proof-of-concept experiments where the task of the human operator was to use a tool to polish an object that was manipulated by the robot.
ER  - 

TY  - CONF
TI  - Evolutionary Motion Control Optimization in Physical Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1347
EP  - 1353
AU  - N. A. Nadeau
AU  - I. A. Bonev
PY  - 2018
KW  - biomedical ultrasonics
KW  - evolutionary computation
KW  - force control
KW  - human-robot interaction
KW  - medical robotics
KW  - motion control
KW  - optimisation
KW  - phantoms
KW  - trajectory control
KW  - evolutionary motion control optimization
KW  - medical freehand ultrasound
KW  - trajectory planning
KW  - optimal trajectories
KW  - human leg phantom
KW  - physical human-robot interaction
KW  - online tuning
KW  - collaborative robot
KW  - medical ultrasound motion
KW  - parallel force-impedance control
KW  - differential evolution
KW  - pHRI
KW  - mean absolute error
KW  - Ultrasonic imaging
KW  - Task analysis
KW  - Tuning
KW  - Legged locomotion
KW  - Force
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593598
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Given that the success of an interaction task depends on the capability of the robot system to handle physical contact with its environment, pure motion control is often insufficient. This is especially true in the context of medical freehand ultrasound where the human body is a deformable surface and an unstructured environment, representing both a safety concern and a challenge for trajectory planning and control. The systematic tuning of practical high degree-of-freedom physical human-robot interaction (pHRI) tasks is not trivial and there are many parameters to be tuned. While traditional tuning is generally performed ad hoc and requires knowledge of the robot and environment dynamics, we propose a simple and effective online tuning framework using differential evolution (DE) to optimize the motion parameters for parallel force/impedance control in a pHRI and medical ultrasound motion application. Through real-world experiments with a KUKA LBR iiwa 7 R800 collaborative robot, the DE framework tuned motion control for optimal and safe trajectories along a human leg phantom. The optimization process was able to successfully reduce the mean absolute error of the motion contact force to 0.537 N through the evolution of eight motion control parameters.
ER  - 

TY  - CONF
TI  - Human-Robot Cooperative Object Manipulation with Contact Changes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1354
EP  - 1360
AU  - M. Gienger
AU  - D. Ruiken
AU  - T. Bates
AU  - M. Regaieg
AU  - M. MeiBner
AU  - J. Kober
AU  - P. Seiwald
AU  - A. Hildebrandt
PY  - 2018
KW  - cooperative systems
KW  - human-robot interaction
KW  - interactive systems
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - physical interaction system
KW  - bi-manual physical cooperation
KW  - force interaction cues
KW  - interactive search-based planning
KW  - online trajectory
KW  - motion generation
KW  - mixed initiative collaboration strategy
KW  - human-robot cooperative object manipulation
KW  - human-robot interaction
KW  - bi-manual mobile robot
KW  - Robot sensing systems
KW  - Task analysis
KW  - Planning
KW  - Robot kinematics
KW  - Trajectory
KW  - Synchronization
DO  - 10.1109/IROS.2018.8594140
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a system for cooperatively manipulating large objects between a human and a robot. This physical interaction system is designed to handle, transport, or manipulate large objects of different shapes in cooperation with a human. Unique points are the bi-manual physical cooperation, the sequential characteristic of the cooperation including contact changes, and a novel architecture combining force interaction cues, interactive search-based planning, and online trajectory and motion generation. The resulting system implements a mixed initiative collaboration strategy, deferring to the human when his intentions are unclear, and driving the task once understood. This results in an easy and intuitive human-robot interaction. It is evaluated in simulations and on a bi-manual mobile robot with 32 degrees of freedom.
ER  - 

TY  - CONF
TI  - From Human Physical Interaction To Online Motion Adaptation Using Parameterized Dynamical Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1361
EP  - 1366
AU  - M. Khoramshahi
AU  - A. Laurens
AU  - T. Triquet
AU  - A. Billard
PY  - 2018
KW  - adaptive control
KW  - control engineering computing
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - trajectory control
KW  - parameterized time-independent dynamical systems
KW  - motion flexibility
KW  - motion generation
KW  - impedance-controlled robots
KW  - adaptive motion planning approach
KW  - parameterized dynamical systems
KW  - online motion adaptation
KW  - human physical interaction
KW  - Task analysis
KW  - Trajectory
KW  - Impedance
KW  - Service robots
KW  - Convergence
KW  - Planning
DO  - 10.1109/IROS.2018.8594366
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we present an adaptive motion planning approach for impedance-controlled robots to modify their tasks based on human physical interactions. We use a class of parameterized time-independent dynamical systems for motion generation where the modulation of such parameters allows for motion flexibility. To adapt to human interactions, we update the parameters of our dynamical system in order to reduce the tracking error (i.e., between the desired trajectory generated by the dynamical system and the real trajectory influenced by the human interaction). We provide analytical analysis and several simulations of our method. Finally, we investigate our approach through real world experiments with a 7-DOF KUKA LWR 4+ robot performing tasks such as polishing and pick-and-place.
ER  - 

TY  - CONF
TI  - A Series Elastic Brake Pedal to Preserve Conventional Pedal Feel under Regenerative Braking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1367
EP  - 1373
AU  - U. Caliskan
AU  - A. Apaydin
AU  - A. Otaran
AU  - V. Patoglu
PY  - 2018
KW  - actuators
KW  - brakes
KW  - closed loop systems
KW  - elasticity
KW  - force control
KW  - force feedback
KW  - regenerative braking
KW  - robust control
KW  - series elastic brake pedal
KW  - force-feedback brake pedal
KW  - series elastic actuation
KW  - closed-loop force control
KW  - pedal feel compensation
KW  - regenerative braking
KW  - robust controller
KW  - fidelity force control
KW  - impedance characteristic
KW  - frequency spectrum
KW  - Brakes
KW  - Force
KW  - Friction
KW  - Force control
KW  - Actuators
KW  - Vehicles
KW  - Couplings
DO  - 10.1109/IROS.2018.8594317
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a force-feedback brake pedal with series elastic actuation to preserve the conventional brake pedal feel during cooperative regenerative braking. The novelty of the proposed design is due to the deliberate introduction of a compliant element between the actuator and the brake pedal whose deflections are measured to estimate interaction forces and to perform closed-loop force control. Thanks to its series elasticity, the force-feedback brake pedal can utilize robust controllers to achieve high fidelity force control, possesses favorable output impedance characteristics over the entire frequency spectrum, and can be implemented in a compact package using low-cost components. The applicability and effectiveness of the proposed series elastic brake pedal have been tested through human subject experiments that evaluate simulated cooperative regenerative braking scenarios with and without pedal feel compensation. The experimental results and responses to the accompanying questionnaire indicate that pedal feel compensation through the series elastic brake pedal can significantly decrease hard braking instances, improving safety and driver experience.
ER  - 

TY  - CONF
TI  - Unmanned Aerial Auger for Underground Sensor Installation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1374
EP  - 1381
AU  - Y. Sun
AU  - A. Plowcha
AU  - M. Nail
AU  - S. Elbaum
AU  - B. Terry
AU  - C. Detweiler
PY  - 2018
KW  - Auger effect
KW  - autonomous aerial vehicles
KW  - geophysical equipment
KW  - geophysical techniques
KW  - sensors
KW  - soil
KW  - underground equipment
KW  - digging mechanism
KW  - power consumption
KW  - unmanned aerial systems
KW  - target soil sensors
KW  - unmanned aerial auger performance
KW  - UAS
KW  - underground sensor installation
KW  - depth 120.0 mm
KW  - Force
KW  - Robot sensing systems
KW  - Substrates
KW  - Fasteners
KW  - Monitoring
KW  - Soil moisture
DO  - 10.1109/IROS.2018.8593824
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Using an Unmanned Aerial Systems (UAS) to autonomously deploy soil sensors enables their installation in otherwise hard to access locations. In this paper, we present a system that integrates a UAS and a digging mechanism which can carry, secure, and install a small sensor into dirt effectively and efficiently. The integrated system includes 1) a low profile, light-weight, inexpensive auger mechanism, 2) a sensor carrying and deploying mechanism with low power consumption, and 3) sensors and software that control and evaluate the auger performance during digging. When tested on a suite of target soils and a target depth of 120mm, the system achieved a success rate of 100% for indoor tests and 92.5% for outdoors, verifying the potential of the approach.
ER  - 

TY  - CONF
TI  - Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1382
EP  - 1388
AU  - H. Kim
AU  - M. A. Woodward
AU  - M. Sitti
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - design engineering
KW  - drag
KW  - mobile robots
KW  - optimal control
KW  - pitch control (position)
KW  - robot dynamics
KW  - active pitch control strategy
KW  - center-of-mass location
KW  - morphological intelligence
KW  - optimal control strategy
KW  - collapsible airfoils
KW  - nonsteady-state gliding performance
KW  - gliding robots
KW  - drag coefficients
KW  - aerodynamic complexities
KW  - Robots
KW  - Automotive components
KW  - Aerodynamics
KW  - Optimization
KW  - Atmospheric modeling
KW  - Trajectory
KW  - Springs
DO  - 10.1109/IROS.2018.8593613
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.
ER  - 

TY  - CONF
TI  - Active Range and Bearing-based Radiation Source Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1389
EP  - 1394
AU  - M. S. Lee
AU  - D. Shy
AU  - W. R. Whittaker
AU  - N. Michael
PY  - 2018
KW  - cameras
KW  - image sensors
KW  - radioactive sources
KW  - static step size
KW  - radiation mapping approach
KW  - active source localization approach
KW  - adaptive step size
KW  - localization time
KW  - 3D radiation source localization
KW  - bearing sensor
KW  - Compton gamma camera
KW  - image radiation
KW  - source locations
KW  - active source localization framework
KW  - Fisher Information
KW  - bearing-based radiation source localization
KW  - passive source localization
KW  - size 0.26 m
KW  - Sensors
KW  - Cameras
KW  - Photonics
KW  - Three-dimensional displays
KW  - Image sensors
KW  - Position measurement
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593625
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D radiation source localization is a common task across applications such as decommissioning, disaster response, and security, but traditional count-based sensors struggle to efficiently disambiguate between symmetries in sensor, source, and environment configurations. Recent works have demonstrated successful passive source localization using a bearing sensor called the Compton gamma camera that can image radiation. This paper first presents an approach to mapping the spatial distribution of radiation with a gamma camera to estimate source locations. An active source localization framework is then developed that greedily selects new waypoints that maximize the Fisher Information provided by the camera's range and bearing observations for source localization. Finally the common assumption of a static step size in between waypoints is relaxed to allow step sizes to adapt online to the observed information. The proposed radiation mapping approach is evaluated in 5×4 m2 and 14×6 m2 laboratory environments, where multiple point sources were localized to within an average of 0.26 m or 0.6% of the environment dimensions. The active source localization approach is evaluated in simulation and an adaptive step size yields a 27% decrease in the localization time and a 16% decrease in the distance traveled to localize a source in a 15×15×15 m3 environment.
ER  - 

TY  - CONF
TI  - Development of Camber-Flat Wing Structure Convert Mechanism for Asymmetric Flapping Micro Air Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1395
EP  - 1400
AU  - J. Jang
AU  - G. Yang
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - design engineering
KW  - vehicle dynamics
KW  - r asymmetric flapping micro air vehicle
KW  - rigidity
KW  - camber-flat wing structure convert mechanism
KW  - Force
KW  - Muscles
KW  - Robots
KW  - Drag
KW  - Force measurement
KW  - Insects
KW  - Actuators
DO  - 10.1109/IROS.2018.8594104
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study presents principle of the camber-flat wing structure conversion mechanism, which is inspired by a dragonfly, and its applicability to MAV. The camber-flat wing structure convert mechanism makes MAV flight using asymmetric flapping pattern through control of angle of attack without complicate structure. This mechanism was inspired from the dragonfly's feature that the camber structure of the wing increases the rigidity of wing structure and makes dragonfly has asymmetric flapping pattern. Experimental results show that MAV has asymmetric flapping pattern that can more stable flight performance when hovering flight with a camber structure and superior performance when the forward flight with a flat structure. The average lift force in the camber wing structure was 0.02N, the average thrust force was 0.02N and the average lift force was 0.011N in the flat wing structure at 20 Hz flapping frequency.
ER  - 

TY  - CONF
TI  - Robotic Boreblending: The Future of In-Situ Gas Turbine Repair
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1401
EP  - 1406
AU  - D. Alatorre
AU  - B. Nasser
AU  - A. Rabani
AU  - A. Nagy-Sochacki
AU  - X. Dong
AU  - D. Axinte
AU  - J. Kell
PY  - 2018
KW  - compressors
KW  - gas turbines
KW  - industrial robots
KW  - inspection
KW  - maintenance engineering
KW  - maintenance
KW  - robot flexible joints
KW  - kinematic analysis
KW  - In-Situ Gas Turbine Repair
KW  - robotic boreblending
KW  - Tools
KW  - Blades
KW  - Maintenance engineering
KW  - Turbines
KW  - Joints
KW  - End effectors
DO  - 10.1109/IROS.2018.8594155
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Automation of inspection and repair tasks on complex installations is gaining attention from industries with high-value assets such as aerospace, nuclear and marine. This paper reports on a five degrees of freedom robotic system capable of performing accurate and repeatable repair procedures through a narrow inspection port, which minimizes the cost and downtime associated with unscheduled maintenance. Careful study of the target working volume and repair process informed the design of a robotic probe capable of replicating the operation. Kinematic analysis of the robot's flexible, prismatic and rotary joints was used to define accurate machining paths in 3D space, and the results were verified using an optical motion capture system (accuracy of 0.25 mm). After comprehensive verifications of the constitutive elements, the robotic system was successfully demonstrated for repair of a high-pressure compressor aerofoil in a gas turbine. The results not only proves the ability of the system to address such difficult repair scenarios but also highlights a domain of opportunities in developing specialist robotics for repair of high-value assets, which is a subject to growing global demand.
ER  - 

TY  - CONF
TI  - Design of an Autonomous Robot for Mapping, Navigation, and Manipulation in Underground Mines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1407
EP  - 1412
AU  - R. Lösch
AU  - S. Grehl
AU  - M. Donner
AU  - C. Buhl
AU  - B. Jung
PY  - 2018
KW  - cameras
KW  - inertial systems
KW  - manipulators
KW  - mining
KW  - mobile robots
KW  - robot vision
KW  - sensors
KW  - autonomous driving
KW  - autonomous robot
KW  - manipulation
KW  - underground mines
KW  - dangerous working environment
KW  - harsh environment
KW  - robot design
KW  - underground objects
KW  - manipulating objects
KW  - robotic arm
KW  - robust four wheeled platform
KW  - depth cameras
KW  - inertial measurement unit
KW  - autonomous navigation
KW  - Robot sensing systems
KW  - Manipulators
KW  - Cameras
KW  - Navigation
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8594190
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Underground mines are a dangerous working environment and, therefore, robots could help putting less humans at risk. Traditional robots, sensors, and software often do not work reliably underground due to the harsh environment. This paper analyzes requirements and presents a robot design capable of navigating autonomously underground and manipulating objects with a robotic arm. The robot's base is a robust four wheeled platform powered by electric motors and able to withstand the harsh environment. It is equipped with color and depth cameras, lighting, laser scanners, an inertial measurement unit, and a robotic arm. We conducted two experiments testing mapping and autonomous navigation. Mapping a 75 meters long route including a loop closure results in a map that qualitatively matches the original map to a good extent. Testing autonomous driving on a previously created map of a second, straight, 150 meters long route was also successful. However, without loop closure, rotation errors cause apparent deviations in the created map. These first experiments showed the robot's operability underground.
ER  - 

TY  - CONF
TI  - Design and Performance Evaluation of an Infotaxis-Based Three-Dimensional Algorithm for Odor Source Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1413
EP  - 1420
AU  - J. Ruddick
AU  - A. Marjovi
AU  - F. Rahbar
AU  - A. Martinoli
PY  - 2018
KW  - electronic noses
KW  - gases
KW  - mobile robots
KW  - probability
KW  - wind tunnels
KW  - gaseous leak source
KW  - high wind speeds
KW  - environmental conditions
KW  - environmental parameters
KW  - multiple algorithmic parameters
KW  - wind tunnel
KW  - probabilistic Infotaxis algorithm
KW  - odor source localization
KW  - infotaxis-based three-dimensional algorithm
KW  - Robots
KW  - Entropy
KW  - Atmospheric modeling
KW  - Mathematical model
KW  - Probabilistic logic
KW  - Numerical models
KW  - Probability
DO  - 10.1109/IROS.2018.8593997
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we tackle the problem of finding the source of a gaseous leak with a robot in a three-dimensional (3-D) physical space. The proposed method extends the operational range of the probabilistic Infotaxis algorithm [1] into 3-D and makes multiple improvements in order to increase its performance in such settings. The method has been tested systematically through high-fidelity simulations and in a wind tunnel emulating realistic conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments. The algorithm shows good performance in various environmental conditions, particularly in high wind speeds and different source release rates.
ER  - 

TY  - CONF
TI  - Cognition-enabled Framework for Mixed Human-Robot Rescue Teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1421
EP  - 1428
AU  - F. Yazdani
AU  - G. Kazhoyan
AU  - A. K. Bozcuoğlu
AU  - A. Haidu
AU  - F. Bálint-Benczédi
AU  - D. Beßler
AU  - M. Pomarlan
AU  - M. Beetz
PY  - 2018
KW  - cognition
KW  - human-robot interaction
KW  - mobile robots
KW  - telerobotics
KW  - cognition-enabled framework
KW  - rescue missions
KW  - cognitive capabilities
KW  - robot behavior
KW  - human-robot rescue teams
KW  - human-robot interaction
KW  - visibility areas
KW  - robotic systems teleoperation
KW  - locomotion areas
KW  - belief state representations
KW  - Cognition
KW  - Robot sensing systems
KW  - Geographic information systems
KW  - Task analysis
KW  - Lakes
KW  - Bridges
DO  - 10.1109/IROS.2018.8594311
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.
ER  - 

TY  - CONF
TI  - Pulleys and Force Sensors Influence on Payload Estimation of Cable-Driven Parallel Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1429
EP  - 1436
AU  - É. Picard
AU  - S. Caro
AU  - F. Claveau
AU  - F. Plestan
PY  - 2018
KW  - cables (mechanical)
KW  - feedforward
KW  - force sensors
KW  - manipulators
KW  - motion control
KW  - pulleys
KW  - robot kinematics
KW  - robust control
KW  - torque control
KW  - Cable-Driven Parallel robots
KW  - suspended Cable-Driven Parallel Robot
KW  - heavy objects
KW  - heterogeneous objects
KW  - payload mass
KW  - robust control
KW  - pulleys
KW  - payload estimation
KW  - geometric model
KW  - mass estimations
KW  - cable tensions
KW  - torque controller
KW  - real-time mass compensation
KW  - CDPR prototype
KW  - force sensors influence
KW  - pick-and-place operations
KW  - Pulleys
KW  - Payloads
KW  - Mechanical cables
KW  - Estimation
KW  - Robots
KW  - Prototypes
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594171
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The subject of this paper is about the use of a suspended Cable-Driven Parallel Robot (CDPR) for pick-and-place operations of heavy and heterogeneous objects. The knowledge of the payload mass and its center of mass in realtime is an asset for robust control of the device, which is required to ensure a good stability, especially when the objects have different shapes, sizes and masses. Accordingly, this paper aims at experimentally evaluating the effects of (i) the pulleys modeling and (ii) the use of force sensors for the payload estimation. It turns out that the consideration of the pulleys into the geometric model of the robot improves the mass and center of mass estimations of the payload. A comparison is made between the estimation of cable tensions from force sensors and from motor currents. Finally, a torque controller with a feedforward term for real-time mass compensation is proposed and implemented on a CDPR prototype.
ER  - 

TY  - CONF
TI  - 3D-printed flexure-based finger joints for anthropomorphic hands
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1437
EP  - 1442
AU  - L. Garcia
AU  - M. Naves
AU  - D. M. Brouwer
PY  - 2018
KW  - dexterous manipulators
KW  - grippers
KW  - hinges
KW  - production engineering computing
KW  - prosthetics
KW  - springs (mechanical)
KW  - three-dimensional printing
KW  - 3D printed flexure-based finger joints
KW  - grasping force
KW  - load bearing capacity
KW  - anthropomorphic hands
KW  - nonflexure-based prosthetic hands
KW  - presented joints power grasping capability outperform current state flexure-base hands
KW  - Angle Three-Flexure Cross Hinge
KW  - Fasteners
KW  - Force
KW  - Topology
KW  - Grasping
KW  - Stress
KW  - Optimization
KW  - Load modeling
KW  - Compliant joints
KW  - flexures
KW  - robotic hand
KW  - prosthetic hand
KW  - anthropomorphic
KW  - additive manufacturing
DO  - 10.1109/IROS.2018.8594102
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flexure-based finger joints for prosthetic hands have been studied, but until now they lack stiffness and load bearing capacity. In this paper we present a design which combines large range of motion, stiffness and load bearing capacity, with an overload protection mechanism. Several planar and non-planar hinge topologies are studied to determine load capacity over the range of motion. Optimized topologies are compared, in 30 degrees deflected state, in terms of stresses by deflection and grasping forces. Additionally, support stiffnesses were computed for all hinges in the whole range of motion (45 degrees). The Hole Cross Hinge presented the best performance over the range of motion with a grasping force up to 15 N while deflected 30 degrees. A new concept, the Angle Three-Flexure Cross Hinge, provides outstanding performance for deflections from 17.5 up to 30 degrees with a 20 N maximum grasping force when fully deflected. Experimental verification of the support stiffness over the range of motion shows some additional compliances, but the stiffness trend of the printed hinge is in line with the model. The presented joints power grasping capability outperform current state flexure-base hands and are comparable to commercial non-flexure-based prosthetic hands. In the event of excessive loads, an overload protection mechanism is in place to protect the flexure- hinges.
ER  - 

TY  - CONF
TI  - Body-Mounted Robot for Image-Guided Percutaneous Interventions: Mechanical Design and Preliminary Accuracy Evaluation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1443
EP  - 1448
AU  - N. A. Patel
AU  - J. Yan
AU  - D. Levi
AU  - R. Monfaredi
AU  - K. Cleary
AU  - I. Iordachita
PY  - 2018
KW  - biomedical MRI
KW  - computerised tomography
KW  - diagnostic radiography
KW  - image registration
KW  - manipulators
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - robot kinematics
KW  - surgery
KW  - needle-based percutaneous interventions
KW  - biopsy seed placement
KW  - brachytherapy seed placement
KW  - robot mechanism
KW  - Magnetic Resonance Imaging
KW  - repeatable robot registration
KW  - robot kinematics
KW  - robot calibration procedure
KW  - robotic manipulator
KW  - body-mounted robot
KW  - image-guided percutaneous interventions
KW  - MRI guidance
KW  - Computed Tomography
KW  - shoulder arthrography
KW  - Robot kinematics
KW  - Magnetic resonance imaging
KW  - Needles
KW  - Manipulators
KW  - Computed tomography
KW  - Calibration
DO  - 10.1109/IROS.2018.8593807
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a body-mounted, four degree-of-freedom (4-DOF) parallel mechanism robot for image-guided percutaneous interventions. The design of the robot is optimized to be light weight and compact such that it could be mounted to the patient body. It has a modular design that can be adopted for assisting various image-guided, needle-based percutaneous interventions such as arthrography, biopsy and brachytherapy seed placement. The robot mechanism and the control system are designed and manufactured with components compatible with imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT). The current version of the robot presented in this paper is optimized for shoulder arthrography under MRI guidance; a Z-shaped fiducial frame is attached to the robot, providing accurate and repeatable robot registration with the MR scanner coordinate system. Here we present the mechanical design of the manipulator, robot kinematics, robot calibration procedure, and preliminary bench-top accuracy assessment. The bench-top accuracy evaluation of the robotic manipulator shows average translational error of 1.01 mm and 0.96 mm in X and Z axes, respectively, and average rotational error of 3.06 degrees and 2.07 degrees about the X and Z axes, respectively.
ER  - 

TY  - CONF
TI  - HERI II: A Robust and Flexible Robotic Hand based on Modular Finger design and Under Actuation Principles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1449
EP  - 1455
AU  - Z. Ren
AU  - N. Kashiri
AU  - C. Zhou
AU  - N. G. Tsagarakis
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - manipulators
KW  - position measurement
KW  - design effectiveness
KW  - resilient manipulation
KW  - robust manipulation
KW  - Centauro Robot
KW  - transmission system
KW  - motor current readings
KW  - finger phalanxes
KW  - contact pressure
KW  - absolute position measurements
KW  - precise grasping
KW  - delicate grasping
KW  - sensory system
KW  - under-actuated transmission
KW  - single actuator
KW  - finger module
KW  - finger arrangement
KW  - highly integrated modular finger units
KW  - under-actuated hand
KW  - actuation principles
KW  - modular finger design
KW  - HERI II
KW  - Grasping
KW  - Tendons
KW  - Force
KW  - Pulleys
KW  - Thumb
KW  - Robots
DO  - 10.1109/IROS.2018.8594507
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces the design of a novel under-actuated hand with highly integrated modular finger units, which can be easily reconfigured in terms of finger arrangement and number to account for the manipulation needs of different applications. Each finger module is powered by a single actuator through an under-actuated transmission and equipped with a sensory system for delicate and precise grasping, which includes absolute position measurements, contact pressure sensing at finger phalanxes and motor current readings. Finally, intrinsic elasticity integrated in the transmission system make the hand robust and adaptive to impacts when interacting with the objects and environment. This highly integrated hand (HERI II) was developed for the Centauro Robot to enable robust and resilient manipulation. A set of experiments demonstrating the hand's grasping performance were carried out and fully verified the design effectiveness of the proposed hand.
ER  - 

TY  - CONF
TI  - Design, Modeling and Control of a Soft Robotic Arm
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1456
EP  - 1463
AU  - M. Hofer
AU  - R. D'Andrea
PY  - 2018
KW  - closed loop systems
KW  - design engineering
KW  - linear quadratic Gaussian control
KW  - manipulators
KW  - nonlinear control systems
KW  - pendulums
KW  - pressure control
KW  - stability
KW  - valves
KW  - soft robotic arm
KW  - hybrid robotic arm
KW  - soft bladders
KW  - inflatable bladders
KW  - low cost switching valves
KW  - pressure control
KW  - valve model
KW  - system identification
KW  - linear quadratic Gaussian controller
KW  - closed loop control performance
KW  - stabilization
KW  - rotational inverted pendulum
KW  - Furuta pendulum
KW  - Actuators
KW  - Valves
KW  - Manipulators
KW  - Fabrics
KW  - Welding
KW  - Switches
DO  - 10.1109/IROS.2018.8594221
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present the design of a hybrid robotic arm using soft, inflatable bladders for actuation. Low cost switching valves are used for pressure control, where the valve model is identified experimentally. A model of the robotic arm is derived based on system identification and used to derive a linear quadratic Gaussian controller. A method to solve limitations of the employed switching valves is proposed and experimentally proven to improve tracking performance. The closed loop control performance of the robotic arm is demonstrated by stabilizing a rotational inverted pendulum known as the Furuta pendulum.
ER  - 

TY  - CONF
TI  - Energy-Efficient Design and Control of a Vibro-Driven Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1464
EP  - 1469
AU  - P. Liu
AU  - G. Neumann
AU  - Q. Fu
AU  - S. Pearson
AU  - H. Yu
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - friction
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - position control
KW  - robot dynamics
KW  - springs (mechanical)
KW  - stick-slip
KW  - trajectory generation profile
KW  - VDR systems
KW  - nonlinear-motion prototype
KW  - physical robot
KW  - dynamic contributions
KW  - driving pendulum
KW  - partial feedback controller
KW  - tracking control
KW  - noncollocated constraint conditions
KW  - travelling distance
KW  - passive dynamics
KW  - friction-induced stick-slip motions
KW  - spring-augmented pendulum
KW  - open problems
KW  - underactuated nature
KW  - locomotion
KW  - vibro-driven robotic systems
KW  - energy-efficient design
KW  - Robots
KW  - Trajectory
KW  - Force
KW  - Dynamics
KW  - Friction
KW  - Energy efficiency
KW  - Acceleration
DO  - 10.1109/IROS.2018.8594322
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficiency. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller for the driving pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.
ER  - 

TY  - CONF
TI  - Design of Compliant Mechanosensory Composite (CMC) and its Application Toward the Sensible Mesoscale Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1470
EP  - 1475
AU  - B. Kwak
AU  - J. Bae
PY  - 2018
KW  - angular measurement
KW  - coils
KW  - composite materials
KW  - conducting polymers
KW  - contact resistance
KW  - grippers
KW  - intelligent sensors
KW  - mobile robots
KW  - motion measurement
KW  - embedded sensing ability
KW  - conductive polymer PEDOT:PSS
KW  - CMC process
KW  - sensible mesoscale robotics
KW  - macroscale robots
KW  - compliant mechanosensory composite design
KW  - locomotory modulation
KW  - electric contact resistance
KW  - ECR
KW  - bending angle estimation
KW  - cyclic bending analysis
KW  - sparsely printed serpentine pattern
KW  - SMA coil
KW  - shape memory alloy coil
KW  - embedded sensors
KW  - size 0.1 mm to 10.0 mm
KW  - Robot sensing systems
KW  - Resistance
KW  - Fabrication
KW  - Contact resistance
KW  - Manufacturing processes
DO  - 10.1109/IROS.2018.8593590
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensed information greatly helps a robot to adjust its motion or modulate the locomotory behavior. While many sensing components have been developed for macroscale robots, such off-the-shelf sensors are hardly integrated with a mesoscale (i.e., 0.1 mm to 10 mm) robot due to the size limitation. In this work, we propose a Compliant Mechanosensory Composite (CMC) to fabricate a small compliant mechanism with embedded sensing ability. As the first demonstration of CMC, we directly print a conductive polymer PEDOT:PSS onto the flexible joint of a compliant mechanism to sense the motion of the flexible joint itself. Owing to the variation of electric contact resistance (ECR) upon bending, the CMC could estimate its bending angle. The performance of the CMC was verified by analyzing the cyclic bending, transient and stationary response. Overall, a sparsely printed serpentine pattern with thicker line exhibited consistent response without a noticeable hysteresis. To demonstrate the applicability of the CMC process, a small gripper actuated by a SMA (shape memory alloy) coil was fabricated, and its motion was successfully measured using the embedded sensors. We expect the proposed CMC will enable a small robot to become sensible at its self motion, external load, and physical contacts in future.
ER  - 


TY  - CONF
TI  - Conductive Knit-covered Pneumatic Artificial Muscle (k-PAM) Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1476
EP  - 1481
AU  - B. Jamil
AU  - S. Lee
AU  - Y. Choi
PY  - 2018
KW  - durability
KW  - fabrics
KW  - pneumatic actuators
KW  - silver
KW  - yarn
KW  - stitch methods
KW  - semipermanent conductive knit
KW  - high repetitive operation environment
KW  - nonconductive yarn
KW  - external force
KW  - actuator body
KW  - k-PAM
KW  - conductive knit-covered pneumatic artificial muscle
KW  - Actuators
KW  - Yarn
KW  - Bladder
KW  - Fabrication
KW  - Force
KW  - Sensors
KW  - Resistance
DO  - 10.1109/IROS.2018.8594510
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper presents design, fabrication and characteristics of two kinds of conductive Knit-covered Pneumatic Artificial Muscle (it is called as k-PAM in the paper) actuators, in which two different knits are made by braiding silver-coated (conductive) yarn and spandex (non-conductive) yarn with different stitch methods. The k-PAM is able to measure the change in length of the actuator body according to the applied air pressures as well as the strain due to external force. A complete fabrication method is presented to make the actuator work for higher pressure (≥ 300[kPa]). Since the force generated by the actuator is decoupled from the external force, ultimately, it can be directly used to measure not only the length but also the force. Experimental validations are performed describing the characteristics of two different types of k-PAMs. It is expected that the k-PAM can be used directly for robotic applications in higher pressure condition, while the semi-permanent conductive knit provides the actuator with durability in high repetitive operation environment.
ER  - 

TY  - CONF
TI  - Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1482
EP  - 1487
AU  - O. Álvarez-Tuñón
AU  - Á. Rodríguez
AU  - A. Jardón
AU  - C. Balaguer
PY  - 2018
KW  - coal
KW  - floods
KW  - inspection
KW  - maintenance engineering
KW  - mining
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - sensors
KW  - shafts
KW  - underwater vehicles
KW  - flooded shafts
KW  - EU project STAMS
KW  - autonomous underwater robotic system
KW  - periodic monitoring
KW  - underwater robot navigation
KW  - flooded mine shafts inspection
KW  - flooded mine shafts maintenance
KW  - sensor information
KW  - Robot sensing systems
KW  - Shafts
KW  - Three-dimensional displays
KW  - Sonar
KW  - Navigation
KW  - Visual odometry
DO  - 10.1109/IROS.2018.8594445
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.
ER  - 

TY  - CONF
TI  - Mechanical subsystems integration and structural analysis for the autonomous underwater explorer
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1488
EP  - 1493
AU  - J. Villa
AU  - A. Heininen
AU  - S. Zavari
AU  - T. Salomaa
AU  - O. Usenius
AU  - J. Laitinen
AU  - J. Aaltonen
AU  - K. T. Koskinen
PY  - 2018
KW  - autonomous underwater vehicles
KW  - finite element analysis
KW  - mechanical strength
KW  - mobile robots
KW  - robot dynamics
KW  - strain gauges
KW  - position requirements
KW  - finite element method
KW  - perception unit
KW  - FEM
KW  - strain gauge locations
KW  - modular mechanical design
KW  - autonomous underwater explorer
KW  - structural analysis
KW  - mechanical subsystems integration
KW  - hull endures pressures
KW  - deep dives
KW  - hull strength
KW  - structural strength analysis
KW  - orientation requirements
KW  - navigation systems
KW  - propulsion unit
KW  - ballast system
KW  - UX-1
KW  - Shape
KW  - Robots
KW  - Electronic ballasts
KW  - Manifolds
KW  - Propulsion
KW  - Finite element analysis
KW  - Cameras
DO  - 10.1109/IROS.2018.8593393
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The aim of this study is to analyse the modular mechanical design and integration of all three low-level modules in UX-1 (pendulum, ballast system and propulsion unit). The components of the perception and navigation systems have position and orientation requirements that dictate the shape of the hull. A structural strength analysis using Finite Element method (FEM) was made to study the hull strength during deep dives. The results are presented here, which indicates that the hull endures pressures related to deep dives. Also for validation, strain gauge locations were defined.
ER  - 

TY  - CONF
TI  - UX 1 system design - A robotic system for underwater mining exploration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1494
EP  - 1500
AU  - A. Martins
AU  - J. Almeida
AU  - C. Almeida
AU  - A. Dias
AU  - N. Dias
AU  - J. Aaltonen
AU  - A. Heininen
AU  - K. T. Koskinen
AU  - C. Rossi
AU  - S. Dominguez
AU  - C. Vörös
AU  - S. Henley
AU  - M. McLoughlin
AU  - H. van Moerkerk
AU  - J. Tweedie
AU  - B. Bodo
AU  - N. Zajzon
AU  - E. Silva
PY  - 2018
KW  - cameras
KW  - control system synthesis
KW  - innovation management
KW  - mining
KW  - mobile robots
KW  - robot vision
KW  - sonar
KW  - underwater vehicles
KW  - UX 1 system design
KW  - underwater mining exploration
KW  - UX-1 underwater mine exploration robotic system
KW  - UNEXMIN project
KW  - international innovation action
KW  - EU H2020 program
KW  - flooded underground mines
KW  - UX-1 robot prototype
KW  - recovery system
KW  - post-processing computational infrastructure
KW  - spherical robot
KW  - rotating laser line structured light systems
KW  - comprehensive mine model
KW  - robot design
KW  - UV-light
KW  - natural gamma-ray detector
KW  - multi-spectral camera
KW  - electro-conductivity
KW  - magnetic field sensors
KW  - high resolution imagery
KW  - Robot sensing systems
KW  - Sonar
KW  - Cameras
KW  - Payloads
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593999
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.
ER  - 

TY  - CONF
TI  - Automation in sensing and raw material characterization - a conceptual framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1501
EP  - 1506
AU  - F. S. Desta
AU  - M. W. N. Buxton
PY  - 2018
KW  - hyperspectral imaging
KW  - image fusion
KW  - image sensors
KW  - infrared spectra
KW  - infrared spectroscopy
KW  - statistical analysis
KW  - raw material characterization
KW  - material identification process
KW  - technological maturity
KW  - data fusion
KW  - sensor combinations approach
KW  - sensors signals
KW  - sensor technologies
KW  - real-time mining project concept
KW  - red green blue imaging
KW  - short wave infrared hyperspectral imaging
KW  - sensing automation
KW  - sensor signal
KW  - sensor data combinations
KW  - RTM
KW  - RGB imaging
KW  - visible near infrared hyperspectral imaging
KW  - VNIR
KW  - SWIR
KW  - Fourier-transform infrared spectroscopy
KW  - FTIR
KW  - laser induced breakdown spectroscopy
KW  - LIBS
KW  - multi-variate statistical interpretation
KW  - Minerals
KW  - Data integration
KW  - Automation
KW  - Robot sensing systems
KW  - Hyperspectral imaging
KW  - Raw materials
KW  - sensors data
KW  - data fusion
KW  - automation
KW  - material characterization
KW  - polymetallic sulphides
DO  - 10.1109/IROS.2018.8593774
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of sensor technologies for material characterization is rapidly growing and innovative advancement is observed. However, the use of sensor combinations for a raw material characterization in mining is very limited and automation of the material identification process using a combined sensor signal is not defined. Potential sensor technologies for raw material characterization were evaluated based on the applicability and technological maturity. To ensure a rapid implementation of the Real-time mining (RTM) project concept, mature technologies such as Red Green Blue (RGB) imaging, Visible Near Infrared (VNIR) hyperspectral imaging, Short Wave Infrared (SWIR) hyperspectral imaging, Fourier-Transform Infrared Spectroscopy (FTIR), Laser Induced Breakdown Spectroscopy (LIBS) and Raman were selected. Each selected technology was assessed for automation in sensing and applicability (for characterization of the test case materials). Based on the results the sensor data were further considered for data fusion. The proposed sensor combinations approach encompasses three levels of data fusion: low-level, mid-level and high-level. The data of the different sensors are fused together in order to acquire a wide range of mineral properties within each lithotype and an improved classification and predictive models. The preferred level of data fusion and preferred sensor data combinations will be used to develop a multi-variate statistical interpretation rule which relates combination of sensors signals with raw material properties. Thus a tool which integrates the combined sensor signal with materials properties will be developed and used to automate the material characterization process.
ER  - 

TY  - CONF
TI  - The benefits and challenges of robotics in the mineral raw materials sector - an overview
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1507
EP  - 1512
AU  - L. Lopes
AU  - T. Miklovicz
AU  - E. Bakker
AU  - Z. Milosevic
PY  - 2018
KW  - industrial robots
KW  - mineral processing industry
KW  - mining industry
KW  - raw materials
KW  - mineral raw materials sector
KW  - material transport
KW  - robotic digging
KW  - robotic loading
KW  - mining industry
KW  - Service robots
KW  - Minerals
KW  - Productivity
KW  - Fuel processing industries
KW  - Robot sensing systems
KW  - Raw materials
DO  - 10.1109/IROS.2018.8594218
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotics applications in the raw materials sector are becoming increasingly common due to their many perceived benefits. In mining, the extended use of robotics is especially seen in the exploration and exploitation phases, where mineral resources are discovered, extracted and processed. The use of robotics in the mining industry started in the 60s and today it is seen in the automation of material transport or in robotic digging and loading. Potential benefits include improved productivity, decreased production costs, better operational efficiency, increased safety, reduced waste and, ultimately, more value creation. The increasing amount of robotics used in the raw materials sector is coupled with a series of ethical and legal issues, regulatory challenges and policy requirements that affect both producers and end-users of robotic technologies. The benefits and challenges of robotics applications, often overlooked by the stakeholders, can hinder both their integration in the sector and the further development of mining activities, if not properly addressed.
ER  - 

TY  - CONF
TI  - Design, Modeling and Control of a Spherical Autonomous Underwater Vehicle for Mine Exploration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1513
EP  - 1519
AU  - R. A. S. Fernandez
AU  - E. A. Parra R.
AU  - Z. Milosevic
AU  - S. Dominguez
AU  - C. Rossi
PY  - 2018
KW  - autonomous underwater vehicles
KW  - control system synthesis
KW  - intelligent control
KW  - motion control
KW  - oceanographic equipment
KW  - position control
KW  - three-term control
KW  - flooded mine tunnel networks
KW  - unique mechanical hardware design
KW  - electrical hardware design
KW  - high-fidelity dynamic model
KW  - underwater experiments
KW  - controlled environment
KW  - standard motion patterns
KW  - Proportional-Integral-Derivative controller
KW  - PID controller
KW  - advanced control schemes
KW  - spherical AUV
KW  - tested underwater motions
KW  - spherical autonomous underwater vehicle
KW  - vehicle prototype
KW  - novel spherical autonomous
KW  - Prototypes
KW  - DC motors
KW  - Manifolds
KW  - Mathematical model
KW  - Robots
KW  - Propulsion
KW  - Shape
DO  - 10.1109/IROS.2018.8594016
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design, implementation and validation of a novel spherical Autonomous Underwater Vehicle (AUV) prototype, developed for inspection and exploration of flooded mine tunnel networks. The unique mechanical, electrical and hardware design is presented, as well as the development of a theoretical 6 degree-of-freedom (DOF) high-fidelity dynamic model of the system. A series of underwater experiments were carried out in a controlled environment to test the standard motion patterns of the AUV with a Proportional-Integral-Derivative (PID) controller. The performance of the PID controller will be used as the baseline for comparison of more advanced control schemes. The experimental results demonstrated that the spherical AUV was able to realize the tested underwater motions with notable performance.
ER  - 

TY  - CONF
TI  - ίVAMOS! Underwater Mining Machine Navigation System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1520
EP  - 1526
AU  - J. Almeida
AU  - A. Ferreira
AU  - B. Matias
AU  - C. Lomba
AU  - A. Martins
AU  - E. Silva
PY  - 2018
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - mining
KW  - mining equipment
KW  - mobile robots
KW  - nonlinear filters
KW  - satellite navigation
KW  - sensor fusion
KW  - underwater acoustic communication
KW  - underwater mining machine navigation system
KW  - data fusion approach
KW  - sensor information
KW  - extended kalman filter
KW  - EKF
KW  - ¡VAMOS
KW  - multiple antenna GNSS system
KW  - inverted ultra-short baseline
KW  - surface vessel
KW  - underwater mining vehicle
KW  - multiple vehicle underwater localization solution
KW  - Position measurement
KW  - Global navigation satellite system
KW  - Receivers
KW  - Transponders
KW  - Accelerometers
KW  - Data mining
KW  - Gravity
DO  - 10.1109/IROS.2018.8593773
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.
ER  - 

TY  - CONF
TI  - Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1527
EP  - 1533
AU  - J. Almeida
AU  - A. Martins
AU  - C. Almeida
AU  - A. Dias
AU  - B. Matias
AU  - A. Ferreira
AU  - P. Jorge
AU  - R. Martins
AU  - M. Bleier
AU  - A. Nuchter
AU  - J. Pidgeon
AU  - S. Kapusniak
AU  - E. Silva
PY  - 2018
KW  - control engineering computing
KW  - mining
KW  - mobile robots
KW  - position control
KW  - virtual reality
KW  - global architecture
KW  - real-time grade system
KW  - 3D virtual reality HMI
KW  - realtime mine modeling
KW  - ¡VAMOS!
KW  - underwater robotic mining system
KW  - navigation
KW  - mining field trial
KW  - PNA system
KW  - PNA sensors
KW  - Three-dimensional displays
KW  - Sensor systems
KW  - Solid modeling
KW  - Presence network agents
KW  - Virtual reality
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593869
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.
ER  - 

TY  - CONF
TI  - Multi-Agent Imitation Learning for Driving Simulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1534
EP  - 1539
AU  - R. P. Bhattacharyya
AU  - D. J. Phillips
AU  - B. Wulfe
AU  - J. Morton
AU  - A. Kuefler
AU  - M. J. Kochenderfer
PY  - 2018
KW  - intelligent transportation systems
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - multiagent Imitation Learning
KW  - human drivers
KW  - multiagent setting
KW  - PS-GAIL method
KW  - single-agent GAIL policies
KW  - curriculum learning
KW  - multiple agents
KW  - test time
KW  - multiagent driving scenarios
KW  - single-agent environments
KW  - representative human driver models
KW  - Generative Adversarial Imitation Learning
KW  - autonomous vehicles
KW  - appealing option
KW  - Vehicles
KW  - Training
KW  - Trajectory
KW  - Optimization
KW  - Biological system modeling
KW  - Testing
KW  - Markov processes
DO  - 10.1109/IROS.2018.8593758
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.
ER  - 

TY  - CONF
TI  - Model-Based Action Exploration for Learning Dynamic Motion Skills
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1540
EP  - 1546
AU  - G. Berseth
AU  - A. Kyriazis
AU  - I. Zinin
AU  - W. Choi
AU  - M. van de Panne
PY  - 2018
KW  - Gaussian distribution
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - model-based action exploration
KW  - dynamic motion skills
KW  - deep reinforcement learning
KW  - Gaussian distribution
KW  - forward dynamics model
KW  - motion control tasks
KW  - internal lookahead prediction
KW  - robotic locomotion
KW  - juggling
KW  - Computational modeling
KW  - Stochastic processes
KW  - Robots
KW  - Predictive models
KW  - Task analysis
KW  - Training
KW  - Generative adversarial networks
DO  - 10.1109/IROS.2018.8593588
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep reinforcement learning has achieved great strides in solving challenging motion control tasks. Recently, there has been significant work on methods for exploiting the data gathered during training, but there has been less work on how to best generate the data to learn from. For continuous action domains, the most common method for generating exploratory actions involves sampling from a Gaussian distribution centred around the mean action output by a policy. Although these methods can be quite capable, they do not scale well with the dimensionality of the action space, and can be dangerous to apply on hardware. We consider learning a forward dynamics model to predict the result, (xt+1), of taking a particular action, (u), given a specific observation of the state, (xt). With this model we perform internal lookahead predictions of outcomes and seek actions we believe have a reasonable chance of success. This method alters the exploratory action space, thereby increasing learning speed and enables higher quality solutions to difficult problems, such as robotic locomotion and juggling.
ER  - 

TY  - CONF
TI  - Active Learning based on Data Uncertainty and Model Sensitivity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1547
EP  - 1554
AU  - N. Chen
AU  - A. Klushyn
AU  - A. Paraschos
AU  - D. Benbouzid
AU  - P. Van der Smagt
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - pendulums
KW  - elementary skills
KW  - smooth movements
KW  - newly acquired knowledge
KW  - additional demonstration
KW  - nonsmooth transitions
KW  - latent space
KW  - metric learning
KW  - deep generative models
KW  - smooth trajectories
KW  - abrupt movements
KW  - missing information
KW  - necessary knowledge
KW  - fundamentally different skills
KW  - model sensitivity
KW  - data uncertainty
KW  - active learning
KW  - Uncertainty
KW  - Jacobian matrices
KW  - Manifolds
KW  - Data models
KW  - Measurement
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593552
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots can rapidly acquire new skills from demonstrations. However, during generalisation of skills or transitioning across fundamentally different skills, it is unclear whether the robot has the necessary knowledge to perform the task. Failing to detect missing information often leads to abrupt movements or to collisions with the environment. Active learning can quantify the uncertainty of performing the task and, in general, locate regions of missing information. We introduce a novel algorithm for active learning and demonstrate its utility for generating smooth trajectories. Our approach is based on deep generative models and metric learning in latent spaces. It relies on the Jacobian of the likelihood to detect non-smooth transitions in the latent space, i.e., transitions that lead to abrupt changes in the movement of the robot. When non-smooth transitions are detected, our algorithm asks for an additional demonstration from that specific region. The newly acquired knowledge modifies the data manifold and allows for learning a latent representation for generating smooth movements. We demonstrate the efficacy of our approach on generalising elementary skills, transitioning across different skills, and implicitly avoiding collisions with the environment. For our experiments, we use a simulated pendulum where we observe its motion from images and a 7-DoF anthropomorphic arm.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning for Audio-Visual Gaze Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1555
EP  - 1562
AU  - S. Lathuilière
AU  - B. Massé
AU  - P. Mesejo
AU  - R. Horaud
PY  - 2018
KW  - gaze tracking
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - deep reinforcement
KW  - audio-visual gaze control
KW  - human-robot interaction
KW  - controlled robot motions
KW  - visual observations
KW  - acoustic observations
KW  - robot head
KW  - robotic head
KW  - reinforcement learning formulation
KW  - gaze control problem
KW  - audio data
KW  - visual data
KW  - audio-visual fusion framework
KW  - RL
KW  - microphone observations
KW  - deep architectures
KW  - Visualization
KW  - Cameras
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8594327
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.
ER  - 

TY  - CONF
TI  - An Ensemble with Shared Representations Based on Convolutional Networks for Continually Learning Facial Expressions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1563
EP  - 1568
AU  - H. Siqueira
AU  - P. Barros
AU  - S. Magg
AU  - S. Wermter
PY  - 2018
KW  - convolutional neural nets
KW  - emotion recognition
KW  - face recognition
KW  - feature extraction
KW  - human-robot interaction
KW  - robot vision
KW  - supervised learning
KW  - ensemble-based systems
KW  - human-robot interactions
KW  - unlabelled facial expressions
KW  - emotion recognition capability
KW  - social robots
KW  - continually learning facial expressions
KW  - shared representations
KW  - ensemble predictions
KW  - convolutional branches
KW  - low-level feature extractors
KW  - convolutional networks
KW  - Training
KW  - Feature extraction
KW  - Robots
KW  - Computer architecture
KW  - Face recognition
KW  - Convolution
KW  - Redundancy
DO  - 10.1109/IROS.2018.8594276
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Social robots able to continually learn facial expressions could progressively improve their emotion recognition capability towards people interacting with them. Semi-supervised learning through ensemble predictions is an efficient strategy to leverage the high exposure of unlabelled facial expressions during human-robot interactions. Traditional ensemble-based systems, however, are composed of several independent classifiers leading to a high degree of redundancy, and unnecessary allocation of computational resources. In this paper, we proposed an ensemble based on convolutional networks where the early layers are strong low-level feature extractors, and their representations shared with an ensemble of convolutional branches. This results in a significant drop in redundancy of low-level features processing. Training in a semi-supervised setting, we show that our approach is able to continually learn facial expressions through ensemble predictions using unlabelled samples from different data distributions.
ER  - 

TY  - CONF
TI  - Deep Q-Learning for Dry Stacking Irregular Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1569
EP  - 1576
AU  - Y. Liu
AU  - S. M. Shamsi
AU  - L. Fang
AU  - C. Chen
AU  - N. Napp
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - neurocontrollers
KW  - state-action pairs
KW  - Q-network
KW  - robot arm
KW  - generated stacking plans
KW  - physical constraints
KW  - geometric constraints
KW  - action space
KW  - deep neural network
KW  - learned Q-function
KW  - reinforcement learning algorithm
KW  - local geometric considerations
KW  - reinforcement learning approach
KW  - dry stacking irregular objects
KW  - deep Q-learning
KW  - Stacking
KW  - Buildings
KW  - Robots
KW  - Planning
KW  - Shape
KW  - Stability analysis
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593619
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a reinforcement learning approach for automatically building dry stacked (i.e. no mortar) structures with irregular objects. Stacking irregular objects is a challenging problem since each assembly action can be drawn from a continuous space of poses for an object, and several local geometric and physical considerations strongly affect the stability. To tackle this challenge, we concentrate on a simplified 2D version of the problem. We present a reinforcement learning algorithm based on deep Q-learning, where the learned Q-function, which maps state-action pairs into expected long-term rewards, is represented by a deep neural network. As the action space is continuous the Q-network is trained by sampling a finite number of actions that consider both geometric and physical constraints to approximate the target Q-values, Experiments show that the proposed method outperforms previous heuristics-based planning, leading to super construction with objects containing a significant amount of variations. We validate the generated stacking plans by executing them using a robot arm and manufactured, irregular objects.
ER  - 

TY  - CONF
TI  - Learning Actionable Representations from Visual Observations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1577
EP  - 1584
AU  - D. Dwibedi
AU  - J. Tompson
AU  - C. Lynch
AU  - P. Sermanet
PY  - 2018
KW  - learning (artificial intelligence)
KW  - video coding
KW  - learning task-agnostic representations
KW  - continuous control tasks
KW  - multiple frames
KW  - single frame
KW  - self-supervised approach
KW  - reinforcement learning setting
KW  - random actions
KW  - continuous control policies
KW  - Proximal Policy Optimization
KW  - learned embeddings
KW  - real-world Pouring dataset
KW  - single-frame baseline
KW  - learning actionable representations
KW  - time-contrastive networks
KW  - Task analysis
KW  - Robots
KW  - Visualization
KW  - Reinforcement learning
KW  - Aerospace electronics
KW  - Solid modeling
KW  - Semantics
DO  - 10.1109/IROS.2018.8593951
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.
ER  - 

TY  - CONF
TI  - Efficient Distributed Torque Computation for Large Scale Robot Skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1593
EP  - 1599
AU  - F. Bergner
AU  - E. Dean-Leon
AU  - G. Cheng
PY  - 2018
KW  - computational complexity
KW  - control engineering computing
KW  - mobile robots
KW  - real-time systems
KW  - sensor fusion
KW  - skin
KW  - tactile sensors
KW  - torque control
KW  - skin information
KW  - reactive skin torque controller
KW  - kinesthetic robot behavior
KW  - scale robot skin
KW  - efficient distributed torque computation
KW  - real-time control loop
KW  - skin joint torques
KW  - computational delay
KW  - control PC
KW  - distributed skin joint torque computation
KW  - local microcontrollers
KW  - skin joint torque computations
KW  - real-time loop
KW  - complex computations
KW  - distributed skin cells
KW  - scale skin
KW  - appropriate skin joint torque
KW  - Skin
KW  - Torque
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594144
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The realization of a kinesthetic robot behavior using robot skin requires a reactive skin torque controller, which fuses skin information and robot information to an appropriate skin joint torque in real-time. This fusion of information in real-time is challenging when deploying large scale skin. In this paper, we present a system which efficiently computes the torque of distributed skin cells locally at the point of contacts, completely removing this complex computations from the real-time loop. We demonstrate the feasibility of realizing the skin joint torque computations on the local micro-controllers of the skin cells. Conducting experiments with a real robot, we compare the accuracy of the distributed skin joint torque computation with the computation on the control PC. We also show that the novel distributed approach completely eliminates the computational delay of computing skin joint torques in the robot's real-time control loop. As a result, this approach removes any limits for the maximum number of skin cells in control.
ER  - 

TY  - CONF
TI  - A Robust and Efficient Dynamic Network Protocol for a large-scale artificial robotic skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1600
EP  - 1605
AU  - C. Bader
AU  - F. Bergner
AU  - G. Cheng
PY  - 2018
KW  - protocols
KW  - robots
KW  - skin
KW  - telecommunication network reliability
KW  - protocol converges
KW  - skin network
KW  - artificial robot skin
KW  - dynamic network protocol
KW  - static network protocol approach
KW  - skin cells
KW  - artificial robotic skins
KW  - large-scale artificial robotic skin
KW  - Skin
KW  - Routing protocols
KW  - Robot sensing systems
KW  - Routing
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8594499
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Artificial robotic skins are continuously in contact with their environment, and therefore highly rely on proper connections in their skin cells' network. With a static network protocol approach, the affected skin area is unusable after a connection failure. Therefore, we developed a dynamic network protocol for large-scale artificial robotic skins, which re-routes the network upon connection failures to keep the whole skin in operation. Furthermore, the protocol balances the load for driving larger skins without packet loss. For verification, we validated the protocol on a large artificial robot skin we have developed and analyzed its performance with a skin network consisting of up to 204 cells. The failure recovery of the protocol converges in at most 50ms. We showed that the balancing method achieves a packet loss reduction of over 30% compared to the previously used protocol.
ER  - 

TY  - CONF
TI  - 3D Shape Perception from Monocular Vision, Touch, and Shape Priors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1606
EP  - 1613
AU  - S. Wang
AU  - J. Wu
AU  - X. Sun
AU  - W. Yuan
AU  - W. T. Freeman
AU  - J. B. Tenenbaum
AU  - E. H. Adelson
PY  - 2018
KW  - cameras
KW  - computational geometry
KW  - feature extraction
KW  - image colour analysis
KW  - image reconstruction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - shape recognition
KW  - solid modelling
KW  - tactile sensors
KW  - visual perception
KW  - 3D object shape
KW  - precise local shape information
KW  - monocular camera
KW  - visual observations
KW  - physical world
KW  - perceiving accurate 3D object shape
KW  - touch
KW  - monocular vision
KW  - real-world objects
KW  - visual prediction
KW  - object regions
KW  - learned shape priors
KW  - large-scale shape repositories
KW  - common object shapes
KW  - tactile observations
KW  - Shape
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Surface reconstruction
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593430
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Perceiving accurate 3D object shape is important for robots to interact with the physical world. Current research along this direction has been primarily relying on visual observations. Vision, however useful, has inherent limitations due to occlusions and the 2D-3D ambiguities, especially for perception with a monocular camera. In contrast, touch gets precise local shape information, though its efficiency for reconstructing the entire shape could be low. In this paper, we propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories. We use vision first, applying neural networks with learned shape priors to predict an object's 3D shape from a single-view color image. We then use tactile sensing to refine the shape; the robot actively touches the object regions where the visual prediction has high uncertainty. Our method efficiently builds the 3D shape of common objects from a color image and a small number of tactile explorations (around 10). Our setup is easy to apply and has potentials to help robots better perform grasping or manipulation tasks on real-world objects.
ER  - 

TY  - CONF
TI  - Exploration and Reconstruction of Unknown Objects using a Novel Normal and Contact Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1614
EP  - 1620
AU  - S. Ottenhaus
AU  - P. Weiner
AU  - L. Kaul
AU  - A. Tulbure
AU  - T. Asfour
PY  - 2018
KW  - humanoid robots
KW  - manipulators
KW  - object recognition
KW  - pressure sensors
KW  - tactile sensors
KW  - tactile sensors
KW  - contact measurement
KW  - surface orientation
KW  - surface reconstruction
KW  - unknown objects
KW  - pressure sensor
KW  - contact force
KW  - developed sensor prototype
KW  - contact detection capability
KW  - normal estimation accuracy
KW  - contact sensor
KW  - surface normals
KW  - inertial measurement unit
KW  - IMU
KW  - mean reconstruction accuracy
KW  - Surface reconstruction
KW  - Surface treatment
KW  - Tactile sensors
KW  - Force
DO  - 10.1109/IROS.2018.8594272
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tactile sensing of surface normals is essential for exploration of unknown objects. Many tactile sensors have been developed for contact measurement. However, few of these sensors provide surface orientation, and only up to a limited degree. This paper presents a novel contact and surface orientation sensor concept and its application for surface reconstruction of unknown objects. The sensor is comprised of an Inertial Measurement Unit (IMU) and a pressure sensor to accurately estimate the surface orientation in a wide range, while at the same time measuring contact force. We describe the developed sensor prototype and evaluate its performance regarding contact detection capability and normal estimation accuracy. We use this to reconstruct the surface of unknown objects using the humanoid robot ARMAR-III resulting in a mean reconstruction accuracy of 3.6 mm.
ER  - 

TY  - CONF
TI  - Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1621
EP  - 1627
AU  - C. B. Teeple
AU  - K. P. Becker
AU  - R. J. Wood
PY  - 2018
KW  - actuators
KW  - force sensors
KW  - grippers
KW  - optical sensors
KW  - optical waveguides
KW  - remotely operated vehicles
KW  - soft robotic hand
KW  - optical sensing elements
KW  - proprioception
KW  - curvature sensing elements
KW  - contact force sensors
KW  - normal force
KW  - sensor design decisions
KW  - simulated deep-sea environments
KW  - curvature sensors
KW  - soft finger actuators
KW  - soft curvature
KW  - deep-sea grasping
KW  - intentionally-lossy optical waveguides
KW  - soft robotic grasping applications
KW  - subNewton force sensitivity
KW  - temperature -10.0 degC to 50.0 degC
KW  - Optical waveguides
KW  - Optical sensors
KW  - Optical device fabrication
KW  - Optical losses
KW  - Optical refraction
KW  - Optical variables control
DO  - 10.1109/IROS.2018.8594270
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.
ER  - 

TY  - CONF
TI  - Realtime State Estimation with Tactile and Visual Sensing for Inserting a Suction-held Object
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1628
EP  - 1635
AU  - K. Yu
AU  - A. Rodriguez
PY  - 2018
KW  - mobile robots
KW  - robot kinematics
KW  - robot vision
KW  - state estimation
KW  - tactile sensors
KW  - visual sensing
KW  - suction-held object
KW  - real-time state estimation system
KW  - robotic packaging
KW  - tactile sensing
KW  - on-line estimation technique
KW  - contact geometry
KW  - complex contact interactions
KW  - iSAM
KW  - robot kinematic measurement
KW  - planar settings
KW  - data-driven method
KW  - Robot sensing systems
KW  - Visualization
KW  - State estimation
KW  - Task analysis
KW  - Containers
DO  - 10.1109/IROS.2018.8594077
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We develop a real-time state estimation system to recover the pose and contact formation of an object relative to its environment. In this paper, we focus on the application of inserting an object picked by a suction cup into a tight space, a key technology for robotic packaging. We propose a framework that fuses tactile and visual sensing. Visual sensing is versatile and non-intrusive, but suffers from occlusions and limited accuracy, especially for tasks involving contact. Tactile sensing is local, but provides accuracy and robustness to occlusions. The proposed algorithm to fuse them is based on iSAM, an on-line estimation technique, which we use to incorporate kinematic measurements from the robot, contact geometry of the object and the container, and visual tracking. In this paper, we generalize previous results in planar settings [1] to a 3D task with more complex contact interactions. A key challenge is that we do not observe contact locations between the suction-held object and the container directly. We propose a data-driven method to infer the contact formation, which is then used in real-time by the state estimator. We demonstrate and evaluate the algorithm in a setup instrumented to provide groundtruth.
ER  - 

TY  - CONF
TI  - Mechanical and Perceptual Characterizations of the Localized Shearing using a Novel Haptic Display
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1636
EP  - 1642
AU  - H. Van Anh
AU  - S. Hirai
PY  - 2018
KW  - display devices
KW  - haptic interfaces
KW  - haptic pins
KW  - lateral localized displacement
KW  - localized shearing
KW  - perceptual characterizations
KW  - haptic display devices
KW  - human slip perception
KW  - mechanical response
KW  - human fingertip
KW  - Pins
KW  - Haptic interfaces
KW  - Force
KW  - Skin
KW  - Mathematical model
KW  - Numerical models
KW  - Strain
DO  - 10.1109/IROS.2018.8593958
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Previously, we presented the concept of a novel haptic display device that could generate lateral localized displacement on a human fingertip. This device is characterized by a bundle of haptic pins whose ends gently make contact with a human fingertip. In this paper, we proposed a dynamic model of interaction between haptic pins and finger for investigation of mechanical response of stress or strain on human fingertip under operation of the proposed haptic device. We also conducted preliminary experiment to determine the possible setups that maximizes the sense of partial slippage. The results presented in this paper may help assess human slip perception for the development of haptic display devices.
ER  - 

TY  - CONF
TI  - Finding safe 3D robot grasps through efficient haptic exploration with unscented Bayesian optimization and collision penalty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1643
EP  - 1648
AU  - J. Castanheira
AU  - P. Vicente
AU  - R. Martinez-Cantin
AU  - L. Jamone
AU  - A. Bernardino
PY  - 2018
KW  - approximation theory
KW  - Bayes methods
KW  - collision avoidance
KW  - grippers
KW  - haptic interfaces
KW  - Kalman filters
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - unscented Bayesian optimization
KW  - novel collision penalty
KW  - exploration steps
KW  - safe 3D robot grasps
KW  - efficient haptic exploration
KW  - robust grasping
KW  - accurate models
KW  - known objects
KW  - approximate models
KW  - familiar objects
KW  - partial point clouds
KW  - unknown objects
KW  - sensing inaccuracies
KW  - local exploration
KW  - grasp execution
KW  - 3D haptic exploration strategy
KW  - Grasping
KW  - Three-dimensional displays
KW  - Optimization
KW  - Robot sensing systems
KW  - Bayes methods
DO  - 10.1109/IROS.2018.8594009
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust grasping is a major, and still unsolved, problem in robotics. Information about the 3D shape of an object can be obtained either from prior knowledge (e.g., accurate models of known objects or approximate models of familiar objects) or real-time sensing (e.g., partial point clouds of unknown objects) and can be used to identify good potential grasps. However, due to modeling and sensing inaccuracies, local exploration is often needed to refine such grasps and successfully apply them in the real world. The recently proposed unscented Bayesian optimization technique can make such exploration safer by selecting grasps that are robust to uncertainty in the input space (e.g., inaccuracies in the grasp execution). Extending our previous work on 2D optimization, in this paper we propose a 3D haptic exploration strategy that combines unscented Bayesian optimization with a novel collision penalty heuristic to find safe grasps in a very efficient way: while by augmenting the search-space to 3D we are able to find better grasps, the collision penalty heuristic allows us to do so without increasing the number of exploration steps.
ER  - 

TY  - CONF
TI  - Indoor Mapping and Localization for Pedestrians using Opportunistic Sensing with Smartphones
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1649
EP  - 1656
AU  - Q. Liang
AU  - L. Wang
AU  - Y. Li
AU  - M. Liu
PY  - 2018
KW  - Bayes methods
KW  - Gaussian processes
KW  - indoor radio
KW  - mobile computing
KW  - mobile robots
KW  - optimisation
KW  - particle filtering (numerical methods)
KW  - path planning
KW  - radionavigation
KW  - regression analysis
KW  - SLAM (robots)
KW  - smart phones
KW  - wireless LAN
KW  - Gaussian Processes Regression
KW  - real-time localization
KW  - GPR variance map
KW  - pseudowall constraints
KW  - magnetic fields
KW  - globally consistent trajectories
KW  - opportunistic magnetic headings
KW  - WiFi signal similarity validation
KW  - magnetic sequence matching
KW  - loop-closure constraints
KW  - pedestrian dead-reckoning
KW  - motion constraints
KW  - GraphSLAM front-end
KW  - signal maps
KW  - Bayesian filtering-based online localization
KW  - GraphSLAM-based offline mapping
KW  - ambient indoor environments
KW  - low-cost indoor mapping
KW  - indoor localization
KW  - smartphone
KW  - size 2.3 m
KW  - size 3.41 m
KW  - Wireless fidelity
KW  - Trajectory
KW  - Smart phones
KW  - Simultaneous localization and mapping
KW  - Ground penetrating radar
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8594254
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor localization for pedestrians has gained increasing popularity among the rich body of literature for the last decade. In this paper, a low-cost indoor mapping and localization solution is proposed using the opportunistic signals from ambient indoor environments with a smartphone. It is composed of GraphSLAM-based offline mapping and Bayesian filtering-based online localization using generated signal maps. The GraphSLAM front-end is constructed by motion constraints from pedestrian dead-reckoning (PDR), loop-closure constraints identified by magnetic sequence matching with WiFi signal similarity validation, and observation constraints from opportunistic magnetic headings after error rejection. Globally consistent trajectories are created by graph optimization, after which signal maps (e.g., WiFi, magnetic fields, lights) are generated by Gaussian Processes Regression (GPR) for later localization. We propose to use the pseudo-wall constraints from the GPR variance map of magnetic fields and the lights measurements as observations for particle filtering. The proposed method is evaluated on several datasets collected from both the in-compass office buildings and outside public areas. Real-time localization is demonstrated on a smartphone in an office building covering 2000 square meters with the 50- and 90-percentile accuracies being 2.30 m and 3.41 m, respectively.
ER  - 

TY  - CONF
TI  - Navigation without localisation: reliable teach and repeat based on the convergence theorem
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1657
EP  - 1664
AU  - T. Krajník
AU  - F. Majer
AU  - L. Halodová
AU  - T. Vintr
PY  - 2018
KW  - calibration
KW  - cameras
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - velocity control
KW  - mobile robot
KW  - taught path
KW  - learned velocities
KW  - camera information
KW  - position error model
KW  - mathematical proof
KW  - camera calibration
KW  - navigation system
KW  - mathematical model
KW  - explicit localisation
KW  - teach-and-repeat navigation scenarios
KW  - teach-and-repeat visual navigation
KW  - Robot kinematics
KW  - Navigation
KW  - Cameras
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593803
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel concept for teach-and-repeat visual navigation. The proposed concept is based on a mathematical model, which indicates that in teach-and-repeat navigation scenarios, mobile robots do not need to perform explicit localisation. Rather than that, a mobile robot which repeats a previously taught path can simply “replay” the learned velocities, while using its camera information only to correct its heading relative to the intended path. To support our claim, we establish a position error model of a robot, which traverses a taught path by only correcting its heading. Then, we outline a mathematical proof which shows that this position error does not diverge over time. Based on the insights from the model, we present a simple monocular teach-and-repeat navigation method. The method is computationally efficient, it does not require camera calibration, and it can learn and autonomously traverse arbitrarily-shaped paths. In a series of experiments, we demonstrate that the method can reliably guide mobile robots in realistic indoor and outdoor conditions, and can cope with imperfect odometry, landmark deficiency, illumination variations and naturally-occurring environment changes. Furthermore, we provide the navigation system and the datasets gathered at www.github.com/gestom/stroll_bearnav.
ER  - 

TY  - CONF
TI  - Accurate Mix-Norm-Based Scan Matching
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1665
EP  - 1671
AU  - D. Wang
AU  - J. Xue
AU  - Z. Tao
AU  - Y. Zhong
AU  - D. Cui
AU  - S. Du
AU  - N. Zheng
PY  - 2018
KW  - expectation-maximisation algorithm
KW  - image matching
KW  - learning (artificial intelligence)
KW  - least squares approximations
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - exponential power distributions
KW  - convergence characteristic
KW  - mix-norm-based scan matching
KW  - robust objective function design
KW  - MoEP-based residual error model
KW  - EM-like algorithm
KW  - likelihood field model
KW  - iteratively reweighted least squares phase
KW  - LFM
KW  - IRLS
KW  - on-line parameter learning
KW  - MiNoM optimization
KW  - mobile robotics
KW  - Iterative closest point algorithm
KW  - Linear programming
KW  - Gaussian distribution
KW  - Standards
KW  - Convergence
KW  - Optimization
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8594278
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Highly accurate mapping and localization is of prime importance for mobile robotics, and its core lies in efficient scan matching. Previous research are focusing on designing a robust objective function and the residual error distribution is often ignored or simply assumed as unitary or mixture of simple distributions. In this paper, a mixture of exponential power (MoEP) distributions is proposed to approximate the residual error distribution. The objective function induced by MoEP-based residual error modelling ensembles a mix-norm-based scan matching (MiNoM), which enhances the matching accuracy and convergence characteristic. Both the parameters of transformation (rotation and translation) and residual error distribution are estimated efficiently via an EM-like algorithm. The optimization of MiNoM is iteratively achieved via two phases: An on-line parameter learning (OPL) phase to learn residual error distribution for better representation according to the likelihood field model (LFM), and an iteratively reweighted least squares (IRLS) phase to attain transformation for accuracy and efficiency. Extensive experimental results validate that the proposed MiNoM out-performs several state-of-the-art scan matching algorithms in both convergence characteristic and matching accuracy.
ER  - 

TY  - CONF
TI  - StreetMap - Mapping and Localization on Ground Planes using a Downward Facing Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1672
EP  - 1679
AU  - X. Chen
AU  - A. S. Vempati
AU  - P. Beardsley
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image filtering
KW  - image texture
KW  - mobile robots
KW  - robot vision
KW  - rectilinear textures
KW  - indoor tiling
KW  - ground plane texture
KW  - globally consistent map
KW  - complete working pipeline
KW  - absolute localization
KW  - indoor tiles
KW  - general texture
KW  - ground textures
KW  - mobile robot
KW  - downward facing camera
KW  - Cameras
KW  - Robot vision systems
KW  - Feature extraction
KW  - Robot kinematics
KW  - Slabs
DO  - 10.1109/IROS.2018.8594157
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a system to map a ground-plane, and to subsequently use the map for localization of a mobile robot. The robot has a downward-facing camera, and works on a variety of ground textures including general texture like tarmac, man-made designs like carpet, and rectilinear textures like indoor tiles or outdoor slabs. Such textures provide a basis for measuring relative motion (i.e. computer mouse functionality). But the goal here is the more challenging one of absolute localization. The paper describes a complete working pipeline to build a globally consistent map of a given ground-plane and subsequently to localize within this map at real-time. Two algorithms are described. The first is a feature-based approach which is general to any ground plane texture. The second algorithm takes advantage of the extra constraints available for common rectilinear textures like indoor tiling, paving slabs, and laid brickwork. Quantitative and qualitative experimental results are shown for mapping and localization on a variety of ground-planes.
ER  - 

TY  - CONF
TI  - The TUM VI Benchmark for Evaluating Visual-Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1680
EP  - 1687
AU  - D. Schubert
AU  - T. Goll
AU  - N. Demmel
AU  - V. Usenko
AU  - J. Stückler
AU  - D. Cremers
PY  - 2018
KW  - augmented reality
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - image capture
KW  - image sensors
KW  - image sequences
KW  - mobile robots
KW  - optical tracking
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - synchronisation
KW  - visual-inertial odometry
KW  - photometric calibration
KW  - motion capture system
KW  - IMU measurements
KW  - pose ground truth
KW  - inertial measurements
KW  - vision sensors
KW  - augmented reality
KW  - SLAM methods
KW  - visual odometry
KW  - IMU sensors
KW  - camera images
KW  - TUM VI benchmark
KW  - frequency 20.0 Hz
KW  - frequency 200.0 Hz
KW  - frequency 120.0 Hz
KW  - Cameras
KW  - Calibration
KW  - Simultaneous localization and mapping
KW  - Benchmark testing
KW  - Visual odometry
KW  - Time measurement
DO  - 10.1109/IROS.2018.8593419
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual odometry and SLAM methods have a large variety of applications in domains such as augmented reality or robotics. Complementing vision sensors with inertial measurements tremendously improves tracking accuracy and robustness, and thus has spawned large interest in the development of visual-inertial (VI) odometry approaches. In this paper, we propose the TUM VI benchmark, a novel dataset with a diverse set of sequences in different scenes for evaluating VI odometry. It provides camera images with 1024×1024 resolution at 20 Hz, high dynamic range and photometric calibration. An IMU measures accelerations and angular velocities on 3 axes at 200 Hz, while the cameras and IMU sensors are time-synchronized in hardware. For trajectory evaluation, we also provide accurate pose ground truth from a motion capture system at high frequency (120 Hz) at the start and end of the sequences which we accurately aligned with the camera and IMU measurements. The full dataset with raw and calibrated data is publicly available. We also evaluate state-of-the-art VI odometry approaches on our dataset.
ER  - 

TY  - CONF
TI  - Scale-Robust Localization Using General Object Landmarks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1688
EP  - 1694
AU  - A. Holliday
AU  - G. Dudek
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - deep-learning-based object features
KW  - KITTI Odometry benchmark
KW  - outdoor images
KW  - scale-robust localization
KW  - visual localization
KW  - robotic mapping applications
KW  - object landmarks
KW  - SIFT point-features
KW  - Visualization
KW  - Measurement
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Databases
KW  - Search problems
DO  - 10.1109/IROS.2018.8594011
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3× difference in scale between map and query images. We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change. This technique is training-free and class-agnostic, and in principle can be deployed in any environment out-of-the-box. We evaluate the proposed technique on the KITTI Odometry benchmark and on a novel dataset of outdoor images exhibiting changes in visual scale of 7× and greater, which we have released to the public. Our technique consistently outperforms localization using either SIFT features or the proposed object features alone, achieving both greater accuracy and much lower failure rates under large changes in scale.
ER  - 

TY  - CONF
TI  - Localization of an Acoustic Fish-Tag using the Time-of-Arrival Measurements: Preliminary results using eXogenous Kalman Filter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1695
EP  - 1702
AU  - R. P. Jain
AU  - A. P. Aguiar
AU  - J. B. de Sousa
AU  - A. Zolich
AU  - T. A. Johansen
AU  - J. A. Alfredsen
AU  - E. Erstorp
AU  - J. Kuttenkeuler
PY  - 2018
KW  - Kalman filters
KW  - remotely operated vehicles
KW  - time-varying systems
KW  - time-of-arrival measurement
KW  - eXogenous Kalman filter
KW  - three stage estimation strategy
KW  - time-of-transmission
KW  - acoustic fish-tag localization
KW  - uniformly globally asymptotically stable
KW  - UGAS
KW  - unmanned surface vessels
KW  - Kalman Filter based estimator
KW  - quasilinear time-varying measurement model
KW  - pseudorange measurement equation
KW  - acoustic receiver
KW  - acoustic signal
KW  - source localization problem
KW  - Acoustics
KW  - Mathematical model
KW  - Receivers
KW  - Acoustic measurements
KW  - Kalman filters
KW  - Estimation
KW  - Measurement uncertainty
DO  - 10.1109/IROS.2018.8593659
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the source localization problem of an acoustic fish-tag using the Time-of-Arrival measurement of an acoustic signal, transmitted by the fish-tag. The Time-of-Arrival measurements denote the pseudo-range information between the acoustic receiver and the fish-tag, except that the Time-of-Transmission of the acoustic signal is unknown. Starting with the pseudo-range measurement equation, a globally valid quasi-linear time-varying measurement model is presented that is independent of the Time-of-Transmission of the acoustic signal. Using this measurement model, an Uniformly Globally Asymptotically Stable (UGAS), three stage estimation strategy (eXogenous Kalman Filter) is designed to estimate the position of an acoustic fish-tag and evaluated against a benchmark Extended Kalman Filter based estimator. The efficacy of the developed estimation method is demonstrated experimentally, in presence of intermittent observations using an array of receivers mounted on three Unmanned Surface Vessels (USVs).
ER  - 

TY  - CONF
TI  - Invariant smoothing on Lie Groups
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1703
EP  - 1710
AU  - P. Chauchat
AU  - A. Barrau
AU  - S. Bonnabel
PY  - 2018
KW  - estimation theory
KW  - Kalman filters
KW  - Lie groups
KW  - linearisation techniques
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - smoothing methods
KW  - linearizations
KW  - invariant Kalman filtering
KW  - robot localization
KW  - posteriori estimator
KW  - nonlinear smoothing methods
KW  - group-affine observation systems
KW  - Lie groups
KW  - invariant smoothing
KW  - Smoothing methods
KW  - Manifolds
KW  - Simultaneous localization and mapping
KW  - Kalman filters
KW  - Random variables
KW  - Estimation
KW  - Robot localization
DO  - 10.1109/IROS.2018.8594068
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we propose a (non-linear) smoothing algorithm for group-affine observation systems, a recently introduced class of estimation problems on Lie groups that bear a particular structure. As most non-linear smoothing methods, the proposed algorithm is based on a maximum a posteriori estimator, determined by optimization. But owing to the specific properties of the considered class of problems, the involved linearizations are proved to have a form of independence with respect to the current estimates, leveraged to avoid (partially or sometimes totally) the need to relinearize. The method is validated on a robot localization example, both in simulations and on real experimental data.
ER  - 

TY  - CONF
TI  - Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1711
EP  - 1717
AU  - K. Kawaharazuka
AU  - S. Makino
AU  - M. Kawamura
AU  - A. Fujii
AU  - Y. Asano
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - data acquisition
KW  - humanoid robots
KW  - muscle
KW  - robot vision
KW  - body tissue
KW  - joint-muscle model
KW  - muscle-route change model
KW  - geometric model
KW  - tendon-driven musculoskeletal humanoid Kengoro
KW  - muscle routes
KW  - tendon-driven musculoskeletal humanoids
KW  - flexible spine
KW  - body complexity
KW  - muscle lengths
KW  - muscle route changes
KW  - internal muscle tension
KW  - online self-body image acquisition
KW  - multiple degrees of freedom
KW  - controllability
KW  - neural network
KW  - Muscles
KW  - Robot sensing systems
KW  - Humanoid robots
KW  - Solid modeling
KW  - Training
DO  - 10.1109/IROS.2018.8593428
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.
ER  - 

TY  - CONF
TI  - A Combined RGB and Depth Descriptor for SLAM with Humanoids
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1718
EP  - 1724
AU  - R. Sheikh
AU  - S. OBwald
AU  - M. Bennewitz
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - humanoid robots
KW  - image colour analysis
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - feature tracking
KW  - codebooks
KW  - reproducibility
KW  - humanoid robots
KW  - visual simultaneous localization
KW  - depth descriptor
KW  - ORB-SLAM
KW  - visual SLAM system
KW  - track features
KW  - DLab
KW  - RGB-D camera
KW  - Nao humanoid
KW  - binary descriptor
KW  - FAB-MAP
KW  - place recognition module
KW  - Simultaneous localization and mapping
KW  - Image color analysis
KW  - Cameras
KW  - Three-dimensional displays
KW  - Humanoid robots
KW  - Visualization
DO  - 10.1109/IROS.2018.8593768
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a visual simultaneous localization and mapping (SLAM) system for humanoid robots. We introduce a new binary descriptor called DLab that exploits the combined information of color, depth, and intensity to achieve robustness with respect to uniqueness, reproducibility, and stability. We use DLab within ORB-SLAM, where we replaced the place recognition module with a modification of FAB-MAP that works with newly built codebooks using our binary descriptor. In experiments carried out in simulation and with a real Nao humanoid equipped with an RGB-D camera, we show that DLab has a superior performance in comparison to other descriptors. The application to feature tracking and place recognition reveal that the new descriptor is able to reliably track features even in sequences with seriously blurred images and that it has a higher percentage of correctly identified similar images. As a result, our new visual SLAM system has a lower absolute trajectory error in comparison to ORB-SLAM and is able to accurately track the robot's trajectory.
ER  - 

TY  - CONF
TI  - Neural-Network-Controlled Spring Mass Template for Humanoid Running
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1725
EP  - 1731
AU  - S. Xin
AU  - B. Delhaisse
AU  - Y. You
AU  - C. Zhou
AU  - M. Shahbazi
AU  - N. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - interpolation
KW  - legged locomotion
KW  - neurocontrollers
KW  - pendulums
KW  - robot dynamics
KW  - springs (mechanical)
KW  - table lookup
KW  - lookup tables
KW  - data-driven approach
KW  - deep neural network
KW  - simulation data
KW  - SLIP model
KW  - humanoid robot
KW  - whole-body model
KW  - QP-based inverse dynamics controller
KW  - WALK-MAN robot
KW  - robust running motions
KW  - neural-network-controlled spring mass template
KW  - humanoid running
KW  - legged robots
KW  - model-based approaches
KW  - whole-body robot
KW  - controlled SLIP-like behaviors
KW  - online incompatibility
KW  - interpolations
KW  - spring-loaded inverted pendulum model
KW  - Legged locomotion
KW  - Neural networks
KW  - Data models
KW  - Training
KW  - Biological system modeling
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593403
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To generate dynamic motions such as hopping and running on legged robots, model-based approaches are usually used to embed the well studied spring-loaded inverted pendulum (SLIP) model into the whole-body robot. In producing controlled SLIP-like behaviors, existing methods either suffer from online incompatibility or resort to classical interpolations based on lookup tables. Alternatively, this paper presents the application of a data-driven approach which obviates the need for solving the inverse of the running return map online. Specifically, a deep neural network is trained offline with a large amount of simulation data based on the SLIP model to learn its dynamics. The trained network is applied online to generate reference foot placements for the humanoid robot. The references are then mapped to the whole-body model through a QP-based inverse dynamics controller. Simulation experiments on the WALK-MAN robot are conducted to evaluate the effectiveness of the proposed approach in generating bio-inspired and robust running motions.
ER  - 

TY  - CONF
TI  - Quadruped Locomotion Control Based on Two Bipeds Jointly Carrying Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1732
EP  - 1738
AU  - G. Zhang
AU  - S. Ma
AU  - F. Liang
AU  - Y. Li
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - quadruped locomotion control
KW  - novel gait planning
KW  - control framework
KW  - quadruped robot
KW  - rear ends
KW  - joint torques
KW  - support legs
KW  - bipedal sub-robots
KW  - quadruped body forces
KW  - bipedal torso forces
KW  - operating modes
KW  - virtual forces
KW  - support leg torques
KW  - gait generators
KW  - gait parameters
KW  - hind legs
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Torso
KW  - Radio frequency
KW  - Hip
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593413
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A novel gait planning and control framework was developed for quadruped locomotion of a robot. It modeled the quadruped robot as two bipeds carrying the body from the front and rear ends. We first mapped the relationship between the joint torques of support legs and the torso forces of the bipedal sub-robots. Then the equations describing the relationship between the quadruped body forces and the bipedal torso forces under various operating modes of the robot were deduced and solved. Virtual forces were generated on the quadruped body to manipulate its velocity and orientation. Then these virtual forces were distributed to the front and hind sub-robots to generate support leg torques. The state machines and gait generators for the two bipedal sub-robots were designed individually, resulting in the decoupling of the gait parameters in the front legs and hind legs. The effectiveness of the controller was validated through dynamic simulations.
ER  - 

TY  - CONF
TI  - An Investigation of 2nd-Order Fixed Point SLIP Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1739
EP  - 1744
AU  - I. Kontolatis
AU  - E. Papadopoulos
PY  - 2018
KW  - approximation theory
KW  - collision avoidance
KW  - friction
KW  - legged locomotion
KW  - nonlinear control systems
KW  - pendulums
KW  - 1st-order fixed points
KW  - 2nd-order fixed points
KW  - 2nd-order fixed point SLIP behavior
KW  - analytical stance phase approximation
KW  - friction cone constraints
KW  - obstacle avoidance
KW  - SLIP model behavior analysis
KW  - nondimensional leg stiffness
KW  - numerical return map search scheme
KW  - nondimensional SLIP model
KW  - Legged locomotion
KW  - Springs
KW  - Friction
KW  - Mathematical model
KW  - Numerical models
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594375
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces alternative behaviors described by the SLIP model when it is subject to a range of initial conditions. A non-dimensional SLIP model and a numerical return map search scheme are used to determine fixed points as a function of non-dimensional leg stiffness and vertical displacement under friction constraints. A SLIP model behavior analysis is performed, using an analytical stance phase approximation, by diverging from the fixed points, i.e. by increasing/decreasing initial horizontal velocity, and/or touchdown angle. The results show that beyond the regular fixed points, the SLIP model performs an alternative, stable behavior that repeats itself every two cycles of motion. We call these 2nd-order fixed points and the regular ones 1st-order fixed points. A numerical simulation scheme was developed to investigate 2nd-order fixed points for a wide range of horizontal velocities and touchdown angles. Results show that 2nd-order fixed points respecting the friction cone constraints exist that can lead to a number of different behaviors such as high jumps, obstacle avoidance of different heights, or backward motion.
ER  - 

TY  - CONF
TI  - Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1745
EP  - 1750
AU  - M. Prágr
AU  - P. Čížek
AU  - J. Faigl
PY  - 2018
KW  - feature extraction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - terrain mapping
KW  - multilegged robot
KW  - crawled terrain
KW  - hexapod robot
KW  - legged robot
KW  - terrain features inference
KW  - aerial scan
KW  - robot locomotion
KW  - incremental learning
KW  - geometrical data
KW  - visual data
KW  - terrain learning
KW  - extraterrestrial missions
KW  - robot deployment
KW  - robot motion planning
KW  - cost of transport estimation
KW  - terrain descriptors
KW  - mechanical properties
KW  - Robots
KW  - Feature extraction
KW  - Image color analysis
KW  - Estimation
KW  - Unmanned aerial vehicles
KW  - Three-dimensional displays
KW  - Visualization
DO  - 10.1109/IROS.2018.8593374
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.
ER  - 

TY  - CONF
TI  - Determining Optimal Gait Parameters for a Statically Stable Walking Human Assistive Quadruped Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1751
EP  - 1756
AU  - E. W. McClain
AU  - S. Meek
PY  - 2018
KW  - legged locomotion
KW  - optimal control
KW  - optimisation
KW  - robot dynamics
KW  - stability
KW  - optimal gait parameters
KW  - statically stable walking human assistive quadruped robot
KW  - optimal statically stable gait
KW  - quadruped robot walking
KW  - energy efficient gait
KW  - energy efficient quadruped gait
KW  - cost function
KW  - energy term
KW  - stability term
KW  - quasistatic analysis
KW  - human assistive device
KW  - optimization
KW  - Legged locomotion
KW  - Foot
KW  - Cost function
KW  - Stability analysis
KW  - Gravity
DO  - 10.1109/IROS.2018.8593979
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we propose a method to determine an optimal statically stable gait for a quadruped robot walking in the presence of an expected disturbance. There exists a tradeoff between a stable gait and an energy efficient gait. Our goal is to determine an energy efficient quadruped gait that will maintain stability while a human uses the device to stabilize themselves while walking. In order to determine an optimal gait, we present a cost function consisting of an energy term and a stability term. A method of evaluating the cost function using dynamics and quasi-static analysis is demonstrated. The optimization is implemented for a human assistive device currently being designed and the results are verified in simulation.
ER  - 

TY  - CONF
TI  - An Adaptive Landing Gear for Extending the Operational Range of Helicopters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1757
EP  - 1763
AU  - B. Stolz
AU  - T. Brödermann
AU  - E. Castiello
AU  - G. Englberger
AU  - D. Erne
AU  - J. Gasser
AU  - E. Hayoz
AU  - S. Müller
AU  - L. Muhlebach
AU  - T. Löw
AU  - D. Scheuer
AU  - L. Vandeventer
AU  - M. Bjelonic
AU  - F. Günther
AU  - H. Kolvenbach
AU  - M. Hopflinger
AU  - M. Hutter
PY  - 2018
KW  - actuators
KW  - adaptive control
KW  - aircraft landing guidance
KW  - autonomous aerial vehicles
KW  - force control
KW  - gears
KW  - helicopters
KW  - legged locomotion
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - off-field landing
KW  - skid based helicopter landing gears
KW  - mountain rescue
KW  - economic practicability
KW  - innovative actuation
KW  - brake
KW  - motor
KW  - spring-damper system
KW  - force control
KW  - tipping
KW  - aircraft
KW  - unmanned helicopter
KW  - landing phase
KW  - optimal load distribution
KW  - leg
KW  - wheel based helicopter landing gears
KW  - adaptive landing gear
KW  - Legged locomotion
KW  - Gears
KW  - Helicopters
KW  - Foot
KW  - Brakes
KW  - Rotors
KW  - Damping
DO  - 10.1109/IROS.2018.8594062
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Conventional skid or wheel based helicopter landing gears severely limit off-field landing possibilities, which are crucial when operating in scenarios such as mountain rescue. In this context, slopes beyond 8° and small obstacles can already pose a substantial hazard. An adaptive landing gear is proposed to overcome these limitations. It consists of four legs with one degree of freedom each. The total weight was minimized to demonstrate economic practicability. This was achieved by an innovative actuation, composed of a parallel arrangement of motor and brake, which relieves the motor from large impact loads during hard landings. The loads are alleviated by a spring-damper system acting in series to the actuation. Each leg is individually force controlled for optimal load distribution on compliant ground and to avoid tipping. The operation of the legs is fully autonomous during the landing phase. A prototype was designed and successfully tested on an unmanned helicopter with a maximum take-off weight of 78 kg. Finally, the implementation of the landing gear concept on aircraft of various scales was discussed.
ER  - 

TY  - CONF
TI  - Designing Concentric Tube Manipulators for Stability Using Topology Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1764
EP  - 1769
AU  - K. A. Xin Jue Luo
AU  - T. Looi
AU  - S. Sabetian
AU  - J. Drake
PY  - 2018
KW  - bending
KW  - finite element analysis
KW  - manipulator dynamics
KW  - medical robotics
KW  - pipes
KW  - surgery
KW  - torsion
KW  - snapping problem
KW  - concentric tube robotic system
KW  - topology optimization
KW  - concentric tube continuum robots
KW  - surgical environments
KW  - BTSR
KW  - tube design
KW  - concentric tube manipulators
KW  - surgical environment
KW  - bending to torsional stiffness ratio
KW  - finite element analysis
KW  - Electron tubes
KW  - Optimization
KW  - Topology
KW  - Stress
KW  - Manipulators
KW  - Load modeling
DO  - 10.1109/IROS.2018.8593806
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the major problems facing the development and road to practical usage of concentric tube continuum robots in surgical environments is that of instability. This issue, also known as the snapping problem, is caused by a tube having a high bending to torsional stiffness ratio (BTSR). Past efforts have shown that by cutting patterns on the tubes, this problem can be avoided. This paper seeks to redesign the topology of the tubes so that BTSR is decreased and the snapping problem is resolved in a particular tube set. The generated designs are then tested through finite element analysis as well as experimental testing to demonstrate the elimination of the snapping problem. Using this novel tube design on a concentric tube robotic system can increase its stable workspace because it allows the usage of greater tube curvatures and/or curve lengths.
ER  - 

TY  - CONF
TI  - Haptic Feedback and Dynamic Active Constraints for Robot-Assisted Endovascular Catheterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1770
EP  - 1775
AU  - G. Dagnino
AU  - J. Liu
AU  - M. E. M. K. Abdelaziz
AU  - W. Chi
AU  - C. Riga
AU  - G. -. Yang
PY  - 2018
KW  - blood vessels
KW  - catheters
KW  - ergonomics
KW  - force feedback
KW  - haptic interfaces
KW  - manipulators
KW  - medical robotics
KW  - phantoms
KW  - surgery
KW  - robot-assisted endovascular catheterization
KW  - computer assistance
KW  - reduced radiation doses
KW  - tortuous anatomy
KW  - natural bedside manipulation skills
KW  - dexterity
KW  - clinical usability
KW  - robotic platform
KW  - ergonomic master-slave system
KW  - navigation system
KW  - integrated vision-based haptic feedback
KW  - natural bedside skills
KW  - dynamic motion tracking
KW  - catheterization tasks
KW  - phantom
KW  - mean force
KW  - maximum force
KW  - force feedback
KW  - vision-based dynamic active constraints
KW  - ergonomic robotic catheter manipulator
KW  - robot-assisted endovascular procedures
KW  - CathBot
KW  - vessel walls
KW  - vascular surgeon
KW  - catheter tip
KW  - Catheters
KW  - Surgery
KW  - Navigation
KW  - Force feedback
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593628
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic and computer assistance can bring significant benefits to endovascular procedures in terms of precision and stability, reduced radiation doses, improved comfort and access to difficult and tortuous anatomy. However, the design of current commercially available platforms tends to alter the natural bedside manipulation skills of the operator, so that the manually acquired experience and dexterity are not well utilized. Furthermore, most of these systems lack of haptic feedback, preventing their acceptance and limiting the clinical usability. In this paper a new robotic platform for endovascular catheterization, the CathBot, is presented. It is an ergonomic master-slave system with navigation system and integrated vision-based haptic feedback, designed to maintain the natural bedside skills of the vascular surgeon. Unlike previous work reported in literature, dynamic motion tracking of both the vessel walls the catheter tip is incorporated to create dynamic active constraints. The system was evaluated through a combined quantitative and qualitative user study simulating catheterization tasks on a phantom. Forces exerted on the phantom were measured. The results showed a 70% decrease in mean force and 61% decrease in maximum force when force feedback is provided. This research provides the first integration of vision-based dynamic active constraints within an ergonomic robotic catheter manipulator. The technological advances presented here, demonstrates that vision-based haptic feedback can improve the effectiveness, precision, and safety of robot-assisted endovascular procedures.
ER  - 

TY  - CONF
TI  - Intuitive Gaze-Control of a Robotized Flexible Endoscope
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1776
EP  - 1782
AU  - T. J. C. O. Vrielink
AU  - J. G. Puyal
AU  - A. Kogkas
AU  - A. Darzi
AU  - G. Mylonas
PY  - 2018
KW  - endoscopes
KW  - manipulators
KW  - medical robotics
KW  - visual servoing
KW  - intuitive gaze-control
KW  - robotized flexible endoscope
KW  - flexible endoscopy
KW  - intuitive platform
KW  - ergonomic platform
KW  - standard endoscope
KW  - gaze control system
KW  - eye-tracking
KW  - hands-free manipulation
KW  - system characteristics
KW  - robotized system
KW  - manually controlled endoscope
KW  - gaze controlled endoscope
KW  - lower task load
KW  - hands-free gaze control
KW  - visual servoing
KW  - Endoscopes
KW  - Robots
KW  - Optical imaging
KW  - Task analysis
KW  - Gears
KW  - Control systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8594426
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flexible endoscopy is a routinely performed procedure that has predominantly remained unchanged for decades despite its many challenges. This paper introduces a novel, more intuitive and ergonomic platform that can be used with any flexible endoscope, allowing easier navigation and manipulation. A standard endoscope is robotized and a gaze control system based on eye-tracking is developed and implemented, allowing hands-free manipulation. The system characteristics and step response has been evaluated using visual servoing. Further, the robotized system has been compared with a manually controlled endoscope during a user study. The users (n=11) showed a preference for the gaze controlled endoscope and a lower task load when the task was performed with the gaze control. In addition, gaze control was related to a higher success rate and a lower time to perform the task. The results presented validate the system's technical performance and demonstrate the intuitiveness of hands-free gaze control in flexible endoscopy.
ER  - 

TY  - CONF
TI  - A Soft Robot to Navigate the Lumens of the Body Using Undulatory Locomotion Generated by a Rotating Magnetic Dipole Field
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1783
EP  - 1788
AU  - L. N. Pham
AU  - J. J. Abbott
PY  - 2018
KW  - blood vessels
KW  - magnetic actuators
KW  - magnetic fields
KW  - magnetic sensors
KW  - medical robotics
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - path planning
KW  - permanent magnets
KW  - rotating magnetic dipole field
KW  - soft-robotic actuation concept
KW  - mesoscale medical robot
KW  - natural lumens
KW  - blood vessels
KW  - embedded permanent magnets
KW  - magnetic polarity
KW  - rotating dipole magnetic field
KW  - traveling-wave undulatory motion
KW  - soft-actuation technology
KW  - nonuniform dipole fields
KW  - undulatory locomotion
KW  - uniform dipole fields
KW  - diagnostic context
KW  - therapeutic context
KW  - numerical simulation
KW  - Coils
KW  - Magnetic resonance imaging
KW  - Magnetic separation
KW  - Soft robotics
KW  - Permanent magnets
KW  - Magnetic moments
DO  - 10.1109/IROS.2018.8594247
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe a soft-robotic actuation concept to enable a mesoscale medical robot to navigate the natural lumens of the body, such as blood vessels and intestines. The concept comprises a simple soft robot with two embedded permanent magnets with alternating magnetic polarity, and a rotating (nonuniform) dipole magnetic field that is swept over the robot, resulting in a traveling-wave undulatory motion that propels the robot forward and backward. This soft-actuation technology can be fabricated in a wide range of sizes due to its simplicity, and has the potential to be applied in a variety of diagnostic and therapeutic contexts. We conduct experiments and numerical simulations to verify the movement of the soft robot. Then, we confirm the benefits of using nonuniform dipole fields over using uniform fields, as well as the benefits of alternating the polarity of the magnets embedded in the device.
ER  - 

TY  - CONF
TI  - A Robot System for Automated Wound Filling with Jetted Materials
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1789
EP  - 1794
AU  - B. H. Jafari
AU  - L. Namhyung
AU  - R. Thompson
AU  - J. Schellhorn
AU  - B. Antohe
AU  - N. Gans
PY  - 2018
KW  - computer vision
KW  - control engineering computing
KW  - diseases
KW  - medical robotics
KW  - nozzles
KW  - path planning
KW  - patient treatment
KW  - proteins
KW  - skin
KW  - surgery
KW  - tissue engineering
KW  - wounds
KW  - robot system
KW  - automated wound filling
KW  - jetted materials
KW  - skin surface wounds
KW  - chronic illness
KW  - tissue engineering
KW  - 3D machine vision system
KW  - skin wound
KW  - 3D point set
KW  - path planning algorithm
KW  - robot manipulator
KW  - ink-jet nozzle
KW  - biomaterials
KW  - cell growth promoters
KW  - Wounds
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Cameras
KW  - Machine vision
KW  - Manuals
DO  - 10.1109/IROS.2018.8594252
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skin surface wounds due to burns, surgeries and chronic illness affect millions of people worldwide. Tissue engineering has become an increasingly popular treatment, but it is a highly manual process. Increasing the automation in tissue engineering could increase the rate of treatment for patients and improve outcomes. We present an initial investigation into an automated in-situ treatment. In our proposed method, a 3D machine vision system detects a skin wound to be treated and then determines the 3D point set corresponding to the wound. The 3D point set is then passed to path planning algorithm for a robot manipulator to move an ink-jet nozzle over the wound and fill the cavity with quick-curing/gelling fluids such collagen and other biomaterials and cell growth promoters. This paper details initial results and experimental validation of each of the proposed steps.
ER  - 

TY  - CONF
TI  - State Estimation for MRI-Actuated Cathers via Catadioptric Stereo Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1795
EP  - 1800
AU  - T. Greigarn
AU  - R. Jackson
AU  - M. C. Çavuşoğlu
PY  - 2018
KW  - biomedical MRI
KW  - cameras
KW  - catheters
KW  - image segmentation
KW  - medical robotics
KW  - particle filtering (numerical methods)
KW  - particle filter
KW  - catadioptric camera system
KW  - tracking algorithm
KW  - MRI-actuated cathers
KW  - catadioptric stereo camera
KW  - MRI-actuated catheter
KW  - novel robotic catheter system
KW  - MR tracking system
KW  - alternative catheter tracking method
KW  - Catheters
KW  - Cameras
KW  - Actuators
KW  - Tracking
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Mirrors
DO  - 10.1109/IROS.2018.8594153
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An MRI-actuated catheter is a novel robotic catheter system that utilizes the MR scanner for both remote steering and catheter tracking. In order to develop the mathematical model and the planning algorithm of the catheter in parallel to the MR tracking system, an alternative catheter tracking method is needed. This paper presents a catheter tracking algorithm based on the particle filter and the catadioptric camera system. The motion model of the particle filter is based on the quasi-static kinematics of the catheter. The measurement model calculates the weights of the particles according to the normalized crosscorrelation of the segmented image from camera and a virtual rendering of the catheter. The efficacy of the tracking algorithm is demonstrates via experimental results.
ER  - 

TY  - CONF
TI  - Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1801
EP  - 1807
AU  - M. Turan
AU  - E. P. Ornek
AU  - N. Ibrahimli
AU  - C. Giracoglu
AU  - Y. Almalioglu
AU  - M. F. Yanik
AU  - M. Sitti
PY  - 2018
KW  - biomedical optical imaging
KW  - diseases
KW  - endoscopes
KW  - image sequences
KW  - medical image processing
KW  - medical robotics
KW  - motion estimation
KW  - unsupervised learning
KW  - single-view depth estimation network
KW  - passive capsule endoscopes
KW  - minimally invasive diagnostic technology
KW  - realtime odometry
KW  - monocular endoscopic capsule robots
KW  - multiview pose estimation
KW  - endoscopic capsule robots
KW  - disease detection
KW  - drug delivery
KW  - gastrointestinal tract
KW  - reprojection minimization
KW  - unsupervised odometry
KW  - depth learning
KW  - biopsy-like operations
KW  - ex-vivo porcine stomach datasets
KW  - motion estimation
KW  - Cameras
KW  - Robots
KW  - Endoscopes
KW  - Reliability
KW  - Sensors
KW  - Pose estimation
DO  - 10.1109/IROS.2018.8593623
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.
ER  - 

TY  - CONF
TI  - Bayesian-inferred Flexible Path Generation in Human-Robot Collaborative Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1816
EP  - 1822
AU  - W. Bentz
AU  - D. Panagou
PY  - 2018
KW  - Bayes methods
KW  - computational geometry
KW  - human-robot interaction
KW  - inference mechanisms
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - position control
KW  - probability
KW  - stochastic processes
KW  - flexible path human-robot collaborative network
KW  - weighted Euclidean distance
KW  - potentially optimal tasks
KW  - single task
KW  - optimal trajectory
KW  - task selection
KW  - human intent
KW  - Bayesian inference
KW  - human-robot collaborative networks
KW  - Bayesian-inferred flexible path generation
KW  - highly impulsive humans
KW  - Task analysis
KW  - Trajectory
KW  - Robot kinematics
KW  - Bayes methods
KW  - Collaboration
KW  - Cost function
DO  - 10.1109/IROS.2018.8593611
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for generating the trajectory of a robot assisting a human in servicing a set of tasks embedded in a convex 2-D domain. This method makes use of Bayesian inference to predict human intent in task selection. Rather than following optimal trajectory towards a single task, the robot computes a set of potentially optimal tasks each weighted by the human's posterior probability and superimposes them into a cost function that is designed to minimize the weighted Euclidean distance relative to set. The effect is a flexible path human-robot collaborative network that is shown in simulation to complete all tasks in a given domain in less time than existing methods for a certain class of highly impulsive humans, i.e., humans that tend to randomly switch tasks at times generated by a Poisson counting process. The algorithm is also illustrated through an experimental demonstration.
ER  - 

TY  - CONF
TI  - Head-Mounted Augmented Reality for Explainable Robotic Wheelchair Assistance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1823
EP  - 1829
AU  - M. Zolotas
AU  - J. Elsdon
AU  - Y. Demiris
PY  - 2018
KW  - augmented reality
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - wheelchairs
KW  - robotic wheelchair assistance
KW  - visual feedback
KW  - wheelchair navigation
KW  - head-mounted aid
KW  - Microsoft Hololens
KW  - mental model
KW  - severely disabled individuals
KW  - robotic wheelchairs
KW  - head-mounted augmented reality
KW  - augmented information acquisition
KW  - assistive navigation
KW  - immersive wheelchair training regime
KW  - learning curve
KW  - Wheelchairs
KW  - Mobile robots
KW  - Navigation
KW  - Visualization
KW  - Collision avoidance
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594002
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic wheelchairs with built-in assistive features, such as shared control, are an emerging means of providing independent mobility to severely disabled individuals. However, patients often struggle to build a mental model of their wheelchair's behaviour under different environmental conditions. Motivated by the desire to help users bridge this gap in perception, we propose a novel augmented reality system using a Microsoft Hololens as a head-mounted aid for wheelchair navigation. The system displays visual feedback to the wearer as a way of explaining the underlying dynamics of the wheelchair's shared controller and its predicted future states. To investigate the influence of different interface design options, a pilot study was also conducted. We evaluated the acceptance rate and learning curve of an immersive wheelchair training regime, revealing preliminary insights into the potential beneficial and adverse nature of different augmented reality cues for assistive navigation. In particular, we demonstrate that care should be taken in the presentation of information, with effort-reducing cues for augmented information acquisition (for example, a rear-view display) being the most appreciated.
ER  - 

TY  - CONF
TI  - Robot Programming Through Augmented Trajectories in Augmented Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1838
EP  - 1844
AU  - C. P. Quintero
AU  - S. Li
AU  - M. K. Pan
AU  - W. P. Chan
AU  - H. F. Machiel Van der Loos
AU  - E. Croft
PY  - 2018
KW  - augmented reality
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - industrial robots
KW  - motion control
KW  - robot programming
KW  - teaching
KW  - augmented trajectories
KW  - augmented reality
KW  - mixed reality head-mounted display
KW  - robotic interface
KW  - robot programming task
KW  - robot motion
KW  - AR-robot teaching interface
KW  - kinesthetic teaching interface
KW  - 7-DOF robot arm
KW  - Microsoft Hololens
KW  - carbon-fiber-reinforcement-polymer vacuum bagging process
KW  - AR manufacturing paradigm
KW  - Task analysis
KW  - Trajectory
KW  - Service robots
KW  - Visualization
KW  - End effectors
DO  - 10.1109/IROS.2018.8593700
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a future-focused approach for robot programming based on augmented trajectories. Using a mixed reality head-mounted display (Microsoft Hololens) and a 7-DOF robot arm, we designed an augmented reality (AR) robotic interface with four interactive functions to ease the robot programming task: 1) Trajectory specification. 2) Virtual previews of robot motion. 3) Visualization of robot parameters. 4) Online reprogramming during simulation and execution. We validate our AR-robot teaching interface by comparing it with a kinesthetic teaching interface in two different scenarios as part of a pilot study: creation of contact surface path and free space path. Furthermore, we present an industrial case study that illustrates our AR manufacturing paradigm by interacting with a 7-DOF robot arm to reduce wrinkles during the pleating step of the carbon-fiber-reinforcement-polymer vacuum bagging process in a simulated scenario.
ER  - 

TY  - CONF
TI  - The HRC Model Set for Human-Robot Collaboration Research
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1845
EP  - 1852
AU  - S. Zeylikman
AU  - S. Widder
AU  - A. Roncone
AU  - O. Mangin
AU  - B. Scassellati
PY  - 2018
KW  - human-robot interaction
KW  - HRC model set
KW  - human-robot collaboration research
KW  - human-robot collaboration experiments
KW  - HRC experiments
KW  - Robots
KW  - Task analysis
KW  - Collaboration
KW  - Robotic assembly
KW  - Complexity theory
KW  - Standards
DO  - 10.1109/IROS.2018.8593858
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a model set for designing human-robot collaboration (HRC) experiments. It targets a common scenario in HRC, which is the collaborative assembly of furniture, and it consists of a combination of standard components and custom designs. With this work, we aim at reducing the amount of work required to set up and reproduce HRC experiments, and we provide a unified framework to facilitate the comparison and integration of contributions to the field. The model set is designed to be modular, extendable, and easy to distribute. Importantly, it covers the majority of relevant research in HRC, and it allows tuning of a number of experimental variables that are particularly valuable to the field. Additionally, we provide a set of software libraries for perception, control and interaction, with the goal of encouraging other researchers to proactively contribute to our work.
ER  - 

TY  - CONF
TI  - Band of Brothers and Bolts: Caring About Your Robot Teammate
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1853
EP  - 1858
AU  - J. Wen
AU  - A. Stewart
AU  - M. Billinghurst
AU  - C. Tossell
PY  - 2018
KW  - computer games
KW  - human-robot interaction
KW  - consequential behavioral pattern
KW  - empathic response
KW  - robot teammate
KW  - robot companion
KW  - Robots
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Computer bugs
KW  - Time measurement
KW  - Bonding
DO  - 10.1109/IROS.2018.8594324
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.
ER  - 

TY  - CONF
TI  - DNN-based Speech Recognition System dealing with Motor State as Auxiliary Information of DNN for Head Shaking Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1859
EP  - 1863
AU  - M. Lee
AU  - J. Chang
PY  - 2018
KW  - acoustic signal processing
KW  - neural nets
KW  - robots
KW  - signal denoising
KW  - speech processing
KW  - speech recognition
KW  - motor state
KW  - head shaking robot
KW  - deep neural network
KW  - acoustic modeling
KW  - speech recognition algorithm
KW  - feature mapping model
KW  - acoustic model
KW  - phoneme recognition
KW  - feature enhancement model
KW  - speech recognition system
KW  - auxiliary information
KW  - DNN
KW  - background noise suppression
KW  - Robots
KW  - Speech recognition
KW  - Speech enhancement
KW  - Noise measurement
KW  - Feature extraction
KW  - Mel frequency cepstral coefficient
DO  - 10.1109/IROS.2018.8593396
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a deep neural network (DNN) based integrated background noise suppression and acoustic modeling for speech recognition proposed in which on/off state of the motor for the head shaking robot is employed as the relevant auxiliary information of the DNN input. Since the motor sound being generated when the robot is moving or shaking its head severely degrades the performance of the speech recognition accuracy, we propose to use the motor on/off state as additional information when designing the DNN-based recognition system. Our speech recognition algorithm consists of two parts including the feature mapping model for feature enhancement and the acoustic model for phoneme recognition. As for the feature mapping, the stacked DNN is designed for the precise feature enhancement such that the lower DNN and upper DNN are trained separately and combined after which the motor state is plugged into both the lower DNN and upper DNN in addition to the input noisy speech. Then, the acoustic model is trained upon the feature enhancement model in which the motor state is again used as the augmented feature. The proposed technique to suppress the acoustic and motor noises was evaluated in term of the phoneme error rate (PER) and showed a significant improvement over the conventional system.
ER  - 

TY  - CONF
TI  - The Power of a Hand-shake in Human-Robot Interactions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1864
EP  - 1869
AU  - J. Avelino
AU  - F. Correia
AU  - J. Catarino
AU  - P. Ribeiro
AU  - P. Moreno
AU  - A. Bernardino
AU  - A. Paiva
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - nonhandshake conditions
KW  - human-robot interactions
KW  - human emotional bond
KW  - human willingness
KW  - social robot Vizzy
KW  - handshake conditions
KW  - Task analysis
KW  - Navigation
KW  - Haptic interfaces
KW  - Human-robot interaction
KW  - Tactile sensors
DO  - 10.1109/IROS.2018.8593980
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we study the influence of a handshake in the human emotional bond to a robot. In particular, we evaluate the human willingness to help a robot whether the robot first introduces itself to the human with or without a handshake. In the tested paradigm the robot and the human have to perform a joint task, but at a certain stage, the robot needs help to navigate through an obstacle. Without requesting explicit help from the human, the robot performs some attempts to navigate through the obstacle, suggesting to the human that it requires help. In a study with 45 participants, we measure the human's perceptions of the social robot Vizzy, comparing the handshake vs non-handshake conditions. In addition, we evaluate the influence of a handshake in the pro-social behaviour of helping it and the willingness to help it in the future. The results show that a handshake increases the perception of Warmth, Animacy, Likeability, and the tendency to help the robot more, by removing the obstacle.
ER  - 

TY  - CONF
TI  - Received Signal Strength of Electromagnetic Waves Aided Integrated Inertial Navigation System for Underwater Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1870
EP  - 1876
AU  - D. Park
AU  - J. Jung
AU  - K. Kwak
AU  - J. Kim
AU  - W. K. Chung
PY  - 2018
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - navigation
KW  - position measurement
KW  - remotely operated vehicles
KW  - sensor fusion
KW  - underwater vehicles
KW  - wireless sensor networks
KW  - Kalman filter
KW  - Earth-fixed reference sensors
KW  - EM waves attenuation
KW  - long-term navigation
KW  - basin environment
KW  - underwater wireless sensor networks
KW  - EM waves sensors
KW  - sensor-fusion-based localization scheme
KW  - electromagnetic waves sensors
KW  - sensor fusion
KW  - underwater localization scheme
KW  - strong signal attenuation
KW  - signal uncertainties
KW  - underwater environment
KW  - unmanned underwater vehicle
KW  - sensory information
KW  - integrated inertial navigation system
KW  - Manganese
KW  - Attenuation
KW  - Sensor fusion
KW  - Robot sensing systems
KW  - Noise measurement
KW  - Time measurement
DO  - 10.1109/IROS.2018.8593675
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensory information from an Earth-fixed reference is necessary to guarantee a high localization accuracy of an unmanned underwater vehicle (UUV). However, the implementation of these sensors in an underwater environment is challenging because of signal uncertainties and strong signal attenuation. In this paper, we propose an underwater localization scheme with a sensor fusion of inertial navigation system (INS) and received signal strength of electromagnetic (EM) waves sensors. In the proposed sensor-fusion-based localization scheme, the UUV predicts its location by using INS based on dead-reckoning and corrects the predicted position by Kalman filter using EM waves sensor information when the UUV receives the signals of EM waves sensors in underwater wireless sensor networks. The proposed scheme enables localization with high accuracy and high sampling rate during a long-term task. The results of an experiment performed in a basin environment shows the feasibility of the proposed scheme. The scheme achieved reliable localization accuracy by comparing the pre-measured ground-truth position and long-term navigation. These results show the feasibility of exploiting EM waves attenuation as Earth-fixed reference sensors.
ER  - 

TY  - CONF
TI  - Multibeam Data Processing for Underwater Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1877
EP  - 1884
AU  - P. V. Teixeira
AU  - F. S. Hover
AU  - J. J. Leonard
AU  - M. Kaess
PY  - 2018
KW  - image segmentation
KW  - oceanographic techniques
KW  - sonar
KW  - sonar detection
KW  - sonar imaging
KW  - underwater vehicles
KW  - balanced trade-off
KW  - underwater mapping literature
KW  - underwater mapping literature
KW  - local thresholding techniques
KW  - subsea structures
KW  - multibeam data processing
KW  - DIDSON imaging sonar
KW  - map accuracy
KW  - sonar-based underwater mapping
KW  - sonar artifacts
KW  - range measurements
KW  - occupied regions
KW  - free regions
KW  - received acoustic echos
KW  - sonars output
KW  - underwater mapping platforms
KW  - primary sensor
KW  - multibeam sonars
KW  - Sonar measurements
KW  - Robot sensing systems
KW  - Acoustic beams
KW  - Image segmentation
KW  - Mathematical model
KW  - Acoustics
DO  - 10.1109/IROS.2018.8594128
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.
ER  - 

TY  - CONF
TI  - Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1885
EP  - 1891
AU  - T. Manderson
AU  - J. C. G. Higuera
AU  - R. Cheng
AU  - G. Dudek
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - mobile robots
KW  - navigation
KW  - object detection
KW  - robot vision
KW  - supervised learning
KW  - proportional controller
KW  - vision-based autonomous underwater swimming
KW  - computer vision
KW  - visual target selection
KW  - coral-deprived regions
KW  - monocular image data
KW  - convolutional neural network
KW  - supervised learning
KW  - motor controller
KW  - collision avoidance
KW  - autonomous robot swimming
KW  - autonomous coral reef navigation
KW  - obstacle-avoidance
KW  - forward-facing camera
KW  - Navigation
KW  - Cameras
KW  - Robot vision systems
KW  - Task analysis
KW  - Visualization
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594410
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.
ER  - 

TY  - CONF
TI  - Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1892
EP  - 1899
AU  - C. A. Mueller
AU  - T. Doernbach
AU  - A. G. Chavez
AU  - D. Köhntopp
AU  - A. Birk
PY  - 2018
KW  - autonomous underwater vehicles
KW  - data acquisition
KW  - marine safety
KW  - mobile robots
KW  - perception
KW  - robust continuous system integration
KW  - critical deep-sea robot operations
KW  - knowledge-enabled simulation
KW  - reliability
KW  - self-localization
KW  - system components
KW  - safety
KW  - simulation in the loop methodology
KW  - SIL methodology
KW  - Task analysis
KW  - Robot sensing systems
KW  - Data models
KW  - Benchmark testing
KW  - Continuous time systems
DO  - 10.1109/IROS.2018.8594392
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.
ER  - 

TY  - CONF
TI  - Reliable fusion of black-box estimates of underwater localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1900
EP  - 1905
AU  - H. F. Chame
AU  - M. M. dos Santos
AU  - S. S. da Costa Botelho
PY  - 2018
KW  - estimation theory
KW  - Kalman filters
KW  - mobile robots
KW  - Monte Carlo methods
KW  - sensor fusion
KW  - underwater vehicles
KW  - inertial sensory
KW  - Kalman filter
KW  - augmented Monte Carlo localization algorithms
KW  - geophysical sensory
KW  - task context
KW  - localization signal
KW  - heuristic model
KW  - underwater robot localization
KW  - un-modeled noise
KW  - adaptive fusion policy
KW  - redundant parametric estimations
KW  - information fusion
KW  - robot tracking
KW  - black-box estimates
KW  - reliable fusion
KW  - Estimation
KW  - Task analysis
KW  - Reliability
KW  - Robot sensing systems
KW  - Global Positioning System
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593593
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.
ER  - 

TY  - CONF
TI  - Coverage Optimization with Non-Actuated, Floating Mobile Sensors using Iterative Trajectory Planning in Marine Flow Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1906
EP  - 1912
AU  - J. Hansen
AU  - G. Dudek
PY  - 2018
KW  - oceanographic equipment
KW  - oceanographic techniques
KW  - passive nodes
KW  - coverage optimization
KW  - mobile sensors
KW  - iterative trajectory planning
KW  - marine flow fields
KW  - spatial coverage problem
KW  - passive floating sensors
KW  - iterative measurement
KW  - modeling scheme
KW  - initial sample point
KW  - survey area
KW  - ambient surface currents
KW  - computational tool
KW  - autonomous marine surveying system
KW  - ocean drifters
KW  - spatial distribution
KW  - ocean flow fields
KW  - Trajectory
KW  - Sensors
KW  - Oceans
KW  - Planning
KW  - Sea measurements
KW  - Computational modeling
KW  - Robots
DO  - 10.1109/IROS.2018.8594281
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers a spatial coverage problem in which a network of passive floating sensors is used to collect samples in a body of water. We employ an iterative measurement and modeling scheme to incrementally deploy sensors so as to achieve spatial coverage, despite only controlling the initial sample point. Once deployed, sensors are moved about a survey area by ambient surface currents. We demonstrate our results in simulation on 40 different ocean flow fields and compare against several baselines. This work provides a computational tool for scientists seeking a low-cost, autonomous marine surveying system. Although in this paper, we concentrate on ocean drifters, our approach can be extended to other domains where a spatial distribution of passive nodes in a flow field can be modeled.
ER  - 

TY  - CONF
TI  - A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1913
EP  - 1918
AU  - M. Hassan
AU  - D. Liu
PY  - 2018
KW  - autonomous underwater vehicles
KW  - bridges (structures)
KW  - inspection
KW  - multi-robot systems
KW  - path planning
KW  - underwater structures
KW  - DSCPP
KW  - smooth paths
KW  - spiral path
KW  - popular boustrophedon-based coverage approach
KW  - intervention autonomous underwater vehicle
KW  - deformable spiral coverage path planning algorithm
KW  - smooth coverage path planning
KW  - deformable spiral-based algorithm
KW  - Spirals
KW  - Cleaning
KW  - Path planning
KW  - Fatigue
KW  - Underwater structures
KW  - Manipulators
KW  - Poles and towers
DO  - 10.1109/IROS.2018.8593563
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.
ER  - 

TY  - CONF
TI  - Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1919
EP  - 1926
AU  - J. Shi
AU  - T. Ma
AU  - C. Lee
AU  - E. Shimelis
AU  - C. Van Eijk
AU  - C. M. Clark
AU  - C. G. Lowe
PY  - 2018
KW  - autonomous underwater vehicles
KW  - calibration
KW  - clocks
KW  - Global Positioning System
KW  - hydrophones
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - sensors
KW  - synchronisation
KW  - time-of-arrival estimation
KW  - underwater sound
KW  - underwater acoustic transmitter
KW  - real-time calibration algorithms
KW  - TOF measurements
KW  - temperature variation
KW  - mixed integer linear program
KW  - AUV
KW  - TDOA filtering methods
KW  - mean localization errors
KW  - acoustic tag state estimation
KW  - unsynchronized hydrophones
KW  - underwater robotic sensor system
KW  - marine animals
KW  - time difference of arrival
KW  - autonomous underwater vehicle
KW  - nonlinear clock skews
KW  - time of flight
KW  - GPS data
KW  - TOF filtering methods
KW  - standard deviation
KW  - Clocks
KW  - Sonar equipment
KW  - Acoustics
KW  - Temperature measurement
KW  - Acoustic measurements
KW  - Estimation
DO  - 10.1109/IROS.2018.8593589
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.
ER  - 

TY  - CONF
TI  - GelSlim: A High-Resolution, Compact, Robust, and Calibrated Tactile-sensing Finger
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1927
EP  - 1934
AU  - E. Donlon
AU  - S. Dong
AU  - M. Liu
AU  - J. Li
AU  - E. Adelson
AU  - A. Rodriguez
PY  - 2018
KW  - calibration
KW  - dexterous manipulators
KW  - grippers
KW  - robot vision
KW  - tactile sensors
KW  - calibrated tactile-sensing finger
KW  - high-resolution tactile-sensing finger
KW  - robot grasping
KW  - previous GelSight sensing techniques
KW  - Adelson 2009
KW  - homogeneous output
KW  - previous vision-based tactile sensors
KW  - compact integration
KW  - optical path
KW  - illumination source
KW  - geometric design variables
KW  - finger thickness
KW  - tactile sensing area
KW  - grasping tasks
KW  - compliant gel
KW  - calibration process
KW  - homogeneous illumination
KW  - tactile images
KW  - Tactile sensors
KW  - Cameras
KW  - Three-dimensional displays
KW  - Grasping
DO  - 10.1109/IROS.2018.8593661
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work describes the development of a high-resolution tactile-sensing finger for robot grasping. This finger, inspired by previous GelSight sensing techniques (Johnson and Adelson 2009), features an integration that is slimmer, more robust, and with more homogeneous output than previous vision-based tactile sensors. To achieve a compact integration, we redesign the optical path from illumination source to camera by combining light guides and an arrangement of mirror reflections. We parameterize the optical path with geometric design variables and describe the tradeoffs between the finger thickness, camera depth of field, and size of the tactile sensing area. The sensor sustains the wear from continuous use - and abuse - in grasping tasks by combining tougher materials for the compliant gel, a textured fabric skin, a structurally rigid body, and a calibration process that maintains homogeneous illumination and contrast of the tactile images during use. Finally, we evaluate the sensor's durability along four metrics that track the signal quality during more than 3000 grasping experiments.
ER  - 

TY  - CONF
TI  - Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1943
EP  - 1950
AU  - Z. Flintoff
AU  - B. Johnston
AU  - M. Liarokapis
PY  - 2018
KW  - end effectors
KW  - force measurement
KW  - grippers
KW  - position control
KW  - tactile sensors
KW  - object exploration
KW  - Google Soli readings
KW  - grasping process
KW  - stable grasps
KW  - single-grasp
KW  - model-free object classification
KW  - hyper-adaptive hand
KW  - tactile sensors
KW  - end-effectors
KW  - object identification
KW  - robotics applications
KW  - autonomous object
KW  - quality inspection
KW  - hyper-adaptive robot hand
KW  - model objects
KW  - adaptive grasping mechanisms
KW  - tactile modules
KW  - barometric sensors
KW  - Google Soli sensor
KW  - everyday objects
KW  - random forests classifier
KW  - Robot sensing systems
KW  - Thumb
KW  - Google
KW  - Pins
DO  - 10.1109/IROS.2018.8594166
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots need to use their end-effectors not only to grasp and manipulate objects but also to understand the environment surrounding them. Object identification is of paramount importance in robotics applications, as it facilitates autonomous object handling, sorting, and quality inspection. In this paper, we present a new hyper-adaptive robot hand that is capable of discriminating between different everyday objects, as well as `model' objects with the same external geometry but varying material, density, or volume, with a single grasp. This work leverages all the benefits of simple, adaptive grasping mechanisms (robustness, simplicity, low weight, adaptability), a Random Forests classifier, tactile modules based on barometric sensors, and radar technology offered by the Google Soli sensor. Unlike prior work, the method does not rely on object exploration, object release or re-grasping and works for a wide variety of everyday objects. The feature space used consists of the Google Soli readings, the motor positions and the contact forces measured at different time instances of the grasping process. The whole approach is model-free and the hand is controlled in an open-loop fashion, achieving stable grasps with minimal complexity. The efficiency of the designs, sensors, and methods has been experimentally validated with experimental paradigms involving model and everyday objects.
ER  - 

TY  - CONF
TI  - Encoding Guidelines for a Culturally Competent Robot for Elderly Care
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1988
EP  - 1995
AU  - A. Sgorbissa
AU  - I. Papadopoulos
AU  - B. Bruno
AU  - C. Koulouglioti
AU  - C. Recchiuto
PY  - 2018
KW  - geriatrics
KW  - handicapped aids
KW  - human-robot interaction
KW  - man-machine systems
KW  - service robots
KW  - encoding guidelines
KW  - culturally competent robot
KW  - elderly care
KW  - socially assistive robots
KW  - older people
KW  - runtime adaptation
KW  - assisted person
KW  - invaluable enabling technology
KW  - culturally competent assistive behaviours
KW  - pepper robot
KW  - Indian persona
KW  - Guidelines
KW  - Cultural differences
KW  - Robot sensing systems
KW  - Motion pictures
KW  - Medical services
KW  - Encoding
DO  - 10.1109/IROS.2018.8594089
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The functionalities and behaviours of socially assistive robots for the care of older people are usually defined by the robot's designers with limited room for runtime adaptation to meet the preferences, expectations and needs of the assisted person. However, adaptation plays a crucial role for the robot's acceptability and ultimately for its effectiveness. Culture, which deeply influences a person's preferences and habits, can be viewed as an invaluable “enabling technology” to achieve such level of adaptation. This paper discusses how guidelines describing culturally competent assistive behaviours can be encoded in a robot to effectively tune its actions, gestures and words. The proposed system is implemented on a Pepper robot and tested with an Indian persona, whose habits and preferences the robot discovers and adapts to at runtime.
ER  - 

TY  - CONF
TI  - Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1996
EP  - 2001
AU  - L. Battistuzzi
AU  - A. Sgorbissa
AU  - C. Papadopoulos
AU  - I. Papadopoulos
AU  - C. Koulouglioti
PY  - 2018
KW  - ethical aspects
KW  - geriatrics
KW  - medical robotics
KW  - CARESSES robot
KW  - ethical thinking
KW  - VSD
KW  - international multidisciplinary project
KW  - culturally competent SAR
KW  - ethical concepts
KW  - value sensitive design
KW  - culturally competent socially assistive robots
KW  - Robots
KW  - Task analysis
KW  - Ethics
KW  - Guidelines
KW  - Cultural differences
KW  - Assistive technology
KW  - Medical services
DO  - 10.1109/IROS.2018.8594361
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.
ER  - 

TY  - CONF
TI  - Developing a New Brand of Culturally-Aware Personal Robots Based on Local Cultural Practices in the Danish Health Care System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2002
EP  - 2007
AU  - M. Rehm
AU  - K. Rodil
AU  - A. L. Krummheuer
PY  - 2018
KW  - brain
KW  - cultural aspects
KW  - health care
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - good starting point
KW  - concrete application fields
KW  - national culture
KW  - concrete applications
KW  - local cultural practices
KW  - culturally-aware personal robots
KW  - human robot interaction
KW  - Danish health care system
KW  - brain damage
KW  - learning processes
KW  - Cultural differences
KW  - Global communication
KW  - Robot sensing systems
KW  - Task analysis
KW  - Conferences
KW  - Programming
DO  - 10.1109/IROS.2018.8594478
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In earlier work it has been shown how culture can be used as a parameter influencing human robot interaction in general (e.g. [1]). While this is a good starting point, in our work with concrete application fields we encounter that culture in its usual definition as national culture (e.g. [2]; [3]) is too general a concept to be useful in these concrete applications. Thus, we shifted our focus instead to a concept of local cultural practices, which is derived from situated practices as in Wengers communities of practice [4] and grounded loosely in Sperbers idea of an epidemiology of representations [5], i.e. culture or rather cultural practices as an emergent phenomenon from learning processes in a given group. Developing this new kind of culture-aware robots can then not start from a general definition of culture like Hofstede [2], Schwartz and Sagiv [6], etc. but has to take the actual group of users (and stakeholders) into account. We exemplify this approach with our work in a residency for citizens with acquired brain damage.
ER  - 

TY  - CONF
TI  - Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2008
EP  - 2013
AU  - N. T. Viet Tuyen
AU  - S. Jeong
AU  - N. Y. Chong
PY  - 2018
KW  - emotion recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - multiculture society
KW  - incremental learning model
KW  - habitual emotional behaviors
KW  - social robot
KW  - emotional bodily expressions
KW  - imitated robot motions
KW  - cultural background
KW  - culturally competent robots
KW  - long term human-robot interaction
KW  - Robot kinematics
KW  - Neurons
KW  - Self-organizing feature maps
KW  - Trajectory
KW  - Training
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593974
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.
ER  - 

TY  - CONF
TI  - Identification of the User's Habits based on Activity Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2014
EP  - 2019
AU  - N. Melo
AU  - J. Lee
AU  - R. Suzuki
PY  - 2018
KW  - Fourier series
KW  - home automation
KW  - service robots
KW  - k-means method
KW  - Fourier series representation
KW  - activity recognition module
KW  - habit estimation system
KW  - smart house
KW  - user habits
KW  - activity information
KW  - user personality traits
KW  - habit representation
KW  - Activity recognition
KW  - Robot kinematics
KW  - TV
KW  - Radiofrequency identification
KW  - Receivers
KW  - Senior citizens
DO  - 10.1109/IROS.2018.8593873
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work proposes a system able to recognize the user habits based on his daily activities in a smart house. The habit estimation system uses the information provided by an activity recognition module, which provides the sequence and the duration of the activities performed by the user. Based on those parameters, the activities are represented as a signal by using Fourier series representation. Several output signals from different users are clustered into groups using the k-means method, where each cluster corresponds to a specific habit from a group of people. The proposed system was tested with dataset from the experiment that took place in an environment similar to a smart house. The users were asked to perform a set of 6 activities in any desired orders. In total, twenty-four subjects took part in the experiments. All activities were successfully recognized by the system and three different habits were found. The proposed system along with its habit representation can be potentially used to trace the relationships between the habits observed and some aspects of the user personality traits.
ER  - 

TY  - CONF
TI  - AIBO Robot Mortuary Rites in the Japanese Cultural Context*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2020
EP  - 2025
AU  - E. Knox
AU  - K. Watanabe
PY  - 2018
KW  - biomimetics
KW  - robots
KW  - AIBO Robot mortuary rites
KW  - Japanese cultural context
KW  - AlBO Entertainment Robot
KW  - Japanese tech-repair company
KW  - Buddhist funeral ceremony
KW  - A-Fun's maintenance services
KW  - AIBO funerals
KW  - human-machine relations
KW  - robot design
KW  - pet-like robots
KW  - zoomorphism
KW  - Companies
KW  - Maintenance engineering
KW  - Animals
KW  - Robot sensing systems
KW  - Medical treatment
KW  - Toy manufacturing industry
DO  - 10.1109/IROS.2018.8594066
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In 1999 Sony released the AlBO Entertainment Robot, selling more than 150,000 units worldwide until 2006. By 2014, Sony had stopped offering upgrades and maintenance for the product, and owners were faced with the fact their pet-like robots would “die”. Some shrines and temples in Japan hold ningyo kuyo̅ or mass funerals for dolls and other toys. At the suggestion of a small Japanese tech-repair company called A-Fun, one temple began offering a Buddhist funeral ceremony for AIBOs. Approximately 700 AIBOs have so far received a funeral service. This paper surveys A-Fun`s maintenance services for old AIBOs, the AIBO funerals, and Sony's new 2018 AIBO release, in the cross-disciplinary context of human-machine relations in Japan and elsewhere. Drawing on the author's interviews with key actors, it articulates links between philosophy and neuroscience to explain tendencies toward zoomorphism in robot design. Perceiving presence (sonzai kan) and sensibility (kansei) in objects is a culturally contingent phenomenon. Whereas ways of conceiving the partly animate are largely absent from Western philosophy, in the case of AIBO ownership in Japan there is a reverential mindfulness of the technology's inherent contradictions.
ER  - 

TY  - CONF
TI  - Social Robots as a Means of Integration? an Explorative Acceptance Study considering Gender and Non-verbal Behaviour
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2026
EP  - 2032
AU  - B. Lugrin
AU  - J. Dippold
AU  - K. Bergmann
PY  - 2018
KW  - computer aided instruction
KW  - educational robots
KW  - gender issues
KW  - human-robot interaction
KW  - culture-specific behaviours
KW  - social robot
KW  - german female nonverbal behaviour
KW  - educational robot
KW  - culture-specific manipulations
KW  - European states
KW  - gender-specific behaviours
KW  - Robot sensing systems
KW  - Mouth
KW  - Cultural differences
KW  - Training
KW  - Europe
DO  - 10.1109/IROS.2018.8593818
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The integration of migrants and refugees is currently a severe challenge for European states. Especially the imparting of culture- and gender-specific behaviours is an important issue. Social robots might be a valuable tool to introduce refugees to culture-specific behaviours of their host country. In this paper, we investigate the general acceptance of a social robot as well as users' perception of a robot presenting stereo-typical Arabic vs. German female non-verbal behaviour to Syrian newcomers to Germany. Our preliminary study revealed a generally positive attitude towards robots and the idea of an educational robot. Culture-specific manipulations were reflected in participants' partial preference for the Arabic version, but not in participants' perceptual ratings.
ER  - 

TY  - CONF
TI  - Do I act familiar? Investigating the Similarity-Attraction Principle on Culture-specific Communicative behaviour for Social Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2033
EP  - 2039
AU  - B. Lugrin
AU  - A. Bartl
AU  - H. Striepe
AU  - J. Lax
AU  - T. Toriizuka
PY  - 2018
KW  - behavioural sciences computing
KW  - cultural aspects
KW  - human-robot interaction
KW  - mobile robots
KW  - social robots conversation
KW  - cultural dichotomy
KW  - human-human interactions
KW  - culture-specific communicative behaviour
KW  - similarity-attraction principle
KW  - Cultural differences
KW  - Observers
KW  - Computational modeling
KW  - Global communication
KW  - Service robots
KW  - Senior citizens
DO  - 10.1109/IROS.2018.8594035
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Culture, amongst other individual and social factors, plays a crucial role in human-human interactions. If robots should become a part of our society, they should be able to act in culture-specific manners as well. In this paper, we showcase the implementation of a cultural dichotomy, namely individualism vs. collectivism, in a social robots' conversation. Presenting these conversations to human observers from Germany and Japan, we investigate whether the implemented differences are recognized as such, and whether stereotypical culture-specific behaviours that correspond to the observers' cultural background is preferred. Results suggest that the manipulations in behaviour had the intended effect, but are not reflected in personal preferences.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation Graphs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2040
EP  - 2047
AU  - S. Cruciani
AU  - C. Smith
AU  - D. Kragic
AU  - K. Hang
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - graph theory
KW  - grippers
KW  - Dexterous Manipulation graphs
KW  - in-hand manipulation
KW  - end-effector
KW  - dual arm robot
KW  - end pose
KW  - parallel grippers
KW  - Grippers
KW  - End effectors
KW  - Planning
KW  - Dynamics
KW  - Shape
DO  - 10.1109/IROS.2018.8594303
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.
ER  - 

TY  - CONF
TI  - Instance Segmentation of Visible and Occluded Regions for Finding and Picking Target from a Pile of Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2048
EP  - 2055
AU  - K. Wada
AU  - S. Kitagawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - image motion analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - target object
KW  - robotic system
KW  - human-annotated dataset
KW  - human annotations
KW  - image synthesis
KW  - inter-instance relationship
KW  - novel relook architecture
KW  - instance occlusion segmentation
KW  - occluded masks
KW  - Image segmentation
KW  - Robots
KW  - Feature extraction
KW  - Object segmentation
KW  - Image generation
KW  - Task analysis
KW  - Predictive models
DO  - 10.1109/IROS.2018.8593690
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order. The fundamental idea is to segment instances with both visible and occluded masks, which we call `instance occlusion segmentation'. To achieve this, we extend an existing instance segmentation model with a novel `relook' architecture, in which the model explicitly learns the inter-instance relationship. Also, by using image synthesis, we make the system capable of handling new objects without human annotations. The experimental results show the effectiveness of the relook architecture when compared with a conventional model and of the image synthesis when compared to a human-annotated dataset. We also demonstrate the capability of our system to achieve picking a target in a cluttered environment with a real robot.
ER  - 

TY  - CONF
TI  - Online prediction of threading task failure using Convolutional Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2056
EP  - 2061
AU  - G. R. Moreira
AU  - G. J. G. Lahr
AU  - T. Boaventura
AU  - J. O. Savazzi
AU  - G. A. P. Caurin
PY  - 2018
KW  - assembling
KW  - convolutional neural nets
KW  - fasteners
KW  - fault diagnosis
KW  - flexible manufacturing systems
KW  - force sensors
KW  - grippers
KW  - industrial robots
KW  - pattern classification
KW  - production engineering computing
KW  - supervised learning
KW  - online prediction
KW  - fasteners assembly automation
KW  - flexible systems
KW  - industrial robot
KW  - force-torque sensor
KW  - pneumatic gripper
KW  - supervised machine learning algorithm
KW  - threading task execution time
KW  - task failure
KW  - FDI techniques
KW  - convolutional neural network classifier
KW  - fault detection and isolation
KW  - CNN
KW  - Fasteners
KW  - Task analysis
KW  - Robot sensing systems
KW  - Instruction sets
KW  - Force
KW  - Service robots
DO  - 10.1109/IROS.2018.8594501
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fasteners assembly automation in different industries require flexible systems capable of dealing with faulty situations. Fault detection and isolation (FDI) techniques are used to detect failure and deal with them, avoiding losses on parts, tools or robots. However, FDI usually deals with the faults after or at the moment they occur. Thus, we propose a method that predicts potential failures online, based on the forces and torques signatures captured during the task. We demonstrate the approach experimentally using an industrial robot, equipped with a force-torque sensor and a pneumatic gripper, used to align and thread nuts into bolts. All effort information is fed into a supervised machine learning algorithm, based on a Convolutional Neural Network (CNN) classifier. The network was able to predict and classify the threading task outcomes in 3 groups: mounted, not mounted or jammed. Our approach was able to reduce in 10.9% the threading task execution time when compared to a reference without FDI, but had problem to predict jammed cases. The same experiment was also performed with other two additional learning algorithms, and the results were systematically compared.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning for Robotic Assembly of Mixed Deformable and Rigid Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2062
EP  - 2069
AU  - J. Luo
AU  - E. Solowjow
AU  - C. Wen
AU  - J. A. Ojea
AU  - A. M. Agogino
PY  - 2018
KW  - control engineering computing
KW  - feedback
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - position control
KW  - robot programming
KW  - robotic assembly
KW  - torque control
KW  - torque measurement
KW  - neural network
KW  - force torque measurements
KW  - passive mechanical compliance
KW  - deep reinforcement learning
KW  - torque control
KW  - robot control algorithms
KW  - assembly tasks
KW  - feedback control methods
KW  - robotic assembly
KW  - industrial robot
KW  - robot learning
KW  - admittance controller
KW  - policy learning process
KW  - robot arm wrist sensor
KW  - deformable hole
KW  - rigid peg
KW  - Robot sensing systems
KW  - Task analysis
KW  - Reinforcement learning
KW  - Neural networks
KW  - Service robots
KW  - Robotic assembly
DO  - 10.1109/IROS.2018.8594353
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning for assembly tasks can yield powerful robot control algorithms for applications that are challenging or even impossible for “conventional” feedback control methods. Insertion of a rigid peg into a deformable hole of smaller diameter is such a task. In this contribution we solve this task with Deep Reinforcement Learning. Force-torque measurements from a robot arm wrist sensor are thereby incorporated two-fold; they are integrated into the policy learning process and they are exploited in an admittance controller that is coupled to the neural network. This enables robot learning of contact-rich assembly tasks without explicit joint torque control or passive mechanical compliance. We demonstrate our approach in experiments with an industrial robot.
ER  - 

TY  - CONF
TI  - A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2100
EP  - 2106
AU  - M. Razban
AU  - J. Dargahi
AU  - B. Boulet
PY  - 2018
KW  - bending
KW  - blood vessels
KW  - catheters
KW  - finite element analysis
KW  - medical image processing
KW  - force estimation accuracy
KW  - endovascular intervention procedures
KW  - multiple catheter
KW  - sensor-less catheter contact force estimation approach
KW  - vessel wall
KW  - embolization
KW  - navigation process safety
KW  - robotic vascular interventions
KW  - sensor-less sensing solution
KW  - multiple contact point forces
KW  - image feedback
KW  - catheter-vessel interaction
KW  - real-time image processing algorithms
KW  - interaction contact points
KW  - image-based deflection measurement
KW  - nonlinear finite element beam model
KW  - three-point-bending tests
KW  - catheter-guidewire-vessel interaction contact forces
KW  - catheter-guidewire manipulation
KW  - bending modulus property
KW  - under-actuated catheter-guidewire
KW  - catheter-guidewire-vessel interaction
KW  - Catheters
KW  - Force
KW  - Robot sensing systems
KW  - Estimation
KW  - Force measurement
KW  - Phantoms
KW  - Finite element analysis
DO  - 10.1109/IROS.2018.8593387
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.
ER  - 

TY  - CONF
TI  - Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2107
EP  - 2113
AU  - X. Meng
AU  - Y. He
AU  - Q. Li
AU  - F. Gu
AU  - L. Yang
AU  - T. Yan
AU  - J. Han
PY  - 2018
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - force control
KW  - manipulators
KW  - position control
KW  - springs (mechanical)
KW  - vibration control
KW  - emergency switch process
KW  - dangerous work situation
KW  - industrial leakage accidents
KW  - flexible robot
KW  - small robot
KW  - aerial manipulator system
KW  - hexa-rotor UAV
KW  - UAV platform
KW  - hover flight
KW  - impedance control algorithm
KW  - force-sensorless contact force control method
KW  - one-DOF manipulator
KW  - spring-mass-damper system model
KW  - Manipulators
KW  - Force
KW  - Contacts
KW  - Attitude control
KW  - Force control
KW  - Pressing
DO  - 10.1109/IROS.2018.8593535
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.
ER  - 

TY  - CONF
TI  - Mechatronic fingernail with static and dynamic force sensing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2114
EP  - 2119
AU  - R. Kõiva
AU  - T. Schwank
AU  - G. Walck
AU  - R. Haschke
AU  - H. J. Ritter
PY  - 2018
KW  - force control
KW  - force sensors
KW  - manipulators
KW  - mechatronics
KW  - motion control
KW  - compact working prototype
KW  - multicell tactile fingertip sensor
KW  - distal phalange
KW  - robotic hand
KW  - mechatronic fingernail
KW  - static force sensing
KW  - dynamic force sensing
KW  - sensorized fingernail
KW  - mechatronic hands
KW  - static interaction forces
KW  - dynamic interaction forces
KW  - Nails
KW  - Robot sensing systems
KW  - Force
KW  - Force measurement
KW  - Delays
DO  - 10.1109/IROS.2018.8594207
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.
ER  - 

TY  - CONF
TI  - Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2159
EP  - 2166
AU  - R. Kreiser
AU  - A. Renner
AU  - Y. Sandamirskaya
AU  - P. Pienroj
PY  - 2018
KW  - mixed analogue-digital integrated circuits
KW  - mobile robots
KW  - neural nets
KW  - neurophysiology
KW  - pose estimation
KW  - SLAM (robots)
KW  - pose estimation
KW  - spiking neural networks
KW  - neuromorphic SLAM
KW  - biologically inspired neuronal path integration
KW  - mobile robot
KW  - neuronal map formation architecture
KW  - simultaneous localization and mapping
KW  - mixed signal analog-digital neuromorphic hardware
KW  - ultra low-power neuromorphic hardware
KW  - robotic vehicle simulation
KW  - on-board plasticity
KW  - Neurons
KW  - Neuromorphics
KW  - Collision avoidance
KW  - Simultaneous localization and mapping
KW  - Synapses
DO  - 10.1109/IROS.2018.8594228
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).
ER  - 

TY  - CONF
TI  - Precise Localization in High-Definition Road Maps for Urban Regions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2167
EP  - 2174
AU  - F. Poggenhans
AU  - N. O. Salscheider
AU  - C. Stiller
PY  - 2018
KW  - cameras
KW  - image resolution
KW  - Kalman filters
KW  - nonlinear filters
KW  - road vehicles
KW  - satellite navigation
KW  - stereo image processing
KW  - traffic engineering computing
KW  - high-resolution road maps
KW  - road borders
KW  - Unscented Kalman Filter
KW  - narrow urban roads
KW  - highly automated driving
KW  - precise localization
KW  - high-definition road maps
KW  - sensor specific feature layers
KW  - stereo camera
KW  - vehicle odometry
KW  - low-cost GNSS module
KW  - size 5.0 km
KW  - size 0.08 m
KW  - Roads
KW  - Global navigation satellite system
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Urban areas
KW  - Receivers
DO  - 10.1109/IROS.2018.8594414
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The future of automated driving in urban areas will most probably rely on highly accurate road maps. However, the necessary precision of a localization in such maps has so far only been reached using extra, sensor specific feature layers for localization. In this paper we want to show that it is possible to achieve sufficient accuracy without a separate localization layer. Instead, elements are used that are already contained in high-resolution road maps, such as markings and road borders. For this, we introduce a modular approach in which detections from different detection algorithms are associated with elements in the map and then fused to an absolute pose using an Unscented Kalman Filter. We evaluate our approach using a sensor setup that employs a stereo camera, vehicle odometry and a low-cost GNSS module on a 5km test route covering both narrow urban roads and multi-lane main roads under varying weather conditions. The results show that this approach is capable to be used for highly automated driving, showing an accuracy of 0.08m in typical road scenarios and a is available 98% of the time.
ER  - 

TY  - CONF
TI  - Virtual Occupancy Grid Map for Submap-based Pose Graph SLAM and Planning in 3D Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2175
EP  - 2182
AU  - B. Ho
AU  - P. Sodhi
AU  - P. Teixeira
AU  - M. Hsiao
AU  - T. Kusnur
AU  - M. Kaess
PY  - 2018
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - 3D scene reconstructions
KW  - virtual occupancy grid map
KW  - mobile robots
KW  - VOG-map
KW  - submap-based pose graph SLAM
KW  - underwater SLAM system
KW  - path planning
KW  - free space information
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Path planning
KW  - Robot kinematics
KW  - Casting
DO  - 10.1109/IROS.2018.8594234
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a mapping approach that constructs a globally deformable virtual occupancy grid map (VOG-map) based on local submaps. Such a representation allows pose graph SLAM systems to correct globally accumulated drift via loop closures while maintaining free space information for the purpose of path planning. We demonstrate use of such a representation for implementing an underwater SLAM system in which the robot actively plans paths to generate accurate 3D scene reconstructions. We evaluate performance on simulated as well as real-world experiments. Our work furthers capabilities of mobile robots actively mapping and exploring unstructured, three dimensional environments.
ER  - 

TY  - CONF
TI  - Decentralized Localization Framework using Heterogeneous Map-matchings
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2183
EP  - 2189
AU  - S. Lee
AU  - J. Kim
AU  - J. Kim
AU  - G. Oh
AU  - S. W. Seo
PY  - 2018
KW  - decentralised control
KW  - mobile robots
KW  - road vehicles
KW  - sensor fusion
KW  - stability
KW  - stochastic processes
KW  - decentralized localization framework
KW  - heterogeneous map-matchings
KW  - system stability
KW  - localization methods
KW  - map matchings
KW  - stochastic situational analysis model
KW  - heterogeneous map-matching sources
KW  - dissimilar sensors
KW  - fusion methods
KW  - multienvironment sensors
KW  - single environmental sensor
KW  - autonomous driving applications
KW  - robust real-time localization
KW  - Roads
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Cameras
KW  - Feature extraction
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8593948
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.
ER  - 

TY  - CONF
TI  - LDSO: Direct Sparse Odometry with Loop Closure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2198
EP  - 2204
AU  - X. Gao
AU  - R. Wang
AU  - N. Demmel
AU  - D. Cremers
PY  - 2018
KW  - feature extraction
KW  - graph theory
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - intensity gradient
KW  - DSO sliding window optimization
KW  - Sim(3) relative pose constraints
KW  - image pixel
KW  - loop closure detection
KW  - monocular visual SLAM system
KW  - Direct Sparse Odometry
KW  - state-of-the-art feature-based systems
KW  - pose-graph optimization
KW  - modified point selection strategy
KW  - relative poses
KW  - co-visibility graph
KW  - 3D geometric error terms
KW  - conventional feature-based bag-of-words approach
KW  - loop closure candidates
KW  - tracking frontend
KW  - corner features
KW  - LDSO
KW  - featureless areas
KW  - Optimization
KW  - Feature extraction
KW  - Microsoft Windows
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Bundle adjustment
KW  - Robustness
DO  - 10.1109/IROS.2018.8593376
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present an extension of Direct Sparse Odometry (DSO) [1] to a monocular visual SLAM system with loop closure detection and pose-graph optimization (LDSO). As a direct technique, DSO can utilize any image pixel with sufficient intensity gradient, which makes it robust even in featureless areas. LDSO retains this robustness, while at the same time ensuring repeatability of some of these points by favoring corner features in the tracking frontend. This repeatability allows to reliably detect loop closure candidates with a conventional feature-based bag-of-words (BoW) approach. Loop closure candidates are verified geometrically and Sim(3) relative pose constraints are estimated by jointly minimizing 2D and 3D geometric error terms. These constraints are fused with a co-visibility graph of relative poses extracted from DSO's sliding window optimization. Our evaluation on publicly available datasets demonstrates that the modified point selection strategy retains the tracking accuracy and robustness, and the integrated pose-graph optimization significantly reduces the accumulated rotation-, translation- and scale-drift, resulting in an overall performance comparable to state-of-the-art feature-based systems, even without global bundle adjustment.
ER  - 

TY  - CONF
TI  - Energetic Efficiency of a Compositional Controller on a Monoped With an Articulated Leg and SLIP Dynamics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2221
EP  - 2228
AU  - J. Yu
AU  - D. Hong
AU  - M. Haberland
PY  - 2018
KW  - design engineering
KW  - energy conservation
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - springs (mechanical)
KW  - trajectory control
KW  - energetic efficiency
KW  - compositional controller
KW  - articulated leg
KW  - SLIP dynamics
KW  - dynamic legged robot locomotion control
KW  - jumping robots
KW  - Raibert-style controller
KW  - SLIP-Raibert approach
KW  - trajectory-optimized controller
KW  - robot design
KW  - spring loaded inverted pendulum
KW  - three-link monoped model
KW  - Legged locomotion
KW  - Aerospace electronics
KW  - Actuators
KW  - Dynamics
KW  - Optimization
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593638
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Embedding the dynamics of the Spring Loaded Inverted Pendulum (SLIP) and applying a compositional controller around it can simplify dynamic legged robot locomotion control, but what is the energetic cost of this convenience? This paper measures the magnitude of this effect in such a way that the results are applicable to a wide class of jumping robots. A three-link monoped model with revolute joints is used to compare the energetic costs of locomotion using two different control approaches: 1) SLIP-embedding with a Raibert-style controller optimized for energetic efficiency, and 2) a trajectory optimized only for energetic efficiency. By performing this comparison in simulation for a large number of different monopeds randomly sampled from a space of realistic robot designs, it is found that the SLIP-Raibert approach requires, on average, almost twice the energy of the trajectory-optimized controller to traverse a given distance. Furthermore, the increase in energetic cost does not depend much on the particulars of the robot design, as the SLIP-Raibert approach requires at least 50% more energy for approximately 88% of realistic robot designs.
ER  - 

TY  - CONF
TI  - Precision Jumping Limits from Flight-phase Control in Salto-1P
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2229
EP  - 2236
AU  - J. K. Yim
AU  - R. S. Fearing
PY  - 2018
KW  - approximation theory
KW  - attitude control
KW  - control system synthesis
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - running velocity
KW  - precision results
KW  - height increases
KW  - foot placement precision degrades
KW  - attitude error
KW  - attitude control accuracy
KW  - error standard deviation
KW  - random walk
KW  - aggressive changes
KW  - precise foot placement
KW  - physical platform
KW  - offline dynamic model
KW  - order Taylor series approximation
KW  - untethered monopedal robot
KW  - deadbeat foot placement
KW  - Salto-1P
KW  - flight-phase control
KW  - precision jumping limits
KW  - Foot
KW  - Legged locomotion
KW  - Trajectory
KW  - Attitude control
KW  - Mathematical model
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594154
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We developed a deadbeat foot placement hopping controller for an untethered monopedal robot, Salto-1P. The controller uses a third order Taylor series approximation to an offline dynamic model and performs well on the physical platform. The robot demonstrated precise foot placement even on trajectories with aggressive changes in speed, direction, and height: in a random walk, its error standard deviation was 0.10 m. We establish how foot placement precision is tightly limited by attitude control accuracy, requiring attitude error less than 0.7 degrees for some tasks. We also show how foot placement precision degrades linearly as hopping height increases. These precision results apply to the large class of controllers that prescribe touchdown angle to control running velocity.
ER  - 

TY  - CONF
TI  - Analytically-Guided Design of a Tailed Bipedal Hopping Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2237
EP  - 2244
AU  - A. Shamsah
AU  - A. De
AU  - D. E. Koditschek
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - legged locomotion
KW  - robot dynamics
KW  - robot kinematics
KW  - hybrid averaging analysis
KW  - conjectured closed form representation
KW  - approximate hopping limit cycle
KW  - physical control
KW  - dynamical design choices affords
KW  - tailed bipedal hopping robot
KW  - template dynamics
KW  - actuator template
KW  - spatial hopping gait
KW  - Actuators
KW  - Legged locomotion
KW  - Damping
KW  - Kinematics
KW  - Limit-cycles
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8593677
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the first fully spatial hopping gait of a 12 DoF tailed biped driven by only 4 actuators. The control of this physical machine is built up from parallel compositions of controllers for progressively higher DoF extensions of a simple 2 DoF, 1 actuator template. These template dynamics are still not themselves integrable, but a new hybrid averaging analysis yields a conjectured closed form representation of the approximate hopping limit cycle as a function of its physical and control parameters. The resulting insight into the role of the machines kinematic and dynamical design choices affords a redesign leading to the newly achieved behavior.
ER  - 

TY  - CONF
TI  - MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2245
EP  - 2252
AU  - G. Bledt
AU  - M. J. Powell
AU  - B. Katz
AU  - J. Di Carlo
AU  - P. M. Wensing
AU  - S. Kim
PY  - 2018
KW  - actuators
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robust control
KW  - control architecture
KW  - legged locomotion
KW  - abduction-adduction degrees
KW  - gait modification
KW  - cost of transport
KW  - CoT
KW  - proprioceptive actuation
KW  - leg design
KW  - mechanical design
KW  - dynamic quadruped robot
KW  - robust robot
KW  - MIT cheetah 3
KW  - Legged locomotion
KW  - Actuators
KW  - Torque
KW  - Force
KW  - Knee
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593885
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.
ER  - 

TY  - CONF
TI  - Magneto: A Versatile Multi-Limbed Inspection Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2253
EP  - 2260
AU  - T. Bandyopadhyay
AU  - R. Steindl
AU  - F. Talbot
AU  - N. Kottege
AU  - R. Dungavell
AU  - B. Wood
AU  - J. Barker
AU  - K. Hoehn
AU  - A. Elfes
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - inspection
KW  - legged locomotion
KW  - manipulator kinematics
KW  - quadruped climbing robot
KW  - high dimensional system design
KW  - human entry portholes
KW  - three degrees of freedom actuated limbs
KW  - 3-DOF compliant magnetic foot
KW  - locomotion
KW  - complex 3-D structures
KW  - industrial confined spaces
KW  - body shape
KW  - multilimbed inspection robot
KW  - legged climbing robots
KW  - confined space openings
KW  - manipulation mode mid-climb
KW  - limb function
KW  - Magneto
KW  - compact foot design
KW  - Adhesives
KW  - Legged locomotion
KW  - Magnetic separation
KW  - Foot
KW  - Inspection
KW  - Soft magnetic materials
DO  - 10.1109/IROS.2018.8593891
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.
ER  - 

TY  - CONF
TI  - Data-Driven Discrete Planning for Targeted Hopping of Compliantly Actuated Robotic Legs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2261
EP  - 2266
AU  - D. Seidel
AU  - D. Lakatos
AU  - A. Albu-Schäffer
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - planar hopping leg prototype validate
KW  - hopping trials
KW  - data-driven manner
KW  - serial elastic actuation
KW  - planar leg
KW  - discrete-time planning problem
KW  - simple controller structure
KW  - time-continuous trajectories
KW  - considerable real-time problems
KW  - fast locomotion
KW  - motion planning
KW  - compliantly actuated robotic legs
KW  - targeted hopping
KW  - data-driven discrete planning
KW  - Legged locomotion
KW  - Planning
KW  - Springs
KW  - Switches
KW  - Hardware
DO  - 10.1109/IROS.2018.8593819
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning for fast locomotion of compliantly actuated robotic legs is generally considered to be a challenging issue, posing considerable real-time problems. This is at least the case if time-continuous trajectories need to be generated online. In this paper we take advantage of a simple controller structure, which reduces the motion planning to a discrete-time planning problem, in which only a small set of input parameters need to be determined for each step. We show that for a planar leg with serial elastic actuation, hopping on a ground with stairs of irregular length and height can be planned online, based on a parameter mapping which has been learned in a data-driven manner by performing hopping trials with an adaptive exploration algorithm to evenly sample the parameter space. Experiments on a planar hopping leg prototype validate the approach.
ER  - 

TY  - CONF
TI  - Quadrupedal walking motion and footstep placement through Linear Model Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2267
EP  - 2273
AU  - A. Laurenzi
AU  - E. M. Hoffman
AU  - N. G. Tsagarakis
PY  - 2018
KW  - convex programming
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - predictive control
KW  - robot dynamics
KW  - linear model predictive control framework
KW  - quadrupedal walking motion
KW  - auxiliary states
KW  - bipedal locomotion
KW  - hybrid wheeled-legged quadruped
KW  - humanoid upper-body
KW  - joint optimization problem
KW  - nonconvex programming framework
KW  - quadrupedal robot
KW  - automatic footstep placement
KW  - walking gait
KW  - CENTAURO robot
KW  - control inputs
KW  - linear constraints
KW  - approximate QP
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Optimization
KW  - Stability analysis
KW  - Planning
DO  - 10.1109/IROS.2018.8593692
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The present work addresses the generation of a walking gait with automatic footstep placement for a quadrupedal robot, within a Linear Model Predictive Control framework. Existing work has shown how this is only possible within a non-convex programming framework, finding a solution of which is well-known to be very hard. We propose a way to formulate the joint optimization problem as an approximate QP with linear constraints, whose global optimum can be quickly found with off-the-shelf solvers. More specifically, this is done by introducing auxiliary states and control inputs, each of which is subject to linear constraints that are inspired from the literature on bipedal locomotion. Finally, we validate our method on the CENTAURO robot, a hybrid wheeled-legged quadruped with a humanoid upper-body.
ER  - 

TY  - CONF
TI  - A Synergetic Voluntary Control for Exoskeleton based on Spinal Cord Mapping of Peripheral Bioelectric Activity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2274
EP  - 2279
AU  - S. Ishikawa
AU  - H. Kadone
AU  - K. Suzuki
PY  - 2018
KW  - bioelectric phenomena
KW  - electromyography
KW  - gait analysis
KW  - injuries
KW  - matrix decomposition
KW  - medical robotics
KW  - neurophysiology
KW  - patient rehabilitation
KW  - synergetic voluntary control
KW  - spinal cord mapping
KW  - peripheral bioelectric activity
KW  - voluntary motion intention
KW  - control method
KW  - exoskeleton robot control
KW  - voluntary lower limb muscle activities
KW  - spinal cord injury
KW  - muscle synergy
KW  - walking motion
KW  - spinal cord map level
KW  - reliable cord levels
KW  - unreliable spinal cord levels
KW  - maximally voluntary locomotion
KW  - whole-body muscle activity
KW  - intended lower limb muscle activity
KW  - spinal cord activity
KW  - walking rehabilitation
KW  - nonnegative matrix factorization
KW  - transformation matrix
KW  - hybrid assistive limb
KW  - walking experiments
KW  - Muscles
KW  - Legged locomotion
KW  - Spinal cord
KW  - Exoskeletons
KW  - Robot kinematics
KW  - Estimation
DO  - 10.1109/IROS.2018.8593695
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Walking rehabilitation must be performed based on voluntary motion intention, and for this purpose, the development of a control method for an exoskeleton robot based on voluntary intention is investigated. This study proposes a method of exoskeleton robot control to estimate the voluntary lower limb muscle activities lost after a spinal cord injury (SCI). This method is based on the spinal cord mapping of the remaining muscle activities and its matching to the one obtained from healthy participants considering the muscle synergy of the whole body during the walking motion. By implementing the matching procedure at the spinal cord map level and incorporating information of reliable and unreliable spinal cord levels based on a diagnosis, the method has the potential to provide a maximally voluntary locomotion for people with SCI. We report an analysis of the synergy of the whole-body muscle activity during walking and its spinal cord mapping using non-negative matrix factorization and the computation of the transformation matrix to estimate the intended lower limb muscle activity from the remaining spinal cord activity. The implementation of the proposed method using the right leg of the hybrid assistive limb and walking experiments with a healthy participant are also reported.
ER  - 

TY  - CONF
TI  - Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton with Hemiplegia Patients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2280
EP  - 2285
AU  - R. Huang
AU  - Z. Peng
AU  - H. Cheng
AU  - J. Hu
AU  - J. Qiu
AU  - C. Zou
AU  - Q. Chen
PY  - 2018
KW  - adaptive control
KW  - dynamic programming
KW  - gait analysis
KW  - handicapped aids
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - motion control
KW  - multi-agent systems
KW  - patient rehabilitation
KW  - hemiplegia patient
KW  - lower limb exoskeleton
KW  - learning-based walking assistance control strategy
KW  - paraplegia patients
KW  - leader-follower multi-agent system
KW  - LF-MAS
KW  - reinforcement learning framework
KW  - policy iteration adaptive dynamic programming algorithm
KW  - PI-ADP algorithm
KW  - tracking control
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Reinforcement learning
KW  - Control systems
KW  - Heuristic algorithms
KW  - Multi-agent systems
KW  - Cost function
KW  - Walking Assistance Strategy
KW  - Leader-Follower Multi-Agent System
KW  - Reinforcement Learning
KW  - Lower Exoskeleton
KW  - Hemiplegia
DO  - 10.1109/IROS.2018.8594464
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.
ER  - 

TY  - CONF
TI  - Similarity of the Impact of Humanoid and In-Person Communications on Frontal Brain Activity of Older People
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2286
EP  - 2291
AU  - S. Keshmiri
AU  - H. Sumioka
AU  - R. Yamazaki
AU  - M. Okubo
AU  - H. Ishiguro
PY  - 2018
KW  - brain
KW  - geriatrics
KW  - handicapped aids
KW  - humanoid robots
KW  - human-robot interaction
KW  - medical robotics
KW  - older people
KW  - in-person communication
KW  - brain information
KW  - frontal brain activity
KW  - humanoid robot
KW  - video-chat
KW  - speaker
KW  - brain activation
KW  - storytelling experiment
KW  - sensory gateway
KW  - behavioural responses
KW  - human-robot interaction
KW  - Brain
KW  - Humanoid robots
KW  - Time series analysis
KW  - Media
KW  - Senior citizens
KW  - Data acquisition
DO  - 10.1109/IROS.2018.8594521
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We report results of the analyses of the effect of communication through a humanoid robot in comparison with in-person, video-chat, and speaker on frontal brain activity of older people during an storytelling experiment. Our results suggest that whereas communicating through a physically embodied medium potentially induces a significantly higher pattern of brain activation with respect to video-chat and speaker, its difference is non-significant in comparison with in-person communication. These results imply that communicating through a humanoid robot induces a pattern of brain activity in older people that is potentially similar to in-person communication. Our findings benefit researchers and practitioners in rehabilitation and elderly care facilities in search of effective means of communication with their patients to increase their involvement in the incremental steps of their treatments. Moreover, they imply the utility of brain information as a promising sensory gateway in characterization of the behavioural responses in human-robot interaction.
ER  - 

TY  - CONF
TI  - A Phase Variable Approach to Volitional Control of Powered Knee-Ankle Prostheses
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2292
EP  - 2298
AU  - S. Rezazadeh
AU  - D. Quintero
AU  - N. Divekar
AU  - R. D. Gregg
PY  - 2018
KW  - artificial limbs
KW  - finite state machines
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - trajectory control
KW  - volitional control
KW  - powered knee-ankle prostheses
KW  - multijoint prosthetic legs
KW  - periodic walking
KW  - piecewise holonomic phase variable
KW  - finite state machine
KW  - nominal reference gait trajectory
KW  - high-speed walking
KW  - backward walking
KW  - phase variable approach
KW  - volitional leg motions
KW  - Legged locomotion
KW  - Thigh
KW  - Trajectory
KW  - Task analysis
KW  - Prosthetics
KW  - Sensors
KW  - Foot
DO  - 10.1109/IROS.2018.8594023
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Although there has been recent progress in control of multi-joint prosthetic legs for periodic tasks such as walking, volitional control of these systems for non-periodic maneuvers is still an open problem. In this paper, we develop a new controller that is capable of both periodic walking and common volitional leg motions based on a piecewise holonomic phase variable through a finite state machine. The phase variable is constructed by measuring the thigh angle, and the transitions in the finite state machine are formulated through sensing foot contact together with attributes of a nominal reference gait trajectory. The controller was implemented on a powered knee-ankle prosthesis and tested with a transfemoral amputee subject, who successfully performed a wide range of periodic and non-periodic tasks, including low- and high-speed walking, quick start and stop, backward walking, walking over obstacles, and kicking a soccer ball. The proposed approach is expected to provide better understanding of volitional motions and lead to more reliable control of multi-joint prostheses for a wider range of tasks.
ER  - 

TY  - CONF
TI  - Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2299
EP  - 2304
AU  - A. Mancisidor
AU  - A. Zubizarreta
AU  - I. Cabanes
AU  - A. Brull
AU  - A. Rodriguez
AU  - J. H. Jung
PY  - 2018
KW  - biomechanics
KW  - force control
KW  - medical robotics
KW  - patient rehabilitation
KW  - position control
KW  - robotic device interacts
KW  - pre-clinical validation
KW  - upper-limb rehabilitation robotic platform
KW  - UHP multifunctional upper-limb rehabilitation robot
KW  - rehabilitation therapies
KW  - UHP rehabilitation robot
KW  - multifunctional device
KW  - robotized therapies
KW  - advanced position-force control approaches
KW  - Rehabilitation robotics
KW  - Training
KW  - Games
KW  - Software
KW  - Robot sensing systems
KW  - Elbow
DO  - 10.1109/IROS.2018.8593527
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.
ER  - 

TY  - CONF
TI  - Cable Actuated Dexterous (CADEX) Glove for Effective Rehabilitation of the Hand for Patients with Neurological diseases
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2305
EP  - 2310
AU  - D. H. Kim
AU  - H. Park
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - bone
KW  - dexterous manipulators
KW  - diseases
KW  - medical disorders
KW  - medical robotics
KW  - neurophysiology
KW  - patient rehabilitation
KW  - decoupled opposition-reposition
KW  - functional recovery
KW  - CADEX glove
KW  - consistent motion
KW  - actuated cables
KW  - exotendons
KW  - dexterous motion
KW  - carpometacarpal joint
KW  - simple thumb motions
KW  - compact design
KW  - soft robotic devices
KW  - wearable robotic devices
KW  - hands
KW  - larger motor cortical area
KW  - recovery motor function
KW  - motor cortex
KW  - neuroplastic change
KW  - neurological disease
KW  - effective rehabilitation
KW  - cable actuated dexterous glove
KW  - Thumb
KW  - Force
KW  - Routing
KW  - Silicon
KW  - Tendons
KW  - IP networks
DO  - 10.1109/IROS.2018.8594336
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Neuroplastic changes in motor cortex is essential for the recovery motor function of patients with neurological diseases. To enlarge neuroplastic change, various movements should be provided to stimulate larger motor cortical area, and because hands occupy the largest area, it is especially important. Many wearable robotic devices have been developed for rehabilitation of the hand, and soft robotic devices in particular have drawn attention for their compact design. However, most soft devices provide simple thumb motions, which flex or extend all joints without assistance of opposition/reposition of the carpometacarpal joint although the importance in producing various grasps. In this study, the design of a cable actuated dexterous (CADEX) glove is proposed. For dexterous motion, the structure and orientation of major finger tendons were replicated with exotendons (actuated cables), and four exotendons were used for the thumb with the path optimized to provide flexion/extension of the thumb and decoupled opposition/reposition of the carpometacarpal with other joints. To provide consistent motion, silicon was used for stable anchoring of exotendons while preventing slippage and reducing deformation. The motion generated by the CADEX glove was experimentally evaluated for a single healthy subject. The result shows that the CADEX glove could flex and extend the finger with various ratios among joints, and the opposition/reposition of carpometacarpal joint of the thumb could be achieved consistently with minimal effect on the other joints. The CADEX glove is expected to help providing various tasks which is expected to enhance the functional recovery of patients with neurological disease.
ER  - 

TY  - CONF
TI  - Modified Adaptive Control of an Actuated Ankle Foot Orthosis to assist Paretic Patients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2311
EP  - 2317
AU  - V. Arnez-Paniagua
AU  - H. Rifaï
AU  - Y. Amirat
AU  - S. Mohammed
AU  - M. Ghedira
AU  - J. M. Gracies
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - gait analysis
KW  - Lyapunov methods
KW  - medical control systems
KW  - model reference adaptive control systems
KW  - muscle
KW  - orthotics
KW  - stability
KW  - modified adaptive control
KW  - actuated ankle foot orthosis
KW  - saturated proportional derivative action
KW  - active ankle foot orthosis
KW  - classical model-based controllers
KW  - prior estimation
KW  - AAFO system
KW  - residual human torque
KW  - ankle joint
KW  - ankle reference trajectory
KW  - AAFO-wearer system
KW  - bounded human muscular torque
KW  - model reference adaptive control
KW  - AAFO actuator
KW  - paretic patient gait
KW  - self-selected walking speed
KW  - Lyapunov analysis
KW  - closed-loop
KW  - gait cycle
KW  - input-to-state stability
KW  - Torque
KW  - Foot
KW  - Legged locomotion
KW  - Lyapunov methods
KW  - Adaptation models
KW  - Trajectory
KW  - Muscles
DO  - 10.1109/IROS.2018.8594046
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a model reference adaptive control with saturated proportional derivative (PD) action for an active ankle foot orthosis (AAFO) to assist the gait of paretic patients, is studied. Unlike most classical model-based controllers, the proposed controller does not require any prior estimation of the system's model parameters. The AAFO system is actively driven by the residual human torque delivered by muscles spanning the ankle joint and the AAFO's actuator's torque. The ankle reference trajectory is updated online based on the self-selected walking speed of the wearer. The input-to-state stability of the AAFO-wearer system with respect to a bounded human muscular torque is proved in closed-loop based on a Lyapunov analysis. Experimental results, obtained from one healthy subject and one paretic patient, show satisfactory results in terms of tracking performance and ankle joint assistance throughout the full gait cycle.
ER  - 

TY  - CONF
TI  - SMA based wrist exoskeleton for rehabilitation therapy*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2318
EP  - 2323
AU  - D. Serrano
AU  - D. Copaci
AU  - L. Moreno
AU  - D. Blanco
PY  - 2018
KW  - biomechanics
KW  - electroactive polymer actuators
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - shape memory effects
KW  - wearable robots
KW  - SMA based wrist exoskeleton
KW  - rehabilitation therapy
KW  - rehabilitation wearable exoskeleton
KW  - wrist joint
KW  - flexion-extension
KW  - adduction-abduction
KW  - Shape Memory Alloy based actuators
KW  - SMA actuator technology
KW  - rehabilitation robotic devices
KW  - Wrist
KW  - Actuators
KW  - Exoskeletons
KW  - Wires
KW  - Medical treatment
KW  - Robots
KW  - Biological system modeling
DO  - 10.1109/IROS.2018.8593987
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a rehabilitation wearable exoskeleton for wrist joint with two degrees of freedom (DOF), flexion-extension and adduction-abduction (radial and ulnar deviation), actuated with Shape Memory Alloy (SMA) based actuators. Thanks to this type of actuators, the proposed device presents a very light weight and noiseless operation, in comparison with similar devices. The preliminary results obtained over real tests with the wrist exoskeleton are presented. This prototype demonstrates that SMA actuator technology is a viable alternative when investigating possible improvement of rehabilitation robotic devices in terms of weight, size and cost.
ER  - 

TY  - CONF
TI  - Utility Model Re-description within a Motivational System for Cognitive Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2324
EP  - 2329
AU  - A. Romero
AU  - F. Bellas
AU  - A. Prieto
AU  - R. J. Duro
PY  - 2018
KW  - cognition
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - motivational system
KW  - cognitive architecture
KW  - interaction traces
KW  - robotic setup
KW  - cognitive robotics
KW  - value functions
KW  - redescriptive approach
KW  - utility model redescription
KW  - precise utility models
KW  - MotivEn model
KW  - robot coordination
KW  - Robot sensing systems
KW  - Cognitive systems
KW  - Robot kinematics
KW  - Space exploration
KW  - Instruments
KW  - Drives
DO  - 10.1109/IROS.2018.8593799
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.
ER  - 


TY  - CONF
TI  - A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2330
EP  - 2335
AU  - G. I. Parisi
AU  - P. Barros
AU  - D. Fu
AU  - S. Magg
AU  - H. Wu
AU  - X. Liu
AU  - S. Wermter
PY  - 2018
KW  - audio signal processing
KW  - audio-visual systems
KW  - avatars
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - motion control
KW  - crossmodal conflict resolution
KW  - robot sensorimotor coupling
KW  - swift behaviour
KW  - robust behaviour
KW  - neurorobotic experiment
KW  - iCub robot exhibits
KW  - complex crossmodal environment
KW  - multisensory conflicts
KW  - behavioural study
KW  - audio-visual cues
KW  - visual bias
KW  - discrete behavioural response
KW  - complex environments
KW  - incongruent dynamic audio-visual cues
KW  - human-like responses
KW  - environmental statistics
KW  - stereophonic sound processing
KW  - facial features
KW  - body motion
KW  - deep learning model
KW  - animated avatars
KW  - Avatars
KW  - Visualization
KW  - Robot sensing systems
KW  - Lips
KW  - Task analysis
KW  - Spatial resolution
DO  - 10.1109/IROS.2018.8594036
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.
ER  - 

TY  - CONF
TI  - Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2336
EP  - 2341
AU  - J. Cartucho
AU  - R. Ventura
AU  - M. Veloso
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - service robots
KW  - robust object recognition
KW  - symbiotic deep learning
KW  - mobile service robot
KW  - human environments
KW  - symbiotic autonomy approach
KW  - HHELP
KW  - RGB camera
KW  - onboard tablet
KW  - object detection
KW  - deep neural network
KW  - domestic environment
KW  - YOLOv2 neural network
KW  - bootstrap YOLOv2
KW  - CMU
KW  - Monarch Mbot
KW  - ISR-Lisbon
KW  - Neural networks
KW  - Labeling
KW  - Training
KW  - Symbiosis
KW  - Service robots
KW  - Object recognition
DO  - 10.1109/IROS.2018.8594067
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.
ER  - 

TY  - CONF
TI  - People as Sensors: Imputing Maps from Human Actions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2342
EP  - 2348
AU  - O. Afolabi
AU  - K. Driggs–Campbell
AU  - R. Dong
AU  - M. J. Kochenderfer
AU  - S. S. Sastry
PY  - 2018
KW  - collision avoidance
KW  - driver information systems
KW  - mobile robots
KW  - pedestrians
KW  - road vehicles
KW  - human actions
KW  - autonomous vehicles
KW  - pedestrian detection
KW  - collision avoidance
KW  - map estimation
KW  - human driving experiments
KW  - landmark-based mapping approaches
KW  - agents actions
KW  - Random variables
KW  - Estimation
KW  - Automobiles
KW  - Computational modeling
KW  - Intelligent sensors
DO  - 10.1109/IROS.2018.8594511
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite growing attention in autonomy, there are still many open problems, including how autonomous vehicles will interact and communicate with other agents, such as human drivers and pedestrians. Unlike most approaches that focus on pedestrian detection and planning for collision avoidance, this paper considers modeling the interaction between human drivers and pedestrians and how it might influence map estimation, as a proxy for detection. We take a mapping inspired approach and incorporate people as sensors into mapping frameworks. By taking advantage of other agents' actions, we demonstrate how we can impute portions of the map that would otherwise be occluded. We evaluate our framework in human driving experiments and on real-world data, using occupancy grids and landmark-based mapping approaches. Our approach significantly improves overall environment awareness and outperforms standard mapping techniques.
ER  - 

TY  - CONF
TI  - How do humans read robotics? The matter of the lexical ambiguity resolution
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2349
EP  - 2354
AU  - C. Pieters
AU  - E. Danblon
AU  - J. P. Laumond
AU  - L. ULB
PY  - 2018
KW  - human-robot interaction
KW  - robotic actions
KW  - lexical ambiguity resolution
KW  - Robots
KW  - Linguistics
KW  - Rhetoric
KW  - Semantics
KW  - Task analysis
KW  - Psychology
DO  - 10.1109/IROS.2018.8594138
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The words used to describe robotic performances include a degree of ambiguity that the human brain should solve without difficulty. However, the language used in-and about-robotics seems to escape from the ordinary processing of lexical ambiguity resolution. In this paper, we argue that there is no lack of an adequate language for robotics but that the lexicon at hand is forced by our representations. We investigate the main representational issues of the notions that express robotic actions and dispositions (i.e. behaviors).
ER  - 

TY  - CONF
TI  - Free-View, 3D Gaze-Guided, Assistive Robotic System for Activities of Daily Living
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2355
EP  - 2361
AU  - M. Wang
AU  - A. A. Kogkas
AU  - A. Darzi
AU  - G. P. Mylonas
PY  - 2018
KW  - assisted living
KW  - end effectors
KW  - gaze tracking
KW  - medical robotics
KW  - object recognition
KW  - trajectory control
KW  - user interfaces
KW  - gaze control
KW  - assistive robotic system
KW  - daily living
KW  - free-view gaze interface
KW  - object recognition
KW  - trajectory planning
KW  - quadriplegia patient
KW  - end-effector position
KW  - Three-dimensional displays
KW  - Cameras
KW  - Task analysis
KW  - Robot kinematics
KW  - Object recognition
KW  - Planning
DO  - 10.1109/IROS.2018.8594045
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Patients suffering from quadriplegia have limited body motion which prevents them from performing daily activities. We have developed an assistive robotic system with an intuitive free-view gaze interface. The user's point of regard is estimated in 3D space while allowing free head movement and is combined with object recognition and trajectory planning. This framework allows the user to interact with objects using fixations. Two operational modes have been implemented to cater for different eventualities. The automatic mode performs a pre-defined task associated with a gaze-selected object, while the manual mode allows gaze control of the robot's end-effector position on the user's frame of reference. User studies reported effortless operation in automatic mode. A manual pick and place task achieved a success rate of 100% on the users' first attempt.
ER  - 

TY  - CONF
TI  - The Future of Legal and Ethical Regulations for Autonomous Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2362
EP  - 2366
AU  - H. Xu
AU  - J. E. Borson
PY  - 2018
KW  - consumer electronics
KW  - mobile robots
KW  - autonomous robotics
KW  - autonomous systems
KW  - novel autonomy framework
KW  - device safety
KW  - regulatory frameworks
KW  - specific framework those devices
KW  - future autonomy regulations
KW  - consumer electronics vis-á-vis medical devices
KW  - regulatory landscape
KW  - autonomous elements
KW  - future regulation
KW  - Autonomous systems
KW  - Robots
KW  - Law
KW  - Standards
KW  - Ethics
KW  - Complex systems
DO  - 10.1109/IROS.2018.8593915
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - “Autonomous robotics” promise significant improvements across a host of different complex systems, which will need to be managed within regulatory frameworks to promote, at a minimum, device safety. Contrary to how they are often portrayed, however, these systems do not necessarily require fundamentally new approaches to engineering or regulatory challenges, i.e., the development of a novel “autonomy framework” applicable to different types of devices. Rather, because autonomous systems generally represent a progressive improvement of existing complex systems, preexisting regulatory scheme offer the best guidance for considering future regulation of autonomous elements. Moreover, the regulatory landscape differs considerably based on the type of device at issue (e.g., consumer electronics vis-á-vis medical devices). This paper argues that users and regulators must consider future autonomy regulations within the specific framework those devices currently inhabit, rather than focusing on a novel set of rules divorced from the preexisting context.
ER  - 

TY  - CONF
TI  - Uncertainty-based Online Mapping and Motion Planning for Marine Robotics Guidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2367
EP  - 2374
AU  - È. Pairet
AU  - J. D. Hernández
AU  - M. Lahijanian
AU  - M. Carreras
PY  - 2018
KW  - autonomous underwater vehicles
KW  - path planning
KW  - probability
KW  - robot dynamics
KW  - vehicle dynamics
KW  - uncertainty-based framework
KW  - online computation constraints
KW  - motion planning
KW  - marine robotics guidance
KW  - robotic systems
KW  - safe path
KW  - underwater environments
KW  - autonomous vehicles
KW  - probabilistic safety
KW  - online mapping
KW  - Uncertainty
KW  - Safety
KW  - Planning
KW  - Probabilistic logic
KW  - Robot sensing systems
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8593394
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In real-world robotics, motion planning remains to be an open challenge. Not only robotic systems are required to move through unexplored environments, but also their manoeuvrability is constrained by their dynamics and often suffer from uncertainty. One approach to overcome this problem is to incrementally map the surroundings while, simultaneously, planning a safe and feasible path to a desired goal. This is especially critical in underwater environments, where autonomous vehicles must deal with both motion and environment uncertainties. In order to cope with these constraints, this work proposes an uncertainty-based framework for mapping and planning3 feasible motions online with probabilistic safety-guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by (i) incrementally representing the environment as a collection of local maps, and (ii) iteratively (re)planning kinodynamically-feasible and probabilistically-safe paths to goal. The proposed framework is evaluated on the Sparus II, a nonholonomic torpedo-shaped AUV, by conducting simulated and real-world trials, thus proving the efficacy of the method and its suitability even for systems with limited on-board computational power.
ER  - 

TY  - CONF
TI  - Heterogeneous Vehicles Routing for Water Canal Damage Assessment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2375
EP  - 2382
AU  - D. Deng
AU  - P. Palli
AU  - F. Shu
AU  - K. Shimada
AU  - T. Pang
PY  - 2018
KW  - autonomous aerial vehicles
KW  - canals
KW  - graph theory
KW  - inspection
KW  - integer programming
KW  - irrigation
KW  - path planning
KW  - quadratic programming
KW  - vehicle routing
KW  - water canal damage assessment
KW  - irrigation water canals
KW  - manual inspection
KW  - shortened inspection time
KW  - reduced labor cost
KW  - automated inspection
KW  - road networks
KW  - path planning
KW  - UAV
KW  - unmanned aerial vehicles
KW  - ground vehicles
KW  - integer quadratic program
KW  - IQP
KW  - heterogeneous vehicle routing
KW  - Irrigation
KW  - Automobiles
KW  - Inspection
KW  - Roads
KW  - Planning
KW  - Batteries
KW  - Routing
DO  - 10.1109/IROS.2018.8593365
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In Japan, inspection of irrigation water canals has been mostly conducted manually. However, the huge demand for more regular inspections as infrastructure ages, coupled with the limited time window available for inspection, has rendered manual inspection increasingly insufficient. With shortened inspection time and reduced labor cost, automated inspection using a combination of unmanned aerial vehicles (UAVs) and ground vehicles (cars) has emerged as an attractive alternative to manual inspection. In this paper, we propose a path planning framework that generates optimal plans for UAVs and cars to inspect water canals in a large agricultural area (tens of square kilometers). In addition to optimality, the paths need to satisfy several constraints, in order to guarantee UAV navigation safety and to abide by local traffic regulations. In the proposed framework, the canal and road networks are first modeled as two graphs, which are then partitioned into smaller subgraphs that can be covered by a given fleet of UAVs within one battery charge. The problem of finding optimal paths for both UAVs and cars on the graphs, subject to the constraints, is formulated as a integer quadratic program (IQP). The proposed framework can also quickly generate new plans when a current plan is interrupted. The effectiveness of the proposed framework is validated by simulation results showing the successful generation of plans covering all given canal segments, and the ability to quickly revise the plan when conditions change.
ER  - 

TY  - CONF
TI  - Passive acoustic tracking for behavior mode classification between surface and underwater vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2383
EP  - 2388
AU  - E. M. Fischell
AU  - O. Viquez
AU  - H. Schmidt
PY  - 2018
KW  - autonomous underwater vehicles
KW  - hydrophones
KW  - mobile robots
KW  - acoustic modems
KW  - vehicle state
KW  - communication line
KW  - submerged vehicles
KW  - hydrophone arrays
KW  - AUV mode estimates
KW  - dynamic time
KW  - simulation data
KW  - simulation-based classifier
KW  - bearing tracking data
KW  - passive tracking
KW  - TTI data
KW  - field array data
KW  - experiment data
KW  - surface vessels
KW  - AUV behavior
KW  - passive acoustic tracking
KW  - behavior mode classification
KW  - autonomous underwater vehicles
KW  - speed-of-light communication
KW  - AUV platforms
KW  - surface vehicle behavior
KW  - K-nearest-neighbor
KW  - Boats
KW  - Acoustics
KW  - Sea surface
KW  - Trajectory
KW  - Arrays
KW  - Data models
KW  - Sonar equipment
DO  - 10.1109/IROS.2018.8593981
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous underwater vehicles (AUVs) pose significant communication challenges: vehicles are submerged for periods of time in which speed-of-light communication is impossible. This is a particular problem on low-cost AUV platforms, on which acoustic modems are not available to get vehicle state or provide re-deploy commands. We investigate one possible method of providing operators with a communication line to these vehicles by using noise underwater to both classify behavior of submerged vehicles and to command them. In this scheme, processing of data from hydrophone arrays provide operators with AUV mode estimates and AUVs with surface vehicle behavior updates. Simulation studies were used to characterize trajectories for simple transect versus loiter behaviors based on the bearing and time to intercept (TTI). A classifier based on K-nearest-neighbor with dynamic time warping as a distance metric was used to classify simulation data. The simulation-based classifier was then applied to classify bearing tracking data from passive tracking of a loitering AUV and bearing and TTI data from passive tracking of a transecting boat based on field array data. Experiment data was classified with 76 % accuracy using bearing-only data, 96% accuracy for TTI -only data and 99 % accuracy for combined classification. The techniques developed here could be used for AUV cuing by surface vessels and monitoring of AUV behavior.
ER  - 

TY  - CONF
TI  - A Rationale-Driven Team Plan Representation for Autonomous Intra-Robot Replanning*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2389
EP  - 2394
AU  - P. Cooksey
AU  - M. Veloso
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - rationale-driven team plan representation
KW  - autonomous multirobot teams
KW  - autonomous intrarobot replanning
KW  - team planner
KW  - intrarobot replanning algorithm
KW  - Robots
KW  - Oceans
KW  - Task analysis
KW  - Prediction algorithms
KW  - Planning
KW  - Satellites
KW  - Global Positioning System
DO  - 10.1109/IROS.2018.8593765
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.
ER  - 

TY  - CONF
TI  - Stochastic Optimization for Autonomous Vehicles with Limited Control Authority
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2395
EP  - 2401
AU  - D. Jones
AU  - G. A. Hollinger
AU  - M. J. Kuhlman
AU  - D. A. Sofge
AU  - S. K. Gupta
PY  - 2018
KW  - gradient methods
KW  - greedy algorithms
KW  - mobile robots
KW  - optimisation
KW  - state-space methods
KW  - stochastic processes
KW  - SGA
KW  - multivehicle information gathering
KW  - action space representation
KW  - stochastic optimization scheme
KW  - perturbed action sequences
KW  - state space information function
KW  - sequential greedy allocation
KW  - autonomous vehicles
KW  - stochastic gradient ascent algorithm
KW  - vehicle control authority
KW  - navy coastal ocean model
KW  - NCOM
KW  - Gulf of Mexico
KW  - GoM
KW  - Monte Carlo tree search method
KW  - MCTS
KW  - Oceans
KW  - Optimization
KW  - Stochastic processes
KW  - Approximation algorithms
KW  - Trajectory
KW  - Aerospace electronics
KW  - Robots
DO  - 10.1109/IROS.2018.8594020
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we present a Stochastic Gradient Ascent (SGA) algorithm for multi-vehicle information gathering that accounts for limitations on a vehicle's control authority caused by external forces. By representing vehicle paths using a novel action space representation, rather than a state space representation, we remove the need to perform feasibility calculations on the vehicle's path. Our algorithm uses a stochastic optimization scheme by sampling perturbed action sequences around the current best known sequence to estimate the gradient of a state space information function with respect to the action sequence. Additionally, we use sequential greedy allocation to plan for multiple vehicles. Results are shown using a Navy Coastal Ocean Model (NCOM) for the Gulf of Mexico (GoM). SGA shows improvement in the amount of information gained over a greedy baseline. Additionally, we compare to Monte Carlo Tree Search (MCTS) Method, which is able to gather competitive amounts of information but is more computationally intensive than our approach.
ER  - 

TY  - CONF
TI  - Proactive Collision Avoidance for ASVs using A Dynamic Reciprocal Velocity Obstacles Method
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2402
EP  - 2409
AU  - D. K. M. Kufoalor
AU  - E. F. Brekke
AU  - T. A. Johansen
PY  - 2018
KW  - collision avoidance
KW  - marine vehicles
KW  - mobile robots
KW  - velocity control
KW  - reciprocal velocity obstacles framework
KW  - dynamic obstacles
KW  - collision avoidance decisions
KW  - international regulations
KW  - autonomous surface vessel
KW  - future behavior
KW  - interactive behavior
KW  - collision avoidance method
KW  - dynamic reciprocal velocity obstacles method
KW  - proactive collision avoidance
KW  - COLREGs
KW  - ASV behavior
KW  - complex dynamic models
KW  - RVO framework
KW  - predictive approach
KW  - Collision avoidance
KW  - Decision making
KW  - Propulsion
KW  - Uncertainty
KW  - Sensor systems
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594382
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a collision avoidance method that incorporates the interactive behavior of agents and is proactive in dealing with the uncertainty of the future behavior of obstacles. The proposed method considers interactions that will be experienced by an autonomous surface vessel (ASV) in an environment governed by the international regulations for preventing collisions at sea (COLREGs). Our approach aims at encouraging dynamic obstacles to cooperate according to COLREGs. Therefore, we propose a strategy for assessing the cooperative behavior of obstacles, and the result of the assessment is used to adapt collision avoidance decisions within the Reciprocal Velocity Obstacles (RVO) framework. Moreover, we propose a predictive approach to solving known limitations of the RVO framework, and we present computationally feasible extensions that enable the use of complex dynamic models and objectives suitable for ASVs. We demonstrate the performance and potentials of our method through a simulation study, and the results show that the proposed method leads to proactive and more predictable ASV behavior compared with both Velocity Obstacles (VO) and RVO, especially when obstacles cooperate by following COLREGs.
ER  - 

TY  - CONF
TI  - A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2410
EP  - 2417
AU  - A. Peñalver
AU  - J. J. Fernández
AU  - A. Soriano
AU  - P. J. Sanz
PY  - 2018
KW  - redundant manipulators
KW  - multiple kinematic chains
KW  - hard joint
KW  - reverse priority framework
KW  - kinematic control
KW  - redundant robots
KW  - reverse priority method
KW  - robotic systems
KW  - bilateral constraints
KW  - unilateral constraints
KW  - multitask priority framework
KW  - joint priorities
KW  - Cartesian constraints
KW  - Task analysis
KW  - Kinematics
KW  - Jacobian matrices
KW  - Redundancy
KW  - End effectors
DO  - 10.1109/IROS.2018.8593967
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.
ER  - 

TY  - CONF
TI  - Vision-based Target Tracking for a Skid-steer Vehicle using Guided Policy Search with Field-of-view Constraint
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2418
EP  - 2425
AU  - T. Kim
AU  - C. Lee
AU  - H. Seo
AU  - S. Choi
AU  - W. Kim
AU  - H. J. Kim
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - remotely operated vehicles
KW  - robot dynamics
KW  - robot kinematics
KW  - robot vision
KW  - search problems
KW  - steering systems
KW  - target tracking
KW  - skid-steer vehicle
KW  - guided policy search
KW  - skid-type robot
KW  - local policy optimization
KW  - FOV constraint
KW  - vision-based tracking policy
KW  - skid-steer mobile robot
KW  - field-of-view constraint
KW  - vision-based target tracking method
KW  - end-to-end policy
KW  - pixel image data
KW  - deep reinforcement learning
KW  - kinematic slip model
KW  - Mobile robots
KW  - Training
KW  - Kinematics
KW  - Cameras
KW  - Target tracking
KW  - Wheels
DO  - 10.1109/IROS.2018.8593843
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a vision-based target tracking method for a skid-steer vehicle. With the development of deep reinforcement learning, many researchers have tried to generate an end-to-end policy to control the mobile robot from a raw pixel image data. However, the action in most research only concerns high-level decisions such as go straight, turn left and right. High-level decisions alone are not sufficient to precisely control platforms such as a skid-steer vehicle due to the lack of steering mechanism. Thus, unlike existing work, we aim to control the motor command for the wheels directly. To this end, we employ guided policy search (GPS) based on the general kinematic slip model for the skid-type robot. Furthermore, to prohibit the target from getting out of the camera field of view (FOV) in the training phase, we update local policy optimization with a FOV constraint and perform a pre-training to make the initial policy more efficient. Our method allows the skid-type robot to automatically acquire the vision-based tracking policy while local policies satisfy the FOV constraint during the training phase. We evaluate our method through both simulation and experiment with a skid-steer mobile robot. Finally, we test the performance of learned policy with a moving target in a new environment.
ER  - 

TY  - CONF
TI  - On the Kinematics of Wheeled Motion Control of a Hybrid Wheeled-Legged CENTAURO robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2426
EP  - 2433
AU  - M. Kamedula
AU  - N. Kashiri
AU  - N. G. Tsagarakis
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - robot kinematics
KW  - stability
KW  - wheels
KW  - wheeled-legged CENTAURO robot
KW  - real-world terrains
KW  - mobile platforms
KW  - versatile mobility
KW  - first-order inverse kinematics scheme
KW  - wheeled mobility
KW  - legged-wheeled motion kinematics control
KW  - wheels camber angles
KW  - legged-wheeled system stability
KW  - floating base model
KW  - legged-wheeled centaur-like robot
KW  - Legged locomotion
KW  - Wheels
KW  - Kinematics
KW  - Robot kinematics
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594222
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Legged-wheeled robots combine the advantages of efficient wheeled mobility with the adaptability to real-world terrains through the legged locomotion. Due to this hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, their versatile mobility increases the number of constraints in their motion control where both the properties of legged and wheeled systems need to be considered. Relevant schemes for legged-wheeled platforms so far have been developed exploiting separate motion control of the wheeled and legged functionalities. This paper discusses the legged-wheeled motion kinematics without constraining the camber angles of the wheels, and it proposes a first-order inverse kinematics scheme that stabilizes the legged-wheeled system in the wheeled motion. Furthermore, the work adopts a floating base model that allows to easily incorporate the legged motion to the scheme. The developed controller is tested in simulation and experiments on a legged-wheeled centaur-like robot - CENTAURO.
ER  - 

TY  - CONF
TI  - Development of Stone Throwing Robot and High Precision Driving Control for Curling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2434
EP  - 2440
AU  - J. H. Choi
AU  - C. Song
AU  - K. Kim
AU  - S. Oh
PY  - 2018
KW  - artificial intelligence
KW  - control engineering computing
KW  - control system synthesis
KW  - feedforward
KW  - mobile robots
KW  - motion control
KW  - observers
KW  - position control
KW  - three-term control
KW  - velocity control
KW  - wheels
KW  - AI system
KW  - stone throwing robot
KW  - curling sports
KW  - throwing-curling
KW  - artificial intelligence system
KW  - precise driving control
KW  - STR driving
KW  - robust heading angle control
KW  - model-based feedforward control
KW  - conventional PID controller
KW  - anti-slip control
KW  - dimensional drive control
KW  - curling sport
KW  - robot component
KW  - developed robot
KW  - novel mobile robot
KW  - high precision driving Control
KW  - Mobile robots
KW  - Wheels
KW  - Cameras
KW  - Artificial intelligence
KW  - Ice
KW  - Servers
DO  - 10.1109/IROS.2018.8594026
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a novel mobile robot developed to perform Curling sports is introduced. The developed robot is a Stone Throwing Robot (STR) for Curling that can travel on the ice with wheels and throw a stone as well as make curls of the stone. The STR is developed as a robot component of an Artificial Intelligence(AI) system that can autonomously play the curling sport. The proposed STR can throw a stone at any desired speed and in any desired direction, which are determined by the AI system. To achieve this precise driving of the STR and throwing of the stone, two dimensional drive control is developed for the STR, which consists of 1) anti-slip control for high traction, 2) precise velocity control and 3) high accuracy heading angle control. In addition to the conventional PID controller, model-based feedforward control, Model Following Control (MFC) for the anti-slip control of the wheel on the ice and Yaw Moment Observer (YMO) for the robust heading angle control are applied as key technologies for the STR driving. The design configurations of the STR to achieve the detection of its own location and throwing/curling of the stone is proposed in this paper as well as the detail of the precise driving control.
ER  - 

TY  - CONF
TI  - MAP - A Mobile Agile Printer Robot for on-site Construction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2441
EP  - 2448
AU  - J. Sustarevas
AU  - D. Butters
AU  - M. Hammid
AU  - G. Dwyer
AU  - R. Stuart-Smith
AU  - V. M. Pawar
PY  - 2018
KW  - construction
KW  - legged locomotion
KW  - mobile robots
KW  - robot kinematics
KW  - service robots
KW  - three-dimensional printing
KW  - wheels
KW  - outdoors construction site
KW  - 3D printing large structures
KW  - omnidirectional robot capable
KW  - Mobile Agile Printer construction robot
KW  - on-site construction
KW  - concurrent on-site operations
KW  - low 3D printing trajectory deviations
KW  - construction robots
KW  - mobile platform
KW  - high-DoF 3D printing system
KW  - MAP
KW  - Three-dimensional printing
KW  - Wheels
KW  - Legged locomotion
KW  - Printers
DO  - 10.1109/IROS.2018.8593815
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a Mobile Agile Printer (MAP) construction robot; a highly agile, 4-legged, omnidirectional robot capable of 3D printing large structures. To overcome dynamic challenges when operating within an outdoors construction site, MAP incorporates a high-DoF 3D printing system connected to a mobile platform with novel features designed to enable disturbance rejection and live adaption to the robot's pose. In doing so, we demonstrate the benefits of designing construction robots with a focus on agility, a compact working volume and ability to operate within a potentially unlimited workspace. Performance tests were conducted showing smooth omni-directional motion as a key requirement for maintaining low 3D printing trajectory deviations over a large volume. In doing so, we show that MAP has the ability to construct in new ways more sensitive to its environment, context and concurrent on-site operations.
ER  - 

TY  - CONF
TI  - Slip Modeling and Estimation for a Planetary Exploration Rover: Experimental Results from Mt. Etna
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2449
EP  - 2456
AU  - K. Bussmann
AU  - L. Meyer
AU  - F. Steidle
AU  - A. Wedler
PY  - 2018
KW  - aerospace robotics
KW  - mobile robots
KW  - planetary rovers
KW  - position control
KW  - wheels
KW  - wheel-soil interaction properties
KW  - inherent errors
KW  - wheel slippage
KW  - parameter-based approach
KW  - whole-body slip modeling
KW  - lightweight rover system
KW  - slip parameter calibration
KW  - system-specific implementation
KW  - experimental results
KW  - Mt. Etna
KW  - resulting wheel odometry measurements
KW  - space exploration scenario
KW  - planetary exploration rover
KW  - wheeled mobile systems
KW  - planetary rovers
KW  - planetary exploration missions
KW  - Wheels
KW  - Jacobian matrices
KW  - Trajectory
KW  - Current measurement
KW  - Extraterrestrial measurements
KW  - Soil
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594294
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For wheeled mobile systems, the wheel odometry is an important source of information about the current motion of the vehicle. It is used e.g. in the context of pose estimation and self-localization of planetary rovers, which is a crucial part of the success of planetary exploration missions. Depending on the wheel-soil interaction properties, wheel odometry measurements are subject to inherent errors such as wheel slippage. In this paper, a parameter-based approach for whole-body slip modeling and calibration is applied to a four-wheeled lightweight rover system. Details on the method for slip parameter calibration as well as the system-specific implementation are given. Experimental results from a test campaign on Mt. Etna are presented, showing significant improvements of the resulting wheel odometry measurements. The results are validated during a long range drive of approx. 900 m and discussed w. r. t. the advantages but also limitations of the method within a space exploration scenario.
ER  - 

TY  - CONF
TI  - User-specific Gaussian Process Model of Wheelchair Drivers with a Haptic Joystick Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2457
EP  - 2463
AU  - A. Hünternann
AU  - E. Demeester
AU  - E. V. Poorten
PY  - 2018
KW  - Gaussian processes
KW  - handicapped aids
KW  - haptic interfaces
KW  - human-robot interaction
KW  - interactive devices
KW  - man-machine systems
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - user modelling
KW  - wheelchairs
KW  - Gaussian process
KW  - spastic wheelchair user
KW  - navigation assistance frequency
KW  - achievable user model evaluation frequency
KW  - haptic joysticks
KW  - probabilistic user-specific driver model
KW  - mental navigation plan
KW  - particular user
KW  - personalised driver model
KW  - navigation plans
KW  - probabilistic framework
KW  - navigation task
KW  - inherent uncertainty
KW  - heterogeneous driving styles
KW  - mobile robot
KW  - intuitive control
KW  - driving semiautonomous
KW  - collaborative human-robot navigation
KW  - haptic joystick interface
KW  - wheelchair drivers
KW  - user-specific Gaussian process model
KW  - Wheelchairs
KW  - Navigation
KW  - Mobile robots
KW  - Probabilistic logic
KW  - Gaussian processes
KW  - Hidden Markov models
DO  - 10.1109/IROS.2018.8593931
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In collaborative human-robot navigation such as when driving semi-autonomous robotic wheelchairs, intuitive control of the mobile robot is only possible if the robot understands its user. This becomes especially important as users present varying levels of abilities and heterogeneous driving styles. Furthermore, the robot needs to consider the inherent uncertainty on its navigation task because the user may not be able to communicate his or her plans explicitly. In order to address these requirements, we have adopted a probabilistic framework to recognise navigation plans. A key component in this framework is a personalised driver model, which captures how a particular user transforms his or her mental navigation plan into inputs to the robot. In this work, we evaluate the use of Gaussian Processes to implement and calibrate this probabilistic, user-specific driver model, and this for use with haptic joysticks. Furthermore, special care was taken to obtain fast online evaluation of this user model through sparse approximation and parallel computation on a GPU. This resulted in an achievable user model evaluation frequency of 40 Hz, which is far above the navigation assistance frequency we aimed for, i.e. 5 Hz. We illustrate the validity of the approach by recognising the navigation plans of a spastic wheelchair user.
ER  - 

TY  - CONF
TI  - A minimalist Stair Climbing Robot (SCR) formed as a leg balancing & climbing Mobile Inverted Pendulum (MIP)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2464
EP  - 2469
AU  - D. Yang
AU  - T. Bewley
PY  - 2018
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - pendulums
KW  - robot kinematics
KW  - service robots
KW  - stability
KW  - wheels
KW  - SCR
KW  - leg balancing
KW  - patent-pending
KW  - minimal-complexity Stair Climbing Robot
KW  - vehicle design
KW  - stairs
KW  - leveraging feedback control
KW  - foot
KW  - MIP drive wheels
KW  - reaction wheels
KW  - stair-climbing throwbot
KW  - mobile inverted pendulum
KW  - left-right stability
KW  - fore-aft stabilization
KW  - chassis-wheel assembly
KW  - minimalist stair climbing robot
KW  - Wheels
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Gears
KW  - Torque
DO  - 10.1109/IROS.2018.8593988
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a (patent-pending) small, quasi-static, minimal-complexity Stair Climbing Robot (SCR). The vehicle design is given simply by adding a third motor to a (Segway-like) Mobile Inverted Pendulum (MIP), enabling it to maneuver up stairs, leveraging feedback control, by planting it's “foot” onto the ground in front of the next step, lifting the chassis/wheel assembly up it's own “leg”, leaning over onto the top of the next step, self uprighting, and repeating for the following step(s). Fore/aft stabilization during leg balancing is given by using the MIP drive wheels as reaction wheels, while left/right stability is given by the width of the foot itself. The design is small and simple enough to potentially be ruggedized as a stair-climbing throwbot, akin to the Recon Scout (but able to climb up stairs) for reconnaissance in military and homeland security applications.
ER  - 

TY  - CONF
TI  - Tire Force Estimation of Dynamic Wheeled Mobile Robots using Tire-Model Based Constrained Kalman Filtering
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2470
EP  - 2477
AU  - S. Jeon
AU  - R. Chung
AU  - D. Lee
PY  - 2018
KW  - automobiles
KW  - feedback
KW  - friction
KW  - gears
KW  - Kalman filters
KW  - mobile robots
KW  - robot dynamics
KW  - tyres
KW  - wheels
KW  - wheel encoders
KW  - tire-road interaction
KW  - estimation algorithm
KW  - three-dimensional individual tire forces
KW  - dynamic wheeled mobile robots
KW  - tire-model based constrained Kalman filtering
KW  - tire force real-time estimation
KW  - tire force estimation techniques
KW  - car-like rearwheel-driven four wheel wheeled mobile robots
KW  - onboard navigation sensors
KW  - feedback
KW  - tire-road friction coefficient
KW  - torque inputs
KW  - differential gear
KW  - CarSim
KW  - Tires
KW  - Wheels
KW  - Force
KW  - Estimation
KW  - Dynamics
KW  - Sensors
KW  - Friction
DO  - 10.1109/IROS.2018.8593708
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel real-time algorithm to estimate the full three-dimensional individual tire forces (i.e., vertical, longitudinal as well as lateral) of a car-like rearwheel-driven four wheel wheeled mobile robots equipped with onboard navigation sensors and wheel encoders. The key enabling idea for this is to utilize the tire model (i.e., the magic formula) in a feedback manner on the framework of the constrained Kalman filtering to render the tire force estimation: 1) more accurate as compared to the typical tire force estimation techniques neglecting the tire-road interaction; and 2) more robust as compared to the results adopting the tire model, yet, only in an open-loop manner. Our proposed algorithm, while performing this full tire force onboard/real-time estimation, also provides the estimation of: 1) tire-road friction coefficient; and 2) torque inputs of the rear left and right wheels, which are connected via differential gear. Simulations with CarSim and outdoor experiments are performed to validate the proposed estimation algorithm.
ER  - 

TY  - CONF
TI  - Online Spatial Sound Perception Using Microphone Array on Mobile Robot*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2478
EP  - 2484
AU  - Y. Sasaki
AU  - R. Tanabe
AU  - H. Takernura
PY  - 2018
KW  - acoustic generators
KW  - acoustic signal detection
KW  - acoustic signal processing
KW  - convolutional neural nets
KW  - microphone arrays
KW  - mobile robots
KW  - probability
KW  - probabilistic regions
KW  - sound sources
KW  - microphone array
KW  - autonomous mobile robot
KW  - three-dimensional position localization
KW  - sound signals detection
KW  - online spatial sound perception system
KW  - convolutional neural network
KW  - CNN
KW  - three-dimensional position recognition
KW  - sound positions estimation
KW  - Mobile robots
KW  - Robot sensing systems
KW  - Microphone arrays
KW  - Estimation
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593777
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper proposes a spatial sound perception system for an autonomous mobile robot. The system performs three-dimensional position localization and recognition as online processing from a robot in motion. For online processing, the sound positions are estimated as probabilistic regions in three dimensional space, because the robot could observe only arrival direction of the sound at a moment. The detected sound signals are recognized using Convolutional Neural Network (CNN), for the adjustment to short input signals. The experimental results show our mobile robot could observe surrounding sound sources online and continuously update its position and sound label.
ER  - 

TY  - CONF
TI  - Extracting the Relationship between the Spatial Distribution and Types of Bird Vocalizations Using Robot Audition System HARK
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2485
EP  - 2490
AU  - S. Sumitani
AU  - R. Suzuki
AU  - S. Matsubayashi
AU  - T. Arita
AU  - K. Nakadai
AU  - H. G. Okuno
PY  - 2018
KW  - acoustic signal processing
KW  - biocommunications
KW  - microphone arrays
KW  - robots
KW  - zoology
KW  - HARK robot audition system
KW  - song-behavior relationships
KW  - HARKBird
KW  - wild birds
KW  - 2D localize vocalizations
KW  - vocalizations characteristics
KW  - microphone arrays
KW  - portable observation system
KW  - wild bird vocalizations
KW  - ecological functions
KW  - spatial distribution
KW  - Birds
KW  - Microphone arrays
KW  - Two dimensional displays
KW  - Robots
KW  - Real-time systems
KW  - Arrays
DO  - 10.1109/IROS.2018.8594130
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For a deeper understanding of ecological functions and semantics of wild bird vocalizations (i.e., songs and calls), it is important to clarify the fine-scaled and detailed relationships among their characteristics of vocalizations and their behavioral contexts. However, it takes a lot of time and effort to obtain such data using conventional recordings or by human observation. Bringing out a robot to a field is our approach to solve this problem. We are developing a portable observation system called HARKBird using a robot audition HARK and microphone arrays to understand temporal patterns of vocalizations characteristics and their behavioral contexts. In this paper, we introduce a prototype system to 2D localize vocalizations of wild birds in real-time, and to classify their song types after recording. We show that the system can estimate the position of songs of a target individual and classify their songs with a reasonable quality to discuss their song - behavior relationships.
ER  - 

TY  - CONF
TI  - Failure Detection Using Proprioceptive, Auditory and Visual Modalities
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2491
EP  - 2496
AU  - A. Inceoglu
AU  - G. Ince
AU  - Y. Yaslan
AU  - S. Sariel
PY  - 2018
KW  - computerised monitoring
KW  - humanoid robots
KW  - manipulators
KW  - robot vision
KW  - sensor fusion
KW  - failure detection
KW  - continuous execution monitoring
KW  - multimodal failure monitoring
KW  - single sensor modality
KW  - high level proprioceptive
KW  - auditory predicates
KW  - visual predicates
KW  - humanoid robot
KW  - tabletop manipulation scenarios
KW  - safety handling
KW  - multimodal fusion
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Monitoring
KW  - Visualization
KW  - Task analysis
KW  - Grasping
DO  - 10.1109/IROS.2018.8594169
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Handling safety is crucial to achieve lifelong autonomy for robots. Unsafe situations might arise during manipulation in unstructured environments due to noises in sensory feedback, improper action parameters, hardware limitations or external factors. In order to assure safety, continuous execution monitoring and failure detection procedures are mandatory. To this end, we present a multimodal failure monitoring and detection system to detect manipulation failures. Rather than relying only on a single sensor modality, we consider integration of different modalities to get better detection performance in different failure cases. In our system, high level proprioceptive, auditory and visual predicates are extracted by processing each modality separately. Then, the extracted predicates are fused. Experiments on a humanoid robot for tabletop manipulation scenarios indicate that the contribution of each modality is different depending on the action in execution and multimodal fusion results in an overall performance increase in detecting failures compared to the performance attained by unimodal processing.
ER  - 

TY  - CONF
TI  - HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2497
EP  - 2502
AU  - R. Kojima
AU  - O. Sugiyama
AU  - K. Hoshiba
AU  - R. Suzuki
AU  - K. Nakadai
PY  - 2018
KW  - acoustic signal processing
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - microphone arrays
KW  - neural nets
KW  - public domain software
KW  - robots
KW  - zoology
KW  - wild birds
KW  - portable device
KW  - sound sources
KW  - real-time requirement
KW  - sound source detection
KW  - bird song analysis
KW  - open source software
KW  - bird song classifier
KW  - portability
KW  - computational time
KW  - bird song dataset
KW  - classification accuracy
KW  - HARK-bird-box
KW  - real-time bird song scene analysis system
KW  - Birds
KW  - Real-time systems
KW  - Microphone arrays
KW  - Source separation
KW  - Feature extraction
KW  - Image analysis
KW  - bird song scene analysis
KW  - robot audition
KW  - scene understanding
KW  - real-time system
DO  - 10.1109/IROS.2018.8594070
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.
ER  - 

TY  - CONF
TI  - Multi-timescale Feature-extraction Architecture of Deep Neural Networks for Acoustic Model Training from Raw Speech Signal
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2503
EP  - 2510
AU  - R. Takeda
AU  - K. Nakadai
AU  - K. Komatani
PY  - 2018
KW  - acoustic signal processing
KW  - feature extraction
KW  - neural nets
KW  - speech recognition
KW  - robot audition
KW  - normalization-free processing
KW  - speech features
KW  - multitimescale architecture
KW  - speech signals
KW  - low-latency speech recognition
KW  - utterance-wise mean subtraction
KW  - acoustic models
KW  - raw speech signal
KW  - acoustic model training
KW  - deep neural networks
KW  - multitimescale feature-extraction architecture
KW  - Feature extraction
KW  - Acoustics
KW  - Artificial neural networks
KW  - Splicing
KW  - Robots
KW  - Filter banks
KW  - Training
DO  - 10.1109/IROS.2018.8593925
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.
ER  - 

TY  - CONF
TI  - Tracking a moving sound source from a multi-rotor drone
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2511
EP  - 2516
AU  - L. Wang
AU  - R. Sanchez-Matilla
AU  - A. Cavallaro
PY  - 2018
KW  - acoustic signal processing
KW  - audio signal processing
KW  - autonomous aerial vehicles
KW  - cameras
KW  - feature extraction
KW  - helicopters
KW  - humanoid robots
KW  - particle filtering (numerical methods)
KW  - signal denoising
KW  - spatial filters
KW  - time-frequency analysis
KW  - ground-truth trajectory
KW  - noisy estimations
KW  - direction of arrival
KW  - ego-noise
KW  - human speaker
KW  - multirotor drone
KW  - moving sound source
KW  - moving source
KW  - short audio segments
KW  - time-frequency spatial filter
KW  - specific drone
KW  - propellers
KW  - motors
KW  - emergency whistle
KW  - Drones
KW  - Time-frequency analysis
KW  - Direction-of-arrival estimation
KW  - Microphone arrays
KW  - Loudspeakers
KW  - Propellers
DO  - 10.1109/IROS.2018.8594483
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a method to track from a multi-rotor drone a moving source, such as a human speaker or an emergency whistle, whose sound is mixed with the strong ego-noise generated by rotating motors and propellers. The proposed method is independent of the specific drone and does not need pre-training nor reference signals. We first employ a time-frequency spatial filter to estimate, on short audio segments, the direction of arrival of the moving source and then we track these noisy estimations with a particle filter. We quantitatively evaluate the results using a ground-truth trajectory of the sound source obtained with an on-board camera and compare the performance of the proposed method with baseline solutions.
ER  - 

TY  - CONF
TI  - Kinematic Morphing Networks for Manipulation Skill Transfer
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2517
EP  - 2523
AU  - P. Englert
AU  - M. Toussaint
PY  - 2018
KW  - affine transforms
KW  - image morphing
KW  - iterative methods
KW  - manipulators
KW  - motion control
KW  - neural nets
KW  - robot vision
KW  - kinematic model
KW  - robot motions
KW  - robot skill
KW  - manipulation skill transfer
KW  - kinematic morphing networks
KW  - affine transformations
KW  - map depth image observations
KW  - deep neural network
KW  - Kinematics
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Prototypes
KW  - Neural networks
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8593832
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The transfer of a robot skill between different geometric environments is non-trivial since a wide variety of environments exists, sensor observations as well as robot motions are high-dimensional, and the environment might only be partially observed. We consider the problem of extracting a low-dimensional description of the manipulated environment in form of a kinematic model. This allows us to transfer a skill by defining a policy on a prototype model and morphing the observed environment to this prototype. A deep neural network is used to map depth image observations of the environment to morphing parameter, which include transformations and configurations of the prototype model. Using the concatenation property of affine transformations and the ability to convert point clouds to depth images allows to apply the network in an iterative manner. The network is trained on data generated in a simulator and on augmented data that is created with its own predictions. The algorithm is evaluated on different tasks, where it is shown that iterative predictions lead to a higher accuracy than one-step predictions.
ER  - 

TY  - CONF
TI  - Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2524
EP  - 2531
AU  - E. J. Shamwell
AU  - S. Leung
AU  - W. D. Nothwang
PY  - 2018
KW  - accelerometers
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - gyroscopes
KW  - inertial navigation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - vision-aided absolute trajectory estimation
KW  - unsupervised deep network
KW  - online error correction
KW  - unsupervised deep neural network approach
KW  - RGB-D imagery
KW  - inertial measurements
KW  - Visual-Inertial-Odometry Learner
KW  - inertial measurement unit intrinsic parameters
KW  - white noise
KW  - extrinsic calibration
KW  - camera
KW  - IMU measurements
KW  - hypothesis trajectories
KW  - scaled image projection errors
KW  - visual odometry
KW  - visual simultaneous localization
KW  - KITTI Odometry dataset
KW  - competitive odometry performance
KW  - visual-inertial odometry
KW  - Cameras
KW  - Jacobian matrices
KW  - Image reconstruction
KW  - Trajectory
KW  - Simultaneous localization and mapping
KW  - Training
DO  - 10.1109/IROS.2018.8593573
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Adstract- We present an unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters (corresponding to gyroscope and accelerometer bias or white noise) or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to a spatial grid of pixel coordinates. We evaluate our network against state-of-the-art (SOA) visual-inertial odometry, visual odometry, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset [1] and demonstrate competitive odometry performance.
ER  - 

TY  - CONF
TI  - Distributed Deep Reinforcement Learning based Indoor Visual Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2532
EP  - 2537
AU  - S. Hsu
AU  - S. Chan
AU  - P. Wu
AU  - K. Xiao
AU  - L. Fu
PY  - 2018
KW  - indoor environment
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - complicated environment scene
KW  - motor control command
KW  - navigation task
KW  - large-scale indoor complex environment
KW  - pre-constructed map
KW  - indoor environment
KW  - complex spatial perception possible
KW  - indoor space
KW  - complex navigation path
KW  - aforementioned large-scale environment
KW  - real environments
KW  - distributed deep reinforcement learning based indoor visual navigation
KW  - Navigation
KW  - Visualization
KW  - Task analysis
KW  - Training
KW  - Reinforcement learning
KW  - Robots
KW  - Indoor environments
KW  - deep reinforcement learning
KW  - visual navigation
DO  - 10.1109/IROS.2018.8594352
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recently, as the rise of deep reinforcement learning, it not only can help the robot to convert the complicated environment scene to motor control command directly but also can accomplish the navigation task properly. In this paper, we propose a novel structure, where the objective is to achieve navigation in large-scale indoor complex environment without pre-constructed map. Generally, it requires good understanding of such indoor environment to make complex spatial perception possible, especially when the indoor space consists of many walls and doors which might block the view of robot leading to complex navigation path. By the proposed distributed deep reinforcement learning in different local regions, our method can achieve indoor visual navigation in the aforementioned large-scale environment without extra map information and human instruction. In the experiments, we validate our proposed method by conducting highly promising navigation tasks both in simulation and real environments.
ER  - 

TY  - CONF
TI  - Synthesizing Neural Network Controllers with Probabilistic Model-Based Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2538
EP  - 2544
AU  - J. C. Gamboa Higuera
AU  - D. Meger
AU  - G. Dudek
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - underwater vehicles
KW  - complex neural network controllers
KW  - motor controllers
KW  - probabilistic model-based reinforcement learning
KW  - robotics systems
KW  - sample-based version
KW  - Deep-PILeO
KW  - model-based algorithm
KW  - random numbers
KW  - clips gradients
KW  - neural network dynamics model
KW  - data-efficient synthesis
KW  - complex neural network policies
KW  - data-efficiency
KW  - truncated log-normal noise
KW  - Robots
KW  - Optimization
KW  - Vehicle dynamics
KW  - Task analysis
KW  - Heuristic algorithms
KW  - Neural networks
KW  - Stochastic processes
DO  - 10.1109/IROS.2018.8594018
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.
ER  - 

TY  - CONF
TI  - Composite Reinforcement Learning for Social Robot Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2553
EP  - 2558
AU  - P. Ciou
AU  - Y. Hsiao
AU  - Z. Wu
AU  - S. Tseng
AU  - L. Fu
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - minimum distance path
KW  - deep reinforcement learning technique
KW  - navigational movement
KW  - service robot
KW  - social robot navigation
KW  - CRL system
KW  - human robot interaction
KW  - human feedback
KW  - composite reinforcement learning framework
KW  - high dimension complex problem
KW  - Navigation
KW  - Reinforcement learning
KW  - Legged locomotion
KW  - Task analysis
KW  - Collision avoidance
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593410
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For a service robot, it is not adequate to let its navigational movement be based only on a single metric, such as minimum distance path. In the environment where the robot and humans are coexisting, the robot should always perform social navigation whenever it is moving. However, to perform social navigation, the robot needs to follow certain “social norms” of the environment. Recently, deep reinforcement learning (DRL) technique is popularly applied to the robotics field; yet, it is rarely used to solve the mentioned social navigation problem, generally deemed as a high dimension complex problem. In this paper, we propose the composite reinforcement learning (CRL) framework under which the robot learns appropriate social navigation with sensor input and reward update based on human feedback. For learning the aspect of human robot interaction (HRI), we provide a method to facilitate the training of DRL in real environment by incorporating prior knowledge to the system. It turns out that our CRL system not only can incrementally learn how to set its velocity and to perform HRI but also keep collecting human feedback to synchronize the reward functions to the current social norms. The experiments show that the proposed CRL system can safely learn how to navigate in the environment and show that our system is able to perform HRI for social navigation.
ER  - 

TY  - CONF
TI  - Apple Counting using Convolutional Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2559
EP  - 2565
AU  - N. Häni
AU  - P. Roy
AU  - V. Isler
PY  - 2018
KW  - agricultural products
KW  - convolutional neural nets
KW  - Gaussian processes
KW  - horticulture
KW  - image classification
KW  - object detection
KW  - horticultural studies
KW  - logistics planning
KW  - Gaussian mixture model
KW  - convolutional neural network
KW  - yield estimate
KW  - per-image accuracy
KW  - fruit counting
KW  - fruit detection
KW  - vegetable counts
KW  - apple counting
KW  - Image color analysis
KW  - Yield estimation
KW  - Agriculture
KW  - Image segmentation
KW  - Clustering algorithms
KW  - Task analysis
KW  - Vegetation
DO  - 10.1109/IROS.2018.8594304
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating accurate and reliable fruit and vegetable counts from images in real-world settings, such as orchards, is a challenging problem that has received significant recent attention. Estimating fruit counts before harvest provides useful information for logistics planning. While considerable progress has been made toward fruit detection, estimating the actual counts remains challenging. In practice, fruits are often clustered together. Therefore, methods that only detect fruits fail to offer general solutions to estimate accurate fruit counts. Furthermore, in horticultural studies, rather than a single yield estimate, finer information such as the distribution of the number of apples per cluster is desirable. In this work, we formulate fruit counting from images as a multi-class classification problem and solve it by training a Convolutional Neural Network. We first evaluate the per-image accuracy of our method and compare it with a state of the art method based on Gaussian Mixture Models over four test datasets. Even though the parameters of the Gaussian Mixture Model based method are specifically tuned for each dataset, our network outperforms it in three out of four datasets with a maximum of 94% accuracy. Next, we use the method to estimate the yield for two datasets for which we have ground truth. Our method achieved 96-97% accuracies. For additional details please see our video here: https://www.youtube.com/watch?v=Le0mb5P-SYc.
ER  - 

TY  - CONF
TI  - Target Localization with Drones using Mobile CNNs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2566
EP  - 2573
AU  - Y. Lu
AU  - Z. Wang
AU  - Z. Tang
AU  - T. Javidi
PY  - 2018
KW  - aerospace robotics
KW  - decision theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - search problems
KW  - target localization
KW  - accurate visual search
KW  - effective search strategies
KW  - observation models
KW  - latest developments
KW  - mobile platforms
KW  - policy search
KW  - point based methods
KW  - POMDP framework
KW  - single basketball
KW  - perception modules
KW  - error characteristics
KW  - control algorithm
KW  - realistic parameters
KW  - fast search strategy
KW  - longer search time
KW  - real data
KW  - error rates
KW  - false positive rates
KW  - false negative rates
KW  - visual search strategies
KW  - drone platform
KW  - robust algorithm
KW  - mobile CNN
KW  - Drones
KW  - Sensors
KW  - Search problems
KW  - Data collection
KW  - Computational modeling
KW  - Delays
KW  - Visualization
DO  - 10.1109/IROS.2018.8594163
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fast and accurate visual search is an enabler for many applications of drones. Prior works use POMDPs to produce effective search strategies. As the observation models are from heuristics, the robustness of these approaches on the field is unclear. This work builds a testbed that combines latest developments in related areas, including mobile CNNs for inference on mobile platforms and policy search with point based methods, in a POMDP framework. A dataset for a simple but realistic application, search for a single basketball, is collected to train the perception modules, investigate their error characteristics and validate the control algorithm. From simulation using realistic parameters, we found the significant role persistent factors in the environment can play in designing a fast search strategy. Failure to taking these factors into account results in up to 60% longer search time at the same success rate. Our empirical tests using mobile CNN and real data reveals that prior assumptions on error rates as functions of heights are wrong. The errors grows non-linearly, and there is significant between false positive and false negative rates. Our findings shed new lights on what to consider in designing visual search strategies in a drone platform and is one step towards a fast and robust algorithm.
ER  - 

TY  - CONF
TI  - An Adjustable Force Sensitive Sensor with an Electromagnet for a Soft, Distributed, Digital 3-axis Skin Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2582
EP  - 2588
AU  - A. C. Holgado
AU  - J. A. Alvarez Lopez
AU  - A. Schmitz
AU  - T. P. Tomo
AU  - S. Somlor
AU  - L. Jamone
AU  - S. Sugano
PY  - 2018
KW  - distributed sensors
KW  - electromagnets
KW  - foams
KW  - force measurement
KW  - force sensors
KW  - magnetic field measurement
KW  - magnetic sensors
KW  - microcontrollers
KW  - microsensors
KW  - skin
KW  - 3-axis force sensor
KW  - soft distributed digital 3-axis skin sensor
KW  - integrated microcontroller
KW  - adjustable force sensitive sensor
KW  - magnetic field strength
KW  - soft foam
KW  - 3-axis magnetic sensor
KW  - planar electromagnet
KW  - Robot sensing systems
KW  - Sensitivity
KW  - Magnetometers
KW  - Magnetic separation
KW  - Coils
KW  - Force
DO  - 10.1109/IROS.2018.8593757
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typically, the range and sensitivity of force sensors are determined during production. However, to be able to do both delicate and high-force demanding work, adjustable force sensitivity would be beneficial. The current paper proposes such a sensor by implementing a planar electromagnet above a 3-axis magnetic sensor, separated by soft foam. Furthermore, the sensor has digital output with an integrated microcontroller. The magnetic field strength with varying currents is examined in simulation, and the field changes according to displacements are investigated both in simulation and with the actual sensor. A prototype 3-axis force sensor is implemented and the relationship between the magnetic field change and the corresponding applied force is also investigated. It could be shown that the sensitivity of the sensor to displacements, as well as force, can indeed be adjusted.
ER  - 

TY  - CONF
TI  - Object Recognition Through Active Sensing Using a Multi-Fingered Robot Hand with 3D Tactile Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2589
EP  - 2595
AU  - S. Funabashi
AU  - S. Morikuni
AU  - A. Geier
AU  - A. Schmitz
AU  - S. Ogasa
AU  - T. P. Torno
AU  - S. Somlor
AU  - S. Sugano
PY  - 2018
KW  - control engineering computing
KW  - convolutional neural nets
KW  - dexterous manipulators
KW  - object recognition
KW  - recurrent neural nets
KW  - tactile sensors
KW  - time series
KW  - multifingered robot hand
KW  - triaxial force vector measurements
KW  - 3D tactile sensors
KW  - distributed force vector measurements
KW  - feedforward neural network
KW  - recurrent neural network
KW  - time-series training
KW  - active object sensing
KW  - Allegro Hand
KW  - uSkin tactile sensors
KW  - tactile object recognition
KW  - time series data
KW  - Force
KW  - Force measurement
KW  - Object recognition
KW  - Tactile sensors
DO  - 10.1109/IROS.2018.8594159
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates tactile object recognition with relatively densely distributed force vector measurements and evaluates what kind of tactile information is beneficial for object recognition. The uSkin tactile sensors are embedded in an Allegro Hand, and provide 240 triaxial force vector measurements in total in all fingers. Active object sensing is used to gather time-series training and testing data. A simple feedforward, a recurrent, and a convolutional neural network are used for recognizing objects. Evaluations with different number of employed measurements, static vs. time series data and force vector vs. only normal force vector measurements show that the high-dimensional information provided by the sensors is indeed beneficial. An object recognition rate of up to 95% for 20 objects was achieved.
ER  - 

TY  - CONF
TI  - Sensory-motor augmentation of the robot with shared human perception
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2596
EP  - 2603
AU  - R. Ishida
AU  - L. Meli
AU  - Y. Tanaka
AU  - K. Minamizawa
AU  - D. Prattichizzo
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - haptic interfaces
KW  - human-robot interaction
KW  - manipulators
KW  - man-machine systems
KW  - mobile robots
KW  - robot vision
KW  - robots
KW  - tactile sensors
KW  - operator actions
KW  - co-manipulated object
KW  - human hand
KW  - tiny vibration sensor
KW  - low-level robot intelligence
KW  - human operator
KW  - human-robot collaboration
KW  - human-robot cooperation
KW  - dexterous manipulation operations
KW  - manufacturing production lines
KW  - shared human perception
KW  - sensory-motor augmentation
KW  - Robot sensing systems
KW  - Task analysis
KW  - Vibrations
KW  - Force
KW  - Mechanical sensors
DO  - 10.1109/IROS.2018.8594496
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots have replaced people in many manufacturing production lines but the information they gather from sensors might not be sufficient to autonomously accomplish dexterous manipulation operations. Symbiotic human-robot cooperation appears to be a more realistic near future in industrial scenarios. In this paper we present a configuration of human-robot collaboration in which the robot is sensory-augmented by means of a set of tactile signals coming from the human operator. The incorporation of low-level robot “intelligence” permits the cooperative manipulation of an object while enabling the human operator to stay focused on task itself and carry it out in the most natural way. The effectiveness of this approach is demonstrated in a use case in which a robot helps a human operator to successfully accomplish a writing task. System performance has been evaluated, considering several positions of the tiny vibration sensor in charge of gathering the human perception, by testing it on both the human hand and the co-manipulated object. Results suggest that the sensor provides valuable information for recognizing operator actions when it is placed either on the human hand or on the co-manipulated object. However, the sensor on the finger directly represents the operator's perception, while the output of the sensor attached to the object changes according to the distance between the interaction point and the sensor itself. In addition, in wearing the sensor, neither the object nor the robot need to be instrumented: the operator is free to interact with a large set of objects and collaborate with any existing robot without requiring supplemental equipment.
ER  - 

TY  - CONF
TI  - HTC Vive: Analysis and Accuracy Improvement
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2610
EP  - 2615
AU  - M. Borges
AU  - A. Symington
AU  - B. Coltin
AU  - T. Smith
AU  - R. Ventura
PY  - 2018
KW  - calibration
KW  - object tracking
KW  - pose estimation
KW  - tracking
KW  - virtual reality
KW  - estimation repeatability
KW  - calibration procedure
KW  - open-source tracking algorithm
KW  - robotics applications
KW  - shelf algorithm
KW  - virtual reality applications
KW  - inertial measurements
KW  - millimeter magnitude
KW  - controlled experiments
KW  - ground truth
KW  - off-the-shelf tracking system
KW  - cost-effective
KW  - HTC Vive
KW  - Robots
KW  - Tracking
KW  - Photodiodes
KW  - Extraterrestrial measurements
KW  - Pose estimation
KW  - Transforms
DO  - 10.1109/IROS.2018.8593707
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - HTC Vive has been gaining attention as a cost-effective, off-the-shelf tracking system for collecting ground truth pose data. We assess this system's pose estimation through a series of controlled experiments where we show its precision to be in the millimeter magnitude and accuracy to range from millimeter to meter. We also show that Vive gives greater weight to inertial measurements in order to produce a smooth trajectory for virtual reality applications. Hence, the Vive's off the shelf algorithm is poorly suited for robotics applications such as measuring ground truth poses, where accuracy and repeatability are key. Therefore we introduce a new open-source tracking algorithm and calibration procedure for Vive which address these problems. We also show that our approach improves the pose estimation repeatability and accuracy by up to two orders of magnitude.
ER  - 

TY  - CONF
TI  - Improving indoor robots localisation by fusing different sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2616
EP  - 2623
AU  - B. P. Alvarado
AU  - F. Matía
AU  - R. Galán
PY  - 2018
KW  - cameras
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - pose estimation
KW  - laser LMS-200
KW  - omnidirectional camera Mobotix C2S
KW  - tour guide robot
KW  - external landmarks
KW  - indoor mobile robots navigation
KW  - odometry
KW  - external sensors
KW  - indoor robots localisation
KW  - Cameras
KW  - Measurement by laser beam
KW  - Lasers
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593667
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor mobile robots navigation must use external sensors to complement odometry. This paper analyses two different external sensors such as a laser LMS-200 and an omnidirectional camera Mobotix C2S. Experiments with only one of these sensors and with both integrated are carried out on a tour guide robot in order to obtain conclusions about their contribution to robot pose estimation, and how to locate external landmarks in the environment.
ER  - 

TY  - CONF
TI  - Robust Camera Pose Estimation via Consensus on Ray Bundle and Vector Field
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2624
EP  - 2631
AU  - H. Li
AU  - J. Zhao
AU  - J. Bazin
AU  - L. Luo
AU  - J. Wu
AU  - J. Yao
PY  - 2018
KW  - Bayes methods
KW  - expectation-maximisation algorithm
KW  - image matching
KW  - pose estimation
KW  - probability
KW  - vectors
KW  - robust camera pose estimation
KW  - point correspondences
KW  - general outlier removal strategy
KW  - 3D ray bundle consensus
KW  - 2D vector field consensus
KW  - expectation-maximization algorithm
KW  - inlier probability
KW  - outlier rejection methods
KW  - Cameras
KW  - Pose estimation
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Robustness
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594486
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating the camera pose requires point correspondences. However, in practice, correspondences are inevitably corrupted by outliers, which affects the pose estimation. We propose a general and accurate outlier removal strategy for robust camera pose estimation. The proposed strategy can detect outliers by leveraging the fact that only inliers comply with two effective consensuses, i.e., 3D ray bundle consensus and 2D vector field consensus. Our strategy has a nested structure. First, the outer module utilizes the 3D ray bundle consensus. We define the likelihood based on the probabilistic mixture model and maximize it by the expectation-maximization (EM) algorithm. The inlier probability of each correspondence and the camera pose are determined alternately. Second, the inner module exploits the 2D vector field consensus to refine the probabilities obtained by the outer module. The refinement based on the Bayesian rule facilitates the convergence of the outer module and improves the accuracy of the entire framework. Our strategy can be integrated into various existing camera pose estimation methods which are originally vulnerable to outliers. Experiments on both synthesized data and real images have shown that our approach outperforms state-of-the-art outlier rejection methods in terms of accuracy and robustness.
ER  - 

TY  - CONF
TI  - Efficient Map Representations for Multi-Dimensional Normal Distributions Transforms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2679
EP  - 2686
AU  - C. Schulz
AU  - R. Hanten
AU  - A. Zell
PY  - 2018
KW  - mobile robots
KW  - Monte Carlo methods
KW  - normal distribution
KW  - probability
KW  - robot vision
KW  - stereo image processing
KW  - transforms
KW  - indoor environments
KW  - outdoor environments
KW  - driving flying robots
KW  - fast approach
KW  - accurate approach
KW  - indexed kd-trees
KW  - free space
KW  - occupancy probabilities
KW  - map consistency
KW  - large-scale environments
KW  - mapping efficiency
KW  - efficient map representations
KW  - 3D map representations
KW  - static environments
KW  - dynamic environments
KW  - multidimensional normal distributions transforms
KW  - 3D normal distributions transform mapping
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Gaussian distribution
KW  - Two dimensional displays
KW  - Task analysis
KW  - Transforms
DO  - 10.1109/IROS.2018.8593602
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.
ER  - 

TY  - CONF
TI  - Modeling and Control of an Articulated Tail for Maneuvering a Reduced Degree of Freedom Legged Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2695
EP  - 2700
AU  - W. Saab
AU  - J. Yang
AU  - P. Ben-Tzvi
PY  - 2018
KW  - actuators
KW  - feedback
KW  - hardware-in-the loop simulation
KW  - legged locomotion
KW  - linearisation techniques
KW  - motion control
KW  - robot dynamics
KW  - leg mechanisms
KW  - quadruped robot
KW  - dynamic tail motions
KW  - robotic system design
KW  - outer loop controller
KW  - articulated tail mechanism
KW  - inner loop controller
KW  - tail prototype
KW  - dynamic modeling control
KW  - articulated robotic tail
KW  - maneuvering
KW  - legged robotic systems
KW  - reduced degree of freedom legged robot
KW  - hardware-in-the-loop experiments
KW  - quadruped platform simulation
KW  - feedback linearization maps
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Foot
KW  - Dynamics
KW  - Task analysis
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593945
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents dynamic modeling and control of an articulated robotic tail to maneuver and stabilize a reduced degree-of-freedom (DOF) quadruped robot. Conventional legged robotic systems consist of leg mechanisms that provide simultaneous propulsion, maneuvering and stabilization. However, in nature animals have been observed to utilize their tails to assist the legs in multiple tasks. Similarly, by incorporating an articulated tail onboard a quadruped robot, dynamic tail motions can be used to aid maneuvering. Therefore, tail implementation can potentially lead to simplifications in design and control of the legged robot since the legs will be responsible for only propulsion tasks. In this paper, a robotic system design consisting of an articulated tail and quadruped robot system is presented. Dynamic models are derived to analyze an optimal tail mass and length ratio to enhance inertial adjustment applications and develop an outer loop controller to plan tail trajectories for desired maneuvering applications. Results of analytical optimization are corroborated with measured data from biological animals. To decouple the dynamics of the articulated tail mechanism an inner loop controller using feedback linearization maps the desired behavior to the actuator inputs. This approach is validated using hardware-in-the-loop experiments with tail prototype in conjunction with simulated quadruped platform. Results demonstrate the capabilities of the articulated tail in enabling precise left and right turning (maneuvering).
ER  - 

TY  - CONF
TI  - Modeling and Fuzzy Control of One-legged Somersaulting Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2701
EP  - 2706
AU  - M. Zabihi
AU  - A. Alasty
PY  - 2018
KW  - fuzzy control
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - springs (mechanical)
KW  - flight phases
KW  - hybrid dynamic model
KW  - challenging control issue
KW  - one-legged hopping robots
KW  - springy leg
KW  - fuzzy logic control
KW  - one-legged somersaulting robot
KW  - multilegged ones
KW  - hopping motion
KW  - SLIP robots
KW  - Legged locomotion
KW  - Actuators
KW  - Mathematical model
KW  - Torque
KW  - Wheels
DO  - 10.1109/IROS.2018.8593897
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Research on legged robots has developed rapidly in the recent decades. One-legged robots, unlike multi-legged ones, have only one type of motion, called hopping. Hopping motion is generally divided into stance and flight phases. Switching between these two phases represents a hybrid dynamic model. Dynamic stabilization of hopping motion is a challenging control issue. Most of one-legged hopping robots studied in the past are able to hop with their one springy leg. In this paper, a novel one-legged robot is introduced and studied with two springs on the two sides. The one-legged somersaulting robot is able to hop with both springy sides. This ability causes lower energy consumption in passing obstacles and a longer step length in comparison with well-known SLIP robots with hopping motion stemming from the fact that it only has one rotary actuator. Fuzzy logic control is applied to achieve a stable limit cycle in the robot's somersaulting motion.
ER  - 

TY  - CONF
TI  - Towards a Passive Adaptive Planar Foot with Ground Orientation and Contact Force Sensing for Legged Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2707
EP  - 2714
AU  - R. Käslin
AU  - H. Kolvenbach
AU  - L. Paez
AU  - K. Lika
AU  - M. Hutter
PY  - 2018
KW  - force sensors
KW  - gait analysis
KW  - legged locomotion
KW  - robot dynamics
KW  - soil
KW  - stability
KW  - ground orientation
KW  - drift-free relative foot sole pose
KW  - passive adaptive planar foot
KW  - ground contact
KW  - highly dynamic legged robots
KW  - point foot design
KW  - legged locomotion
KW  - contact force sensor
KW  - stability
KW  - inertial measurement units
KW  - IMUs
KW  - quadrupedal robot ANYmal
KW  - compressible soils
KW  - built-in 6-axis force-torque transducer
KW  - Foot
KW  - Sensors
KW  - Legged locomotion
KW  - Force
KW  - Force measurement
KW  - Microcontrollers
DO  - 10.1109/IROS.2018.8593875
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Adapting to the ground enables stable footholds in legged locomotion by exploiting the structure of the terrain. On that account, we present a passive adaptive planar foot with three rotational degrees of freedom that is lightweight and thus suited for highly dynamic legged robots. Its low laying pivot joint provides high stability towards kinking. Information about the relative foot sole pose, and accordingly, the ground orientation is gathered by inertial measurement units (IMUs) placed on the foot sole and the shank. A complementary filter is presented that fuses these orientation estimates with an angular encoder to obtain a drift-free relative foot sole pose. The passive adaptive planar foot has been tested and compared to the classical point foot design on a variety of terrains and shows superior traction performance, especially on compressible soils. Being mounted on the quadrupedal robot ANYmal, the foot provides a reliable contact detection based on the fusion of the built-in 6-axis force/torque transducer and the IMUs. This allows to walk and trot on uneven terrain, loose soils, as well as climbing up a ramp and stairs while keeping the entire foot sole in ground contact all the time.
ER  - 

TY  - CONF
TI  - SLIP-Model-Based Dynamic Motion Transition Between Different Fixed Points in One Stride in a Leg-Wheel Transformable Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2715
EP  - 2720
AU  - H. Lin
AU  - Y. Lin
AU  - P. Lin
PY  - 2018
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - stable running motion
KW  - stable fixed-point trajectories
KW  - ordinary SLIP model
KW  - passive spring
KW  - leg-spring stiffness
KW  - fixed-point trajectory
KW  - multistride transition
KW  - leg-wheel transformable robot
KW  - SLIP-model-based dynamic motion transition
KW  - motion generation strategy
KW  - force control
KW  - TurboQuad
KW  - Legged locomotion
KW  - Springs
KW  - Robot kinematics
KW  - Mathematical model
KW  - Dynamics
KW  - DC motors
DO  - 10.1109/IROS.2018.8594364
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We report on the development of a motion generation strategy that allows the robot to transit from one stable running motion to another in one stride by actively changing leg stiffness in real time. Stable motion of the robot is generated based on the stable fixed-point trajectories of the spring-loaded inverted pendulum (SLIP) model. While the transition of the ordinary SLIP model with fixed parameters gradually converges if stable, a robot that uses force control to simulate the passive spring of the SLIP can actively modulate leg-spring stiffness. This enables the robot to switch instantly to another fixed-point trajectory of the SLIP model without going through multi-stride transition. The proposed method is implemented on a leg-wheel transformable robot, TurboQuad, and is evaluated experimentally. The results confirm that the robot can successfully transit between different fixed-point trajectories.
ER  - 

TY  - CONF
TI  - Continuous Shape Changing Locomotion of 32-legged Spherical Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2721
EP  - 2726
AU  - H. Nozaki
AU  - Y. Kujirai
AU  - R. Niiyama
AU  - Y. Kawahara
AU  - T. Yonezawa
AU  - J. Nakazawa
PY  - 2018
KW  - legged locomotion
KW  - trajectory control
KW  - amoeba movement
KW  - Mochibot
KW  - trajectory control
KW  - deformable robots
KW  - omni directional continuous crawling
KW  - free form locomotion
KW  - 32-legged spherical robot
KW  - continuous shape changing locomotion
KW  - Shape
KW  - Legged locomotion
KW  - Actuators
KW  - Skeleton
KW  - Rails
DO  - 10.1109/IROS.2018.8593791
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Shape changing robot is an approach towards locomotion on uncertain terrain due to its omni-directional features. However, the current locomotion method for such robots rely on discontinuous rolling. We propose a free form locomotion: an omni directional continuous crawling for deformable robots. This method introduce continuous shifting of contact surface similar to amoeba movement. A Mochibot that has thirty two telescopic legs is developed to verify the proposed locomotion method. Through the experiments, we have confirmed that the robot can track smooth paths: straight, smooth, and hand written curves. We also evaluate errors between desired and measured trajectories of the robot.
ER  - 

TY  - CONF
TI  - End-effector with a Hook and Two Fingers for the Locomotion and Simple Work of a Four-limbed Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2727
EP  - 2732
AU  - T. Matsuzawa
AU  - A. Imai
AU  - K. Hashimoto
AU  - T. Teramachi
AU  - X. Sun
AU  - S. Kimura
AU  - N. Sakai
AU  - Y. Yoshida
AU  - K. Kumaaai
AU  - T. Matsubara
AU  - K. Yamaguchi
AU  - A. Takanishi
PY  - 2018
KW  - end effectors
KW  - legged locomotion
KW  - motion control
KW  - manipulation tasks
KW  - four-limb robot WAREC-1
KW  - vertical ladder
KW  - fingers
KW  - locomotion modes
KW  - legged robot
KW  - hook shape
KW  - grasping working
KW  - end-effector
KW  - End effectors
KW  - Thumb
KW  - Grasping
KW  - Force
KW  - Shape
DO  - 10.1109/IROS.2018.8593422
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose an end-effector for realizing various locomotion modes and simple work of a legged robot. The locomotion modes include climbing a vertical ladder, crawling, and walking. The simple work includes grasping and switching motions required at a disaster site. The developed end-effector has a two-pronged hook shape and two fingers for grasping and working and can be used to perform the locomotion and manipulation tasks described above. The experimental results confirmed that the four-limb robot WAREC-1 (WAseda REsCuer-No. 1) equipped with our proposed end-effector was able to climb a vertical ladder and perform the crawling motion. We also confirmed that the end-effector could grasp and switch five types of objects: a cylinder, cylinder with trigger, T-shaped, disk, and thin plate.
ER  - 

TY  - CONF
TI  - A Framework for Modeling Closed Kinematic Chains with a Focus on Legged Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2733
EP  - 2738
AU  - V. R. Kamidi
AU  - A. Williams
AU  - P. Ben–Tzvi
PY  - 2018
KW  - legged locomotion
KW  - robot kinematics
KW  - singularly perturbed systems
KW  - legged robots
KW  - MATLAB framework
KW  - dynamic modeling simulation
KW  - legged locomotive mechanisms
KW  - fixed-base systems
KW  - singular perturbation theory
KW  - CKC mechanisms
KW  - dynamic monopedal gait
KW  - closed kinematic chains
KW  - floating-base systems
KW  - functional API
KW  - Mathematical model
KW  - Legged locomotion
KW  - Kinematics
KW  - Software
KW  - Computational modeling
KW  - Couplings
DO  - 10.1109/IROS.2018.8593909
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the foundations of a MATLAB framework for dynamic modeling and simulation of closed kinematic chain (CKC) mechanisms, with a particular focus on implementation with legged locomotive mechanisms. As such, the framework supports both floating-base and fixed-base systems. Through the use of singular perturbation theory, various CKC mechanisms can be modeled so that constraint errors asymptotically converge to zero, thus avoiding the numerical drift that plagues commonly used methods. A functional API and the relevant core commands necessary to construct a model are presented. Two robotic legs incorporating CKC mechanisms are utilized as case studies, and simulations of each leg performing a dynamic monopedal gait are illustrated.
ER  - 

TY  - CONF
TI  - Steering of an Underactuated Legged Robot through Terrain Contact with an Active Tail
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2739
EP  - 2746
AU  - C. S. Casarez
AU  - R. S. Fearing
PY  - 2018
KW  - closed loop systems
KW  - drag
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - steering systems
KW  - underactuated legged robot
KW  - terrain contact
KW  - rapid point turn
KW  - active tail payload
KW  - steady-state turning model
KW  - differential drive turning gaits
KW  - tail impact turning
KW  - tail drag
KW  - palm-sized legged robot
KW  - LoadRoACH
KW  - tail contact turning strategies
KW  - closed-loop corner steering maneuver
KW  - mass 55.0 g
KW  - Turning
KW  - Legged locomotion
KW  - Force
KW  - Steady-state
KW  - Drag
KW  - Aerodynamics
DO  - 10.1109/IROS.2018.8594384
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper analyzes and implements two novel turning strategies for underactuated legged robots that leverage contact of an active tail against terrain. The first strategy produces a sustained turn with a tail dragging against the ground during forward locomotion. The second strategy produces a rapid point turn by impacting the tail against the ground. LoadRoACH, a 55 g palm-sized legged robot, is developed to carry the active tail payload used in turning experiments. A steady-state turning model predicts the achievable turn speed of the robot on carpet, and open-loop turning experiments characterize the performance of the two tail contact turning strategies. Tail drag turning provides comparable turning maneuverability to differential drive turning gaits on carpet and gravel surfaces. Tail impact turning can produce rapid point turns on carpet, tarp, and gravel, but has a large variability in turn angle and time to recover from the turn. Finally, tail drag and tail impact turning control methods are implemented in an aggressive closed-loop corner steering maneuver.
ER  - 

TY  - CONF
TI  - Characterization of Active/Passive Pneumatic Actuators for Assistive Devices
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2747
EP  - 2754
AU  - D. Kaneishi
AU  - M. Tomizuka
AU  - R. P. Matthew
PY  - 2018
KW  - handicapped aids
KW  - nonlinear control systems
KW  - pneumatic actuators
KW  - springs (mechanical)
KW  - stability
KW  - passive nonlinear spring
KW  - stability
KW  - assistive device
KW  - active/passive pneumatic actuators
KW  - adjustable passive nonlinear spring
KW  - Force
KW  - Valves
KW  - Springs
KW  - Task analysis
KW  - Assistive devices
KW  - Pneumatic actuators
DO  - 10.1109/IROS.2018.8594143
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Assistive devices have been developed for power augmentation and task-oriented assistance such as loaded walking. The effective joint dynamics of the user can be altered using a wearable system, providing assistance when a task is performed. The authors have investigated an Active/Passive Pneumatic Actuator (AP2A) for an assistive device, which has a simple structure and responds as a passive nonlinear spring with controllable stiffness. This paper introduces a novel controller for the AP2 A and validates the performance through experiments. The developed controller is found to stabilize at the desired stiffness response within 1 second, confirming the ability of the AP2 A to act as an adjustable passive nonlinear spring.
ER  - 

TY  - CONF
TI  - Unpowered Lower-Body Exoskeleton with Torso Lifting Mechanism for Supporting Sit-to-Stand Transitions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2755
EP  - 2761
AU  - D. F. P. Granados
AU  - H. Kadone
AU  - K. Suzuki
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - injuries
KW  - muscle
KW  - patient rehabilitation
KW  - pulleys
KW  - unpowered lower-body exoskeleton
KW  - torso lifting mechanism
KW  - knee joint
KW  - lower torso
KW  - spinal cord injury
KW  - lower-body impairments
KW  - power transfer mechanism
KW  - lumbar motion
KW  - cable-driven pulley system
KW  - human body dynamics
KW  - rigid link model
KW  - impedance model
KW  - passive system
KW  - natural motions
KW  - upper body
KW  - body residual capabilities
KW  - external power source
KW  - upper-body
KW  - passive energy storage
KW  - muscle activity
KW  - exoskeleton support
KW  - passive exoskeleton
KW  - STS training
KW  - STS posture transitions
KW  - sit-to-stand posture transitions
KW  - STS transition support
KW  - upright locomotion
KW  - patient rehabilitation
KW  - Exoskeletons
KW  - Biological system modeling
KW  - Torso
KW  - Torque
KW  - Robots
KW  - Wheelchairs
KW  - Dynamics
KW  - Passive exoskeleton
KW  - human dynamics modeling
KW  - physical human-robot interaction
KW  - rehabilitation robotics
DO  - 10.1109/IROS.2018.8594199
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose the design of an exoskeleton with support at the knee joint and lower torso for sit-to-stand and stand-to-sit (STS) posture transitions; devised for users with spinal cord injury and other complete lower-body impairments. The STS transitions assistance is achieved through a power transfer mechanism that synchronizes knees and lumbar motion through a cable-driven pulley system. We analyze the human body dynamics in the posture transition with a rigid link model and the interaction interface with the exoskeleton through an impedance model for producing a passive system voluntarily controlled by natural motions of the upper body. Therefore, allowing the potential users to achieve STS transitions with their body residual capabilities without an external power source. Instead, transferring power from their upper-body to lower-body, herewith, controlling a passive energy storage. A prototype was constructed and evaluated with seven healthy subjects observing the proposed motion and muscle activity during the STS transitions. The results show a significant reduction in the muscle activity evaluated, at the erector spinae, gluteus maximus and rectus femoris, with reductions between 30% to 50% at the p <; 0.01 level comparing STS transitions with and without the exoskeleton support. Concluding that the STS transitions support is feasible with the passive exoskeleton envisioned for applications in upright locomotion, STS training, and rehabilitation.
ER  - 

TY  - CONF
TI  - Development of Master-slave Type Lower Limb Motion Teaching System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2762
EP  - 2767
AU  - T. Tagami
AU  - T. Kawase
AU  - D. Morisaki
AU  - R. Miyazaki
AU  - T. Miyazaki
AU  - T. Kanno
AU  - K. Kawashima
PY  - 2018
KW  - control engineering computing
KW  - electromyography
KW  - medical robotics
KW  - motion control
KW  - pneumatic actuators
KW  - recurrent neural nets
KW  - robot vision
KW  - teaching
KW  - pneumatic artificial rubber muscle
KW  - PARM
KW  - assistive force
KW  - hip joint motion
KW  - master-slave type lower limb motion teaching system
KW  - motor skill learning
KW  - physical activities
KW  - teachers motion
KW  - recurrent neural network
KW  - electromyogram signals
KW  - learners motion
KW  - Hip
KW  - Education
KW  - Visualization
KW  - Force
KW  - Neural networks
KW  - Delays
KW  - Belts
DO  - 10.1109/IROS.2018.8593737
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motor skill learning is fundamental in many physical activities of human. In the processes of learning of motor skills, learners often receive visual or physical information about postures from teachers. However, the information about postures usually cannot be transmitted precisely. In this paper, we propose a motion teaching system to transmit teachers' motion to learners directly by using a motion capture and an assist suit. The assist suit, which has a pneumatic artificial rubber muscle (PARM) as an actuator, was designed to move a learner's hip joint with less loss of assistive force and less constraint of motion. Hip joint motion of a teacher can be transmitted to the assist suit by master-slave control. In addition, to compensate the delay of the PARM, posture of the teacher is predicted before the occurence by a recurrent neural network by using electromyogram signals and the past joint angle. We confirmed the system can transmit a teacher's motion to a learner in real time, and with the neural network, the delay of the learner's motion could be suppressed to approximately 0.1s, which is enough to feel visual and physical information synchronous. Therefore, the proposed motion teaching system would have the ability to transmit teachers' motion to learners visually and physically with precision sufficient to facilitate skill transmission.
ER  - 

TY  - CONF
TI  - Design and Experimental Characterisation of a Hydrostatic Transmission for Upper Limb Exoskeletons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2768
EP  - 2773
AU  - M. Bolignari
AU  - G. Moretti
AU  - M. Fontana
PY  - 2018
KW  - controllability
KW  - force control
KW  - friction
KW  - hydrostatics
KW  - medical robotics
KW  - power transmission (mechanical)
KW  - torque control
KW  - wearable robots
KW  - high performance fluid power transmission
KW  - leakage-free operation
KW  - virtually zero stick-friction
KW  - intrinsic backdrivable operation
KW  - fluid transmission system
KW  - design parameters
KW  - upper limb exoskeleton
KW  - hydrostatic transmission
KW  - remote electrical actuation
KW  - hydrostatic air-liquid torque transmission system
KW  - rolling membrane cylinders
KW  - controllability
KW  - Exoskeletons
KW  - Torque
KW  - Robots
KW  - Hydraulic systems
KW  - Layout
KW  - Pulleys
KW  - Actuators
DO  - 10.1109/IROS.2018.8593639
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a novel hydrostatic air-liquid torque transmission system for an upper limb exoskeleton. The proposed design is based on remote electrical actuation, with grounded motors, combined with high performance fluid power transmission employed to deliver the power to the joints of the exoskeleton. The fluid transmission is based on rolling membrane cylinders that guarantee leakage-free operation, no backlash, and virtually zero stick-friction. This solution makes it possible to obtain easy controllability, good efficiency, intrinsic backdrivable operation, and reduced mass/inertia of the links of the robot. Additionally, the proposed system can be potentially implemented at relatively low-costs thanks to the employment of standard components and an architecture based on a modular approach. A test bench of the fluid transmission system is developed and a campaign of experiments is conducted to characterize its static/dynamic response for different choice of design parameters. In addition, we present a preliminary complete integrated arrangement of an upper limb exoskeleton equipped with the proposed transmission system. Results confirm the feasibility of the proposed actuation approach for the envisaged application.
ER  - 

TY  - CONF
TI  - Development of Tendon Driven Under-Actuated Mechanism Applied in an EMG Prosthetic Hand with Three Major Grasps for Daily Life
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2774
EP  - 2779
AU  - X. Jing
AU  - X. Yong
AU  - L. Tian
AU  - S. Togo
AU  - Y. Jiang
AU  - H. Yokoi
AU  - G. Li
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - biomimetics
KW  - electromyography
KW  - medical control systems
KW  - prosthetics
KW  - three-dimensional printing
KW  - EMG prosthetic hand
KW  - grasps
KW  - daily life
KW  - actuators
KW  - grasping tasks
KW  - weight saving
KW  - short driven distance
KW  - 3D printing technology
KW  - flexion-extension
KW  - artificial hand
KW  - tendon driven under-actuated mechanism
KW  - biomimetic prosthetic hand
KW  - thumb adduction-abduction
KW  - compact structure
KW  - motion verification
KW  - transradial amputee
KW  - Thumb
KW  - Tendons
KW  - Indexes
KW  - Grasping
KW  - Prosthetic hand
KW  - Actuators
DO  - 10.1109/IROS.2018.8593939
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a lightweight (<;250 g) and low-cost (<;350 USD) biomimetic prosthetic hand with two actuators embedded in the palm. One of them is employed for flexion/extension of the five digits, and the other one is used for the adduction/abduction of thumb. Thus, the hand can achieve major grasping tasks that account for about 85% of activities in daily life. The unique transmission provides various advantages such as a compact structure, weight saving, and short driven distance. Furthermore, by using 3D printing technology, most parts of the prosthetic hand were made to be much lighter and have a humanlike appearance, compared with conventionally manufactured artificial hand. Finally, the performance and practical applicability of the proposed design was verified experimentally through both of a motion verification and an intuitive control test by a healthy subject and a transradial amputee.
ER  - 

TY  - CONF
TI  - Muscle Activation Source Model-based sEMG Signal Decomposition and Recognition of Interface Rotation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2780
EP  - 2786
AU  - M. Kim
AU  - W. K. Chung
PY  - 2018
KW  - biomechanics
KW  - electromyography
KW  - medical signal processing
KW  - motion estimation
KW  - skin
KW  - muscle structures
KW  - muscle activation source model-based sEMG signal decomposition
KW  - sEMG interface rotation
KW  - muscle activation signals
KW  - surface electromyography signals
KW  - muscle activation extraction
KW  - hand motion estimation
KW  - rotation recognition
KW  - inertial measurement unit
KW  - Electrodes
KW  - Muscles
KW  - Mathematical model
KW  - Signal resolution
KW  - Electromyography
KW  - Conductivity
KW  - Motion estimation
DO  - 10.1109/IROS.2018.8593448
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Muscle activation signals are measured from the skin surface as surface electromyography (EMG) signals that contain information on human intentions; therefore, they are widely used in various robotics applications owing to their usability. However, selective muscle activation extraction is difficult because of the complexity of muscle structures. This study investigated muscle activation source model-based sEMG signal decomposition that considers the anatomical factors of muscle structures. The main advantage of the proposed model-based signal decomposition is that sEMG interface rotation can be recognized by comparing source parameters identified before and after rotation. To assess the performance of the proposed model-based decomposition method, hand motion estimation and rotation recognition were conducted. Additionally, two-dimensional simultaneous control was conducted with an inertial measurement unit to verify the usability of the proposed model. The results indicate that the proposed model decomposes an sEMG signal based on motion with good performance and demonstrate feasibility of motion estimation independent of sEMG interface rotation.
ER  - 

TY  - CONF
TI  - Design, Control and Preliminary Test of Robotic Ankle Prosthesis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2787
EP  - 2793
AU  - X. Sun
AU  - F. Sugai
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - actuators
KW  - artificial limbs
KW  - biomechanics
KW  - elasticity
KW  - gait analysis
KW  - medical control systems
KW  - medical robotics
KW  - prosthetics
KW  - springs (mechanical)
KW  - torque
KW  - torque control
KW  - variable transmission series elastic actuator
KW  - commercially available ankle foot prosthesis
KW  - robotic ankle prosthesis
KW  - preliminary test
KW  - variable transmission mechanism
KW  - powered plantar flexion
KW  - robotic ankle foot prosthesis
KW  - ankle joint torque-angle
KW  - ankle angle varies
KW  - variable transmission ratio
KW  - ankle foot joint
KW  - Prosthetics
KW  - Foot
KW  - Legged locomotion
KW  - Torque
KW  - Springs
DO  - 10.1109/IROS.2018.8594498
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Currently, most of commercially available ankle foot prosthesis are passive, which don't exhibit appropriate biomechanics during walking and could not adapt to dynamic property of able-bodied walking. In this paper, we present a novel robotic ankle foot prosthesis with variable transmission series elastic actuator (SEA). Slider crank mechanism is applied to transform linear motion of series elastic actuator to rotary motion of ankle foot joint. And this could contribute to variable transmission ratio while ankle angle varies. Because of variable transmission ratio, ankle joint torque is increasing while ankle angle is flexed from plantar flexion to dorsiflexion, whose feature has similar increase trend with human's ankle joint torque-angle relationship, and exhibits an appropriate characteristic for developing robotic ankle foot prosthesis. Larger torque could be obtained in powered plantar flexion, and this indicates that variable transmission mechanism would help reduce required motor torque compared with traditional mechanism. Energy stored in springs of series elastic actuator contribute a torque to powered plantar flexion. Preliminary experiments with a transtibial amputee and a transferomal amputee have been performed to test the prototype.
ER  - 

TY  - CONF
TI  - A Method for Robot Motor Fatigue Management in Physical Interaction and Human-Robot Collaboration Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2850
EP  - 2856
AU  - L. Peternel
AU  - N. Tsagarakis
AU  - A. Ajoudani
PY  - 2018
KW  - collision avoidance
KW  - fatigue
KW  - human-robot interaction
KW  - industrial accidents
KW  - industrial robots
KW  - mobile robots
KW  - motion control
KW  - robot kinematics
KW  - human co-worker
KW  - KUKA lightweight robot
KW  - human-robot collaboration tasks
KW  - software frameworks
KW  - robot motor fatigue management
KW  - robot kinematic redundancy
KW  - collaborative human-robot surface polishing
KW  - autonomous surface wiping
KW  - Cartesian task production
KW  - two-stage reaction process
KW  - robot productivity
KW  - hardware solutions
KW  - accidental collisions
KW  - human safety
KW  - Robots
KW  - Task analysis
KW  - Fatigue
KW  - Temperature measurement
KW  - Torque
KW  - Force
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594196
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Collaborative robots are often designed with limited power and force capacity, with the aim to provide affordable solutions and ensure human safety in case of accidental collisions and impacts. If a task requires a power beyond this capacity, or is performed repeatedly over long periods, such limits may be exceeded, which can cause inevitable robot damage and contribute to the lost productivity. In such cases, where hardware solutions and improvements are not applicable, effective software frameworks can prolong robot productivity and lifetime. To this end, in this paper we propose a novel technique for the monitoring and management of robot fatigue in repetitive or high-effort task execution scenarios. The robot fatigue is estimated by the measured temperature of motors in the joints. The proposed fatigue management system is composed of two-stage reaction process that is triggered by different levels of the estimated fatigue. The first stage exploits the kinematic redundancy of robot structure in attempt to minimise the load in the specific joints that under fatigue by reconfiguration in the joint space through the null space of the Cartesian task production. If the first stage is not successful in reducing the fatigue, the second stage is activated that gradually reduces the forces of hybrid controller. At that point, the human co-worker can temporarily take over the task execution until the robot will be recovered from the excessive fatigue. To validate the proposed approach we conducted experiments on KUKA Lightweight Robot performing two interaction tasks: autonomous surface wiping and collaborative human-robot surface polishing.
ER  - 

TY  - CONF
TI  - Adaptive Task Planner for Performing Home Service Tasks in Cooperation with a Human
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2857
EP  - 2864
AU  - S. Lee
AU  - J. Park
AU  - D. Kim
AU  - J. Kim
PY  - 2018
KW  - humanoid robots
KW  - human-robot interaction
KW  - image colour analysis
KW  - image sensors
KW  - path planning
KW  - robot vision
KW  - sequence network
KW  - episodic memory
KW  - user behaviors
KW  - task scheduler schedules
KW  - executable behavior
KW  - alternative behavior sequence
KW  - failed behavior problem
KW  - wheel-based humanoid robot
KW  - adaptive task planner
KW  - home service task
KW  - temporal sequence
KW  - fast forward planner
KW  - sequence to sequence network
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Planning
KW  - Generators
KW  - Thermal sensors
DO  - 10.1109/IROS.2018.8594040
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To perform a home service task through cooperation with a human in a real environment, a robot needs to deal with the environmental changes and accordingly plan appropriate behavior sequence. For this purpose, in this paper, we propose an adaptive task planner which is based on memory and reasoning. A robot perceives user behaviors and objects using an RGB-depth and thermal sensor. The robot stores a temporal sequence of behaviors for performing a task in its episodic memory that is realized by a sequence to sequence network. When the user command is given, the episodic memory is used to retrieve the behavior sequence to carry out the command. On the other hand, when the robot perceives user behaviors, the robot postpones its behavior till his/her behavior is stopped. Once stopped, the episodic memory retrieves the behavior sequence to conduct a task that the user has intended. A task scheduler schedules the behavior sequence from the memory and sends it to an internal simulator. The internal simulator confirms the behavior sequence to be executable and then if executable, it sends the next executable behavior to the execution module. If a behavior fails in the internal simulation test, fast forward planner generates an alternative behavior sequence to resolve the failed behavior problem. The effectiveness and applicability of the proposed planner is demonstrated by a wheel-based humanoid robot.
ER  - 

TY  - CONF
TI  - Design of SUPERball v2, a Compliant Tensegrity Robot for Absorbing Large Impacts
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2865
EP  - 2871
AU  - M. Vespignani
AU  - J. M. Friesen
AU  - V. SunSpiral
AU  - J. Bruce
PY  - 2018
KW  - actuators
KW  - aerospace robotics
KW  - cables (mechanical)
KW  - design engineering
KW  - impact (mechanical)
KW  - mobile robots
KW  - planetary rovers
KW  - torque control
KW  - velocity control
KW  - SUPERball v2
KW  - spherical six-bar tensegrity robot
KW  - fully actuated six-bar design
KW  - compliant nylon cables
KW  - torque-control enabled motor
KW  - robust mechanical structure
KW  - system design
KW  - compliant tensegrity robot
KW  - impact velocities
KW  - 24 actuators
KW  - actuation
KW  - high-speed landings
KW  - six-bar tensegrity robot
KW  - Robot kinematics
KW  - Springs
KW  - Meters
KW  - NASA
KW  - Mechanical cables
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594374
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present the system design and initial testing of SUPERball v2, a completely re-designed 2-meter spherical six-bar tensegrity robot designed to survive high-speed landings as well as locomote to desired locations. SUPERball v2 was designed to enable a host of new actuation and experimentation. The prototype features a fully actuated six-bar design (24 actuators), compliant nylon cables (up to 15% stretch), torque-control enabled motors, and a robust mechanical structure capable of surviving impact velocities upwards of 8 m/s.
ER  - 

TY  - CONF
TI  - Slip Avoidance in Dual-Arm Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2872
EP  - 2879
AU  - D. S. Carabis
AU  - J. T. Wen
PY  - 2018
KW  - aerospace robotics
KW  - force control
KW  - friction
KW  - manipulator dynamics
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - stability
KW  - slip avoidance
KW  - dual-arm manipulation
KW  - multifinger
KW  - multiarm grasping
KW  - friction contacts
KW  - contact slippage
KW  - space robotics
KW  - stable grasp
KW  - static conditions
KW  - grasp stability
KW  - safe force closure condition
KW  - specified motion trajectory
KW  - estimated inertial force
KW  - required squeeze force
KW  - inertial force component
KW  - motion-induced disturbance force
KW  - slip prevention strategy
KW  - dual-arm transportation
KW  - dual-arm robot
KW  - dynamic squeeze adjustment
KW  - robot-load motion
KW  - Force
KW  - Manipulators
KW  - Satellites
KW  - Grasping
KW  - Collision avoidance
KW  - Friction
DO  - 10.1109/IROS.2018.8593377
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In multi-finger or multi-arm grasping with friction contacts, maintaining force closure during motion is critical. Violation of this condition would cause contact slippage and possibly loss of grasp. This issue is of particular importance in space robotics, where the loss of grasp could lead to catastrophic consequences. There has been ample literature on stable grasp and force closure under static conditions. This paper investigates multi-arm grasping during motion, where the inertial force from the load could adversely affect grasp stability. Our approach dynamically adjusts the squeeze force and commanded robot/load motion to maintain a safe force closure condition. For a specified motion trajectory, the squeeze force is updated to prevent slippage based on the estimated inertial force. When the required squeeze force is beyond what the manipulators can safely apply, the trajectory will be scaled to reduce the inertial force component. In addition to motion-induced disturbance force, contact between the load and other objects in the environment can also cause slippage. The slip prevention strategy is extended to this case as well. The application scenario is based on the dual-arm transportation and berthing of a load in a micro-gravity environment. For laboratory testing, we use a fixed-base dual-arm robot to grasp, transport, and berth an object on a planar air bearing table. We also extend the transportation tests to a more general spatial setting, and use the dynamic squeeze adjustment to grasp, lift, and transport an object. Experimental results show the proposed method is effective at avoiding contact slippage during motion and when the object is in contact with the environment.
ER  - 

TY  - CONF
TI  - Relative and inertial attitude determination in three-vehicle long formations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2880
EP  - 2885
AU  - P. Cruz
AU  - P. Batista
PY  - 2018
KW  - attitude control
KW  - attitude measurement
KW  - inertial navigation
KW  - mobile robots
KW  - multi-robot systems
KW  - inertial attitude
KW  - three-vehicle long formations
KW  - attitude determination problem
KW  - three-vehicle formation
KW  - independent inertial measurement
KW  - attitude relations
KW  - relative attitude
KW  - inertial candidates
KW  - constrained formations
KW  - sensor noise
KW  - Position measurement
KW  - Sensors
KW  - Extraterrestrial measurements
KW  - Visualization
KW  - Estimation
KW  - Space vehicles
KW  - Navigation
DO  - 10.1109/IROS.2018.8593763
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses a new attitude determination problem for formations. It considers a three-vehicle formation with relative and inertial measurements from sensors, where Constraints limit the relative measurements, which are not available between two of the vehicles, also known as deputies. The other vehicle is called the chief and does not have any limitation. Furthermore, each of the vehicles has an independent inertial measurement, whose references are known. The goal is to determine all attitude relations, both inertial and relative. The solution for this problem is divided into different stages. First, the relative attitude between the chief and the deputies is assessed, which results in two candidates for each of these relations. Then, each candidate yields a candidate for the inertial attitude of the chief. Next, comparing the four inertial candidates gives the solution for their respective relations and consequently for the relative relations as well. The remaining relations derive directly from those already known. The paper also provides some early insights about degeneracies, possible particular cases of the solution, and the effect of sensor noise. Finally, the solution is validated with a simulation, whose results are similar to attitude determination problems in constrained formations.
ER  - 

TY  - CONF
TI  - Steerable Locomotion Controller for Six-strut Icosahedral Tensegrity Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2886
EP  - 2892
AU  - M. Vespignani
AU  - C. Ercolani
AU  - J. M. Friesen
AU  - J. Bruce
PY  - 2018
KW  - accelerometers
KW  - mobile robots
KW  - motion control
KW  - nonlinear dynamical systems
KW  - robust control
KW  - steerable locomotion controller
KW  - nonlinear dynamics
KW  - six-strut icosahedral tensegrity robots
KW  - step-wise locomotion
KW  - SUPERball v2 robot
KW  - preexisting step-wise controller
KW  - tensegrity structure
KW  - locomotion problem
KW  - step-wise motion controllers
KW  - Robot kinematics
KW  - NASA
KW  - Trajectory
KW  - Face
KW  - Robot sensing systems
KW  - Navigation
DO  - 10.1109/IROS.2018.8593676
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a novel steerable locomotion controller for six-strut tensegrity robots. Tensegrity robots are lightweight and have many promising features such as robustness, shape-shifting capabilities, and deployability, making them good candidates for exploration and scouting of remote areas. Despite these advantages, tensegrity robots are challenging to control due to their large number of degrees of freedom, nonlinear dynamics, and intrinsic compliance. Recently, many step-wise motion controllers have been employed to simplify the locomotion problem, thanks to the discrete nature of the tensegrity structure. In this paper we present a novel locomotion controller which will steer the direction of motion of a six-strut tensegrity robot when used in conjunction with any preexisting step-wise controller. We validated our controller on the SUPERball v2 robot, showing straight and curved trajectories, and an example of navigation around obstacles. Our method is computationally inexpensive, only requires knowledge about the current base triangle (e.g, via accelerometer data), and can be generalized to any six-strut tensegrity robot which can perform step-wise locomotion.
ER  - 

TY  - CONF
TI  - Series Elastic Tether Management for Rappelling Rovers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2893
EP  - 2900
AU  - T. Brown
AU  - A. Stefanini
AU  - J. Sawoniewicz
AU  - I. Nesnas
AU  - N. Georgiev
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - design engineering
KW  - elasticity
KW  - force control
KW  - mobile robots
KW  - position control
KW  - robot kinematics
KW  - wheels
KW  - series elastic tether management
KW  - Axel rappelling rover
KW  - intriguing science sites
KW  - important science sites
KW  - difficult terrains
KW  - conventional rovers
KW  - extended autonomous rappelling
KW  - tether spooling
KW  - shock tolerance
KW  - first-generation tether management system
KW  - double bull-wheel capstan
KW  - low-stiffness series elastic actuator
KW  - SEA
KW  - decouple internal spooling tension
KW  - external tether tension
KW  - closed-loop tether tension control
KW  - rappelling system
KW  - constant spooling tension
KW  - measured output tension
KW  - tension contribution
KW  - shock-drop tolerance
KW  - Springs
KW  - Bandwidth
KW  - Sea measurements
KW  - Actuators
KW  - Electric shock
KW  - Robots
KW  - Friction
DO  - 10.1109/IROS.2018.8594134
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The Axel rappelling rover was designed to enable access to intriguing and important science sites that lie in difficult terrains that are inaccessible to conventional rovers. Extended autonomous rappelling calls for careful control of tether tension, precise management of tether spooling, and some measure of shock tolerance. This paper covers the design and testing of a first-generation tether management system (TMS) for Axel. The system uses a double bull-wheel capstan driven by a low-stiffness series elastic actuator (SEA) to provide tension control and decouple internal spooling tension from external tether tension. A series elastic actuator was chosen for this application to permit closed-loop tether tension control and to provide shock/drop tolerance of the rappelling system both while moving and when the system is inactive with the motors locked. Experiments on the new TMS show that this design performs well in keeping nearly constant spooling tension while rejecting large dynamic disturbances at the output. While the SEA is very effective at maintaining a given tension contribution, the additional effects of friction and the unique mechanical properties of the tether result in substantial errors in the measured output tension. Upcoming field trials will be used to evaluate the effectiveness and sufficiency of this system when integrated in Axel.
ER  - 

TY  - CONF
TI  - Image Based Visual Servoing for Tumbling Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2901
EP  - 2908
AU  - P. Mithun
AU  - H. Pandya
AU  - A. Gaud
AU  - S. V. Shah
AU  - K. M. Krishna
PY  - 2018
KW  - feature extraction
KW  - image reconstruction
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - visual servoing
KW  - image based visual servoing
KW  - image plane
KW  - elliptical track
KW  - feature points
KW  - image space
KW  - feature error
KW  - explicit reconstruction
KW  - uncooperative tumbling object
KW  - robotic system
KW  - inertial axis
KW  - tumbling motion
KW  - Visual servoing
KW  - Cameras
KW  - Feature extraction
KW  - Estimation
KW  - Solid modeling
KW  - Satellites
DO  - 10.1109/IROS.2018.8594176
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Objects in space often exhibit a tumbling motion around the major inertial axis. In this paper, we address the image based visual servoing of a robotic system towards an uncooperative tumbling object. In contrast to previous approaches that require explicit reconstruction of the object and an estimation of its velocity, we propose a novel controller that is able to minimize the feature error directly in image space. This is achieved by observing that the feature points on the tumbling object follow a circular path around the axis of rotation and their projection creates an elliptical track in the image plane. Our controller minimizes the error between this elliptical track and the desired features, such that at the desired pose the features lie on the circumference of the ellipse. The effectiveness of our framework is exhibited by implementing the algorithm in simulation as well on a mobile robot.
ER  - 

TY  - CONF
TI  - Online Path Planning and Compliance Control of Space Robot for Capturing Tumbling Large Object
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2909
EP  - 2916
AU  - D. Hirano
AU  - H. Kato
AU  - T. Saito
PY  - 2018
KW  - aerospace control
KW  - aerospace robotics
KW  - compliance control
KW  - end effectors
KW  - force feedback
KW  - image capture
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - object recognition
KW  - path planning
KW  - position control
KW  - robot vision
KW  - robust control
KW  - compliance control
KW  - planned trajectory
KW  - moving grasping point
KW  - end-effector position error
KW  - end-effector motion
KW  - coordinated control
KW  - spacecraft base
KW  - robotic arm
KW  - online path planning
KW  - space robot
KW  - coordinated motion control
KW  - robust control scheme
KW  - end-effector trajectory
KW  - tumbling large object capturing
KW  - Grasping
KW  - End effectors
KW  - Robot kinematics
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594099
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the path planning and coordinated control of a space robot with a manipulator for capturing a rotating large object. As the grasping point on a rotating large object is translationally moving fast, an appropriate strategy and coordinated motion control of the spacecraft base and robotic arm must be employed for approaching and tracking such a grasping point. In this paper, we propose a robust control scheme including the online path planning and compliance control for grasping such a target. The path planning is derived in a simple form that allows the desired end-effector trajectory to be easily modified in real-time using the newly updated states without complex numerical calculation. In addition, the compliance control allows the end-effector to track the planned trajectory or the moving grasping point, while using contact force feedback to reduce the end-effector position error from the grasping point when capturing the target. This end-effector motion is implemented by coordinated control on the spacecraft base and robotic arm, which can suitably alter their distribution of motion according to scenes using a weighted pseudoinverse matrix. Experiments are conducted to demonstrate the validity of the proposed path planning and compliance control.
ER  - 

TY  - CONF
TI  - Workspace Aware Online Grasp Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2917
EP  - 2924
AU  - I. Akinola
AU  - J. Varley
AU  - B. Chen
AU  - P. K. Allen
PY  - 2018
KW  - end effectors
KW  - path planning
KW  - reachable end-effector configurations
KW  - unique end-effector poses
KW  - workspace aware online grasp planning
KW  - reachable grasps
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Measurement
KW  - Kinematics
KW  - Grasping
KW  - Databases
DO  - 10.1109/IROS.2018.8593644
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work provides a framework for a workspace aware online grasp planner. This framework greatly improves the performance of standard online grasp planning algorithms by incorporating a notion of reachability into the online grasp planning process. Offline, a database of hundreds of thousands of unique end-effector poses were queried for feasibility. At runtime, our grasp planner uses this database to bias the hand towards reachable end-effector configurations. The bias keeps the grasp planner in accessible regions of the planning scene so that the resulting grasps are tailored to the situation at hand. This results in a higher percentage of reachable grasps, a higher percentage of successful grasp executions, and a reduced planning time. We also present experimental results using simulated and real environments.
ER  - 

TY  - CONF
TI  - Robotic Grasping Using Proximity Sensors for Detecting both Target Object and Support Surface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2925
EP  - 2932
AU  - K. Sasaki
AU  - K. Koyama
AU  - A. Ming
AU  - M. Shimojo
AU  - R. Plateaux
AU  - J. Choley
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - manipulators
KW  - position control
KW  - robot vision
KW  - tactile sensors
KW  - support surface
KW  - target object
KW  - positioning
KW  - posturing
KW  - robotic grasping
KW  - proximity sensors
KW  - adequate relative posture
KW  - Grasping
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Visualization
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8594430
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The robustness of the positioning and posturing of robot hands relative to target object and support surface is an important issue for autonomous grasping. For example, to perform a grasping action such as picking up thin objects from a table top, the position and posture of the hand must be controlled to keep adequate relative posture and distance to the support surface besides those between the hand and the target object. Because slight errors in the posture and position are enough to cause grasping failure, the positioning and posturing of the hand must be precise enough, specially when the hand is close to the target object and support surface. To improve the robustness of robotic grasping, in this paper we present a method by grasping control based on the relative posture and position between hand and support surface besides those between hand and target object, using proximity sensors. Proximity sensors are newly installed on fingernails besides on the fingertips. As the fingernail sensor, an integration of Time-of-Flight (TOF) sensor and photo-reflector is designed to realize long range detection, as well as with precise and high-speed detection regardless of the reflectance of support surfaces when approaching the support surface. By the sensors, the hand can approach the object and support surface coarsely first, and then can be controlled fast and precisely to realize adequate grasping motion along the support surface but without contact with the support face. The method has been implemented to a manipulator system, and successful grasping experiments have demonstrated the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - Model-free and learning-free grasping by Local Contact Moment matching
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2933
EP  - 2940
AU  - M. Adjigble
AU  - N. Marturi
AU  - V. Ortenzi
AU  - V. Rajasekaran
AU  - P. Corke
AU  - R. Stolkin
PY  - 2018
KW  - dexterous manipulators
KW  - grippers
KW  - image matching
KW  - learning (artificial intelligence)
KW  - path planning
KW  - robot vision
KW  - local contact moment matching
KW  - LoCoMo metric
KW  - grasp planners
KW  - learning-based approaches
KW  - prototype grasp configurations
KW  - robust contacts
KW  - fingertip contacts
KW  - physical parameters
KW  - force-closure analysis
KW  - object surface patches
KW  - zero-moment shift features
KW  - learning-free grasping
KW  - Grasping
KW  - Robots
KW  - Measurement
KW  - Grippers
KW  - Shape
KW  - Three-dimensional displays
KW  - Training data
DO  - 10.1109/IROS.2018.8594226
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the problem of grasping arbitrarily shaped objects, observed as partial point-clouds, without requiring: models of the objects, physics parameters, training data, or other a-priori knowledge. A grasp metric is proposed based on Local Contact Moment (LoCoMo). LoCoMo combines zero-moment shift features, of both hand and object surface patches, to determine local similarity. This metric is then used to search for a set of feasible grasp poses with associated grasp likelihoods. LoCoMo overcomes some limitations of both classical grasp planners and learning-based approaches. Unlike force-closure analysis, LoCoMo does not require knowledge of physical parameters such as friction coefficients, and avoids assumptions about fingertip contacts, instead enabling robust contacts of large areas of hand and object surface. Unlike more recent learning-based approaches, LoCoMo does not require training data, and does not need any prototype grasp configurations to be taught by kinesthetic demonstration. We present results of real-robot experiments grasping 21 different objects, observed by a wrist-mounted depth camera. All objects are grasped successfully when presented to the robot individually. The robot also successfully clears cluttered heaps of objects by sequentially grasping and lifting objects until none remain.
ER  - 

TY  - CONF
TI  - A Framework for Robot Grasp Transferring with Non-rigid Transformation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2941
EP  - 2948
AU  - H. Lin
AU  - T. Tang
AU  - Y. Fan
AU  - M. Tomizuka
PY  - 2018
KW  - collision avoidance
KW  - control engineering computing
KW  - dexterous manipulators
KW  - grippers
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - path planning
KW  - orientation search
KW  - collision avoidance
KW  - grasp generation
KW  - dexterous tasks execution
KW  - online planning
KW  - grasp planning
KW  - robot grasp transferring
KW  - task requirements
KW  - robot reachability
KW  - grasp robustness
KW  - nonrigid transformation
KW  - human demonstration
KW  - analytic approach
KW  - Task analysis
KW  - Robots
KW  - Grasping
KW  - Planning
KW  - Collision avoidance
KW  - Grippers
KW  - Databases
DO  - 10.1109/IROS.2018.8593668
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasp planning is essential for robots to execute dexterous tasks. Solving the optimal grasps for various objects online, however, is challenging due to the heavy computation load during exhaustive sampling, and the difficulties to consider task requirements. This paper proposes a framework to combine analytic approach with learning for efficient grasp generation. The example grasps are taught by human demonstration and mapped to similar objects by a non-rigid transformation. The mapped grasps are evaluated analytically and refined by an orientation search to improve the grasp robustness and robot reachability. The proposed approach is able to plan high-quality grasps, avoid collision, satisfy task requirements, and achieve efficient online planning. The effectiveness of the proposed method is verified by a series of experiments.
ER  - 

TY  - CONF
TI  - Using human studies to analyze capabilities of underactuated and compliant hands in manipulation tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2949
EP  - 2954
AU  - J. Morrow
AU  - A. Kothari
AU  - Y. H. Ong
AU  - N. Harlan
AU  - R. Balasubramanian
AU  - C. Grimm
PY  - 2018
KW  - actuators
KW  - manipulators
KW  - human studies
KW  - underactuated hands
KW  - compliant hands
KW  - manipulation tasks
KW  - human-subjects
KW  - manipulation performance
KW  - robotic hands
KW  - compliance
KW  - compliant distal joints
KW  - task completion
KW  - different poses
KW  - superior task performance
KW  - fully-actuated techniques
KW  - actuation
KW  - robotic systems
KW  - Task analysis
KW  - Grasping
KW  - Robots
KW  - Spraying
KW  - Shape
KW  - Potentiometers
KW  - Rubber
DO  - 10.1109/IROS.2018.8594344
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a human-subjects study approach that supports the analysis of the manipulation performance of robotic hands that have the same morphology but different actuation and compliance. Specifically, we use this approach to analyze three different types of hands (one underactuated, one fully actuated, one fully actuated with compliant distal joints) as they are used to perform two manipulation tasks. The first task uses a power grasp (spraying with a spray bottle), the second a precision grasp (tracing a line on a bowl with a pen). We show that compliance in the distal joints significantly improves performance and task completion. We also show that humans choose significantly different poses for the same task when using a fully-actuated versus underactuated hand, which also results in superior task performance. Our results suggest that humans use a combination of under-actuated and fully-actuated techniques, which when used on robotic systems would also improve their performance on manipulation tasks.
ER  - 

TY  - CONF
TI  - Affordance Wayfields for Task and Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2955
EP  - 2962
AU  - T. McMahon
AU  - O. C. Jenkins
AU  - N. Amato
PY  - 2018
KW  - gradient methods
KW  - manipulators
KW  - path planning
KW  - manipulation affordances
KW  - affordance wayfields
KW  - motion planning
KW  - gradient descent
KW  - Michigan Progress Fetch mobile manipulator
KW  - Planning
KW  - Task analysis
KW  - End effectors
KW  - Trajectory
KW  - Cost function
DO  - 10.1109/IROS.2018.8594492
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Affordances provide a natural means for a robot to describe its agency as actions it can perform on objects. Further, affordances can enable robots to reason complicated, multi-step tasks that involve proper use of a diversity of objects. This paper proposes the concept of affordance wayfields for representing manipulation affordances as objective functions in configuration space. Affordance wayfields quantify how well a path, or sequence of motions, will accomplish an afforded action on an object. Paths that enact affordances can be located by performing a randomized form of gradient descent over affordance wayfields. Incorporating obstacles, or other constraints into wayfields allows our method to adaptively generate valid motions for executing afforded actions. We demonstrate that affordance wayfields can enable robots, such as the Michigan Progress Fetch mobile manipulator, to solve complex real-world tasks such as assembling a table, or loading and unloading objects from a storage chest.
ER  - 

TY  - CONF
TI  - Tactile Regrasp: Grasp Adjustments via Simulated Tactile Transformations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2963
EP  - 2970
AU  - F. R. Hogan
AU  - M. Bauza
AU  - O. Canal
AU  - E. Donlon
AU  - A. Rodriguez
PY  - 2018
KW  - convolutional neural nets
KW  - grippers
KW  - manipulators
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - tactile regrasp
KW  - simulated tactile transformations
KW  - tactile sensing
KW  - regrasp action
KW  - local transformations
KW  - grasp quality metric
KW  - deep convolutional neural network
KW  - rigid-body transformations
KW  - grasp quality network
KW  - grasp actions
KW  - tactile measurements
KW  - grasp adjustments
KW  - regrasp control policy
KW  - tactile imprints
KW  - robot motions
KW  - Grasping
KW  - Measurement
KW  - Tactile sensors
KW  - Grippers
DO  - 10.1109/IROS.2018.8593528
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel regrasp control policy that makes use of tactile sensing to plan local grasp adjustments. Our approach determines regrasp actions by virtually searching for local transformations of tactile measurements that improve the quality of the grasp. First, we construct a tactile-based grasp quality metric using a deep convolutional neural network trained on over 2800 grasps. The quality of each grasp, a continuous value between 0 and 1, is determined experimentally by measuring its resistance to external perturbations. Second, we simulate the tactile imprints associated with robot motions relative to the initial grasp by performing rigid-body transformations of the given tactile measurements. The newly generated tactile imprints are evaluated with the learned grasp quality network and the regrasp action is chosen to maximize the grasp quality. Results show that the grasp quality network can predict the outcome of grasps with an average accuracy of 85% on known objects and 75% on novel objects. The regrasp control policy improves the success rate of grasp actions by an average relative increase of 70% on a test set of 8 objects. We provide a video summarizing our approach at https://youtu.be/gjn7DmfpwDk.
ER  - 

TY  - CONF
TI  - Adaptive Autonomous Grasp Selection via Pairwise Ranking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2971
EP  - 2976
AU  - D. Kent
AU  - R. Toris
PY  - 2018
KW  - feature selection
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - object subsets
KW  - grasp selection algorithm
KW  - grasp metrics
KW  - object features
KW  - user-specified grasp preferences
KW  - pairwise ranking problem
KW  - pointwise ranking formulation
KW  - adaptive autonomous grasp selection
KW  - object databases
KW  - grasping strategies
KW  - robot pick-and-place applications
KW  - Measurement
KW  - Solid modeling
KW  - Training data
KW  - Three-dimensional displays
KW  - Databases
KW  - Training
KW  - Data models
DO  - 10.1109/IROS.2018.8594105
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous grasp selection for robot pick-and-place applications makes use of either empirical methods leveraging object databases, which generate grasps for specific objects at the initial cost of modeling effort, or analytical methods, which generalize to novel objects but fail on object subsets that require specific grasping strategies not captured by the algorithm. We introduce a grasp selection algorithm that ranks grasp candidates with a set of grasp metrics augmented with object features, creating an approach that adapts its strategies based on user-specified grasp preferences. We formulate grasp selection as a pairwise ranking problem, which significantly reduces data collection compared to traditional grasp ranking methods and generalizes to novel objects. Our approach outperforms a state-of-the-art grasp calculation baseline and a pointwise ranking formulation of the same problem.
ER  - 

TY  - CONF
TI  - Experience-Based Model Selection to Enable Long-Term, Safe Control for Repetitive Tasks Under Changing Conditions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2977
EP  - 2984
AU  - C. D. McKinnon
AU  - A. P. Schoellig
PY  - 2018
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - regression analysis
KW  - robot dynamics
KW  - learning approaches
KW  - significant performance improvements
KW  - robotic control
KW  - realistic scenarios
KW  - rapid changes
KW  - existing single-mode safe learning controller
KW  - increasing number
KW  - nonlinear models
KW  - robot dynamics
KW  - visited operating conditions
KW  - new operating condition
KW  - distinct operating condition
KW  - control loop
KW  - physical changes
KW  - artificial changes
KW  - experience-based model selection
KW  - enable long-term
KW  - safe control
KW  - repetitive tasks
KW  - Gaussian process regression
KW  - Robots
KW  - Vehicle dynamics
KW  - Safety
KW  - Heuristic algorithms
KW  - Data models
KW  - Computational modeling
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593882
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning approaches have enabled significant performance improvements in robotic control allowing robots to execute motions that were previously impossible. The majority of the work to date, however, assumes that the parts to be learned are static or slowly changing, which limits their applicability in realistic scenarios with rapid changes in the conditions. This paper presents a method to extend an existing single-mode safe learning controller based on Gaussian Process Regression to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experiences from a large number of previously visited operating conditions, and to safely adapt when a new and distinct operating condition is encountered. This allows the robot to achieve safety and high performance in a large number of operating conditions that do not have to be specified ahead of time. Our approach runs independently from the controller, imposing no additional computation time on the control loop regardless of the number of previous operating conditions considered. We demonstrate the effectiveness of our approach in experiment on a 900 kg ground robot with both physical and artificial changes to its dynamics. All of our experiments are conducted using vision for localization.
ER  - 

TY  - CONF
TI  - Efficient Model Identification for Tensegrity Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2985
EP  - 2990
AU  - S. Zhu
AU  - D. Surovik
AU  - K. Bekris
AU  - A. Boularias
PY  - 2018
KW  - Bayes methods
KW  - legged locomotion
KW  - optimisation
KW  - robot dynamics
KW  - Tensegrity locomotion
KW  - mechanical models
KW  - actuated robot links
KW  - dynamical robotic tasks
KW  - Bayesian optimization framework
KW  - high-dimensional Tensegrity robot
KW  - compliant Tensegrity robot
KW  - precise locomotion control
KW  - model identification
KW  - unknown physical parameters
KW  - physics engine
KW  - Robots
KW  - Engines
KW  - Optimization
KW  - Physics
KW  - Predictive models
KW  - Dimensionality reduction
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594425
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper aims to identify in a practical manner unknown physical parameters, such as mechanical models of actuated robot links, which are critical in dynamical robotic tasks. Key features include the use of an off-the-shelf physics engine and the Bayesian optimization framework. The task being considered is locomotion with a high-dimensional, compliant Tensegrity robot. A key insight, in this case, is the need to project the space of models into an appropriate lower dimensional space for time efficiency. Comparisons with alternatives indicate that the proposed method can identify the parameters more accurately within the given time budget, which also results in more precise locomotion control.
ER  - 

TY  - CONF
TI  - Robot-driven Trajectory Improvement for Feeding Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2991
EP  - 2996
AU  - T. Rhodes
AU  - M. Veloso
PY  - 2018
KW  - assisted living
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - mobile robots
KW  - path planning
KW  - search problems
KW  - trajectory control
KW  - robotic joints
KW  - kinesthetic learning
KW  - active learning
KW  - robot-driven trajectory improvement
KW  - assistive robotics
KW  - parameterized similar path search algorithm
KW  - PSPS
KW  - feeding tasks
KW  - computer programming
KW  - Trajectory
KW  - Task analysis
KW  - Robot kinematics
KW  - Cost function
KW  - Training
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593525
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Kinesthetic learning is a type of learning from demonstration in which the teacher manually moves the robot through the demonstrated trajectory. It shows great promise in the area of assistive robotics since it enables a caretaker who is not an expert in computer programming to communicate a novel task to an assistive robot. However, the trajectory the caretaker demonstrates to solve the task may be a high-cost trajectory for the robot. The demonstrated trajectory could be high-cost because the teacher does not know what trajectories are easy or hard for the robot to perform, which would be due to a limitation of the teacher's knowledge, or because the teacher has difficulty moving all the robotic joints precisely along the desired trajectories, which would be due to a limitation of the teacher's coordination. We propose the Parameterized Similar Path Search (PSPS) algorithm to extend kinesthetic learning so that a robot can improve the learned trajectory over a known cost function. This algorithm is based on active learning from the robot through collaboration between the robot's knowledge of the cost function and the caretaker's knowledge of the constraints of the assigned task.
ER  - 

TY  - CONF
TI  - Accelerating Learning in Constructive Predictive Frameworks with the Successor Representation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2997
EP  - 3003
AU  - C. Sherstan
AU  - M. C. Machado
AU  - P. M. Pilarski
PY  - 2018
KW  - computer aided instruction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot programming
KW  - unstructured environments
KW  - dynamic environments
KW  - reinforcement learning
KW  - predictive questions
KW  - massive network
KW  - interconnected GVFs
KW  - interdependent GVFs
KW  - SR
KW  - continual learning
KW  - physical robot arm
KW  - constructive predictive frameworks
KW  - constructive knowledge system
KW  - general value functions
KW  - successor representation
KW  - accelerated learning
KW  - Robots
KW  - Prediction algorithms
KW  - Function approximation
KW  - Acceleration
KW  - Approximation algorithms
KW  - Standards
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594242
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose using the Successor Representation (SR) to accelerate learning in a constructive knowledge system based on General Value Functions (GVFs). In real-world settings, like robotics for unstructured and dynamic environments, it is impossible to model all meaningful aspects of a system and its environment by hand. Instead, robots must learn and adapt to changes in their environment and task, incrementally constructing models from their own experience. GVFs, taken from the field of reinforcement learning (RL), are a way of modeling the world as predictive questions. One approach to such models proposes a massive network of interconnected and interdependent GVFs, which are incrementally added over time. It is reasonable to expect that new, incrementally added predictions can be learned more swiftly if the learning process leverages knowledge gained from past experience. The SR provides a means of capturing regularities that can be reused across multiple GVFs by separating the dynamics of the world from the prediction targets. As a primary contribution of this work, we show that using the SR can improve sample efficiency and learning speed of GVFs in a continual learning setting where new predictions are incrementally added and learned over time. We analyze our approach in a grid-world and then demonstrate its potential on data from a physical robot arm.
ER  - 

TY  - CONF
TI  - Reinforcement Learning with Symbolic Input-Output Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3004
EP  - 3009
AU  - E. Derner
AU  - J. Kubalík
AU  - R. Babuška
PY  - 2018
KW  - autoregressive processes
KW  - learning systems
KW  - optimal control
KW  - regression analysis
KW  - state-space methods
KW  - reinforcement learning
KW  - symbolic input-output models
KW  - dynamic prediction model
KW  - RL algorithms
KW  - nonlinear autoregressive with exogenous input
KW  - symbolic regression
KW  - parsimonious models
KW  - symbolic input-output process model
KW  - state-space models
KW  - Robots
KW  - Springs
KW  - Data models
KW  - Computational modeling
KW  - Optimal control
KW  - Reinforcement learning
KW  - Process control
KW  - Model learning
KW  - symbolic regression
KW  - reinforcement learning
KW  - optimal control
DO  - 10.1109/IROS.2018.8593881
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - It is well known that reinforcement learning (RL) can benefit from the use of a dynamic prediction model which is learned on data samples collected online from the process to be controlled. Most RL algorithms are formulated in the state-space domain and use state-space models. However, learning state-space models is difficult, mainly because in the vast majority of problems the full state cannot be measured on the system or reconstructed from the measurements. To circumvent this limitation, we propose to use input-output models of the NARX (nonlinear autoregressive with exogenous input) type. Symbolic regression is employed to construct parsimonious models and the corresponding value functions. Thanks to this approach, we can learn accurate models and compute optimal policies even from small amounts of training data. We demonstrate the approach on two simulated examples, a hopping robot and a 1-DOF robot arm, and on a real inverted pendulum system. Results show that our proposed method can reliably determine a good control policy based on a symbolic input-output process model and value function.
ER  - 

TY  - CONF
TI  - A Framework for Teaching Impedance Behaviours by Combining Human and Robot ‘Best Practice’
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3010
EP  - 3015
AU  - Y. Zhao
AU  - A. Sena
AU  - F. Wu
AU  - M. J. Howard
PY  - 2018
KW  - control engineering education
KW  - educational robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - muscle
KW  - robot dynamics
KW  - robot programming
KW  - human robot best practice
KW  - physical robot
KW  - teaching impedance
KW  - impedance modulation
KW  - human demonstrations
KW  - human stiffness
KW  - damping
KW  - muscle level
KW  - task demands
KW  - robotic systems
KW  - task critical component
KW  - robot-specific controller
KW  - variable impedance profile
KW  - Impedance
KW  - Task analysis
KW  - Damping
KW  - Modulation
KW  - Robot kinematics
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8593502
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a programming by demonstration framework for teaching impedance modulation using human demonstrations. Physiologically, human stiffness and damping are coupled at the muscle level, restricting the ability to modulate impedance according to task demands. Robotic systems often do not have this restriction (stiffness and damping can be varied independently), but the challenge is to devise an appropriate variable impedance profile for a given task. In this paper, the task critical component is first learned for imitation and a robot-specific controller is then blended into the control using the null space. In doing so, the control cheme takes advantage of both human and robot `best practice'. Experimental results on a physical robot suggest an order of magnitude better mean performance, with lower variance, can be achieved using the blended scheme.
ER  - 

TY  - CONF
TI  - Automated Tuning of Nonlinear Model Predictive Controller by Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3016
EP  - 3021
AU  - M. Mehndiratta
AU  - E. Camci
AU  - E. Kayacan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - nonlinear control systems
KW  - predictive control
KW  - trajectory control
KW  - nonlinear MPC
KW  - trajectory tracking control
KW  - aerial robots
KW  - NMPC weights
KW  - automated tuning
KW  - nonlinear model predictive controller
KW  - reinforcement learning
KW  - nontrivial weight tuning process
KW  - generic user-independent framework
KW  - trial-and-error method
KW  - iterative Gazebo simulations
KW  - standard desktop computer
KW  - Tuning
KW  - Rotors
KW  - Computational modeling
KW  - Optimization
KW  - Aerodynamics
KW  - Iron
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8594350
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the major challenges of model predictive control (MPC) for robotic applications is the non-trivial weight tuning process while crafting the objective function. This process is often executed using the trial-and-error method by the user. Consequently, the optimality of the weights and the time required for the process become highly dependent on the skill set and experience of the user. In this study, we present a generic and user-independent framework which automates the tuning process by reinforcement learning. The proposed method shows competency in tuning a nonlinear MPC (NMPC) which is employed for trajectory tracking control of aerial robots. It explores the desirable weights within less than an hour in iterative Gazebo simulations running on a standard desktop computer. The real world experiments illustrate that the NMPC weights explored by the proposed method result in a satisfactory trajectory tracking performance.
ER  - 

TY  - CONF
TI  - Soft-obstacle Avoidance for Redundant Manipulators with Recurrent Neural Network
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3022
EP  - 3027
AU  - Y. Li
AU  - B. Hannaford
PY  - 2018
KW  - biological tissues
KW  - collision avoidance
KW  - medical robotics
KW  - motion control
KW  - optimisation
KW  - recurrent neural nets
KW  - redundant manipulators
KW  - surgery
KW  - telerobotics
KW  - surgical trauma
KW  - safety motion constraints
KW  - soft-obstacle avoidance problem
KW  - redundant manipulators
KW  - recurrent neural network
KW  - human beings
KW  - teleoperated robots
KW  - robotic autonomy
KW  - soft tissues
KW  - surgical safety
KW  - robotic surgery
KW  - optimization problem
KW  - minimally invasive surgeries
KW  - Raven-II surgical robot
KW  - RNNs
KW  - Surgery
KW  - Manipulators
KW  - Task analysis
KW  - Collision avoidance
KW  - Recurrent neural networks
KW  - Optimization
KW  - Soft Obstacle Avoidance
KW  - Autonomous Robotic Surgery
KW  - Robot Arm
KW  - Recurrent Neural Network
DO  - 10.1109/IROS.2018.8594346
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Compressing soft-obstacles secondary to a controlled motion task is common for human beings. While these tasks are nearly trivial for teleoperated robots, they remain a challenging problem in robotic autonomy. Addressing the problem is significant. For example, in Minimally Invasive Surgeries (MISs), safely compressing soft tissues ensures the surgical safety and decreases tissue removal, thus dramatically decreases surgical trauma and operating room time, and leads to improved surgical outcomes. In this work, we define the problem of soft-obstacle avoidance and project the safety motion constraints into the task space and the velocity space. We illustrate the significance of addressing this problem in the robotic surgery scenario. We present a Recurrent Neural Networks (RNNs) based solution, which formulates the problem as an inequality constrained optimization problem and solves it in its dual space. The application of the proposed method was demonstrated in the Raven II surgical robot. Experimental results demonstrated that the proposed method is effective in addressing the soft-obstacle avoidance problem.
ER  - 

TY  - CONF
TI  - GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3044
EP  - 3051
AU  - N. Hirose
AU  - A. Sadeghian
AU  - M. Vázquez
AU  - P. Goebel
AU  - S. Savarese
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - stereo image processing
KW  - traversable places
KW  - traversable spaces
KW  - traversability estimation approaches
KW  - GONet
KW  - semisupervised deep learning approach
KW  - fisheye images
KW  - generative adversarial networks
KW  - GANs
KW  - stereo fisheye cameras
KW  - time 24.0 hour
KW  - Cameras
KW  - Estimation
KW  - Robot vision systems
KW  - Generators
KW  - Training
KW  - Gallium nitride
DO  - 10.1109/IROS.2018.8594031
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present semi-supervised deep learning approaches for traversability estimation from fisheye images. Our method, GONet, and the proposed extensions leverage Generative Adversarial Networks (GANs) to effectively predict whether the area seen in the input image(s) is safe for a robot to traverse. These methods are trained with many positive images of traversable places, but just a small set of negative images depicting blocked and unsafe areas. This makes the proposed methods practical. Positive examples can be collected easily by simply operating a robot through traversable spaces, while obtaining negative examples is time consuming, costly, and potentially dangerous. Through extensive experiments and several demonstrations, we show that the proposed traversability estimation approaches are robust and can generalize to unseen scenarios. Further, we demonstrate that our methods are memory efficient and fast, allowing for real-time operation on a mobile robot with single or stereo fisheye cameras. As part of our contributions, we open-source two new datasets for traversability estimation. These datasets are composed of approximately 24h of videos from more than 25 indoor environments. Our methods outperform baseline approaches for traversability estimation on these new datasets.
ER  - 

TY  - CONF
TI  - Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3052
EP  - 3059
AU  - M. Everett
AU  - Y. F. Chen
AU  - J. P. How
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - safe operation
KW  - deep reinforcement learning
KW  - complex interactions
KW  - environment increases
KW  - dynamic agents
KW  - particular behavior rules
KW  - arbitrary number
KW  - motion planning
KW  - decision-making agents
KW  - collision avoidance algorithms
KW  - Collision avoidance
KW  - Robots
KW  - Training
KW  - Decision making
KW  - Heuristic algorithms
KW  - Sensors
KW  - Navigation
DO  - 10.1109/IROS.2018.8593871
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.
ER  - 

TY  - CONF
TI  - Real-Time Workload Classification during Driving using HyperNetworks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3060
EP  - 3065
AU  - R. Wang
AU  - P. V. Amadori
AU  - Y. Demiris
PY  - 2018
KW  - cognition
KW  - medical signal processing
KW  - pattern classification
KW  - recurrent neural nets
KW  - signal classification
KW  - traffic engineering computing
KW  - m-HyperLSTM
KW  - mixture hyper long short term memory networks
KW  - cognitive demands
KW  - data variability
KW  - robotics
KW  - physiological signals
KW  - behavioral signals
KW  - human cognitive states
KW  - eye-gaze pattern dataset
KW  - HyperNetworks
KW  - real-time cognitive workload classification
KW  - sensor artefacts
KW  - Adaptation models
KW  - Data models
KW  - Physiology
KW  - Task analysis
KW  - Real-time systems
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594305
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks (m-HyperLSTM), a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9% precision and 87.8% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.
ER  - 

TY  - CONF
TI  - Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3066
EP  - 3073
AU  - A. Ajay
AU  - J. Wu
AU  - N. Fazeli
AU  - M. Bauza
AU  - L. P. Kaelbling
AU  - J. B. Tenenbaum
AU  - A. Rodriguez
PY  - 2018
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - state estimation
KW  - robot state estimation
KW  - planar pushing
KW  - ball bouncing
KW  - analytical rigid-body simulator
KW  - model uncertainty
KW  - symbolic simulators
KW  - stochastic neural networks
KW  - generalizable physical simulator
KW  - universal uncertainty estimates
KW  - analytical learned simulators
KW  - Gaussian processes
KW  - object trajectories
KW  - Analytical models
KW  - Predictive models
KW  - Physics
KW  - Data models
KW  - Uncertainty
KW  - Engines
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593995
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.
ER  - 

TY  - CONF
TI  - Learning to Pour using Deep Deterministic Policy Gradients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3074
EP  - 3079
AU  - C. Do
AU  - C. Gordillo
AU  - W. Burgard
PY  - 2018
KW  - learning (artificial intelligence)
KW  - robots
KW  - domestic environments
KW  - industrial environments
KW  - pre-defined heights
KW  - liquid dynamics
KW  - PR2 robot
KW  - learned policy
KW  - fundamental skill
KW  - deep deterministic policy gradients
KW  - liquid simulator
KW  - Liquids
KW  - Training
KW  - Task analysis
KW  - Reinforcement learning
KW  - Service robots
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593654
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pouring is a fundamental skill for robots in both domestic and industrial environments. Ideally, a robot should be able to pour with high accuracy to specific, pre-defined heights and without spilling. However, due to the complex dynamics of liquids, it is difficult to learn how to pour to achieve these goals. In this paper we present an approach to learn a policy for pouring using Deep Deterministic Policy Gradients (DDPG). We remove the need for collecting training experiences on a real robot, by using a state-of-the-art liquid simulator, which allows for learning the liquid dynamics. We show through our experiments, performed with a PR2 robot, that it is possible to successfully transfer the learned policy to a real robot and even apply it to different liquids.
ER  - 

TY  - CONF
TI  - Learning Sample-Efficient Target Reaching for Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3080
EP  - 3087
AU  - A. Khan
AU  - V. Kumar
AU  - A. Ribeiro
PY  - 2018
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - self-supervised policy gradient algorithm
KW  - unsupervised auxiliary tasks
KW  - sparse range-finder measurements
KW  - convolutional networks
KW  - network architecture
KW  - sparse reward problem
KW  - robots uncertainty
KW  - unsupervised tasks
KW  - mobile robots
KW  - planning problem
KW  - sample-efficient target reaching learning
KW  - Task analysis
KW  - Robot sensing systems
KW  - Planning
KW  - Encoding
KW  - Uncertainty
KW  - Training
DO  - 10.1109/IROS.2018.8594168
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel architecture and a self-supervised policy gradient algorithm, which employs unsupervised auxiliary tasks to enable a mobile robot to learn how to navigate to a given goal. The dependency on the global information is eliminated by providing only sparse range-finder measurements to the robot. The partially observable planning problem is addressed by splitting it into a hierarchical process. We use convolutional networks to plan locally, and a differentiable memory to provide information about past time steps in the trajectory. These modules, combined in our network architecture, produce globally consistent plans. The sparse reward problem is mitigated by our modified policy gradient algorithm. We model the robots uncertainty with unsupervised tasks to force exploration. The novel architecture we propose with the modified version of the policy gradient algorithm allows our robot to reach the goal in a sample efficient manner, which is orders of magnitude faster than the current state of the art policy gradient algorithm. Simulation and experimental results are provided to validate the proposed approach.
ER  - 

TY  - CONF
TI  - Generative Modeling of Multimodal Multi-Human Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3088
EP  - 3095
AU  - B. Ivanovic
AU  - E. Schmerling
AU  - K. Leung
AU  - M. Pavone
PY  - 2018
KW  - approximation theory
KW  - behavioural sciences computing
KW  - bin packing
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - statistical distributions
KW  - deep learning approximations
KW  - probabilistic graphical models
KW  - candidate future agent behavior
KW  - crowded environments
KW  - human-driven vehicles
KW  - human-robot collaborative bin packing
KW  - multimodal probability distribution
KW  - multihuman interactions
KW  - basketball player trajectories
KW  - multimodal multihuman behavior
KW  - self-driving cars
KW  - warehouse
KW  - autoencoders
KW  - response dynamics
KW  - robotic applications
KW  - proxy
KW  - Trajectory
KW  - Predictive models
KW  - Analytical models
KW  - Deep learning
KW  - Ground penetrating radar
KW  - Data models
KW  - Robots
DO  - 10.1109/IROS.2018.8594393
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.
ER  - 

TY  - CONF
TI  - Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3096
EP  - 3101
AU  - K. Chaudhary
AU  - K. Okada
AU  - M. Inaba
AU  - X. Chen
PY  - 2018
KW  - convolutional neural nets
KW  - image fusion
KW  - learning (artificial intelligence)
KW  - convolutional network
KW  - part affordances
KW  - object affordances
KW  - affordance detection network
KW  - physical properties
KW  - geometrical structures
KW  - two-stream fully convolutional network
KW  - potential affordances
KW  - multimodal encoding
KW  - geometrical properties
KW  - abstract rich photometrical properties
KW  - depth images
KW  - powerful discriminative features
KW  - decoding stream
KW  - encoding streams
KW  - RGB-D data
KW  - Feature extraction
KW  - Encoding
KW  - Task analysis
KW  - Robots
KW  - Streaming media
KW  - Decoding
KW  - Fuses
KW  - Affordance detection network (ADNet)
KW  - fully convolutional network (FCN)
DO  - 10.1109/IROS.2018.8593617
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For a robot to manipulate an object, it has to understand the functions and the actions that can be subjected to the object. This set of information is known as affordance of the object. Affordances are generally defined by the geometrical structures and physical properties of the objects. In this paper, we present an affordance detection network (ADNet) for detecting object affordances using multimodal input i.e., RGB-D data. The method is based on the state-of-the-art fully convolutional network with two encoding streams and one decoding stream. In the presented formulation, the network learns powerful discriminative features independently from the RGB and depth images, which enables it to abstract rich photometrical and geometrical properties of the objects. The multimodal encoding is combined at multiple stages of the network using the late-fusion strategy and used is for predicting the potential affordances of the objects.
ER  - 

TY  - CONF
TI  - Deep Multi-Sensor Lane Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3102
EP  - 3109
AU  - M. Bai
AU  - G. Mattyus
AU  - N. Homayounfar
AU  - S. Wang
AU  - S. K. Lakshmikanth
AU  - R. Urtasun
PY  - 2018
KW  - driver information systems
KW  - image sensors
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - road traffic
KW  - multisensor lane detection
KW  - reliable lane detection
KW  - accurate lane detection
KW  - long-standing problem
KW  - autonomous driving
KW  - image space
KW  - accurate image estimates
KW  - precise 3D lane boundaries
KW  - modern motion planning algorithms
KW  - deep neural network
KW  - camera sensors
KW  - accurate estimates
KW  - LiDAR
KW  - Cameras
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Sensors
KW  - Roads
KW  - Task analysis
KW  - Reliability
DO  - 10.1109/IROS.2018.8594388
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable and accurate lane detection has been a long-standing problem in the field of autonomous driving. In recent years, many approaches have been developed that use images (or videos) as input and reason in image space. In this paper we argue that accurate image estimates do not translate to precise 3D lane boundaries, which are the input required by modern motion planning algorithms. To address this issue, we propose a novel deep neural network that takes advantage of both LiDAR and camera sensors and produces very accurate estimates directly in 3D space. We demonstrate the performance of our approach on both highways and in cities, and show very accurate estimates in complex scenarios such as heavy traffic (which produces occlusion), fork, merges and intersections.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3110
EP  - 3116
AU  - X. Chen
AU  - A. Ghadirzadeh
AU  - J. Folkesson
AU  - M. Björkman
AU  - P. Jensfelt
PY  - 2018
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - path planning
KW  - robot vision
KW  - wheels
KW  - navigation skills
KW  - navigation behaviors
KW  - action policies training
KW  - height-map image observations
KW  - motor commands
KW  - dynamic environments
KW  - mobile robot navigation
KW  - complex environments
KW  - deep reinforcement learning
KW  - wheel-legged robots
KW  - Training
KW  - Task analysis
KW  - Navigation
KW  - Mobile robots
KW  - Trajectory
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593702
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robot navigation in complex and dynamic environments is a challenging but important problem. Reinforcement learning approaches fail to solve these tasks efficiently due to reward sparsities, temporal complexities and high-dimensionality of sensorimotor spaces which are inherent in such problems. We present a novel approach to train action policies to acquire navigation skills for wheel-legged robots using deep reinforcement learning. The policy maps height-map image observations to motor commands to navigate to a target position while avoiding obstacles. We propose to acquire the multifaceted navigation skill by learning and exploiting a number of manageable navigation behaviors. We also introduce a domain randomization technique to improve the versatility of the training samples. We demonstrate experimentally a significant improvement in terms of data-efficiency, success rate, robustness against irrelevant sensory data, and also the quality of the maneuver skills.
ER  - 

TY  - CONF
TI  - Learning and Generalization of Dynamic Movement Primitives by Hierarchical Deep Reinforcement Learning from Demonstration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3117
EP  - 3123
AU  - W. Kim
AU  - C. Lee
AU  - H. J. Kim
PY  - 2018
KW  - grippers
KW  - learning (artificial intelligence)
KW  - nonlinear differential equations
KW  - meta-controller
KW  - learning generalization
KW  - dynamic movement primitives
KW  - hierarchical deep reinforcement learning
KW  - nonlinear differential equation
KW  - observed movement
KW  - hierarchical strategy
KW  - hierarchical deep RL
KW  - DMP framework
KW  - 6-degree-of-freedom arm
KW  - deterministic actor-critic algorithm
KW  - robotic skill learning
KW  - Task analysis
KW  - Robots
KW  - Reinforcement learning
KW  - Mathematical model
KW  - Differential equations
KW  - Dynamics
KW  - Deep learning
DO  - 10.1109/IROS.2018.8594476
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an approach to learn and generalize robotic skills from a demonstration using deep reinforcement learning (deep RL). Dynamic Movement Primitives (DMPs) formulate a nonlinear differential equation and produce the observed movement from a demonstration. However, it is hard to generate new behaviors from using DMPs. Thus, we apply DMPs framework into deep RL as an initial setting for learning the robotic skills. First, we build a network to represent this differential equation, and learn and generalize the movements by optimizing the shape of DMPs with respect to the rewards up to the end of each sequence of movement primitives. In order to do this, we consider a deterministic actor-critic algorithm for deep RL and we also apply a hierarchical strategy. This drastically reduces the search space for a robot by decomposing the task, which allows to solve the sparse reward problem from a complex task. In order to integrate DMPs with hierarchical deep RL, the differential equation is considered as temporal abstraction of option. The overall structure is mainly composed of two controllers: meta-controller and sub-controller. The meta-controller learns a policy over intrinsic goals and a sub-controller learns a policy over actions to accomplish the given goals. We demonstrate our approach on a 6 degree-of-freedom (DOF) arm with a I-DOF gripper and evaluate our approach through a pick-and-place task.
ER  - 

TY  - CONF
TI  - Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3124
EP  - 3129
AU  - S. Hosseinzadeh
AU  - M. Shakeri
AU  - H. Zhang
PY  - 2018
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - statistical analysis
KW  - support vector machines
KW  - patched convolutional neural network
KW  - semantic-aware patch-level convolutional neural network
KW  - statistical features
KW  - multiclass support vector machine
KW  - deep learning framework
KW  - robotic applications
KW  - vision systems
KW  - shadow detection methods
KW  - Image color analysis
KW  - Image edge detection
KW  - Support vector machines
KW  - Robots
KW  - Image segmentation
KW  - Training
KW  - Time complexity
DO  - 10.1109/IROS.2018.8594050
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In recent years, various shadow detection methods from a single image have been proposed and used in vision systems; however, most of them are not appropriate for the robotic applications due to the expensive time complexity. This paper introduces a fast shadow detection method using a deep learning framework, with a time cost that is appropriate for robotic applications. In our solution, we first obtain a shadow prior map with the help of multi-class support vector machine using statistical features. Then, we use a semantic-aware patch-level Convolutional Neural Network that efficiently trains on shadow examples by combining the original image and the shadow prior map. Experiments on benchmark datasets demonstrate the proposed method significantly decreases the time complexity of shadow detection, by one or two orders of magnitude compared with state-of-the-art methods, without losing accuracy.
ER  - 

TY  - CONF
TI  - Robust Decentralized Context-Aware Sensor Fault Detection with In-Place Self-Calibration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3130
EP  - 3136
AU  - J. L. Paneque
AU  - J. R. Martinez-Dedios
AU  - A. Ollero
PY  - 2018
KW  - Bayes methods
KW  - calibration
KW  - fault diagnosis
KW  - hidden Markov models
KW  - sensors
KW  - statistical analysis
KW  - complex context information
KW  - decentralized RANSAC
KW  - Bayesian networks
KW  - uncalibrated sensor
KW  - hidden Markov models
KW  - robust decentralized context-aware sensor fault detection methods
KW  - industrial plants
KW  - in-place sensor self-recalibration capability
KW  - consensus-based modeling step
KW  - statistical analysis
KW  - network topology
KW  - complex dynamic systems
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Computational modeling
KW  - Monitoring
KW  - Temperature measurement
KW  - Bayes methods
KW  - Analytical models
DO  - 10.1109/IROS.2018.8593680
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There is a high demand in advanced fault detection methods suitable for sensor networks monitoring complex dynamic systems such as industrial plants or large infrastructure units. This paper proposes a robust and efficient decentralized sensor fault detection method with in-place sensor self-recalibration capability that extracts and uses complex context information referred to the full monitored process. The method includes three main components, all decentralized and sharing the same statistical framework: 1) a consensus-based modeling step based on decentralized RANSAC; 2) a statistical analysis based on Bayesian networks and Hidden Markov Models in which each sensor identifies inconsistencies with the consensus model and determines if it is correctly calibrated, uncalibrated or faulty and; 3) a final step in which each uncalibrated sensor self-recalibrates using the consensus model. The proposed method is efficient in the use of computational and communicational resources, it is scalable and robust against outliers, transmission errors, sensor failures and network topology changes. It has been extensively validated in an experimental industrial setting.
ER  - 

TY  - CONF
TI  - Heterogeneous Sensor-Robot Team Positioning and Mixed Strategy Scheduling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3137
EP  - 3144
AU  - B. T. Hartman
AU  - R. D. Tatum
AU  - M. J. Bays
PY  - 2018
KW  - game theory
KW  - multi-robot systems
KW  - scheduling
KW  - sensor placement
KW  - simulated annealing
KW  - heterogeneous sensor-robot team positioning
KW  - mixed strategy scheduling
KW  - effector robots
KW  - anticipated arrival traffic
KW  - adversarial game
KW  - sensor positions
KW  - anticipated potential arrival paths
KW  - uniform power schedule
KW  - adaptive simulated annealing
KW  - Robot sensing systems
KW  - Schedules
KW  - Robot kinematics
KW  - Games
KW  - Linear programming
DO  - 10.1109/IROS.2018.8594263
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We are faced with the problem of optimally placing a heterogeneous team of sensors and effector robots in an area while taking into account the environment, anticipated arrival traffic, and desired power consumption of the team. We stage the problems of anticipating arrival traffic and determining a proper power schedule as an adversarial game, incorporating our analysis of the game in the objective function which evaluates sensor positions. We obtain the set of sensor positions which performs best at the desired power consumption, evaluating the mixed strategy of sensor activity that best counters the anticipated potential arrival paths. To determine an approximate global optima for a large number of heterogeneous nodes, we employ Adaptive Simulated Annealing (ASA) to ensure our algorithm is flexible over a varied range of scenarios. We compare the proposed algorithm to a gradient-based greedy placement algorithm with a uniform power schedule within simulation.
ER  - 

TY  - CONF
TI  - Robotic Subsurface Pipeline Mapping with a Ground-penetrating Radar and a Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3145
EP  - 3150
AU  - H. Li
AU  - C. Chou
AU  - L. Fan
AU  - B. Li
AU  - D. Wang
AU  - D. Song
PY  - 2018
KW  - buried object detection
KW  - geophysical image processing
KW  - geophysical techniques
KW  - ground penetrating radar
KW  - image reconstruction
KW  - maximum likelihood estimation
KW  - pipelines
KW  - radar detection
KW  - radar imaging
KW  - robot vision
KW  - pipeline groups
KW  - hyperbola response
KW  - GPR sensing process
KW  - Ground Penetrating Radar scans
KW  - subsurface pipeline mapping method
KW  - robotic subsurface pipeline mapping
KW  - subsurface pipes
KW  - representative pipeline configurations
KW  - maximum likelihood estimation
KW  - J-Linkage method
KW  - hyperbolas
KW  - GPR scans
KW  - mapping outputs
KW  - visual simultaneous localization
KW  - nonperpendicular angles
KW  - general scanning
KW  - size 4.69 cm
KW  - Ground penetrating radar
KW  - Pipelines
KW  - Cameras
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594006
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel subsurface pipeline mapping method by fusing Ground Penetrating Radar (GPR) scans and camera images. To facilitate the simultaneous detection of multiple pipelines, we model the GPR sensing process and prove hyperbola response for general scanning with non-perpendicular angles. Furthermore, we fuse visual simultaneous localization and mapping outputs, encoder readings with GPR scans to classify hyperbolas into different pipeline groups. We extensively apply the J-Linkage method and maximum likelihood estimation to improve algorithm robustness and accuracy. As the result, we optimally estimate the radii and locations of all pipelines. We have implemented our method and tested it in physical experiments with representative pipeline configurations. The results show that our method successfully reconstructs all subsurface pipes. Moreover, the average localization error is 4.69cm.
ER  - 

TY  - CONF
TI  - UAV Based Wireless Charging of Sensor Networks Without Prior Knowledge
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3151
EP  - 3158
AU  - N. W. Najeeb
AU  - C. Detweiler
PY  - 2018
KW  - autonomous aerial vehicles
KW  - wireless sensor networks
KW  - Power Transfer Efficiency Compensation
KW  - efficiency drops
KW  - real-world power transfer scenarios
KW  - knowledge algorithm
KW  - maximum power transfer efficiency
KW  - constant maximum efficiency CPTEC
KW  - UAV based Wireless Charging
KW  - Unmanned Aerial Vehicles
KW  - Wireless Rechargeable Sensor Networks
KW  - charging efficiency
KW  - wireless transmitter
KW  - charged node
KW  - sensor nodes
KW  - power information
KW  - limits scalability
KW  - wireless receiver
KW  - power level increase
KW  - power level increase
KW  - Robot sensing systems
KW  - Unmanned aerial vehicles
KW  - Wireless sensor networks
KW  - Wireless communication
KW  - Receivers
KW  - Wireless power transfer
DO  - 10.1109/IROS.2018.8594255
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unmanned Aerial Vehicles (UAVs) can charge Wireless Rechargeable Sensor Networks (WRSNs) in remote or hard to access locations. However, the charging efficiency is heavily affected by the distance between the wireless transmitter and receiver. This efficiency impacts the possible power level increase of each charged node. Most charging algorithms require full knowledge of sensor nodes' power levels to identify the nodes to charge. Collecting this power information adds overhead to the network and limits scalability. We propose and implement Charging with Power Transfer Efficiency Compensation (CPTEC), an algorithm that charges a WRSN without the need for a priori knowledge of the nodes' power levels. We show that CPTEC compensates for efficiency drops, due to landing alignments, making it practical for real-world power transfer scenarios. Our results show that CPTEC is able to perform with a median at ≈ 72% of the optimal performance of a full knowledge algorithm that assumes maximum power transfer efficiency, while other work drops to ≈ 22%. Under constant maximum efficiency CPTEC performs ≈ 90% of the optimal full knowledge case.
ER  - 

TY  - CONF
TI  - Mobile Robot Localization Considering Class of Sensor Observations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3159
EP  - 3166
AU  - N. Akai
AU  - L. Y. Morales
AU  - H. Murase
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - localization robustness
KW  - environment dynamics
KW  - robots
KW  - sensor observations
KW  - mapped obstacles
KW  - observation model
KW  - unmapped obstacles
KW  - real-world mobile robot navigation competition
KW  - mobile robot localization
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Robustness
KW  - Hidden Markov models
KW  - Mobile robots
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594146
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Localization robustness against environment dynamics is significant for robots to achieve autonomous navigation in unmodified environments. A basic method of improving the robustness of a robot is considering the sensor observations obtained from mapped obstacles and using them for localizing the robot's pose. This study proposes an observation model that considers the class of sensor observations, where “class” categorizes the sensor observations as those obtained from mapped and unmapped obstacles. In the proposed approach, the robot's pose and the class are estimated simultaneously. As a result, the robot's pose can be localized using the sensor observations obtained only from mapped obstacles. First, we evaluated the performance of the proposed approach using simulations. Further, we tested the proposed approach in a real-world mobile robot navigation competition, called “Tsukuba Challenge,” held in Japan. The robustness and effectiveness of the proposed approach against environment dynamics were verified from the experimental results.
ER  - 

TY  - CONF
TI  - Robust Odometry using Sensor Consensus Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3167
EP  - 3173
AU  - A. W. Palmer
AU  - N. Nourani-Vatani
PY  - 2018
KW  - calibration
KW  - distance measurement
KW  - Kalman filters
KW  - measurement uncertainty
KW  - nonlinear filters
KW  - sensors
KW  - statistical testing
KW  - odometry system
KW  - measurement pre-processing stage
KW  - sensor consensus analysis
KW  - German Intercity-Express highspeed trains
KW  - wheel slip
KW  - autonomous systems
KW  - rail industry
KW  - extended Kalman filter
KW  - automatic train protection systems
KW  - incorrect velocity estimation
KW  - robust odometry systems
KW  - wheel encoder miscalibration
KW  - wheel slippage
KW  - wheel encoder calibration
KW  - SCA
KW  - statistical z-testing
KW  - measurement uncertainty
KW  - Wheels
KW  - Robot sensing systems
KW  - Acceleration
KW  - Measurement uncertainty
KW  - Global Positioning System
KW  - Extraterrestrial measurements
KW  - Length measurement
DO  - 10.1109/IROS.2018.8594473
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Odometry forms an important component of many manned and autonomous systems. In the rail industry in particular, having precise and robust odometry is crucial for the correct operation of the Automatic Train Protection systems that ensure the safety of high-speed trains in operation around the world. Two problems commonly encountered in such odometry systems are miscalibration of the wheel encoders and slippage of the wheels under acceleration and braking, resulting in incorrect velocity estimates. This paper introduces an odometry system that addresses these problems. It comprises of an Extended Kalman Filter that tracks the calibration of the wheel encoders as state variables, and a measurement pre-processing stage called Sensor Consensus Analysis (SCA) that scales the uncertainty of a measurement based on how consistent it is with the measurements from the other sensors. SCA uses the statistical z-test to determine when an individual measurement is inconsistent with the other measurements, and scales the uncertainty until the z-test passes. This system is demonstrated on data from German Intercity-Express highspeed trains and it is shown to successfully deal with errors due to miscalibration and wheel slip.
ER  - 

TY  - CONF
TI  - Octree map based on sparse point cloud and heuristic probability distribution for labeled images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3174
EP  - 3181
AU  - J. S. Berrio
AU  - W. Zhou
AU  - J. Ward
AU  - S. Worrall
AU  - E. Nebot
PY  - 2018
KW  - calibration
KW  - cameras
KW  - convolutional neural nets
KW  - image recognition
KW  - object recognition
KW  - octrees
KW  - probability
KW  - stereo image processing
KW  - semantic octree maps
KW  - probabilistic octree framework
KW  - single lidar scans
KW  - octree map building algorithm
KW  - labeled lidar scan
KW  - camera-lidar calibration parameters
KW  - convolutional neural network
KW  - accurate driving maneuvers
KW  - automated vehicle
KW  - urban roads
KW  - labeled images
KW  - heuristic probability distribution
KW  - sparse point cloud
KW  - Three-dimensional displays
KW  - Semantics
KW  - Laser radar
KW  - Uncertainty
KW  - Octrees
KW  - Cameras
KW  - Buildings
DO  - 10.1109/IROS.2018.8594024
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To navigate through urban roads, an automated vehicle must be able to perceive and recognize objects in a three-dimensional environment. A high level contextual understanding of the surroundings is necessary to execute accurate driving maneuvers. This paper presents a novel approach to build three dimensional semantic octree maps from lidar scans and the output of a convolutional neural network (CNN) to obtain the labels of the environment. We present a heuristic method to associate uncertainties to the labels from the images based on a combination of the labels themselves, score maps retrieved by the CNN and the raw images. These uncertainties and the camera-lidar calibration parameters for multiple cameras are considered in the projection of the labels and their uncertainties into the point cloud. Every labeled lidar scan works as an input to an octree map building algorithm that calculates and updates the label probabilities of the voxels in the map. This paper also presents a qualitative and quantitative evaluation of accuracy, analyzing projection in single lidar scans and complete maps built with our probabilistic octree framework.
ER  - 


TY  - CONF
TI  - Human-in-the-loop Augmented Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3190
EP  - 3195
AU  - A. Sidaoui
AU  - I. H. Elhajj
AU  - D. Asmar
PY  - 2018
KW  - inertial systems
KW  - mobile robots
KW  - operating systems (computers)
KW  - optical radar
KW  - path planning
KW  - robot programming
KW  - user interfaces
KW  - 2D map building
KW  - user interface
KW  - human map augmentation
KW  - LIDAR
KW  - Gmapping ROS package
KW  - Unity software
KW  - online editing capabilities
KW  - user-friendly system
KW  - traditional offline post processing
KW  - real-time human augmented mapping system
KW  - human-in-the-loop
KW  - mapping errors
KW  - Two dimensional displays
KW  - Laser radar
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Corporate acquisitions
DO  - 10.1109/IROS.2018.8594494
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we develop a real-time human augmented mapping system. This approach replaces the traditional offline post processing of maps by a user-friendly system allowing for online editing capabilities. A wide number of applications that acquire accurate mapping of the environment could benefit from such a solution. The proposed framework consists of two main parts: 2D map building using LIDAR, encoders, and IMU; and a user interface for human map augmentation. The first part is built over Gmapping ROS package, while the second is developed in Unity software. Realworld experiments validated the ability of our system to correct for sensor noise and various mapping errors, thus increasing the accuracy of the obtained maps without additional computational costs.
ER  - 

TY  - CONF
TI  - VLASE: Vehicle Localization by Aggregating Semantic Edges
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3196
EP  - 3203
AU  - X. Yu
AU  - S. Chaturvedi
AU  - C. Feng
AU  - Y. Taguchi
AU  - T. Lee
AU  - C. Fernandes
AU  - S. Ramalingam
PY  - 2018
KW  - feature extraction
KW  - geographic information systems
KW  - image retrieval
KW  - image segmentation
KW  - road vehicles
KW  - traffic information systems
KW  - semantic edge features
KW  - edge contours
KW  - building-sky
KW  - state-of-the-art localization algorithms
KW  - individual prominent features
KW  - VLASE
KW  - vehicle localization
KW  - on-road localization
KW  - semantic classes
KW  - VLAD framework
KW  - image retrieval
KW  - SIFT-VLAD
KW  - NetVLAD
KW  - SLC Marathon dataset
KW  - Salt Lake city
KW  - lighting variations
KW  - Semantics
KW  - Image edge detection
KW  - Feature extraction
KW  - Buildings
KW  - Databases
KW  - Visualization
KW  - Urban areas
DO  - 10.1109/IROS.2018.8594358
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose VLASE, a framework to use semantic edge features from images to achieve on-road localization. Semantic edge features denote edge contours that separate pairs of distinct objects such as building-sky, road-sidewalk, and building-ground. While prior work has shown promising results by utilizing the boundary between prominent classes such as sky and building using skylines, we generalize this to consider 19 semantic classes. We extract semantic edge features using CASENet architecture and utilize VLAD framework to perform image retrieval. We achieve improvement over state-of-the-art localization algorithms such as SIFT-VLAD and its deep variant NetVLAD. Ablation study shows the importance of different semantic classes, and our unified approach achieves better performance compared to individual prominent features such as skylines. We also introduce SLC Marathon dataset, a challenging dataset covering most of Salt Lake City with sufficient lighting variations.
ER  - 

TY  - CONF
TI  - A B-Spline Mapping Framework for Long-Term Autonomous Operations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3204
EP  - 3209
AU  - R. T. Rodrigues
AU  - A. P. Aguiar
AU  - A. Pascoal
PY  - 2018
KW  - image representation
KW  - image sensors
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - splines (mathematics)
KW  - landmark-based maps
KW  - robotics community
KW  - high frequency sensor
KW  - B-spline curves
KW  - B-spline maps
KW  - mapping algorithm
KW  - 2D B-spline mapping framework
KW  - outdoor long-term autonomous operations
KW  - simultaneous localization and mapping
KW  - SLAM algorithm
KW  - software-in-the-loop simulations
KW  - Splines (mathematics)
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594456
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.
ER  - 

TY  - CONF
TI  - Building Dense Reflectance Maps of Indoor Environments Using an RGB-D Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3210
EP  - 3217
AU  - M. Krawez
AU  - T. Caselitz
AU  - D. Büscher
AU  - M. Van Loock
AU  - W. Burgard
PY  - 2018
KW  - brightness
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - lighting conditions
KW  - light emitters
KW  - high dynamic range radiosity estimation
KW  - reflectance estimate
KW  - diffuse reflectance
KW  - specific lighting condition
KW  - colored models
KW  - extensive progress
KW  - RGB-D cameras
KW  - dense surface geometry
KW  - robotic applications
KW  - indoor environments
KW  - building dense reflectance maps
KW  - Cameras
KW  - Lighting
KW  - Image reconstruction
KW  - Robots
KW  - Geometry
KW  - Indoor environments
KW  - Surface treatment
DO  - 10.1109/IROS.2018.8594107
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The ability to build models of the environment is an essential prerequisite for many robotic applications. In recent years, mapping of dense surface geometry using RGB-D cameras has seen extensive progress. Many approaches build colored models, typically directly using the intensity values provided by the camera. Unfortunately, these intensities are inherently affected by illumination. Therefore, the resulting maps only represent the environment for one specific lighting condition. To overcome this limitation, we propose to build reflectance maps that are invariant against changes in lighting. Our approach estimates the diffuse reflectance of a surface by recovering its radiosity and the corresponding irradiance. As imperfections in this process can significantly degrade the reflectance estimate, we remove outliers in the high dynamic range radiosity estimation and propose a method to refine the reflectance estimate. Our system implements the whole pipeline for offline reconstruction of dense reflectance maps including the segmentation of light emitters in the scene. We demonstrate the applicability of our approach in real-world experiments under varying lighting conditions.
ER  - 

TY  - CONF
TI  - 3D Underground Mapping with a Mobile Robot and a GPR Antenna
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3218
EP  - 3224
AU  - G. Kouros
AU  - I. Kotavelis
AU  - E. Skartados
AU  - D. Giakoumis
AU  - D. Tzovaras
AU  - A. Simi
AU  - G. Manacorda
PY  - 2018
KW  - feature extraction
KW  - ground penetrating radar
KW  - image matching
KW  - image segmentation
KW  - mobile robots
KW  - radar imaging
KW  - underground robotic applications
KW  - image processing techniques
KW  - subsurface 3D map
KW  - Ground Penetrating Radar
KW  - construction services
KW  - automatic subsurface mapping
KW  - GPR antenna
KW  - mobile robot
KW  - underground mapping
KW  - Ground penetrating radar
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Mobile antennas
KW  - Mobile robots
KW  - Antenna measurements
DO  - 10.1109/IROS.2018.8593848
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Automatic subsurface mapping is essential in the construction services, as it is anticipated to become the main operational environment of the future robots to be realized in the respective domain. Towards this direction, the paper at hand, introduces for the first time herein, an integrated framework for subsurface mapping by exploiting a surface operating mobile robot with a Ground Penetrating Radar (GPR). The mobile robot tows the GPR antenna, which is mounted on a specifically designed trailer, and is utilized as the mean to cover the surface area, while at the same time the antenna scans the subsurface by emitting electromagnetic pulses. The gathered data are processed for the construction of a subsurface 3D map. Specifically, image processing techniques, that involve background segmentation, HOG [1] feature extraction, hypothesis verification and matching are applied on the 2D radargram (B-Scan) for the detection of the salient points that correspond to buried utilities. By employing the pulse propagation velocity into the subsurface and the soil utilities, the salient points are expressed in world coordinates and used for the composition of the 3D subsurface map. Our method has been evaluated on a real test site, accompanied by ground-truth annotation data of experts and revealed remarkable performance, exhibiting not only the feasibility of underground mapping but also the capacity to obtain exploitable results for underground robotic applications.
ER  - 

TY  - CONF
TI  - Adaptive Baseline Monocular Dense Mapping with Inter-Frame Depth Propagation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3225
EP  - 3232
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - image matching
KW  - image reconstruction
KW  - image sequences
KW  - stereo image processing
KW  - monocular dense mapping methods
KW  - frame-to-frame propagated depth filter
KW  - wide-baseline observations
KW  - sequential input images
KW  - adaptive baseline matching cost computation
KW  - sequential depth estimation
KW  - multibaseline observations
KW  - separate multiview stereo problems
KW  - image sequence
KW  - inter-frame depth propagation
KW  - adaptive baseline monocular dense mapping
KW  - Estimation
KW  - Cameras
KW  - Probabilistic logic
KW  - Adaptive systems
KW  - Image sequences
KW  - Real-time systems
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593936
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - State-of-the-art monocular dense mapping methods usually divide the image sequence into several separate multi-view stereo problems thus have limited utilization of the information in multi-baseline observations and sequential depth estimations. In this paper, two core contributions are proposed to improve the mapping performance by exploiting the information. The first is an adaptive baseline matching cost computation that uses the sequential input images to provide each pixel with wide-baseline observations. The second is a frame-to-frame propagated depth filter which integrates the sequential depth estimation of the same physical point in a robust probabilistic manner. Two contributions are integrated into a monocular dense mapping system that generates the depth maps in real-time for both pinhole and fisheye cameras. Our system is fully parallelized and can run at more than 25 fps on a Nvidia Jetson TX2. We compare our work with state-of-the-art methods on the public dataset. Onboard UAV mapping and handhold experiments are also used to demonstrate the performance of our method. For the benefit of the community, we make the implementation open source.
ER  - 

TY  - CONF
TI  - Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3233
EP  - 3240
AU  - A. Kumar
AU  - J. R. McBride
AU  - G. Pandey
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image reconstruction
KW  - image resolution
KW  - image texture
KW  - mesh generation
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - scan matching techniques
KW  - end-to-end real time framework
KW  - real time incremental foveal texture mapping
KW  - real time incremental foveal texture mapping
KW  - precise localization
KW  - detailed map
KW  - urban environment
KW  - high resolution graphics grade
KW  - texture mapping error
KW  - texture error
KW  - output map
KW  - computation time
KW  - ray-filtering
KW  - sparse input LIDAR scan
KW  - high resolution 3D
KW  - camera image information
KW  - pose-refinement procedure
KW  - color texture
KW  - coherent 3D surface
KW  - computer games
KW  - background map
KW  - planning algorithms
KW  - virtual test bed
KW  - autonomous vehicles
KW  - navigation
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Cameras
KW  - Real-time systems
KW  - Image color analysis
KW  - Global Positioning System
DO  - 10.1109/IROS.2018.8593998
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose an end-to-end real time framework to generate high resolution graphics grade textured 3D map of urban environment. The generated detailed map finds its application in the precise localization and navigation of autonomous vehicles. It can also serve as a virtual test bed for various vision and planning algorithms as well as a background map in the computer games. In this paper, we focus on two important issues: (i) incrementally generating a map with coherent 3D surface, in real time and (ii) preserving the quality of color texture. To handle the above issues, firstly, we perform a pose-refinement procedure which leverages camera image information, Delaunay triangulation and existing scan matching techniques to produce high resolution 3D map from the sparse input LIDAR scan. This 3D map is then texturized and accumulated by using a novel technique of ray-filtering which handles occlusion and inconsistencies in pose-refinement. Further, inspired by human fovea, we introduce foveal-processing which significantly reduces the computation time and also assists ray-filtering to maintain consistency in color texture and coherency in 3D surface of the output map. Moreover, we also introduce texture error (TE) and mean texture mapping error (MTME), which provides quantitative measure of texturing and overall quality of the textured maps.
ER  - 

TY  - CONF
TI  - Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3241
EP  - 3248
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - probability
KW  - directional grid maps
KW  - occupancy map
KW  - mobile robot
KW  - robotic arm
KW  - static environments
KW  - dynamic objects
KW  - safer navigation
KW  - human-robot interaction
KW  - directional statistics
KW  - robotic mapping
KW  - model circular data
KW  - angular motion
KW  - probability measure-field
KW  - angular variations
KW  - indoor environments
KW  - outdoor environments
KW  - dynamic environments
KW  - grid maps
KW  - multimodal angular uncertainty
KW  - Vehicle dynamics
KW  - Robot sensing systems
KW  - Data models
KW  - Uncertainty
KW  - Navigation
DO  - 10.1109/IROS.2018.8594041
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.
ER  - 

TY  - CONF
TI  - The Effect of Swing Leg Retraction on Biped Walking Stability is Influenced by the Walking Speed and Step-Length
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3257
EP  - 3262
AU  - R. Bao
AU  - T. Geng
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - mechanical stability
KW  - mechanical variables control
KW  - walking speed
KW  - swing leg retraction
KW  - human-preferred walking patterns
KW  - human walking speeds/step-lengths
KW  - simple biped model
KW  - SLR effects
KW  - human walking patterns
KW  - biped walking stability
KW  - Legged locomotion
KW  - Mathematical model
KW  - Analytical models
KW  - Stability criteria
KW  - Foot
KW  - Biped robots
KW  - Swing leg retraction
KW  - Human walking
DO  - 10.1109/IROS.2018.8593932
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Swing Leg Retraction (SLR) is observed in human walking and running. Previous studies have concluded that SLR improves the stability and robustness of biped walking. But this conclusion was based on analysis of robot models that can only walk at a very small range of step-lengths and slow or fixed speeds. By contrast, humans can walk with a large range of speeds and step-lengths. Moreover, human walking patterns have a special feature that has not been considered in the previous studies on SLR effects: At a given walking speed, v, humans prefer a step-length, s, which satisfies the power law, s-vβ. Therefore, previous studies on SLR can't tell us whether their conclusion will still hold in the full range of human walking patterns (i.e., various walking speeds and step-lengths). This is the question we want to answer in this paper. In this study, using a simple biped model, we studied how the SLR affects the walking stability in the full range of human walking speeds/step-lengths. Preliminary analysis of both models suggests the same conclusion: (1) SLR improves the stability more evidently in human-preferred walking patterns than in other walking patterns. (2) In walking patterns that are very unlike human-preferred ones, the SLR improves the stability very little, or even deteriorates it drastically. Therefore, the new finding of our study is that how the SLR affects the biped walking stability depends on the walking speed and step-length. SLR does not always improve the stability of biped walking.
ER  - 

TY  - CONF
TI  - An Analytical Study on Trotting at Constant Velocity and Height
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3279
EP  - 3284
AU  - K. Machairas
AU  - E. Papadopoulos
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - body height
KW  - quadrupedal trotting gaits
KW  - single-legged model
KW  - point mass
KW  - actuated rotational joints
KW  - robot mass
KW  - actuator properties
KW  - robot body feasible trajectories
KW  - forward velocity
KW  - leg properties
KW  - Legged locomotion
KW  - Actuators
KW  - Trajectory
KW  - Knee
KW  - Torque
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593686
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quadrupedal trotting gaits of constant forward velocity and body height are studied. A method is developed, which is structured upon analytical expressions derived from the dynamics of a reduced single-legged model comprised of a point mass, and two actuated rotational joints. The inputs of the method include the robot mass, the leg and actuator properties, and the desired forward velocity, yielding all robot body feasible trajectories and their energy footprints. Thus, the method predicts the maximum forward velocity of a trotting quadruped; it also suggests energetically optimal combinations of body height and step length for a given forward velocity.
ER  - 

TY  - CONF
TI  - Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3285
EP  - 3291
AU  - Y. Ishii
AU  - S. Nishikawa
AU  - R. Niiyama
AU  - Y. Kuniyoshi
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - humanoid robots
KW  - kinematics
KW  - mobile robots
KW  - motion control
KW  - muscle
KW  - swimming style
KW  - musculoskeletal humanoid robot
KW  - Triton
KW  - flexible spine
KW  - erector spinae muscles
KW  - stiffness adjustment system
KW  - lumbar joints
KW  - musculoskeletal body
KW  - multijoint coordination
KW  - pneumatic muscles
KW  - lightweight properties
KW  - inherently waterproof properties
KW  - human swimming
KW  - musculoskeletal swimming robot
KW  - joint angle
KW  - thrust force
KW  - biomechanical research
KW  - underwater dolphin kick
KW  - Muscles
KW  - Dolphins
KW  - Force
KW  - Legged locomotion
KW  - Sports
DO  - 10.1109/IROS.2018.8593912
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.
ER  - 

TY  - CONF
TI  - Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3292
EP  - 3297
AU  - X. Li
AU  - H. Zhou
AU  - H. Feng
AU  - S. Zhang
AU  - Y. Fu
PY  - 2018
KW  - humanoid robots
KW  - hydraulic control equipment
KW  - hydraulic systems
KW  - legged locomotion
KW  - magnetorheology
KW  - robust control
KW  - vibration control
KW  - wheels
KW  - magnetorheological fluid-based damper
KW  - hydraulic wheel-legged robot
KW  - terrain environments
KW  - direct-drive wheels
KW  - hydraulic system
KW  - environmental adaptability
KW  - mobile abilities
KW  - innovative design
KW  - robustness
KW  - humanoid structural design
KW  - multimodal locomotion
KW  - wheel-legged hybrid robot
KW  - WLR
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8594484
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.
ER  - 

TY  - CONF
TI  - Sensor-Based Reactive Execution of Symbolic Rearrangement Plans by a Legged Mobile Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3298
EP  - 3305
AU  - V. Vasilopoulos
AU  - T. T. Topping
AU  - W. Vega-Brown
AU  - N. Roy
AU  - D. E. Koditschek
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - legged locomotion
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - torque control
KW  - motion planner
KW  - reactive layer
KW  - reference output
KW  - deliberative layer
KW  - unanticipated obstacles
KW  - gait layer
KW  - abstract unicycle commands
KW  - reactive module
KW  - appropriately coordinated joint level torque feedback loops
KW  - empirical demonstration
KW  - sensor-based reactive execution
KW  - symbolic rearrangement plans
KW  - legged mobile manipulator
KW  - physical rearrangement
KW  - wheeled stools
KW  - moderately cluttered indoor environment
KW  - quadrupedal robot
KW  - layer hierarchical architecture
KW  - offline symbolic task
KW  - Task analysis
KW  - Grippers
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Mobile robots
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594342
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We demonstrate the physical rearrangement of wheeled stools in a moderately cluttered indoor environment by a quadrupedal robot that autonomously achieves a user's desired configuration. The robot's behaviors are planned and executed by a three layer hierarchical architecture consisting of: an offline symbolic task and motion planner; a reactive layer that tracks the reference output of the deliberative layer and avoids unanticipated obstacles sensed online; and a gait layer that realizes the abstract unicycle commands from the reactive module through appropriately coordinated joint level torque feedback loops. This work also extends prior formal results about the reactive layer to a broad class of nonconvex obstacles. Our design is verified both by formal proofs as well as empirical demonstration of various assembly tasks.
ER  - 

TY  - CONF
TI  - An Assist-as-Needed Velocity Field Control Scheme for Rehabilitation Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3322
EP  - 3327
AU  - H. J. Asl
AU  - T. Narikiyo
AU  - M. Kawanishi
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - medical robotics
KW  - neural nets
KW  - patient rehabilitation
KW  - stability
KW  - velocity control
KW  - rehabilitation robots
KW  - neural network term
KW  - dead-zone function
KW  - feedback control term
KW  - bounded control command
KW  - AAN scheme
KW  - controller design
KW  - assist-as-needed velocity field control scheme
KW  - proportional-like feedback term
KW  - forgetting factor
KW  - lower-limb exoskeleton
KW  - NN component
KW  - system stability
KW  - Artificial neural networks
KW  - Timing
KW  - Aerospace electronics
KW  - Rehabilitation robotics
KW  - Stability analysis
KW  - Exoskeletons
KW  - Rehabilitation robots
KW  - assist-as-need control
KW  - neural network
KW  - exoskeleton
DO  - 10.1109/IROS.2018.8594244
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the problem of assist-as-needed (AAN) control for rehabilitation robots. To achieve a motion which is not explicitly a function of time, the velocity field control is considered in this paper. The proposed new controller consists of a proportional-like feedback term and a neural network (NN) term, where the later is exploited to compensate for the dynamic uncertainties of the system. The AAN property is facilitated by means of a dead-zone function in the feedback control term and a forgetting factor in the adaptation law of NN component. The designed controller guarantees the stability of the system with a bounded control command. The performance of the proposed AAN scheme is validated through the simulation and experiment conducted on a lower-limb exoskeleton.
ER  - 

TY  - CONF
TI  - The KIT Prosthetic Hand: Design and Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3328
EP  - 3334
AU  - P. Weiner
AU  - J. Starke
AU  - F. Hundhausen
AU  - J. Beil
AU  - T. Asfour
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - cameras
KW  - colour displays
KW  - dexterous manipulators
KW  - embedded systems
KW  - mechatronics
KW  - medical robotics
KW  - prosthetics
KW  - three-dimensional printing
KW  - mechatronics
KW  - kinematic parameters
KW  - RGB camera
KW  - colour display
KW  - innovative control
KW  - sensor integration
KW  - hand closing time
KW  - percentile male hand
KW  - underactuated TUAT/Karlsruhe mechanism
KW  - hand mechanics
KW  - embedded control system
KW  - underactuated mechanism
KW  - five-finger 3D printed hand prosthesis
KW  - KIT prosthetic hand
KW  - Embedded systems
KW  - Grasping
KW  - Tendons
KW  - Robot sensing systems
KW  - Thumb
KW  - Prosthetic hand
DO  - 10.1109/IROS.2018.8593851
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The development and control of prosthetic hands is an active research area and recently progress in mechatronics, sensor integration and innovative control has been made. However, integration of different components into a prosthetic hand remains challenging due to space constraints, the requirements regarding holistic integration and the need for a user interface. In this paper, we present the KIT prosthetic hand, a novel five-finger 3D printed hand prosthesis, with its underactuated mechanism, sensors and embedded control system. The hand mechanics is based on the underactuated TUAT/Karlsruhe mechanism with two motors actuating 10 degrees of freedom. The mechanism has been realized in 3D printing technologies to facilitate a personalization of the prosthetic hand in terms of size and kinematic parameters. The prosthesis has been designed as a 50th percentile male hand. It integrates an advanced embedded system as well as an RGB camera in the base of the palm and a colour display in the back of the hand. Experiments indicate a finger tip force of 7.48 N to 11.82 N, a hook grasp force of 120 N and a hand closing time of ~ 1.3 s.
ER  - 

TY  - CONF
TI  - Robot Controllers Compatible with Human Beam Balancing Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3335
EP  - 3341
AU  - J. Lee
AU  - M. E. Huber
AU  - D. Sternad
AU  - N. Hogan
PY  - 2018
KW  - angular momentum
KW  - biocontrol
KW  - biomechanics
KW  - legged locomotion
KW  - mechanoception
KW  - motion control
KW  - pendulums
KW  - stability
KW  - human beam balancing behavior
KW  - challenging motor skill
KW  - upright balance
KW  - stability
KW  - humans
KW  - narrow beam
KW  - lower-body angular momentum
KW  - interlimb coordination
KW  - balance controller
KW  - robotics literature
KW  - robot controllers
KW  - balancing controllers
KW  - Robot kinematics
KW  - Foot
KW  - Task analysis
KW  - Legged locomotion
KW  - Correlation
KW  - Exoskeletons
DO  - 10.1109/IROS.2018.8593549
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Standing on a beam is a challenging motor skill that requires the regulation of upright balance and stability. In this paper, we analyzed the behavior of humans balancing on a narrow beam without footwear. The results revealed high anti-correlation between lumped upper- and lower-body angular momentum. Despite differences in gross measures of balance, interlimb coordination was consistent between the novice and expert subjects, suggesting that both performances could be described with the same balance controller. By simulating a double inverted pendulum model utilizing different balancing controllers described in the robotics literature, we identified that the whole behavior observed from humans standing on a beam was best replicated with controllers that predominantly utilized hip actuation.
ER  - 

TY  - CONF
TI  - Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3342
EP  - 3349
AU  - J. Ueda
AU  - M. Turkseven
AU  - E. Kim
AU  - Q. Lowery
AU  - C. Bivens
AU  - M. Mayo
PY  - 2018
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - shock absorbers
KW  - viscoelasticity
KW  - wearable robots
KW  - lower-extremity wearable link mechanism
KW  - exoskeleton robot
KW  - shock absorbing exoskeleton
KW  - human skeletal system
KW  - human-exoskeleton coupled system
KW  - vertical mobility system
KW  - dynamic models
KW  - kinematic models
KW  - multielement viscoelastic model
KW  - Exoskeletons
KW  - Electric shock
KW  - Muscles
KW  - Joints
KW  - Bones
KW  - Force
KW  - Injuries
DO  - 10.1109/IROS.2018.8593820
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.
ER  - 

TY  - CONF
TI  - Prediction of Manipulation Action Classes Using Semantic Spatial Reasoning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3350
EP  - 3357
AU  - F. Ziaeetabar
AU  - T. Kulvicius
AU  - M. Tamosiunaite
AU  - F. Wörgötter
PY  - 2018
KW  - hidden Markov models
KW  - human-robot interaction
KW  - image sequences
KW  - manipulators
KW  - spatial reasoning
KW  - video signal processing
KW  - trajectory-based HMM method
KW  - simple robot demonstration
KW  - dynamic spatial relations
KW  - static relations
KW  - temporal sequence
KW  - Enriched Semantic Event Chain framework
KW  - video sequences
KW  - predictive action recognition
KW  - human-robot interaction
KW  - Semantic spatial reasoning
KW  - manipulation action classes
KW  - Robots
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Semantics
KW  - Human-robot interaction
KW  - Prediction algorithms
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8593717
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-robot interaction strongly benefits from fast, predictive action recognition. For us this is relatively easy but difficult for a robot. To address this problem, here we present a novel prediction algorithm for manipulation action classes in video sequences. Manipulations are first represented using the Enriched Semantic Event Chain (ESEC) framework. This creates a temporal sequence of static and dynamic spatial relations between the objects that take part in the manipulation by which an action can be quickly recognized. We measured performance on 32 ideal as well as real manipulations and compared our method also against a state of the art trajectory-based HMM method for action recognition. We observe that manipulations can be correctly predicted after only (on average) 45% of action's total time and that we are almost twice as fast as the HMM-based method. Finally, we demonstrate the advantage of this framework in a simple robot demonstration comparing two different approaches.
ER  - 

TY  - CONF
TI  - Human Motion Prediction Under Social Grouping Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3358
EP  - 3364
AU  - A. Rudenko
AU  - L. Palmieri
AU  - A. J. Lilienthal
AU  - K. O. Arras
PY  - 2018
KW  - Markov processes
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - planning (artificial intelligence)
KW  - probability
KW  - random processes
KW  - human motion prediction
KW  - social grouping constraints
KW  - long-term prediction
KW  - social relations
KW  - social norms
KW  - surrounding agents
KW  - MDP planning problem
KW  - social forces
KW  - social grouping information
KW  - prediction process
KW  - soft formation constraints
KW  - mobile robots
KW  - Force
KW  - Task analysis
KW  - Trajectory
KW  - Predictive models
KW  - Computational modeling
KW  - Tracking
KW  - Planning
DO  - 10.1109/IROS.2018.8594258
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.
ER  - 

TY  - CONF
TI  - Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3365
EP  - 3372
AU  - Z. Talebpour
AU  - A. Martinoli
PY  - 2018
KW  - human-robot interaction
KW  - Kalman filters
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - risk analysis
KW  - trajectory control
KW  - risk-based human-aware multirobot coordination
KW  - dynamic environments
KW  - human-populated environments
KW  - Kalman filter
KW  - position estimation
KW  - MRTA problem
KW  - human trajectory prediction
KW  - multirobot task allocation problem
KW  - human-aware navigation
KW  - risk-based bids
KW  - risk-based human-aware planning
KW  - human-agnostic planning
KW  - prediction error
KW  - Robot kinematics
KW  - Task analysis
KW  - Navigation
KW  - Planning
KW  - Uncertainty
KW  - Estimation
DO  - 10.1109/IROS.2018.8593586
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.
ER  - 

TY  - CONF
TI  - Modeling Social Interaction Based on Joint Motion Significance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3373
EP  - 3380
AU  - N. J. Cho
AU  - S. H. Lee
AU  - T. Kwon
AU  - I. H. Suh
AU  - H. Kim
PY  - 2018
KW  - avatars
KW  - entropy
KW  - feature extraction
KW  - Gaussian processes
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - principal component analysis
KW  - regression analysis
KW  - modeling social interaction
KW  - joint motion significance
KW  - human performers
KW  - human demonstrations
KW  - relative joints
KW  - human joints
KW  - Gaussian mixture model
KW  - Entropy
KW  - Hidden Markov models
KW  - Motion segmentation
KW  - Motion measurement
KW  - Trajectory
KW  - Shoulder
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8594436
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a method to model social interaction between a human and a virtual avatar. To this end, two human performers fist perform social interactions according to the Learning from Demonstration paradigm. Then, the relative relevance of all joints of both performers should be reasonably modeled based on human demonstrations. However, among all possible combinations of relative joints, it is necessary to select only some of the combinations that play key roles in social interaction. We select such significant features based on the joint motion significance, which is a metric to measure the significance degree by calculating both temporal entropy and spatial entropy of all human joints from a Gaussian mixture model. To evaluate our proposed method, we performed experiments on five social interactions: hand shaking, hand slapping, shoulder holding, object passing, and target kicking. In addition, we compared our method to existing modeling methods using different metrics, such as principal component analysis and information gain.
ER  - 

TY  - CONF
TI  - Effects of Integrated Intent Recognition and Communication on Human-Robot Collaboration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3381
EP  - 3386
AU  - M. Lee Chang
AU  - R. A. Gutierrez
AU  - P. Khante
AU  - E. Schaertl Short
AU  - A. Lockerd Thomaz
PY  - 2018
KW  - human-robot interaction
KW  - image motion analysis
KW  - mobile robots
KW  - human-robot interaction
KW  - human partners hand motion intent
KW  - communication system
KW  - bi-directional intent system
KW  - predictable motion
KW  - legible motion
KW  - motion planner system
KW  - intent recognition system
KW  - collaborative physical task
KW  - intentional motion
KW  - human-robot collaboration
KW  - integrated intent recognition
KW  - Collaboration
KW  - Task analysis
KW  - Trajectory
KW  - Motion segmentation
KW  - Containers
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593359
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-robot interaction research to date has investigated intent recognition and communication separately. In this paper, we explore the effects of integrating both the robot's ability to generate intentional motion and predict the human's motion in a collaborative physical task. We implemented an intent recognition system to recognize the human partner's hand motion intent and a motion planner system to enable the robot to communicate its intent by using legible and predictable motion. We tested this bi-directional intent system in a 2-way within-subjects user study. Results suggest that an integrated intent recognition and communication system may facilitate more collaborative behavior among team members.
ER  - 

TY  - CONF
TI  - After You: Doorway Negotiation for Human-Robot and Robot-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3387
EP  - 3394
AU  - J. Thomas
AU  - R. Vaughan
PY  - 2018
KW  - human-robot interaction
KW  - path planning
KW  - doorway negotiation
KW  - robot-robot interaction
KW  - autonomous robot behavior
KW  - aggressive interaction
KW  - navigation deadlocks
KW  - assertive robot
KW  - common navigation sensors
KW  - naive human participants
KW  - human users
KW  - robot-robot experiments
KW  - human-robot interaction study
KW  - Navigation
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - System recovery
KW  - Autonomous robots
KW  - Safety
DO  - 10.1109/IROS.2018.8594034
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose and test an autonomous robot behavior for socially-compliant navigation of doorways with both human and robot interlocutors. Building on previous work for “aggressive” interaction between robots to resolve navigation deadlocks in corridors, we demonstrate an “assertive” robot that negotiates right-of-way when faced with a human or other robot. The negotiation is implemented using only motion and common navigation sensors, without explicit message-passing. Our goal is for the correct agent to take priority, as decided both by time-efficiency and as judged subjectively by naive human participants. Our contribution is a practical method for doorway negotiation, and a study of human users' responses to a robot that appears to participate in existing social customs surrounding doors. Our method is evaluated with robot-robot experiments and a human-robot interaction study with nonexpert users.
ER  - 

TY  - CONF
TI  - The Power of Color: A Study on the Effective Use of Colored Light in Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3395
EP  - 3402
AU  - A. Pörtner
AU  - L. Schröder
AU  - R. Rasch
AU  - D. Sprute
AU  - M. Hoffmann
AU  - M. König
PY  - 2018
KW  - human computer interaction
KW  - human-robot interaction
KW  - mobile robots
KW  - service robots
KW  - mobile robot
KW  - color preference
KW  - appropriate colors
KW  - cheap feedback mechanism
KW  - complex interaction techniques
KW  - human-robot interaction
KW  - colored light
KW  - Color
KW  - Videos
KW  - Animation
KW  - Mobile robots
KW  - Task analysis
KW  - Human-robot interaction
DO  - 10.1109/IROS.2018.8594231
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In times of more and more complex interaction techniques, we point out the powerfulness of colored light as a simple and cheap feedback mechanism. Since it is visible over a distance and does not interfere with other modalities, it is especially interesting for mobile robots. In an online survey, we asked 56 participants to choose the most appropriate colors for scenarios that were presented in the form of videos. In these scenarios a mobile robot accomplished tasks, in some with success, in others it failed because the task is not feasible, in others it stopped because it waited for help. We analyze in what way the color preferences differ between these three categories. The results show a connection between colors and meanings and that it depends on the participants' technical affinity, experience with robots and gender how clear the color preference is for a certain category. Finally, we found out that the participants' favorite color is not related to color preferences.
ER  - 

TY  - CONF
TI  - Neuroscientifically-Grounded Research for Improved Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3403
EP  - 3408
AU  - K. Kompatsiari
AU  - J. Pérez-Osorio
AU  - D. De Tommaso
AU  - G. Metta
AU  - A. Wykowska
PY  - 2018
KW  - cognition
KW  - electroencephalography
KW  - humanoid robots
KW  - human-robot interaction
KW  - man-machine systems
KW  - neurophysiology
KW  - psychology
KW  - objective neuroscientific methods
KW  - experimental psychology research
KW  - well-controlled experimental designs
KW  - improved human-robot interaction
KW  - experimentation tapping
KW  - robot design
KW  - human social cognition
KW  - humanoid robot
KW  - robotics community
KW  - enhanced event-related potentials
KW  - faster response times
KW  - gaze-cueing research
KW  - documented results
KW  - iCub robot
KW  - HRI protocol
KW  - gaze cueing
KW  - joint attention
KW  - attentional cueing
KW  - human-robot interaction research
KW  - Cognition
KW  - Psychology
KW  - Humanoid robots
KW  - Protocols
KW  - Electroencephalography
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594441
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The present study highlights the benefits of using well-controlled experimental designs, grounded in experimental psychology research and objective neuroscientific methods, for generating progress in human-robot interaction (HRI) research. More specifically, we aimed at implementing a well-studied paradigm of attentional cueing through gaze (the so-called “joint attention” or “gaze cueing”) in an HRI protocol involving the iCub robot. Similarly to documented results in gaze-cueing research, we found faster response times and enhanced event-related potentials of the EEG signal for discrimination of cued, relative to uncued, targets. These results are informative for the robotics community by showing that a humanoid robot with mechanistic eyes and human-like characteristics of the face is in fact capable of engaging a human in joint attention to a similar extent as another human would do. More generally, we propose that the methodology of combining neuroscience methods with an HRI protocol, contributes to understanding mechanisms of human social cognition in interactions with robots and to improving robot design, thanks to systematic and well-controlled experimentation tapping onto specific cognitive mechanisms of the human, such as joint attention.
ER  - 

TY  - CONF
TI  - Robust LIDAR Localization for Autonomous Driving in Rain
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3409
EP  - 3415
AU  - C. Zhang
AU  - M. H. Ang
AU  - D. Rus
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - optical radar
KW  - particle filtering (numerical methods)
KW  - stereo image processing
KW  - traffic engineering computing
KW  - 3D LIDAR scans
KW  - histogram filter
KW  - particle filter
KW  - posterior distributions
KW  - vehicle poses
KW  - complex urban environments
KW  - fair weather
KW  - rainy weather
KW  - robust LIDAR localization
KW  - autonomous driving
KW  - map-based localization method
KW  - rainy conditions
KW  - ground reflectivity features
KW  - vertical features extraction
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Histograms
KW  - Rain
KW  - Measurement by laser beam
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593703
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a map-based localization method aiming to increase robustness in rainy conditions. This method utilizes two types of features: ground reflectivity features and vertical features extracted from 3D LIDAR scans and builds vehicle pose belief with two filters: a histogram filter and a particle filter. The posterior distributions from the two filters are integrated to estimate vehicle poses. This method exploits advantages of both features and filters, compensating respective weakness to deal with complex urban environments. Testing was performed in the fair and rainy weather. Road test results prove robustness and reliability of the proposed method.
ER  - 

TY  - CONF
TI  - Move Base Flex A Highly Flexible Navigation Framework for Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3416
EP  - 3421
AU  - S. Pütz
AU  - J. Santos Simón
AU  - J. Hertzberg
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - path planning
KW  - MBF
KW  - path planning
KW  - motion control
KW  - robot tasks
KW  - complex navigation tasks
KW  - Move Base Flex
KW  - highly flexible navigation framework
KW  - modular navigation
KW  - map-independent navigation
KW  - open-source navigation
KW  - Navigation
KW  - Robots
KW  - Computer architecture
KW  - Task analysis
KW  - Flexible printed circuits
KW  - Servers
KW  - Planning
DO  - 10.1109/IROS.2018.8593829
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present Move Base Flex (MBF), a highly flexible, modular, map-independent, open-source navigation framework for use in ROS. MBF provides modular actions for executing plugins for path planning, motion control, and recovery. These actions define interfaces for external executives to allow highly flexible navigation strategies, which can be intertwined with other robot tasks. MBF has been successfully deployed in a professional setting at customer facilities to control robots in highly dynamic environments. We compare MBF with the well-known move_base and present the architecture as well as different deployment approaches, including how MBF can be used with different executives to perform complex navigation tasks interleaved with other robot operations.
ER  - 

TY  - CONF
TI  - Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3422
EP  - 3429
AU  - G. Todoran
AU  - M. Bader
PY  - 2018
KW  - collision avoidance
KW  - emergency management
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - trajectory control
KW  - safe navigation
KW  - safe motion controls
KW  - emergency trajectory candidates
KW  - just-in-time emergency trajectories
KW  - autonomous navigation
KW  - vehicle operation
KW  - safe system state
KW  - MHTP
KW  - moving horizon trajectory planner
KW  - safety requirements
KW  - vehicle's local control system
KW  - differential-drive mobile agent
KW  - nonstatic environment
KW  - robot
KW  - Trajectory
KW  - Safety
KW  - Navigation
KW  - Robots
KW  - Vehicle dynamics
KW  - Planning
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593721
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.
ER  - 

TY  - CONF
TI  - PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3430
EP  - 3437
AU  - P. Egger
AU  - P. V. K. Borges
AU  - G. Catt
AU  - A. Pfrunder
AU  - R. Siegwart
AU  - R. Dubé
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - local views
KW  - sliding window fashion
KW  - matching current
KW  - old features
KW  - map representation
KW  - local maps
KW  - off-road environments
KW  - single localization failure
KW  - distinctive features
KW  - coined PoseMap
KW  - dynamic environments
KW  - robotic systems
KW  - long-term localization
KW  - multienvironment 3D LiDAR localization
KW  - frequency 8.0 Hz
KW  - time 18.0 month
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Optimization
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593854
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.
ER  - 

TY  - CONF
TI  - Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3438
EP  - 3444
AU  - Y. Morales
AU  - N. Akai
AU  - H. Murase
PY  - 2018
KW  - collision avoidance
KW  - human computer interaction
KW  - mobile robots
KW  - navigation
KW  - pedestrians
KW  - road vehicles
KW  - vehicles
KW  - personal mobility vehicle autonomous navigation
KW  - pedestrian flow
KW  - data driven approach
KW  - parameter extraction
KW  - safe navigation
KW  - moving obstacles
KW  - public pedestrian paths
KW  - robotic PMV
KW  - human-driven smooth navigation
KW  - PMV-Human interaction
KW  - Navigation
KW  - Legged locomotion
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Wheelchairs
KW  - Bicycles
DO  - 10.1109/IROS.2018.8593902
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.
ER  - 

TY  - CONF
TI  - Identifying Driver Behaviors Using Trajectory Features for Vehicle Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3445
EP  - 3452
AU  - E. Cheung
AU  - A. Bera
AU  - E. Kubin
AU  - K. Gray
AU  - D. Manocha
PY  - 2018
KW  - automobiles
KW  - behavioural sciences computing
KW  - driver information systems
KW  - feature extraction
KW  - Internet
KW  - mobile robots
KW  - vehicle trajectories
KW  - autonomous vehicles
KW  - car trajectories
KW  - data-driven mapping
KW  - vehicle navigation simulation system
KW  - driver behavior identification
KW  - Web-based user study
KW  - Trajectory
KW  - Navigation
KW  - Automobiles
KW  - Feature extraction
KW  - Measurement
KW  - Acceleration
DO  - 10.1109/IROS.2018.8594348
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel approach to automatically identify driver behaviors from vehicle trajectories and use them for safe navigation of autonomous vehicles. We propose a novel set of features that can be easily extracted from car trajectories. We derive a data-driven mapping between these features and six driver behaviors using an elaborate web-based user study. We also compute a summarized score indicating a level of awareness that is needed while driving next to other vehicles. We also incorporate our algorithm into a vehicle navigation simulation system and demonstrate its benefits in terms of safer realtime navigation, while driving next to aggressive or dangerous drivers.
ER  - 

TY  - CONF
TI  - Preliminary Evaluation of Null-Space Dynamic Process Model Identification with Application to Cooperative Navigation of Underwater Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3453
EP  - 3459
AU  - Z. J. Harris
AU  - T. M. Paine
AU  - L. L. Whitcomb
PY  - 2018
KW  - least squares approximations
KW  - marine communication
KW  - parameter estimation
KW  - position control
KW  - underwater vehicles
KW  - vehicle dynamics
KW  - UV model parameters
KW  - control-surface parameters
KW  - thruster-model parameters
KW  - preliminary evaluation
KW  - null-space dynamic process model identification
KW  - underactuated underwater vehicle
KW  - control-input parameters
KW  - UV nonlinear plant-model parameters
KW  - nonlinear model identification
KW  - underwater communication
KW  - cooperative navigation
KW  - null-space least-squares parameter identification method
KW  - Navigation
KW  - Vehicle dynamics
KW  - Acoustics
KW  - Underwater vehicles
KW  - Heuristic algorithms
KW  - Kinematics
KW  - Kalman filters
DO  - 10.1109/IROS.2018.8594257
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper reports a method and preliminary evaluation of a novel null-space least-squares parameter identification method for a fully nonlinear second -order 6-degree-of-freedom (DOF) dynamic process model of an underactuated underwater vehicle (UV) for which both the model parameters and the control-input parameters are unknown. This paper further reports the application of the identified plant models in combined underwater communication and navigation (cooperative navigation) of UVs. We report an approach to model identification that simultaneously identifies 6-DOF UV nonlinear plant-model parameters, control-surface parameters, and thruster-model parameters. We believe this approach is suitable for identifying plant model parameters from data obtained in full-scale experimental trials of UVs in controlled motion. The reported approach to nonlinear model identification of UVs is evaluated in simulation studies. The resulting identified UV plant models are further evaluated in simulated cooperative navigation missions of the UV that are representative of high-precision survey missions. To the best of our knowledge, this paper reports the first method to identify 6-DOF UV model parameters, control-surface parameters, and thruster-model parameters simultaneously.
ER  - 

TY  - CONF
TI  - Autonomous Acquisition of Behavior Trees for Robot Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3460
EP  - 3467
AU  - B. Banerjee
PY  - 2018
KW  - computer games
KW  - feedback
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - trees (mathematics)
KW  - robot control
KW  - learned control policy
KW  - RL control policies
KW  - optimal behavior permutation
KW  - intelligent agents
KW  - autonomous acquisition
KW  - computer game industry
KW  - intelligent robots
KW  - reinforcement learning
KW  - decanonicalization algorithm
KW  - canonical behavior tree
KW  - combinatorial search
KW  - Task analysis
KW  - Computer architecture
KW  - Reinforcement learning
KW  - Robot control
KW  - Games
KW  - Industries
DO  - 10.1109/IROS.2018.8594083
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Behavior trees (BT) are a popular control architecture in the computer game industry, and have been more recently applied in robotics. One open question is how can intelligent agents/robots autonomously acquire their behavior trees for task level control? In contrast with existing approaches that either refine an initially given BT, or directly build the BT based on human feedback/demonstration, we leverage reinforcement learning (RL) that allows robots to autonomously learn control policies by repeated task interaction, but often expressed in a language more difficult to interpret than BTs. The learned control policy is then converted to a behavior tree via our proposed decanonicalization algorithm. The feasibility of this idea is based on a proposed notion of canonical behavior trees (CBT). In particular, we show (1) CBTs are sufficiently expressive to capture RL control policies, and (2) that RL can be independent of an optimal behavior permutation, despite the BT convention of left-to-right priority, thus obviating the need for a combinatorial search. Two evaluation domains help illustrate our approach.
ER  - 

TY  - CONF
TI  - Learning-Based Modular Task-Oriented Grasp Stability Assessment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3468
EP  - 3475
AU  - J. Xu
AU  - A. Bhardwaj
AU  - G. Sun
AU  - T. Aykut
AU  - N. Alt
AU  - M. Karimi
AU  - E. Steinbach
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - stability
KW  - tactile sensors
KW  - modular task-oriented stability assessment
KW  - stability prediction
KW  - relevant modular tasks
KW  - unnecessary grasp adaptations
KW  - manipulation actions
KW  - trained model
KW  - individual stability demands
KW  - specific task
KW  - underlying model
KW  - learning-based approach
KW  - object uncertainties
KW  - sensory data
KW  - robotic manipulation tasks
KW  - modular task-oriented grasp stability assessment
KW  - manipulation task
KW  - unnecessary grasp force adaptations
KW  - Task analysis
KW  - Stability analysis
KW  - Force
KW  - Tactile sensors
KW  - Feature extraction
KW  - Friction
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594412
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Assessing grasp stability is essential to prevent the failure of robotic manipulation tasks due to sensory data and object uncertainties. Learning-based approaches are widely deployed to infer the success of a grasp. Typically, the underlying model used to estimate the grasp stability is trained for a specific task, such as lifting, hand-over, or pouring. Since every task has individual stability demands, it is important to adapt the trained model to new manipulation actions. If the same trained model is directly applied to a new task, unnecessary grasp adaptations might be triggered, or in the worst case, the manipulation might fail. To address this issue, we divide the manipulation task used for training into seven sub-tasks, defined as modular tasks. We deploy a learning-based approach and assess the stability for each modular task separately. We further propose analytical features to reduce the dimensionality and the redundancy of the tactile sensor readings. A main task can thereby be represented as a sequence of relevant modular tasks. The stability prediction of the main task is computed based on the inferred success labels of the modular tasks. Our experimental evaluation shows that the proposed feature set lowers the prediction error up to 5.69% compared to other sets used in state-of-the-art methods. Robotic experiments demonstrate that our modular task-oriented stability assessment avoids unnecessary grasp force adaptations and regrasps for various manipulation tasks.
ER  - 

TY  - CONF
TI  - Interactive Robotic Manipulation of Elastic Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3476
EP  - 3481
AU  - S. Duenser
AU  - J. M. Bern
AU  - R. Poranne
AU  - S. Coros
PY  - 2018
KW  - collision avoidance
KW  - elastic deformation
KW  - finite element analysis
KW  - force control
KW  - manipulators
KW  - robot kinematics
KW  - sensitivity analysis
KW  - simulation
KW  - interactive simulation-based control methodology
KW  - interactive robotic manipulation
KW  - finite element method
KW  - sensitivity analysis
KW  - mathematical model
KW  - robots configuration
KW  - collision avoidance
KW  - elastic deformation objects
KW  - quasistatic assumption
KW  - Robots
KW  - Computational modeling
KW  - Shape
KW  - Collision avoidance
KW  - Mathematical model
KW  - Strain
KW  - Finite element analysis
DO  - 10.1109/IROS.2018.8594291
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we address the challenge of robotic manipulation of elastically deforming objects. To this end, we model elastic objects using the Finite Element Method. Through a quasi-static assumption, we leverage sensitivity analysis to mathematically model how changes in the robot's configuration affect the deformed shape of the object being manipulated. This enables an interactive, simulation-based control methodology, wherein user-specified deformations for the elastic objects are automatically mapped to joint angle commands. The optimization formulation we introduce is general, operates directly within a robot's workspace and can readily incorporate joint limits as well as collision avoidance between the links. We validate our control methodology on a YuMi® IRB 14000, which we use to manipulate a variety of elastic objects.
ER  - 

TY  - CONF
TI  - Domain Randomization and Generative Models for Robotic Grasping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3482
EP  - 3489
AU  - J. Tobin
AU  - L. Biewald
AU  - R. Duan
AU  - M. Andrychowicz
AU  - A. Handa
AU  - V. Kumar
AU  - B. McGrew
AU  - A. Ray
AU  - J. Schneider
AU  - P. Welinder
AU  - W. Zaremba
AU  - P. Abbeel
PY  - 2018
KW  - grippers
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - probability
KW  - domain randomization
KW  - generative models
KW  - deep learning-based robotic grasping
KW  - significant progress thanks
KW  - algorithmic improvements
KW  - increased data availability
KW  - state-of-the-art models
KW  - unique object instances
KW  - result generalization
KW  - novel data generation pipeline
KW  - deep neural network
KW  - successful grasps
KW  - autoregressive grasp planning model
KW  - probability distribution
KW  - possible grasps
KW  - sample grasps
KW  - test time
KW  - model architecture
KW  - unseen realistic objects
KW  - random objects
KW  - real-world grasp
KW  - random simulated objects
KW  - Grasping
KW  - Training
KW  - Data models
KW  - Computational modeling
KW  - Robot sensing systems
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593933
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.
ER  - 

TY  - CONF
TI  - Improving Grasping Forces During the Manipulation of Unknown Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3490
EP  - 3495
AU  - A. Montaño
AU  - R. Suárez
PY  - 2018
KW  - dexterous manipulators
KW  - manipulator kinematics
KW  - object recognition
KW  - simple geometrical approach
KW  - kinematic information
KW  - local object curvature
KW  - object manipulation problem
KW  - tactile information
KW  - object shape recognition
KW  - grasping forces
KW  - Schunk dexterous hand
KW  - SDH2
KW  - Shape
KW  - Tactile sensors
KW  - Force
KW  - Kinematics
KW  - Grasping
DO  - 10.1109/IROS.2018.8593655
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many of the solutions proposed for the object manipulation problem are based on the knowledge of the object features. The approach proposed in this paper intends to provide a simple geometrical approach to securely manipulate an unknown object based only on tactile and kinematic information. The tactile and kinematic data obtained during the manipulation is used to recognize the object shape (at least the local object curvature), allowing to improve the grasping forces when this information is added to the manipulation strategy. The approach has been fully implemented and tested using the Schunk Dexterous Hand (SDH2). Experimental results are shown to illustrate the efficiency of the approach.
ER  - 

TY  - CONF
TI  - Intrinsically Motivated Self-Supervised Deep Sensorimotor Learning for Grasping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3496
EP  - 3502
AU  - T. Takahashi
AU  - M. W. Lanighan
AU  - R. A. Grupen
PY  - 2018
KW  - closed loop systems
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - high-dimensional state spaces
KW  - object recognition
KW  - video games
KW  - machine translation
KW  - deep neural networks
KW  - training datasets
KW  - deep learning
KW  - robot systems
KW  - closed-loop control states
KW  - motivated self-supervised deep sensorimotor learning
KW  - intrinsic motivators
KW  - Robot sensing systems
KW  - Entropy
KW  - Training
KW  - Uncertainty
KW  - Deep learning
KW  - Biological neural networks
DO  - 10.1109/IROS.2018.8593424
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep learning has been successful in a variety of applications that have high-dimensional state spaces such as object recognition, video games, and machine translation. Deep neural networks can automatically learn important features from high-dimensional state given large training datasets. However, the success of deep learning in robot systems in the realworld is limited due to the cost of obtaining these large datasets. To overcome this problem, we propose an information-theoretic, intrinsically motivated, self-labeling mechanism using closed-loop control states. Taking this approach biases exploration to informative interactions-as such, a robot requires much less training to achieve reliable performance. In this paper, we explore the impact such an approach has on learning how to grasp objects. We evaluate different intrinsic motivators present in the literature applied appropriately in our framework and discuss the benefits and drawbacks of each.
ER  - 

TY  - CONF
TI  - Manipulation Planning Under Changing External Forces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3503
EP  - 3510
AU  - L. Chen
AU  - L. F. C. Figueredo
AU  - M. Dogar
PY  - 2018
KW  - grippers
KW  - path planning
KW  - position control
KW  - stability
KW  - bimanual regrasp planning
KW  - bimanual robot
KW  - external forces
KW  - manipulation planning algorithm
KW  - forceful operations
KW  - subsequent grasps
KW  - single gripper
KW  - stability
KW  - Planning
KW  - Grippers
KW  - Manifolds
KW  - Manipulators
KW  - Task analysis
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593555
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a manipulation planning algorithm for a robot to keep an object stable under changing external forces. We particularly focus on the case where a human may be applying forceful operations, e.g. cutting or drilling, on an object that the robot is holding. The planner produces an efficient plan by intelligently deciding when the robot should change its grasp on the object as the human applies the forces. The planner also tries to choose subsequent grasps such that they will minimize the number of regrasps that will be required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the problem of bimanual regrasp planning, where the object is not placed on a support surface, but instead it is held by a single gripper until the second gripper moves to a new position on the object. This requires the planner to also reason about the stability of the object under gravity. We provide an implementation on a bimanual robot and present experiments to show the performance of our planner.
ER  - 

TY  - CONF
TI  - Jacquard: A Large Scale Dataset for Robotic Grasp Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3511
EP  - 3516
AU  - A. Depierre
AU  - E. Dellandréa
AU  - L. Chen
PY  - 2018
KW  - belief networks
KW  - CAD
KW  - computer vision
KW  - grippers
KW  - image classification
KW  - image representation
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - robot vision
KW  - solid modelling
KW  - robotic grasp detection
KW  - grasping skill
KW  - real-life applications
KW  - state-of-the-art robotic
KW  - deep neural networks
KW  - robotics
KW  - scale synthetic dataset
KW  - ground truth
KW  - Jacquard grasping dataset
KW  - CAD models dataset
KW  - successful grasping positions
KW  - grasp attempts
KW  - grasping robot trials
KW  - generalization skills
KW  - Jacquard dataset
KW  - grasping position detections
KW  - human labeled dataset
KW  - CNN
KW  - RGB-D images
KW  - ShapeNet
KW  - Solid modeling
KW  - Grippers
KW  - Robot kinematics
KW  - Grasping
KW  - Data models
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593950
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset.
ER  - 

TY  - CONF
TI  - Planning Hand-Arm Grasping Motions with Human-Like Appearance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3517
EP  - 3522
AU  - N. García
AU  - R. Suárez
AU  - J. Rosell
PY  - 2018
KW  - humanoid robots
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - planning hand-arm grasping motions
KW  - hand-arm robotic systems
KW  - grasping actions
KW  - coordinated movements
KW  - robotic arm
KW  - anthropomorphic mechanical hand
KW  - human movements
KW  - human hand synergies
KW  - planning phase
KW  - motion planning
KW  - state-of-the-art planning algorithm
KW  - human-like appearance
KW  - search space
KW  - sampling-based planner
KW  - Planning
KW  - Grasping
KW  - Robot kinematics
KW  - Trajectory
KW  - Complexity theory
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594432
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the problem of obtaining human-like motions on hand-arm robotic systems performing grasping actions. The focus is set on the coordinated movements of the robotic arm and the anthropomorphic mechanical hand, with which the arm is equipped. For this, human movements performing different grasps are captured and mapped to the robot in order to compute the human hand synergies. These synergies are used to both obtain human-like movements and to reduce the complexity of the planning phase by reducing the dimension of the search space. In addition, the paper proposes a sampling-based planner, which guides the motion planning following the synergies and considering different types of grasps. The introduced approach is tested in an application example and thoroughly compared with a state-of-the-art planning algorithm, obtaining better results.
ER  - 

TY  - CONF
TI  - Efficient Computation of Invariably Safe States for Motion Planning of Self-Driving Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3523
EP  - 3530
AU  - C. Pek
AU  - M. Althoff
PY  - 2018
KW  - collision avoidance
KW  - Markov processes
KW  - road vehicles
KW  - stochastic systems
KW  - self-driving vehicles
KW  - planning horizon
KW  - infinite time horizon
KW  - time-to-react metric
KW  - motion planning
KW  - Trajectory
KW  - Planning
KW  - Safety
KW  - Dynamics
KW  - Vehicle dynamics
KW  - Measurement
KW  - Reachability analysis
DO  - 10.1109/IROS.2018.8593597
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Safe motion planning requires that a vehicle reaches a set of safe states at the end of the planning horizon. However, safe states of vehicles have not yet been systematically defined in the literature, nor does a computationally efficient way to obtain them for online motion planning exist. To tackle the aforementioned issues, we introduce invariably safe sets. These are regions that allow vehicles to remain safe for an infinite time horizon. We show how invariably safe sets can be computed and propose a tight under-approximation which can be obtained efficiently in linear time with respect to the number of traffic participants. We use invariably safe sets to lift safety verification from finite to infinite time horizons. In addition, our sets can be used to determine the existence of feasible evasive maneuvers and the criticality of scenarios by computing the time-to-react metric.
ER  - 

TY  - CONF
TI  - Improving Offline Value-Function Approximations for POMDPs by Reducing Discount Factors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3531
EP  - 3536
AU  - Y. Chen
AU  - M. J. Kochenderfer
AU  - M. T. J. Spaan
PY  - 2018
KW  - decision theory
KW  - function approximation
KW  - Markov processes
KW  - exponentially discounted rewards
KW  - state space
KW  - observation model
KW  - offline value-function approximations
KW  - partially observable Markov decision processes
KW  - POMDP
KW  - discount factor reduction
KW  - Planning
KW  - Observability
KW  - Approximation error
KW  - Markov processes
KW  - Memory management
KW  - Benchmark testing
DO  - 10.1109/IROS.2018.8594418
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A common solution criterion for partially observable Markov decision processes (POMDPs) is to maximize the expected sum of exponentially discounted rewards, for which a variety of approximate methods have been proposed. Those that plan in the belief space typically provide tighter performance guarantees, but those that plan over the state space (e.g., QMDP and FIB) often require much less memory and computation. This paper presents an encouraging result that shows that reducing the discount factor while planning in the state space can actually improve performance significantly when evaluated on the original problem. This phenomenon is confirmed by both a theoretical analysis as well as a series of empirical studies on benchmark problems. As predicted by the theory and confirmed empirically, the phenomenon is most prominent when the observation model is noisy or rewards are sparse.
ER  - 

TY  - CONF
TI  - Robust Exploration with Multiple Hypothesis Data Association
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3537
EP  - 3544
AU  - J. Wang
AU  - B. Englot
PY  - 2018
KW  - image fusion
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - target tracking
KW  - tree searching
KW  - joint compatibility branch
KW  - simultaneous localization and mapping
KW  - map accuracy
KW  - diverse hypotheses
KW  - multiple hypothesis tracking
KW  - robust back-ends
KW  - catastrophic failure
KW  - single false positive assignment
KW  - rich features
KW  - autonomous exploration
KW  - SLAM
KW  - ambiguous data association problem
KW  - multiple hypothesis data association
KW  - robust exploration
KW  - Simultaneous localization and mapping
KW  - Trajectory
KW  - Noise measurement
KW  - State estimation
KW  - Optimization
KW  - Measurement uncertainty
DO  - 10.1109/IROS.2018.8593753
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We study the ambiguous data association problem confronting simultaneous localization and mapping (SLAM), specifically for the autonomous exploration of environments lacking rich features. In such environments, a single false positive assignment might lead to catastrophic failure, which even robust back-ends may be unable to resolve. Inspired by multiple hypothesis tracking, we present a novel approach to effectively manage multiple hypotheses (MH) of data association inherited from traditional joint compatibility branch and bound (JCBB), which entails the generation, ordering and elimination of hypotheses. We analyze the performance of MHJCBB in two particular situations, one applying it to SLAM over a predefined trajectory and the other showing its applicability in exploring unknown environments. Statistical results demonstrate that MHJCBB's maintenance of diverse hypotheses under ambiguous conditions significantly improves map accuracy.
ER  - 

TY  - CONF
TI  - Reactive Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3545
EP  - 3550
AU  - A. Dhawale
AU  - X. Yang
AU  - N. Michael
PY  - 2018
KW  - cameras
KW  - collision avoidance
KW  - Gaussian processes
KW  - geometry
KW  - helicopters
KW  - mobile robots
KW  - probability
KW  - trajectory control
KW  - collision avoidance
KW  - discrete map
KW  - GMM local mapping algorithm
KW  - gaussian mixture model maps
KW  - robots
KW  - CPU
KW  - quadrotor navigation
KW  - depth camera processing
KW  - time-parameterized trajectory
KW  - geometric properties
KW  - probabilistic approach
KW  - cluttered environments
KW  - Trajectory
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Current measurement
KW  - Gaussian mixture model
DO  - 10.1109/IROS.2018.8593723
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.
ER  - 

TY  - CONF
TI  - Integrating Human-Provided Information into Belief State Representation Using Dynamic Factorization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3551
EP  - 3558
AU  - R. Chitnis
AU  - L. P. Kaelbling
AU  - T. Lozano-Pérez
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - 3D continuous cooking task
KW  - 2D discrete gridworld task
KW  - open-domain planning problems
KW  - complex partially observed tasks
KW  - efficient planning
KW  - static factoring
KW  - possible objects
KW  - open domains
KW  - appropriate factoring
KW  - efficient belief state representation
KW  - raw sensory information
KW  - internal knowledge
KW  - sensory observations
KW  - probabilistic relational constraints
KW  - declarative information
KW  - partially observed environments
KW  - dynamic factorization
KW  - Planning
KW  - Robot sensing systems
KW  - Task analysis
KW  - Markov processes
KW  - Intelligent robots
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594468
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In partially observed environments, it can be useful for a human to provide the robot with declarative information that represents probabilistic relational constraints on properties of objects in the world, augmenting the robot's sensory observations. For instance, a robot tasked with a search-and-rescue mission may be informed by the human that two victims are probably in the same room. An important question arises: how should we represent the robot's internal knowledge so that this information is correctly processed and combined with raw sensory information? In this paper, we provide an efficient belief state representation that dynamically selects an appropriate factoring, combining aspects of the belief when they are correlated through information and separating them when they are not. This strategy works in open domains, in which the set of possible objects is not known in advance, and provides significant improvements in inference time over a static factoring, leading to more efficient planning for complex partially observed tasks. We validate our approach experimentally in two open-domain planning problems: a 2D discrete gridworld task and a 3D continuous cooking task. A supplementary video can be found at http://tinyurl.com/chitnis-iros-18.
ER  - 

TY  - CONF
TI  - Simultaneous Task Allocation and Planning Under Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3559
EP  - 3564
AU  - F. Faruq
AU  - D. Parker
AU  - B. Laccrda
AU  - N. Hawes
PY  - 2018
KW  - control engineering computing
KW  - formal verification
KW  - iterative methods
KW  - Markov processes
KW  - mobile robots
KW  - multi-robot systems
KW  - operating systems (computers)
KW  - path planning
KW  - resource allocation
KW  - robot programming
KW  - temporal logic
KW  - simultaneous task allocation
KW  - uncertain environments
KW  - individual robot behaviour
KW  - linear temporal logic
KW  - multirobot policies
KW  - simultaneous task planning
KW  - Markov decision processes
KW  - formal verification
KW  - multirobot operating systems
KW  - Task analysis
KW  - Planning
KW  - Robot kinematics
KW  - Resource management
KW  - Uncertainty
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594404
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.
ER  - 

TY  - CONF
TI  - Strategic-Tactical Planning for Autonomous Underwater Vehicles over Long Horizons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3565
EP  - 3572
AU  - D. Buksz
AU  - M. Cashmore
AU  - B. Krarup
AU  - D. Magazzeni
AU  - B. Ridder
PY  - 2018
KW  - autonomous underwater vehicles
KW  - control engineering computing
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - robot dynamics
KW  - vehicle dynamics
KW  - strategic-tactical planning
KW  - autonomous underwater vehicles
KW  - long horizons
KW  - persistent autonomy
KW  - AI Planners
KW  - long-term autonomous behaviour
KW  - abstraction planning techniques
KW  - two-level hierarchical structure
KW  - hierarchical decompositions
KW  - Task analysis
KW  - Planning
KW  - Manifolds
KW  - Batteries
KW  - Inspection
KW  - Robots
KW  - Valves
DO  - 10.1109/IROS.2018.8594347
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In challenging environments where human intervention is expensive, robust and persistent autonomy is a key requirement. AI Planners can efficiently construct plans to achieve this long-term autonomous behaviour. However, in plans which are expected to last over days, or even weeks, the size of the state-space becomes too large for current planners to solve as a single problem. These problems are well-suited to decomposition and abstraction planning techniques. We present a novel approach in the context of persistent autonomy in autonomous underwater vehicles, in which tasks are complex and diverse and plans cannot be precomputed. Our approach performs a decomposition into a two-level hierarchical structure, which dynamically constructs planning problems at the upper level of the hierarchy using solution plans from the lower level. Solution plans are then executed and monitored simultaneously at both levels. We evaluate the approach, showing that compared to strictly top-down hierarchical decompositions, our approach leads to more robust solution plans of higher quality.
ER  - 

TY  - CONF
TI  - Grid-Based Motion Planning Using Advanced Motions for Hexapod Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3573
EP  - 3578
AU  - W. Cheah
AU  - H. H. Khalili
AU  - S. Watson
AU  - P. Green
AU  - B. Lennox
PY  - 2018
KW  - graph theory
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - grid-based motion planning
KW  - advanced motions
KW  - hexapod robots
KW  - motion planning framework
KW  - chimney walking
KW  - robot motion
KW  - hierarchical planning framework
KW  - custom-designed Corin hexapod
KW  - environment surfaces
KW  - Legged locomotion
KW  - Planning
KW  - Trajectory
KW  - Collision avoidance
KW  - Robot motion
DO  - 10.1109/IROS.2018.8593964
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the motion planning framework for a hexapod, based on advanced motions, for accessing challenging spaces, namely narrow pathways and large holes, both of which are surrounded by walls. The advanced motions, wall and chimney walking, utilise environment surfaces that are perpendicular to the ground plane to support the robot motion. Such techniques have not yet been studied in the literature. The hierarchical planning framework proposed here is an extension to existing approaches which have only considered ground walking where foothold contacts are confined to the ground plane. During the pre-processing phase of the 2.5D grid map, the motion primitives employed are assessed for each cell and stacked to the graph if valid. The A* algorithm is then used to find a path to the goal position. Following that, the path is post-processed to smoothen the motions and generate a continuous path. Footholds are then selected along the path. The framework has been evaluated in simulation on the custom-designed Corin hexapod. The resulting path enables access to areas that are previously thought to be inaccessible and reduces the travelling distance compared to previous studies.
ER  - 

TY  - CONF
TI  - Learning from Demonstration for Hydraulic Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3579
EP  - 3586
AU  - M. Suomalainen
AU  - J. Koivumäki
AU  - S. Lampinen
AU  - V. Kyrki
AU  - J. Mattila
PY  - 2018
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - force sensors
KW  - friction
KW  - hydraulic systems
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - manipulators
KW  - motion control
KW  - position control
KW  - stability
KW  - telerobotics
KW  - fragile force-torque sensor
KW  - heavy-duty hydraulic manipulators
KW  - teleoperated human demonstrations
KW  - novel VDC-based impedance control method
KW  - sliding motion
KW  - learning method
KW  - manipulator actuators
KW  - contact force
KW  - hydraulic slave manipulator
KW  - slave manipulators
KW  - teleoperation system
KW  - stability-guaranteed controller
KW  - virtual decomposition control
KW  - advanced subsystem-dynamic-based control design framework
KW  - human demonstration
KW  - reasonable method
KW  - force-reflected bilateral teleoperation
KW  - extremely powerful hydraulic manipulator
KW  - teleoperated demonstration
KW  - in-contact tasks
KW  - Hydraulic systems
KW  - Force
KW  - Task analysis
KW  - Manipulator dynamics
KW  - Impedance
KW  - Control design
DO  - 10.1109/IROS.2018.8594285
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents, for the first time, a method for learning in-contact tasks from a teleoperated demonstration with a hydraulic manipulator. Due to the use of extremely powerful hydraulic manipulator, a force-reflected bilateral teleoperation is the most reasonable method of giving a human demonstration. An advanced subsystem-dynamic-based control design framework, virtual decomposition control (VDC), is used to design a stability-guaranteed controller for the teleoperation system, while taking into account the full nonlinear dynamics of the master and slave manipulators. The use of fragile force/torque sensor at the tip of the hydraulic slave manipulator is avoided by estimating the contact forces from the manipulator actuators' chamber pressures. In the proposed learning method, it is observed that a surface-sliding tool has a friction-dependent range of directions (between the actual direction of motion and the contact force) from which the manipulator can apply force to produce the sliding motion. By this intuition, an intersection of these ranges can be taken over a motion to robustly find a desired direction for the motion from one or more demonstrations. The compliant axes required to reproduce the motion can be found by assuming that all motions outside the desired direction is caused by the environment, signalling the need for compliance. Finally, the learning method is incorporated to a novel VDC-based impedance control method to learn compliant behaviour from teleoperated human demonstrations. Experiments with 2-DOF hydraulic manipulator with a 475kg payload demonstrate the suitability and effectiveness of the proposed method to perform learning from demonstration (LfD) with heavy-duty hydraulic manipulators.
ER  - 

TY  - CONF
TI  - Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3587
EP  - 3592
AU  - S. Shi
AU  - Y. Cheng
AU  - H. Pan
AU  - W. Zhao
AU  - H. Wu
PY  - 2018
KW  - backpropagation
KW  - collision avoidance
KW  - error compensation
KW  - fusion reactor design
KW  - fusion reactor instrumentation
KW  - high energy physics instrumentation computing
KW  - manipulator kinematics
KW  - neural nets
KW  - physical instrumentation control
KW  - plasma toroidal confinement
KW  - Tokamak devices
KW  - nuclear fusion environment
KW  - Experimental Advanced Superconducting Tokamak
KW  - noncircular cross-section
KW  - real-time detection
KW  - plasma discharges
KW  - EAMA system design
KW  - vacuum-available design scheme
KW  - error prediction
KW  - EAST articulated maintenance arm
KW  - repair operations
KW  - internal components
KW  - high temperature environments
KW  - flexible robot arms
KW  - error compensation
KW  - flexible multijoint manipulator
KW  - EAST ultrahigh vacuum condition
KW  - inverse kinematics
KW  - obstacle avoidance strategy
KW  - back-propagation neural network
KW  - integrated control strategy
KW  - temperature 80.0 degC to 120.0 degC
KW  - Manipulators
KW  - Kinematics
KW  - Predictive models
KW  - Load modeling
KW  - Error compensation
KW  - Strain
DO  - 10.1109/IROS.2018.8593621
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10-5Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.
ER  - 

TY  - CONF
TI  - Progress and Prospects of EAST Remote Maintenance System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3593
EP  - 3598
AU  - H. Pan
AU  - S. Shi
AU  - Y. Cheng
AU  - W. Zhao
PY  - 2018
KW  - automatic optical inspection
KW  - edge detection
KW  - fusion reactor instrumentation
KW  - grippers
KW  - inspection
KW  - maintenance engineering
KW  - nuclear power stations
KW  - object detection
KW  - plasma toroidal confinement
KW  - power system control
KW  - robot vision
KW  - service robots
KW  - Tokamak devices
KW  - light maintenance capability
KW  - tokamak condition
KW  - EAST remote maintenance system
KW  - grasping tasks
KW  - EAMA robot
KW  - EAST articulated maintenance arm
KW  - EAMA control system
KW  - EAST tokamak
KW  - CIVIS
KW  - CFETR in-vessel inspection system
KW  - Maintenance engineering
KW  - Inspection
KW  - Solid modeling
KW  - Manipulators
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594000
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fast inspection and light maintenance capability is already a clear demand to control the tokamak condition and improve the efficiency of the experimental campaigns. EAST remote maintenance system has been developed to implement inspection and grasping tasks during plasma. The paper presents design description of EAMA (EAST articulated maintenance arm) robot, the gripper and the CASK. The field commissioning was performed both in mockup and EAST tokamak to demonstrate the availability and functionalities of EAMA system. To be able to realize fully routine operation on EAST, improvement of EAMA control system was proposed with integration developed algorithm, such as the robot flexible model modeling, vision servo, motion planning, etc. Finally, thoughts for CFETR In-Vessel Inspection System (CIVIS) are given.
ER  - 

TY  - CONF
TI  - Pose Estimation for Mobile Robots to Maximise Data Quality of Fixed-Focus Laser Diagnostics in Hazardous Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3599
EP  - 3604
AU  - A. West
AU  - S. Watson
AU  - B. Lennox
PY  - 2018
KW  - collision avoidance
KW  - laser beam effects
KW  - mobile robots
KW  - pose estimation
KW  - sensor placement
KW  - service robots
KW  - spectroscopy
KW  - pose estimation
KW  - mobile robots
KW  - data quality
KW  - fixed-focus laser diagnostic
KW  - hazardous environments
KW  - nuclear environments
KW  - decommissioning
KW  - LIBS
KW  - scientific instrument
KW  - optical emission
KW  - arbitrary diagnostic mounting
KW  - obstacle avoidance
KW  - diagnostic mounting
KW  - sensor placement
KW  - high intensity pulsed laser
KW  - laser induced breakdown spectroscopy
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Data integrity
KW  - Lasers
KW  - Instruments
KW  - Plasmas
DO  - 10.1109/IROS.2018.8593367
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Characterisation of nuclear environments is critical for long term operation and decommissioning. Laser Induced Breakdown Spectroscopy (LIBS) is an example of a scientific instrument that could be deployed to aid in characterisation of unknown environments. LIBS consists of a high intensity pulsed laser being focussed down onto a target to create a plasma, and optical emission from the plasma is then used to determine elemental composition of unknown materials. For robots deployed with these instruments in extreme environments, mission time can be limited by hazards present such as radiation. Once deployed a robot must be able to collect the best data possible whilst maximising operational runtime. We present a data quality based probabilistic approach to robot pose estimation to maximise data quality, by considering optimum sensor placement whilst avoiding harmful environmental features such as radiation for a fixed-focus laser diagnostic such as LIBS. This approach is able to determine optimum robot poses for arbitrary targets in 3D for arbitrary diagnostic mounting with respect to the robot. The approach is able to avoid obstacles and avoid occlusion of the target by said obstacles. This can be used as part of autonomous investigation and characterisation performed by mobile robots in hazardous environments.
ER  - 

TY  - CONF
TI  - A Variational Feature Encoding Method of 3D Object for Probabilistic Semantic SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3605
EP  - 3612
AU  - H. W. Yu
AU  - B. H. Lee
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - feature extraction
KW  - maximum likelihood estimation
KW  - object recognition
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - object recognition methods
KW  - true generative model
KW  - semantic simultaneous localization and mapping
KW  - maximum likelihood estimation
KW  - shape retrieval
KW  - Bayesian inference
KW  - Bayesian networks
KW  - approximated distributions
KW  - variational auto-encoder
KW  - complex distributions
KW  - observation likelihood
KW  - tractable distributions
KW  - 3D object shapes
KW  - view-independent loop closure
KW  - object shape
KW  - range sensor
KW  - mobile robot
KW  - complex probability distribution
KW  - probabilistic observation model
KW  - high-level semantic features
KW  - complex 3D objects
KW  - probabilistic semantic SLAM
KW  - variational feature encoding method
KW  - Shape
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Semantics
KW  - Solid modeling
KW  - Bayes methods
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593831
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a feature encoding method of complex 3D objects for high-level semantic features. Recent approaches to object recognition methods become important for semantic simultaneous localization and mapping (SLAM). However, there is a lack of consideration of the probabilistic observation model for 3D objects, as the shape of a 3D object basically follows a complex probability distribution. Furthermore, since the mobile robot equipped with a range sensor observes only a single view, much information of the object shape is discarded. These limitations are the major obstacles to semantic SLAM and view-independent loop closure using 3D object shapes as features. In order to enable the numerical analysis for the Bayesian inference, we approximate the true observation model of 3D objects to tractable distributions. Since the observation likelihood can be obtained from the generative model, we formulate the true generative model for 3D object with the Bayesian networks. To capture these complex distributions, we apply a variational auto-encoder. To analyze the approximated distributions and encoded features, we perform classification with maximum likelihood estimation and shape retrieval.
ER  - 

TY  - CONF
TI  - End to End Vehicle Lateral Control Using a Single Fisheye Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3613
EP  - 3619
AU  - M. Toromanoff
AU  - E. Wirbel
AU  - F. Wilhelm
AU  - C. Vejarano
AU  - X. Perrotton
AU  - F. Moutarde
PY  - 2018
KW  - automobiles
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - mobile robots
KW  - robot vision
KW  - steering systems
KW  - label augmentation
KW  - short range fisheye camera
KW  - open road driving
KW  - single fisheye camera
KW  - convolutional neural networks
KW  - steering angle
KW  - autonomous cars
KW  - end-to-end control evaluation
KW  - end-to-end vehicle lateral control
KW  - urban road
KW  - sharp turns
KW  - obstacle avoidance
KW  - data augmentation
KW  - Automobiles
KW  - Cameras
KW  - Roads
KW  - Training
KW  - Neural networks
KW  - Testing
DO  - 10.1109/IROS.2018.8594090
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.
ER  - 

TY  - CONF
TI  - Learning Trajectories for Real- Time Optimal Control of Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3620
EP  - 3625
AU  - G. Tang
AU  - W. Sun
AU  - K. Hauser
PY  - 2018
KW  - control engineering computing
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - optimal control
KW  - quadratic programming
KW  - optimal trajectories
KW  - learning trajectories
KW  - quadrotors
KW  - agile movement
KW  - machine learning
KW  - trajectory optimization approach
KW  - nonlinear optimal control problems
KW  - fly-to-target movement problem
KW  - sparse quadratic programming solver
KW  - neural network
KW  - quadratic optimization
KW  - Trajectory
KW  - Neural networks
KW  - Optimal control
KW  - Training
KW  - Cost function
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593536
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nonlinear optimal control problems are challenging to solve efficiently due to non-convexity. This paper introduces a trajectory optimization approach that achieves realtime performance by combining machine learning to predict optimal trajectories with refinement by quadratic optimization. First, a library of optimal trajectories is calculated offline and used to train a neural network. Online, the neural network predicts a trajectory for a novel initial state and cost function, and this prediction is further optimized by a sparse quadratic programming solver. We apply this approach to a fly-to-target movement problem for an indoor quadrotor. Experiments demonstrate that the technique calculates near-optimal trajectories in a few milliseconds, and generates agile movement that can be tracked more accurately than existing methods.
ER  - 

TY  - CONF
TI  - A Novel OCR-RCNN for Elevator Button Recognition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3626
EP  - 3631
AU  - D. Zhu
AU  - T. Li
AU  - D. Ho
AU  - T. Zhou
AU  - M. Q. Meng
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - optical character recognition
KW  - path planning
KW  - recurrent neural nets
KW  - robot vision
KW  - service robots
KW  - autonomous elevator operation
KW  - inter-floor navigation problem
KW  - elevator button recognition
KW  - severe class imbalance problem
KW  - optical character recognition network
KW  - Faster RCNN architecture
KW  - elevator panels
KW  - OCR-RCNN architecture
KW  - service robots
KW  - image conditions
KW  - Elevators
KW  - Optical character recognition software
KW  - Proposals
KW  - Task analysis
KW  - Feature extraction
KW  - Training
KW  - Pipelines
DO  - 10.1109/IROS.2018.8594071
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous elevator operation is considered an intelligent solution in handling the inter-floor navigation problem of service robots. As one of the most fundamental steps, elevator button recognition starts to receive more and more attention. However, due to the challenging image conditions and severe class imbalance problem, the performance of existing results is unsatisfying. In this paper, we propose to combine an optical character recognition (OCR) network and the Faster RCNN architecture into a single neural network, called OCR-RCNN to facilitate an end-to-end training and elevator button recognition procedure. To verify our method, we collect a large dataset of elevator panels and carry out extensive comparative experiments. The experiment results show that our method can greatly outperform the traditional recognition pipelines, yielding an accurate and robust performance on recognizing untrained elevator buttons.
ER  - 

TY  - CONF
TI  - Cost Functions for Robot Motion Style
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3632
EP  - 3639
AU  - A. Zhou
AU  - A. D. Dragan
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - task constraints
KW  - nominal task cost
KW  - task types
KW  - task instances
KW  - robot motion style
KW  - nuanced costs
KW  - featurized costs
KW  - nominal motion
KW  - cost type
KW  - raw trajectory input
KW  - neural network parameterization operating
KW  - hand-designed features
KW  - weighted linear combination
KW  - cost functions
KW  - trajectory optimization process
KW  - Task analysis
KW  - Robots
KW  - Cost function
KW  - Neural networks
KW  - Trajectory optimization
DO  - 10.1109/IROS.2018.8594433
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We focus on autonomously generating robot motion for day to day physical tasks that is expressive of a certain style or emotion. Because we seek generalization across task instances and task types, we propose to capture style via cost functions that the robot can use to augment its nominal task cost and task constraints in a trajectory optimization process. We compare two approaches to representing such cost functions: a weighted linear combination of hand-designed features, and a neural network parameterization operating on raw trajectory input. For each cost type, we learn weights for each style from user feedback. We contrast these approaches to a nominal motion across different tasks and for different styles in a user study, and find that they both perform on par with each other, and significantly outperform the baseline. Each approach has its advantages: featurized costs require learning fewer parameters and can perform better on some styles, but neural network representations do not require expert knowledge to design features and could even learn more complex, nuanced costs than an expert can easily design.
ER  - 

TY  - CONF
TI  - Game-Theoretic Cooperative Lane Changing Using Data-Driven Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3640
EP  - 3647
AU  - G. Ding
AU  - S. Aghli
AU  - C. Heckman
AU  - L. Chen
PY  - 2018
KW  - game theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - multi-agent systems
KW  - road traffic
KW  - data-driven models
KW  - self-driving vehicles
KW  - autonomous driving
KW  - road-bound multivehicle systems
KW  - DRL
KW  - game theory
KW  - proactive-passive lane changing framework
KW  - Markov game
KW  - multiagent autonomous vehicle tasks
KW  - deep reinforcement learning
KW  - single-agent RL setting
KW  - Games
KW  - Markov processes
KW  - Merging
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Neural networks
KW  - Space vehicles
DO  - 10.1109/IROS.2018.8593725
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.
ER  - 

TY  - CONF
TI  - Imitation Learning for Object Manipulation Based on Position/Force Information Using Bilateral Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3648
EP  - 3653
AU  - T. Adachi
AU  - K. Fujimoto
AU  - S. Sakaino
AU  - T. Tsuji
PY  - 2018
KW  - control engineering computing
KW  - force control
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - position control
KW  - bilateral control
KW  - imitation learning method
KW  - position information
KW  - precise object manipulation
KW  - neural networks
KW  - robots
KW  - position-force information
KW  - Force
KW  - Torque
KW  - Predictive models
KW  - Manipulators
KW  - Angular velocity
KW  - Control systems
DO  - 10.1109/IROS.2018.8594489
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study proposes an imitation learning method based on force and position information. Force information is required for precise object manipulation but is difficult to obtain because the acting and reaction forces cannot be separated. To separate the forces, we proposed to introduce bilateral control, in which the acting and reaction forces are divided using two robots. In the proposed method, two models of neural networks learn a task; to draw a line along a ruler. We verify the possibility that force information is essential to imitate the human skill of object manipulation.
ER  - 

TY  - CONF
TI  - Learning Implicit Sampling Distributions for Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3654
EP  - 3661
AU  - C. Zhang
AU  - J. Huh
AU  - D. D. Lee
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - search problems
KW  - implicit sampling distributions
KW  - motion planning
KW  - sampling-based motion planners
KW  - state space
KW  - sampling distribution
KW  - hand selected heuristics
KW  - policy-search based method
KW  - sampling-based planners
KW  - 7DOF robot arm
KW  - Planning
KW  - Task analysis
KW  - Probability distribution
KW  - Manipulators
KW  - Space exploration
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594028
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling-based motion planners have experienced much success due to their ability to efficiently and evenly explore the state space. However, for many tasks, it may be more efficient to not uniformly explore the state space, especially when there is prior information about its structure. Previous methods have attempted to modify the sampling distribution using hand selected heuristics that can work well for specific environments but not universally. In this paper, a policy-search based method is presented as an adaptive way to learn implicit sampling distributions for different environments. It utilizes information from past searches in similar environments to generate better distributions in novel environments, thus reducing overall computational cost. Our method can be incorporated with a variety of sampling-based planners to improve performance. Our approach is validated on a number of tasks, including a 7DOF robot arm, showing marked improvement in number of collision checks as well as number of nodes expanded compared with baseline methods.
ER  - 

TY  - CONF
TI  - Online Temporal Calibration for Monocular Visual-Inertial Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3662
EP  - 3669
AU  - T. Qin
AU  - S. Shen
PY  - 2018
KW  - calibration
KW  - cameras
KW  - inertial systems
KW  - motion estimation
KW  - optimisation
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - monocular visual-inertial systems
KW  - accurate state estimation
KW  - intelligent applications
KW  - robot navigation
KW  - autonomous driving
KW  - virtual reality
KW  - augmented reality
KW  - visual fusion
KW  - inertial fusion
KW  - sensor fusion
KW  - visual measurements
KW  - inertial measurements
KW  - IMU states
KW  - SLAM system
KW  - feature-based optimization frameworks
KW  - Cameras
KW  - Sensors
KW  - Delays
KW  - Calibration
KW  - Visualization
KW  - Clocks
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593603
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate state estimation is a fundamental module for various intelligent applications, such as robot navigation, autonomous driving, virtual and augmented reality. Visual and inertial fusion is a popular technology for 6-DOF state estimation in recent years. Time instants at which different sensors' measurements are recorded are of crucial importance to the system's robustness and accuracy. In practice, timestamps of each sensor typically suffer from triggering and transmission delays, leading to temporal misalignment (time offsets) among different sensors. Such temporal offset dramatically influences the performance of sensor fusion. To this end, we propose an online approach for calibrating temporal offset between visual and inertial measurements. Our approach achieves temporal offset calibration by jointly optimizing time offset, camera and IMU states, as well as feature locations in a SLAM system. Furthermore, the approach is a general model, which can be easily employed in several feature-based optimization frameworks. Simulation and experimental results demonstrate the high accuracy of our calibration approach even compared with other state-of-art offline tools. The VIO comparison against other methods proves that the online temporal calibration significantly benefits visual-inertial systems. The source code of temporal calibration is integrated into our public project, VINS-Mono1.
ER  - 

TY  - CONF
TI  - Modular Sensor Fusion for Semantic Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3670
EP  - 3677
AU  - H. Blum
AU  - A. Gawel
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - sensor fusion
KW  - statistical analysis
KW  - training sets
KW  - single modality segmentation results
KW  - statistical models
KW  - competitive performance
KW  - statistical fusion approaches
KW  - aligned multisensor training data
KW  - specific architecture
KW  - semantic segmentation approaches
KW  - current multisensor deep learning
KW  - real-world operations
KW  - perceptual range
KW  - robotic systems
KW  - fundamental process
KW  - modular sensor fusion
KW  - Semantics
KW  - Image segmentation
KW  - Robot sensing systems
KW  - Training
KW  - Fuses
KW  - Computer architecture
DO  - 10.1109/IROS.2018.8593786
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.
ER  - 

TY  - CONF
TI  - Robust Sensor Fusion with Self-Tuning Mixture Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3678
EP  - 3685
AU  - T. Pfeifer
AU  - P. Protzel
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - least squares approximations
KW  - mixture models
KW  - nonlinear control systems
KW  - optimisation
KW  - robots
KW  - robust control
KW  - self-adjusting systems
KW  - sensor fusion
KW  - state estimation
KW  - robust sensor fusion
KW  - self-tuning mixture models
KW  - nonlinear state estimation
KW  - robotics
KW  - robust cost functions
KW  - nonGaussian error models
KW  - environmental changes
KW  - ageing
KW  - error distribution
KW  - state estimation process
KW  - Gaussian mixture
KW  - sensor model
KW  - standard state estimation
KW  - implicit expectation-maximization approach
KW  - distribution parameters
KW  - self-tuning algorithm
KW  - least-squares optimization framework
KW  - parameter tuning
KW  - Estimation
KW  - Robot sensing systems
KW  - Optimization
KW  - Tuning
KW  - Biological system modeling
KW  - Heuristic algorithms
KW  - Standards
DO  - 10.1109/IROS.2018.8594459
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.
ER  - 

TY  - CONF
TI  - Trifo-VIO: Robust and Efficient Stereo Visual Inertial Odometry Using Points and Lines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3686
EP  - 3693
AU  - F. Zheng
AU  - G. Tsai
AU  - Z. Zhang
AU  - S. Liu
AU  - C. Chu
AU  - H. Hu
PY  - 2018
KW  - computer graphics
KW  - distance measurement
KW  - filtering theory
KW  - graph theory
KW  - image matching
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - efficient stereo Visual Inertial Odometry
KW  - stereo VIO system
KW  - line features
KW  - system robustness
KW  - point features
KW  - low-texture environment
KW  - lightweight filtering-based loop closing technique
KW  - global bundle adjustment
KW  - graph optimization
KW  - current sliding window
KW  - Trifo Ironsides dataset
KW  - visual-inertial dataset
KW  - high-quality synchronized stereo camera
KW  - Cameras
KW  - Optimization
KW  - Visualization
KW  - Feature extraction
KW  - Image edge detection
KW  - Three-dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594354
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present the Trifo Visual Inertial Odometry (Trifo-VIO), a tightly-coupled filtering-based stereo VIO system using both points and lines. Line features help improve system robustness in challenging scenarios when point features cannot be reliably detected or tracked, e.g. low-texture environment or lighting change. In addition, we propose a novel lightweight filtering-based loop closing technique to reduce accumulated drift without global bundle adjustment or pose graph optimization. We formulate loop closure as EKF updates to optimally relocate the current sliding window maintained by the filter to past keyframes. We also present the Trifo Ironsides dataset, a new visual-inertial dataset, featuring high-quality synchronized stereo camera and IMU data from the Ironsides sensor [3] with various motion types and textures and millimeter-accuracy groundtruth. To validate the performance of the proposed system, we conduct extensive comparison with state-of-the-art approaches (OKVIS, VINS-MONO and S-MSCKF) using both the public EuRoC dataset and the Trifo Ironsides dataset.
ER  - 

TY  - CONF
TI  - Scale Correct Monocular Visual Odometry Using a LiDAR Altimeter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3694
EP  - 3700
AU  - R. Giubilato
AU  - S. Chiodini
AU  - M. Pertile
AU  - S. Debei
PY  - 2018
KW  - distance measurement
KW  - image sequences
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - stereo visual SLAM
KW  - monocular vision
KW  - inherent scale ambiguity
KW  - LiDAR altimeter
KW  - scale correct monocular visual odometry
KW  - RGB-D methods
KW  - scale drift
KW  - keyframe basis
KW  - scale constraint
KW  - mapping algorithm
KW  - keyframe based tracking
KW  - Visual Odometry method
KW  - laser altimeter
KW  - range data
KW  - exploration vehicles
KW  - power requirements
KW  - computational load
KW  - metrological accuracy
KW  - RGB-D sensors
KW  - 3D LiDARs
KW  - metric references
KW  - sensory sources
KW  - Cameras
KW  - Laser radar
KW  - Measurement
KW  - Three-dimensional displays
KW  - Visual odometry
KW  - Visualization
KW  - Sensors
DO  - 10.1109/IROS.2018.8594096
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The inherent scale ambiguity in monocular vision is a well known issue that forces the integration of other sensory sources to obtain metric references. However, 2D or 3D LiDARs and RGB-D sensors, while guaranteeing metrological accuracy, impose a non negligible burden both in terms of computational load and power requirements limiting the feasibility of being implemented on small exploration vehicles. This paper presents a scale aware monocular Visual Odometry framework that fuses range data from a laser altimeter in order to recover and maintain a correct metric scale. The proposed Visual Odometry method consists of a keyframe based tracking and mapping algorithm using optical flow where range data serves as a scale constraint on a keyframe to keyframe basis. An optimization backend based on iSAM2 is employed in order to refine the trajectory and map estimates eliminating the scale drift without the need of performing loop closures. We demonstrate that our algorithm can obtain very similar performances to state of the art stereo visual SLAM and RGB-D methods.
ER  - 

TY  - CONF
TI  - Robust Visual-Inertial State Estimation with Multiple Odometries and Efficient Mapping on an MAV with Ultra-Wide FOV Stereo Vision
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3701
EP  - 3708
AU  - M. G. Miiller
AU  - F. Steidle
AU  - M. J. Schuster
AU  - P. Lutz
AU  - M. Maier
AU  - S. Stoneman
AU  - T. Tomic
AU  - W. Stürzl
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - distance measurement
KW  - estimation theory
KW  - image fusion
KW  - image sensors
KW  - inertial navigation
KW  - motion estimation
KW  - motion measurement
KW  - state estimation
KW  - stereo image processing
KW  - visual perception
KW  - wide-angle stereo cameras
KW  - multicopter system
KW  - inertial measurement unit
KW  - virtual pinhole cameras
KW  - independent visual odometry
KW  - vision system
KW  - sensor fusion
KW  - robust visual-inertial state estimation
KW  - ultrawide FOV stereo vision
KW  - MAV
KW  - IMU
KW  - robust visual-inertial navigation
KW  - omnidirectional 3D mapping pipeline experiment
KW  - field of view
KW  - synthesized pinhole stereo systems
KW  - motion estimation fusion
KW  - image processing
KW  - multiVO approach
KW  - Cameras
KW  - Distortion
KW  - Image resolution
KW  - Computational modeling
KW  - Navigation
KW  - Visual odometry
KW  - Hardware
DO  - 10.1109/IROS.2018.8594117
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The here presented flying system uses two pairs of wide-angle stereo cameras and maps a large area of interest in a short amount of time. We present a multicopter system equipped with two pairs of wide-angle stereo cameras and an inertial measurement unit (IMU) for robust visual-inertial navigation and time-efficient omni-directional 3D mapping. The four cameras cover a 240 degree stereo field of view (FOV) vertically, which makes the system also suitable for cramped and confined environments like caves. In our approach, we synthesize eight virtual pinhole cameras from four wide-angle cameras. Each of the resulting four synthesized pinhole stereo systems provides input to an independent visual odometry (VO). Subsequently, the four individual motion estimates are fused with data from an IMU, based on their consistency with the state estimation. We describe the configuration and image processing of the vision system as well as the sensor fusion and mapping pipeline on board the MAV. We demonstrate the robustness of our multi-VO approach for visual-inertial navigation and present results of a 3D-mapping experiment.
ER  - 

TY  - CONF
TI  - Plugo: A Scalable Visible Light Communication System Towards Low-Cost Indoor Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3709
EP  - 3714
AU  - Q. Liang
AU  - L. Wang
AU  - Y. Li
AU  - M. Liu
PY  - 2018
KW  - free-space optical communication
KW  - indoor communication
KW  - photodiodes
KW  - Plugo
KW  - novel VLC system
KW  - cheap photodiode receiver
KW  - VLC-based localization techniques
KW  - location-aware applications
KW  - scalable visible light communication system
KW  - preliminary localization result
KW  - VLC signals
KW  - low-cost offthe-shelf components
KW  - compact VLC-compatible
KW  - dedicated wireless access points
KW  - conventional RF-based approaches
KW  - low-cost indoor localization
KW  - random multiple access
KW  - Light emitting diodes
KW  - Receivers
KW  - Wireless communication
KW  - Optical transmitters
KW  - Encoding
KW  - Frequency modulation
DO  - 10.1109/IROS.2018.8594287
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor localization is critical to many location-aware applications, however, a low-cost solution with guaranteed accuracies has not yet come. Visible Light Communication (VLC-) based localization techniques are very promising to fill this gap. In this paper, we propose Plugo, a novel VLC system with random multiple access towards low-cost indoor localization. Compared to conventional RF-based approaches that rely on dedicated wireless access points as location beacons, the proposed system has the potential to deliver better accuracies with reduced cost. Specifically, we build a handful of compact VLC-compatible LED bulbs out of low-cost offthe-shelf components (around $10 total cost for each assembly) and recover VLC signals using a cheap photodiode receiver. The basic framed slotted Additive Links On-line Hawaii Area (ALOHA) is exploited to achieve random multiple access over the shared optical medium. We show its effectiveness in beacon broadcasting by experiments, and further, demonstrate a preliminary localization result with sound accuracy by using fingerprinting-based methods in a customized testbed.
ER  - 

TY  - CONF
TI  - Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3723
EP  - 3729
AU  - A. Li
AU  - L. Wang
AU  - P. Pierpaoli
AU  - M. Egerstedt
PY  - 2018
KW  - convergence
KW  - mobile robots
KW  - multi-robot systems
KW  - composition strategy
KW  - mobile robots
KW  - multirobot systems
KW  - efficient solution
KW  - low-level tasks
KW  - high-level missions
KW  - single behavior
KW  - requisite expressiveness
KW  - provably correct composition
KW  - terminal configuration
KW  - valid initial configuration
KW  - nominal control inputs
KW  - control barrier certificates
KW  - finite-time convergence control barrier functions
KW  - information-exchange network
KW  - Convergence
KW  - Robot kinematics
KW  - Task analysis
KW  - Multi-robot systems
KW  - Mobile robots
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594302
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3730
EP  - 3737
AU  - K. Doherty
AU  - G. Flaspohler
AU  - N. Roy
AU  - Y. Girdhar
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - oceanographic equipment
KW  - optimisation
KW  - underwater equipment
KW  - unsupervised learning
KW  - distributed spatiotemporal topic models
KW  - real seabed imagery
KW  - multirobot underwater terrain characterization
KW  - local robot topic distributions
KW  - local topic model
KW  - multirobot distributed learning
KW  - marine robots
KW  - multirobot teams
KW  - multiple robots
KW  - single-robot topic models
KW  - learned models
KW  - unsupervised models
KW  - raw data
KW  - latent structure
KW  - Bayesian topic models
KW  - unsupervised learning techniques
KW  - multirobot terrain characterization
KW  - Adaptation models
KW  - Robot sensing systems
KW  - Spatiotemporal phenomena
KW  - Data models
KW  - Visualization
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594442
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.
ER  - 

TY  - CONF
TI  - On the Use of Energy Tanks for Multi-Robot Interconnection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3738
EP  - 3743
AU  - G. Riggio
AU  - C. Fantuzzi
AU  - C. Secchi
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - robust control
KW  - energy tank
KW  - multirobot systems passive interconnections
KW  - robustly stable cooperative behavior
KW  - passivity constraint
KW  - novel generalized interconnection
KW  - passive systems
KW  - coupled system
KW  - Couplings
KW  - Damping
KW  - Robots
KW  - Multi-robot systems
KW  - Robust stability
KW  - Buildings
KW  - Nonlinear dynamical systems
DO  - 10.1109/IROS.2018.8594262
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.
ER  - 

TY  - CONF
TI  - A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3744
EP  - 3750
AU  - R. Ravichandran
AU  - E. Prassler
AU  - N. Huebel
AU  - S. Blumenthal
PY  - 2018
KW  - database management systems
KW  - multi-robot systems
KW  - multirobot applications
KW  - robots
KW  - log files
KW  - querying features
KW  - scaling capabilities
KW  - modern databases
KW  - multirobot systems
KW  - robotic use cases
KW  - benchmarking scenarios
KW  - networked multirobot architectures
KW  - extensible workbench
KW  - benchmarking databases
KW  - Databases
KW  - Robot sensing systems
KW  - Benchmark testing
KW  - Containers
KW  - Systems architecture
DO  - 10.1109/IROS.2018.8594241
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.
ER  - 

TY  - CONF
TI  - Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3751
EP  - 3756
AU  - I. Buckley
AU  - M. Egerstedt
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - self-assembly
KW  - robots measure
KW  - frame-work
KW  - infinitesimally shape-similar frameworks
KW  - shape-similarity matrix
KW  - differential-drive robots
KW  - formation control strategies
KW  - multirobot team
KW  - infinitesimal shape-similarity
KW  - Robot sensing systems
KW  - Transmission line matrix methods
KW  - Self-assembly
KW  - Shape
KW  - Trajectory
KW  - Multi-Robot Systems
DO  - 10.1109/IROS.2018.8594381
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.
ER  - 

TY  - CONF
TI  - Optimal Redeployment of Multirobot Teams for Communication Maintenance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3757
EP  - 3764
AU  - J. Banfi
AU  - N. Basilico
AU  - S. Carpin
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - human-robot interaction
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal redeployment
KW  - multirobot teams
KW  - communication maintenance
KW  - mobile robots
KW  - communication relays
KW  - computational complexity
KW  - Integer Linear Programming formulation
KW  - approximation hardness
KW  - Maintenance engineering
KW  - Relays
KW  - Task analysis
KW  - Complexity theory
KW  - Linear programming
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593532
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.
ER  - 

TY  - CONF
TI  - Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3765
EP  - 3770
AU  - P. Maini
AU  - G. Gupta
AU  - P. Tokekar
AU  - P. B. Sujit
PY  - 2018
KW  - aerospace robotics
KW  - dynamic programming
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - visibility-based monitoring
KW  - heterogeneous robot team
KW  - terrain path
KW  - aerial robots
KW  - route planning
KW  - dynamic programming approach
KW  - integer linear programming solution
KW  - ground robots
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
KW  - Educational robots
KW  - Monitoring
KW  - Dynamic programming
KW  - Integrated circuits
DO  - 10.1109/IROS.2018.8593960
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.
ER  - 

TY  - CONF
TI  - Algorithms for Task Allocation in Homogeneous Swarm of Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3771
EP  - 3776
AU  - D. K. Jha
PY  - 2018
KW  - control system synthesis
KW  - decentralised control
KW  - feedback
KW  - Markov processes
KW  - mobile robots
KW  - multi-robot systems
KW  - task allocation
KW  - homogeneous swarm
KW  - homogeneous robots
KW  - Markov chain
KW  - agent converges
KW  - local-decentralized controllers
KW  - controller design
KW  - local-feedback
KW  - Task analysis
KW  - Markov processes
KW  - Robot kinematics
KW  - Kernel
KW  - Probabilistic logic
KW  - Q measurement
DO  - 10.1109/IROS.2018.8594052
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.
ER  - 

TY  - CONF
TI  - Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3777
EP  - 3782
AU  - J. Hooks
AU  - D. Hong
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulators
KW  - robot dynamics
KW  - autonomous legged personal helper robot
KW  - enhanced dynamics
KW  - multimodal legged robotic platform
KW  - versatile 3D ZMP trajectory optimization algorithm
KW  - stable locomotion
KW  - multimodal robotic platform
KW  - 2D zero moment point trajectory optimization
KW  - manipulation
KW  - light weight robotic system
KW  - Legged locomotion
KW  - Foot
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593968
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.
ER  - 

TY  - CONF
TI  - Hybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3783
EP  - 3790
AU  - R. Hartley
AU  - M. G. Jadidi
AU  - L. Gan
AU  - J. Huang
AU  - J. W. Grizzle
AU  - R. M. Eustice
PY  - 2018
KW  - distance measurement
KW  - graph theory
KW  - inertial navigation
KW  - legged locomotion
KW  - motion estimation
KW  - optimisation
KW  - sensor fusion
KW  - state estimation
KW  - factor graphs
KW  - robotic state estimation
KW  - sensor fusion framework
KW  - legged robots
KW  - visual encoder
KW  - inertial encoder
KW  - visual-inertial odometry
KW  - visual-inertial navigation systems
KW  - cassie-series robot
KW  - nonlinear optimization
KW  - motion capture system
KW  - preintegration theory
KW  - Kinematics
KW  - Legged locomotion
KW  - Optimization
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593801
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The factor graph framework is a convenient modeling technique for robotic state estimation where states are represented as nodes, and measurements are modeled as factors. When designing a sensor fusion framework for legged robots, one often has access to visual, inertial, joint encoder, and contact sensors. While visual-inertial odometry has been studied extensively in this framework, the addition of a preintegrated contact factor for legged robots has been only recently proposed. This allowed for integration of encoder and contact measurements into existing factor graphs, however, new nodes had to be added to the graph every time contact was made or broken. In this work, to cope with the problem of switching contact frames, we propose a hybrid contact preintegration theory that allows contact information to be integrated through an arbitrary number of contact switches. The proposed hybrid modeling approach reduces the number of required variables in the nonlinear optimization problem by only requiring new states to be added alongside camera or selected keyframes. This method is evaluated using real experimental data collected from a Cassie-series robot where the trajectory of the robot produced by a motion capture system is used as a proxy for ground truth. The evaluation shows that inclusion of the proposed preintegrated hybrid contact factor alongside visual-inertial navigation systems improves estimation accuracy as well as robustness to vision failure, while its generalization makes it more accessible for legged platforms.
ER  - 

TY  - CONF
TI  - Stable, Autonomous, Unknown Terrain Locomotion for Quadrupeds Based on Visual Feedback and Mixed-Integer Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3791
EP  - 3798
AU  - M. S. Ahn
AU  - H. Chae
AU  - D. W. Hong
PY  - 2018
KW  - convex programming
KW  - integer programming
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - quadratic programming
KW  - robot vision
KW  - visual feedback
KW  - mixed-integer convex optimization
KW  - complete motion planning approach
KW  - quadruped locomotion
KW  - convex polygons
KW  - potentially feasible foothold regions
KW  - feasible destination planner
KW  - extracted polygons
KW  - footstep planner
KW  - mass trajectory planner
KW  - path planner
KW  - stable terrain locomotion
KW  - autonomous terrain locomotion
KW  - unknown terrain locomotion
KW  - quadrupeds
KW  - feasible goal position
KW  - ALPHRED
KW  - Optimization
KW  - Trajectory
KW  - Legged locomotion
KW  - Planning
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594015
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a complete motion planning approach for quadruped locomotion across an unknown terrain using a framework based on mixed-integer convex optimization and visual feedback. Vision data is used to find convex polygons in the surrounding environment, which acts as potentially feasible foothold regions. Then, a goal position is initially provided, which the best feasible destination planner uses to solve for an actual feasible goal position based on the extracted polygons. Next, a footstep planner uses the feasible goal position to plan a fixed number of footsteps, which may or may not result in the robot reaching the position. The center of mass (COM) trajectory planner using quadratic programming is extended to solve for a trajectory in 3D space while maintaining convexity, which reduces the computation time, allowing the robot to plan and execute motions online. The suggested method is implemented as a policy rather than a path planner, but its performance as a path planner is also shown. The approach is verified on both simulation and on a physical robot, ALPHRED, walking on various unknown terrains.
ER  - 

TY  - CONF
TI  - Leg Design to Enable Dynamic Running and Climbing on BOBCAT
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3799
EP  - 3806
AU  - M. P. Austin
AU  - J. M. Brown
AU  - C. A. Young
AU  - J. E. Clark
PY  - 2018
KW  - legged locomotion
KW  - manipulator dynamics
KW  - robot kinematics
KW  - design tool
KW  - leg configuration
KW  - multimodal platform BOBCAT
KW  - leg design
KW  - design process
KW  - leg morphology
KW  - manipulator community
KW  - dynamic workspace
KW  - template dynamics
KW  - dynamic climbing
KW  - dynamic running
KW  - Legged locomotion
KW  - Dynamics
KW  - Couplings
KW  - Force
KW  - Kinematics
KW  - Foot
DO  - 10.1109/IROS.2018.8594355
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The design process for leg morphology has taken much of its inspiration from the manipulator community, including the concept of maximizing the workspace of a design. In this paper, we define the concept of Effective Dynamic Workspace, which examines the subset of the overall workspace capable of achieving the desired template dynamics. With this new design tool, the leg configuration of a new multi-modal platform BOBCAT is examined and refined. With the refined design, BOBCAT is able to achieve speeds of 2m/s while running and 0.17m/s while climbing a vertical wall.
ER  - 

TY  - CONF
TI  - Learning Hardware Dynamics Model from Experiments for Locomotion Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3807
EP  - 3814
AU  - K. Chen
AU  - S. Ha
AU  - K. Yamane
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - locomotion optimization
KW  - hardware compatibility
KW  - hardware-compatible motion plan
KW  - linear inverted pendulum
KW  - ZMP
KW  - hardware dynamics model learning
KW  - zero moment point
KW  - LIP
KW  - center of mass
KW  - quadruped
KW  - Hardware
KW  - Optimization
KW  - Dynamics
KW  - Legged locomotion
KW  - Data models
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8593804
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The hardware compatibility of legged locomotion is often illustrated by Zero Moment Point (ZMP) that has been extensively studied for decades. One of the most popular models for computing the ZMP is the linear inverted pendulum (LIP) model that expresses ZMP as a linear function of the center of mass(COM) and its acceleration. In the real world, however, it may not accurately predict the true ZMP of hardware due to various reasons such as unmodeled dynamics and differences between simulation model and hardware. In this paper, we aim to improve the theoretical ZMP model by learning the real hardware dynamics from experimental data. We first optimize the motion plan using the theoretical ZMP model and collect COP data by executing the motion on a force plate. We then train a new ZMP model that maps the motion plan variable to the actual ZMP and use the learned model for finding a new hardware-compatible motion plan. Through various locomotion tasks of a quadruped, we demonstrate that motions planned for the learned ZMP model are compatible on hardware when those for the theoretical ZMP model are not. Furthermore, experiments using ZMP models with different complexities reveal that overly complex models may suffer from over-fitting even though they can potentially represent more complex, unmodeled dynamics.
ER  - 

TY  - CONF
TI  - Iterative Learning of Energy-Efficient Dynamic Walking Gaits
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3815
EP  - 3820
AU  - F. H. Kong
AU  - I. R. Manchester
PY  - 2018
KW  - iterative methods
KW  - learning systems
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - energy-efficient dynamic walking gaits
KW  - dynamic walking robots
KW  - lifelike locomotion
KW  - efficient gaits
KW  - Iterative Learning Control
KW  - control signal
KW  - periodic reference
KW  - terminal ILC
KW  - dynamic walking robot gaits
KW  - final foot placement
KW  - energy efficiency
KW  - phase-indexed TILC
KW  - energy-efficient walking motion
KW  - time-indexed TILC
KW  - Legged locomotion
KW  - Computational modeling
KW  - Data models
KW  - Foot
KW  - Planning
KW  - Convergence
DO  - 10.1109/IROS.2018.8593548
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic walking robots have the potential for efficient and lifelike locomotion, but computing efficient gaits and tracking them is difficult in the presence of under-modeling. Iterative Learning Control (ILC) is a method to learn the control signal to track a periodic reference over several attempts, augmenting a model with online data. Terminal ILC (TILC), a variant of ILC, allows other performance objectives to be addressed at the cost of ignoring parts of the reference. However, dynamic walking robot gaits are not necessarily periodic in time. In this paper, we adapt TILC to jointly optimize final foot placement and energy efficiency on dynamic walking robots by indexing by a phase variable instead of time, yielding “phase-indexed TILC” (θ - TILC). When implemented on a five-link walker in simulation, θ- TILC learns a more energy-efficient walking motion compared to traditional time-indexed TILC.
ER  - 

TY  - CONF
TI  - Bipedal Hopping: Reduced-Order Model Embedding via Optimization-Based Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3821
EP  - 3828
AU  - X. Xiong
AU  - A. D. Ames
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - legged locomotion
KW  - Lyapunov methods
KW  - nonlinear control systems
KW  - quadratic programming
KW  - robot dynamics
KW  - robot kinematics
KW  - springs (mechanical)
KW  - stability
KW  - bipedal hopping
KW  - reduced-order model embedding
KW  - optimization-based control
KW  - spring-mass model
KW  - spring stiffness
KW  - damping
KW  - trajectory optimization
KW  - control Lyapunov function
KW  - CLF-QP
KW  - nonlinear feedback control law
KW  - dynamic jumping behaviors
KW  - bipedal robots
KW  - 3D bipedal robot Cassie
KW  - quadratic program
KW  - Legged locomotion
KW  - Springs
KW  - Robot kinematics
KW  - Kinematics
KW  - Hip
KW  - Jacobian matrices
DO  - 10.1109/IROS.2018.8593547
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and validation of controlling hopping on the 3D bipedal robot Cassie. A spring-mass model is identified from the kinematics and compliance of the robot. The spring stiffness and damping are encapsulated by the leg length, thus actuating the leg length can create and control hopping behaviors. Trajectory optimization via direct collocation is performed on the spring-mass model to plan jumping and landing motions. The leg length trajectories are utilized as desired outputs to synthesize a control Lyapunov function based quadratic program (CLF-QP). Centroidal angular momentum, taking as an addition output in the CLF-QP, is also stabilized in the jumping phase to prevent whole body rotation in the underactuated flight phase. The solution to the CLF-QP is a nonlinear feedback control law that achieves dynamic jumping behaviors on bipedal robots with compliance. The framework presented in this paper is verified experimentally on the bipedal robot Cassie.
ER  - 

TY  - CONF
TI  - An Actuator Design Criterion to Maximize Physical Balance Recovery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2829
EP  - 2836
AU  - J. J. M. Driessen
AU  - R. Featherstone
AU  - A. E. Gkikakis
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - gears
KW  - legged locomotion
KW  - mechanical stability
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - wheels
KW  - legged robot
KW  - hip joint
KW  - balance recovery motion
KW  - actuator design
KW  - physical balance recovery
KW  - electric motor
KW  - gear reduction
KW  - wheel pendulum
KW  - robot design
KW  - Actuators
KW  - Torque
KW  - Robot kinematics
KW  - Friction
KW  - Electrical resistance measurement
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8593729
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper first presents a formula to predict the largest balance disturbance from which a legged robot can recover without taking a step. It then presents an actuator design criterion derived from this formula that maximizes the robot's ability to recover. In this study, it is assumed that the robot is using a single major joint (e.g, a hip joint) to perform its balance recovery movement, and that the actuator consists of an electric motor and reduction gear. It is also assumed that the robot's support polygon is sufficiently small that it can be approximated as a point, and that the balance recovery motion is essentially planar, so that a 2-D analysis remains valid in 3-D. Finally, it is assumed that, for the purpose of studying balance recovery motion, the robot can be approximated by a reaction wheel pendulum. The theory has been tested experimentally on a robot designed to be good at balancing, and was found to agree closely with experimental results.
ER  - 

TY  - CONF
TI  - Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3845
EP  - 3852
AU  - V. Virdyawan
AU  - F. R. Y Baena
PY  - 2018
KW  - biomedical optical imaging
KW  - blood vessels
KW  - brain
KW  - collision avoidance
KW  - Doppler measurement
KW  - image motion analysis
KW  - laser applications in medicine
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - pose estimation
KW  - steering systems
KW  - surgery
KW  - percutaneous procedures
KW  - hemorrhage
KW  - vessel motion
KW  - tissue bulk motion
KW  - Doppler signals
KW  - multiple forward looking sensors
KW  - preoperative imaging modalities
KW  - vessel pose estimation
KW  - needle steering systems
KW  - robotic assisted needle insertion process
KW  - vessel detection
KW  - biologically inspired steerable needle
KW  - laser Doppler flowmetry
KW  - life threatening complications
KW  - percutaneous interventions
KW  - needle steering surgery
KW  - obstacle avoidance
KW  - Needles
KW  - Probes
KW  - Phantoms
KW  - Sensors
KW  - Doppler effect
KW  - Gold
KW  - Grey matter
DO  - 10.1109/IROS.2018.8594198
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.
ER  - 

TY  - CONF
TI  - Trajectory Optimization of Robot-Assisted Endovascular Catheterization with Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3875
EP  - 3881
AU  - W. Chi
AU  - J. Liu
AU  - M. E. M. K. Abdelaziz
AU  - G. Dagnino
AU  - C. Riga
AU  - C. Bicknell
AU  - G. Yang
PY  - 2018
KW  - blood vessels
KW  - cardiovascular system
KW  - catheters
KW  - diagnostic radiography
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - path planning
KW  - patient treatment
KW  - surgery
KW  - telerobotics
KW  - catheter manipulation
KW  - learning-based robotic catheterization platform
KW  - dynamic movement primitives
KW  - catheterization tasks
KW  - customized robotic manipulator
KW  - robotic trajectories
KW  - catheter tip
KW  - hands-on robotic navigation platforms
KW  - trajectory optimization
KW  - robot-assisted endovascular catheterization
KW  - flow simulations
KW  - X-ray radiation reduction
KW  - path integral RL
KW  - path integral reinforcement learning
KW  - Robots
KW  - Catheters
KW  - Task analysis
KW  - Catheterization
KW  - Surgery
KW  - Trajectory
KW  - Navigation
DO  - 10.1109/IROS.2018.8593421
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Emerging robot-assisted endovascular intervention has the potential to reduce X-ray radiations to the operator while enhancing the stability and dexterity of catheter manipulation. Supervised and shared autonomy of endovascular procedures could add further improvements in reduced fatigue and cognitive workloads of the operator, higher success rates of cannulation and improved surgical outcomes. However, robotic path planning for endovascular procedure is challenging due to complex and non-linear flow dynamics inside the vasculature. This paper presents a learning-based robotic catheterization platform addressing those challenges, this approach incorporates path integral reinforcement learning (RL) framework based on dynamic movement primitives (DMP) to enhance catheterization tasks by a customized robotic manipulator. The robotic trajectories were optimized through RL in order to avoid unwanted contacts between the catheter tip and the vessel wall. The proposed methods can adapt to different flow simulations, vascular models, and catheterization tasks. The quality of the catheterization was evaluated with performance metrics. The results show significant refinement of catheter paths by the proposed approach, resulting in shorter overall lengths and fewer contact forces, which can potentially reduce risks in endothelial wall damages, embolization, and stroke. The results support the development of robotic path planning for endovascular procedures as well as designing intelligent, hands-on robotic navigation platforms.
ER  - 

TY  - CONF
TI  - ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3882
EP  - 3889
AU  - A. Marmol
AU  - P. Corke
AU  - T. Peynot
PY  - 2018
KW  - biomedical optical imaging
KW  - cameras
KW  - endoscopes
KW  - image sensors
KW  - Kalman filters
KW  - medical image processing
KW  - medical robotics
KW  - orthopaedics
KW  - SLAM (robots)
KW  - surgery
KW  - image feedback
KW  - ArthroSLAM
KW  - Simultaneous Localisation and Mapping system
KW  - SLAM system
KW  - external camera
KW  - robotic arm
KW  - minimally invasive arthroscopic surgery
KW  - minimally invasive orthopedic surgery
KW  - robotic orthopedic surgical assistant
KW  - knee section
KW  - human cadaver knee joint
KW  - Extended Kalman Filter framework
KW  - arthroscope holder
KW  - intraarticular space
KW  - Cameras
KW  - Robot vision systems
KW  - Visualization
KW  - Reliability
DO  - 10.1109/IROS.2018.8593501
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.
ER  - 

TY  - CONF
TI  - I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3897
EP  - 3904
AU  - J. Stolzenwald
AU  - W. W. Mayol-Cuevas
PY  - 2018
KW  - gaze tracking
KW  - human-robot interaction
KW  - mobile robots
KW  - robot vision
KW  - robot autonomy
KW  - attention model
KW  - user attention
KW  - handheld robot collaboration
KW  - handheld tool
KW  - task knowledge
KW  - tool-mounted gaze tracking system
KW  - video game setup
KW  - cooperative handheld robot
KW  - Task analysis
KW  - Robot kinematics
KW  - Tools
KW  - Tracking
KW  - Gaze tracking
KW  - Estimation
DO  - 10.1109/IROS.2018.8594184
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users.
ER  - 

TY  - CONF
TI  - Recursive Bayesian Human Intent Recognition in Shared-Control Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3905
EP  - 3912
AU  - S. Jain
AU  - B. Argall
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - human-robot interaction
KW  - inference mechanisms
KW  - mobile robots
KW  - telerobotics
KW  - recursive Bayesian human intent recognition
KW  - shared-control robotics
KW  - human-robot collaboration
KW  - mathematical formulation
KW  - assistive teleoperation
KW  - recursive Bayesian filtering approach models
KW  - nonverbal observations
KW  - contextual observations
KW  - goal-directed actions
KW  - human inference
KW  - robot motion
KW  - autonomy intent inference performance
KW  - shared-control operation
KW  - probabilistic reasoning
KW  - human intent recognition
KW  - human agents behavior
KW  - probabilistic fusion
KW  - Robots
KW  - Bayes methods
KW  - Task analysis
KW  - Hidden Markov models
KW  - Uncertainty
KW  - Mathematical model
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593766
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.
ER  - 

TY  - CONF
TI  - A Novel Shared Position Control Method for Robot Navigation Via Low Throughput Human-Machine Interfaces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3913
EP  - 3920
AU  - D. A. Sinyukov
AU  - T. Padır
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - user interfaces
KW  - wheelchairs
KW  - shared position control method
KW  - inference parallelization
KW  - low throughput human-machine interfaces
KW  - robot navigation
KW  - robotic wheelchair
KW  - circular massless holonomic robot
KW  - robot motion
KW  - single switch interface
KW  - brain-computer interface
KW  - Navigation
KW  - Wheelchairs
KW  - Mobile robots
KW  - Position control
KW  - Linear systems
KW  - Throughput
DO  - 10.1109/IROS.2018.8593921
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we analyze systems with low throughput human-machine interfaces (such as a brain-computer interface, single switch interface) from the controls perspective. We develop some principles for performance improvement in such systems based on the parallelization of inference and robot motion. The proposed principles are used to design a novel shared position control to navigate a circular massless holonomic robot in a known environment. The system is implemented in simulation and integrated with a real robotic wheelchair. Robot experiments demonstrated the viability of the proposed navigation method in various modes of operation.
ER  - 

TY  - CONF
TI  - Robot Identification and Localization with Pointing Gestures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3921
EP  - 3928
AU  - B. Gromov
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2018
KW  - distance measurement
KW  - gesture recognition
KW  - mobile robots
KW  - multi-robot systems
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - mobile robot
KW  - multirobot scenarios
KW  - robot identification and localization
KW  - gesture pointing
KW  - robot odometry frame
KW  - inertial measurement unit
KW  - IMU
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Solid modeling
KW  - Manipulators
KW  - Drones
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594174
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.
ER  - 

TY  - CONF
TI  - Establishing Appropriate Trust via Critical States
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3929
EP  - 3936
AU  - S. H. Huang
AU  - K. Bhatia
AU  - P. Abbeel
AU  - A. D. Dragan
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robots
KW  - trusted computing
KW  - appropriate trust
KW  - critical states
KW  - learned neural network policies
KW  - end-users
KW  - mental model
KW  - robot learning
KW  - Autonomous automobiles
KW  - Cognitive science
KW  - Task analysis
KW  - Automobiles
KW  - Reinforcement learning
KW  - Entropy
DO  - 10.1109/IROS.2018.8593649
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.
ER  - 

TY  - CONF
TI  - Learned Hand Gesture Classification Through Synthetically Generated Training Samples
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3937
EP  - 3942
AU  - K. Lindgren
AU  - N. Kalavakonda
AU  - D. E. Caballero
AU  - K. Huang
AU  - B. Hannaford
PY  - 2018
KW  - gesture recognition
KW  - human computer interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - user input mechanism
KW  - intuitive control
KW  - physical constraints
KW  - ambient electrical interference
KW  - light interference
KW  - sound interference
KW  - semantic information
KW  - logical information
KW  - communication channel
KW  - human-machine interfaces
KW  - hand gesture recognition
KW  - synthetic hand gesture dataset generation
KW  - physical data collection
KW  - real-world hand gesture classifier
KW  - learned hand gesture classification
KW  - synthetically generated training samples
KW  - natural component
KW  - human-human communication
KW  - rule-based classification schemes
KW  - data-driven deep learning approaches
KW  - Training
KW  - Gesture recognition
KW  - Training data
KW  - Real-time systems
KW  - Engines
KW  - Task analysis
KW  - Computer vision
DO  - 10.1109/IROS.2018.8593433
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hand gestures are a natural component of human-human communication. Simple hand gestures are intuitive and can exhibit great lexical variety. It stands to reason that such a user input mechanism can have many benefits, including seamless interaction, intuitive control and robustness to physical constraints and ambient electrical, light and sound interference. However, while semantic and logical information encoded via hand gestures is readily decoded by humans, leveraging this communication channel in human-machine interfaces remains a challenge. Recent data-driven deep learning approaches are promising towards uncovering abstract and complex relationships that manual and direct rule-based classification schemes fail to discover. Such an approach is amenable towards hand gesture recognition, but requires myriad data which can be collected physically via user experiments. This process, however, is onerous and tedious. A streamlined approach with less overhead is sought. To that end, this work presents a novel method of synthetic hand gesture dataset generation that leverages modern gaming engines. Furthermore, preliminary results indicate that the dataset, despite being synthetic and requiring no physical data collection, is both accurate and rich enough to train a real-world hand gesture classifier that operates in real-time.
ER  - 

TY  - CONF
TI  - Interaction System Based on an Avatar Projected on a Pyramidal Display
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3943
EP  - 3948
AU  - D. Loza Matovelle
AU  - S. Marcos
AU  - E. Zalama
AU  - J. Gómez García Bermejo
PY  - 2018
KW  - avatars
KW  - computer animation
KW  - control engineering computing
KW  - emotion recognition
KW  - face recognition
KW  - human computer interaction
KW  - human-robot interaction
KW  - middleware
KW  - mobile robots
KW  - operating systems (computers)
KW  - telerobotics
KW  - pyramidal structure
KW  - expression generator subsystem
KW  - avatar animations
KW  - avatar teleoperation
KW  - emotion displaying ability
KW  - interaction system
KW  - pyramidal display
KW  - social robot behavioral architecture
KW  - back projection subsystem
KW  - three-dimensional avatar
KW  - robotic operating system
KW  - three dimensional virtual head
KW  - 3D avatar
KW  - facial action coding system
KW  - ROS middleware
KW  - user interface
KW  - avatars gestural ability
KW  - Avatars
KW  - Animation
KW  - Robots
KW  - Solid modeling
KW  - Face
KW  - Shape
KW  - Bones
DO  - 10.1109/IROS.2018.8593740
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper an interaction system based on a three dimensional virtual head projected onto a pyramidal display is proposed. The proposed system makes use of a social robot behavioral architecture already developed in our lab, which allows us to interchange developments between our robotic realizations and the 3D avatar. The overall system is divided into two parts: back projection subsystem and expression generator subsystem. The back projection subsystem projects a three-dimensional avatar onto a pyramidal structure in order to achieve a sensation of depth and realism. The expression generator subsystem carries out the avatar animations using shape keys and bones, following the Facial Action Coding System (FACS). The system consists in several nodes that are integrated in ROS middleware (Robotic Operating System), and includes a user interface that makes the avatar teleoperation easier (the package is avaible in github public respository). In order to evaluate the expressiveness of the system, two sets of experiments have been performed: one to analyze the avatar's gestural ability, that is, its capability to perform expressions that can be identified by an observer, and a second experiment to measure the emotion displaying ability in terms of valence and arousal.
ER  - 

TY  - CONF
TI  - Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3949
EP  - 3956
AU  - K. M. Judd
AU  - J. D. Gammell
AU  - P. Newman
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image motion analysis
KW  - image segmentation
KW  - image sensors
KW  - image sequences
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - stereo image processing
KW  - dynamic scene
KW  - multimotion visual odometry pipeline
KW  - MVO
KW  - dynamic objects
KW  - motion capture system
KW  - simultaneous estimation
KW  - third-party motions
KW  - computer vision
KW  - previous work
KW  - moving camera
KW  - largely static environment
KW  - segment
KW  - tracking-by-detection
KW  - motion constraints
KW  - planar motion
KW  - SE motion
KW  - scene flow
KW  - unconstrained motions
KW  - camera motions
KW  - object tracking
KW  - stereo/RGB-D camera
KW  - multimodal visual odometry pipeline
KW  - Cameras
KW  - Motion segmentation
KW  - Tracking
KW  - Dynamics
KW  - Trajectory
KW  - Estimation
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594213
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.
ER  - 

TY  - CONF
TI  - Underwater Surveying via Bearing Only Cooperative Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3957
EP  - 3963
AU  - H. Damron
AU  - A. Q. Li
AU  - I. Rekleitis
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - underwater vehicles
KW  - bearing only cooperative localization
KW  - aerial ground vehicles
KW  - underwater domain
KW  - robotic applications
KW  - cave mapping
KW  - marine archeology surveying
KW  - fresh water
KW  - South Carolina
KW  - visibility conditions
KW  - depth sensors
KW  - magnetic sensors
KW  - inertial sensors
KW  - Florida
KW  - Barbados
KW  - Cameras
KW  - Springs
KW  - Robot kinematics
KW  - Lakes
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593431
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.
ER  - 

TY  - CONF
TI  - Ego-Motion Estimate Corruption Due to Violations of the Range Flow Constraint
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3964
EP  - 3969
AU  - C. D. Monaco
AU  - S. N. Brennan
PY  - 2018
KW  - distance measurement
KW  - image sensors
KW  - image sequences
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - range sensors
KW  - visual odometry techniques
KW  - dense geometry-based visual odometry methods
KW  - range flow constraint equation
KW  - temporal derivatives
KW  - spatial derivatives
KW  - range images
KW  - ego-motion estimation
KW  - range data
KW  - Mathematical model
KW  - Cameras
KW  - Optical imaging
KW  - Visual odometry
KW  - Optical sensors
KW  - Adaptive optics
KW  - Optical variables control
DO  - 10.1109/IROS.2018.8594131
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.
ER  - 

TY  - CONF
TI  - Semi-Supervised SLAM: Leveraging Low-Cost Sensors on Underground Autonomous Vehicles for Position Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3970
EP  - 3977
AU  - A. Jacobson
AU  - F. Zeng
AU  - D. Smith
AU  - N. Boswell
AU  - T. Peynot
AU  - M. Milford
PY  - 2018
KW  - cameras
KW  - learning (artificial intelligence)
KW  - mining
KW  - mining industry
KW  - mobile robots
KW  - object tracking
KW  - robot vision
KW  - SLAM (robots)
KW  - ORB-SLAM2
KW  - ground map locations
KW  - deep learning
KW  - position tracking
KW  - operational underground mining vehicles
KW  - single camera localization
KW  - map creation
KW  - mine environment
KW  - mining companies
KW  - underground environment
KW  - SemiSupervised SLAM
KW  - underground autonomous vehicles
KW  - low-cost sensors
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Measurement
KW  - Grounding
KW  - Visual odometry
KW  - Lighting
DO  - 10.1109/IROS.2018.8593750
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents Semi-Supervised SLAM - a method for developing a map suitable for coarse localization within an underground environment with minimal human intervention, with system characteristics driven by real-world requirements of major mining companies. This work leverages existing information common within a mining environment - namely a surveyed mine map - which is used to sparsely ground map locations within the mine environment, increasing map accuracy and allowing localization within a global frame. Map creation utilizes a low cost camera sensor and minimal user information to produce a map which can be used for single camera localization within a mining environment. We evaluate the localization capabilities of the proposed approach in depth by performing data collection on operational underground mining vehicles within an active underground mine and by simulating occlusions common to the environment such as dust and water. The proposed system is capable of producing maps which have an average localization error 2.5 times smaller than the next best performing method ORB-SLAM2, comparable localization performance to a state-of-the-art deep learning approach (which is not a feasible solution due to both compute and training requirements) and is robust to simulated environmental obscurants.
ER  - 

TY  - CONF
TI  - An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3978
EP  - 3983
AU  - W. Zhao
AU  - M. Kamezaki
AU  - K. Yoshida
AU  - M. Konno
AU  - A. Onuki
AU  - S. Sugano
PY  - 2018
KW  - cooperative communication
KW  - inspection
KW  - mobile robots
KW  - protocols
KW  - automatic tracked robot chain system
KW  - gas pipeline inspection
KW  - wireless relay communication
KW  - wireless signal attenuation
KW  - relay communication node
KW  - wireless application layer communication protocol
KW  - relay transmission efficiency
KW  - RSSI-based coordinated movement
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Pipelines
KW  - Relays
KW  - Wireless communication
KW  - Wireless sensor networks
DO  - 10.1109/IROS.2018.8593550
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.
ER  - 

TY  - CONF
TI  - Multi-Level Bayesian Decision-Making for Safe and Flexible Autonomous Navigation in Highway Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3984
EP  - 3990
AU  - D. Iberraken
AU  - L. Adouane
AU  - D. Denis
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - decision making
KW  - navigation
KW  - probability
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - traffic engineering computing
KW  - TSLDN
KW  - driving situation assessment
KW  - vehicle navigation task
KW  - control architecture
KW  - probabilistic decision-making
KW  - safe navigation
KW  - flexible autonomous navigation
KW  - highway environment
KW  - MCA
KW  - multi-level Bayesian decision-making
KW  - multi-controller architecture
KW  - two-sequential level decision network
KW  - Extended Time-To-Collision metric
KW  - ETTC metric
KW  - Predicted Inter-Distance Profile
KW  - Safety
KW  - Decision making
KW  - Navigation
KW  - Trajectory
KW  - Road transportation
KW  - Uncertainty
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593565
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an overall Multi-Controller Architecture (MCA) for safe and flexible navigation of autonomous navigation, under uncertainties in highway use-cases. In addition to the details given about the main modules (and their interactions) composing the proposed MCA, an important focus of the paper is made on the definition of a robust Two-Sequential Level Decision Network (TSLDN), which uses both: Extended Time-To-Collision (ETTC) metric and a new definition of a specific Predicted Inter-Distance Profile (PIDP, between vehicles during lane changes maneuvers) in order to estimate the maneuvers risks. The TSLDN is utilized for: the driving situation assessment, decision-making and for safety retrospection over the current maneuver risk. It allows us to have the best decision to achieve the vehicle navigation task while maximizing its safety. Several simulation results show the good performance of the overall proposed control architecture, mainly in terms of efficiency to handle probabilistic decision-making even for very risky scenarios.
ER  - 


TY  - CONF
TI  - Estimating Achievable Range of Ground Robots Operating on Single Battery Discharge for Operational Efficacy Amelioration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3991
EP  - 3998
AU  - K. Tiwari
AU  - X. Xiao
AU  - N. Y. Chong
PY  - 2018
KW  - mobile robots
KW  - estimation error
KW  - single battery discharge
KW  - operational efficacy
KW  - mobile robots
KW  - active pursuit
KW  - law enforcement
KW  - plausible traversal velocity
KW  - energy utilization
KW  - consumers
KW  - ancillary robotic functions
KW  - Robot sensing systems
KW  - Batteries
KW  - Mobile robots
KW  - Energy consumption
KW  - Discharges (electric)
DO  - 10.1109/IROS.2018.8593845
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.
ER  - 

TY  - CONF
TI  - Interaction-Aware Probabilistic Behavior Prediction in Urban Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3999
EP  - 4006
AU  - J. Schulz
AU  - C. Hubmann
AU  - J. Löchner
AU  - D. Burschka
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - control engineering computing
KW  - driver information systems
KW  - inference mechanisms
KW  - Markov processes
KW  - mobile robots
KW  - Monte Carlo methods
KW  - probability
KW  - road vehicles
KW  - traffic engineering computing
KW  - combinatorial scene developments
KW  - road layouts
KW  - future scenes
KW  - probabilistic forward simulation
KW  - sequential Monte Carlo inference
KW  - single agents
KW  - context-dependent motion models
KW  - complete scene
KW  - dynamic Bayesian network
KW  - probabilistic prediction framework
KW  - mutual interaction
KW  - traffic rules
KW  - road-geometry
KW  - route intentions
KW  - traffic participants
KW  - urban scenarios
KW  - complex scenarios
KW  - autonomous driving
KW  - urban environments
KW  - interaction-aware probabilistic behavior prediction
KW  - interaction-unaware physics
KW  - real-world scenarios
KW  - Trajectory
KW  - Estimation
KW  - Vehicles
KW  - Probabilistic logic
KW  - Hidden Markov models
KW  - Predictive models
KW  - Bayes methods
DO  - 10.1109/IROS.2018.8594095
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Planning for autonomous driving in complex, urban scenarios requires accurate prediction of the trajectories of surrounding traffic participants. Their future behavior depends on their route intentions, the road-geometry, traffic rules and mutual interaction, resulting in interdependencies between their trajectories. We present a probabilistic prediction framework based on a dynamic Bayesian network, which represents the state of the complete scene including all agents and respects the aforementioned dependencies. We propose Markovian, context-dependent motion models to define the interaction-aware behavior of drivers. At first, the state of the dynamic Bayesian network is estimated over time by tracking the single agents via sequential Monte Carlo inference. Secondly, we perform a probabilistic forward simulation of the network's estimated belief state to generate the different combinatorial scene developments. This provides the corresponding trajectories for the set of possible, future scenes. Our framework can handle various road layouts and number of traffic participants. We evaluate the approach in online simulations and real-world scenarios. It is shown that our interaction-aware prediction outperforms interaction-unaware physics- and map-based approaches.
ER  - 

TY  - CONF
TI  - FEM-Based Deformation Control for Dexterous Manipulation of 3D Soft Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4007
EP  - 4013
AU  - F. Ficuciello
AU  - A. Migliozzi
AU  - E. Coevoet
AU  - A. Petit
AU  - C. Duriez
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - elasticity
KW  - finite element analysis
KW  - force sensors
KW  - mobile robots
KW  - robot vision
KW  - solid modelling
KW  - finite element method
KW  - Lagrange multipliers
KW  - elasticity parameters
KW  - 3D soft objects
KW  - dexterous manipulation
KW  - FEM-based deformation control
KW  - soft cylindrical object
KW  - manipulation task
KW  - underactuated anthropomorphic hand
KW  - force sensor
KW  - contact points
KW  - in-hand manipulation
KW  - anthropomorphic device
KW  - Strain
KW  - Finite element analysis
KW  - Robots
KW  - Deformable models
KW  - Three-dimensional displays
KW  - Biological system modeling
KW  - Estimation
DO  - 10.1109/IROS.2018.8593512
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a method for dexterous manipulation of 3D soft objects for real-time deformation control is presented, relying on Finite Element modelling. The goal is to generate proper forces on the fingertips of an anthropomorphic device during in-hand manipulation to produce desired displacements of selected control points on the object. The desired motions of the fingers are computed in real-time as an inverse solution of a Finite Element Method (FEM), the forces applied by the fingertips at the contact points being modelled by Lagrange multipliers. The elasticity parameters of the model are preliminarly estimated using a vision system and a force sensor. Experimental results are shown with an underactuated anthropomorphic hand that performs a manipulation task on a soft cylindrical object.
ER  - 

TY  - CONF
TI  - An Adaptive Robotic Gripper with L-Shape Fingers for Peg-in-Hole Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4022
EP  - 4028
AU  - K. Nie
AU  - W. Wan
AU  - K. Harada
PY  - 2018
KW  - force sensors
KW  - grippers
KW  - mobile robots
KW  - adaptive robotic gripper
KW  - L-shape finger
KW  - peg-in-hole process
KW  - force sensor
KW  - IREX
KW  - international robotic exhibition 2017
KW  - Grippers
KW  - Task analysis
KW  - Uncertainty
KW  - Manufacturing processes
KW  - Robot sensing systems
KW  - Planning
DO  - 10.1109/IROS.2018.8594370
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper develops an adaptive gripper for peg-in-hole tasks. Conventional grippers require complicated compliant mechanisms or complicated control strategy and force sensing to successfully insert pegs into holes. Different from them, this paper proposes a simple gripper with an L-shape finger as a low-cost peg-in-hole solution. The basic idea is to divide a peg-in-hole process into a preparation phase and an execution phase, and eliminate uncertainty step-by-step by pushing using the L-shape finger in the preparation phase. The robustness of the gripper for peg-in-hole tasks is examined by repeated executions for different pegs in the International Robotic Exhibition 2017 (IREX) in Tokyo. The experimental section presents details of the executions, and qualitatively shows the high performance of the proposed gripper.
ER  - 

TY  - CONF
TI  - Real-Time Grasp Planning for Multi-Fingered Hands by Finger Splitting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4045
EP  - 4052
AU  - Y. Fan
AU  - T. Tang
AU  - H. Lin
AU  - M. Tomizuka
PY  - 2018
KW  - grippers
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - time grasp planning
KW  - multifingered hands
KW  - traditional planning methods
KW  - optimal parallel grasps
KW  - dual-stage iterative optimization
KW  - contact point optimization
KW  - finger splitting
KW  - Optimization
KW  - Planning
KW  - Grippers
KW  - Search problems
KW  - Grasping
KW  - Databases
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594369
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasp planning for multi-fingered hands is computationally expensive due to the joint-contact coupling, surface nonlinearities and high dimensionality, thus is generally not affordable for real-time implementations. Traditional planning methods by optimization, sampling or learning work well in planning for parallel grippers but remain challenging for multi-fingered hands. This paper proposes a strategy called finger splitting, to plan precision grasps for multi-fingered hands starting from optimal parallel grasps. The finger splitting is optimized by a dual-stage iterative optimization including a contact point optimization (CPO) and a palm pose optimization (PPO), to gradually split fingers and adjust both the contact points and the palm pose. The dual-stage optimization is able to consider both the object grasp quality and hand manipulability, address the nonlinearities and coupling, and achieve efficient convergence within one second. Simulation results demonstrate the effectiveness of the proposed approach. The simulation video is available at [1].
ER  - 

TY  - CONF
TI  - Interleaving Hierarchical Task Planning and Motion Constraint Testing for Dual-Arm Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4061
EP  - 4066
AU  - A. Suárez-Hernández
AU  - G. Alenyà
AU  - C. Torras
PY  - 2018
KW  - control engineering computing
KW  - geometry
KW  - inference mechanisms
KW  - manipulators
KW  - path planning
KW  - planning (artificial intelligence)
KW  - dual-arm manipulation
KW  - symbolic planning
KW  - reasoning capabilities
KW  - robotic manipulators
KW  - geometric constraint verification
KW  - Barrett WAM robots
KW  - geometric puzzle
KW  - hierarchical task network planner
KW  - hierarchical task planning
KW  - motion constraint testing
KW  - motion planning
KW  - Task analysis
KW  - Planning
KW  - Uncertainty
KW  - Shape
KW  - Manipulators
KW  - Cameras
DO  - 10.1109/IROS.2018.8593847
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In recent years the topic of combining motion and symbolic planning to perform complex tasks in the field of robotics has received a lot of attention. The underlying idea is to have access at once to the reasoning capabilities of a task planner and to the ability of the motion planner to verify that the plan is feasible from a physical and geometrical point of view. The present work describes a framework to perform manipulation tasks that require the use of two robotic manipulators. To do so we employ a Hierarchical Task Network (HTN) planner interleaved with geometric constraint verification. In this framework we also consider observation actions and handle noisy perceptions from a probabilistic perspective. These ideas are put into practice by means of an experimental set-up in which two Barrett WAM robots have to cooperatively solve a geometric puzzle. Our findings provide further evidence that considering explicitly physical constraints during task planning, rather than deferring their validation to the moment of execution, is advantageous in terms of execution time and breadth of situations that can be handled.
ER  - 

TY  - CONF
TI  - Sequence Pattern Extraction by Segmenting Time Series Data Using GP-HSMM with Hierarchical Dirichlet Process
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4067
EP  - 4074
AU  - M. Nagano
AU  - T. Nakamura
AU  - T. Nagai
AU  - D. Mochihashi
AU  - I. Kobayashi
AU  - M. Kaneko
PY  - 2018
KW  - Bayes methods
KW  - feature extraction
KW  - Gaussian processes
KW  - hidden Markov models
KW  - image motion analysis
KW  - image sampling
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - nonparametric statistics
KW  - time series
KW  - continuous time-series data
KW  - semiMarkov model
KW  - Gaussian processes
KW  - nonparametric models
KW  - unit motion patterns
KW  - complicated continuous motion
KW  - nonparametric Bayesian model
KW  - hierarchical Dirichlet process
KW  - hierarchical Dirichlet processes-Gaussian process
KW  - HDP-GP-HSMM
KW  - motion-capture data
KW  - sequence pattern extraction
KW  - time series data
KW  - continuous information
KW  - unit motions
KW  - unsupervised segmentation
KW  - Hidden Markov models
KW  - Motion segmentation
KW  - Gaussian processes
KW  - Bayes methods
KW  - Data models
KW  - Trajectory
KW  - Kernel
DO  - 10.1109/IROS.2018.8594029
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humans recognize perceived continuous information by dividing it into significant segments such as words and unit motions. We believe that such unsupervised segmentation is also an important ability that robots need to learn topics such as language and motions. Hence, in this paper, we propose a method for dividing continuous time-series data into segments in an unsupervised manner. To this end, we proposed a method based on a hidden semi-Markov model with Gaussian process (GP-HSMM). If Gaussian processes, which are nonparametric models, are used, unit motion patterns can be extracted from complicated continuous motion. However, this approach requires the number of classes of segments in the time-series data in advance. To overcome this problem, in this paper, we extend GP-HSMM to a nonparametric Bayesian model by introducing a hierarchical Dirichlet process (HDP) and propose the hierarchical Dirichlet processes-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). In the nonparametric Bayesian model, an infinite number of classes is assumed and it becomes difficult to estimate the parameters naively. Instead, the parameters of the proposed HDP-GP-HSMM are estimated by applying slice sampling. In the experiments, we use various synthetic and motion-capture data to show that our proposed model can estimate a more correct number of classes and achieve more accurate segmentation than baseline methods.
ER  - 

TY  - CONF
TI  - Persistent Anytime Learning of Objects from Unseen Classes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4075
EP  - 4082
AU  - M. Denninger
AU  - R. Triebel
PY  - 2018
KW  - image classification
KW  - random forests
KW  - random forest classifier
KW  - semantic mapping
KW  - object classification
KW  - standard offline methods
KW  - incremental approach
KW  - robotic applications
KW  - data samples
KW  - Training
KW  - Vegetation
KW  - Robots
KW  - Semantics
KW  - Standards
KW  - Training data
KW  - Uncertainty
KW  - Learning and Adaptive Systems
KW  - Object Detection
KW  - Segmentation and Categorization
KW  - Online Learning
DO  - 10.1109/IROS.2018.8594165
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a fast and very effective method for object classification that is particularly suited for robotic applications such as grasping and semantic mapping. Our approach is based on a Random Forest classifier that can be trained incrementally. This has the major benefit that semantic information from new data samples can be incorporated without retraining the entire model. Even if new samples from a previously unseen class are presented, our method is able to perform efficient updates and learn a sustainable representation for this new class. Further features of our method include a very fast and memory-efficient implementation, as well as the ability to interrupt the learning process at any time without a significant performance degradation. Experiments on benchmark data for robotic applications show the clear benefits of our incremental approach and its competitiveness with standard offline methods in terms of classification accuracy.
ER  - 

TY  - CONF
TI  - Adaptive Robot Body Learning and Estimation Through Predictive Coding
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4083
EP  - 4090
AU  - P. Lanillos
AU  - G. Cheng
PY  - 2018
KW  - actuators
KW  - adaptive control
KW  - Bayes methods
KW  - Gaussian processes
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - mobile robots
KW  - regression analysis
KW  - sensor fusion
KW  - nonlinear actuators
KW  - noisy sensory information
KW  - computational perceptual model
KW  - predictive processing
KW  - arbitrary sensors
KW  - Gaussian additive noise
KW  - Gaussian process regression
KW  - robot body configuration belief
KW  - sensory prediction errors
KW  - multisensory robotic arm
KW  - additive errors
KW  - adaptive robot body learning
KW  - predictive coding
KW  - predictive functions
KW  - sensorimotor integration
KW  - human-robot interaction
KW  - sensor modalities contributions
KW  - sensory visuo-tactile perturbations
KW  - Robot sensing systems
KW  - Visualization
KW  - Estimation
KW  - Computational modeling
KW  - Adaptation models
KW  - Bio-inspired perception
KW  - body-schema
KW  - predictive processing
KW  - embodied artificial intelligence
KW  - learning and adaptive systems
KW  - humanoid robotics
DO  - 10.1109/IROS.2018.8593684
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.
ER  - 

TY  - CONF
TI  - Online Learning of Body Orientation Control on a Humanoid Robot Using Finite Element Goal Babbling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4091
EP  - 4098
AU  - P. Loviken
AU  - N. Hemion
AU  - A. Laflaquière
AU  - M. Spranger
AU  - A. Cangelosi
PY  - 2018
KW  - control engineering computing
KW  - finite element analysis
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - position control
KW  - robust control
KW  - finite element goal babbling
KW  - utility function maximization
KW  - Nao humanoid robot
KW  - robust control
KW  - online learning method
KW  - FEGB
KW  - body orientation control
KW  - time 20.0 min to 30.0 min
KW  - Task analysis
KW  - Aerospace electronics
KW  - Finite element analysis
KW  - Space exploration
KW  - Humanoid robots
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593762
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - How can high dimensional robots learn general sets of skills from experience in the real world? Many previous approaches focus on maximizing a single utility function and require large datasets of experience to do this, something that is not possible to collect outside of simulation as every data point is expensive both in time and in a potential wear down of the robot. This paper addresses this question using a newly developed framework called Finite Element Goal Babbling (FEGB). FEGB is an online learning method that aims at providing general control over some measurable feature, in contrast to optimizing it to some given utility function. It generalizes standard goal babbling by breaking down the full learning problem into local sub-problems, and combining it with a planner that learns how to navigate between these subproblems. We test FEGB using a real humanoid robot Nao, and find that it could quickly learn to robustly control its body orientation. After only 20-30 minutes of training, the robot could freely move into any body orientation between lying on either side and on its back. Rapid learning of body orientation control in high dimensional real robots is largely an unexplored field of robotics, and although many challenges remain, FEGB shows a feasible approach to the problem.
ER  - 

TY  - CONF
TI  - Cost Adaptation for Robust Decentralized Swarm Behaviour
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4099
EP  - 4106
AU  - P. Henderson
AU  - M. Vertescher
AU  - D. Meger
AU  - M. Coates
PY  - 2018
KW  - computer games
KW  - control engineering computing
KW  - decentralised control
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - robot dynamics
KW  - cost adaptation
KW  - decentralized receding horizon control
KW  - multiagent settings
KW  - meta-learning process
KW  - mesh-networked swarm agents
KW  - adaptation mechanism
KW  - safer task completion
KW  - Unity3D game engine
KW  - D-RHC
KW  - robust decentralized swarm behaviour
KW  - Task analysis
KW  - Delays
KW  - Decision making
KW  - Cost function
KW  - Mesh networks
KW  - Control systems
DO  - 10.1109/IROS.2018.8594283
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multiagent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process - cost adaptation - which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.
ER  - 

TY  - CONF
TI  - Active Model Learning and Diverse Action Sampling for Task and Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4107
EP  - 4114
AU  - Z. Wang
AU  - C. R. Garrett
AU  - L. P. Kaelbling
AU  - T. Lozano-Pérez
PY  - 2018
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - complex domains
KW  - flexible generative planning
KW  - state-of-the-art methods
KW  - active learning
KW  - Gaussian process methods
KW  - operator effectiveness
KW  - adaptive sampling methods
KW  - diverse elements
KW  - robot configurations
KW  - object poses
KW  - newly learned models
KW  - long horizon problems
KW  - active model learning
KW  - action sampling
KW  - motion planning
KW  - sensorimotor primitives
KW  - complex long-horizon problems
KW  - continuous-space robot task
KW  - Planning
KW  - Task analysis
KW  - Level set
KW  - Robot sensing systems
KW  - Gaussian processes
KW  - Training
DO  - 10.1109/IROS.2018.8594027
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world. In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world? We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.
ER  - 

TY  - CONF
TI  - Improving Reinforcement Learning Pre-Training with Variational Dropout
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4115
EP  - 4122
AU  - T. Blau
AU  - L. Ott
AU  - F. Ramos
PY  - 2018
KW  - control engineering computing
KW  - Gaussian processes
KW  - legged locomotion
KW  - supervised learning
KW  - reinforcement learning pre-training
KW  - control policies
KW  - robotic agents
KW  - bipedal locomotion
KW  - data points
KW  - Gaussian dropout networks
KW  - variational inference
KW  - policy parameters
KW  - standard supervised learning
KW  - optimal policies
KW  - variational dropout
KW  - regularization term
KW  - RL algorithm
KW  - high-dimensional continuous control problems
KW  - Task analysis
KW  - Training
KW  - Reinforcement learning
KW  - Training data
KW  - Cloning
KW  - Supervised learning
KW  - Robots
DO  - 10.1109/IROS.2018.8594341
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning has been very successful at learning control policies for robotic agents in order to perform various tasks, such as driving around a track, navigating a maze, and bipedal locomotion. One significant drawback of reinforcement learning methods is that they require a large number of data points in order to learn good policies, a trait known as poor data efficiency or poor sample efficiency. One approach for improving sample efficiency is supervised pre-training of policies to directly clone the behavior of an expert, but this suffers from poor generalization far from the training data. We propose to improve this by using Gaussian dropout networks with a regularization term based on variational inference in the pre-training step. We show that this initializes policy parameters to significantly better values than standard supervised learning or random initialization, thus greatly reducing sample complexity compared with state-of-the-art methods, and enabling an RL algorithm to learn optimal policies for high-dimensional continuous control problems in a practical time frame.
ER  - 

TY  - CONF
TI  - A Framework for Dexterous Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4131
EP  - 4138
AU  - L. Y. Ku
AU  - J. Rogers
AU  - P. Strawser
AU  - J. Badger
AU  - E. Learned-Mille
AU  - R. Grupen
PY  - 2018
KW  - dexterous manipulators
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - dexterous manipulation
KW  - humanoid robot Robonaut-2
KW  - anthropomorphic Robonaut-2 hand
KW  - manipulation tasks
KW  - hand fan
KW  - IROS2018 fan robotic challenge
KW  - phase I modality A competition
KW  - Robots
KW  - Task analysis
KW  - Neurons
KW  - Brain modeling
KW  - Fans
KW  - Computational modeling
KW  - Grasping
DO  - 10.1109/IROS.2018.8594497
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we introduce a framework for performing dexterous manipulations on the humanoid robot Robonaut-2. This framework memorizes how actions change perceptions and can learn a sequence of actions based on demonstrations. With the anthropomorphic Robonaut-2 hand and arm, a variety of manipulation tasks such as grasping novel objects, rotating a drill for grasping, and tightening a bolt with a ratchet can be accomplished. This framework was also used to compete in the IROS2018 Fan Robotic Challenge that requires manipulating a hand fan and was a winner of the phase I modality A competition.
ER  - 

TY  - CONF
TI  - An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4139
EP  - 4144
AU  - J. Kwiatkowski
AU  - J. Roberge
AU  - N. A. Nadeau
AU  - L. L'Écuyer-Lapierre
AU  - V. Duchaine
PY  - 2018
KW  - dexterous manipulators
KW  - grippers
KW  - motion control
KW  - tactile sensors
KW  - vibrations
KW  - extrinsic dexterity approach
KW  - IROS 2018 fan robotic challenge
KW  - Spanish folding fan
KW  - dexterous manipulation
KW  - robotic systems
KW  - external dexterity
KW  - high DoF grippers
KW  - 3D-printed adaptation
KW  - multimodal tactile sensor
KW  - Fans
KW  - Grippers
KW  - Robot kinematics
KW  - Service robots
KW  - Task analysis
KW  - End effectors
DO  - 10.1109/IROS.2018.8594224
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.
ER  - 

TY  - CONF
TI  - Development of Low-Inertia High-Stiffness Manipulator LIMS2 for High-Speed Manipulation of Foldable Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4145
EP  - 4151
AU  - H. Song
AU  - Y. Kim
AU  - J. Yoon
AU  - S. Yun
AU  - J. Seo
AU  - Y. Kim
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - dexterous manipulators
KW  - elastic constants
KW  - fans
KW  - grippers
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - operating systems (computers)
KW  - protocols
KW  - low-inertia high-stiffness manipulator
KW  - high-speed manipulation
KW  - foldable objects
KW  - dual-arm robot system
KW  - LIMS2-AMBIDEX
KW  - IROS2018 Robotic Challenge
KW  - seven-degrees-of-freedom
KW  - foldable fan
KW  - Fan Robotic Challenge Phase
KW  - high-speed communication protocol
KW  - tension-amplification mechanisms
KW  - gripper
KW  - robot operating system
KW  - Xenomai
KW  - real-time development framework
KW  - EtherCAT
KW  - software framework
KW  - mass 2.63 kg
KW  - Wrist
KW  - Fans
KW  - Robots
KW  - Elbow
KW  - Shoulder
KW  - Grippers
KW  - Actuators
DO  - 10.1109/IROS.2018.8594005
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a dual-arm robot system for high-speed manipulations, which is named LIMS2-AMBIDEX and is developed to compete in the IROS2018 Robotic Challenge, is presented. It has two seven-degrees-of-freedom (DO F) lightweight arms, a three-DOF head, and a one-DOF gripper to manipulate foldable objects. Because all the heavy actuators are placed at the shoulder, it has remarkably low mass beyond the shoulder (2.63 kg), which guarantees an inherent safety at high speeds. Utilizing tension-amplification mechanisms, the high stiffness and strength are achieved, and thus it has the control performance comparable to conventional industrial manipulators. A unique three-DOF wrist mechanism, whose motions directly represent the quaternion values of the joint orientation, can manipulate objects without singular points in the entire range of motion. In order to utilize the object's inertia during rapid manipulation, the gripper was specially designed: it has a one-DOF finger to grasp the upper rib of the foldable fan and two supporting forks to grasp the bottom rib stably. For real-time performance and increased scalability, a software framework was developed based on Robot Operating System (ROS). The real-time capability is achieved by using the real-time development framework Xenomai and the high-speed communication protocol EtherCAT. As most of the algorithms are implemented in the distributed nodes using ROS, it is convenient to expand, improve, and replace the algorithms. Consequentially, the entire motion of the Fan Robotic Challenge Phase I Modality B required 1.05 s, which is substantially faster than a similar manipulation by most humans.
ER  - 

TY  - CONF
TI  - Flamen − 7 DOF Robotic Arm to Manipulate a Spanish Fan
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4152
EP  - 4157
AU  - M. Harikrishnan Nair
AU  - T. Ghanshsyam Singh
AU  - G. Chourasia
AU  - A. Das
AU  - A. Shrivastava
AU  - Z. S. Bhatt
PY  - 2018
KW  - control engineering computing
KW  - fans
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - 7-DOF robotic arm
KW  - Flamen
KW  - Flamenco dancers
KW  - manipulation
KW  - traditional fan
KW  - Spanish fan
KW  - Fans
KW  - Manipulators
KW  - Robot kinematics
KW  - Actuators
KW  - Grasping
KW  - Cameras
KW  - Actuation
KW  - Automation
KW  - Background subtraction
KW  - Contour Detection
KW  - Coordinate extraction
KW  - Filtering
KW  - Mapping
KW  - Masking
KW  - Robotic Arm
KW  - Spanish Fan
DO  - 10.1109/IROS.2018.8594129
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A Spanish fan is a hand held traditional fan which is used as an accessory and also by Flamenco dancers. The manipulation of the fan is quite difficult as it involves dynamic motion which includes opening, flapping and closing the fan along a pivotal point. The key points include the motion to be quick and the fan to be opened to the maximum degree possible without human intervention. A robotic arm with 7 Degrees of Freedom (DOF) is used to manipulate the autonomous motion. The fan placed on the table is localized and detected using a camera by background subtraction, masking and filtering; post which the contour of the fan is detected. The pixels obtained is then transformed into real life coordinates. The Dynamixel motors then traverses to the coordinates of the fan's position to grasp, open, flap, close and put the fan down.
ER  - 

TY  - CONF
TI  - IROS 2018 Fan Challenge - Team DLR Augsburg
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4158
EP  - 4163
AU  - M. Schönheits
AU  - A. Schuster
AU  - P. Gänswürger
AU  - L. Larsen
PY  - 2018
KW  - human-robot interaction
KW  - service robots
KW  - hot summer
KW  - blistering sun
KW  - Madrid
KW  - scorching heat
KW  - simple gesture
KW  - robotic assistant
KW  - relaxing shade
KW  - team DLR Augsburg
KW  - IROS 2018 fan challenge
KW  - tinto de verano
KW  - Fans
KW  - Grippers
KW  - Robot kinematics
KW  - End effectors
KW  - Cameras
KW  - Servomotors
DO  - 10.1109/IROS.2018.8593792
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - It's a hot summer in 2021 and the blistering sun is shining upon Madrid. You are enjoying some tinto de verano on your terraza. Sizzling in the scorching heat, you are trying to relax. With a simple gesture you call your robotic assistant to help you cool down a little bit. Without further ado, your robot provides some relaxing shade holding a parasol for you, picks up a fan autonomously and starts waving it and the gentle breeze brings you some light relief.
ER  - 

TY  - CONF
TI  - Improved Quadcopter Disturbance Rejection Using Added Angular Momentum
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4164
EP  - 4170
AU  - N. Bucki
AU  - M. W. Mueller
PY  - 2018
KW  - attitude control
KW  - control system synthesis
KW  - helicopters
KW  - position control
KW  - stability
KW  - torque control
KW  - vehicle dynamics
KW  - wheels
KW  - quadcopter disturbance rejection
KW  - added angular momentum
KW  - novel quadcopter design
KW  - added momentum wheel
KW  - enhanced stability
KW  - torque disturbance rejection capabilities
KW  - standard quadcopter
KW  - vehicle dynamics
KW  - torque disturbances
KW  - torque impulses
KW  - Wheels
KW  - Vehicle dynamics
KW  - Propellers
KW  - Torque
KW  - Attitude control
KW  - Angular velocity
KW  - State feedback
DO  - 10.1109/IROS.2018.8594109
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel quadcopter design with an added momentum wheel for enhanced stability. The novel vehicle has improved torque disturbance rejection capabilities compared to a standard quadcopter. An analysis of the vehicle dynamics shows that the effect of torque disturbances decreases monotonically with increasing angular momentum of the momentum wheel. A framework for choosing the mass moment of inertia and speed of the momentum wheel is given based on an upper bound on the allowable energy stored in the wheel. Theoretical results are experimentally validated by comparing responses to torque impulses applied to the vehicle with and without the momentum wheel spinning.
ER  - 

TY  - CONF
TI  - A Universal Controller for Unmanned Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4171
EP  - 4176
AU  - E. Bulka
AU  - M. Nahon
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - UAVs
KW  - agile fixed-wing aircraft
KW  - control logic
KW  - unmanned aerial vehicles
KW  - tilt-rotor
KW  - vehicle flight envelope
KW  - single physics-based controller
KW  - multicopters
KW  - autonomous flight
KW  - quadrotor
KW  - Force
KW  - Aircraft
KW  - Quaternions
KW  - Attitude control
KW  - Actuators
DO  - 10.1109/IROS.2018.8593878
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.
ER  - 

TY  - CONF
TI  - Passive Compliance Control of Aerial Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4177
EP  - 4184
AU  - M. J. Kim
AU  - R. Balachandran
AU  - M. De Stefano
AU  - K. Kondak
AU  - C. Ott
PY  - 2018
KW  - aerospace components
KW  - compliance control
KW  - end effectors
KW  - force control
KW  - manipulators
KW  - position control
KW  - time domain passivity technique
KW  - passive compliance control
KW  - aerial manipulators
KW  - stable environmental interactions
KW  - body-planar directions
KW  - aerial vehicle
KW  - manipulator
KW  - Manipulator dynamics
KW  - End effectors
KW  - Dynamics
KW  - Unmanned aerial vehicles
KW  - Mathematical model
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593718
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a passive compliance control for aerial manipulators to achieve stable environmental interactions. The main challenge is the absence of actuation along body-planar directions of the aerial vehicle which might be required during the interaction to preserve passivity. The controller proposed in this paper guarantees passivity of the manipulator through a proper choice of end-effector coordinates, and that of vehicle fuselage is guaranteed by exploiting time domain passivity technique. Simulation studies validate the proposed approach.
ER  - 

TY  - CONF
TI  - Guidance Laws for Partially-Observable Interception Based on Linear Covariance Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4185
EP  - 4191
AU  - J. Arneberg
AU  - E. Tal
AU  - S. Karaman
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - covariance analysis
KW  - differential games
KW  - optimal control
KW  - differential game
KW  - linear covariance analysis
KW  - maneuvers
KW  - resulting guidance law
KW  - guidance laws
KW  - pursuit-evasion games
KW  - partial measurements
KW  - visual sensing
KW  - bearing measurements
KW  - partially-observable interception problem
KW  - observability
KW  - Observability
KW  - Games
KW  - Uncertainty
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Extraterrestrial measurements
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593929
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider pursuit-evasion games in which the pursuer is tasked with intercepting the evader using only partial measurements. Motivated by the utilization of visual sensing on board the pursuer, we focus on the case when only bearing measurements are available to the pursuer. The resulting partially-observable interception problem is computationally challenging, and the separation principle does not hold in general. In this paper, we identify a set of maneuvers that improve observability, and we propose an algorithm that utilizes these maneuvers to move the pursuer so that the expected payoff of the differential game is maximized. The algorithm uses in-the-loop uncertainty propagation based on linear covariance analysis to assess the effect of the maneuvers. We evaluate the resulting guidance law in experiments involving a quadcopter in flight representing the pursuer, and a simulated evader.
ER  - 

TY  - CONF
TI  - MMAC Height Control System of a Quadrotor for Constant Unknown Load Transportation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4192
EP  - 4197
AU  - P. Outeiro
AU  - C. Cardeira
AU  - P. Oliveira
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - helicopters
KW  - Kalman filters
KW  - linear quadratic control
KW  - motion sensors
KW  - quadrotor
KW  - multimodel adaptive controller
KW  - LQR
KW  - IMU
KW  - motion sensors
KW  - state variables
KW  - constant unknown load transportation
KW  - MMAC height control system
KW  - ultrasound height sensor
KW  - Kalman filter
KW  - Gravity
KW  - Estimation
KW  - Sensors
KW  - Kalman filters
KW  - Computational modeling
KW  - Control systems
KW  - Transportation
DO  - 10.1109/IROS.2018.8594215
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a methodology for height control of a quadrotor that transports a constant unknown load, given the estimates on both weight and state variables, based on measurements from motion sensors installed on-board. The proposed control and estimation framework is a Multi-Model Adaptive Controller using LQR with integrative action and Kalman filter with integrative component. The control system obtained is validated both in simulation and experimentally, resorting to an off-the-shelf commercially available quadrotor equipped with an IMU, an ultrasound height sensor, and a barometer, among other sensors.
ER  - 

TY  - CONF
TI  - Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4198
EP  - 4203
AU  - K. Mohammadi
AU  - M. Jafarinasab
AU  - S. Sirouspour
AU  - E. Dyer
PY  - 2018
KW  - aerospace robotics
KW  - decentralised control
KW  - helicopters
KW  - Lyapunov methods
KW  - materials handling
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - optical tracking
KW  - stability
KW  - energetic passivity property
KW  - drone on-board IMUs
KW  - Lyapunov analysis
KW  - optical tracking systems
KW  - three-drone payload transport system
KW  - motion stability
KW  - cable-suspended payload
KW  - multiple conventional quadcopters
KW  - cabled-based multidrone load transport system
KW  - decentralized motion control
KW  - Payloads
KW  - Drones
KW  - Force
KW  - Stability analysis
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593952
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A provably stable decentralized control scheme is proposed to allow multiple conventional quadcopters carry a cable-suspended payload. The method exploits a fundamental energetic passivity property of the combined drones, cables, and payload system to stably move the payload from its origin to destination. This is achieved without making any assumption about the status of the cables tension during the flight, and any measurement from the payload. The controller is decentralized in the sense that inter-drone communication of feedback measurements is not required. Motion stability is demonstrated via a Lyapunov analysis. The proposed controller is successfully implemented on a three-drone payload transport system in an indoor environment, using measurement from an optical tracking systems and the drones on-board IMUs.
ER  - 

TY  - CONF
TI  - SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4204
EP  - 4209
AU  - E. Tsykunov
AU  - L. Labazanova
AU  - A. Tleugazy
AU  - D. Tsetserukou
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - human-robot interaction
KW  - microrobots
KW  - multi-robot systems
KW  - path planning
KW  - tactile sensors
KW  - trajectory control
KW  - impedance controlled swarm
KW  - nanoquadrotors
KW  - novel interaction strategy
KW  - human-swarm communication
KW  - human operator guides
KW  - quadrotors
KW  - impedance control
KW  - human hand velocity
KW  - formation shape
KW  - Crazyflie 2.0 quadrotor platform
KW  - control algorithm
KW  - tactile patterns
KW  - controllability
KW  - complex life-like formation
KW  - tactile sensation
KW  - drone formation
KW  - human-swarm interaction
KW  - swarm navigation
KW  - Impedance
KW  - Drones
KW  - Robots
KW  - Mathematical model
KW  - Shape
KW  - Force
KW  - Safety
DO  - 10.1109/IROS.2018.8594424
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Novel Aerial Manipulator with Tandem Ducted Fans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4210
EP  - 4217
AU  - Y. Zhang
AU  - C. Xiang
AU  - B. Xu
AU  - Y. Wang
AU  - X. Wang
PY  - 2018
KW  - aerospace testing
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control system synthesis
KW  - fans
KW  - feedforward
KW  - helicopters
KW  - manipulator dynamics
KW  - stability
KW  - vehicle dynamics
KW  - aerial vehicle dynamics
KW  - manipulator dynamics
KW  - tandem ducted fans
KW  - trafficability
KW  - comprehensive integrated dynamic model
KW  - aerial manipulator
KW  - loading
KW  - multirotor
KW  - multilayer composite controller
KW  - feedforward compensation
KW  - flight tests
KW  - Manipulator dynamics
KW  - Fans
KW  - Payloads
KW  - Helicopters
KW  - Ducts
DO  - 10.1109/IROS.2018.8593868
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a novel aerial manipulator with tandem ducted fans, which takes both trafficability and effective loading into account. The aerial manipulator is particularly suitable for grasping in complex and narrow environment, in which traditional multi-rotor and helicopter would be inaccessible. The comprehensive integrated dynamic model is established by taking the aerial vehicle dynamics and manipulator dynamics as a whole. On this basis, a multilayer composite controller with feedforward compensation is designed, considering the mutual reactive influence between the aerial vehicle and the manipulator to improve the stability of the system under the motion of the manipulator. The simulation and actual flight tests verify the effectiveness of the design and show good stability and tracking performance of the system.
ER  - 

TY  - CONF
TI  - Real-Time Light Field Processing for Autonomous Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4218
EP  - 4225
AU  - A. Bajpayee
AU  - A. H. Techet
AU  - H. Singh
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image sensors
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - telerobotics
KW  - autonomous robotics systems
KW  - LIDAR sensors
KW  - time light field processing
KW  - simple linear arrays
KW  - high frequency vibrations
KW  - light fields
KW  - autonomous cars
KW  - light field imaging system
KW  - field-of-view
KW  - software framework
KW  - Cameras
KW  - Robot vision systems
KW  - Vibrations
KW  - Calibration
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594477
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.
ER  - 

TY  - CONF
TI  - Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4226
EP  - 4231
AU  - T. Ohashi
AU  - Y. Ikegami
AU  - K. Yamamoto
AU  - W. Takano
AU  - Y. Nakamura
PY  - 2018
KW  - cameras
KW  - image filtering
KW  - image motion analysis
KW  - image reconstruction
KW  - image sequences
KW  - spatiotemporal phenomena
KW  - video signal processing
KW  - video motion capture
KW  - part confidence maps
KW  - inverted motions
KW  - two-time inverse kinematics computations
KW  - human skeleton
KW  - human motion analysis
KW  - human motion data
KW  - spatiotemporal filter
KW  - camera image
KW  - human skeletal model
KW  - spatiotemporal filtering
KW  - multicamera images
KW  - Phase change materials
KW  - Three-dimensional displays
KW  - Cameras
KW  - Computational modeling
KW  - Optical imaging
KW  - Adaptive optics
KW  - Spatiotemporal phenomena
DO  - 10.1109/IROS.2018.8593867
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper discusses video motion capture, namely, 3D reconstruction of human motion from multi-camera images. After the Part Confidence Maps are computed from each camera image, the proposed spatiotemporal filter is applied to deliver the human motion data with accuracy and smoothness for human motion analysis. The spatiotemporal filter uses the human skeleton and mixes temporal smoothing in two-time inverse kinematics computations. The experimental results show that the mean per joint position error was 26.1mm for regular motions and 38.8mm for inverted motions.
ER  - 

TY  - CONF
TI  - Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4232
EP  - 4237
AU  - S. Shimizu
AU  - R. Murakami
AU  - M. Tominaga
AU  - Y. Akamine
AU  - N. Kawasaki
AU  - O. Shimomura
AU  - K. Ishimaru
AU  - S. Mita
PY  - 2018
KW  - image sensors
KW  - lenses
KW  - photodetectors
KW  - robot vision
KW  - stereo image processing
KW  - visual perception
KW  - WAF lens
KW  - wide angle fovea lens
KW  - high-definition imager
KW  - autonomous robot
KW  - vehicle supersensing vision system
KW  - robotic vision
KW  - field of view
KW  - FOV
KW  - high-resolution photosensitive imaging chip
KW  - stereo vision system
KW  - optical performance
KW  - aspherical surface
KW  - projection testing
KW  - Lenses
KW  - Prototypes
KW  - Spatial resolution
KW  - Cameras
KW  - Robots
KW  - Optical imaging
DO  - 10.1109/IROS.2018.8594194
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.
ER  - 

TY  - CONF
TI  - Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4238
EP  - 4245
AU  - A. Zeng
AU  - S. Song
AU  - S. Welker
AU  - J. Lee
AU  - A. Rodriguez
AU  - T. Funkhouser
PY  - 2018
KW  - convolutional neural nets
KW  - end effectors
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neurocontrollers
KW  - learning synergies
KW  - self-supervised deep reinforcement learning
KW  - cluttered objects
KW  - pushing movements
KW  - model-free deep reinforcement learning
KW  - fully convolutional networks
KW  - end-effector orientations
KW  - Q-learning framework
KW  - pushing motions
KW  - grasping success rates
KW  - picking efficiencies
KW  - skilled robotic manipulation
KW  - grasping
KW  - prehensile action
KW  - pixel-wise sampling
KW  - Grasping
KW  - Training
KW  - Three-dimensional displays
KW  - Reinforcement learning
KW  - Planning
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593986
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/
ER  - 

TY  - CONF
TI  - Towards Material Classification of Scenes Using Active Thermography
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4262
EP  - 4269
AU  - H. Bai
AU  - T. Bhattacharjee
AU  - H. Chen
AU  - A. Kapusta
AU  - C. C. Kemp
PY  - 2018
KW  - image classification
KW  - infrared imaging
KW  - learning (artificial intelligence)
KW  - temperature measurement
KW  - multimaterial scene
KW  - varying distances
KW  - multiclass classification
KW  - heating intensity
KW  - material classification
KW  - variable distances
KW  - relatively large surface areas
KW  - modern machine learning methods
KW  - data-driven approach
KW  - signal variations
KW  - thermal camera
KW  - heat lamp
KW  - size 20.0 cm
KW  - size 40.0 cm
KW  - size 30.0 cm
KW  - time 4.0 s
KW  - time 5.0 s
KW  - time 1.0 s
KW  - Heating systems
KW  - Cameras
KW  - Heat transfer
KW  - Robot sensing systems
KW  - Surface treatment
DO  - 10.1109/IROS.2018.8594469
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.
ER  - 

TY  - CONF
TI  - Vision-Based State Estimation and Trajectory Tracking Control of Car-Like Mobile Robots with Wheel Skidding and Slipping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4270
EP  - 4275
AU  - S. Zhou
AU  - Z. Miao
AU  - Z. Liu
AU  - H. Zhao
AU  - H. Wang
AU  - H. Chen
AU  - Y. Liu
PY  - 2018
KW  - automobiles
KW  - control system synthesis
KW  - estimation theory
KW  - Lyapunov methods
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - stability
KW  - state estimation
KW  - trajectory control
KW  - wheels
KW  - car-like mobile robots
KW  - wheel slipping
KW  - Lyapunov method
KW  - system stability
KW  - visual estimation algorithm
KW  - vision-based approach
KW  - wheel skidding
KW  - trajectory tracking control
KW  - vision-based state estimation
KW  - Mobile robots
KW  - Wheels
KW  - Perturbation methods
KW  - Visualization
KW  - Estimation
KW  - Trajectory tracking
DO  - 10.1109/IROS.2018.8593982
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most existing trajectory tracking controllers are based on non-skidding and non-slipping assumptions, also assume that full states are accessible, which is unrealistic for real-world applications due to tire-road interaction. This paper presents a novel vision-based approach to achieve high performance tracking control of a Car-Like Mobile Robot (CLMR) with wheel skidding and slippage. A visual estimation algorithm is proposed to provide reliable position, velocity, skidding and slipping information to close the control loop. The stability of the proposed system can be guaranteed by Lyapunov method since the position tracking error and the estimation error converge to zero simultaneously. Simulation is made to validate the effectiveness of the developed controller in the presence of skidding and slipping with online visual estimator.
ER  - 

TY  - CONF
TI  - Recruitment Near Worksites Facilitates Robustness of Foraging E-Puck Swarms to Global Positioning Noise
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4276
EP  - 4281
AU  - L. Pitonakova
AU  - A. Winfield
AU  - R. Crowder
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - position control
KW  - worksites facilitates robustness
KW  - foraging e-puck swarms
KW  - global positioning noise
KW  - collective foraging
KW  - robot global positioning data
KW  - broadcast messages
KW  - e-puck robots
KW  - semivirtual environment
KW  - VICON positioning system
KW  - robot positioning data
KW  - pseudorandom environments
KW  - important physical aspects
KW  - inherent noise
KW  - robot infra-red sensors
KW  - robot controllers
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Servers
KW  - Task analysis
KW  - Recruitment
DO  - 10.1109/IROS.2018.8593788
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We compare the ability of two different robot controllers for collective foraging to cope with noise in robot global positioning data and show how recruitment, in the form of broadcast messages near worksites, can make swarms more robust. Swarms of five e-puck robots are used in a semi-virtual environment, facilitated by the VICON positioning system. This setup allows us to control the amount of noise in the robot positioning data and to generate pseudo-random environments, while retaining important physical aspects of the experiment. The effect of inherent noise in the robot infra-red sensors, used for obstacle avoidance, is noted and the importance of modelling such noise in agent-based simulations is highlighted.
ER  - 

TY  - CONF
TI  - Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4282
EP  - 4287
AU  - M. Divband Soorati
AU  - J. Ghofrani
AU  - P. Zahadat
AU  - H. Hamann
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - self-adjusting systems
KW  - self-assembly
KW  - trees (mathematics)
KW  - complex patterns
KW  - programmable systems
KW  - similar complexity
KW  - role model
KW  - natural plants
KW  - environmental conditions
KW  - dynamic environments
KW  - patterned formation
KW  - vascular tissue
KW  - aggregated robots
KW  - dynamic environment
KW  - robot swarm experiments
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Self-assembly
KW  - Shape
KW  - Resource management
DO  - 10.1109/IROS.2018.8594093
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.
ER  - 

TY  - CONF
TI  - $\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4288
EP  - 4294
AU  - F. Arvin
AU  - A. E. Turgut
AU  - T. Krajník
AU  - S. Rahimi
AU  - İ. E. Okay
AU  - S. Yue
AU  - S. Watson
AU  - B. Lennox
PY  - 2018
KW  - aggregation
KW  - fuzzy control
KW  - fuzzy set theory
KW  - image colour analysis
KW  - mobile robots
KW  - multi-robot systems
KW  - pheromone diffusion
KW  - BEECLUST algorithm
KW  - pheromone-based communication
KW  - pheromone-based aggregation method
KW  - ΦClust
KW  - artificial pheromone
KW  - BEECLUST method
KW  - pheromone evaporation
KW  - robotic swarms
KW  - Robot sensing systems
KW  - Biological system modeling
KW  - Aggregates
KW  - Swarm robotics
KW  - Temperature sensors
KW  - Swarm Robotics
KW  - Aggregation
KW  - Pheromone
KW  - Bio-inspired
DO  - 10.1109/IROS.2018.8593961
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.
ER  - 

TY  - CONF
TI  - Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4295
EP  - 4302
AU  - N. Majcherczyk
AU  - A. Jayabalan
AU  - G. Beltrame
AU  - C. Pinciroli
PY  - 2018
KW  - collision avoidance
KW  - decentralised control
KW  - mobile robots
KW  - multi-robot systems
KW  - robots
KW  - trees (mathematics)
KW  - physics-based simulations
KW  - logical tree
KW  - robot network
KW  - spatially distributed targets
KW  - robot swarm
KW  - large-scale robot
KW  - decentralized connectivity-preserving deployment
KW  - real-robot experiments
KW  - tree root
KW  - connectivity constraints
KW  - physical network
KW  - logical tree topology
KW  - Robot kinematics
KW  - Topology
KW  - Heuristic algorithms
KW  - Network topology
KW  - Switches
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594422
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.
ER  - 

TY  - CONF
TI  - A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4303
EP  - 4308
AU  - R. F. Carpio
AU  - L. Di Giulio
AU  - E. Garone
AU  - G. Ulivi
AU  - A. Gasparri
PY  - 2018
KW  - collision avoidance
KW  - logistics
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - control scheme
KW  - collaborative transportation
KW  - bar-like shaped loads
KW  - robot-teams
KW  - collaborative object transportation task
KW  - precision farming setting
KW  - distributed swarm aggregation algorithm
KW  - bar shaped multiagent systems
KW  - state space
KW  - aggregate state
KW  - collision avoidance
KW  - angular consensus
KW  - segment-to-segment distance definition
KW  - control law
KW  - autonomous tractors
KW  - Bars
KW  - Multi-agent systems
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Aggregates
KW  - Load modeling
DO  - 10.1109/IROS.2018.8594236
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.
ER  - 

TY  - CONF
TI  - Resilient Active Information Gathering with Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4309
EP  - 4316
AU  - B. Schlotfeldt
AU  - V. Tzoumas
AU  - D. Thakur
AU  - G. J. Pappas
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - information acquisition tasks
KW  - failure-prone
KW  - resilient design problems
KW  - submodular approximation algorithms
KW  - active robots
KW  - mobile robots
KW  - resilient active information gathering
KW  - multirobot target tracking
KW  - active information gathering scenario
KW  - denial-of-service attacks
KW  - system-wide resiliency
KW  - minimal communication
KW  - Robot sensing systems
KW  - Target tracking
KW  - Mobile robots
KW  - Robot kinematics
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593630
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.
ER  - 

TY  - CONF
TI  - Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4317
EP  - 4324
AU  - S. Al-Hussaini
AU  - J. M. Gregory
AU  - S. K. Gupta
PY  - 2018
KW  - decision making
KW  - multi-robot systems
KW  - probability
KW  - rescue robots
KW  - robust control
KW  - state estimation
KW  - computationally-efficient manner
KW  - feasible baseline approaches
KW  - context-dependent policies
KW  - robot rescue decision-making
KW  - multirobot teams
KW  - scalable policy synthesis framework
KW  - parallelizable policy synthesis framework
KW  - time-varying
KW  - stochastic mission conditions
KW  - physics-based simulations
KW  - probability minimization
KW  - state estimation
KW  - Robots
KW  - Task analysis
KW  - Computational modeling
KW  - State estimation
KW  - Probabilistic logic
KW  - Switches
KW  - Navigation
DO  - 10.1109/IROS.2018.8594114
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.
ER  - 

TY  - CONF
TI  - Reach-Avoid Problems via Sum-or-Squares Optimization and Dynamic Programming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4325
EP  - 4332
AU  - B. Landry
AU  - M. Chen
AU  - S. Hemley
AU  - M. Pavone
PY  - 2018
KW  - dynamic programming
KW  - reachability analysis
KW  - state-space methods
KW  - reach-avoid problem
KW  - dynamic programming
KW  - sum-of-squares optimization
KW  - polynomial system dynamics
KW  - mathematical guarantees
KW  - Optimization
KW  - Dynamic programming
KW  - System dynamics
KW  - Games
KW  - Planning
KW  - Automobiles
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594078
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reach-avoid problems involve driving a system to a set of desirable configurations while keeping it away from undesirable ones. Providing mathematical guarantees for such scenarios is challenging but have numerous potential practical applications. Due to the challenges, analysis of reach-avoid problems involves making trade-offs between generality of system dynamics, generality of problem setups, optimality of solutions, and computational complexity. In this paper, we combine sum-of-squares optimization and dynamic programming to address the reach-avoid problem, and provide a conservative solution that maintains reaching and avoidance guarantees. Our method is applicable to polynomial system dynamics and to general problem setups, and is more computationally scalable than previous related methods. Through a numerical example involving two single integrators, we validate our proposed theory and compare our method to Hamilton-Jacobi reachability. Having validated our theory, we demonstrate the computational scalability of our method by computing the reach-avoid set of a system involving two kinematic cars.
ER  - 

TY  - CONF
TI  - Development of Rimless Wheel with Controlled Wobbling Mass
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4333
EP  - 4339
AU  - Y. Hanazawa
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - numerical analysis
KW  - robot dynamics
KW  - wheels
KW  - controlled wobbling mass
KW  - rimless wheel
KW  - level-ground walking
KW  - propulsive effects
KW  - physical parameters
KW  - control parameters
KW  - numerical simulation
KW  - robots
KW  - Legged locomotion
KW  - Wheels
KW  - Trajectory
KW  - Torso
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593812
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for generating level-ground walking for a rimless wheel with a controlled wobbling mass. Our rimless wheel achieves level-ground walking by simply controlling the wobbling mass attached to the wheel. We mathematically demonstrate that the controlled wobbling mass generates propulsive effects for the rimless wheel. The walking speed of the rimless wheel can be changed by varying the amplitude of the wobbling mass: thus slow walking to high-speed walking can be realized for the wheel. Moreover, we have developed a robot based on a rimless wheel to show effectiveness of our proposed methods. We then analyze the walking properties with respect to the physical parameters and control parameters of our robot through numerical simulation.
ER  - 

TY  - CONF
TI  - Maneuverability in Dynamic Vertical Climbing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4340
EP  - 4347
AU  - J. M. Brown
AU  - M. P. Austin
AU  - B. Kanwar
AU  - T. E. Jonas
AU  - J. E. Clark
PY  - 2018
KW  - legged locomotion
KW  - robot dynamics
KW  - distinct dynamic gait identification
KW  - dynamic climbing platform
KW  - prescribed body roll
KW  - reduced order pendular dynamic climbing model
KW  - dynamic vertical climbing
KW  - dynamic maneuverability
KW  - dynamic downward climbing
KW  - Legged locomotion
KW  - Dynamics
KW  - Foot
KW  - Mathematical model
KW  - Force
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594074
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we examine the reduced order pendular dynamic climbing model with the addition of attachment windows based on prescribed body roll. With this model and on the new dynamic climbing platform, TAILS, we demonstrate dynamic downward climbing as well as identify distinct dynamic gaits within downward climbing. This, combined with the application of an asymmetric configuration of the rear legs enables strafing motions and thus dynamic maneuverability on walls in the vertical domain.
ER  - 

TY  - CONF
TI  - Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4348
EP  - 4354
AU  - D. J. Gonzalez
AU  - H. H. Asada
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - design engineering
KW  - force control
KW  - gears
KW  - industrial robots
KW  - legged locomotion
KW  - manipulator kinematics
KW  - motion control
KW  - torque control
KW  - wearable robots
KW  - force control
KW  - PPE loads
KW  - extra robotic legs system
KW  - hazardous material emergency
KW  - gear reductions
KW  - XRL system
KW  - power systems
KW  - closed-loop kinematic chain
KW  - actuator loads
KW  - personal protective equipment
KW  - robotic human augmentation system
KW  - torque redistribution
KW  - Legged locomotion
KW  - Payloads
KW  - Kinematics
KW  - Force
KW  - Torque
KW  - Actuators
KW  - Human Augmentation
KW  - Supernumerary Robotic Limbs
KW  - Exoskeletons
KW  - Mechanism Design
KW  - Industrial Robotics
DO  - 10.1109/IROS.2018.8593506
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.
ER  - 

TY  - CONF
TI  - Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4355
EP  - 4362
AU  - X. Lin
AU  - H. Krishnan
AU  - Y. Su
AU  - D. W. Hong
PY  - 2018
KW  - end effectors
KW  - friction
KW  - legged locomotion
KW  - climbing region
KW  - feasibility region analysis
KW  - multilimbed climbing robots
KW  - slide failure mode
KW  - over-torque failure mode
KW  - pure friction end effectors
KW  - walls
KW  - hexapod robot
KW  - robot deformation
KW  - climbing failure
KW  - robots
KW  - stiffness matrices
KW  - statically indeterminate forces
KW  - static indeterminacy modeling
KW  - multilimbed robot vertical two wall climbing
KW  - Strain
KW  - Mathematical model
KW  - Friction
KW  - Force
KW  - Robot kinematics
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593734
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.
ER  - 

TY  - CONF
TI  - Fast Walking with Rhythmic Sway of Torso in a 2D Passive Ankle Walker
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4363
EP  - 4368
AU  - R. Bao
AU  - T. Geng
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - 2D passive ankle walker
KW  - biped robots
KW  - rhythmic sway
KW  - torso-swaying optimization
KW  - optimal trajectories
KW  - fast walking speed
KW  - un-actuated ankles
KW  - Legged locomotion
KW  - Torso
KW  - Trajectory
KW  - Optimization
KW  - Mathematical model
KW  - Foot
KW  - Biped robots
KW  - legged locomotion
DO  - 10.1109/IROS.2018.8593665
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There is a category of biped robots that are equipped with passive or un-actuated ankles, which we call Passive-Ankle Walkers (PAWs). Lack of actuation at ankles is a disadvantage in the fast walking of PAWs. We started this study with an intuitive hypothesis that rhythmic sway of torso may enable faster walking in PAWs. To test this hypothesis, firstly, we optimized the rhythmic sway of torso of a simulated PAW model for fast walking speed, and analyzed the robustness of the optimal trajectories. Then we implemented the optimal trajectories on a real robot. Both the simulation analysis and the experimental results indicated that optimized torso-swaying can greatly increase the walking speed by 40%. By analyzing the walking patterns of the simulated model and the real robot, we identified the reason for the faster walking with swaying-torso: The rhythmic sway of torso enables the robot to walk with a relatively large step-length while still keeninu a hizh sten-frenuencv.
ER  - 

TY  - CONF
TI  - Torque Controlled Biped Model Through a Bio-Inspired Controller Using Adaptive Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4369
EP  - 4374
AU  - C. Ferreira
AU  - T. Cunha
AU  - C. P. Santos
AU  - L. P. Reis
PY  - 2018
KW  - biomimetics
KW  - legged locomotion
KW  - motion control
KW  - oscillators
KW  - robot dynamics
KW  - torque control
KW  - flat terrain
KW  - impedance control
KW  - adaptive frequency oscillator
KW  - biomimetic controller
KW  - torque adjustment
KW  - walking behavior
KW  - joint stiffness
KW  - adaptable stiffness
KW  - bipedal robots
KW  - motion control
KW  - biomimetic solutions
KW  - slopes
KW  - holes
KW  - obstacles
KW  - unstructured terrains
KW  - human beings
KW  - harmonious locomotion
KW  - efficient locomotion
KW  - biped robots
KW  - adaptive learning
KW  - bio-inspired controller
KW  - torque controlled biped model
KW  - Legged locomotion
KW  - Oscillators
KW  - Biological system modeling
KW  - Adaptation models
KW  - Torque
KW  - Robot kinematics
KW  - Biped
KW  - Central Pattern Generator
KW  - Hopf
KW  - AFO
KW  - torque
KW  - stiffness
DO  - 10.1109/IROS.2018.8594160
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Biped robots have not achieved the efficient and harmonious locomotion of the human beings, capable of walking and running on unstructured terrains, with obstacles, holes and slopes. With this in mind, researchers started the development of biomimetic solutions to control the locomotion of biped models. This work presents a new solution of motion control of bipedal robots with adaptable stiffness, by exploring effects of joint stiffness in modulating walking behavior. Further, torque adjustment is achieved through a biomimetic controller that mimics and adjusts the natural dynamics of the robot to the environment. Specifically, the torque adjustment is made using AFOs (adaptive frequency oscillator) to generate the correct equilibrium positions that will be applied to the impedance control that computes the torque of each joint. Results show that the biped model is capable of walking in several types of terrain, including flat terrain, ramps, stairs and flat terrain with obstacles.
ER  - 

TY  - CONF
TI  - High-Speed Stealth Walking of Underactuated Biped Utilizing Effects of Upper-Body Control and Semicircular Feet
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4375
EP  - 4380
AU  - F. Asano
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - high-speed stealth walking
KW  - upper-body control
KW  - semicircular feet
KW  - stable legged locomotion
KW  - underactuated robotic walkers
KW  - double-limb support phase
KW  - gait properties
KW  - typical stealth walking gaits
KW  - upper body motion
KW  - underactuated biped
KW  - Legged locomotion
KW  - Foot
KW  - Mathematical model
KW  - Trajectory
KW  - Numerical models
KW  - Stability analysis
KW  - Analytical models
DO  - 10.1109/IROS.2018.8593821
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Stealth walking is a way of walking carefully and noiselessly, and is an approach to stable legged locomotion of underactuated robotic walkers on irregular terrains. This paper proposes a method for generating a high-speed stealth walking gait without including double-limb support phase, and discusses the effect of upper-body control and semicircular feet on the gait properties. First, we introduce a model of a 3-link planar underactuated biped with an upper body and semicircular feet, and derive the approximate target initial state of the upper body by using the linearized equation of motion. Second, we conduct numerical simulations of the nonlinear model to observe the typical stealth walking gaits, and analyze the changing tendency of the upper body motion with respect to the foot radius. Furthermore, we discuss the advantage of semicircular feet through parametric studies of the gait efficiencies.
ER  - 

TY  - CONF
TI  - A Comparison of Assistive Methods for Suturing in MIRS
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4389
EP  - 4395
AU  - G. A. Fontanelli
AU  - G. Yang
AU  - B. Siciliano
PY  - 2018
KW  - dexterous manipulators
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - human-in-the-Ioop
KW  - vision-free
KW  - telemanipulation paradigm
KW  - surgeons control
KW  - minimally invasive robotic surgery
KW  - robotic systems
KW  - laparoscopic interventions
KW  - assistive methods
KW  - da Vinci Research Kit robot
KW  - robot behaviour
KW  - MIRS
KW  - cognitive load
KW  - dexterity
KW  - surgical site
KW  - Robots
KW  - Needles
KW  - Surgery
KW  - Force
KW  - Trajectory
KW  - Force measurement
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593607
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In Minimally Invasive Robotic Surgery (MIRS) a robot is interposed between the surgeon and the surgical site to increase the precision, dexterity, and to reduce surgeon's effort and cognitive load with respect to the standard laparoscopic interventions. However, the modern robotic systems for MIRS are still based on the traditional telemanipulation paradigm, e.g. the robot behaviour is fully under surgeon's control, and no autonomy or assistance is implemented. In this work, supervised and shared controllers have been developed in a vision-free, human-in-the-Ioop, control framework to help surgeon during a surgical suturing procedure. Experiments conducted on the da Vinci Research Kit robot proves the effectiveness of the method indicating also the guidelines for improving results.
ER  - 

TY  - CONF
TI  - External Force/Torque Estimation on a Dexterous Parallel Robotic Surgical Instrument Wrist
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4396
EP  - 4403
AU  - N. Yilmaz
AU  - M. Bazman
AU  - U. Tumerdem
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - force control
KW  - force sensors
KW  - linear motors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - medical robotics
KW  - motion control
KW  - observers
KW  - position control
KW  - surgery
KW  - torque control
KW  - sensorless force estimation algorithm
KW  - rigid link parallel wrist mechanism
KW  - reaction force observers
KW  - back-drivable rigid-link wrist mechanism
KW  - force sensors
KW  - robotic surgical wrist mechanism
KW  - estimation method
KW  - dexterous parallel robotic surgical instrument wrist
KW  - RMS force-torque estimation error values
KW  - external force-torque estimation
KW  - Wrist
KW  - Force
KW  - Robot sensing systems
KW  - Estimation
KW  - Jacobian matrices
KW  - Kinematics
DO  - 10.1109/IROS.2018.8594326
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a novel sensorless force estimation algorithm for the rigid link parallel wrist mechanism of a robotic surgical instrument. The method utilizes novel reaction force observers (RFOB) in joint space, which are modified disturbance observers (DOB) combined with Neural Networks (NN) for inverse dynamics calculations, to estimate external forces acting on the motors. External force/torque estimation in Cartesian space is achieved by the use of the robot Jacobian. The proposed algorithm is applicable to any back-drivable rigid-link wrist mechanism without the need for force sensors. In this paper, the method is implemented on a novel 3 degree-of-freedom (DOF) parallel robotic surgical wrist mechanism that is designed for high dexterity (±90 degrees pitch-yaw rotations, thrust motion) and force/torque estimation. The wrist is actuated extracorporally with 3 rigid push-pull rods and 3 linear motors. With a rigid transmission and high back-drivability, external force/torque estimation can be achieved from the motor position readings utilizing the proposed method. Several experiments were performed on the manufactured prototype of the instrument and results validate the efficacy of the wrist and estimation method with RMS force/torque estimation error values of 0.0024 Nm in pitch axis, 0.0043 Nm in yaw axis and 0.1866 N in thrust axis.
ER  - 

TY  - CONF
TI  - Hand-Impedance Measurement During Laparoscopic Training Coupled with Robotic Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4404
EP  - 4410
AU  - H. Tugal
AU  - B. Gautier
AU  - M. Kircicek
AU  - M. S. Erden
PY  - 2018
KW  - end effectors
KW  - force sensors
KW  - medical robotics
KW  - position control
KW  - surgery
KW  - end-effector position information
KW  - impedance measurement
KW  - human hand-impedance
KW  - laparoscopic training program
KW  - physically interactive robotic manipulators
KW  - robotic assistants
KW  - needle
KW  - variable admittance controlled robots
KW  - step vice velocity disturbances
KW  - force sensor
KW  - minimally invasive surgery training box
KW  - Robots
KW  - Force
KW  - Laparoscopes
KW  - Training
KW  - Admittance
KW  - Frequency measurement
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8593560
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents measurements of human hand-impedance during a laparoscopic training program with physically interactive robotic manipulators. The knowledge of how the hand-impedance changes due to training might be useful to inform better training programs and to introduce co-manipulated robotic assistants for effective trainings. Ten novice subjects participated in a three weeks training program for a suturing activity in laparoscopy. The subjects have been instructed to set the needle, enter the skin, and tie knots by using laparoscopic tools within a Minimally Invasive Surgery training box. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle. Based on the interaction force and end-effector position information, impedances of the left and right hands were computed in four different directions. The computed results were compared with respect to the participants skill progression.
ER  - 

TY  - CONF
TI  - Comparison of 3D Surgical Tool Segmentation Procedures with Robot Kinematics Prior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4411
EP  - 4418
AU  - Y. Su
AU  - I. Huang
AU  - K. Huang
AU  - B. Hannaford
PY  - 2018
KW  - biological tissues
KW  - biomedical MRI
KW  - computerised tomography
KW  - image reconstruction
KW  - image registration
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - robot kinematics
KW  - surgery
KW  - robot-assisted laparoscopic surgery
KW  - surgical guidance
KW  - local 3D reconstruction
KW  - tool-tissue interaction region
KW  - 3D reconstructed model
KW  - Raven II surgical robot system
KW  - 3D surgical tool segmentation procedure
KW  - robot kinematics
KW  - vision-based force estimation
KW  - medical image registration
KW  - preoperative data
KW  - patient anatomy
KW  - surgical task space
KW  - Tools
KW  - Three-dimensional displays
KW  - Cameras
KW  - Image segmentation
KW  - Robot vision systems
KW  - Force
KW  - Image reconstruction
DO  - 10.1109/IROS.2018.8594428
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D reconstruction and surgical tool segmentation are necessary for several advanced tasks in robot-assisted laparoscopic surgery. These tasks include vision-based force estimation, surgical guidance, and medical image registration where pre-operative data (CT or MRI scan image slices) are overlaid on patient anatomy in real-time during surgery [1] to name a few. In this work, two main strategies were considered: (1) initialize with surgical tool segmentation from 2D images, then proceed to local 3D reconstruction near the tool-tissue interaction region by projecting the segmented result into 3D space, and (2) initialize with 3D reconstruction of the entire surgical task space, followed by surgical tool segmentation from within the 3D reconstructed model. Both methods were implemented on the Raven II surgical robot system, and accuracy and time complexity for both methods were comparatively analyzed while considering various task parameters. Finally, based on the results of this work, guidelines for selecting reconstruction and segmentation strategies and procedure for particular situations are outlined in Section V.
ER  - 

TY  - CONF
TI  - Real-Time Tumor Tracking for Pencil Beam Scanning Proton Therapy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4434
EP  - 4440
AU  - S. Vemprala
AU  - S. Saripalli
AU  - C. Vargas
AU  - M. Bues
AU  - Y. Hu
AU  - J. Shen
PY  - 2018
KW  - biological organs
KW  - cancer
KW  - diagnostic radiography
KW  - image motion analysis
KW  - medical image processing
KW  - pneumodynamics
KW  - proton beams
KW  - radiation therapy
KW  - tumours
KW  - tumor locations
KW  - ceramic-metallic fiducials
KW  - surgical clips
KW  - correlation filters
KW  - cross-correlation matching
KW  - advanced cancer treatment system
KW  - pencil beam scanning proton therapy system
KW  - real-time tumor tracking system
KW  - PBS therapy
KW  - organ motion
KW  - normal breathing movement
KW  - X-ray fluoroscopy system
KW  - visicoil markers
KW  - real-time image guidance
KW  - proton beam
KW  - cancer tumors
KW  - fiducial markers
KW  - Tumors
KW  - Real-time systems
KW  - X-ray imaging
KW  - Particle beams
KW  - Target tracking
KW  - Correlation
DO  - 10.1109/IROS.2018.8593861
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe the method and implementation of a real-time tumor tracking system for a pencil beam scanning (PBS) proton therapy system. PBS is an advanced cancer treatment system that can benefit from precise localization of the tumors through motion. We utilize techniques such as cross-correlation matching, correlation filters and small object saliency, creating an array of methods that can detect and track fiducial markers implanted in the cancer tumors. The final aim is to control the proton beam using real-time image guidance. Our technique works robustly on various types of markers such as ceramic/metallic fiducials, visicoil markers and surgical clips. Left and right views of an X-ray fluoroscopy system were utilized to also triangulate the marker positions in full 3D as they are tracked through normal breathing movement and organ motion. We have tested our detection system on data from several patients with different tumor locations both offline and in real-time and wish to implement it within a full treatment system soon. To the best of the authors knowledge, this is the first real time tracking system for PBS therapy that is applicable for various types of fiducials and tumor locations.
ER  - 

TY  - CONF
TI  - Preference-Based Assistance Prediction for Human-Robot Collaboration Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4441
EP  - 4448
AU  - E. C. Grigore
AU  - A. Roncone
AU  - O. Mangin
AU  - B. Scassellati
PY  - 2018
KW  - control engineering computing
KW  - hidden Markov models
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - human-robot collaboration tasks
KW  - learning supportive behavior preferences
KW  - human-level prediction
KW  - personalized supportive behavior model
KW  - observed human workers
KW  - hidden Markov model
KW  - training data
KW  - human peer
KW  - physical tasks
KW  - human worker
KW  - robots
KW  - preference-based assistance prediction
KW  - Task analysis
KW  - Hidden Markov models
KW  - Service robots
KW  - Collaboration
KW  - Legged locomotion
KW  - Data models
DO  - 10.1109/IROS.2018.8593716
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-Robot Collaboration (HRC) aims to develop robots that provide assistance to human workers while performing physical tasks. Such assistance comes in the form of supportive behaviors that are different from the actions part of the task, and that are meant to help a human worker more effectively accomplish the task. Learning how to provide useful behaviors that are tailored to a human peer represents a difficult challenge. This is due to the need of large amounts of training data in the form of real world observations that include information about such preferences. This data needs to encode not only the structure and progression of the task, but also the different workers' preferences with respect to when and what assistance the robot should provide. Our work separates the challenge of learning a model of the task (which requires a large amount of training data) from that of learning supportive behavior preferences for the interaction (which has obvious restrictions for the number of user-provided demonstrations to which we have access). We first learn a hidden Markov model (HMM) from a training set consisting of observed human workers performing the considered task in simulation. We then use this model to predict, while observing the human peer, what supportive behaviors a robot should offer throughout the task. Building upon the hidden state representation, our system is able to learn the supportive behaviors based on as few as five user-annotated demonstrations, learning a personalized supportive behavior model. We evaluate our system on a user study with 14 participants, and show results on par with human-level prediction for the task.
ER  - 

TY  - CONF
TI  - Collaborative Planning for Mixed-Autonomy Lane Merging
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4449
EP  - 4455
AU  - S. Bansal
AU  - A. Cosgun
AU  - A. Nakhaei
AU  - K. Fujimura
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - driver information systems
KW  - game theory
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - road traffic
KW  - road vehicles
KW  - collaborative planning
KW  - social activity
KW  - mixed-autonomy traffic
KW  - Human-driven Vehicle
KW  - HV
KW  - Autonomous Vehicle drive
KW  - AV
KW  - planning framework
KW  - two-lane highway
KW  - double lane merging
KW  - collaborative decision making
KW  - mixed-autonomy lane merging
KW  - Automobiles
KW  - Planning
KW  - Merging
KW  - Collaboration
KW  - Robots
KW  - Autonomous vehicles
DO  - 10.1109/IROS.2018.8594197
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.
ER  - 

TY  - CONF
TI  - Adaptive Modality Selection Algorithm in Robot-Assisted Cognitive Training
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4456
EP  - 4461
AU  - A. Taranović
AU  - A. Jevtić
AU  - C. Torras
PY  - 2018
KW  - cognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - patient rehabilitation
KW  - robot programming
KW  - service robots
KW  - robotic system
KW  - robot-assisted cognitive training
KW  - socially assistive robots
KW  - therapy
KW  - Alzheimer's disease
KW  - mild cognitive impairment
KW  - dementia
KW  - adaptive modality selection algorithm
KW  - interaction modalities
KW  - AMS algorithm
KW  - Shape
KW  - Training
KW  - Service robots
KW  - Manipulators
KW  - Task analysis
KW  - Market research
DO  - 10.1109/IROS.2018.8593730
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interaction of socially assistive robots with users is based on social cues coming from different interaction modalities, such as speech or gestures. However, using all modalities at all times may be inefficient as it can overload the user with redundant information and increase the task completion time. Additionally, users may favor certain modalities over the other as a result of their disability or personal preference. In this paper, we propose an Adaptive Modality Selection (AMS) algorithm that chooses modalities depending on the state of the user and the environment, as well as user preferences. The variables that describe the environment and the user state are defined as resources, and we posit that modalities are successful if certain resources possess specific values during their use. Besides the resources, the proposed algorithm takes into account user preferences which it learns while interacting with users. We tested our algorithm in simulations, and we implemented it on a robotic system that provides cognitive training, specifically Sequential memory exercises. Experimental results show that it is possible to use only a subset of available modalities without compromising the interaction. Moreover, we see a trend for users to perform better when interacting with a system with implemented AMS algorithm.
ER  - 

TY  - CONF
TI  - Continuous Shared Control for Robotic Arm Reaching Driven by a Hybrid Gaze-Brain Machine Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4462
EP  - 4467
AU  - Y. Wang
AU  - G. Xu
AU  - A. Song
AU  - B. Xu
AU  - H. Li
AU  - C. Hu
AU  - H. Zeng
PY  - 2018
KW  - brain-computer interfaces
KW  - continuous systems
KW  - electroencephalography
KW  - end effectors
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical control systems
KW  - medical robotics
KW  - motion control
KW  - shared control paradigm
KW  - human-robot interface
KW  - robot autonomy
KW  - gaze-BMI control
KW  - hybrid gaze-BMI
KW  - robotic arm end-effector
KW  - continuous shared control
KW  - hybrid gaze-brain machine interface
KW  - brain-machine interface
KW  - assistive robot
KW  - motor impaired people
KW  - motion intention strength
KW  - obstacle avoidance
KW  - Robot kinematics
KW  - End effectors
KW  - Task analysis
KW  - Electroencephalography
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594367
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The brain-machine interface (BMI) has been reported to offer the potential for controlling the assistive robot for the motor impaired people, using the non-invasively obtained electroencephalogram (EEG) signals. However, the EEG based BMI may not be sufficient and stable to drive the robot moving freely in its 2D or 3D workspace. The robot autonomy may provide assistance for the BMI users with the shared control paradigm. Nevertheless, users suffers from several limitations of the current shared control paradigms applied on BMI, e.g., loss of sense of control, high mental workload due to unintuitive control with the human-robot interface and fixed level of assistance. To overcome these drawbacks, we propose a new control paradigm for the robotic arm reaching task where the robot autonomy is dynamically blended with the gaze-BMI control from a user. In this paradigm, the hybrid gaze-BMI constitutes an intuitive and effective input to continuously control the robotic arm end-effector moving freely in its 2D workspace, with an adjustable speed proportional to the motion intention strength. Furthermore, the adjustable level of assistance by our paradigm allows the system to balance the user's capabilities and feelings of control while compensating for the reaching task's difficulty. The proposed paradigm is verified in the task where a healthy subject utilizes the hybrid gaze-BMI to control the robotic arm end-effector reaching for a target object while avoiding the obstacle in the path. The experimental results demonstrate that the movements with our shared control paradigm are safer, more efficient and less difficult than those without shared control.
ER  - 

TY  - CONF
TI  - The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4468
EP  - 4475
AU  - A. Bera
AU  - T. Randhavane
AU  - E. Kubin
AU  - A. Wang
AU  - K. Gray
AU  - D. Manocha
PY  - 2018
KW  - human-robot interaction
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - simulated robot-human interaction scenarios
KW  - entitative robots
KW  - strong emotional reactions
KW  - socially invisible robot navigation
KW  - robot entitativity
KW  - data-driven algorithm
KW  - navigational algorithms
KW  - trajectory computation
KW  - multirobot systems
KW  - Trajectory
KW  - Navigation
KW  - Psychology
KW  - Computational modeling
KW  - Surveillance
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593411
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.
ER  - 

TY  - CONF
TI  - Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4476
EP  - 4482
AU  - T. Chakraborti
AU  - S. Sreedharan
AU  - A. Kulkarni
AU  - S. Kambhampati
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - planning (artificial intelligence)
KW  - virtual reality
KW  - mixed-reality technologies
KW  - human-robot interaction
KW  - HoloLens
KW  - human-in-the-loop operation
KW  - projection-aware task planning capabilities
KW  - Robots
KW  - Task analysis
KW  - Planning
KW  - Virtual reality
KW  - Observers
KW  - Vocabulary
KW  - Natural languages
DO  - 10.1109/IROS.2018.8593830
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent advances in mixed-reality technologies have renewed interest in alternative modes of communication for human-robot interaction. However, most of the work in this direction has been confined to tasks such as teleoperation, simulation or explication of individual actions of a robot. In this paper, we will discuss how the capability to project intentions affect the task planning capabilities of a robot. Specifically, we will start with a discussion on how projection actions can be used to reveal information regarding the future intentions of the robot at the time of task execution. We will then pose a new planning paradigm - projection-aware planning - whereby a robot can trade off its plan cost with its ability to reveal its intentions using its projection actions. We will demonstrate each of these scenarios with the help of a joint human-robot activity using the HoloLens.
ER  - 

TY  - CONF
TI  - KnowRobSIM — Game Engine-Enabled Knowledge Processing Towards Cognition-Enabled Robot Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4491
EP  - 4498
AU  - A. Haidu
AU  - D. Beßler
AU  - A. K. Bozcuoğlu
AU  - M. Beetz
PY  - 2018
KW  - cognitive systems
KW  - computer games
KW  - control engineering computing
KW  - data structures
KW  - decision making
KW  - inference mechanisms
KW  - knowledge representation
KW  - manipulators
KW  - motion control
KW  - rendering (computer graphics)
KW  - action simulation
KW  - physics engine
KW  - AI knowledge representation
KW  - decision making capabilities
KW  - robotic agents
KW  - motion parameterization
KW  - symbolic reasoning methods
KW  - modern game engine technology
KW  - game engine-enabled knowledge processing
KW  - cognition-enabled robot control
KW  - KnowRobSIM
KW  - reasoning methods
KW  - manipulation tasks
KW  - data structures
KW  - world scene rendering
KW  - object manipulation
KW  - Cognition
KW  - Games
KW  - Engines
KW  - Robots
KW  - Force
KW  - Data structures
DO  - 10.1109/IROS.2018.8593935
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - AI knowledge representation and reasoning methods consider actions to be blackboxes that abstract away from how they are executed. This abstract view does not suffice for the decision making capabilities required by robotic agents that are to accomplish manipulation tasks. Such robots have to reason about how to pour without spilling, where to grasp a pot, how to open different containers, and so on. To enable such reasoning it is necessary to consider how objects are perceived, how motions can be executed and parameterized, and how motion parameterization affects the physical effects of actions. To this end, we propose to complement and extend symbolic reasoning methods with KnowRobSIM, an additional reasoning infrastructure based on modern game engine technology, including the subsymbolic world modeling through data structures, action simulation based on physics engine, and world scene rendering. We demonstrate how KnowRobSIM can perform powerful reasoning, prediction, and learning tasks that are required for informed decision making in object manipulation.
ER  - 

TY  - CONF
TI  - Probabilistic Collision Threat Assessment for Autonomous Driving at Road Intersections Inclusive of Vehicles in Violation of Traffic Rules
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4499
EP  - 4506
AU  - S. Noh
PY  - 2018
KW  - belief networks
KW  - collision avoidance
KW  - decision making
KW  - mobile robots
KW  - probability
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - traffic rules violation
KW  - vehicles road intersections inclusive
KW  - Bayesian networks
KW  - time window filtering
KW  - decision-making
KW  - in-vehicle testing
KW  - nonviolation vehicles
KW  - closed urban test road
KW  - violation vehicles
KW  - autonomous vehicle
KW  - probabilistic collision threat assessment algorithm
KW  - autonomous driving
KW  - Roads
KW  - Reliability
KW  - Principal component analysis
KW  - Probabilistic logic
KW  - Prediction algorithms
KW  - Autonomous vehicles
DO  - 10.1109/IROS.2018.8593645
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a probabilistic collision threat assessment algorithm for autonomous driving at road intersections that assesses a given traffic situation at an intersection reliably and robustly for an autonomous vehicle to cross the intersection safely, even in the face of violation vehicles (that is, vehicles in violation of traffic rules at the intersection). To this end, the proposed algorithm employs a detailed digital map to predict future paths of observed vehicles and then utilizes the predicted future paths to identify potential threats (vehicles) and potential collision areas, regardless of whether observed vehicles are obeying traffic rules at the intersection. Next, by means of Bayesian networks and time window filtering under an independent and distributed reasoning structure, it assesses the potential threats regarding the possibility of collision reliably and robustly, even under uncertain and incomplete noise data. Then, it has been tested and evaluated through in-vehicle testing on a closed urban test road under traffic conditions inclusive of non-violation and violation vehicles. In-vehicle testing results show that the performance of the proposed algorithm is sufficiently reliable to be used in decision-making for autonomous driving at intersections in terms of reliability and robustness, even in the face of violation vehicles.
ER  - 

TY  - CONF
TI  - LiDAR-Based Object Tracking and Shape Estimation Using Polylines and Free-Space Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4515
EP  - 4522
AU  - S. Kraemer
AU  - C. Stiller
AU  - M. E. Bouzouraa
PY  - 2018
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - traffic engineering computing
KW  - tracking framework targets
KW  - simultaneous estimation
KW  - free-space information
KW  - accurate dynamic estimates
KW  - consistent shape reconstructions
KW  - polylines
KW  - reliable object perception
KW  - automated driving
KW  - precise contour measurements
KW  - object geometry
KW  - bounding boxes
KW  - public traffic
KW  - box assumption
KW  - object contours
KW  - object poses
KW  - 2D polylines
KW  - tracking systems
KW  - Shape
KW  - Estimation
KW  - Laser modes
KW  - Measurement by laser beam
KW  - Radar tracking
KW  - Geometry
KW  - Shape measurement
DO  - 10.1109/IROS.2018.8593385
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable object perception is a vital requirement for automated driving. Despite the availability of precise contour measurements, most state-of-the-art tracking systems still represent object geometry as bounding boxes. However, there are objects operating in public traffic for which the box assumption is highly inappropriate. We therefore propose to represent object contours using 2D polylines. Taking into account the mutual dependence of object poses and shape, our tracking framework targets at a simultaneous estimation of both states. Moreover, we propose to augment scan segments with free-space information at their boundaries and show how this knowledge can be incorporated into the tracking framework and beyond. Evaluation with real scan data shows that our method produces accurate dynamic estimates and consistent shape reconstructions.
ER  - 

TY  - CONF
TI  - Search-Based Optimal Motion Planning for Automated Driving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4523
EP  - 4530
AU  - Z. Ajanovic
AU  - B. Lacevic
AU  - B. Shyrokau
AU  - M. Stolz
AU  - M. Horn
PY  - 2018
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - road vehicles
KW  - search problems
KW  - trajectory control
KW  - automated driving
KW  - fast motion planning
KW  - robust motion planning
KW  - real-time computation
KW  - urban conditions
KW  - convenient geometrical representation
KW  - search space
KW  - driving constraints
KW  - classical path planning approach
KW  - exact cost-to-go map
KW  - optimal motion trajectory
KW  - time horizons
KW  - fast driving conditions
KW  - slow driving conditions
KW  - search-based optimal motion planning
KW  - Planning
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Dynamics
KW  - Roads
KW  - Search problems
KW  - Automation
KW  - motion planning
KW  - automated driving
KW  - lane change
KW  - multi-lane driving
KW  - traffic lights
KW  - A* search
KW  - MPC
DO  - 10.1109/IROS.2018.8593813
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.
ER  - 

TY  - CONF
TI  - Visual Vehicle Tracking Through Noise and Occlusions Using Crowd-Sourced Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4531
EP  - 4538
AU  - S. M.S.
AU  - H. Grimmett
AU  - L. Platinský
AU  - P. Ondrúška
PY  - 2018
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - traffic engineering computing
KW  - video signal processing
KW  - video surveillance
KW  - camera phones
KW  - performed city-scale structure-from-motion
KW  - high-accuracy localisation
KW  - unsupervised motion prediction
KW  - real-time visual tracking pipeline
KW  - monocular camera
KW  - large-scale datasets
KW  - New York City
KW  - perception system
KW  - large-scale crowd-sourced maps
KW  - visual vehicle tracking
KW  - location-specific method
KW  - Automobiles
KW  - Trajectory
KW  - Tracking
KW  - Three-dimensional displays
KW  - Cameras
KW  - Pipelines
KW  - Hidden Markov models
DO  - 10.1109/IROS.2018.8593378
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a location-specific method to visually track the positions of observed vehicles based on large-scale crowd-sourced maps. We equipped a large fleet of cars that drive around cities with camera phones mounted on the dashboard, and performed city-scale structure-from-motion to accurately reconstruct the trajectories taken by the vehicles. We show that these data can be used to first create a system enabling high-accuracy localisation, and then to accurately predict the future motion of newly observed cars in the camera view. As a basis for the method we use a recently proposed system [1] for unsupervised motion prediction and extend it to a real-time visual tracking pipeline which can track vehicles through noise and extended occlusions using only a monocular camera. The system is tested using two large-scale datasets of San Francisco and New York City containing millions of frames. We demonstrate the performance of the system in a variety of traffic, time, and weather conditions. The presented system requires no manual annotation or knowledge of road infrastructure. To our knowledge, this is the first time a perception system based on a large-scale crowd-sourced maps has been evaluated at this scale.
ER  - 

TY  - CONF
TI  - Vehicle Rebalancing for Mobility-on-Demand Systems with Ride-Sharing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4539
EP  - 4546
AU  - A. Wallar
AU  - M. Van Der Zee
AU  - J. Alonso-Mora
AU  - D. Rus
PY  - 2018
KW  - integer programming
KW  - linear programming
KW  - road traffic
KW  - road vehicles
KW  - scheduling
KW  - vehicle routing
KW  - historical taxi data
KW  - integer linear programming
KW  - idle vehicle redistribution
KW  - MoD systems
KW  - urban transportation
KW  - mobility-on-demand systems
KW  - real-time demand estimate
KW  - fleet operating area
KW  - MoD fleet
KW  - vehicle routes
KW  - road vehicles
KW  - ride-sharing
KW  - vehicle rebalancing
KW  - average waiting time
KW  - rebalancing regions
KW  - time 13.7 s
KW  - Schedules
KW  - Real-time systems
KW  - Delays
KW  - Partitioning algorithms
KW  - Public transportation
KW  - Automobiles
DO  - 10.1109/IROS.2018.8593743
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent developments in Mobility-on-Demand (MoD) systems have demonstrated the potential of road vehicles as an efficient mode of urban transportation Newly developed algorithms can compute vehicle routes in real-time for batches of requests and allow for multiple requests to share vehicles. These algorithms have primarily focused on optimally producing vehicle schedules to pick up and drop off requests. The redistribution of idle vehicles to areas of high demand, known as rebalancing, on the contrary has received little attention in the context of ride-sharing. In this paper, we present a method to rebalance idle vehicles in a ride-sharing enabled MoD fleet. This method consists of an algorithm to optimally partition the fleet operating area into rebalancing regions, an algorithm to determine a real-time demand estimate for every region using incoming requests, and an algorithm to optimize the assignment of idle vehicles to these rebalancing regions using an integer linear program. Evaluation with historical taxi data from Manhattan shows that we can service 99.8% of taxi requests in Manhattan using 3000 vehicles with an average waiting time of 57.4 seconds and an average in-car delay of 13.7 seconds. Moreover, we can achieve a higher service rate using 2000 vehicles than prior work achieved with 3000. Furthermore, with a fleet of 3000 vehicles, we reduce the average travel delay by 86%, the average waiting time by 37%, and the amount of ignored requests by 95% compared to earlier work at the expense of an increased distance travelled by the fleet.
ER  - 

TY  - CONF
TI  - Transferable Pedestrian Motion Prediction Models at Intersections
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4547
EP  - 4553
AU  - M. Shen
AU  - G. Habibi
AU  - J. P. How
PY  - 2018
KW  - automobiles
KW  - feature selection
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pedestrians
KW  - road safety
KW  - statistical analysis
KW  - trajectory control
KW  - autonomous cars
KW  - transfer learning algorithms
KW  - pedestrian trajectories
KW  - transferable pedestrian motion prediction algorithm
KW  - trajectory planning
KW  - inverse reinforcement learning
KW  - feature selection
KW  - IRL
KW  - augmented seminonnegative sparse coding
KW  - ASNSC
KW  - Trajectory
KW  - Hidden Markov models
KW  - Semantics
KW  - Predictive models
KW  - Prediction algorithms
KW  - Feature extraction
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593783
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One desirable capability of autonomous cars is to accurately predict the pedestrian motion near intersections for safe and efficient trajectory planning. We are interested in developing transfer learning algorithms that can be trained on the pedestrian trajectories collected at one intersection and yet still provide accurate predictions of the trajectories at another, previously unseen intersection. We first discussed the feature selection for transferable pedestrian motion models in general. Following this discussion, we developed one transferable pedestrian motion prediction algorithm based on Inverse Reinforcement Learning (IRL) that infers pedestrian intentions and predicts future trajectories based on observed trajectory. We evaluated our algorithm at three intersections. We used the accuracy of augmented semi-nonnegative sparse coding (ASNSC), trained and tested at the same intersection as a baseline. The result shows that the proposed algorithm improves the baseline accuracy by a statistically significant percentage in both non-transfer task and transfer task.
ER  - 

TY  - CONF
TI  - Model-Free Grasp Planning for Configurable Vacuum Grippers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4554
EP  - 4561
AU  - F. You
AU  - M. Mende
AU  - D. Štogl
AU  - B. Hein
AU  - T. Kröger
PY  - 2018
KW  - data acquisition
KW  - dexterous manipulators
KW  - grippers
KW  - path planning
KW  - robot vision
KW  - model-free grasp planning
KW  - adequate sensor-based surface acquisition
KW  - two-step 3D data acquisition approach
KW  - action execution
KW  - iterative grasp planning
KW  - visual detection
KW  - arbitrary suction cups
KW  - contact surfaces
KW  - formalized aspects
KW  - arbitrary positions
KW  - robustly grasp unknown objects
KW  - grasp planner
KW  - robot arm
KW  - visual sensor
KW  - dynamically configurable vacuum gripper
KW  - robot system
KW  - optimal grasp configurations
KW  - configurable vacuum gripper system
KW  - Grippers
KW  - Three-dimensional displays
KW  - Planning
KW  - Grasping
KW  - Robot sensing systems
KW  - Force
DO  - 10.1109/IROS.2018.8594227
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A concept consisting of a new configurable vacuum gripper system and a corresponding method for determining optimal grasp configurations solely based on 3D vision is introduced. The robot system consists of a dynamically configurable vacuum gripper, a visual sensor, and a robot arm that are used in combination with a new grasp planner to robustly grasp unknown objects in arbitrary positions. For this purpose, formalized aspects of selecting contact surfaces for arbitrary suction cups are described; the concept involves visual detection of the objects, segmentation, iterative grasp planning, and action execution. The approach allows for a fast and efficient, yet precise execution of grasps. The core idea is a two-step 3D data acquisition approach and grasp point computation that takes advantage of the fact that the suction cups of the gripper can all be aligned axis-parallel. Therefore, an adequate sensor-based surface acquisition is done from a single viewpoint with respect to the gripper. Results of realworld experiments show that the proposed concept is suitable for a wide range of different and unknown objects in our setup.
ER  - 

TY  - CONF
TI  - Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4562
EP  - 4567
AU  - S. Makino
AU  - K. Kawaharazuka
AU  - A. Fujii
AU  - M. Kawamura
AU  - T. Makabe
AU  - M. Onitsuka
AU  - Y. Asano
AU  - K. Okada
AU  - K. Kawasaki
AU  - M. Inaba
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - dexterous manipulators
KW  - shear modulus
KW  - springs (mechanical)
KW  - grasping
KW  - fingered hand
KW  - machined spring
KW  - variable stiffness
KW  - human hands
KW  - gripping force
KW  - robot hands
KW  - thumb CM joint
KW  - MP joints
KW  - fingers
KW  - variable rigidity mechanism
KW  - joint mechanism
KW  - Springs
KW  - Joints
KW  - Thumb
KW  - Muscles
KW  - Actuators
KW  - Force
KW  - Wires
DO  - 10.1109/IROS.2018.8594316
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human hands can not only grasp objects of various shape and size and manipulate them in hands but also exert such a large gripping force that they can support the body in the situations such as dangling a bar and climbing a ladder. On the other hand, it is difficult for most robot hands to manage both. Therefore in this paper we developed the hand which can grasp various objects and exert large gripping force. To develop such hand, we focused on the thumb CM joint with wide range of motion and the MP joints of four fingers with the DOF of abduction and adduction. Based on the hand with large gripping force and flexibility using machined spring, we applied above mentioned joint mechanism to the hand. The thumb CM joint has wide range of motion because of the combination of three machined springs and MP joints of four fingers have variable rigidity mechanism instead of driving each joint independently in order to move joint in limited space and by limited actuators. Using the developed hand, we achieved the grasping of various objects, supporting a large load and several motions with an arm.
ER  - 

TY  - CONF
TI  - VARO-Fi: A Variable Orientable Gripper to Obtain In-Hand Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4568
EP  - 4575
AU  - N. Rahman
AU  - D. Caldwell
AU  - F. Cannella
PY  - 2018
KW  - control engineering computing
KW  - design engineering
KW  - end effectors
KW  - grippers
KW  - variable orientable gripper
KW  - obtain in-hand manipulation
KW  - variable orientable fingers
KW  - VARO-fi
KW  - gripper platform
KW  - in-hand manipulation tasks
KW  - Payloads
KW  - Grippers
KW  - Grasping
KW  - Kinematics
KW  - Fasteners
KW  - End effectors
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594380
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a novel gripper or end-effector named VARO-fi (VARiable Orientable fingers with translation), with the aim of obtaining human like prehensile manoeuvre such as, in-hand manipulation. The 4 fingered VARO-fi consists of 9 degrees of freedom and it can perform several in-hand manipulation tasks which have been described in this paper. Moreover, the gripper is a simplification of previously proposed gripper platform called Dexclar. The derivation of VARO-fi has been presented and its capabilities have been demonstrated by experiments. Although a generic convex payload is considered as a primitive in the design of VARO-fi however, it is capable to address manipulation for other regular shaped payloads, which has been proven by experiments. A comparison is also illustrated in order to underline the strength of the novel gripper with respect to the state of the art.
ER  - 

TY  - CONF
TI  - The Co-Gripper: A Wireless Cooperative Gripper for Safe Human Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4576
EP  - 4581
AU  - G. Salvietti
AU  - Z. Iqbal
AU  - I. Hussain
AU  - D. Prattichizzo
AU  - M. Malvezzi
PY  - 2018
KW  - grippers
KW  - human-robot interaction
KW  - robust control
KW  - safe human robot interaction
KW  - intuitive control
KW  - industrial service applications
KW  - robotic device
KW  - manipulation tasks
KW  - modular underactuated structure
KW  - robotic arms
KW  - wearable wireless control interface
KW  - human operator
KW  - gripper performance
KW  - human-robot cooperation tasks
KW  - co-gripper
KW  - Grippers
KW  - Collaboration
KW  - Robot kinematics
KW  - Manipulators
KW  - Service robots
KW  - Wireless communication
DO  - 10.1109/IROS.2018.8593877
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a set of guidelines for the design of grippers suitable for a safe human robot/interaction in cooperative tasks. Modularity, adaptability, robustness, intuitive control, limited weight are some of the key elements that could allow to effectively spread these devices in industrial and service applications. Following such guidelines, we present the prototype of the Co-Gripper: a robotic device for cooperative manipulation tasks with humans. The gripper is composed of two pairs of fingers, actuated with two motors, that can be controlled in a coordinated way or independently. Each finger has a modular underactuated structure, composed of three phalanges connected by passive joints. The gripper is wireless, so it can be easily connected both to the robotic arms and on passive structures. We designed a wearable wireless control interface composed of a ring and a bracelet allowing a simple and intuitive activation of the gripper without limiting human operator's manipulation capabilities. We performed a set of tests to quantify gripper performance and to exploit its potentialities in human-robot cooperation tasks.
ER  - 

TY  - CONF
TI  - The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4590
EP  - 4597
AU  - J. Borràs
AU  - R. Heudorfer
AU  - S. Rader
AU  - P. Kaiser
AU  - T. Asfour
PY  - 2018
KW  - assembling
KW  - design engineering
KW  - dexterous manipulators
KW  - grippers
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - bimanual manipulation
KW  - electromechanical devices
KW  - classic dual arm manipulation
KW  - classic industrial robotic arms kinematics
KW  - general purpose grasping
KW  - KIT swiss knife gripper
KW  - disassembly tasks
KW  - robotic gripper design
KW  - dexterous in-hand manipulation
KW  - Grippers
KW  - Tools
KW  - Task analysis
KW  - Grasping
KW  - Manipulators
KW  - Service robots
DO  - 10.1109/IROS.2018.8593567
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.
ER  - 

TY  - CONF
TI  - Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4606
EP  - 4613
AU  - A. Nagabandi
AU  - G. Yang
AU  - T. Asmar
AU  - R. Pandya
AU  - G. Kahn
AU  - S. Levine
AU  - R. S. Fearing
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - microrobots
KW  - mobile robots
KW  - neural nets
KW  - robot dynamics
KW  - underactuated legged systems
KW  - hand-engineered controllers
KW  - dynamic maneuvers
KW  - complex terrains
KW  - real-world legged millirobot
KW  - learned neural network models
KW  - predictive model
KW  - expressive capacity neural network models
KW  - high-capacity neural network models
KW  - effective learning
KW  - dynamic legged millirobot
KW  - image-conditioned dynamics models
KW  - underactuated legged millirobots
KW  - low manufacturing costs
KW  - complex environments
KW  - highly dynamic systems
KW  - Vehicle dynamics
KW  - Legged locomotion
KW  - Neural networks
KW  - Adaptation models
KW  - Predictive models
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594193
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.
ER  - 

TY  - CONF
TI  - Online Adaptation of Robot Pushing Control to Object Properties
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4614
EP  - 4621
AU  - S. Krivic
AU  - J. Piater
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - unknown objects
KW  - data-driven approach
KW  - local inverse models
KW  - robot-object interaction
KW  - push manipulation
KW  - object behaviour
KW  - maximum a posteriori estimation
KW  - pushing objects
KW  - holonomic mobile robot base
KW  - diverse object set
KW  - learned inverse models
KW  - object properties
KW  - online adaptation
KW  - robot pushing control
KW  - robotic scenarios
KW  - real-world environments
KW  - MAP
KW  - Inverse problems
KW  - Adaptation models
KW  - Robot kinematics
KW  - Friction
KW  - Feedforward systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594192
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pushing is a common task in robotic scenarios. In real-world environments, robots need to manipulate various unknown objects without previous experience. We propose a data-driven approach for learning local inverse models of robot-object interaction for push manipulation. The robot makes observations of the object behaviour on the fly and adapts its movement direction. The proposed model is probabilistic, and we update it using maximum a posteriori (MAP) estimation. We test our method by pushing objects with a holonomic mobile robot base. Validation of results over a diverse object set demonstrates a high degree of robustness and a high success rate in pushing objects towards a fixed target and along a path compared to previous methods. Moreover, based on learned inverse models, the robot can learn object properties and distinguish between different object behaviours when they are pushed from different sides.
ER  - 

TY  - CONF
TI  - Composable Learning with Sparse Kernel Representations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4622
EP  - 4628
AU  - E. Tolstaya
AU  - E. Stump
AU  - A. Koppel
AU  - A. Ribeiro
PY  - 2018
KW  - collision avoidance
KW  - Hilbert spaces
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - sparse matrices
KW  - stochastic processes
KW  - obstacle-avoidance policies
KW  - Reproducing kernel Hilbert space
KW  - NAF
KW  - 2D environment
KW  - sparse kernel representations
KW  - normalized advantage function
KW  - state-action function
KW  - nonparametric controllers
KW  - reinforcement learning algorithm
KW  - composable learning
KW  - Kernel
KW  - Stochastic processes
KW  - Hilbert space
KW  - Data models
KW  - Training
KW  - Complexity theory
KW  - Robots
DO  - 10.1109/IROS.2018.8594065
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.
ER  - 

TY  - CONF
TI  - Compensating for Context by Learning Local Models of Perception Performance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4629
EP  - 4634
AU  - H. Hu
AU  - G. Kantor
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - probability
KW  - robot vision
KW  - stereo image processing
KW  - perception performance
KW  - perception system performance
KW  - environmental geometry
KW  - probabilistic performance
KW  - monocular odometry systems
KW  - stereo visual odometry systems
KW  - system failures
KW  - ground robot
KW  - Context modeling
KW  - Visual odometry
KW  - Data models
KW  - Training data
KW  - Predictive models
KW  - Prediction algorithms
DO  - 10.1109/IROS.2018.8593778
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Perception system performance can vary dramatically with contextual factors such as environmental geometry, appearance, and other phenomena. In this work we present a theoretical framework for understanding the role of context in perception and discuss three approaches for predicting probabilistic performance from observations by efficiently learning local performance models. We compare these approaches with experiments on the monocular and stereo visual odometry systems for a ground robot, and show that they can effectively predict system failures in a wide variety of environments.
ER  - 

TY  - CONF
TI  - Setting up a Reinforcement Learning Task with a Real-World Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4635
EP  - 4640
AU  - A. Rupam Mahmood
AU  - D. Korenkevych
AU  - B. J. Komer
AU  - J. Bergstra
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - multi-robot systems
KW  - hard-to-engineer adaptive solutions
KW  - complex tasks
KW  - diverse robotic tasks
KW  - reinforcement learning research
KW  - learning task
KW  - real-world robot
KW  - effective learning
KW  - learning performance
KW  - task setup
KW  - UR5 robotic arm
KW  - Task analysis
KW  - Robot sensing systems
KW  - Instruction sets
KW  - Delays
KW  - Reinforcement learning
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593894
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.
ER  - 

TY  - CONF
TI  - CINet: A Learning Based Approach to Incremental Context Modeling in Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4641
EP  - 4646
AU  - F. Irmak Doğan
AU  - İ. Bozcan
AU  - M. Çelik
AU  - S. Kalkan
PY  - 2018
KW  - learning (artificial intelligence)
KW  - recurrent neural nets
KW  - robots
KW  - incremental context modeling
KW  - robots
KW  - rule-based approach
KW  - recurrent neural network
KW  - CINet
KW  - learning based approach
KW  - scene reasoning tasks
KW  - Context modeling
KW  - Training
KW  - Robots
KW  - Computational modeling
KW  - Resource management
KW  - Recurrent neural networks
KW  - Testing
DO  - 10.1109/IROS.2018.8593633
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we pose the task of when to increment as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks.
ER  - 

TY  - CONF
TI  - Learning Generalizable Robot Skills from Demonstrations in Cluttered Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4655
EP  - 4660
AU  - M. Asif Rana
AU  - M. Mukadam
AU  - S. Reza Ahmadzadeh
AU  - S. Chernova
AU  - B. Boots
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - trajectory control
KW  - learning from demonstration
KW  - LfD approach
KW  - reaching skills
KW  - placing skills
KW  - 7-DOF JACO2 manipulator
KW  - clutter-free environments
KW  - human demonstrations
KW  - cluttered environments
KW  - generalizable robot skills
KW  - salient human behavior
KW  - recent inference-based technique
KW  - incremental skill learning approach
KW  - importance weighted batch
KW  - Trajectory
KW  - Robots
KW  - Clamps
KW  - Covariance matrices
KW  - Collision avoidance
KW  - Stochastic processes
KW  - Clutter
DO  - 10.1109/IROS.2018.8593624
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning from Demonstration (LfD) is a popular approach to endowing robots with skills without having to program them by hand. Typically, LfD relies on human demonstrations in clutter-free environments. This prevents the demonstrations from being affected by irrelevant objects, whose influence can obfuscate the true intention of the human or the constraints of the desired skill. However, it is unrealistic to assume that the robot's environment can always be restructured to remove clutter when capturing human demonstrations. To contend with this problem, we develop an importance weighted batch and incremental skill learning approach, building on a recent inference-based technique for skill representation and reproduction. Our approach reduces unwanted environmental influences on the learned skill, while still capturing the salient human behavior. We provide both batch and incremental versions of our approach and validate our algorithms on a 7-DOF JACO2 manipulator with reaching and placing skills.
ER  - 

TY  - CONF
TI  - Interacting with a “Transparent” Upper-Limb Exoskeleton: A Human Motor Control Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4661
EP  - 4666
AU  - S. Bastide
AU  - N. Vignais
AU  - F. Geffard
AU  - B. Berret
PY  - 2018
KW  - biomechanics
KW  - human-robot interaction
KW  - medical robotics
KW  - motion control
KW  - neurophysiology
KW  - optimal control
KW  - patient rehabilitation
KW  - robot dynamics
KW  - robot kinematics
KW  - transparent upper-limb exoskeleton
KW  - human motor control approach
KW  - human-exoskeleton interaction
KW  - exoskeleton device
KW  - motor adaptation
KW  - human motor control research
KW  - as-transparent-as-possible contact/interaction forces
KW  - motor control laws
KW  - human movement
KW  - optimal control simulations
KW  - motor control features
KW  - Exoskeletons
KW  - Motor drives
KW  - Robots
KW  - Torque
KW  - Task analysis
KW  - Perturbation methods
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593991
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Establishing a symbiotic relationship between a human and a exoskeleton is the end goal in many applications in order to provide benefits to the user. However, the literature focusing on the human side of human-exoskeleton interaction has remained less exhaustive than the literature focusing on the design (hardware/software) of the exoskeleton device itself. It is, though, essential to understand how a human adapts his motor control when interacting with an exoskeleton. Motor adaptation is an implicit process carried out by the central nervous system when the body encounters a perturbation, a paradigm that has been extensively studied in the field of human motor control research. When wearing an exoskeleton, even “as-transparent-as-possible”, contact/interaction forces may impact well-known motor control laws in a way that may be detrimental to the user, and even compromise usability in real applications. The present paper investigates how interaction with a backdrivable upper-limb exoskeleton (ABLE) set in “transparent” mode of control affects the kinematics/dynamics of human movement in a simple task. We find that important motor control features are preserved when moving with ABLE but an overall movement slowness occurs, likely as a response to increased inertia according to optimal control simulations. Such a human motor control approach illustrates one possible way to assess the degree of symbiosis between human and exoskeleton, i.e. by grounding on well-known findings in motor control research.
ER  - 

TY  - CONF
TI  - Wearable Pediatric Gait Exoskeleton - A Feasibility Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4667
EP  - 4672
AU  - A. Ganguly
AU  - D. Sanz-Merodio
AU  - G. Puyuelo
AU  - A. Goñi
AU  - E. Garces
AU  - E. Garcia
PY  - 2018
KW  - gait analysis
KW  - medical robotics
KW  - muscle
KW  - orthotics
KW  - paediatrics
KW  - patient rehabilitation
KW  - metabolic degeneration
KW  - SMA patient rehabilitation
KW  - sit-to-stand movements
KW  - degrees-of-freedom
KW  - flexion-extension
KW  - adduction-abduction
KW  - muscle strength
KW  - wearable exoskeleton
KW  - gait assistance
KW  - feasibility test
KW  - ATLAS exoskeleton
KW  - Spinal Muscular Atrophy patients
KW  - wearable pediatric gait exoskeleton
KW  - Exoskeletons
KW  - Pediatrics
KW  - Diseases
KW  - Force
KW  - Torque
KW  - Hip
KW  - Biomimetics
DO  - 10.1109/IROS.2018.8594211
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study reports the initial testing of a gait exoskeleton for Spinal Muscular Atrophy (SMA) patients having variable muscle strength with no balance or ambulation capabilities. To improve the quality of life of such patients, a pediatric gait exoskeleton was developed. The ATLAS exoskeleton has 8 active degrees of freedom (DOF): 2 at the hip (adduction/abduction and flexion/extension), 1 at the knee and ankle joint for flexion and extension. A feasibility test was performed to gauge the initial response of the patients. This study demonstrates that the exoskeleton was able to provide gait assistance and sit-to-stand movements effectively to the subjects. This kind of wearable exoskeleton will play a key role in the rehabilitation of SMA patients and delay further metabolic degeneration in the future.
ER  - 

TY  - CONF
TI  - Verification of a Robotic Ankle Exoskeleton Control Scheme for Gait Assistance in Individuals with Cerebral Palsy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4673
EP  - 4678
AU  - G. M. Gasparri
AU  - M. O. Bair
AU  - R. P. Libby
AU  - Z. F. Lerner
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - muscle
KW  - orthopaedics
KW  - orthotics
KW  - paediatrics
KW  - patient rehabilitation
KW  - wearable robots
KW  - robotic ankle exoskeleton control scheme
KW  - gait assistance
KW  - cerebral palsy
KW  - walking ability
KW  - pediatric health
KW  - pediatric physical disability
KW  - pathological gait patterns
KW  - CP
KW  - ankle-foot-orthoses
KW  - clinically relevant improvement
KW  - gait mechanics
KW  - orthopedic surgery
KW  - muscle injections
KW  - physical therapy
KW  - wearable exoskeletons
KW  - gait rehabilitation
KW  - initial clinical verification
KW  - instrumented gait analysis
KW  - positive ankle power
KW  - powered plantar-flexion assistance
KW  - reduced muscle function
KW  - powered assistance magnitude
KW  - powered assistance timing
KW  - net metabolic rate
KW  - locomotion
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Torque
KW  - DC motors
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Muscles
DO  - 10.1109/IROS.2018.8593904
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Walking ability is critically important for pediatric health, well-being, and independence. Children with cerebral palsy (CP), the most prevalent cause of pediatric physical disability, often present pathological gait patterns that negatively impact walking capacity. Reduced function of the muscles surrounding the ankle joint in those with CP also greatly increases the energy cost of transport leading to reduce mobility. Ankle-foot-orthoses show limited effectiveness for clinically relevant improvement in gait mechanics, while orthopedic surgery, muscle injections and physical therapy are unable to completely restore gait function. While wearable exoskeletons hold promise for gait rehabilitation, appropriately controlling the timing and magnitude of powered assistance across individuals and conditions remains a considerable challenge. This work seeks to address this challenge through the design and initial clinical verification of a simple ankle exoskeleton control scheme designed to reduce the metabolic cost of transport during walking in an individual with CP. Preliminary experimental results from instrumented gait analysis following 5 training visits demonstrated a 45% increase in positive ankle power and a 16% reduction in net metabolic rate during walking with the exoskeleton providing powered plantar-flexion assistance compared to walking without the exoskeleton. Future work will expand this investigation to a larger cohort of individuals with CP and across additional modes of locomotion.
ER  - 

TY  - CONF
TI  - Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4679
EP  - 4684
AU  - K. Baur
AU  - P. Wolf
AU  - V. Klamroth-Marganska
AU  - W. Bierbauer
AU  - U. Scholz
AU  - R. Riener
AU  - J. E. Duarte
PY  - 2018
KW  - computer games
KW  - control engineering computing
KW  - haptic interfaces
KW  - medical computing
KW  - medical robotics
KW  - patient rehabilitation
KW  - user experience
KW  - virtual reality
KW  - game experience
KW  - Haptic Kitchen game
KW  - haptic guidance
KW  - haptic interaction
KW  - haptic performance balancing algorithm
KW  - spouse-controlled haptic support
KW  - patients post-stroke
KW  - robot-supported multiplayer rehabilitation
KW  - haptically linked patient-spouse training
KW  - robot-aided rehabilitation
KW  - multiplayer games
KW  - Air Hockey game
KW  - Games
KW  - Haptic interfaces
KW  - Training
KW  - Robots
KW  - Damping
KW  - Trajectory
KW  - Sports
DO  - 10.1109/IROS.2018.8593769
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.
ER  - 

TY  - CONF
TI  - A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4685
EP  - 4691
AU  - S. M. Cox
AU  - J. Rubenson
AU  - G. S. Sawicki
PY  - 2018
KW  - actuators
KW  - biocontrol
KW  - biomechanics
KW  - bone
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - mobile robots
KW  - muscle
KW  - springs (mechanical)
KW  - underlying biological mechanisms
KW  - wearable robot
KW  - wearable robotic device
KW  - human locomotion mechanics
KW  - wearable robotics
KW  - soft-exosuit enables multiscale analysis
KW  - bipedal animal model
KW  - biological system interface
KW  - Kinematics
KW  - Springs
KW  - Tendons
KW  - Robots
KW  - Birds
KW  - Fixtures
DO  - 10.1109/IROS.2018.8593911
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.
ER  - 

TY  - CONF
TI  - Through-the-Lens Drone Filming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4692
EP  - 4699
AU  - C. Huang
AU  - Z. Yang
AU  - Y. Kong
AU  - P. Chen
AU  - X. Yang
AU  - K. Cheng
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - feature extraction
KW  - Global Positioning System
KW  - image motion analysis
KW  - image sensors
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - video signal processing
KW  - image composition
KW  - monocular 3D human pose estimation
KW  - drone control system
KW  - drone filming system
KW  - wearable GPS-based sensors
KW  - wearable infrared-based sensors
KW  - through-the-lens drone filming
KW  - aerial filming
KW  - camera control
KW  - drone hardware
KW  - human actions
KW  - drone camera system
KW  - through-the-lens camera planning
KW  - flight control
KW  - through-the-lens drone
KW  - wearable-sensor-based solutions
KW  - drone platform
KW  - outdoor environments
KW  - human movement
KW  - remote controller
KW  - action scenes
KW  - Cameras
KW  - Drones
KW  - Three-dimensional displays
KW  - Sensors
KW  - Pose estimation
KW  - Solid modeling
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594333
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Aerial filming in action scenes using a drone is difficult for inexperienced flyers because manipulating a remote controller and meeting the desired image composition are two independent, while concurrent, tasks. Existing systems attempt to utilize wearable GPS-based or infrared-based sensors to track the human movement and to assist in capturing footage. However, these sensors work only in either indoor (infrared-based) or outdoor environments (GPS-based), but not both. In this paper, we introduce a novel drone filming system which integrates monocular 3D human pose estimation and localization into a drone platform to remove the constraints imposed by wearable-sensor-based solutions. Meanwhile, given the estimated position, we propose a novel drone control system, called “through-the-lens drone filming”, to allow a cameraman to conveniently control the drone by manipulating a 3D model in the preview, which closes the gap between the flight control and the viewpoint design. Our system includes two key enabling techniques: 1) subject localization based on visual-inertial fusion, and 2) through-the-lens camera planning. This is the first drone camera system which allows users to capture human actions by manipulating the camera in a virtual environment. From the drone hardware, we integrate a gimbal camera and two GPUs into the limited space of a drone and demonstrate the feasibility of running the entire system onboard with insignificant delays, which are sufficient for filming in our real-time application. Experimental results, in both simulation and real-world scenarios, demonstrate that our techniques can greatly ease camera control and capture better videos.
ER  - 

TY  - CONF
TI  - Towards Aerial Recovery of Parachute-Deployed Payloads
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4700
EP  - 4707
AU  - A. Shankar
AU  - S. Elbaum
AU  - C. Detweiler
PY  - 2018
KW  - aerospace robotics
KW  - aircraft control
KW  - mobile robots
KW  - position control
KW  - parachute-deployed payloads
KW  - sensor payloads
KW  - atmospheric profiling applications
KW  - inaccessible regions
KW  - multirotor unmanned aerial system
KW  - parachute-payload system
KW  - long-term payload transportation systems
KW  - aerial recovery
KW  - Payloads
KW  - Target tracking
KW  - Cameras
KW  - Robot sensing systems
KW  - Vehicle dynamics
KW  - Aerodynamics
DO  - 10.1109/IROS.2018.8594082
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.
ER  - 

TY  - CONF
TI  - Airborne Docking for Multi-Rotor Aerial Manipulations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4708
EP  - 4714
AU  - R. Miyazaki
AU  - R. Jiang
AU  - H. Paul
AU  - K. Ono
AU  - K. Shimonomura
PY  - 2018
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multirotor aerial robots
KW  - transport multirotor UAV
KW  - winch mechanism
KW  - onboard locolization
KW  - mobile manipulation system
KW  - airborne docking method
KW  - IMU data
KW  - multirotor aerial manipulations
KW  - Winches
KW  - Bars
KW  - Cameras
KW  - Robot vision systems
KW  - DC motors
KW  - Propellers
DO  - 10.1109/IROS.2018.8594513
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.
ER  - 

TY  - CONF
TI  - Optimal Time Allocation for Quadrotor Trajectory Generation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4715
EP  - 4722
AU  - F. Gao
AU  - W. Wu
AU  - J. Pan
AU  - B. Zhou
AU  - S. Shen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - convex programming
KW  - helicopters
KW  - mobile robots
KW  - optimal control
KW  - polynomials
KW  - robot dynamics
KW  - trajectory control
KW  - optimal time allocation
KW  - quadrotor flights
KW  - quadrotor trajectory generation problem
KW  - spatial trajectory
KW  - time optimization
KW  - polynomial trajectories
KW  - quadrotor platform
KW  - kinodynamic limits
KW  - autonomous flights
KW  - open-source ROS-package
KW  - temporal trajectory
KW  - convex program
KW  - mapping function
KW  - Trajectory
KW  - Resource management
KW  - Safety
KW  - Optimization
KW  - Acceleration
KW  - Time-domain analysis
KW  - Shape
DO  - 10.1109/IROS.2018.8593579
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a framework to do optimal time allocation for quadrotor trajectory generation. Using this method, we can generate minimum-time piecewise polynomial trajectories for quadrotor flights. We decouple the quadrotor trajectory generation problem into two folds. Firstly we generate a smooth and safe curve which is parameterized by a virtual variable. This curve named spatial trajectory is independent of time and has fixed spatial properties. Then a mapping function which decides how the quadrotor moves along the spatial trajectory respecting kinodynamic limits is found by minimizing total trajectory time. The mapping function maps the virtual variable to time is named temporal trajectory. We formulate the minimum-time temporal trajectory generation problem as a convex program which can be efficiently solved. We show that the proposed method can corporate with various types of previous trajectory generation method to obtain the optimal time allocation. The proposed method is integrated into a customized light-weight quadrotor platform and is validated by presenting autonomous flights in indoor and outdoor environments. We release our code for time optimization as an open-source ros-package.
ER  - 

TY  - CONF
TI  - Aerial Radio-Based Telemetry for Tracking Wildlife
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4723
EP  - 4728
AU  - H. Bayram
AU  - N. Stefas
AU  - V. Isler
PY  - 2018
KW  - autonomous aerial vehicles
KW  - directive antennas
KW  - mobile radio
KW  - mobile robots
KW  - radio tracking
KW  - telemetry
KW  - aerial radio-based telemetry
KW  - measurement locations
KW  - radio collar
KW  - low-cost directional antenna
KW  - USB receiver
KW  - wedges
KW  - online strategy
KW  - measurement noise
KW  - autonomous aerial robot
KW  - wildlife tracking
KW  - localization uncertainty
KW  - Antenna measurements
KW  - Animals
KW  - Measurement uncertainty
KW  - Uncertainty
KW  - Time measurement
KW  - Sensors
KW  - Robots
DO  - 10.1109/IROS.2018.8594503
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.
ER  - 

TY  - CONF
TI  - Planning to Monitor Wildfires with a Fleet of UAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4729
EP  - 4734
AU  - R. Bailon-Ruiz
AU  - S. Lacroix
AU  - A. Bit-Monnot
PY  - 2018
KW  - autonomous aerial vehicles
KW  - emergency management
KW  - fires
KW  - path planning
KW  - search problems
KW  - wildfires
KW  - fire propagation process
KW  - observation trajectories
KW  - fire model
KW  - wildfire monitoring
KW  - variable neighborhood search method
KW  - fixed-wing UAV fleet
KW  - Trajectory
KW  - Monitoring
KW  - Cameras
KW  - Ignition
KW  - Planning
KW  - Fuels
KW  - Shape
DO  - 10.1109/IROS.2018.8593859
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind. The approach tailors a generic Variable Neighborhood Search method to these models and associated constraints. Simulation results show ability to plan observation trajectories for a small fleet of UAVs, and to update the plans when new information on the fire are incorporated in the fire model.
ER  - 

TY  - CONF
TI  - Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4735
EP  - 4742
AU  - M. Zhao
AU  - F. Shi
AU  - T. Anzai
AU  - K. Chaudhary
AU  - X. Chen
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - aerospace control
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - stability
KW  - multilinked model
KW  - near-hover condition
KW  - motion sequence
KW  - improved dynamics derivation
KW  - flight control method
KW  - flight stability
KW  - small opening
KW  - flight motion
KW  - transformable multilinked aerial robot
KW  - multilinked robot
KW  - transformable aerial robot
KW  - under-actuated multirotors
KW  - aggressive maneuvering
KW  - necessary condition
KW  - crucial problems
KW  - unknown obstacle
KW  - multirotor
KW  - robot body
KW  - Unmanned aerial vehicles
KW  - Rotors
KW  - Collision avoidance
KW  - Path planning
KW  - Stability analysis
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593368
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).
ER  - 

TY  - CONF
TI  - Optimal Constrained Trajectory Generation for Quadrotors Through Smoothing Splines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4743
EP  - 4750
AU  - S. Lai
AU  - M. Lan
AU  - B. M. Chen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - optimisation
KW  - path planning
KW  - splines (mathematics)
KW  - time optimal control
KW  - trajectory control
KW  - vehicles physical limits
KW  - large-scale fitting problem
KW  - human sketching
KW  - optimal constrained trajectory generation
KW  - inequality constraints
KW  - closed-form solution
KW  - safe flying zones
KW  - interval-wise constraints
KW  - axes-coupled
KW  - time optimal control techniques
KW  - polynomial splines
KW  - optimal smoothing B-spline
KW  - quadrotors
KW  - Trajectory
KW  - Splines (mathematics)
KW  - Optimization
KW  - Smoothing methods
KW  - Closed-form solutions
KW  - Space vehicles
KW  - Safety
DO  - 10.1109/IROS.2018.8594357
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a trajectory generation method for quadrotors based on the optimal smoothing B-spline. Compared to existing methods which rely on polynomial splines or time optimal control techniques, our method systematically addresses the issue of axes-coupled and interval-wise constraints. These constraints can be used to construct safe flying zones and satisfy vehicle's physical limits. The proposed approach has also been extended to generate trajectories from the nominal plan which consists of not only points but also lines and planes, opening a door for new improvements and applications. Moreover, a closed-form solution can be obtained for cases without inequality constraints. Such a solution is numerically stable for the large-scale fitting problem, which allows us to directly fit the human sketching input from the touch device and capture all subtle details. Our approach is verified by various real flight experiments..
ER  - 

TY  - CONF
TI  - FarSight: Long-Range Depth Estimation from Outdoor Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4751
EP  - 4757
AU  - M. A. Reza
AU  - J. Kosecka
AU  - P. David
PY  - 2018
KW  - convolutional neural nets
KW  - image reconstruction
KW  - image sensors
KW  - rendering (computer graphics)
KW  - stereo image processing
KW  - unsupervised learning
KW  - long-range depth estimation
KW  - outdoor images
KW  - long-range monocular depth estimation
KW  - outdoor urban environments
KW  - range sensors
KW  - outdoor settings
KW  - outdoor single view methods
KW  - synthetic long-range ground truth depth data
KW  - long-range depth renderings
KW  - depth prediction
KW  - depth estimation algorithms
KW  - Generative Adversarial Network
KW  - GAN
KW  - size 10.0 m
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Estimation
KW  - Image reconstruction
KW  - Urban areas
KW  - Google
KW  - Meters
DO  - 10.1109/IROS.2018.8593971
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces the problem of long-range monocular depth estimation for outdoor urban environments. Range sensors and traditional depth estimation algorithms (both stereo and single view) predict depth for distances of less than 100 meters in outdoor settings and 10 meters in indoor settings. The shortcomings of outdoor single view methods that use learning approaches are, to some extent, due to the lack of long-range ground truth training data, which in turn is due to limitations of range sensors. To circumvent this, we first propose a novel strategy for generating synthetic long-range ground truth depth data. We utilize Google Earth images to reconstruct large-scale 3D models of different cities with proper scale. The acquired repository of 3D models and associated RGB views along with their long-range depth renderings are used as training data for depth prediction. We then train two deep neural network models for long-range depth estimation: i) a Convolutional Neural Network (CNN) and ii) a Generative Adversarial Network (GAN). We found in our experiments that the GAN model predicts depth more accurately. We plan to open-source the database and the baseline models for public use.
ER  - 

TY  - CONF
TI  - LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4758
EP  - 4765
AU  - T. Shan
AU  - B. Englot
PY  - 2018
KW  - embedded systems
KW  - feature extraction
KW  - image segmentation
KW  - optical radar
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM framework
KW  - edge features
KW  - feature extraction
KW  - point cloud segmentation
KW  - lightweight and ground-optimized lidar odometry
KW  - real-time six degree-of-freedom pose estimation
KW  - low-power embedded system
KW  - ground plane
KW  - two-step Levenberg-Marquardt optimization method
KW  - optimization steps
KW  - ground vehicles
KW  - LeGO-LOAM
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Image segmentation
KW  - Pose estimation
KW  - Real-time systems
KW  - Iterative closest point algorithm
DO  - 10.1109/IROS.2018.8594299
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a lightweight and ground-optimized lidar odometry and mapping method, LeGO-LOAM, for realtime six degree-of-freedom pose estimation with ground vehicles. LeGO-LOAM is lightweight, as it can achieve realtime pose estimation on a low-power embedded system. LeGO-LOAM is ground-optimized, as it leverages the presence of a ground plane in its segmentation and optimization steps. We first apply point cloud segmentation to filter out noise, and feature extraction to obtain distinctive planar and edge features. A two-step Levenberg-Marquardt optimization method then uses the planar and edge features to solve different components of the six degree-of-freedom transformation across consecutive scans. We compare the performance of LeGO-LOAM with a state-of-the-art method, LOAM, using datasets gathered from variable-terrain environments with ground vehicles, and show that LeGO-LOAM achieves similar or better accuracy with reduced computational expense. We also integrate LeGO-LOAM into a SLAM framework to eliminate the pose estimation error caused by drift, which is tested using the KITTI dataset.
ER  - 

TY  - CONF
TI  - A Maximum Likelihood Approach to Extract Polylines from 2-D Laser Range Scans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4766
EP  - 4773
AU  - A. Schaefer
AU  - D. Büscher
AU  - L. Luft
AU  - W. Burgard
PY  - 2018
KW  - image reconstruction
KW  - image registration
KW  - laser ranging
KW  - maximum likelihood estimation
KW  - probability
KW  - simulated laser scans
KW  - maximum likelihood approach
KW  - 2-D laser range scans
KW  - man-made environments
KW  - factory floors
KW  - linear structures
KW  - probabilistic method
KW  - polylines extraction
KW  - Feature extraction
KW  - Sensors
KW  - Lasers
KW  - Probabilistic logic
KW  - Optimization
KW  - Measurement by laser beam
KW  - Laser radar
DO  - 10.1109/IROS.2018.8593844
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Man-made environments such as households, offices, or factory floors are typically composed of linear structures. Accordingly, polylines are a natural way to accurately represent their geometry. In this paper, we propose a novel probabilistic method to extract polylines from raw 2-D laser range scans. The key idea of our approach is to determine a set of polylines that maximizes the likelihood of a given scan. In extensive experiments carried out on publicly available real-world datasets and on simulated laser scans, we demonstrate that our method substantially outperforms existing state-of-the-art approaches in terms of accuracy, while showing comparable computational requirements. Our implementation is available under https://github.com/acschaefer/ple.
ER  - 

TY  - CONF
TI  - Learning a Local Feature Descriptor for 3D LiDAR Scans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4774
EP  - 4780
AU  - A. Dewan
AU  - T. Caselitz
AU  - W. Burgard
PY  - 2018
KW  - convolutional neural nets
KW  - feature extraction
KW  - image matching
KW  - image representation
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - SLAM (robots)
KW  - learned feature descriptor
KW  - 3D local descriptors
KW  - local feature descriptor
KW  - 3D LiDAR scans
KW  - robust data association
KW  - scan alignment algorithms
KW  - handcrafted feature descriptors
KW  - metric learning network
KW  - local surface patches
KW  - convolutional neural network
KW  - ground-truth correspondences
KW  - SLAM system
KW  - CNN
KW  - Siamese network
KW  - Three-dimensional displays
KW  - Measurement
KW  - Laser radar
KW  - Feature extraction
KW  - Streaming media
KW  - Task analysis
KW  - Gray-scale
DO  - 10.1109/IROS.2018.8594420
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust data association is necessary for virtually every SLAM system and finding corresponding points is typically a preprocessing step for scan alignment algorithms. Traditionally, handcrafted feature descriptors were used for these problems but recently learned descriptors have been shown to perform more robustly. In this work, we propose a local feature descriptor for 3D LiDAR scans. The descriptor is learned using a Convolutional Neural Network (CNN). Our proposed architecture consists of a Siamese network for learning a feature descriptor and a metric learning network for matching the descriptors. We also present a method for estimating local surface patches and obtaining ground-truth correspondences. In extensive experiments, we compare our learned feature descriptor with existing 3D local descriptors and report highly competitive results for multiple experiments in terms of matching accuracy and computation time.
ER  - 

TY  - CONF
TI  - Hallucinating Robots: Inferring Obstacle Distances from Partial Laser Measurements
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4781
EP  - 4787
AU  - J. Lundell
AU  - F. Verdoja
AU  - V. Kyrki
PY  - 2018
KW  - collision avoidance
KW  - distance measurement
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - optical scanners
KW  - hallucinating robots
KW  - obstacle distances
KW  - partial laser measurements
KW  - mobile robots
KW  - 2D laser scanners
KW  - glass panels
KW  - richer sensor readings
KW  - RGBD sensors
KW  - raw 2D laser data
KW  - raw 2D laser distances
KW  - partial 2D laser readings
KW  - Lasers
KW  - Two dimensional displays
KW  - Measurement by laser beam
KW  - Robot sensing systems
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594399
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many mobile robots rely on 2D laser scanners for localization, mapping, and navigation. However, those sensors are unable to correctly provide distance to obstacles such as glass panels and tables whose actual occupancy is invisible at the height the sensor is measuring. In this work, instead of estimating the distance to obstacles from richer sensor readings such as 3D lasers or RGBD sensors, we present a method to estimate the distance directly from raw 2D laser data. To learn a mapping from raw 2D laser distances to obstacle distances we frame the problem as a learning task and train a neural network formed as an autoencoder. A novel configuration of network hyperparameters is proposed for the task at hand and is quantitatively validated on a test set. Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the trained network can successfully infer obstacle distances from partial 2D laser readings.
ER  - 

TY  - CONF
TI  - Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4788
EP  - 4793
AU  - A. Mandow
AU  - J. Morales
AU  - J. A. Gomez-Ruiz
AU  - A. J. García-Cerezo
PY  - 2018
KW  - image sensors
KW  - object detection
KW  - optical radar
KW  - optical scanners
KW  - scan homogeneity
KW  - 3D sensor homogeneity
KW  - spherical formulation
KW  - HDL-32 sensors
KW  - building full-3D lidars
KW  - robotics research
KW  - constant pitch angles
KW  - rolling DOF
KW  - RMBLs
KW  - complex 3D scan measurement distributions
KW  - spherical FOV
KW  - high-resolution scans
KW  - rotating multibeam lidars
KW  - degree-of-freedom
KW  - vertical resolution
KW  - high data rates
KW  - accessible 3D sensors
KW  - MBL
KW  - multibeam lidar scanners
KW  - multibeam Velodyne range-finder
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Indexes
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593916
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.
ER  - 

TY  - CONF
TI  - Laser Map Aided Visual Inertial Localization in Changing Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4794
EP  - 4801
AU  - X. Ding
AU  - Y. Wang
AU  - D. Li
AU  - L. Tang
AU  - H. Yin
AU  - R. Xiong
PY  - 2018
KW  - cameras
KW  - geometry
KW  - optical radar
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - map optimization
KW  - changing environment
KW  - bi-directional tasks
KW  - LiDAR-built map
KW  - online visual inertial odometry system
KW  - laser map aided visual inertial localization
KW  - geometry information
KW  - crossmodal data association
KW  - multisession laser
KW  - Visualization
KW  - Lasers
KW  - Bundle adjustment
KW  - Laser radar
KW  - Robots
KW  - Cameras
DO  - 10.1109/IROS.2018.8593846
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Long-term visual localization in outdoor environment is a challenging problem, especially faced with the cross-seasonal, bi-directional tasks and changing environment. In this paper we propose a novel visual inertial localization framework that localizes against the LiDAR-built map. Based on the geometry information of the laser map, a hybrid bundle adjustment framework is proposed, which estimates the poses of the cameras with respect to the prior laser map as well as optimizes the state variables of the online visual inertial odometry system simultaneously. For more accurate crossmodal data association, the laser map is optimized using multisession laser and visual data to extract the salient and stable subset for visual localization. To validate the efficiency of the proposed method, we collect data in south part of our campus in different seasons, along the same and opposite-direction route. In all sessions of localization data, our proposed method gives satisfactory results, and shows the superiority of the hybrid bundle adjustment and map optimization1.
ER  - 

TY  - CONF
TI  - Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4802
EP  - 4809
AU  - G. Kim
AU  - A. Kim
PY  - 2018
KW  - feature extraction
KW  - optical radar
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - simultaneous localization and mapping
KW  - scan context performance
KW  - Light Detection and Ranging scans
KW  - visual scenes
KW  - two-phase search algorithm
KW  - 3D LiDAR scans
KW  - loop-detection invariant
KW  - nonhistogram-based global descriptor
KW  - global localization
KW  - diverse sensors
KW  - dense 3D maps
KW  - structural information
KW  - diverse feature detectors
KW  - 3D point cloud map
KW  - place recognition
KW  - Three-dimensional displays
KW  - Sensors
KW  - Laser radar
KW  - Histograms
KW  - Shape
KW  - Visualization
KW  - Encoding
DO  - 10.1109/IROS.2018.8593953
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Compared to diverse feature detectors and descriptors used for visual scenes, describing a place using structural information is relatively less reported. Recent advances in simultaneous localization and mapping (SLAM) provides dense 3D maps of the environment and the localization is proposed by diverse sensors. Toward the global localization based on the structural information, we propose Scan Context, a non-histogram-based global descriptor from 3D Light Detection and Ranging (LiDAR) scans. Unlike previously reported methods, the proposed approach directly records a 3D structure of a visible space from a sensor and does not rely on a histogram or on prior training. In addition, this approach proposes the use of a similarity score to calculate the distance between two scan contexts and also a two-phase search algorithm to efficiently detect a loop. Scan context and its search algorithm make loop-detection invariant to LiDAR viewpoint changes so that loops can be detected in places such as reverse revisit and corner. Scan context performance has been evaluated via various benchmark datasets of 3D LiDAR scans, and the proposed method shows a sufficiently improved performance.
ER  - 

TY  - CONF
TI  - Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4810
EP  - 4817
AU  - G. Best
AU  - S. Huang
AU  - R. Fitch
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - probability
KW  - decentralised mission monitoring
KW  - spatiotemporal optimal stopping
KW  - multirobot variant
KW  - mission monitoring problem
KW  - multiple tracker robots
KW  - single target robot
KW  - multirobot systems
KW  - task performance
KW  - marine robotics missions
KW  - single-robot paths
KW  - probabilistic representation
KW  - decentralised scheme
KW  - useful analytical properties
KW  - planned trajectories
KW  - probabilistic motion
KW  - observation models
KW  - mission monitoring systems
KW  - Monitoring
KW  - Trajectory
KW  - Target tracking
KW  - Robot kinematics
KW  - Probabilistic logic
KW  - Predictive models
DO  - 10.1109/IROS.2018.8593663
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.
ER  - 

TY  - CONF
TI  - Uncertain Local Leader Selection in Distributed Formations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4818
EP  - 4824
AU  - D. Rovinsky
AU  - N. Agmon
PY  - 2018
KW  - collision avoidance
KW  - control engineering computing
KW  - mobile robots
KW  - multi-robot systems
KW  - virtual local leader
KW  - accurate local leader
KW  - formation accuracy
KW  - individual robot
KW  - sensory uncertainty
KW  - distributed setting
KW  - optimal multirobot formation control
KW  - uncertain environment
KW  - desired formation
KW  - specific formation
KW  - desired destination
KW  - single robot
KW  - local leaders
KW  - specific predefined angle
KW  - hierarchical form
KW  - Leader-Follower
KW  - distributed formations
KW  - uncertain local leader selection
KW  - visible robots
KW  - Robot sensing systems
KW  - Reliability
KW  - Shape
KW  - Uncertainty
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594307
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.
ER  - 


TY  - CONF
TI  - Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4825
EP  - 4832
AU  - A. Naz
AU  - B. Piranda
AU  - J. Bourgeois
AU  - S. C. Goldstein
PY  - 2018
KW  - approximation theory
KW  - distributed control
KW  - embedded systems
KW  - large-scale systems
KW  - mobile robots
KW  - multi-robot systems
KW  - tree searching
KW  - asynchronous distributed embedded systems
KW  - distributed system coordination
KW  - approximation algorithm
KW  - memory per node
KW  - neighboring modules
KW  - lattice structure
KW  - resource-constrained identical modules
KW  - distributed modular robotic ensembles
KW  - huge modular robot
KW  - large-scale systems
KW  - hardware modular robots
KW  - approximate-center node
KW  - k-BFS SumSweep algorithm
KW  - Approximation algorithms
KW  - Robot kinematics
KW  - Voting
KW  - Heuristic algorithms
KW  - Probabilistic logic
KW  - Embedded systems
KW  - Distributed algorithm
KW  - Modular robots
KW  - Center election
DO  - 10.1109/IROS.2018.8593612
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.
ER  - 

TY  - CONF
TI  - A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4833
EP  - 4839
AU  - F. Morbidi
AU  - E. Bretagne
PY  - 2018
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - position control
KW  - trajectory control
KW  - multiagent systems
KW  - classification task
KW  - conventional centered wheel
KW  - distance-bearing formations
KW  - unicycle robots
KW  - distance-bearing constraints
KW  - macro-robot
KW  - regular convex polygon
KW  - trajectory-tracking control problem
KW  - Mobile robots
KW  - Wheels
KW  - Robot kinematics
KW  - Kinematics
KW  - Vehicle dynamics
KW  - Axles
DO  - 10.1109/IROS.2018.8593984
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.
ER  - 

TY  - CONF
TI  - Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - H. Yang
AU  - N. Staub
AU  - A. Franchi
AU  - D. Lee
PY  - 2018
KW  - aerospace robotics
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - vibration control
KW  - MAGMaS
KW  - load flexibility
KW  - heterogeneous system
KW  - aerial robot
KW  - rigid load manipulation
KW  - load weight holding
KW  - long-slender object manipulation
KW  - multiple aerial-ground manipulator system
KW  - flexible load-tip pose tracking
KW  - vibration suppression controllability
KW  - Unmanned aerial vehicles
KW  - Manipulators
KW  - Load modeling
KW  - Vibrations
KW  - Mathematical model
KW  - Shape
DO  - 10.1109/IROS.2018.8593834
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.
ER  - 

TY  - CONF
TI  - Determining Effective Swarm Sizes for Multi-Job Type Missions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4848
EP  - 4853
AU  - M. Chandarana
AU  - M. Lewis
AU  - K. Sycara
AU  - S. Scherer
PY  - 2018
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - particle swarm optimisation
KW  - queueing theory
KW  - sensitivity analysis
KW  - vehicle routing
KW  - sensitivity analysis
KW  - M/M/k/k queuing model
KW  - swarm search and service mission
KW  - SSS mission
KW  - swarm sizes
KW  - DVR
KW  - dynamic vehicle routing
KW  - multijob type missions
KW  - multiagent framework
KW  - balancing vehicle allocation
KW  - human operators
KW  - Robot sensing systems
KW  - Routing
KW  - Time factors
KW  - Planning
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593919
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.
ER  - 

TY  - CONF
TI  - Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4854
EP  - 4861
AU  - D. Roy
AU  - A. Chowdhury
AU  - M. Maitra
AU  - S. Bhattacharya
PY  - 2018
KW  - collision avoidance
KW  - hierarchical systems
KW  - multi-robot systems
KW  - stability
KW  - switching systems (control)
KW  - trees (mathematics)
KW  - multirobot virtual structure switching
KW  - formation changing strategy
KW  - region-based shape controller
KW  - swarm-robotic framework
KW  - traditional obstacle-avoidance problem
KW  - virtual structure methodology
KW  - triangular formation
KW  - shrinking phenomena
KW  - variable structure
KW  - two-layer hierarchical control strategy
KW  - inter-agent formation
KW  - spanning-tree-assisted-shape-matching algorithm
KW  - stability analysis
KW  - Shape
KW  - Robots
KW  - Switches
KW  - Convergence
KW  - Simulation
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8594438
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.
ER  - 

TY  - CONF
TI  - Distributed Sensing Subject to Temporal Logic Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4862
EP  - 4868
AU  - Z. Serlin
AU  - K. Leahy
AU  - R. Tron
AU  - C. Belta
PY  - 2018
KW  - entropy
KW  - formal specification
KW  - greedy algorithms
KW  - multi-agent systems
KW  - optimisation
KW  - temporal logic
KW  - distributed sensing subject
KW  - temporal logic constraints
KW  - temporal logic specifications
KW  - local objective functions
KW  - motion plans
KW  - objective function
KW  - information entropy
KW  - unassigned agents
KW  - satisfaction guarantees
KW  - optimality loss
KW  - local greedy minimization
KW  - TL constraints
KW  - specification complexity
KW  - TL specification
KW  - product automaton based approach
KW  - Robot sensing systems
KW  - Linear programming
KW  - Task analysis
KW  - Planning
KW  - Automata
DO  - 10.1109/IROS.2018.8593574
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.
ER  - 

TY  - CONF
TI  - Comparison of Dynamic Models for Non-Contact Micromanipulation Based on Dielectrophoretic Actuation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4869
EP  - 4874
AU  - V. Gauthier
AU  - A. Bolopion
AU  - M. Gauthier
PY  - 2018
KW  - closed loop systems
KW  - drag
KW  - electrophoresis
KW  - microfluidics
KW  - micromanipulators
KW  - physics computing
KW  - wall-effect
KW  - dielectrophoretic systems
KW  - closed loop control
KW  - induced dielectrophoretic force
KW  - dielectrophoretic actuation
KW  - noncontact micromanipulation
KW  - anisotropic drag force
KW  - dielectrophoresis force
KW  - dipolar model
KW  - Force
KW  - Drag
KW  - Computational modeling
KW  - Dielectrophoresis
KW  - Electrodes
KW  - Trajectory
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594377
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Several approaches are proposed in the literature to calculate the drag force, the electric field and the induced dielectrophoretic force. This paper analyzes the performances of various models for closed loop control of dielectrophoretic systems in comparison with experiments. This article compares their performance in terms of accuracy, computation time, and memory consumption. Four classical approaches are available to calculate the electric field. Their performances are analyzed in the paper. We have shown that combining the dipolar model of dielectrophoresis force with an anisotropic drag force (integrating the wall-effect) provides an interesting ratio precision/computation time. This paper provides an original comparison of several models described in literature whose performances have been compared with experiments.
ER  - 

TY  - CONF
TI  - A New Robot Fly Design That is Easier to Fabricate and Capable of Flight and Ground Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4875
EP  - 4882
AU  - Y. M. Chukewad
AU  - A. T. Singh
AU  - J. M. James
AU  - S. B. Fuller
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - feedback
KW  - microrobots
KW  - mobile robots
KW  - stability
KW  - new robot fly design
KW  - insect-sized
KW  - potential advantages
KW  - larger robots
KW  - greater deployment numbers
KW  - previous iterations
KW  - locomotion capabilities
KW  - additionally land
KW  - long legs
KW  - wing-driven ground locomotion
KW  - flapping wings
KW  - landing
KW  - extremely confined spaces
KW  - simplifying fabrication
KW  - feedback-stabilized flights
KW  - Actuators
KW  - Legged locomotion
KW  - Fabrication
KW  - Laminates
KW  - Laser beam cutting
KW  - Solid lasers
DO  - 10.1109/IROS.2018.8593972
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Efforts to engineer insect-sized (~100 mg) robots are motivated by their potential advantages relative to larger robots, such as greater deployment numbers at the same cost. Previous iterations have demonstrated controlled flight, but were limited in terms of locomotion capabilities outside of flight. They also consisted of many parts, making them difficult to fabricate. Here we present a re-design that lowers the center of mass, allowing the robot to additionally land without the need for long legs. Furthermore, we show that the new design allows for wing-driven ground locomotion. This is achieved by varying the speed of downstroke relative to the upstroke of the flapping wings, which also allows for steering. By landing and subsequently moving along the ground, the robot can negotiate extremely confined spaces and underneath obstacles, as well as navigate to precise locations for sensing operations. The new design also drastically reduces the number of parts, simplifying fabrication. We describe the new design in detail and present results demonstrating these capabilities, as well as feedback-stabilized flights.
ER  - 

TY  - CONF
TI  - Milligram-Scale Micro Aerial Vehicle Design for Low-Voltage Operation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Bhushan
AU  - C. J. Tomlin
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - electromagnetic actuators
KW  - microrobots
KW  - milligram-scale microaerial vehicle design
KW  - low-voltage operation
KW  - wing-span
KW  - wing aerial vehicle
KW  - electromagnetic actuator
KW  - low-voltage input
KW  - actuation
KW  - single resonant mechanism
KW  - small-linear-displacement amplifying stages
KW  - ±45° wing strokes
KW  - ±45° wing plane
KW  - energy efficient electromagnetic design
KW  - electromagnetic works
KW  - mass 70.0 mg
KW  - size 3.0 cm
KW  - mass 60.0 mg
KW  - voltage 5.5 V
KW  - frequency 98.0 Hz
KW  - power 250.0 mW
KW  - mass 100.0 mg
KW  - Magnetic resonance
KW  - Actuators
KW  - Springs
KW  - Magnetic separation
KW  - Loss measurement
KW  - Mathematical model
KW  - Laser beams
DO  - 10.1109/IROS.2018.8594515
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a 70mg, 3cm wing-span, flapping wing aerial vehicle capable of generating up to 60mg of lift using an electromagnetic actuator with low-voltage input (≈5.5V). Its design is novel, with the actuation and transmission integrated into a single resonant mechanism, thus not requiring any small-linear-displacement amplifying stages seen in other works. It can produce ±45° wing strokes and ±45° wing plane rotations at 98Hz operation mimicking relevant insects at this size scale. With required input power of only 250mW, it is, to the best of our knowledge, the most energy efficient electromagnetic design at the sub-100mg scale reported to date, and an order of magnitude more efficient than all other electromagnetic works.
ER  - 

TY  - CONF
TI  - Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4889
EP  - 4894
AU  - I. Bouhadda
AU  - A. Mohand-Ousaid
AU  - G. Bourbon
AU  - P. L. Moal
AU  - P. Lutz
AU  - H. Hussein
AU  - Y. Haddab
PY  - 2018
KW  - digital control
KW  - mechanical stability
KW  - micromanipulators
KW  - micromechanical devices
KW  - microrobots
KW  - robot dynamics
KW  - mechanical stability
KW  - complex control strategies
KW  - bistable modules
KW  - mechanism size
KW  - repeatability analysis
KW  - multistable module
KW  - DiMiBot robots
KW  - digital microrobotics
KW  - complex systems
KW  - multistable prototype
KW  - multiple modules
KW  - reproducibility analysis
KW  - miniaturized structure
KW  - discrete stable positions
KW  - Clamps
KW  - Actuators
KW  - Prototypes
KW  - Task analysis
KW  - Switches
KW  - Silicon
KW  - Micromechanical devices
DO  - 10.1109/IROS.2018.8594259
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.
ER  - 

TY  - CONF
TI  - Depth Estimation of Optically Transparent Microrobots Using Convolutional and Recurrent Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4895
EP  - 4900
AU  - M. Grammatikopoulou
AU  - L. Zhang
AU  - G. Yang
PY  - 2018
KW  - closed loop systems
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - neurocontrollers
KW  - pose estimation
KW  - position control
KW  - recurrent neural nets
KW  - regression analysis
KW  - robot vision
KW  - three-dimensional printing
KW  - optically transparent microrobots
KW  - closed-loop control techniques
KW  - depth estimation method
KW  - supervised learning
KW  - depth regression model
KW  - 3D-printed microrobots
KW  - recurrent neural networks
KW  - convolutional neural networks
KW  - optical tweezers setup
KW  - three-dimensional position estimation
KW  - long short-term memory cell
KW  - Three-dimensional displays
KW  - Estimation
KW  - Solid modeling
KW  - Optical imaging
KW  - Lighting
KW  - Data models
KW  - Microscopy
DO  - 10.1109/IROS.2018.8593776
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating the three-dimensional (3D) position of microrobots is necessary in order to develop closed-loop control techniques and to improve the user's 3D perception in the micro-scale. This paper describes a depth estimation method based on supervised learning for optically transparent microrobots of known geometry. The proposed methodology uses Convolutional Neural Networks (CNNs) combined with a Recurrent Network, in particular a Long Short-Term Memory (LSTM) cell for depth regression. The proposed depth regression model is independent of the 3D orientation of the microrobot and is robust to varying illumination levels while it uses learned data-specific features. The model is trained and validated using microscope images and ground truth data generated from 3D-printed microrobots imaged in an Optical Tweezers (OT) setup. The validation results demonstrate that the proposed trained model can reconstruct the depth of the microrobot independently of its 3D orientation with submicron accuracy for the test set.
ER  - 

TY  - CONF
TI  - On Designing 2D Discrete Workspacesto Sort or Classify Polyominoes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Keldenich
AU  - S. Manzoor
AU  - L. Huang
AU  - D. Krupke
AU  - A. Schmidt
AU  - S. P. Fekete
AU  - A. T. Becker
PY  - 2018
KW  - materials handling
KW  - robotic assembly
KW  - polyominoes sorting
KW  - 2D discrete workspace design
KW  - dynamic sensorless classifiers
KW  - orthoconvex polyominoes
KW  - grid-based workspace
KW  - Sorting
KW  - Shape
KW  - Robot sensing systems
KW  - Two dimensional displays
KW  - Machine vision
KW  - Cams
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594150
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper studies the general problem of physically sorting polyominoes according to shape using a 2D, rigid, grid-based workspace. The workspace is designed for sensorless operation, using a fixed set of open-loop force-field inputs that move a polyomino from an inlet port to an outlet port that corresponds to the polyomino's shape, and reset the workspace to classify the next polyomino. This paper proves that static workspaces can classify all orthoconvex polyominoes of width w and height h, and provides a motion sequence and required size of workspace as a function of wand h. By allowing moving polyomino cams that assist in the sorting, we can design dynamic works paces that can sort all polyomi-noes that are “completely filled” using a constant number of force-field inputs. Hardware experiments using magnetic and gravity-based actuation demonstrate these static and dynamic sensorless classifiers at the millimeter scale.
ER  - 

TY  - CONF
TI  - Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Izuhara
AU  - T. Mashimo
PY  - 2018
KW  - closed loop systems
KW  - controllability
KW  - dexterous manipulators
KW  - end effectors
KW  - force control
KW  - linear motors
KW  - microactuators
KW  - microrobots
KW  - ultrasonic motors
KW  - miniature robot finger
KW  - microrobot hands
KW  - microlinear ultrasonic motor prototype
KW  - closed-loop six-bar-linkage mechanism
KW  - microfabrication
KW  - Acoustics
KW  - Stators
KW  - Robots
KW  - Couplings
KW  - Actuators
KW  - Electrodes
KW  - Vibrations
DO  - 10.1109/IROS.2018.8594098
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.
ER  - 

TY  - CONF
TI  - Resistive Pulse Study of Liposome Stability: Towards Precision and Efficient Drug Delivery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4914
EP  - 4919
AU  - Y. Lin
AU  - X. Liu
AU  - T. Arai
PY  - 2018
KW  - biological tissues
KW  - biomedical materials
KW  - biomembranes
KW  - cancer
KW  - cellular biophysics
KW  - drug delivery systems
KW  - lipid bilayers
KW  - molecular biophysics
KW  - nanofabrication
KW  - nanomedicine
KW  - nanoparticles
KW  - scanning electron microscopy
KW  - resistive pulse study
KW  - liposome stability
KW  - drug delivery vehicle
KW  - resistive pulse method
KW  - liposome fusion
KW  - cancerous tissue arrangement
KW  - organic nanoparticle measurement
KW  - 3D manipulator positioning
KW  - cellular in-vivo measurement
KW  - environmental SEM chamber
KW  - size 50.0 nm
KW  - size 100.0 nm
KW  - Lipidomics
KW  - Drug delivery
KW  - Manipulators
KW  - Stability analysis
KW  - Size measurement
KW  - Three-dimensional displays
KW  - Glass
KW  - drug delivery vehicle
KW  - liposome
KW  - 3D manipulator
KW  - resistive pulse method
KW  - size measurement
KW  - sub 100nm Nano pores
DO  - 10.1109/IROS.2018.8593731
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, the authors report the investigation of liposomes' stability as a drug delivery vehicle, using the method of resistive pulse method. The main objects of interest are the 50nm diameter liposomes, while the 100nm diameter liposomes are widely used for its stability. However, certain drug delivery scenarios arise, like tighter cancerous tissue arrangement and different circulation time requirement, which dictates the necessity of sub-100nm diameter vesicles. The size measurements upon freshly fabricated liposomes are performed frequently on increasing time interval. The results exhibit a trend of size increasing, suggesting the existence of liposome fusion. The possible models of fusion are proposed and discussed. This work demonstrates the localized organic nanoparticle measurement with fine dual 3D manipulator positioning, which paves the way for the possible cellular in-vivo measurement within an environmental SEM chamber.
ER  - 

TY  - CONF
TI  - Force/Velocity Manipulability Analysis for 3D Continuum Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4920
EP  - 4926
AU  - M. Khadem
AU  - L. Da Cruz
AU  - C. Bergeles
PY  - 2018
KW  - dexterous manipulators
KW  - mobile robots
KW  - path planning
KW  - continuum robots
KW  - continuum manipulators
KW  - effective manipulation
KW  - rigid robots
KW  - manipulability indices
KW  - unified force-velocity manipulability
KW  - concentric-tube robot
KW  - manipulability measurement
KW  - force-velocity manipulability analysis
KW  - Robot kinematics
KW  - Indexes
KW  - Force
KW  - Manipulators
KW  - Jacobian matrices
KW  - Ellipsoids
DO  - 10.1109/IROS.2018.8593874
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The enhanced dexterity and manipulability offered by continuum manipulators makes them the robots of choice for complex procedures inside the human body. However, without tailored analytical tools to evaluate their manipulability, many capabilities of continuum robots such as safe and effective manipulation will remain largely inaccessible. This paper presents a quantifiable measure for analysing force/velocity manipulability of continuum robots. We expand classical measures of manipulability for rigid robots to introduce three types of manipulability indices to continuum robots, namely, velocity, compliance, and unified force-velocity manipulability. We provide a specific case study using the proposed method to analyse the force/velocity manipulability for a concentric-tube robot. We investigate the application of the manipulability measures to compare performance of continuum robots in terms of compliance and force-velocity manipulability. The proposed manipulability measures enable future research on design and optimal path planning for continuum robots.
ER  - 

TY  - CONF
TI  - Analysis of Dynamic Response of an MRI-Guided Magnetically-Actuated Steerable Catheter System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - E. Erdem Tuna
AU  - T. Liu
AU  - R. C. Jackson
AU  - N. Lombard Poirot
AU  - M. Russell
AU  - M. C. Çavuşoğlu
PY  - 2018
KW  - biomedical MRI
KW  - catheters
KW  - closed loop systems
KW  - control nonlinearities
KW  - dynamic response
KW  - frequency response
KW  - linearisation techniques
KW  - magnetic actuators
KW  - medical image processing
KW  - medical robotics
KW  - open loop systems
KW  - robot vision
KW  - MRI-guided magnetically-actuated steerable catheter system
KW  - free-space open-loop dynamic response analysis
KW  - magnetically-actuated steerable intra-vascular catheter system
KW  - current carrying microcoils
KW  - magnetic torques
KW  - system nonlinearity
KW  - pendulum model
KW  - approximate input-output linearization
KW  - black-box system identification approach
KW  - frequency response analysis
KW  - camera system
KW  - free-space trajectories
KW  - robotic catheter
KW  - MRI guidance
KW  - magnetic resonance imaging scanner
KW  - free-space closed-loop control
KW  - Nyquist frequency
KW  - Catheters
KW  - Coils
KW  - Magnetic resonance imaging
KW  - Torque
KW  - Robots
KW  - Chirp
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594308
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a free-space open-loop dynamic response analysis for an MRI -guided magnetically-actuated steerable intra-vascular catheter system. The catheter tip is embedded with a set of current carrying micro-coils. The catheter is directly actuated via the magnetic torques generated on these coils by the magnetic field of the magnetic resonance imaging (MRI)scanner. The relationship between the input current commands and catheter tip deflection angle presents an inherent nonlinearity in the proposed catheter system. The system nonlinearity is analyzed by utilizing a pendulum model. The pendulum model is used to describe the system nonlinearity and to perform an approximate input-output linearization. Then, a black-box system identification approach is performed for frequency response analysis of the linearized dynamics. The optimal estimated model is reduced by observing the modes and considering the Nyquist frequency of the camera system that is used to track the catheter motion. The reduced model is experimentally validated with 3D open-loop Cartesian free-space trajectories. This study paves the way for effective and accurate free-space closed-loop control of the robotic catheter with real-time feedback from MRI guidance in subsequent research.
ER  - 

TY  - CONF
TI  - Development and validation of MRI compatible pediatric surgical robot with modular tooling for bone biopsy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4935
EP  - 4941
AU  - A. N. Alvara
AU  - T. Looi
AU  - R. Saab
AU  - A. Shorter
AU  - A. Goldenberg
AU  - J. Drake
PY  - 2018
KW  - biomedical MRI
KW  - bone
KW  - medical robotics
KW  - paediatrics
KW  - phantoms
KW  - surgery
KW  - tumours
KW  - PSR-BBT
KW  - cortical bone phantoms
KW  - cancellous bone phantoms
KW  - MRI testing
KW  - T1-FFE
KW  - T2-FFE
KW  - MR-guided robotic surgery
KW  - modular Tooling
KW  - magnetic resonance imaging
KW  - MR-compatible tools
KW  - surgical accuracy
KW  - Pediatric Surgery Robot platform
KW  - modular tool interface
KW  - Bone Biopsy Tooling
KW  - modified titanium bone biopsy needle
KW  - joint Cartesian level control
KW  - MRI compatible pediatric surgical robot
KW  - lesion
KW  - tumor
KW  - 5-DOF robot
KW  - Philips Achieva 3.0T MRI bore
KW  - surgical preplanning
KW  - control interface
KW  - Cartesian level control
KW  - axial force
KW  - signal-to-noise ratio variation
KW  - geometric distortion
KW  - magnetic flux density 3 T
KW  - Biopsy
KW  - Bones
KW  - Magnetic resonance imaging
KW  - Robots
KW  - Surgery
KW  - Signal to noise ratio
KW  - Tools
DO  - 10.1109/IROS.2018.8593523
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In clinical practice, magnetic resonance imaging (MRI) is used to locate a lesion/tumor for bone biopsy in children. However, there is a lack of MR-compatible tools that can be used simultaneously during imaging and biopsy while maintaining surgical accuracy and safety. The Pediatric Surgery Robot (PSR) platform is a 5-DOF robot with a modular tool interface. For the case of bone biopsy, a Bone Biopsy Tooling (BBT) is attached. It is designed to fit within a Philips Achieva 3.0T MRI bore and carry a modified titanium bone biopsy needle. A surgical pre-planning and control interface has been developed for joint and Cartesian level control. The PSR-BBT has demonstrated 1.65 +/- 1.77 mm accuracy in Cartesian control in free space. The PSR-BBT can generate 12.46 +/- 0.32 N of axial force while drilling at a speed of 30 rpm, which is sufficient for cortical and cancellous bone phantoms. Under MRI testing (T1-FFE, T1-SE, T2-FFE and T2-TSE scans), the system demonstrated less than 33% signal-to-noise ratio variation while drilling and a 0.46% geometric distortion while powered on without significantly impacting MRI guidance in situ. These results show that the PSR-BBT can allow the user to simultaneously image and perform the biopsy and presents the PSR as a viable platform for MR-guided robotic surgery.
ER  - 

TY  - CONF
TI  - Safe Motion Planning for Steerable Needles Using Cost Maps Automatically Extracted from Pulmonary Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4942
EP  - 4949
AU  - M. Fu
AU  - A. Kuntz
AU  - R. J. Webster
AU  - R. Alterovitz
PY  - 2018
KW  - blood vessels
KW  - cancer
KW  - computerised tomography
KW  - feature extraction
KW  - lung
KW  - medical image processing
KW  - needles
KW  - lung nodule biopsy
KW  - steerable needles
KW  - bronchoscope
KW  - bronchial tubes
KW  - blood vessels
KW  - safe motion planning
KW  - motion planning approach
KW  - lung pleura
KW  - pulmonary CT images
KW  - cost map
KW  - lung periphery
KW  - lung nodules
KW  - needle biopsy
KW  - lung cancer
KW  - Needles
KW  - Lung
KW  - Biomedical imaging
KW  - Planning
KW  - Biopsy
KW  - Computed tomography
KW  - Blood vessels
DO  - 10.1109/IROS.2018.8593407
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Lung cancer is the deadliest form of cancer, and early diagnosis is critical to favorable survival rates. Definitive diagnosis of lung cancer typically requires needle biopsy. Common lung nodule biopsy approaches either carry significant risk or are incapable of accessing large regions of the lung, such as in the periphery. Deploying a steerable needle from a bronchoscope and steering through the lung allows for safe biopsy while improving the accessibility of lung nodules in the lung periphery. In this work, we present a method for extracting a cost map automatically from pulmonary CT images, and utilizing the cost map to efficiently plan safe motions for a steerable needle through the lung. The cost map encodes obstacles that should be avoided, such as the lung pleura, bronchial tubes, and large blood vessels, and additionally formulates a cost for the rest of the lung which corresponds to an approximate likelihood that a blood vessel exists at each location in the anatomy. We then present a motion planning approach that utilizes the cost map to generate paths that minimize accumulated cost while safely reaching a goal location in the lung.
ER  - 

TY  - CONF
TI  - Trigonometric Ratio-Based Remote Center of Motion Mechanism for Bone Drilling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4958
EP  - 4963
AU  - S. Shim
AU  - S. Lee
AU  - D. Ji
AU  - H. Choi
AU  - J. Hong
PY  - 2018
KW  - actuators
KW  - bone
KW  - medical robotics
KW  - motion control
KW  - orthopaedics
KW  - robot vision
KW  - surgery
KW  - bone drilling robotic systems
KW  - drill alignment
KW  - RCM mechanism
KW  - remote center of motion mechanism
KW  - surgical procedures
KW  - linear actuators
KW  - gearless arc-guide
KW  - vision-guided navigation system
KW  - orientation guidance
KW  - trigonometric ratio
KW  - Bones
KW  - Robots
KW  - Surgery
KW  - Actuators
KW  - Force
KW  - Computed tomography
KW  - Task analysis
KW  - Remote center of motion mechanism
KW  - surgical robotics
KW  - vision-guided navigation
KW  - bone drilling
DO  - 10.1109/IROS.2018.8594069
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The remote center of motion (RCM) mechanism is a prominent candidate to aid bone drilling. The surgeon can simply place a drill with the RCM mechanism near the entry point to provide drill alignment with the target. Using this assistive mechanism for bone drilling improves drilling accuracy and reduces the complexity of bone drilling robotic systems. However, because most RCM mechanisms have been developed for laparoscopic surgery or needle insertion into soft tissue, they lack rigidity and are unsuitable for bone drilling. One of the most difficult and important surgical procedures in bone drilling is maintaining as well as guiding the orientation of the drill with respect to the target. This paper proposes an improved RCM mechanism in which a pair of linear actuators and a gearless arc-guide are employed to achieve high rigidity and resolution, which enable bone drilling. A vision-guided navigation system is also integrated into the proposed system to automatically guide the orientation. To verify that the proposed RCM mechanism has sufficient rigidity and targeting accuracy, a series of experiments was performed. The results obtained confirm that the proposed mechanism can maintain its tilting angle under up to 50 N, with a targeting error of approximately 0.28mm.
ER  - 

TY  - CONF
TI  - Rolling-Joint Design Optimization for Tendon Driven Snake-Like Surgical Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4964
EP  - 4971
AU  - P. Berthet-Rayne
AU  - K. Leibrandt
AU  - K. Kim
AU  - C. A. Seneci
AU  - J. Shang
AU  - G. Yang
PY  - 2018
KW  - manipulators
KW  - medical robotics
KW  - surgery
KW  - tendon driven snake-like surgical robots
KW  - intra-luminal procedures
KW  - flexibility
KW  - serial rolling-joints
KW  - base architecture
KW  - joint angle range
KW  - tendons
KW  - rolling-joint design optimization
KW  - optimized joints
KW  - Tendons
KW  - Tools
KW  - Navigation
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593517
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of snake-like robots for surgery is a popular choice for intra-luminal procedures. In practice, the requirements for strength, flexibility and accuracy are difficult to be satisfied simultaneously. This paper presents a computational approach for optimizing the design of a snake-like robot using serial rolling-joints and tendons as the base architecture. The method optimizes the design in terms of joint angle range and tendon placement to prevent the tendons and joints from colliding during bending motion. The resulting optimized joints were manufactured using 3D printing. The robot was characterized in terms of workspace, dexterity, precision and manipulation forces. The results show a repeatability as low as 0.9mm and manipulation forces of up to 5.6N.
ER  - 

TY  - CONF
TI  - Enhancing the Command-Following Bandwidth for Transparent Bilateral Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4972
EP  - 4979
AU  - H. Singh
AU  - A. Jafari
AU  - A. Peer
AU  - J. Ryu
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - telerobotics
KW  - command-following bandwidth
KW  - transparent bilateral teleoperation
KW  - slave robot motion controller
KW  - high motion controller gain
KW  - human user
KW  - successive stiffness increment approach
KW  - SSI approach
KW  - bilateral teleoperation controller
KW  - Pressing
KW  - Force
KW  - Bandwidth
KW  - Haptic interfaces
KW  - Trajectory
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593866
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Enhancing transparency of a teleoperation system by increasing the command-following bandwidth has not received lots of attention so far. This is considered a challenging task since in a teleoperation system the command-following bandwidth of the slave robot motion controller cannot be increased with a conventional motion controller as the desired trajectory is instantaneously commanded by the human user and thus, cannot be considered to be given in a pre-computed, smooth second order derivative form. We propose a method to increase the command-following bandwidth by extending the previously introduced Successive Stiffness Increment (SSI) approach to bilateral teleoperation. The approach allows realizing a very high motion controller gain, which cannot be realized with a conventional bilateral teleoperation controller as confirmed by experimental results.
ER  - 

TY  - CONF
TI  - Transparency-Optimal Passivity Layer Design for Time-Domain Control of Multi-DoF Haptic-Enabled Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4988
EP  - 4994
AU  - O. A. Moreno Franco
AU  - J. Bimbo
AU  - C. Pacchierotti
AU  - D. Prattichizzo
AU  - D. Barcelli
AU  - G. Bianchini
PY  - 2018
KW  - haptic interfaces
KW  - optimisation
KW  - telerobotics
KW  - time-domain scheme
KW  - optimization problem
KW  - optimization-based passivity control algorithm
KW  - virtual teleoperated environment
KW  - real-time implementation
KW  - optimal transparency
KW  - energy-bounding control
KW  - haptic-enabled bilateral teleoperation systems
KW  - multiDoF
KW  - time-domain control
KW  - transparency-optimal passivity layer design
KW  - Force
KW  - Task analysis
KW  - Computer architecture
KW  - Robots
KW  - Indexes
KW  - Time-domain analysis
KW  - Haptic interfaces
DO  - 10.1109/IROS.2018.8593443
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel optimization-based passivity control algorithm for haptic-enabled bilateral teleoperation systems involving multiple degrees of freedom. In particular, in the context of energy-bounding control, the contribution focuses on the implementation of a passivity layer for an existing time-domain scheme, ensuring optimal transparency of the interaction along subsets of the environment space which are preponderant for the given task, while preserving the energy bounds required for passivity. The involved optimization problem is convex and amenable to real-time implementation. The effectiveness of the proposed design is validated via an experiment performed on a virtual teleoperated environment.
ER  - 

TY  - CONF
TI  - Development and Evaluation of an Intuitive Flexible Interface for Teleoperating Soft Growing Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4995
EP  - 5002
AU  - H. El-Hussieny
AU  - U. Mehmood
AU  - Z. Mehdi
AU  - S. Jeong
AU  - M. Usman
AU  - E. W. Hawkes
AU  - A. M. Okarnura
AU  - J. Ryu
PY  - 2018
KW  - bending
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - telerobotics
KW  - user interfaces
KW  - intuitive flexible interface
KW  - teleoperating soft growing robots
KW  - robotic systems design
KW  - tip-extending
KW  - navigation
KW  - disaster scenarios
KW  - intuitive human control
KW  - intuitively map human bending
KW  - shape information
KW  - command mappings
KW  - developed interface
KW  - commercially available interfaces
KW  - virtual task scenarios
KW  - shape mapping
KW  - vine robot rolls
KW  - Shape
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Kinematics
KW  - Current measurement
DO  - 10.1109/IROS.2018.8593896
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobility by growth is a new paradigm in robotic systems design and their applications in the real world. Soft, tip-extending, or “growing”, robots have potential applications including inspection and navigation in disaster scenarios. However, due to their growing capability, such robots create unique challenges for intuitive human control. In this paper, a new flexible interface is proposed to intuitively map human bending commands into movements of the growing robot while providing shape information of the robot in order to improve situational awareness. Several command mappings are proposed, and a subjective study was conducted to assess the intuitiveness of the developed interface and mappings compared with other commercially available interfaces. The interfaces were evaluated using four metrics in two virtual task scenarios. The proposed interface with shape mapping performed better than the other interfaces, especially when the vine robot rolls over unintentionally during complex tasks.
ER  - 

TY  - CONF
TI  - Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - D. Krupke
AU  - F. Steinicke
AU  - P. Lubos
AU  - Y. Jonetzko
AU  - M. Görner
AU  - J. Zhang
PY  - 2018
KW  - control engineering computing
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - intelligent robots
KW  - mobile robots
KW  - multi-robot systems
KW  - service robots
KW  - user interfaces
KW  - virtual reality
KW  - multimodal heading
KW  - pointing gestures
KW  - human operator
KW  - co-located robots
KW  - head-mounted-display
KW  - HRI situations
KW  - enormous potential
KW  - MR human-robot collaboration system
KW  - industrial robot arm
KW  - multimodal HRI techniques
KW  - heading-based interaction techniques
KW  - multirobot system
KW  - current robot programming
KW  - human-robot interaction scenarios
KW  - virtual information
KW  - pick-and-place scenarios
KW  - potential robot actions
KW  - co-located mixed reality human-robot interaction
KW  - Microsoft HoloLens
KW  - Virtual reality
KW  - Service robots
KW  - Task analysis
KW  - Collaboration
KW  - Visualization
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594043
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.
ER  - 

TY  - CONF
TI  - Humanoid Teleoperation Using Task-Relevant Haptic Feedback
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5010
EP  - 5017
AU  - F. Abi-Farrajl
AU  - B. Henze
AU  - A. Werner
AU  - M. Panzirsch
AU  - C. Ott
AU  - M. A. Roa
PY  - 2018
KW  - compliance control
KW  - feedback
KW  - haptic interfaces
KW  - humanoid robots
KW  - stability
KW  - telerobotics
KW  - torque control
KW  - operating tools
KW  - space station
KW  - key technology
KW  - robotic teleoperation
KW  - task-relevant haptic feedback
KW  - humanoid robot TORO
KW  - torque-controlled humanoid robot
KW  - null-space autonomous controller
KW  - robot stability
KW  - haptic cues
KW  - humanoid teleoperation
KW  - task-relevant haptic interface
KW  - disaster scenarios
KW  - Humanoid robots
KW  - Task analysis
KW  - End effectors
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8593521
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic teleoperation is a key technology for a wide variety of fields. Teleoperating a humanoid in particular is essential as it allows the user to act remotely on an interface designed especially for humans, e.g., in a space station, or operating tools and machinery in disaster scenarios. This paper presents a `task-relevant' haptic interface for humanoid teleoperation, which bridges the gap between the task at hand and the balance of the robot. The operator is given command over the humanoid's hands and is informed through haptic cues about the impact of her/his potential actions on the robot' stability. Moreover, a null-space autonomous controller acts in the operator's null-space to provide her/him with a wider workspace and help in the successful execution of the task. The architecture is designed to top an existing compliance controller for a torque-controlled humanoid robot. Experiments on the humanoid robot TORO are reported to demonstrate the feasibility and effectiveness of the approach.
ER  - 

TY  - CONF
TI  - ROS Reality: A Virtual Reality Framework Using Consumer-Grade Hardware for ROS-Enabled Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - D. Whitney
AU  - E. Rosen
AU  - D. Ullman
AU  - E. Phillips
AU  - S. Tellex
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - Internet
KW  - operating systems (computers)
KW  - telerobotics
KW  - virtual reality
KW  - direct kinesthetic handling
KW  - robot operating system
KW  - ROS reality
KW  - virtual reality systems
KW  - virtual reality framework
KW  - VR teleoperation package
KW  - robotic frameworks
KW  - consumer-grade VR systems
KW  - consumer-grade hardware
KW  - robotic teleoperation tasks
KW  - Baxter robot
KW  - Unity-compatible VR headset
KW  - ROS-enabled robot
KW  - Robots
KW  - Task analysis
KW  - Solid modeling
KW  - Virtual reality
KW  - Hardware
KW  - Two dimensional displays
KW  - Engines
DO  - 10.1109/IROS.2018.8593513
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Virtual reality (VR)systems let users intuitively interact with 3D environments and have been used extensively for robotic teleoperation tasks. While more immersive than their 2D counterparts, early VR systems were expensive and required specialized hardware. Fortunately, there has been a recent proliferation of consumer-grade VR systems at affordable price points. These systems are inexpensive, relatively portable, and can be integrated into existing robotic frameworks. Our group has designed a VR teleoperation package for the Robot Operating System (ROS), ROS Reality, that can be easily integrated into such frameworks. ROS Reality is an open-source, over-the-Internet teleoperation interface between any ROS-enabled robot and any Unity-compatible VR headset. We completed a pilot study to test the efficacy of our system, with expert human users controlling a Baxter robot via ROS Reality to complete 24 dexterous manipulation tasks, compared to the same users controlling the robot via direct kinesthetic handling. This study provides insight into the feasibility of robotic teleoperation tasks in VR with current consumer-grade resources and exposes issues that need to be addressed in these VR systems. In addition, this paper presents a description of ROS Reality, its components, and architecture. We hope this system will be adopted by other research groups to allow for easy integration of VR teleoperated robots into future experiments.
ER  - 

TY  - CONF
TI  - User Evaluation of a Haptic-Enabled Shared-Control Approach for Robotic Telemanipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Abi-Farraj
AU  - C. Pacchierotti
AU  - P. R. Giordano
PY  - 2018
KW  - haptic interfaces
KW  - manipulators
KW  - telerobotics
KW  - grounded haptic interface
KW  - remaining null-space directions
KW  - human operator
KW  - slave manipulator degrees
KW  - effective approaches
KW  - nuclear sites
KW  - estimated cost
KW  - currently employed systems
KW  - handling radioactive waste
KW  - nuclear decommissioning sites
KW  - robotic telemanipulators
KW  - robotic telemanipulation
KW  - user evaluation
KW  - remote telemanipulation tasks
KW  - currently-available teleoperation systems
KW  - shared-control approach
KW  - 6-DOF teleoperation approach
KW  - shared-control architecture
KW  - robotic system
KW  - haptic cues
KW  - Task analysis
KW  - Manipulators
KW  - Grippers
KW  - Force
KW  - Grasping
DO  - 10.1109/IROS.2018.8594030
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic telemanipulators are already widely used in nuclear decommissioning sites for handling radioactive waste. However, currently employed systems are still extremely primitive, making the handling of these materials prohibitively slow and ineffective. As the estimated cost for the decommissioning and clean-up of nuclear sites keeps rising, it is clear that one would need faster and more effective approaches. Towards this goal, in this paper we present the user evaluation of a recently proposed haptic-enabled shared-control architecture for telemanipulation. An autonomous algorithm regulates a subset of the slave manipulator degrees of freedom (DoF) in order to help the human operator in grasping an object of interest. The human operator can then steer the manipulator along the remaining null-space directions with respect to the main task by acting on a grounded haptic interface. The haptic cues provided to the operator are designed in order to inform about the feasibility of the user's commands with respect to possible constraints of the robotic system. In this paper we compared this shared-control architecture against a classical 6-DOF teleoperation approach in a real scenario by running experiments with 10 subjects. The results clearly show that the proposed shared-control approach is a viable and effective solution for improving currently-available teleoperation systems in remote telemanipulation tasks.
ER  - 

TY  - CONF
TI  - Towards an Automatic Spasticity Assessment by Means of Collaborative Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Hernandez
AU  - E. Daniel Oña
AU  - J. M. Garcia-Haro
AU  - A. Jardon
AU  - C. Balaguer
PY  - 2018
KW  - biomechanics
KW  - brain
KW  - medical disorders
KW  - medical robotics
KW  - muscle
KW  - neurophysiology
KW  - patient rehabilitation
KW  - shear modulus
KW  - viscoelasticity
KW  - exaggerated stretch reflexes
KW  - upper motor neuron syndrome
KW  - collaborative robots
KW  - noninvasive biomechanical modelling
KW  - automatic spasticity assessment
KW  - muscle control disorder
KW  - muscle tone
KW  - upper limb joints
KW  - patient rehabilitation
KW  - 7-DOF Rosen kinematics
KW  - nonlinear state
KW  - Hills force-velocity relation
KW  - rigidity
KW  - viscoelasticity
KW  - extensibility
KW  - thixotropy
KW  - passive movement response
KW  - Collaboration
KW  - Biological system modeling
KW  - Muscles
KW  - Brain modeling
KW  - Biomechanics
KW  - Intelligent robots
KW  - Collaborative robotics
KW  - Movement capture
KW  - Rehabilitation
KW  - Spasticity
KW  - Upper limb modelling
DO  - 10.1109/IROS.2018.8594158
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Summary form only given. Robotics can play a significant role in the rehabilitation of patients with spasticity by improving their early diagnosis and reducing the costs associated with care. Spasticity is a muscle control disorder characterized by an increase in muscle tone with exaggerated stretch reflexes, as one component of the upper motor neuron syndrome. Furthermore, spasticity is present in other pathologies, such as cerebral palsy, spina bifida, brain stroke among others. This video shows the ongoing research on developing a platform for the modelling and the assessment of spasticity using collaborative robots as clinical tool. Our aim is to develop methods for non-invasive biomechanical modelling of upper limbs joints using 7-DOF Rosen Kinematics [1], mixed with a non-linear state of Hills force-velocity relation [2], improved by introducing new parameters such as rigidity, viscoelasticity, extensibility and thixotropy. After a learning phase performed by the therapist, the robot replicates the trajectories required to perform the assessment. The video also describes the detailed analysis of passive movement response (force/torque and position/velocity)of the limb. These parameters will be used to determine the degree of spasticity of patients in a fast and objective manner, while simultaneously developing new clinical scales, such as a modified version of Ashworth [3].
ER  - 

TY  - CONF
TI  - Research on Carved Turns of a Skiing Humanoid Robot on a Real-World Slope
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Han
AU  - D. Yoon
AU  - H. Song
AU  - B. Kim
AU  - Y. Kim
AU  - C. Park
AU  - Y. Eum
AU  - J. Moon
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - sport
KW  - South Korea
KW  - deep learning method
KW  - motion pattern
KW  - IMU sensor
KW  - skiing humanoid Robot
KW  - realworld slope
KW  - carved turn
KW  - skiing robot DIANA
KW  - Alpine slalom skiing competition
KW  - PyeongChang 2018 Winter Olympic Games
KW  - robot sports events
KW  - Humanoid robots
KW  - Sports
KW  - Robot sensing systems
KW  - Moon
KW  - Service robots
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593796
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humans play sports to improve their athletic ability. The robot, especially humanoid robot, is also able to improve its athletic performances, such as reaction speed and balancing, through robot sports. Therefore, robots have been developed through performing various robot sports events such as robot soccer, robot marathon, robot fight and so on. In this reason, The Ski Robot Challenge was held in South Korea in commemoration of the PyeongChang 2018 Winter Olympic Games. The event was an Alpine slalom skiing competition in the almost same rules to human's but on a relatively short course (80m). To participate in this ski tournament, the skiing robot DIANA has been developed. In this video, the skiing robot technologies were introduced. At first, she must be able to recognize the flags. The deep learning method was used to recognize them. Secondly, she had a motion pattern to perform the carving turn, the most difficult and fastest skiing technique. In order to improve the stability, she compensated her motion to follow reference COP, based on the measured F/T sensor data. In addition, IMU sensor was used to remove instantaneous disturbance. Using these methods, the humanoid robot, DIANA, that can perform the carved turn on a realworld slope was successfully developed.
ER  - 

TY  - CONF
TI  - Waiter Robot Application: Balance Control for Transporting Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. m. Garcia-Haro
AU  - E. Daniel Oña
AU  - S. Martinez
AU  - J. Hernandez-Vicen
AU  - C. Balaguer
PY  - 2018
KW  - force control
KW  - humanoid robots
KW  - manipulators
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - position control
KW  - robot vision
KW  - stability
KW  - waiter robot application
KW  - dynamic balance control
KW  - simplified mathematical model
KW  - robot arm
KW  - manipulation control system
KW  - nongrasping tasks
KW  - ZMP criterion
KW  - humanoid robot TEO
KW  - zero moment point stability criterion
KW  - force-torque sensors
KW  - computer vision
KW  - center of mass
KW  - CoM
KW  - Humanoid robots
KW  - Stability criteria
KW  - Sensors
KW  - Mathematical model
KW  - Control systems
KW  - Balance
KW  - Manipulation
KW  - Force-Torque
KW  - Vision
KW  - Humanoid
DO  - 10.1109/IROS.2018.8593760
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic balance control for humanoid robots encounters difficulties such as stability, speed, and smoothness. In most of the previous studies, joints act as controller of the Center of Mass (CoM)supported using a simplified mathematical model. Then, the stability of the motion is guaranteed using the Zero Moment Point (ZMP)stability criterion. In this video, a humanoid robot [1] will carry a tray secured to the wrist and the objects to be transported will be placed on the tray. This condition implies that the object is not grasped and therefore, the robot arm will be the only point of support of the object through the tray. Thus, the manipulation control system must be able to detect the stability of the object and act according to the different perturbations applied to it. A 3D balance control system for non-grasping tasks is presented and it is based on the ZMP criterion and 3D inverted pendulum equations. The perception system required is based on the use of Force-Torque sensors [2], computer vision [3], and their integration. The effectiveness of the proposed approach is being investigated with the humanoid robot TEO.
ER  - 

TY  - CONF
TI  - Visual-Inertial Teach and Repeat Powered by Google Tango
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Fehr
AU  - T. Schneider
AU  - R. Siegwart
PY  - 2018
KW  - automatic optical inspection
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - control engineering computing
KW  - Global Positioning System
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - trajectory control
KW  - human operator
KW  - visual inspection task
KW  - autonomous aerial vehicle
KW  - Google Tango visual-inertial mapping framework
KW  - pose estimates
KW  - GPS-denied environments
KW  - inspection points
KW  - feature-based localization map
KW  - industrial facilities
KW  - multicopters
KW  - visual-inertial teach
KW  - hedge maze
KW  - Robots
KW  - Inspection
KW  - Task analysis
KW  - Collision avoidance
KW  - Google
KW  - Autonomous systems
KW  - Visualization
DO  - 10.1109/IROS.2018.8593416
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.
ER  - 

TY  - CONF
TI  - Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 1
AU  - L. Briñón-Arranz
AU  - M. Muschinowski
AU  - J. Dumon
AU  - N. Marchand
PY  - 2018
KW  - aircraft control
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - tracking
KW  - trajectory control
KW  - multirobot systems
KW  - geometric parameters
KW  - distributed algorithm
KW  - tracking controller
KW  - robots position
KW  - distributed trajectory generator
KW  - mini aerial vehicles
KW  - distributed reconfigurable formation generator
KW  - Generators
KW  - Intelligent robots
KW  - Trajectory
KW  - Multi-robot systems
KW  - Distributed algorithms
DO  - 10.1109/IROS.2018.8593511
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.
ER  - 

TY  - CONF
TI  - Autonomous Underwater Vehicle Navigation in Structured Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5039
EP  - 5039
AU  - D. Park
AU  - Y. Lee
AU  - K. Jung
AU  - H. Kang
AU  - H. Ki
AU  - J. Lee
AU  - Y. Choi
AU  - J. Li
AU  - H. Myung
AU  - H. Choi
AU  - J. Suh
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cameras
KW  - geophysical image processing
KW  - image sensors
KW  - marine navigation
KW  - oceanographic techniques
KW  - position measurement
KW  - sensor fusion
KW  - sonar
KW  - AUV navigation system
KW  - autonomous underwater vehicle navigation system
KW  - signal uncertainties
KW  - signal distortion
KW  - cameras
KW  - position estimation
KW  - image sonar aided integrated navigation system
KW  - active vision markers
KW  - inherent drift of dead-reckoning velocities
KW  - jacket structure
KW  - artificial landmarks
KW  - sensor-fusion-based localization scheme
KW  - integrated navigation system
KW  - Sonar navigation
KW  - Oceans
KW  - Sonar
KW  - Autonomous robots
KW  - Industries
KW  - Intelligent robots
KW  - Autonomous underwater vehicles
DO  - 10.1109/IROS.2018.8594429
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With the increase in developments in underwater infrastructure, the demand for development of autonomous vehicle navigation system in structured environment is also increased. However, the localization in a structured environment is a challenging problem due to signal uncertainties and distortions. In order to overcome these problems, we propose the camera and sonar aided integrated navigation system. In the proposed sensor-fusion-based localization scheme, the AUV estimates its own position continuously using artificial landmarks. The artificial landmarks for image sonar is deployed along the path to guide the AUV to the structure. The active vision markers are installed on the jacket structure, and they function as both landmarks and waypoints. This approach prevents the inherent drift of dead-reckoning velocities and collision with structures. The proposed approach was verified through a real sea experiment. The AUV conducted the full autonomous navigation from the dock to the jacket structure, and then returned to the dock without collision or significant localization error. These results show the feasibility of full autonomous navigation in a structured environment.
ER  - 

TY  - CONF
TI  - Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5040
EP  - 5040
AU  - C. Kanellakis
AU  - S. S. Mansouri
AU  - E. Fresk
AU  - D. Kominiak
AU  - G. Nikolakopoulos
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - image reconstruction
KW  - inspection
KW  - Kalman filters
KW  - mobile robots
KW  - robot vision
KW  - wind turbines
KW  - UAVs
KW  - Aerial inspection
KW  - aerial tool
KW  - autonomous cooperative coverage
KW  - multiple Unmanned Aerial Vehicles
KW  - onboard computer
KW  - sensory system
KW  - autonomous navigation
KW  - localization system
KW  - Ultra Wideband
KW  - aerial team
KW  - realistic wind turbine inspection experiments
KW  - dense 3D reconstruction
KW  - inspected structures
KW  - state Kalman filter
KW  - 3D infrastructure
KW  - large scale aging infrastructure
KW  - Inspection
KW  - Three-dimensional displays
KW  - Tools
KW  - Intelligent robots
KW  - Aging
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593996
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.
ER  - 

TY  - CONF
TI  - Hear the Egg - Demonstrating Robotic Interactive Auditory Perception
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5041
EP  - 5041
AU  - E. Strahl
AU  - M. Kerzel
AU  - M. Eppe
AU  - S. Griffiths
AU  - S. Wermter
PY  - 2018
KW  - audio signal processing
KW  - hearing
KW  - humanoid robots
KW  - image classification
KW  - interactive video
KW  - mobile robots
KW  - robot vision
KW  - video retrieval
KW  - neuro inspired companion
KW  - plastic capsules
KW  - classic TV game show
KW  - material classification task
KW  - NICO
KW  - humanoid robot
KW  - interactive auditory perception approach
KW  - egg-demonstrating robotic interactive auditory perception
KW  - capsules content
KW  - Humanoid robots
KW  - Mel frequency cepstral coefficient
KW  - Intelligent robots
KW  - Plastics
KW  - Recurrent neural networks
KW  - Gold
DO  - 10.1109/IROS.2018.8593959
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an illustrative example of an interactive auditory perception approach performed by a humanoid robot called NICO, the Neuro Inspired COmpanion [1]. The video demonstrates a material classification task in the style of a classic TV game show. NICO and another candidate are supposed to determine the content of small plastic capsules that are visually indistinguishable. Shaking the capsules produces audio signals that range from rattling stones, over tinkling coins to swooshing sand. NICO can perceive and analyze these sounds to determine the material of the capsules content.
ER  - 

TY  - CONF
TI  - Computing Cross-Sections of the Workspace of Suspended Cable-Driven Parallel Robot with Sagging Cables Having Tension Limitations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5042
EP  - 5047
AU  - J. -. Merlet
PY  - 2018
KW  - cables (mechanical)
KW  - robot kinematics
KW  - suspended cable-driven parallel robot
KW  - sagging cables
KW  - horizontal cross-sections
KW  - tension limitations
KW  - CDPR
KW  - kinematics equations
KW  - inverse kinematics
KW  - Kinematics
KW  - Parallel robots
KW  - Mathematical model
KW  - Legged locomotion
KW  - Mechanical cables
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594321
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Although workspace is essential for the design and control of cable-driven parallel robots (CDPR) very few works have been devoted to this topic when sagging cables are considered, most probably because of the complexity of the cable model. In this paper we consider suspended CDPR with sagging cables that can support only a limited tension. We propose an algorithm to compute the border of horizontal cross-sections of the workspace for a given altitude and orientation of the platform. We show that singularities of the kinematics equations have to be taken into account for a proper determination of the border and that the workspace can be separated in several components according to the branch of the inverse kinematics on which the robot is evolving. We also compare the workspace obtained for ideal and sagging cables.
ER  - 

TY  - CONF
TI  - A Singularity-Robust LQR Controller for Parallel Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 270
EP  - 276
AU  - R. Bordalba
AU  - J. M. Porta
AU  - L. Ros
PY  - 2018
KW  - control system synthesis
KW  - linear quadratic control
KW  - mobile robots
KW  - nonlinear control systems
KW  - optimal control
KW  - robust control
KW  - torque control
KW  - singularity-robust LQR controller
KW  - five-bar parallel robot
KW  - optimal control law
KW  - expensive inverse dynamics computations
KW  - reliable controller
KW  - singularity-crossing trajectories
KW  - motion range
KW  - singularity-free regions
KW  - forward singularities
KW  - parallel robots
KW  - Trajectory
KW  - Parallel robots
KW  - Robot kinematics
KW  - Regulators
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594084
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Parallel robots exhibit the so-called forward singularities, which complicate substantially the planning and control of their motions. Often, such complications are circumvented by restricting the motions to singularity-free regions of the workspace. However, this comes at the expense of reducing the motion range of the robot substantially. It is for this reason that, recently, efforts are underway to control singularity-crossing trajectories. This paper proposes a reliable controller to stabilize such kind of trajectories. The controller is based on the classical theory of linear quadratic regulators, which we adapt appropriately to the case of parallel robots. As opposed to traditional computed-torque methods, the obtained controller does not rely on expensive inverse dynamics computations. Instead, it uses an optimal control law that is easy to evaluate, and does not generate instabilities at forward singularities. The performance of the controller is exemplified on a five-bar parallel robot accomplishing two tasks that require the traversal of singularities.
ER  - 

TY  - CONF
TI  - Performance of an IMU-Based Sensor Concept for Solving the Direct Kinematics Problem of the Stewart-Gough Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5055
EP  - 5062
AU  - S. Schulz
AU  - A. Seibel
AU  - J. Schlattmann
PY  - 2018
KW  - actuators
KW  - manipulator kinematics
KW  - pose estimation
KW  - sensor fusion
KW  - IMU-based sensor concept
KW  - direct kinematics problem
KW  - linear actuators
KW  - measurement errors
KW  - calculated manipulator platform
KW  - state-of-the-art Stewart-Gough platform
KW  - one-time pose determination
KW  - robustness
KW  - sensor fusion concepts
KW  - Manipulators
KW  - Actuators
KW  - Kinematics
KW  - Standards
KW  - Measurement errors
KW  - Accelerometers
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8594039
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The direct kinematics problem of the Stewart-Gough platform can be solved by measuring the manipulator platform's orientation and two of the linear actuators' orientations instead of the six linear actuators' lengths. In this paper, the effect of measurement errors on the calculated manipulator platform's pose is investigated using the Cramer-Ran lower bound and extensive experiments on a state-of-the-art Stewart-Gough platform. Furthermore, different algorithms and filters for one-time as well as continuous pose determinations are investigated. Finally, possible sensor fusion concepts for the one-time pose determination are presented to increase the robustness against noise and measurement errors.
ER  - 

TY  - CONF
TI  - An Active Stabilizer for Cable-Driven Parallel Robot Vibration Damping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5063
EP  - 5070
AU  - M. Lesellier
AU  - L. Cuvillon
AU  - J. Gangloff
AU  - M. Gouttefarde
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - closed loop systems
KW  - damping
KW  - manipulator kinematics
KW  - position control
KW  - vibration control
KW  - vibrations
KW  - parasitic vibrations
KW  - CDPR mobile platform
KW  - vibration damping
KW  - actuated rotating arms
KW  - control strategy
KW  - planar 3-DOF CDPR
KW  - three-arm stabilizer
KW  - cable-driven parallel robots
KW  - active stabilizer
KW  - position control
KW  - cable-driven parallel robot vibration
KW  - closed-loop system
KW  - Vibrations
KW  - Damping
KW  - Actuators
KW  - Stability analysis
KW  - Symmetric matrices
KW  - Torque
KW  - Jacobian matrices
DO  - 10.1109/IROS.2018.8594148
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Cable-Driven Parallel Robots (CDPRs) can execute fast motions across a large workspace. However, these performances are reached at the cost of a relatively low stiffness which often yields parasitic vibrations at the CDPR mobile platform. In this paper, vibration damping of CDPRs is addressed by means of an original active stabilizer consisting of actuated rotating arms installed on-board the CDPR mobile platform. A control strategy for the whole system, which consists of the CDPR and the stabilizer, and with one purpose for each-position control for the platform and vibration damping for the stabilizer-is designed. The system being controlled at two different time scales, the singular perturbation theory can be used to prove the stability of the corresponding closed-loop system. The efficiency of the proposed device and control strategy is tested in simulations in the case of a planar 3-DOF CDPR equipped with a three-arm stabilizer.
ER  - 

TY  - CONF
TI  - Design and Fabrication of a Bipedal Robot Using Serial-Parallel Hybrid Leg Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5095
EP  - 5100
AU  - K. G. Gim
AU  - J. Kim
AU  - K. Yamane
PY  - 2018
KW  - design engineering
KW  - legged locomotion
KW  - machine bearings
KW  - motion control
KW  - robot dynamics
KW  - velocity control
KW  - serial-parallel hybrid leg mechanism
KW  - forward walking motion
KW  - developed robot
KW  - feet workspace
KW  - pelvis structure
KW  - structural rigidity
KW  - bearings
KW  - carbon fiber tubes
KW  - agile bipedal locomotion
KW  - light structural inertia
KW  - parallel mechanism
KW  - serial mechanism
KW  - bipedal robot
KW  - performance evaluation
KW  - Legged locomotion
KW  - Foot
KW  - Hip
KW  - Servomotors
KW  - Humanoid robots
KW  - Knee
DO  - 10.1109/IROS.2018.8594182
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present the design and performance evaluation of a bipedal robot that utilizes the Hybrid Leg mechanism. It is a leg mechanism that achieves 6 DOF with a combined structure of serial and parallel mechanism. It is designed to have a light structural inertia and large workspace for agile bipedal locomotion. A new version of Hybrid Leg is fabricated with carbon fiber tubes and bearings to improve its structural rigidity and accuracy while supporting its weight. A pair of Hybrid Legs is assembled together for bipedal locomotion. In the assembly, we adopt a pelvis structure with an yaw angle offset to enlarge the feet workspace, inspired by the toe-out angle of the human feet. The workspace and range of velocity are presented in simulation and verified with hardware experiments. We also demonstrate a simple forward walking motion with the developed robot.
ER  - 

TY  - CONF
TI  - Configuration Space Metrics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5101
EP  - 5108
AU  - H. J. Jeon
AU  - A. D. Dragan
PY  - 2018
KW  - manipulator kinematics
KW  - path planning
KW  - configuration space metrics
KW  - robot manipulators
KW  - task constraint
KW  - Euclidean distance metric
KW  - robot behavior
KW  - 3DOF arm
KW  - Jaco 7DOF arm
KW  - Task analysis
KW  - Euclidean distance
KW  - Manifolds
KW  - End effectors
KW  - Elbow
DO  - 10.1109/IROS.2018.8593564
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics - metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.
ER  - 

TY  - CONF
TI  - Fused Angles and the Deficiencies of Euler Angles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5109
EP  - 5116
AU  - P. Allgeuer
AU  - S. Behnke
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - robot dynamics
KW  - fused angles
KW  - Euler angles representation
KW  - balance-related scenarios
KW  - parameter sensitivities
KW  - walking bipedal robots
KW  - three-dimensional Euclidean space
KW  - Quaternions
KW  - Task analysis
KW  - Legged locomotion
KW  - Rotation measurement
KW  - Intelligent robots
KW  - Sensitivity
DO  - 10.1109/IROS.2018.8593384
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Just like the well-established Euler angles representation, fused angles are a convenient parameterisation for rotations in three-dimensional Euclidean space. They were developed in the context of balancing bodies, most specifically walking bipedal robots, but have since found wider application due to their useful properties. A comparative analysis between fused angles and Euler angles is presented in this paper, delineating the specific differences between the two representations that make fused angles more suitable for representing orientations in balance-related scenarios. Aspects of comparison include the locations of the singularities, the associated parameter sensitivities, the level of mutual independence of the parameters, and the axisymmetry of the parameters.
ER  - 

TY  - CONF
TI  - Geometric Optimization of a Large Scale CDPR Operating on a Building Facade
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5117
EP  - 5124
AU  - H. Hussein
AU  - J. C. Santos
AU  - M. Gouttefarde
PY  - 2018
KW  - buildings (structures)
KW  - cables (mechanical)
KW  - construction industry
KW  - design engineering
KW  - mobile robots
KW  - optimisation
KW  - geometric design procedure
KW  - geometric optimization
KW  - building facade
KW  - large-scale construction applications
KW  - wrench-feasibility constraints
KW  - cable-driven parallel robot
KW  - cable tension
KW  - Geometry
KW  - Optimization
KW  - Indexes
KW  - Buildings
KW  - Robots
KW  - Trajectory
KW  - Payloads
DO  - 10.1109/IROS.2018.8593900
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper deals with the optimization of the geometry of a Cable-Driven Parallel Robot (CDPR) dedicated to large-scale construction applications. Since the maximum cable tension is a critical parameter in the design of the CDPR components, the geometry of the CDPR is optimized by minimizing the lowest maximum cable tension that ensures the validity of wrench-feasibility constraints. The geometric design procedure used in this paper consists of two phases, the CDPR cable connections is selected in the first phase followed by a second phase where the geometric parameters are optimized. The result of this procedure is an original fully-constrained CDPR geometry.
ER  - 

TY  - CONF
TI  - Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum Robot in SE(3)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5125
EP  - 5132
AU  - R. Grassmann
AU  - V. Modes
AU  - J. Burgner-Kahrs
PY  - 2018
KW  - actuators
KW  - approximation theory
KW  - neural nets
KW  - position control
KW  - robot kinematics
KW  - forward kinematics
KW  - concentric tube continuum robot
KW  - high computational load
KW  - nonlinear modeling effort
KW  - data-driven approach
KW  - physics-based model
KW  - robot prototype
KW  - inverse kinematics approximation
KW  - artificial neural network
KW  - ReLU
KW  - rectified linear unit
KW  - rotation actuator error
KW  - trigonometric function
KW  - mechanics modeling
KW  - position control
KW  - Electron tubes
KW  - Robots
KW  - Kinematics
KW  - Neural networks
KW  - Quaternions
KW  - Computational modeling
KW  - Load modeling
DO  - 10.1109/IROS.2018.8594451
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent physics-based models of concentric tube continuum robots are able to describe pose of the tip, given the preformed translation and rotation in joint space of the robot. However, such model-based approaches are associated with high computational load and highly non-linear modeling effort. A data-driven approach for computationally fast estimation of the kinematics without requiring the knowledge and the uncertainties in the physics-based model would be an asset. This paper introduces an approach to solve the forward kinematics as well as the inverse kinematics of concentric tube continuum robots with 6-DOF in three dimensional space SE(3). Two artificial neural networks with ReLU (rectified linear unit) activation functions are designed in order to approximate the respective kinematics. Measured data from a robot prototype are used in order to train, validate, and test the proposed approach. We introduce a representation of the rotatory joints by trigonometric functions that improves the accuracy of the approximation. The results with experimental measurements show higher accuracy for the forward kinematics compared to the state of the art mechanics modeling. The tip error is less then 2.3 mm w.r.t. position (1 % of total robot length) and 1.1° w.r.t. orientation. The single artificial neural network for the inverse kinematics approximation achieves a translation and rotation actuator error of 4.0 mm and 8.3 0, respectively.
ER  - 

TY  - CONF
TI  - Learning Forward and Inverse Kinematics Maps Efficiently
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5133
EP  - 5140
AU  - D. Kubus
AU  - R. Rayyes
AU  - J. J. Steil
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - elasticity
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - nonparametric statistics
KW  - learning forward kinematics maps
KW  - exploratory learning approaches
KW  - action-outcome sampling
KW  - omnielastic manipulators
KW  - rigid manipulators
KW  - inverse kinematics mappings
KW  - nonparametric models
KW  - elastic discretely-actuated robots
KW  - rigid discretely-actuated robots
KW  - tailored parametric models
KW  - data-efficiency
KW  - Manipulators
KW  - Kinematics
KW  - Solid modeling
KW  - Elasticity
KW  - Analytical models
KW  - Strain
DO  - 10.1109/IROS.2018.8593833
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.
ER  - 

TY  - CONF
TI  - A Fail-Safe Semi-Centralized Impedance Controller: Validation on a Parallel Kinematics Ankle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Ruscelli
AU  - A. Laurenzi
AU  - E. Mingo Hoffman
AU  - N. G. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - robot kinematics
KW  - torque control
KW  - fail-safe semicentralized impedance controller
KW  - parallel kinematics ankle
KW  - COMAN+
KW  - dual four-bar mechanism
KW  - fully centralized impedance control implementation
KW  - torque reference inputs
KW  - local joint torque controllers
KW  - safer robot response
KW  - Impedance
KW  - Torque
KW  - Kinematics
KW  - Actuators
KW  - Damping
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594112
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes the implementation of an impedance controller on the ankle level of COMAN+, a robot with parallel kinematics ankles actuated by a dual four-bar mechanism. The main contribution of the work is a realization of said control scheme that grants a less abrupt and safer robot response in case of system failures, that would cause the local joint torque controllers to lose their torque reference inputs. In particular, we propose a semi-centralized impedance control implementation which eliminates the instability of the pure joint torque control schemes used in the classical fully centralized methods when torque reference interruptions occur. Finally, we present experimental results, proving the effectiveness of our method and demonstrating how it ensures a safer behaviour compared to a fully centralized impedance control implementation when the communication to the ankle joints is interrupted. This paper is a follow-up work of [1], which presented and analyzed the parallel kinematics ankles.
ER  - 

TY  - CONF
TI  - Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5148
EP  - 5154
AU  - S. Ghosh
AU  - K. Otsu
AU  - M. Ono
PY  - 2018
KW  - aerospace robotics
KW  - Mars
KW  - mobile robots
KW  - path planning
KW  - planetary rovers
KW  - robot kinematics
KW  - state estimation
KW  - statistical distributions
KW  - light-weight analytic solution
KW  - rocky terrain
KW  - typical numeric approaches
KW  - onboard computation
KW  - single collision
KW  - unstructured terrain
KW  - robot motion planning
KW  - kinematics-based collision detection
KW  - planetary rovers
KW  - probabilistic kinematic state estimation
KW  - deterministic state bounds
KW  - distribution models
KW  - probabilistic safety guarantees
KW  - worst-case evaluation
KW  - deterministic bounds
KW  - probability distributions
KW  - frequent false positive detection
KW  - conservative safety check approach
KW  - worst-case values
KW  - constraint violation
KW  - terrain height
KW  - articulated suspension systems
KW  - Mars 2020 rover mission
KW  - Approximate Clearance Evaluation
KW  - Wheels
KW  - Kinematics
KW  - Planning
KW  - Space vehicles
KW  - Uncertainty
KW  - Numerical models
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593771
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.
ER  - 

TY  - CONF
TI  - Constrained Control of Robotic Manipulators Using the Explicit Reference Governor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5155
EP  - 5162
AU  - K. Merckaert
AU  - B. Vanderborght
AU  - M. M. Nicotra
AU  - E. Garone
PY  - 2018
KW  - actuators
KW  - collision avoidance
KW  - end effectors
KW  - manipulators
KW  - position control
KW  - robot arm
KW  - ERG
KW  - Explicit Reference Governor
KW  - nonconvex constraints
KW  - constrained control
KW  - 2DOF planar robotic manipulator
KW  - end-effector position
KW  - actuator saturations
KW  - static obstacles
KW  - joint ranges
KW  - Manipulator dynamics
KW  - Safety
KW  - End effectors
KW  - Actuators
KW  - Navigation
DO  - 10.1109/IROS.2018.8593857
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic manipulators that are intended to interact with humans in their operating region are systems that need formal safety guarantees. Current solutions cannot handle both input and state constraints, have difficulties handling nonconvex constraints, or are computationally too expensive. To tackle these drawbacks, we analyzed a constrained control strategy, the Explicit Reference Governor (ERG), which can address both input and state constraints, and does not require any online optimization, thus making it computationally inexpensive. This paper presents the theory of the ERG for a general robotic manipulator and shows simulations for a specific 2DOF planar robotic manipulator. The proposed control scheme is able to steer the robot arm to the desired end-effector position, or an admissible approximation, in the presence of limited joint ranges, actuator saturations, and static obstacles. As a result, the ERG is a promising tool for the control of robotic manipulators subject to constraints.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Novel Semi-Active Hybrid Unilateral Stance Control Knee Ankle Foot Orthosis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5163
EP  - 5168
AU  - J. Gil
AU  - M. C. Sánchez-Villamañán
AU  - J. Gòmez
AU  - A. Ortiz
AU  - J. L. Pons
AU  - J. C. Moreno
AU  - A. J. Del-Ama
PY  - 2018
KW  - bioelectric phenomena
KW  - gait analysis
KW  - medical control systems
KW  - muscle
KW  - neuromuscular stimulation
KW  - orthotics
KW  - patient rehabilitation
KW  - semiactive hybrid orthotic system
KW  - unilateral pathological human walking
KW  - mechanical control
KW  - noninvasive muscle electrostimulation
KW  - artificial activation
KW  - ankle joint muscles
KW  - hybrid scheme
KW  - electrical stimulation patterns
KW  - ankle muscles
KW  - stance control knee ankle foot orthoses
KW  - Iron
KW  - Muscles
KW  - Knee
KW  - Legged locomotion
KW  - Foot
KW  - Exoskeletons
KW  - Fatigue
DO  - 10.1109/IROS.2018.8594219
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents the design and development of a semi-active hybrid orthotic system for support and facilitation of unilateral pathological human walking. The system is based on a novel lower limb orthosis with mechanical control and its combination with non-invasive muscle electrostimulation. The paper presents the concept design and realization of a novel Stance Control Knee Ankle Foot Orthoses (SCKAFO) and the design of Functional Electrical Stimulation (FES) strategies for artificial activation of ankle joint muscles in this hybrid scheme for gait support. In particular, we present the investigation of the effects of electrical stimulation patterns of ankle muscles synchronized in real-time with gait events., on the possible biomechanical alterations to gait in able-bodied individuals (n=8). Bilateral 3D ground reaction forces (GRF) were analyzed between barefoot overground walking with and without FES of ankle muscles. The observed effects of the tested FES strategy are coherent with a physiological gait strategy and compatible with the proposed SCKAFO.
ER  - 

TY  - CONF
TI  - Iterative Learning Vector Field for FES-Supported Cyclic Upper Limb Movements in Combination with Robotic Weight Compensation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5169
EP  - 5174
AU  - A. Passon
AU  - T. Seel
AU  - J. Massmann
AU  - C. Freeman
AU  - T. Schauer
PY  - 2018
KW  - bioelectric phenomena
KW  - biomechanics
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - medical computing
KW  - medical robotics
KW  - muscle
KW  - neuromuscular stimulation
KW  - neurophysiology
KW  - patient rehabilitation
KW  - physiological models
KW  - control system
KW  - spinal cord injured patients
KW  - functional electrical stimulation
KW  - iterative learning control approaches
KW  - prespecified reference trajectory
KW  - self-selected cadence
KW  - smooth stimulation intensity profiles
KW  - complex neuromusculoskeletal model
KW  - initial RMS error
KW  - steady state RMS error
KW  - adaptive FES support
KW  - purely volitional movements
KW  - breaststroke motions
KW  - control algorithm
KW  - artificially activated muscles
KW  - learning algorithm
KW  - joint angle space
KW  - stimulation intensities
KW  - ILVF
KW  - transversal plane
KW  - cable tension forces
KW  - arm weight
KW  - breaststroke swimming exercises
KW  - repetitive arm movements
KW  - cable-driven robotic system
KW  - anterior deltoid
KW  - posterior deltoid
KW  - triceps
KW  - biceps
KW  - feedback-controlled FES
KW  - robotic weight compensation
KW  - FES-supported cyclic upper limb movements
KW  - iterative learning vector field
KW  - Iron
KW  - Muscles
KW  - Trajectory
KW  - Manipulators
KW  - Torque
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594120
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotics and Functional Electrical Stimulation (FES) are well-established technologies for the rehabilitation of stroke and spinal cord injured (SCI) patients. We propose a hybrid solution that combines feedback-controlled FES of biceps and triceps as well as posterior and anterior deltoid with a cable-driven robotic system to support repetitive arm movements, like “breaststroke swimming” exercises. The robotic system partially compensates the arm weight by controlling the cable tension forces, and the FES promotes motion in the transversal plane. To adjust the FES support to the needs of the individual patients we use an iterative learning vector field (ILVF) which encodes the stimulation intensities that are applied to guide the patient along a pre-specified reference trajectory in the joint angle space. In contrast to previous iterative learning control approaches, the ILVF allows the patient to perform the motion at self-selected cadence. The proposed learning algorithm explicitly takes the dynamics of the artificially activated muscles into account and assures smooth stimulation intensity profiles. The control algorithm is tested in simulations using a complex neuro-musculoskeletal model. For “breaststroke” motions, the initial RMS error of purely volitional movements is reduced from 38° to 10° within 21 cycles by the adaptive FES support. After 50 iterations of the ILVF, the algorithm converges to a steady state RMS error of 4°. Changes in the patient's muscle activity and cadence were well tolerated by the control system and did not cause a noticable increase in the steady state RMS error.
ER  - 

TY  - CONF
TI  - Cooperative Control for Knee Joint Flexion-Extension Movement Restoration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5175
EP  - 5180
AU  - M. A. Alouane
AU  - H. Rifai
AU  - Y. Amirat
AU  - S. Mohammed
PY  - 2018
KW  - adaptive control
KW  - closed loop systems
KW  - medical control systems
KW  - neuromuscular stimulation
KW  - nonlinear control systems
KW  - observers
KW  - orthotics
KW  - patient rehabilitation
KW  - torque control
KW  - knee joint angle trajectory
KW  - cooperative control
KW  - functional electrical stimulation
KW  - quadriceps muscle group
KW  - nonlinear disturbance observer
KW  - torque estimation
KW  - rehabilitation technologies
KW  - open-loop FES
KW  - closed-loop adaptive control
KW  - powered knee joint orthosis
KW  - knee joint flexion-extension movement restoration
KW  - Torque
KW  - Muscles
KW  - Knee
KW  - Iron
KW  - Estimation
KW  - Fatigue
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594230
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a cooperative control approach that combines the use of a powered knee joint orthosis along with Functional Electrical Stimulation (FES) for knee joint flexion-extension movement restoration. A closed-loop adaptive control and an open-loop FES of the quadriceps muscle group are combined together to track a desired knee joint angle trajectory of flexion/extension movements. A nonlinear disturbance observer is used to estimate the torque provided by the subject's muscles through the FES. Simulations and experiments with a healthy subject show the feasibility of the proposed approach. Experiments show the repeatability of motion and the complementarity between the torque provided by the quadriceps muscle through FES and the one delivered by the orthosis actuator to ensure satisfactory tracking of the desired trajectory.
ER  - 

TY  - CONF
TI  - New Approach of Cycling Phases Detection to Improve FES-Pedaling in SCI Individuals
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5181
EP  - 5186
AU  - R. Baptista
AU  - B. Sijobert
AU  - C. A. Coste
PY  - 2018
KW  - bioelectric phenomena
KW  - biomechanics
KW  - neuromuscular stimulation
KW  - patient rehabilitation
KW  - functional electrical stimulation
KW  - optimal pedaling force evolution
KW  - cyclist legs
KW  - inertial measurement units
KW  - motion segmentation
KW  - adaptive properties
KW  - muscle activation
KW  - tricycles
KW  - spinal cord
KW  - FES-pedaling
KW  - Knee
KW  - Superluminescent diodes
KW  - Hidden Markov models
KW  - Adaptation models
KW  - Switches
KW  - Legged locomotion
KW  - Muscles
DO  - 10.1109/IROS.2018.8594162
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - FES allows spinal cord injured individuals to propel tricycles by means of their own leg power. The stimulation patterns are in most of the cases predefined and muscle activation triggered on the basis of the pedal position. This requires an empirical tuning to fit the pattern to the pilot sitting position and distance to crank with no possible generalization and no adaptive properties. The aim of the present article is to introduce a new approach of motion segmentation based on inertial measurement units located on the cyclist legs with the final aim to predict the optimal pedaling force evolution. Results obtained with one healthy subject in different cycling conditions are presented and the application to FES-cycling discussed.
ER  - 

TY  - CONF
TI  - Adaptive FES Assistance Using a Novel Gait Phase Detection Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - W. Huo
AU  - V. Arnez-Paniagua
AU  - M. Ghedira
AU  - Y. Amirat
AU  - J. Gracies
AU  - S. Mohammed
PY  - 2018
KW  - bioelectric phenomena
KW  - bone
KW  - gait analysis
KW  - neuromuscular stimulation
KW  - walking speeds
KW  - gastrocnemius muscles
KW  - knee reextension
KW  - plantar flexor cocontraction
KW  - adaptive knee-joint based functional electrical stimulation method
KW  - classical FES method
KW  - abnormal gaits
KW  - normal gaits
KW  - foot contact conditions
KW  - foot-mounted inertial measurement unit
KW  - late swing
KW  - dorsiflexor stimulation
KW  - swing phase
KW  - paretic patients
KW  - foot drop
KW  - gait phase detection approach
KW  - adaptive FES assistance
KW  - Integrated circuits
KW  - Iron
KW  - Foot
KW  - Legged locomotion
KW  - Knee
KW  - Accelerometers
KW  - Sensors
DO  - 10.1109/IROS.2018.8594051
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an adaptive knee-joint based Functional Electrical Stimulation (FES)method to correct the foot drop of paretic patients during swing phase. The rationale behind the adaptive FES is to amplify dorsiflexor stimulation in the late swing when it is most needed in order to face the increased plantar flexor co-contraction as gastrocnemius muscles are stretched by knee re-extension. To accurately detect the swing phase (i.e., toes off (TO)and initial contact (IC)), a novel algorithm is proposed by using a foot-mounted inertial measurement unit (IMU). The proposed strategy is verified by experiments conducted with three healthy subjects and three paretic patients. The experimental results show that highly accurate detection of TO/I C can be achieved under different walking speeds and foot contact conditions (normal and abnormal gaits). The clinical experimental results with paretic patients also reveal that similar effects on ankle dorsiflexion can be observed during mid and late swing using the proposed adaptive FES with respect to the classical FES method, while the adaptive FES used lower stimulation intensity.
ER  - 

TY  - CONF
TI  - Online Self-Supervised Long-Range Scene Segmentation for MAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5194
EP  - 5199
AU  - S. Daftry
AU  - Y. Agrawal
AU  - L. Matthies
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - vision-based autonomous MAV flight
KW  - self-supervised online learning
KW  - adaptive scene segmentation
KW  - data-driven methods
KW  - manually annotated training data
KW  - geometry-based methods
KW  - sensor capabilities
KW  - robust scene understanding
KW  - complex dynamic environments
KW  - autonomous flights
KW  - lightweight MicroAerial Vehicles
KW  - MAVs
KW  - online self-supervised long-range scene segmentation
KW  - Image segmentation
KW  - Training
KW  - Robot sensing systems
KW  - Visualization
KW  - Real-time systems
KW  - Convolution
DO  - 10.1109/IROS.2018.8594405
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.
ER  - 

TY  - CONF
TI  - PAMPC: Perception-Aware Model Predictive Control for Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - D. Falanga
AU  - P. Foehn
AU  - P. Lu
AU  - D. Scaramuzza
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - nonlinear programming
KW  - path planning
KW  - predictive control
KW  - robot vision
KW  - PAMPC
KW  - lighting conditions
KW  - visual-inertial odometry pipeline
KW  - low-power ARM computer
KW  - nonlinear optimization problem
KW  - action objective
KW  - numerical optimization
KW  - perception-aware model predictive control framework
KW  - model-based optimization framework
KW  - perception objective
KW  - quadrotor
KW  - motion planning
KW  - Cameras
KW  - Trajectory
KW  - Optimization
KW  - Robot vision systems
KW  - Predictive control
KW  - Planning
DO  - 10.1109/IROS.2018.8593739
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.
ER  - 

TY  - CONF
TI  - History-Aware Autonomous Exploration in Confined Environments Using MAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Witting
AU  - M. Fehr
AU  - R. Bähnemann
AU  - H. Oleynikova
AU  - R. Siegwart
PY  - 2018
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - sampling-based exploration algorithms
KW  - 3D exploration planner
KW  - field-of-view depth sensor
KW  - configuration space
KW  - high sampling efficiency
KW  - computational constrained real world MAV
KW  - history-aware autonomous exploration
KW  - confined environments
KW  - inspection tasks
KW  - high-dimensional path planning problem
KW  - microaerial vehicle
KW  - search and rescue missions
KW  - next-best views
KW  - robot orientation
KW  - Planning
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Trajectory
KW  - History
KW  - Optimization
DO  - 10.1109/IROS.2018.8594502
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.
ER  - 

TY  - CONF
TI  - Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Kouris
AU  - C. Bouganis
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - convolutional neural nets
KW  - feature extraction
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - regression analysis
KW  - robot vision
KW  - sensor fusion
KW  - velocity control
KW  - indoor flights
KW  - unmanned aerial vehicles
KW  - civilian applications
KW  - indoor-flight dataset
KW  - agent distance-to-collision prediction
KW  - drone safe deployment
KW  - on-board monocular camera
KW  - external sensors
KW  - spatio-temporal feature extraction
KW  - static appearance information
KW  - motion information
KW  - robot distance estimation
KW  - linear velocity
KW  - navigation policy learning
KW  - real-distance labels
KW  - raw visual input
KW  - regression CNN
KW  - real-time obstacle avoidance
KW  - indoor robot navigation
KW  - autonomous navigation methods
KW  - UAV
KW  - self-supervised CNN-based approach
KW  - navigation policy
KW  - Robots
KW  - Navigation
KW  - Sensors
KW  - Drones
KW  - Cameras
KW  - Task analysis
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594204
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.
ER  - 

TY  - CONF
TI  - Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5224
EP  - 5231
AU  - S. MohaimenianPour
AU  - R. Vaughan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - control engineering computing
KW  - convolutional neural nets
KW  - face recognition
KW  - feature extraction
KW  - gesture recognition
KW  - human-robot interaction
KW  - image colour analysis
KW  - image segmentation
KW  - object detection
KW  - robust control
KW  - video signal processing
KW  - YOLOv2 deep convolutional neural network
KW  - hand-and-face detector
KW  - gestural human-UAV interface
KW  - robust control
KW  - hand-labelled videos
KW  - face-engagement
KW  - robust sensor front-end
KW  - gray-scale images
KW  - robust real-time system
KW  - mono-camera user detection
KW  - human-robot interaction
KW  - human-UAV interaction experiments
KW  - Detectors
KW  - Feature extraction
KW  - Proposals
KW  - Training
KW  - Object detection
KW  - Face detection
KW  - Cameras
DO  - 10.1109/IROS.2018.8593709
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.
ER  - 

TY  - CONF
TI  - Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5232
EP  - 5238
AU  - J. Stevens
AU  - R. Mahony
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - helicopters
KW  - image sequences
KW  - mobile robots
KW  - robot vision
KW  - dense high-speed optical flow
KW  - real-time motion cues
KW  - obstacle avoidance
KW  - smooth trajectory
KW  - image flow representation
KW  - forest environment
KW  - forward sensitive reactive control
KW  - quadrotor VTOL
KW  - aerial robotic vehicles
KW  - 3D full reconstruction
KW  - fully image based control criteria
KW  - Optical sensors
KW  - Optical imaging
KW  - Adaptive optics
KW  - Velocity measurement
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8593606
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.
ER  - 

TY  - CONF
TI  - Angle-Encoded Swarm Optimization for UAV Formation Path Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5239
EP  - 5244
AU  - V. T. Hoang
AU  - M. D. Phung
AU  - T. H. Dinh
AU  - Q. P. Ha
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - multi-robot systems
KW  - particle swarm optimisation
KW  - angle-encoded particle swarm optimization
KW  - 3DR solo drones
KW  - mission planner
KW  - Internet-of- Things
KW  - UAV formation path planning
KW  - triangular formation maintenance
KW  - swarm convergence
KW  - multiple-objective optimisation algorithm
KW  - unmanned aerial vehicles
KW  - feasible path planning technique
KW  - Trajectory
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Task analysis
KW  - Cost function
KW  - Shape
KW  - Quadcopter
KW  - θ-PSO
KW  - path planning
KW  - loT
KW  - triangular formation
KW  - collision avoidance
DO  - 10.1109/IROS.2018.8593930
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - An Integrated Localization-Navigation Scheme for Distance-Based Docking of UAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5245
EP  - 5250
AU  - T. Nguyen
AU  - Z. Qiu
AU  - M. Cao
AU  - T. H. Nguyen
AU  - L. Xie
PY  - 2018
KW  - adaptive estimation
KW  - autonomous aerial vehicles
KW  - convergence
KW  - image sequences
KW  - invariance
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - position control
KW  - single landmark
KW  - unmanned aerial vehicles
KW  - GPS-less environment
KW  - optical flow sensors
KW  - ultra-wideband ranging sensors
KW  - discrete-time LaSalle invariance principle
KW  - UAV
KW  - distance-based docking problem
KW  - integrated localization-navigation scheme
KW  - asymptotic docking
KW  - delicate control scheme
KW  - relative position
KW  - nonlinear adaptive estimation scheme
KW  - bounded velocity
KW  - discrete-time integrators
KW  - navigation tasks
KW  - relative localization
KW  - integrated estimation-control scheme
KW  - arbitrarily unknown position
KW  - Navigation
KW  - Convergence
KW  - Distance measurement
KW  - Adaptive estimation
KW  - Estimation
KW  - Task analysis
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8594251
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we study the distance-based docking problem of unmanned aerial vehicles (UAVs) by using a single landmark placed at an arbitrarily unknown position. To solve the problem, we propose an integrated estimation-control scheme to simultaneously achieve the relative localization and navigation tasks for discrete-time integrators under bounded velocity: a nonlinear adaptive estimation scheme to estimate the relative position to the landmark, and a delicate control scheme to ensure both the convergence of the estimation and the asymptotic docking at the given landmark. A rigorous proof of convergence is provided by invoking the discrete-time LaSalle's invariance principle, and we also validate our theoretical findings on quadcopters equipped with ultra-wideband ranging sensors and optical flow sensors in a GPS-less environment.
ER  - 

TY  - CONF
TI  - Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5307
EP  - 5312
AU  - J. Stria
AU  - V. Hlavác
PY  - 2018
KW  - clothing
KW  - computer graphics
KW  - control engineering computing
KW  - convolutional neural nets
KW  - feature extraction
KW  - image classification
KW  - manipulators
KW  - neurocontrollers
KW  - robot vision
KW  - service robots
KW  - support vector machines
KW  - 3D objects
KW  - feature vector extraction
KW  - t-shirts
KW  - hanging garments classification
KW  - 3D point clouds
KW  - SVM
KW  - generalized convolution operation
KW  - single global feature vector
KW  - convolutional neural network
KW  - depth maps
KW  - robotic arm
KW  - hanging state
KW  - robotic manipulation
KW  - garment category
KW  - Clothing
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Convolution
KW  - Image reconstruction
DO  - 10.1109/IROS.2018.8593741
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The presented work deals with classification of garment categories including pants, shorts, shirts, T-shirts and towels. The knowledge of the garment category is crucial for its robotic manipulation. Our work focuses particularly on garments being held in a hanging state by a robotic arm. The input of our method is a set of depth maps taken from different viewpoints around the garment. The depths are fused into a single 3D point cloud. The cloud is fed into a convolutional neural network that transforms it into a single global feature vector. The network utilizes a generalized convolution operation defined over the local neighborhood of a point. It can deal with permutations of the input points. It was trained on a large dataset of common 3D objects. The extracted feature vector is classified with SVM trained on smaller datasets of garments. The proposed method was evaluated on publicly available data and compared to the original methods, achieving competitive performance and better generalization capability.
ER  - 

TY  - CONF
TI  - Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5313
EP  - 5319
AU  - M. Santos
AU  - M. Egerstedt
PY  - 2018
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - multirobot teams
KW  - heterogeneous sensing capabilities
KW  - coverage algorithm
KW  - multirobot systems
KW  - qualitatively different sensing modalities
KW  - required sensing modalities
KW  - particular sensory capability
KW  - distributed control algorithm
KW  - robotic platform
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Monitoring
KW  - Temperature sensors
KW  - Density functional theory
DO  - 10.1109/IROS.2018.8594056
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.
ER  - 

TY  - CONF
TI  - An Adaptive Robot for Building In-Plane Programmable Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Pieber
AU  - R. Neurauter
AU  - J. Gerstmayr
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - mechatronics
KW  - mesh generation
KW  - nonlinear control systems
KW  - optimal control
KW  - position control
KW  - robot kinematics
KW  - supports
KW  - autonomous cells
KW  - unstructured triangular meshes
KW  - arbitrary planar shapes
KW  - self-reconfigurable system
KW  - programmable matter
KW  - kinematic model
KW  - cellular robot
KW  - positioning errors
KW  - simplified mechanical model
KW  - adaptive robot
KW  - single elements
KW  - triangular cells
KW  - linear actuators
KW  - triangular shapes
KW  - in-plane programmable structures
KW  - Actuators
KW  - Robots
KW  - Couplings
KW  - Kinematics
KW  - Shape
KW  - Latches
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593381
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new approach for cellular robots is presented. The single elements of the robot are triangular cells, which can change their shape by means of linear actuators at each edge. The novelty concerns the connection of autonomous cells at their edges rather than at the vertices. In this way, unstructured triangular meshes can be formed. The robot can self-reconfigure and thus can reproduce almost arbitrary planar shapes. In a similar way, the system has been realized with tetrahedrons in a simplified way within a previous work. The self-reconfigurable system shall serve as a basis for programmable matter. The present paper includes the mechatronic design, its components and the kinematic model of the cellular robot. In order to reduce positioning errors, a model is developed, which considers compliance and clearance in the links and joints. Based on a simplified mechanical model using elastic trusses, the positioning errors can be predicted. The parameters of these models are identified from simple motion sequences. Furthermore, the nonlinearity of actuators is identified and corrected. In this way, the desired triangular shapes can be prescribed without measuring the position of the cells.
ER  - 

TY  - CONF
TI  - Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5344
EP  - 5349
AU  - D. St-Onge
AU  - C. Pinciroli
AU  - G. Beltrame
PY  - 2018
KW  - finite state machines
KW  - mobile robots
KW  - multi-robot systems
KW  - spatiotemporal phenomena
KW  - computation-free robots
KW  - emergent behavioural structure
KW  - finite state machine
KW  - minimal robots
KW  - nonholonomic robots
KW  - self-healing circle formations
KW  - frontal binary sensor
KW  - grid-search method
KW  - computation-free behaviour
KW  - spatio-temporal dynamics
KW  - Robot sensing systems
KW  - Mobile robots
KW  - Robot kinematics
KW  - Apertures
KW  - Standards
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593439
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.
ER  - 

TY  - CONF
TI  - Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Lee
AU  - D. Yi
AU  - S. S. Srinivasa
PY  - 2018
KW  - Bayes methods
KW  - Markov processes
KW  - Monte Carlo methods
KW  - Pareto optimisation
KW  - path planning
KW  - implicit uniform distribution
KW  - Pareto-frontier
KW  - progressive objective evaluation
KW  - objective functions
KW  - Pareto-optimal trajectories
KW  - multiobjective motion planning
KW  - multiobjective motion-planning problems
KW  - sampling trajectories
KW  - Pareto-optimal set
KW  - Markov chain Monte Carlo method
KW  - Trajectory
KW  - Markov processes
KW  - Planning
KW  - Monte Carlo methods
KW  - Sociology
KW  - Optimization
DO  - 10.1109/IROS.2018.8593735
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.
ER  - 

TY  - CONF
TI  - Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5366
EP  - 5371
AU  - J. Jesús Roldán
AU  - J. Del Cerro
AU  - A. Barrientos
PY  - 2018
KW  - game theory
KW  - preferred task allocations
KW  - competitive algorithm
KW  - game theoretical algorithms
KW  - described scenario
KW  - relevant question
KW  - partial information
KW  - disaster area
KW  - drone swarms
KW  - task allocation
KW  - game theory
KW  - Task analysis
KW  - Robots
KW  - Resource management
KW  - Games
KW  - Drones
KW  - Nash equilibrium
KW  - Genetic algorithms
DO  - 10.1109/IROS.2018.8594145
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.
ER  - 

TY  - CONF
TI  - Magnetic Navigation of a Rotating Colloidal Swarm Using Ultrasound Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5380
EP  - 5385
AU  - Q. Wang
AU  - L. Yang
AU  - J. Yu
AU  - C. Vong
AU  - P. W. Yan Chiu
AU  - L. Zhang
PY  - 2018
KW  - biomedical ultrasonics
KW  - image enhancement
KW  - magnetic particles
KW  - medical image processing
KW  - medical robotics
KW  - microrobots
KW  - nanomedicine
KW  - nanoparticles
KW  - magnetic navigation
KW  - rotating colloidal swarm
KW  - ultrasound images
KW  - paramagnetic nanoparticle-based swarm
KW  - simple rotating magnetic fields
KW  - microrobotic swarm
KW  - enhanced ultrasound imaging
KW  - imaging contrast
KW  - microrobot imaging
KW  - nanoparticle
KW  - solid surface
KW  - Magnetic resonance imaging
KW  - Ultrasonic imaging
KW  - Nanoparticles
KW  - Magnetic recording
KW  - Magnetic moments
KW  - Navigation
DO  - 10.1109/IROS.2018.8593898
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Microrobots are considered as promising tools for biomedical applications. However, the imaging of them becomes challenges in order to be further applied on in vivo environments. Here we report the magnetic navigation of a paramagnetic nanoparticle-based swarm using ultrasound images. The swarm can be generated using simple rotating magnetic fields, resulting in a region containing particles with a high area density. Ultrasound images of the swarm shows a periodic changing of imaging contrast. The reason for such dynamic contrast has been analyzed and experimental results are presented. Moreover, this swarm exhibits enhanced ultrasound imaging in comparison to that formed by individual nanoparticles with a low area density, and the relationship between imaging contrast and area density is testified. Furthermore, the microrobotic swarm can be navigated near a solid surface at different velocities, and the imaging contrast show negligible changes. This method allows us to localize and navigate a microrobotic swarm with enhanced ultrasound imaging indicating a promising approach for imaging of microrobots.
ER  - 

TY  - CONF
TI  - A Multi-Rate State Observer for Visual Tracking of Magnetic Micro-Agents Using 2D Slow Medical Imaging Modalities
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Kaya
AU  - A. Denasi
AU  - S. Scheggi
AU  - E. Agbahca
AU  - C. Yoon
AU  - D. H. Gracias
AU  - S. Misra
PY  - 2018
KW  - biological tissues
KW  - biomedical optical imaging
KW  - biomedical ultrasonics
KW  - cameras
KW  - Kalman filters
KW  - medical image processing
KW  - object tracking
KW  - observers
KW  - sampling methods
KW  - surgery
KW  - multirate state observer
KW  - visual tracking
KW  - magnetic microagents
KW  - Luenberger state estimators
KW  - minimally invasive surgery
KW  - tracking error
KW  - ultrasound microscope
KW  - ultrasound machine
KW  - electromagnetic coils
KW  - Kalman state estimator
KW  - multirate state estimation
KW  - medical imaging modality
KW  - multirate sampling methods
KW  - Visualization
KW  - Tracking
KW  - Biomedical imaging
KW  - Jacobian matrices
KW  - Two dimensional displays
KW  - State estimation
KW  - Magnetic resonance imaging
DO  - 10.1109/IROS.2018.8594349
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Minimally invasive surgery can benefit greatly from utilizing micro-agents. These miniaturized agents need to be clearly visualized and precisely controlled to ensure the success of the surgery. Since medical imaging modalities suffer from low acquisition rate, multi-rate sampling methods can be used to estimate the intersample states of micro-agents. Hence, the sampling rate of the controller can be virtually increased even if the position data is acquired using a slow medical imaging modality. This study presents multi-rate Luenberger and Kalman state estimators for visual tracking of micro-agents. The micro-agents are tracked using sum of squared differences and normalized cross correlation based visual tracking. Further, the outputs of the two methods are merged to minimize the tracking error and prevent tracking failures. During the experiments, the micro-agents with different geometrical shapes and sizes are imaged using a 2D ultrasound machine and a microscope, and manipulated using electromagnetic coils. The multi-rate state estimation accuracy is measured using a high speed camera. The precision of the tracking and multi-rate state estimation are verified experimentally under challenging conditions. For this purpose, an elliptical shaped magnetic micro-agent with a length of 48 pixels is used. Maximum absolute error in x and y axes are 2.273 and 2.432 pixels for an 8-fold increase of the sample rate (25 frames per second), respectively. During the experiments, it was observed that the micro-agents could be tracked more reliably using normalized cross correlation based visual tracking and inters ample states could be estimated more accurately using Kalman state estimator. Experimental results show that the proposed method could be used to track micro-agents in medical imaging modalities and estimate system states at intermediate time instants in real-time.
ER  - 

TY  - CONF
TI  - Human Motion Classification Based on Multi-Modal Sensor Data for Lower Limb Exoskeletons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5431
EP  - 5436
AU  - J. Beil
AU  - I. Ehrenberger
AU  - C. Scherer
AU  - C. Mandery
AU  - T. Asfour
PY  - 2018
KW  - biomechanics
KW  - force sensors
KW  - gait analysis
KW  - hidden Markov models
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - patient rehabilitation
KW  - pattern classification
KW  - wearable computers
KW  - human motion classification
KW  - multimodal sensor data
KW  - lower limb exoskeletons
KW  - intuitive exoskeleton control
KW  - improved user acceptance
KW  - wearability comfort
KW  - exoskeleton control system
KW  - online classification
KW  - lower-limb exoskeleton
KW  - defined motion patterns
KW  - recent sensor measurements
KW  - sliding window approach
KW  - training data
KW  - passive exoskeleton
KW  - 3D-force sensors
KW  - 3 inertial measurement units
KW  - correct classification
KW  - generalization performance
KW  - hidden Markov models
KW  - Exoskeletons
KW  - Hidden Markov models
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Force
KW  - Force sensors
KW  - Thigh
DO  - 10.1109/IROS.2018.8594110
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.
ER  - 

TY  - CONF
TI  - A Novel Joint Torque Estimation Method and Sensory System for Assistive Lower Limb Exoskeletons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Saccares
AU  - I. Sarakoglou
AU  - N. G. Tsagarakis
PY  - 2018
KW  - biomechanics
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - torque
KW  - torque control
KW  - novel joint torque estimation method
KW  - sensory System
KW  - assistive lower limb exoskeletons
KW  - hip
KW  - reference signals
KW  - life scenarios
KW  - noncyclic locomotion activity
KW  - unexpected terrain
KW  - unpredicted interactions
KW  - upper body
KW  - mass location
KW  - sensorized shoe sensing system
KW  - inverse static analysis
KW  - lower limbs
KW  - leg joint
KW  - body posture sensors
KW  - sensorized shoes
KW  - interaction loads
KW  - irregular terrains
KW  - natural feet postures
KW  - knee torques
KW  - iT-Knee Bipedal System
KW  - assistive task
KW  - Sensors
KW  - Foot
KW  - Torque
KW  - Task analysis
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Knee
DO  - 10.1109/IROS.2018.8594250
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a novel method for estimating online the torques at the ankle, knee and hip of a user with the goal of generating reference signals for torque controlled lower limb exoskeletons. In particular, this approach attempts to address difficulties arising in real life scenarios when noncyclic locomotion activity, unexpected terrain or unpredicted interactions with the surroundings occur. An advantage of the proposed method is that it does not require any information on the user's upper body (i.e. pose, weight and center of mass location)or on any interaction of the user's upper body with the environment (i.e. payload handling or pushing and pulling task). By monitoring the interaction of the user's feet with the ground through a novel sensorized shoe sensing system, the method applies an inverse static analysis on the user's lower limbs to estimate in real time the torque at each leg joint. The system is fully wearable, ergonomic and portable and uses a reduced number of body posture sensors. The design of the sensorized shoes permits plantar flexion, while measuring the toe and heel orientation and the interaction loads. This allows walking on irregular terrains and natural feet postures in different tasks. Trials were performed to validate the proposed approach under different tasks and terrains. Finally, the knee torques estimated online by the proposed strategy were used as reference signals to drive the iT-Knee Bipedal System in an assistive task.
ER  - 

TY  - CONF
TI  - Robotic Hand-Free-Stick for Walking Balance Assistance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5445
EP  - 5450
AU  - Y. Tanaka
AU  - N. Oyama
AU  - T. Takenaka
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - humanoid robots
KW  - legged locomotion
KW  - pressure measurement
KW  - servomotors
KW  - stick motion
KW  - walking tests
KW  - HFS
KW  - ZMP area
KW  - walking balance assistance
KW  - robotic hand-free-stick
KW  - wearable robotic stick
KW  - walking assistance
KW  - nonserious dysfunction
KW  - Zero moment point
KW  - hands free conditions
KW  - body balance ability
KW  - boots type prototype
KW  - lightweight robotic stick
KW  - slider-link mechanism
KW  - stick angle
KW  - hand-free-stick
KW  - Legged locomotion
KW  - Hafnium
KW  - Foot
KW  - Prototypes
KW  - Senior citizens
KW  - Weight measurement
DO  - 10.1109/IROS.2018.8593389
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a wearable robotic stick for walking assistance, called “Hand-Free-Stick” (HFS), for people with non-serious dysfunction in their gait. The basic idea of the proposed HFS is to enlarge ZMP (Zero moment point) area of a user under hands free conditions and to augment his/her body balance ability in walking. A boots type prototype of the HFS is developed with a lightweight robotic stick using a servomotor, in which the slider-link mechanism works to regulate the stick angle and length at the same time. The stick motion is controlled by a single-board computer based on the distribution of foot/feet pressures measured by the sensor system using eight load cells attached at the sole of boots. A set of walking tests with/without the prototype of HFS is carried out for four healthy subjects and demonstrates the effectiveness of the proposed HFS to expand the ZMP area leading to walking balance assistance.
ER  - 

TY  - CONF
TI  - Soft Fabric Actuator for Robotic Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5451
EP  - 5456
AU  - S. Y. Yang
AU  - K. H. Cho
AU  - Y. Kim
AU  - K. Kim
AU  - J. H. Park
AU  - H. S. Jung
AU  - J. U. Ko
AU  - H. Moon
AU  - J. C. Koo
AU  - H. Rodrigue
AU  - J. W. Suk
AU  - J. Nam
AU  - H. R. Choi
PY  - 2018
KW  - electroactive polymer actuators
KW  - fabrics
KW  - microactuators
KW  - polymer fibres
KW  - polymers
KW  - wearable robots
KW  - weaving
KW  - coiled soft actuators
KW  - STCA multiple fabrication method
KW  - continuous fabrication method
KW  - actuation test
KW  - soft fabric actuator
KW  - actuation strain
KW  - robotic applications
KW  - twisted and coiled soft actuators
KW  - Spandex TCA
KW  - Nylon TCA
KW  - human arm size mannequin
KW  - angle control
KW  - Actuators
KW  - Fabrics
KW  - Fabrication
KW  - Strain
KW  - Weaving
KW  - Yarn
KW  - Connectors
DO  - 10.1109/IROS.2018.8594275
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.
ER  - 

TY  - CONF
TI  - Child-Sized Passive Exoskeleton for Supporting Voluntary Sitting and Standing Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5457
EP  - 5462
AU  - K. Sasaki
AU  - M. Sugimoto
AU  - T. Sugiyama
AU  - D. F. Paez Granados
AU  - K. Suzuki
PY  - 2018
KW  - biomechanics
KW  - handicapped aids
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - position control
KW  - springs (mechanical)
KW  - wearable robots
KW  - child-sized passive exoskeleton
KW  - voluntary sitting-standing posture transition
KW  - lower limb impairment
KW  - gas springs
KW  - voluntary upper body motion
KW  - posture transition model
KW  - minimum jerk criterion
KW  - toilet usage
KW  - toilet seat
KW  - voluntary posture transition
KW  - voluntary sitting motion
KW  - voluntary standing motion
KW  - exoskeleton design
KW  - center of gravity transition
KW  - seating position
KW  - locomotion capability
KW  - children self-reliant social activities
KW  - Exoskeletons
KW  - Knee
KW  - Wheelchairs
KW  - Pediatrics
KW  - Mathematical model
KW  - Trajectory
KW  - Springs
DO  - 10.1109/IROS.2018.8593744
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a novel passive exoskeleton for voluntary sitting-standing posture transition for children with lower limb impairment. The design of the exoskeleton is based on the utilization of the center of gravity transition through the user's upper body motion. The passive exoskeleton powered by gas springs allows the user to realize a natural-like posture transition by the user's voluntary upper body motion. We designed the posture transition model such that the user can realize the posture transition in a natural manner based on a minimum jerk criterion. The proposed design aims to permit toilet usage without transferring seating positions between the exoskeleton and toilet seat. Furthermore, the developed mechanism can be integrated with a regular wheelchair, which would allow users to have locomotion capability. We believe that the design can improve children's self-reliant social activities by supporting their voluntary posture transition and toilet use. In this paper, we describe the detailed design process of the exoskeleton and preliminary experiments to investigate its effectiveness through evaluation with a healthy participant.
ER  - 

TY  - CONF
TI  - Hands-Free Assistive Manipulator Using Augmented Reality and Tongue Drive System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5463
EP  - 5468
AU  - F. Chu
AU  - R. Xu
AU  - Z. Zhang
AU  - P. A. Vela
AU  - M. Ghovanloo
PY  - 2018
KW  - assisted living
KW  - augmented reality
KW  - handicapped aids
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - user interfaces
KW  - augmented reality glasses
KW  - robot autonomy
KW  - tongue drive system
KW  - egocentric perspective
KW  - visual feedback
KW  - Cartesian control
KW  - robotic assistant
KW  - cognitive burden
KW  - physical disabilities
KW  - hands-free collaborative manipulation
KW  - human-in-the-loop system
KW  - hands-free assistive manipulator
KW  - robotic arm
KW  - Manipulators
KW  - Task analysis
KW  - Visualization
KW  - Tongue
KW  - Three-dimensional displays
KW  - Machine vision
DO  - 10.1109/IROS.2018.8594508
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A human-in-the-loop system is proposed to enable hands-free collaborative manipulation for people with physical disabilities. Studies show that the cognitive burden of interfacing with a robotic assistant decreases with increased robot autonomy. Incorporating modern advances in perception with augmented reality, this paper describes a framework for obtaining high-level intents from the user to specify manipulation tasks for execution. Augmented reality glasses provide an egocentric perspective to the robot. The glasses also provide visual feedback to users on a virtual menu showing a summary of robot affordances. The system processes the vision input to interpret the users environment. A Tongue Drive System serves as the input modality for triggering task execution by the robotic arm. Several manipulation experiments are performed with comparison to Cartesian control. The outcomes are also compared to reported state-of-the-art approaches. The results demonstrate competitive performance with minimal user input requirements.
ER  - 

TY  - CONF
TI  - Machine Learning Based Skill-Level Classification for Personal Mobility Devices Using Only Operational Characteristics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5469
EP  - 5476
AU  - Y. Huang
AU  - T. Mori
AU  - U. E. Manawadu
AU  - M. Kamezaki
AU  - T. Ishihara
AU  - M. Nakano
AU  - K. Koshiji
AU  - N. Higo
AU  - T. Tubaki
AU  - S. Sugano
PY  - 2018
KW  - electric vehicles
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - wheelchairs
KW  - machine learning
KW  - skill-level classification
KW  - personal mobility devices
KW  - operational characteristics
KW  - electric-powered wheelchairs
KW  - handicapped people
KW  - comfort travel
KW  - skill level classification method
KW  - skill level clusters
KW  - joystick operation data
KW  - five-level classification
KW  - supervised learning
KW  - user operation skills
KW  - unsupervised clustering
KW  - speed control
KW  - direction control
KW  - gradient boosting
KW  - Boosting
KW  - Vehicles
KW  - Sensors
KW  - Feature extraction
KW  - Acceleration
DO  - 10.1109/IROS.2018.8593578
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Some electric-powered wheelchairs are recently redefined as personal mobility devices. Their users are not only elderly or handicapped people, but also passengers with large baggage or pedestrians going from station to destination, i.e., last-mile transport. Consequently, people with different operation skills and expectations on personal mobility would become new users of this kind of devices. Safe and comfort travel in human co-existing environment such as sidewalks and airports is a social expectation for personal mobility. In order to realize this, understanding the operation skill of each user by a practical and simple method is essential. This paper thus introduced a skill level classification method by machine learning using only joystick data as input. In order to determine the number of skill level clusters, basic 26 features of joystick operation data are used for unsupervised clustering (single-linkage). We then made evaluation indexes by using speed, speed control, and direction control. For a five-level classification by using gradient boosting as supervised learning, we achieved a 67% accuracy (tolerance: 0) and a 98% accuracy (tolerance: 1). Further analysis of the feature importance of gradient boosting revealed key features to a good operation. Results also show that skill level differed among people with different driving experiences.
ER  - 

TY  - CONF
TI  - Pneumatic Microneedle-Based High-Density sEMG Sleeve for Stable and Comfortable Skin Contact During Dynamic Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5477
EP  - 5482
AU  - M. Kim
AU  - G. Gu
AU  - W. K. Chung
PY  - 2018
KW  - biomechanics
KW  - biomedical electrodes
KW  - biomedical measurement
KW  - electromyography
KW  - medical signal processing
KW  - needles
KW  - skin
KW  - microneedle-based electrodes
KW  - pneumatic microneedle-based high-density sEMG sleeve
KW  - pneumatic air control
KW  - sEMG signal processing
KW  - wireless signal transmission
KW  - sEMG signal quality
KW  - stable skin contact
KW  - comfortable skin contact
KW  - skin impedance
KW  - sEMG signal measurement
KW  - surface electromyography signals
KW  - motion artifacts
KW  - Velcro armbands
KW  - pneumatic pressure
KW  - needle length
KW  - Electrodes
KW  - Skin
KW  - Impedance
KW  - Needles
KW  - Solenoids
KW  - Valves
KW  - Motion artifacts
DO  - 10.1109/IROS.2018.8594135
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skin impedance should be minimized to obtain reliable and precise surface electromyography (sEMG) signals. High skin impedance decreases sensitivity to muscular activation and makes sEMG signals vulnerable to external noise. Microneedle-based electrodes have been proposed to achieve low skin impedance and high spatial resolution. However, unstable skin contact can occur during dynamic motion due to the electrodes small contact area, and the signal is easily influenced by motion artifacts. In this study, a pneumatic microneedle-based high-density sEMG sleeve is proposed that guarantees stable sEMG signal measurement by pressing the electrodes to the skin. Pneumatic air control, sEMG signal processing, and wireless signal transmission are processed in a single processor. The proposed interface automatically controls the air volume according to sEMG signal quality and is comfortable for users. The usability of the proposed interface was compared to conventional Velcro armbands by examining acquired sEMG signals. The results indicated that the proposed pneumatic sleeve guarantees reliable sEMG signal measurement during dynamic motion. Additionally, optimal pneumatic pressure and needle length were investigated.
ER  - 

TY  - CONF
TI  - Supervised Autonomous Locomotion and Manipulation for Disaster Response with a Centaur-Like Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - T. Klamt
AU  - D. Rodriguez
AU  - M. Schwarz
AU  - C. Lenz
AU  - D. Pavlichenko
AU  - D. Droeschel
AU  - S. Behnke
PY  - 2018
KW  - disasters
KW  - legged locomotion
KW  - manipulators
KW  - motion control
KW  - rescue robots
KW  - telerobotics
KW  - autonomous locomotion
KW  - mobile manipulation tasks
KW  - SAR
KW  - flexible locomotion
KW  - terrains
KW  - anthropomorphic upper body
KW  - complex tasks
KW  - direct teleoperation approaches
KW  - supervised autonomy approaches
KW  - disaster response scenarios
KW  - centaur-like robot Centauro
KW  - hybrid legged-wheeled base
KW  - operator assistance functionalities
KW  - search and rescue
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Legged locomotion
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8594509
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile manipulation tasks are one of the key challenges in the field of search and rescue (SAR) robotics requiring robots with flexible locomotion and manipulation abilities. Since the tasks are mostly unknown in advance, the robot has to adapt to a wide variety of terrains and workspaces during a mission. The centaur-like robot Centauro has a hybrid legged-wheeled base and an anthropomorphic upper body to carry out complex tasks in environments too dangerous for humans. Due to its high number of degrees of freedom, controlling the robot with direct teleoperation approaches is challenging and exhausting. Supervised autonomy approaches are promising to increase quality and speed of control while keeping the flexibility to solve unknown tasks. We developed a set of operator assistance functionalities with different levels of autonomy to control the robot for challenging locomotion and manipulation tasks. The integrated system was evaluated in disaster response scenarios and showed promising performance.
ER  - 

TY  - CONF
TI  - Design of a Lightweight, Ergonomic Manipulator for Enabling Expressive Gesturing in Telepresence Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5491
EP  - 5496
AU  - J. T. Slack
AU  - K. DeProw
AU  - Z. Anderson
AU  - R. M. Albacete Di Bartolomeo
AU  - J. L. Gorlewicz
AU  - J. B. Weinberg
PY  - 2018
KW  - end effectors
KW  - ergonomics
KW  - gesture recognition
KW  - human-robot interaction
KW  - telerobotics
KW  - anthropomorphic end effector
KW  - telepresence experience
KW  - expressive gesturing
KW  - tangible interactions
KW  - face-to-face interactions
KW  - remote users
KW  - local users
KW  - remote communication
KW  - telepresence robots
KW  - telepresence interactions
KW  - ergonomic manipulator
KW  - lightweight manipulator
KW  - engaging communication
KW  - expressive communication
KW  - physical actions
KW  - subconscious quality
KW  - primary social behaviors
KW  - physical referencing
KW  - expressive gestures
KW  - Manipulators
KW  - Shoulder
KW  - Telepresence
KW  - Elbow
KW  - Kinematics
KW  - Torque
DO  - 10.1109/IROS.2018.8593533
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent research on telepresence robots demonstrates that while they enable new heights of remote communication, there still exists challenges for both local and remote users in creating a connectedness one only encounters in face-to-face interactions. A large part of communication is beyond hearing and vision. Tangible interactions, expressive gestures, and physical referencing represent three of the primary social behaviors missing in the current telepresence experience. There is an inherent, subconscious quality to these physical actions that has been shown to allow more expressive and engaging communication. In this project we present the design, fabrication, and initial performance validation of a lightweight, ergonomic manipulator with a heavy, anthropomorphic end effector that enables gesturing capabilities for telepresence interactions.
ER  - 

TY  - CONF
TI  - Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5497
EP  - 5502
AU  - D. Lee
AU  - Y. S. Park
PY  - 2018
KW  - augmented reality
KW  - dexterous manipulators
KW  - haptic interfaces
KW  - human computer interaction
KW  - telerobotics
KW  - augmented teleoperation System
KW  - robot operating system
KW  - rugged robots
KW  - resource sharing
KW  - system integration
KW  - telerobotic system
KW  - operator interface
KW  - virtual fixture generation
KW  - current technology basis
KW  - human operator
KW  - complex robotic systems
KW  - telerobotic operation
KW  - enhanced teleoperator interface incorporating multimodal
KW  - current telerobotics technology
KW  - complex manipulation
KW  - dexterous manipulation
KW  - severe task requirements
KW  - unstructured nuclear environment
KW  - remote systems
KW  - ROS
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Telerobotics
KW  - Haptic interfaces
KW  - Fixtures
DO  - 10.1109/IROS.2018.8594482
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.
ER  - 

TY  - CONF
TI  - Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5503
EP  - 5508
AU  - M. Di Castro
AU  - C. V. Almagro
AU  - G. Lunghi
AU  - R. Marin
AU  - M. Ferre
AU  - A. Masi
PY  - 2018
KW  - force feedback
KW  - human computer interaction
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - telerobotics
KW  - velocity control
KW  - human-robot interface
KW  - tracking experiments
KW  - metallic parts
KW  - vision-based control system
KW  - robotic arm
KW  - monochromatic objects
KW  - metallic connectors
KW  - metallic plates
KW  - featureless objects
KW  - teleoperation loop
KW  - tracking system
KW  - object recognition
KW  - higher-level applications
KW  - safer system
KW  - interaction modalities
KW  - force feedback
KW  - bilateral teleoperation
KW  - low level interaction methods
KW  - multimodal interactions
KW  - robotic operator
KW  - harsh environments
KW  - safe robotic interventions
KW  - robotic guidance
KW  - metallic pieces
KW  - depth estimation
KW  - Cameras
KW  - Estimation
KW  - Robot vision systems
KW  - Correlation
KW  - Object recognition
KW  - Target tracking
DO  - 10.1109/IROS.2018.8594229
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.
ER  - 

TY  - CONF
TI  - Managing Off-Nominal Events in Shared Teleoperation with Learned Task Compliance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5509
EP  - 5516
AU  - P. Owan
AU  - J. Garbini
AU  - S. Devasia
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - telerobotics
KW  - off-nominal events
KW  - shared teleoperation
KW  - learned task compliance
KW  - teleoperation assistance
KW  - remote manufacturing
KW  - off-nominal situations
KW  - attenuate assistance
KW  - hole-cleaning task
KW  - imitation learning policies
KW  - Haptic interfaces
KW  - Task analysis
KW  - Robots
KW  - Collaboration
KW  - Trajectory
KW  - Tools
KW  - Force
DO  - 10.1109/IROS.2018.8594195
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This article studies imitation learning policies that encode task compliance to provide teleoperation assistance for remote manufacturing. The central challenge is how to handle off-nominal situations, such as out-of-sequence work or unplanned obstacles, since the assistance has not been trained to handle such scenarios. In such cases, there is potential for the assistance to degrade-rather than improve-operator performance. This work proposes a method that exploits the learned task compliance to classify persistent human actions as off-nominal, and attenuate assistance in these regions. Applied to a hole-cleaning task with n = 11 subjects, the proposed method shows up to 17% reduction in task completion time and up to 68% reduction in forces in off-nominal situations as compared to assistance without the method. Additionally, the method retains the performance improvements of assistance in nominal operating regimes.
ER  - 

TY  - CONF
TI  - Inferring Semantic State Transitions During Telerobotic Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. S. Bauer
AU  - P. Schmaus
AU  - A. Albu-Schäffer
AU  - D. Leidner
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - inference mechanisms
KW  - manipulators
KW  - mobile robots
KW  - service robots
KW  - telerobotics
KW  - telerobotic manipulation
KW  - autonomous operations
KW  - service robots
KW  - robot teleoperation
KW  - automated planning
KW  - higher abstraction level
KW  - semantic reasoning
KW  - abstract state
KW  - operational modes
KW  - simulation based geometric tracking
KW  - semantic state transitions inference
KW  - state inference entities
KW  - Semantics
KW  - Planning
KW  - Computational modeling
KW  - Physics
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594458
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human teleoperation of robots and autonomous operations go hand in hand in today's service robots. While robot teleoperation is typically performed on low to medium levels of abstraction, automated planning has to take place on a higher abstraction level, i.e. by means of semantic reasoning. Accordingly, an abstract state of the world has to be maintained in order to enable an operator to switch seamlessly between both operational modes. We propose a novel approach that combines simulation based geometric tracking and semantic state inference by means of so called State Inference Entities to overcome this issue. We also demonstrate how Evolutionary Strategies can be employed to refine simulation parameters. All experiments are demonstrated in real-world experiments conducted with the humanoid robot Rollin' Justin.
ER  - 

TY  - CONF
TI  - Smoother Position-Drift Compensation for Time Domain Passivity Approach Based Teleoperation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5525
EP  - 5532
AU  - A. Coelho
AU  - H. Singh
AU  - T. Muskardin
AU  - R. Balachandran
AU  - K. Kondak
PY  - 2018
KW  - compensation
KW  - delays
KW  - force feedback
KW  - motion control
KW  - position control
KW  - robust control
KW  - synchronisation
KW  - telerobotics
KW  - robust methods
KW  - bilateral teleoperation
KW  - position drift
KW  - slave devices
KW  - position synchronization
KW  - position-drift problem
KW  - TDPA-based teleoperation
KW  - force feedback
KW  - high impulse-like force signals
KW  - teleoperation task
KW  - energy-based TDPA
KW  - compensator
KW  - regular-amplitude forces
KW  - time domain passivity approach
KW  - position tracking
KW  - position-drift compensation
KW  - master devices
KW  - robust stability
KW  - time 500.0 ms
KW  - Force
KW  - Task analysis
KW  - Delays
KW  - Communication channels
KW  - Time-domain analysis
KW  - Delay effects
KW  - Admittance
DO  - 10.1109/IROS.2018.8594125
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite being one of the most robust methods in bilateral teleoperation, Time Domain Passivity Approach (TDPA)presents the drawback of accumulating position drift between master and slave devices. The lack of position synchronization poses an obstacle to the performance of teleoperation and may prevent the successful accomplishment of such tasks. Several techniques have been developed in order to solve the position-drift problem in TDPA-based teleoperation. However, they either present poor transparency by over-conservatively constraining force feedback or add high impulse-like force signals that can be harmful to the hardware and to the human operator. We propose a new approach to compensate position drift in TDPA-based teleoperation in a smoother way, which keeps the forces within the normal range of the teleoperation task while preserving the level of transparency and the robust stability of energy-based TDPA. We also add a way of tuning the compensator to behave in accordance with the task being performed, whether it requires faster or smoother compensation. The feasibility and performance of the method were experimentally validated. Good position tracking and regular-amplitude forces are demonstrated with up to 500 ms round-trip constant and variable delays for hard-wall contacts.
ER  - 

TY  - CONF
TI  - An Ungrounded Master Device for Tele-Microassembly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Sakr
AU  - T. Daunizeau
AU  - D. Reversat
AU  - S. Régnier
AU  - S. Haliyo
PY  - 2018
KW  - grippers
KW  - haptic interfaces
KW  - manipulator kinematics
KW  - microassembling
KW  - micromanipulators
KW  - position control
KW  - robotic assembly
KW  - telerobotics
KW  - velocity control
KW  - ungrounded master device
KW  - tele-microassembly
KW  - intuitive remote handling interface
KW  - portable instrumented tweezers
KW  - spatial motion
KW  - slave kinematics
KW  - slave robot
KW  - hand-held assembly tool
KW  - joystick-like interfaces
KW  - microgripper
KW  - haptic feedback
KW  - position variables
KW  - speed variables
KW  - Tracking
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Force
KW  - Tools
DO  - 10.1109/IROS.2018.8594063
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Micro-assembly is a challenging issue for automation due to particularities of micro-world physics and limitations on sensors. Consequently, most applications are human-operated often with basic joystick-like interfaces. Beside being nonintuitive, these solutions do not provide their users with a meaningful insight into the microworld. This paper proposes a novel intuitive remote handling interface, using a classical hand-held assembly tool as a paradigm. The master device is a portable instrumented tweezers with one active degree of freedom. Its spatial motion, tracked by optical means, controls the slave kinematics while its pinch commands the slave robot's microgripper and provides haptic feedback. Different coupling strategies using position or speed variables are demonstrated.
ER  - 

TY  - CONF
TI  - “Hammer: Robot Programming Interface for Common People”
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5539
EP  - 5539
AU  - A. Brunete
AU  - M. Hernando
AU  - E. Gambao
PY  - 2018
KW  - Android (operating system)
KW  - augmented reality
KW  - control engineering computing
KW  - industrial robots
KW  - production engineering computing
KW  - robot programming
KW  - user interfaces
KW  - visual programming
KW  - Hammer
KW  - robot programming interface
KW  - tablet-based end-user interface
KW  - industrial robot programming
KW  - Hephestos European project
KW  - Android application
KW  - Android OS
KW  - visual programming concept
KW  - online programming
KW  - reprogramming
KW  - robot control
KW  - manual-guidance interface
KW  - augmented-reality-based-monitoring system
KW  - scratch programming language
KW  - sensors systems
KW  - Service robots
KW  - Robot programming
KW  - Task analysis
KW  - Robot sensing systems
KW  - Intelligent robots
KW  - Industrial Robots
KW  - Human-Centered Robotics
KW  - Intelligent and Flexible Manufacturing
DO  - 10.1109/IROS.2018.8594453
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video shows the main features of Hammer, a tablet-based end-user interface for industrial robot programming, in a real environment: a robotic cell created for the Hephestos European project. Hammer is an Android application that makes easier to program tasks for industrial robots like polishing, milling or grinding. It is based on the Scratch programming language, but specifically design and created for Android OS. It is a visual programming concept that allows non-skilled operators to create programs. The application allows to monitor the tasks while it is being executed by overlapping real time information through augmented reality. The application includes a teach pendant screen that can be customized according to the operator needs at every moment. The application is designed for online programming and reprogramming; easy use of learn-by-demonstration methods; easy connection with the robot control and sensors systems; and safety-system integration. It aims to be intuitive, easy to use, and simple. The application has four main parts: customized teach pendant, robot programming IDE and simulator, manual-guidance interface and augmented-reality-based-monitoring system.
ER  - 

TY  - CONF
TI  - The Art of Manipulation: Learning to Manipulate Blindly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Haddadin
AU  - L. Johannsmeier
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - peg-in-hole problem
KW  - manipulation learning
KW  - human performance
KW  - robot manipulation
KW  - high-level manipulation planning
KW  - autonomous skill learning
KW  - inter-class generalization
KW  - insertion skills
KW  - human-level performance
KW  - manipulation strategies
KW  - basic motor control
KW  - Task analysis
KW  - Motor drives
KW  - Planning
KW  - Intelligent robots
KW  - Art
KW  - Bridges
DO  - 10.1109/IROS.2018.8593923
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Performing skillfull manipulation is a very challenging task for robots. So far, even experts could barely program them to e.g. perform the well known peg-in-hole problem in the real world. Autonomously acquiring such skills, let alone generalizing them to new tasks, is still a major challenge. Typically, manipulation learning is approached with the help of large computation power, very long learning times, or possibly both. However, the performance achieved up to now is still far from human performance. We show the results of our new paradigm to robot manipulation. It bridges and unifies basic motor control, simple and complex manipulation strategies and high-level manipulation planning. The robots show autonomous skill learning, intra-class and inter-class generalization of insertion skills at human-level performance.
ER  - 

TY  - CONF
TI  - Toward the Next Generation of Robotic Waiters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5541
EP  - 5541
AU  - L. Moriello
AU  - D. Chiaravalli
AU  - L. Biagiotti
AU  - C. Melchiorri
PY  - 2018
KW  - compensation
KW  - feedforward
KW  - manipulators
KW  - service robots
KW  - sloshing phenomena
KW  - orientation compensation
KW  - robotic waiters
KW  - feed-forward control
KW  - robot arm
KW  - feed-forward controller
KW  - motion capture system
KW  - robot manipulator
KW  - Glass
KW  - Manipulators
KW  - Intelligent robots
KW  - Next generation networking
KW  - Steel
KW  - Tracking
DO  - 10.1109/IROS.2018.8594475
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The gap between human waiters and state-of-the-art robot systems that try to serve something to drink is often embarrassing, with the former able to manipulate glasses and trays or glasses on trays with incredible dexterity and the latter that move at incredible slowness. In this video, we want to show that robots can do it better by moving a bottle or a tankard full of beer that are simply placed on a flat steel plate connected the flange of a robot manipulator. The robot tracks the trajectory defined by a human operator that moves its hand in the 3D space, with a motion capture system that acquires in real time the position. A feed-forward controller, placed between the user and the robot and based on the combination of a smoother and proper orientation compensation, counteracts the lateral accelerations and suppress sloshing phenomena of the liquids. Eventually a camera mounted on the robot arm provides a visual feedback to the operator with monitoring purposes. The challenge for the operator was to drop the carried object. will the feed-forward control be robust enough to avoid this event, even at high speed? Watch the video and find out!
ER  - 

TY  - CONF
TI  - Human-Robot-Cooperation Real Time Robot Path Planning for Dynamic HRC-Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5542
EP  - 5542
AU  - M. Bdiwi
AU  - S. Hou
AU  - K. Delang
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - collision optimization
KW  - real time robot path planning
KW  - dynamic obstacles
KW  - motion planning framework
KW  - pre-programmed robot paths
KW  - dynamic HRC-applications
KW  - human-robot-cooperation
KW  - unstructured environment
KW  - robot velocity
KW  - movement paths
KW  - free robot trajectories
KW  - framework plans
KW  - human-robot shared workspace
KW  - human obstacles
KW  - Robots
KW  - Collision avoidance
KW  - Real-time systems
KW  - Machine tools
KW  - Dynamics
KW  - Safety
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594014
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-Robot shared workspace is a dynamic and unstructured environment. In such environment, pre-programmed robot paths might cause collisions or production disruptions. In order to solve this problem, motion planning framework has been proposed that adapts the robot's movement (path and speed)according to the human movement or any other dynamic obstacles in real time. Firstly, it defines the safety distance between robot and human or other obstacles. During run-time the 3D-Smart-Sensors capture the current position of human and other dynamic/static obstacles in human-robot shared workspace. The proposed framework plans and optimizes collision free robot trajectories with consideration for safety distance, path length and executing time. Once a new optimal trajectory is found, the framework controls the robot to adjust its movement paths. Moreover, the proposed framework can adjust the robot velocity based on the 3D-Zone Model of human-robot shared workspace. Therefore, the robot can reach its goal quickly and safely in a dynamic and unstructured environment.
ER  - 

TY  - CONF
TI  - High Power Hand with Retention Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5543
EP  - 5543
AU  - T. Mouri
AU  - H. Kawasaki
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - disasters
KW  - motion control
KW  - plates (structures)
KW  - power system control
KW  - retention mechanism
KW  - electrical power supply
KW  - electrical power saving
KW  - high power hand
KW  - multifingered robot hand
KW  - power manipulation
KW  - dexterous motion
KW  - Robots
KW  - Thumb
KW  - Power supplies
KW  - Force
KW  - Mechanical engineering
KW  - Conferences
DO  - 10.1109/IROS.2018.8594216
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.
ER  - 

TY  - CONF
TI  - On-Chip Virtual Vortex Gear and Its Application
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5544
EP  - 5544
AU  - T. Takayama
AU  - C. Dylan Tsai
AU  - M. Kaneko
PY  - 2018
KW  - flow visualisation
KW  - microchannel flow
KW  - pattern formation
KW  - valves
KW  - vortices
KW  - VVG
KW  - controllable valve
KW  - microfluidic system
KW  - flow speed
KW  - flow energy
KW  - chemical injection
KW  - sheath flow
KW  - 3D flow patterns
KW  - On-Chip Virtual Vortex Gear
KW  - Reynolds number
KW  - parallel streamlines
KW  - circular chamber
KW  - target chamber
KW  - spontaneous diffusing
KW  - Gears
KW  - Valves
KW  - Chemicals
KW  - Mechanical engineering
KW  - Microfluidics
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593418
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video presents a microfluidic phenomenon called “Virtual Vortex Gear (VVG)” and an application of it. The video contains 4 parts and is described as follows: The 1st part shows an application of VVG as a controllable valve in a micro fluidic system and the on and off of the valve are controlled by different flow speeds. The valve is turned on when the flow speed is high enough, and vice versa. The 2nd part shows the generation of VVG and its mechanism. When the flow speed, which is proportional to Reynolds Number, is gradually increased, the flow pattern evolves in the order as (1)parallel streamlines, (2)one vortex, (3)two vortices and eventually (4)three vortices including the last vortex inside the circular chamber. The evolution indicates the transmission of flow energy from the main stream to the inside of the chamber when the flow speed is over a certain range. In addition, every two adjacent vortices rotate in opposite directions which is just like a set of gears, and that is why we named it “VVG”. In the 3rd part, an application of VVG for chemical injection is demonstrated. A colored liquid is represented for the chemical and is surrounded by different sheath flow for the control of injection locations. It is found that only the fluid in a particular pinpoint can be injected into the target chamber. Furthermore, the complex but stable 3D flow patterns are visualized from the video. The last part of the video shows that different amount of chemical injection can be performed in different chambers along the same main stream and the distribution of the color is gradually become uniform by spontaneous diffusing.
ER  - 

TY  - CONF
TI  - Deformation Capture via Self-Sensing Capacitive Arrays (Video)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5545
EP  - 5545
AU  - O. Glauser
AU  - D. Panozzo
AU  - O. Hilliges
AU  - O. Sorkine-Hornung
PY  - 2018
KW  - capacitance
KW  - capacitance measurement
KW  - capacitive sensors
KW  - computerised instrumentation
KW  - data acquisition
KW  - deformation
KW  - mesh generation
KW  - neural nets
KW  - deformation capture
KW  - soft self-sensing capacitive arrays
KW  - dense surface deformations
KW  - electrode patterns
KW  - single silicone compound
KW  - electrode strip patterns
KW  - local capacitors
KW  - local capacitance measurements change
KW  - fabrication technique
KW  - modern fablabs
KW  - resulting sensors
KW  - area changes
KW  - underlying motion
KW  - deep neural network
KW  - sensor geometry
KW  - local area measurements
KW  - motion capture system
KW  - runtime vertex positions
KW  - state-of-the-art elastic surface energy
KW  - prototype sensor
KW  - deforming skeletal
KW  - Robot sensing systems
KW  - Strain
KW  - Electrodes
KW  - Fabrication
KW  - Intelligent robots
KW  - Compounds
KW  - Capacitors
DO  - 10.1109/IROS.2018.8594203
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this video we present soft self-sensing capacitive arrays and demonstrate their use in capturing dense surface deformations without requiring line of sight. The capacitive arrays are made of two electrode patterns embedded into a single silicone compound. The overlaps of the electrode strip patterns form local capacitors. As the sensor is stretched the local capacitance measurements change. We introduce a fabrication technique that allows to produce such sensors while only requiring hardware readily available in modern fablabs. The resulting sensors are able to densely capture area changes as they deform. Since they do not directly measure bend, a prior is required to fully reconstruct the underlying motion. We propose a deep neural network regressing the sensor geometry from the local area measurements. A motion capture system is used for training data acquisition. At runtime vertex positions are predicted and used as positional constraints to deform a mesh using a state-of-the-art elastic surface energy. The flexibility and accuracy of the introduced sensors is demonstrated in a series of controlled experiments and by fabricating a prototype sensor and applying it to capture deforming skeletal and non-skeletal objects.
ER  - 

TY  - CONF
TI  - Excuse Me, May I Say Something? A Robot Facilitating Q&A for Lectures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5546
EP  - 5546
AU  - O. Palinko
AU  - J. Shimaya
AU  - K. Hoeck
AU  - K. Ogawa
AU  - N. Jinnai
AU  - Y. Yoshikawa
AU  - H. Ishiguro
PY  - 2018
KW  - computer aided instruction
KW  - humanoid robots
KW  - human-robot interaction
KW  - Internet
KW  - neural nets
KW  - young students
KW  - CommU
KW  - desktop social robot
KW  - online messaging system
KW  - robot facilitating Q&a
KW  - Hiroshi Ishiguro
KW  - Logic gates
KW  - Intelligent robots
KW  - Monitoring
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593656
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hiroshi Ishiguro gave a lecture to a group of young students. We employed CommU, the desktop social robot, to manage the questions and answers for the talk. We encouraged the students to ask questions anytime. Half of the classroom was told to ask questions by raising their hand while the other half was shown an online messaging system developed for CommU, which allows the audience to post questions, which the robot would directly say. We had a gatekeeper to monitor for invalid sentences. In the middle of the presentation we asked the students to shift roles. The robot used a neural network based estimator of interruptibility to find the best time to speak. We did not expect too many questions, but the audience really embraced using the robot. They posted 44 questions to the presenter through CommU. On the other hand they asked 8 direct questions by raising their hands and standing up. Students thought that they gained more information from the lecturer using the robot than using the conventional method. In this instance we didnt stop the students from asking too many questions, but in a real-world application the gatekeeper will have to play an important role.
ER  - 

TY  - CONF
TI  - Towards Autonomous Auto Calibration of Unregistered RGB-D Setups: The Benefit of Plane Priors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5547
EP  - 5554
AU  - G. Halmetschlager-Funek
AU  - J. Prankl
AU  - M. Vincze
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - optimisation
KW  - spatial variables measurement
KW  - autonomous autocalibration
KW  - color sensor
KW  - depth sensor
KW  - camera system
KW  - structure from motion reconstructions
KW  - SfM reconstructions
KW  - optimization
KW  - robust calibration algorithm
KW  - robot perception
KW  - unregistered RGB-D setups
KW  - Calibration
KW  - Cameras
KW  - Sensors
KW  - Robots
KW  - Image color analysis
KW  - Image reconstruction
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593715
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the last few years novel color and depth (RGB-D) sensors have greatly pushed robot perception. To enable a precise pixel-wise fusion of color and depth information good calibration is needed. The calibration determines the intrinsic parameters, the extrinsic parameters, and corrects for depth errors. While classic calibration approaches involve a dedicated calibration target and a trained expert, the autonomous calibration of such camera systems for robots operating in unknown environments is still an open problem. It demands for robust methods that do not need an expert to set up or tune the algorithm. Hence, we present a robust calibration algorithm that utilizes structure from motion (SfM) reconstructions as a calibration target and incorporates plane priors in the optimization to improve the convergence behavior and improve the calibration robustness. We evaluate our method against the state of the art performing over 300 experiments on ten different datasets, and show a significant improvement of the calibration accuracy.
ER  - 

TY  - CONF
TI  - Adaptive Sensor Bias Estimation in Nine Degree of Freedom Inertial Measurement Units: Theory and Preliminary Evaluation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5555
EP  - 5561
AU  - A. R. Spielvogel
AU  - L. L. Whitcomb
PY  - 2018
KW  - angular measurement
KW  - attitude measurement
KW  - calibration
KW  - gyroscopes
KW  - inertial systems
KW  - magnetic field measurement
KW  - magnetic sensors
KW  - magnetometers
KW  - adaptive sensor bias estimation
KW  - three-axis magnetometers
KW  - three-axis accelerometers
KW  - three-axis angular rate sensors
KW  - high-end angular rate sensors
KW  - ring-laser gyros
KW  - MEMS gyros
KW  - compensation
KW  - attitude estimation
KW  - attitude and heading reference systems
KW  - nine degree of freedom inertial measurement units
KW  - sensor bias calibration methods
KW  - adaptive sensor bias observer
KW  - magnetic-north AHRS heading
KW  - DOF inertial measurement units
KW  - true-North heading AHRS estimation
KW  - Earth-rate estimation
KW  - 9-DOF IMU measurements
KW  - Robot sensing systems
KW  - Magnetometers
KW  - Instruments
KW  - Accelerometers
KW  - Observers
KW  - Gyroscopes
DO  - 10.1109/IROS.2018.8594439
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nine degrees of freedom (DOF) inertial measurement units (IMUs) comprised of three-axis magnetometers, three-axis accelerometers, and three-axis angular rate sensors are commonly used in attitude and heading reference systems (AHRSs). Two classes of AHRSs exist: systems that estimate true-North heading and systems that estimate magnetic-North heading. True-North heading AHRSs require high-end angular rate sensors which are sensitive enough to dynamically estimate Earth-rate (typically fiber-optic and ring-laser gyros), while magnetic-North AHRSs employ gyros that are not sensitive enough to dynamically estimate Earth-rate (i.e. all MEMS gyros). Thus, magnetic-North AHRSs employ magnetometers for estimating heading. This paper will focus on this class of magnetic-North AHRSs. These systems fuse IMU measurements to generate estimates of the instrument's roll, pitch, and magnetic heading. However, their accuracy is limited by sensor measurement bias that is unknown a priori. Hence, accurate sensor bias estimation and compensation is essential for true attitude estimation. This paper reports a novel adaptive sensor bias observer for sensor measurement biases in 9-DOF IMUs. The algorithm requires smaller angular movements of the instrument than other reported sensor bias calibration methods, does not require a priori knowledge of local fields like the local magnetic field or the local gravity vector, and does not require knowledge of the attitude of the instrument. Stability proofs, preliminary simulations, and a full-scale vehicle experimental evaluation are reported.
ER  - 

TY  - CONF
TI  - Automatic Extrinsic Calibration of a Camera and a 3D LiDAR Using Line and Plane Correspondences
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5562
EP  - 5569
AU  - L. Zhou
AU  - Z. Li
AU  - M. Kaess
PY  - 2018
KW  - calibration
KW  - cameras
KW  - measurement errors
KW  - optical radar
KW  - optical sensors
KW  - checkerboard
KW  - 3D light detection and ranging sensor
KW  - 3D line correspondences
KW  - 3D plane correspondences
KW  - measurement errors
KW  - plane-only algorithms
KW  - LiDAR measurement
KW  - LiDAR intrinsic scale factor
KW  - calibration process
KW  - laser points
KW  - parallel planar targets
KW  - automatic extrinsic calibration
KW  - Cameras
KW  - Laser radar
KW  - Calibration
KW  - Three-dimensional displays
KW  - Lasers
KW  - Robot vision systems
KW  - Approximation algorithms
DO  - 10.1109/IROS.2018.8593660
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we address the problem of extrinsic calibration of a camera and a 3D Light Detection and Ranging (LiDAR) sensor using a checkerboard. Unlike previous works which require at least three checkerboard poses, our algorithm reduces the minimal number of poses to one by combining 3D line and plane correspondences. Besides, we prove that parallel planar targets with parallel boundaries provide the same constraints in our algorithm. This allows us to place the checkerboard close to the LiDAR so that the laser points better approximate the target boundary without loss of generality. Moreover, we present an algorithm to estimate the similarity transformation between the LiDAR and the camera for the applications where only the correspondences between laser points and pixels are concerned. Using a similarity transformation can simplify the calibration process since the physical size of the checkerboard is not needed. Meanwhile, estimating the scale can yield a more accurate result due to the inevitable measurement errors of the checkerboard size and the LiDAR intrinsic scale factor that transforms the LiDAR measurement to the metric measurement. Our algorithm is validated through simulations and experiments. Compared to the plane-only algorithms, our algorithm can obtain more accurate result by fewer number of poses. This is beneficial to the large-scale commercial application.
ER  - 

TY  - CONF
TI  - SCALAR - Simultaneous Calibration of 2D Laser and Robot's Kinematic Parameters Using Three Planar Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5570
EP  - 5575
AU  - T. S. Lembono
AU  - F. Suárez-Ruiz
AU  - Q. Pham
PY  - 2018
KW  - calibration
KW  - industrial robots
KW  - laser ranging
KW  - position control
KW  - robot kinematics
KW  - calibration approaches
KW  - calibration parameters
KW  - geometric planar constraints
KW  - 2D Laser Range Finder
KW  - 6-DoF robot
KW  - calibration method
KW  - laser tracker
KW  - expensive external measurement system
KW  - calibrations
KW  - robot accuracy
KW  - industrial robots
KW  - kinematic parameters
KW  - simultaneous calibration
KW  - SCALAR
KW  - robot system
KW  - Robot kinematics
KW  - Calibration
KW  - Cameras
KW  - Measurement by laser beam
KW  - Kinematics
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8594073
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Industrial robots are increasingly used in various applications where the robot accuracy becomes very important, hence calibrations of the robot's kinematic parameters and the measurement system's extrinsic parameters are required. However, the existing calibration approaches are either too cumbersome or require another expensive external measurement system such as laser tracker or measurement spinarm. In this paper, we propose SCALAR, a calibration method to simultaneously improve the kinematic parameters of a 6-DoF robot and the extrinsic parameters of a 2D Laser Range Finder (LRF) that is attached to the robot. Three flat planes are placed around the robot, and for each plane the robot moves to several poses such that the LRF's ray intersect the respective plane. Geometric planar constraints are then used to optimize the calibration parameters using Levenberg-Marquardt nonlinear optimization algorithm. We demonstrate through simulations that SCALAR can reduce the average position and orientation errors of the robot system from 14.6 mm and 4.05° to 0.09 mm and 0.02°.
ER  - 

TY  - CONF
TI  - Keyframe-Based Photometric Online Calibration and Color Correction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Quenzel
AU  - J. Horn
AU  - S. Houben
AU  - S. Behnke
PY  - 2018
KW  - calibration
KW  - cameras
KW  - computer vision
KW  - image colour analysis
KW  - image motion analysis
KW  - image texture
KW  - photometry
KW  - pose estimation
KW  - splines (mathematics)
KW  - exposure estimation
KW  - thin plate splines
KW  - meshing algorithms
KW  - camera view poses estimation
KW  - sparse visual SLAM
KW  - gamma curve
KW  - structure-from-motion system
KW  - textured meshes
KW  - camera response function
KW  - sparsely sampled scene points
KW  - sixth-order polynomial
KW  - TPS
KW  - camera view
KW  - illumination
KW  - uniformly illuminated surfaces
KW  - global-shutter color cameras
KW  - real-time online vignetting
KW  - constant intensity
KW  - photoconsistency
KW  - computer vision algorithms
KW  - vignetting function
KW  - color correction
KW  - keyframe-based photometric online calibration
KW  - Cameras
KW  - Calibration
KW  - Splines (mathematics)
KW  - Image color analysis
KW  - Lighting
KW  - Estimation
KW  - Visualization
DO  - 10.1109/IROS.2018.8593595
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Finding the parameters of a vignetting function for a camera currently involves the acquisition of several images in a given scene under very controlled lighting conditions, a cumbersome and error-prone task where the end result can only be confirmed visually. Many computer vision algorithms assume photoconsistency, constant intensity between scene points in different images, and tend to perform poorly if this assumption is violated. We present a real-time online vignetting and response calibration with additional exposure estimation for global-shutter color cameras. Our method does not require uniformly illuminated surfaces, known texture or specific geometry. The only assumptions are that the camera is moving, the illumination is static and reflections are Lambertian. Our method estimates the camera view poses by sparse visual SLAM and models the vignetting function by a small number of thin plate splines (TPS) together with a sixth-order polynomial to provide a dense estimation of attenuation from sparsely sampled scene points. The camera response function (CRF) is jointly modeled by a TPS and a Gamma curve. We evaluate our approach on synthetic datasets and in real-world scenarios with reference data from a Structure-from-Motion (SfM) system. We show clear visual improvement on textured meshes without the need for extensive meshing algorithms. A useful calibration is obtained from a few keyframes which makes an on-the-fly deployment conceivable.
ER  - 

TY  - CONF
TI  - Automatic Calibration of Multiple Cameras and Depth Sensors with a Spherical Target
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Kümmerle
AU  - T. Kühner
AU  - M. Lauer
PY  - 2018
KW  - calibration
KW  - cameras
KW  - sensor fusion
KW  - spatial variables measurement
KW  - automatic calibration
KW  - multisensor calibration
KW  - spherical calibration target
KW  - subresolution detection accuracy
KW  - camera
KW  - depth sensor
KW  - Calibration
KW  - Cameras
KW  - Image edge detection
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Detectors
DO  - 10.1109/IROS.2018.8593955
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we present a novel approach for multi-sensor calibration that significantly outperforms current state-of-the-art. We introduce a new spherical calibration target which has major benefits over existing targets. Those are subresolution detection accuracy in both camera and depth sensor, view invariance and applicability to a wider range of sensor setups than current approaches. With our method a single person achieves high quality calibration in less than a minute. No preparations for setting up the environment for calibration is needed. Our method is fast, easy to use and fully automatic. We evaluate our method in simulation and show high accuracy with an error of less than 3mm in translation and 0.1 0 in rotation on real data.
ER  - 

TY  - CONF
TI  - Automated Tool Coordinate Calibration System of an Industrial Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5592
EP  - 5597
AU  - R. C. Luo
AU  - H. Wang
PY  - 2018
KW  - artificial intelligence
KW  - calibration
KW  - cameras
KW  - computer vision
KW  - error compensation
KW  - industrial manipulators
KW  - industrial robots
KW  - machine tools
KW  - neural nets
KW  - position control
KW  - production engineering computing
KW  - robot vision
KW  - tool calibration
KW  - automated tool
KW  - freight handling
KW  - tool replacement
KW  - collision accident
KW  - routine maintenance
KW  - tool coordinates
KW  - current industrial practices
KW  - artificial intelligence method
KW  - manual method
KW  - system independent method
KW  - automatic calibration
KW  - hand camera
KW  - tool position data
KW  - coordinate system conversion
KW  - calibration system functions
KW  - current robot
KW  - 6-degree-0f-freedom industrial robot
KW  - optimal deep neural network method error compensation
KW  - Tools
KW  - Robot kinematics
KW  - Cameras
KW  - Calibration
KW  - Service robots
KW  - Robot vision systems
KW  - Calibration
KW  - Tool Coordinate
KW  - CamShift
KW  - MeanShift
KW  - DNN
DO  - 10.1109/IROS.2018.8594298
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Due to the widespread use of industrial robots in market, its application has extended to welding, painting, and freight handling. And tool coordinate calibration is regularly modified after tool replacement due to collision accident or routine maintenance. After tool replacement, operators often rebuild tool coordinates. This is the traditional mode of operation in the current industrial practices. However, smart factory will make artificial intelligence method replace manual method. This paper presents a system independent method for automatic calibration of the tool coordinate system which is faster, simpler, cheaper and more effective than the manual method. The proposed method required images to be captured using two “eye to hand” cameras and one “eye in hand” camera. Tool position data is then acquired through CamShift and MeanShift algorithm for image trajectory tracking along with coordinate system conversion, several methods like PCA, LDA can deal with the vision data. Optimal Deep Neural Network (DNN) method error compensation of a robot allows the tool to automatically run with the calibration system functions. We have developed a 6 degrees of freedom(DoF) industrial robot for this experiment. Nine different kinds of DNN models are built and finally with suitable tool coordinate error compensation for the current robot, tool calibration can be achieved adaptively and efficiently.
ER  - 


TY  - CONF
TI  - Robust Optimization-Based Calculation of Invariant Trajectory Representations for Point and Rigid-body Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5598
EP  - 5605
AU  - M. Vochten
AU  - T. De Laet
AU  - J. De Schutter
PY  - 2018
KW  - image motion analysis
KW  - image recognition
KW  - image reconstruction
KW  - image representation
KW  - optimisation
KW  - smoothing methods
KW  - standard smoothing methods
KW  - measurement noise
KW  - motion trajectories
KW  - robust optimization-based calculation
KW  - invariant trajectory representations
KW  - motion experiments
KW  - motion recognition
KW  - context-independent motion models
KW  - rigid-body motion
KW  - Trajectory
KW  - Sensitivity
KW  - Smoothing methods
KW  - Context modeling
KW  - Fasteners
KW  - Noise measurement
KW  - Programming
DO  - 10.1109/IROS.2018.8593540
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Invariant representations of demonstrated motion trajectories provide context-independent motion models that can be used in motion recognition and generalization applications such as robot programming by demonstration. In practice, the use of invariant representations is still limited because their numerical calculation from a demonstrated trajectory is complicated by sensitivity to measurement noise and singularities, yielding inaccurate invariant functions that do not correspond well with the original trajectory. This paper improves the calculation of invariant representations for point and rigid-body motions by reformulating their calculation as an optimization problem that minimizes the error between the trajectory reconstructed from the invariant representation and the measured trajectory. Robustness against noise and singularities is ensured through the addition of regularization terms on the invariants. Simulations and real motion experiments show that the accuracy of the calculated invariant representations greatly improves with respect to standard smoothing methods. These results encourage future developments of motion recognition and generalization applications based on invariant trajectory representations.
ER  - 

TY  - CONF
TI  - Reducing the Computational Complexity of Mass-Matrix Calculation for High DOF Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5614
EP  - 5619
AU  - M. Safeea
AU  - R. Bearee
AU  - P. Neto
PY  - 2018
KW  - computational complexity
KW  - manipulator dynamics
KW  - matrix algebra
KW  - position control
KW  - high DOF robots
KW  - geometric dynamics algorithm for high number of robot joints
KW  - GDAHJ
KW  - JSIM
KW  - joint space inertia matrix
KW  - dynamics computations
KW  - degrees of freedom
KW  - mass-matrix calculation
KW  - computational complexity
KW  - Acceleration
KW  - Mathematical model
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Dynamics
KW  - Computational complexity
KW  - mass-matrix
KW  - dynamics
KW  - Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ)
KW  - high DOF robots
DO  - 10.1109/IROS.2018.8593775
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Increasingly, robots have more degrees of freedom (DOF), imposing a need for calculating more complex dynamics. As a result, better efficiency in carrying out dynamics computations is becoming more important. In this study, an efficient method for computing the joint space inertia matrix (JSIM) for high DOF serially linked robots is addressed. We call this method the Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ). GDAHJ is non-symbolic, preserve simple formulation, and it is convenient for numerical implementation. This is achieved by simplifying the way to recursively derive the mass-matrix exploiting the unique property of each column of the JSIM and minimizing the number of operations with O(n2) complexity. Results compare favorably with existing methods, achieving better performance over state-of-the-art by Featherstone when applied for robots with more than 13 DOF.
ER  - 

TY  - CONF
TI  - Position-Based Time-Integrator for Frictional Articulated Body Dynamics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - Z. Pan
AU  - D. Manocha
PY  - 2018
KW  - friction
KW  - graphics processing units
KW  - Newton method
KW  - optimisation
KW  - robot dynamics
KW  - Newton-Euler-based simulator
KW  - Newton-type optimization scheme
KW  - friction forces
KW  - position variables
KW  - frictional dynamics
KW  - frictional articulated body dynamics
KW  - position-based time-integrator
KW  - Mathematical model
KW  - Friction
KW  - Dynamics
KW  - Heuristic algorithms
KW  - Optimization
KW  - Linear programming
KW  - Robots
DO  - 10.1109/IROS.2018.8593817
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a new time-integrator for modeling the frictional dynamics of articulated bodies. Our formulation represents the configuration of the articulated body using position variables and then uses those variables to model the friction forces between the articulated body and the environment. Our approach corresponds to a Newton-type optimization scheme that is guaranteed to converge so that it is stable with large timestep sizes. We evaluate the accuracy and stability of our time-integrator by comparing it with a conventional formulations based on the Newton-Euler equation and demonstrate the benefits on standard controller-optimization applications. We achieve 3-5 times speedup over a Newton-Euler-based simulator on a CPU. Our approach can be easily parallelized on a GPU and results in additional 4-15 times performance improvement.
ER  - 

TY  - CONF
TI  - Hydrodynamics Parameter Identification of Submerged Bodies: Numerical Methods Comparison and Friction Model Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5628
EP  - 5633
AU  - N. Gartner
AU  - M. Richier
AU  - V. Hugel
PY  - 2018
KW  - friction
KW  - hydrodynamics
KW  - integration
KW  - numerical analysis
KW  - parameter estimation
KW  - pendulums
KW  - hydrodynamics parameter
KW  - numerical methods
KW  - friction model analysis
KW  - free decay pendulum
KW  - single friction coefficient
KW  - numerical integration method
KW  - dynamical model
KW  - estimation methods
KW  - quadratic friction coefficients
KW  - submerged bodies
KW  - Hydrodynamics
KW  - Friction
KW  - Numerical models
KW  - Damping
KW  - Acceleration
KW  - Cutoff frequency
KW  - Estimation
DO  - 10.1109/IROS.2018.8593770
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper focuses on numerical methods that can be used to identify hydrodynamic parameters of submerged bodies, namely added mass, linear and quadratic friction coefficients. The mechanical setup is a free decay pendulum that is equipped with an encoder. The first contribution of this paper deals with the comparison of two estimation methods: one method that fits the acceleration of the dynamical model with the acceleration obtained from derivatives of the measured angular position, and another method that fits this position with the angle obtained by numerical integration. The second contribution consists of investigating to what extent estimated added mass and friction coefficient parameters of the dynamical model match the empirical or theoretical values in the case of a spherical object. The results obtained show that the numerical integration method allows to determine the added mass with a good accuracy and a single friction coefficient could be used for the dynamic model without loosing validity.
ER  - 

TY  - CONF
TI  - Actuator and Friction Dynamics Formulation in Control of PKMs: From Design to Real-Time Experiments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5634
EP  - 5639
AU  - H. Saied
AU  - A. Chemori
AU  - M. E. Rafei
AU  - C. Francis
AU  - F. Pierret
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - feedforward
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - position control
KW  - real-time experiments
KW  - dynamic formulation
KW  - parallel manipulators
KW  - actuator
KW  - friction dynamics
KW  - model-based controller
KW  - computed feedforward
KW  - formulated dynamics
KW  - control performance
KW  - high-speed motions
KW  - feedforward part
KW  - computational efforts
KW  - PKM
KW  - four-degree-of-freedom parallel robot
KW  - unfavourable nonlinearity abundant extensively
KW  - Friction
KW  - Actuators
KW  - Dynamics
KW  - Manipulator dynamics
KW  - Computational modeling
KW  - Torque
DO  - 10.1109/IROS.2018.8594329
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper deals with a new dynamic formulation of parallel manipulators incorporating the actuator and friction dynamics to be utilized in control. A model-based controller, PD with computed feedforward, is implemented for a parallel robot taking into consideration the formulated dynamics. The motivation behind this contribution is to enhance the control performance by compensating the unfavourable nonlinearities abundant extensively in PKMs. Those nonlinearities may increase considerably when operating at high-speed motions. The proposed feedforward part relies on the reference trajectories instead of the measured ones improving the control performance and the computational efforts. To validate our contribution, real-time experiments are conducted on a four degree-of-freedom parallel robot named VELOCE in different operating conditions.
ER  - 

TY  - CONF
TI  - A Robust Time-Stepping Scheme for Quasistatic Rigid Multibody Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5640
EP  - 5647
AU  - T. Pang
AU  - R. Tedrake
PY  - 2018
KW  - grippers
KW  - integer programming
KW  - manipulator kinematics
KW  - quadratic programming
KW  - robust control
KW  - torque
KW  - robust time-stepping scheme
KW  - quasistatic rigid multibody systems
KW  - quasistatic physics
KW  - linear complementarity problems
KW  - grasping velocity command
KW  - small-to-medium-sized systems
KW  - manipulation
KW  - motion primitive
KW  - LCP
KW  - optimization problem
KW  - mixed-integer quadratic program
KW  - torque
KW  - Grippers
KW  - Friction
KW  - Force
KW  - Kinematics
KW  - Grasping
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594378
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An effective scheme to simulate low-speed, contact-rich manipulation tasks is to assume quasistatic physics and advance system states by solving linear complementarity problems (LCPs). However, the existing LCP-based quasistatic time-stepping scheme fails to simulate grasping-an essential motion primitive in manipulation-due to two drawbacks specific to quasistatic systems. Firstly, inputs to quasistatic systems are velocity commands instead of torques. This can lead to penetration, and thus an infeasible LCP, when two rigid bodies in contact are commanded to push against each other. Secondly, as multiple force solutions exist for a given velocity command, a grasping velocity command is not guaranteed to generate sufficient grasping forces. In this paper, we reformulate the quasistatic time-stepping scheme as an optimization problem with complementarity constraints and a quadratic objective. By minimizing the difference between actual and commanded velocities, linearized non-penetration constraints can always be satisfied. Moreover, undesirable solutions with insufficient normal forces can be removed by considering elasticity, which is modeled by comparing actual and commanded velocities. The resulting optimization problem is a mixed-integer quadratic program, which can be solved reasonably quickly for small-to-medium-sized systems. The effectiveness of the proposed reformulation is validated by simulation results of systems with different levels of complexity.
ER  - 

TY  - CONF
TI  - Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5648
EP  - 5653
AU  - M. Wang
AU  - D. Palmer
AU  - X. Dong
AU  - D. Alatorre
AU  - D. Axinte
AU  - A. Norton
PY  - 2018
KW  - aerodynamics
KW  - aircraft maintenance
KW  - end effectors
KW  - industrial robots
KW  - inspection
KW  - mechatronics
KW  - suspensions (mechanical components)
KW  - slender dual-structure continuum robot
KW  - In-Situ Aeroengine Repair
KW  - in-situ aeroengine maintenance works
KW  - end-effector
KW  - aeroengine combustion chamber
KW  - configuration-cable kinematics
KW  - Maintenance engineering
KW  - Kinematics
KW  - Inspection
KW  - Shape
KW  - End effectors
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594142
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.
ER  - 

TY  - CONF
TI  - Reasoning Systems for Semantic Navigation in Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5654
EP  - 5659
AU  - J. Crespo
AU  - R. Barber
AU  - O. M. Mozos
AU  - D. BeBler
AU  - M. Beetz
PY  - 2018
KW  - control engineering computing
KW  - inference mechanisms
KW  - mobile robots
KW  - navigation
KW  - ontologies (artificial intelligence)
KW  - path planning
KW  - semantic navigation paradigm
KW  - mobile robot
KW  - environmental semantic concepts
KW  - ontological model
KW  - KnowRob
KW  - relational database
KW  - reasoning system
KW  - semantic representation
KW  - semantic navigation system
KW  - Navigation
KW  - Ontologies
KW  - Semantics
KW  - Cognition
KW  - Mobile robots
KW  - Relational databases
DO  - 10.1109/IROS.2018.8594271
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.
ER  - 

TY  - CONF
TI  - Hybrid Approach for Human Activity Recognition by Ubiquitous Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5660
EP  - 5665
AU  - R. Mojarad
AU  - F. Attal
AU  - A. Chibani
AU  - S. R. Fiorini
AU  - Y. Amirat
PY  - 2018
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - ontologies (artificial intelligence)
KW  - ubiquitous computing
KW  - human activity recognition
KW  - ubiquitous robots
KW  - context-aware intelligent services
KW  - humans
KW  - professional living activities
KW  - daily living activities
KW  - consistent description
KW  - correct description
KW  - human context
KW  - Ontologies
KW  - Activity recognition
KW  - Machine learning
KW  - Dairy products
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594173
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the main objectives of ubiquitous robots is to proactively provide context-aware intelligent services to assist humans in their professional or daily living activities. One of the main challenges is how to automatically obtain a consistent and correct description of human context such as location, activities, emotions, etc. In this paper, a new hybrid approach for reasoning on the context is proposed. This approach focuses on human activity recognition and consists of machine-learning algorithms, an expressive ontology representation, and a reasoning system. The latter allows detecting the inconsistencies that may appear during the machine learning phase. The proposed approach can also correct automatically these inconsistencies by considering the context of the ongoing activity. The obtained results on the Opportunity dataset demonstrate the feasibility of the proposed method to enhance the performance of human activity recognition.
ER  - 

TY  - CONF
TI  - Approaches for Action Sequence Representation in Robotics: A Review
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5666
EP  - 5671
AU  - H. Nakawala
AU  - P. J. S. Goncalves
AU  - P. Fiorini
AU  - G. Ferringo
AU  - E. D. Momi
PY  - 2018
KW  - reviews
KW  - robots
KW  - robotics
KW  - action sequences representation
KW  - robots
KW  - action sequence representation
KW  - complex robotic tasks
KW  - robot task
KW  - Task analysis
KW  - Planning
KW  - Calculus
KW  - Strips
KW  - Service robots
KW  - Proposals
DO  - 10.1109/IROS.2018.8594256
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust representation of actions and its sequences for complex robotic tasks would transform robot's understanding to execute robotic tasks efficiently. The challenge is to understand action sequences for highly unstructured environments and to represent and construct action and action sequences. In this manuscript, we present a review of literature dealing with representation of action and action sequences for robot task planning and execution. The methodological review was conducted using Google Scholar and IEEE Xplore, searching the specific keywords. This manuscript gives an overview of current approaches for representing action sequences in robotics. We propose a classification of different methodologies used for action sequences representation and describe the most important aspects of the reviewed publications. This review allows the reader to understand several options that do exist in the research community, to represent and deploy such action representations in real robots.
ER  - 

TY  - CONF
TI  - Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5672
EP  - 5678
AU  - E. A. Topp
AU  - M. Stenmark
AU  - A. Ganslandt
AU  - A. Svensson
AU  - M. Haage
AU  - J. Malec
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - ontologies (artificial intelligence)
KW  - production engineering computing
KW  - robot programming
KW  - ontology-based knowledge representation
KW  - dual-arm robotic system
KW  - industrial applications
KW  - end-user programming
KW  - robot arms
KW  - intuitive programming
KW  - task transfer
KW  - kinematics
KW  - robot-agnostic skills
KW  - industrial robots skill reusability
KW  - Robot kinematics
KW  - Synchronization
KW  - Service robots
KW  - Ontologies
KW  - Manipulators
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593566
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We assume that an intuitive means for the specification, re-use, modification and transfer of synchronized motions-both regarding the two arms of a dual-arm robotic system, as well as regarding the coordination of a user and a robot-is key in interactive and collaborative settings as they are currently targeted for industrial applications. We show, how our knowledge based approach to end-user programming of synchronized motions and other generalizable, robot-agnostic skills can support such specification of coordinated actions between two robot arms and explain how that could be extended to include coordination with a human user. We describe the underlying ontologies and possibilities to populate those with an interface for intuitive programming, and show the generality of our approach through a task transfer between different kinematics (different robots), where the user is supported through underlying reasoning about the fulfillment of certain parameters or constraints for the involved skills.
ER  - 

TY  - CONF
TI  - Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5679
EP  - 5684
AU  - F. Ramos
AU  - C. O. Scrob
AU  - A. S. Vázquez
AU  - R. Fernández
AU  - A. Olivares-Alarcos
PY  - 2018
KW  - control engineering computing
KW  - ontologies (artificial intelligence)
KW  - robots
KW  - ontology
KW  - robotic skills
KW  - structural part
KW  - base configuration
KW  - abstract structure
KW  - modular robotic platform
KW  - skill-oriented designer
KW  - conceptual robotic structures
KW  - Robot sensing systems
KW  - Ontologies
KW  - Legged locomotion
KW  - Semantics
KW  - Taxonomy
KW  - Morphology
DO  - 10.1109/IROS.2018.8593856
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.
ER  - 

TY  - CONF
TI  - Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5685
EP  - 5690
AU  - J. J. Fernández-Lozano
AU  - A. Mandow
AU  - M. Martín-Guzmán
AU  - J. Martín-Ávila
AU  - J. Serón
AU  - J. L. Martínez
AU  - J. A. Gornez-Ruiz
AU  - C. Socarras-Bertiz
AU  - J. Miranda-Páez
AU  - A. García-Cerezo
PY  - 2018
KW  - disasters
KW  - emergency management
KW  - emergency services
KW  - multi-agent systems
KW  - rescue robots
KW  - wireless sensor networks
KW  - search and rescue missions
KW  - wireless sensor networks
KW  - robots
KW  - mobile node
KW  - heterogeneous agents
KW  - multiagent team
KW  - natural disasters
KW  - human disasters
KW  - emergency response
KW  - information gathering
KW  - wireless sensor network
KW  - canine agent
KW  - Dogs
KW  - Wireless sensor networks
KW  - Receivers
KW  - Mobile nodes
KW  - Transmitters
KW  - Databases
DO  - 10.1109/IROS.2018.8593849
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.
ER  - 

TY  - CONF
TI  - Any-Time Trajectory Planning for Safe Emergency Landing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5691
EP  - 5696
AU  - P. Váňa
AU  - J. Sláma
AU  - J. Faigl
AU  - P. Pačes
PY  - 2018
KW  - aerospace components
KW  - aerospace engineering
KW  - aircraft control
KW  - aircraft landing guidance
KW  - path planning
KW  - trajectory control
KW  - landing site selection
KW  - safest emergency landing trajectory
KW  - multiple landing sites
KW  - any-time property
KW  - time trajectory planning
KW  - safe emergency landing
KW  - critical situation
KW  - human pilots
KW  - landing trajectories
KW  - aircraft
KW  - Trajectory
KW  - Aircraft
KW  - Planning
KW  - Turning
KW  - Drag
KW  - Atmospheric modeling
KW  - Force
DO  - 10.1109/IROS.2018.8594225
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Loss of thrust is a critical situation for human pilots of fixed-wing aircraft which force them to select a landing site in the nearby range and perform an emergency landing. The time for the landing site selection is limited by the actual altitude of the aircraft, and it may be fatal if the correct decision is not chosen fast enough. Therefore, we propose a novel RRT* -based planning algorithm for finding the safest emergency landing trajectory towards a given set of possible landing sites. Multiple landing sites are evaluated simultaneously during the flight even before any mechanical issue occurs, and the roadmap of possible landing trajectories is updated permanently. Thus, the proposed algorithm has the any-time property and provides the best emergency landing trajectory almost instantly.
ER  - 

TY  - CONF
TI  - PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - I. Brand
AU  - J. Roy
AU  - A. Ray
AU  - J. Oberlin
AU  - S. Oberlix
PY  - 2018
KW  - aerospace robotics
KW  - cameras
KW  - computer aided instruction
KW  - control engineering education
KW  - educational courses
KW  - mobile robots
KW  - Python
KW  - remotely operated vehicles
KW  - robot programming
KW  - robot vision
KW  - state estimation
KW  - three-term control
KW  - high-level planning
KW  - PiDrone
KW  - autonomous educational drone
KW  - Python
KW  - compelling robotics course
KW  - low-cost aerial educational platform
KW  - associated college-level introductory robotics course
KW  - autonomous aircraft
KW  - downward facing RGB camera
KW  - distance sensor
KW  - onboard Raspberry Pi
KW  - accessible platform
KW  - inexpensive platform
KW  - SSH capable computer
KW  - base station
KW  - programming platform
KW  - robotics operating system framework
KW  - ROS framework
KW  - PID control
KW  - state estimation
KW  - Drones
KW  - Educational robots
KW  - Robot sensing systems
KW  - Python
KW  - Service robots
KW  - Hardware
DO  - 10.1109/IROS.2018.8593943
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.
ER  - 

TY  - CONF
TI  - State Estimate Recovery for Autonomous Quadcopters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - L. Beffa
AU  - A. Ledergerber
AU  - R. D'Andrea
PY  - 2018
KW  - acceleration measurement
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - channel bank filters
KW  - helicopters
KW  - Kalman filters
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - state estimate recovery
KW  - autonomous quadcopters
KW  - aerodynamic force model
KW  - extended Kalman filters
KW  - linear acceleration measurements
KW  - complete recovery logic
KW  - quadcopter platform
KW  - IMU
KW  - Aerodynamics
KW  - Gravity
KW  - Mathematical model
KW  - Accelerometers
KW  - Propellers
KW  - Data models
KW  - Position measurement
DO  - 10.1109/IROS.2018.8594332
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A method for recovery from the complete loss of the state estimate is presented for autonomous quadcopters. Given an aerodynamic force model, the only measurements used to reinitialize the state estimate by means of a bank of extended Kalman filters are the angular rate and linear acceleration measurements of an IMU. The method is integrated within a complete recovery logic on a quadcopter platform and experimentally evaluated.
ER  - 

TY  - CONF
TI  - A Revisited Approach to Lateral Acceleration Modeling for Quadrotor UAVs State Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5711
EP  - 5718
AU  - D. Sartori
AU  - D. Zou
AU  - L. Pei
AU  - W. Yu
PY  - 2018
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - blades
KW  - drag
KW  - helicopters
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - lateral acceleration modeling
KW  - quadrotor UAVs state estimation
KW  - rotors angular speeds
KW  - quadrotor drag
KW  - lateral accelerations
KW  - flight test data
KW  - attitude state estimator
KW  - EKF-based estimator
KW  - velocity state estimator
KW  - vehicle aerodynamics modeling
KW  - blade element theory
KW  - Rotors
KW  - Blades
KW  - Acceleration
KW  - Optical sensors
KW  - Data models
KW  - Atmospheric modeling
KW  - Aerodynamics
DO  - 10.1109/IROS.2018.8593600
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quadrotor state estimation generally relies on the vehicle aerodynamics modeling to achieve improved performance. In this paper the effects of the rotors angular speeds on the quadrotor drag, and therefore on the lateral accelerations, are investigated. While these effects are usually disregarded, we analyze their modeling starting from the Blade Element Theory and flight test data. Two lateral acceleration formulations are proposed. They are adopted within a velocity and attitude state estimator and validated in real-world flights. The EKF-based estimator fuses measurements from low-cost sensors present in the majority of quadrotors (IMU, magnetometer, ultrasonic sensor, optical flow) with the accelerations of the vehicle predicted from the revisited models. Experimental results show the benefits of adopting these innovative models in the estimator when compared with the existing modeling approach.
ER  - 

TY  - CONF
TI  - Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5719
EP  - 5726
AU  - A. McFadyen
AU  - F. Dayoub
AU  - S. Martin
AU  - J. Ford
AU  - P. Corke
PY  - 2018
KW  - aerospace robotics
KW  - collision avoidance
KW  - inspection
KW  - optical sensors
KW  - power overhead lines
KW  - sensor placement
KW  - collision avoidance
KW  - optical sensors
KW  - sensor placement
KW  - fixed energy infrastructure
KW  - aerial inspection
KW  - multirotor platform
KW  - assisted control technology
KW  - aerial vehicles
KW  - semiautonomous power infrastructure inspection
KW  - proximity inspection tasks
KW  - assisted control approach
KW  - Inspection
KW  - Wires
KW  - Measurement
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593529
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.
ER  - 

TY  - CONF
TI  - Bidirectional Thrust for Multirotor MAVs with Fixed-Pitch Propellers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Maier
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - helicopters
KW  - propellers
KW  - fixed-pitch propellers
KW  - multirotor MicroAerial Vehicles
KW  - bidirectional thrust vector
KW  - dedicated motor controllers
KW  - controller design
KW  - control allocation approach
KW  - static thrust test
KW  - inverted flight
KW  - multirotor MAV
KW  - unidirectional thrust vehicles
KW  - Propellers
KW  - Rotors
KW  - Torque
KW  - Resource management
KW  - Force
KW  - Attitude control
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593836
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper is devoted to the study of multirotor Micro Aerial Vehicles (MAVs) with fixed-pitch propellers and bidirectional thrust vector. The latter is realized by using dedicated motor controllers, which allow to invert the propellers' direction of rotation during flight (so-called 3D mode), and almost or fully symmetric propellers. We present a unified modeling, controller design, and control allocation approach that accounts for bidirectional thrust. Suitable propellers with the ability to produce thrust and torque in both directions are compared and their parameters are identified through a static thrust test. Furthermore, we discuss applications of bidirectional thrust, like inverted flight or surface slip reduction, which are impossible to realize with common unidirectional thrust vehicles. We generate suitable flight trajectories and evaluate our unified approach in experiments with a custom-built quadrotor.
ER  - 

TY  - CONF
TI  - DREGON: Dataset and Methods for UAV-Embedded Sound Source Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Strauss
AU  - P. Mordel
AU  - V. Miguet
AU  - A. Deleforge
PY  - 2018
KW  - acoustic noise
KW  - acoustic signal processing
KW  - aerospace computing
KW  - audio signal processing
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - microphone arrays
KW  - broad-band source localization
KW  - microphone array
KW  - noisy in-flight audio recordings
KW  - 3D position
KW  - rotor rotational speed
KW  - loud noise conditions
KW  - extreme noise levels
KW  - accurate motion capture system
KW  - target sound source
KW  - UAV-embedded sound source localization
KW  - DREGON
KW  - Microphone arrays
KW  - Propellers
KW  - Drones
KW  - Robots
KW  - White noise
DO  - 10.1109/IROS.2018.8593581
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces DREGON, a novel publicly-available dataset that aims at pushing research in sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). The dataset contains both clean and noisy in-flight audio recordings continuously annotated with the 3D position of the target sound source using an accurate motion capture system. In addition, various signals of interests are available such as the rotational speed of individual rotors and inertial measurements at all time. Besides introducing the dataset, this paper sheds light on the specific properties, challenges and opportunities brought by the emerging task of UAV-embedded sound source localization. Several baseline methods are evaluated and compared on the dataset, with real-time applicability in mind. Very promising results are obtained for the localization of a broad-band source in loud noise conditions, while speech localization remains a challenge under extreme noise levels.
ER  - 

TY  - CONF
TI  - Incremental Semi-Supervised Learning from Streams for Object Classification
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5743
EP  - 5749
AU  - I. Chiotellis
AU  - F. Zimmermann
AU  - D. Cremers
AU  - R. Triebel
PY  - 2018
KW  - graph theory
KW  - image classification
KW  - nearest neighbour methods
KW  - supervised learning
KW  - object classification
KW  - Zhu
KW  - transductive learning scenarios
KW  - LP algorithm
KW  - data samples
KW  - autonomous driving
KW  - nearest-neighbor graph
KW  - labeled nodes
KW  - unlabeled nodes
KW  - harmonic solution
KW  - KITTI benchmark data stream
KW  - label propagation algorithm
KW  - Ghahramani
KW  - formal convergence
KW  - incremental semisupervised learning
KW  - Harmonic analysis
KW  - Convergence
KW  - Approximation algorithms
KW  - Semisupervised learning
KW  - Benchmark testing
KW  - Training data
KW  - Clustering algorithms
DO  - 10.1109/IROS.2018.8593901
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The Label Propagation (LP) algorithm, first introduced by Zhu and Ghahramani [1], is a semi-supervised method used in transductive learning scenarios, where all data are available already in the beginning. In this work, we present a novel extension of the LP algorithm for applications where data samples are observed sequentially - as is the case in autonomous driving. Specifically, our “Incremental Label Propagation” algorithm efficiently approximates the so called harmonic solution on a nearest-neighbor graph that is regularly updated by new labeled and unlabeled nodes. We achieve this by reformulating the original algorithm based on an active set of nodes and by introducing a threshold to decide whether the label of a given node should be updated or not. Our method can also deal with graphs that are not fully connected, and we give a formal convergence proof for this general case. In experiments on the challenging KITTI benchmark data stream, we show superior performance in terms of both test accuracy and number of required training labels compared to state-of-the-art online learning methods.
ER  - 

TY  - CONF
TI  - Joint 3D Proposal Generation and Object Detection from View Aggregation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Ku
AU  - M. Mozifian
AU  - J. Lee
AU  - A. Harakeh
AU  - S. L. Waslander
PY  - 2018
KW  - image classification
KW  - image colour analysis
KW  - image fusion
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - radar detection
KW  - regression analysis
KW  - road vehicle radar
KW  - robot vision
KW  - high resolution feature maps
KW  - reliable 3D object proposals
KW  - multiple object classes
KW  - category classification
KW  - second stage detection network
KW  - AVOD
KW  - KITTI 3D object detection
KW  - autonomous vehicles
KW  - 3D bounding box regression
KW  - multimodal feature fusion
KW  - RPN
KW  - region proposal network
KW  - RGB images
KW  - LIDAR point clouds
KW  - neural network architecture
KW  - autonomous driving scenarios
KW  - Aggregate View Object Detection network
KW  - joint 3D proposal generation
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Proposals
KW  - Computer architecture
KW  - Agriculture
KW  - Object detection
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594049
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.
ER  - 

TY  - CONF
TI  - TSSD: Temporal Single-Shot Detector Based on Attention and LSTM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - X. Chen
AU  - Z. Wu
AU  - J. Yu
PY  - 2018
KW  - feature extraction
KW  - object detection
KW  - robot vision
KW  - video signal processing
KW  - convolutional long short-term memory
KW  - creative temporal analysis unit
KW  - multiscale feature maps
KW  - high-level ConvLSTM unit
KW  - pyramidal feature hierarchy
KW  - attention mechanism
KW  - real-time online approaches
KW  - video detection task
KW  - robotic vision
KW  - rich temporal information
KW  - temporal object detection
KW  - temporal single-shot detector
KW  - developed TSSD
KW  - attention-aware features
KW  - scale suppression
KW  - background suppression
KW  - ConvLSTM-based attention
KW  - attention-based ConvLSTM
KW  - Feature extraction
KW  - Detectors
KW  - Robots
KW  - Task analysis
KW  - Visualization
KW  - Lenses
KW  - Proposals
DO  - 10.1109/IROS.2018.8593963
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.
ER  - 

TY  - CONF
TI  - Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5764
EP  - 5769
AU  - F. Barranco
AU  - C. Fermuller
AU  - E. Ros
PY  - 2018
KW  - computer vision
KW  - image segmentation
KW  - image sensors
KW  - Kalman filters
KW  - object detection
KW  - pattern clustering
KW  - target tracking
KW  - event-based sensors
KW  - computer vision applications
KW  - robust tracking
KW  - object detection
KW  - segmentation
KW  - real-time clustering technique
KW  - event-based vision sensors
KW  - mean-shift clustering method
KW  - asynchronous events
KW  - multitarget tracking application
KW  - clustering accuracy
KW  - frame-based method
KW  - Sensors
KW  - Shape
KW  - Real-time systems
KW  - Kalman filters
KW  - Target tracking
KW  - Robots
DO  - 10.1109/IROS.2018.8593380
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.
ER  - 

TY  - CONF
TI  - Speeding-Up Object Detection Training for Robotics with FALKON
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5770
EP  - 5776
AU  - E. Maiettini
AU  - G. Pasquale
AU  - L. Rosasco
AU  - L. Natale
PY  - 2018
KW  - computer vision
KW  - data mining
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robots
KW  - sampling methods
KW  - stochastic processes
KW  - end-to-end learning
KW  - deep feature extractor
KW  - bootstrapping approach
KW  - object detection training
KW  - deep learning methods
KW  - robotic applications
KW  - back-propagation
KW  - region proposal network
KW  - hard negatives mining
KW  - FALKON algorithm
KW  - kernel-based method
KW  - stochastic subsampling
KW  - computer vision dataset
KW  - Training
KW  - Feature extraction
KW  - Pipelines
KW  - Object detection
KW  - Robots
KW  - Task analysis
KW  - Proposals
DO  - 10.1109/IROS.2018.8593990
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Latest deep learning methods for object detection provide remarkable performance, but have limits when used in robotic applications. One of the most relevant issues is the long training time, which is due to the large size and imbalance of the associated training sets, characterized by few positive and a large number of negative examples (i.e. background). Proposed approaches are based on end-to-end learning by back-propagation [22] or kernel methods trained with Hard Negatives Mining on top of deep features [8]. These solutions are effective, but prohibitively slow for on-line applications. In this paper we propose a novel pipeline for object detection that overcomes this problem and provides comparable performance, with a 60x training speedup. Our pipeline combines (i) the Region Proposal Network and the deep feature extractor from [22] to efficiently select candidate RoIs and encode them into powerful representations, with (ii) the FALKON [23] algorithm, a novel kernel-based method that allows fast training on large scale problems (millions of points). We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach. We assess the effectiveness of the approach on a standard Computer Vision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a real robotic scenario with the iCubWorld Transformations [18] dataset.
ER  - 

TY  - CONF
TI  - Disparity Sliding Window: Object Proposals from Disparity Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5777
EP  - 5784
AU  - J. Müller
AU  - A. Fregin
AU  - K. Dietmayer
PY  - 2018
KW  - convolutional neural nets
KW  - image classification
KW  - object detection
KW  - object recognition
KW  - stereo image processing
KW  - object proposals
KW  - disparity images
KW  - object recognition tasks
KW  - deep neural networks
KW  - convolutional neural networks
KW  - sliding window technique
KW  - object candidates
KW  - object size
KW  - disparity sliding window approach
KW  - pedestrian detection
KW  - KITTI object detection benchmark
KW  - object detection
KW  - classifier
KW  - depth information
KW  - stereo camera
KW  - Microsoft Windows
KW  - Proposals
KW  - Computational efficiency
KW  - Task analysis
KW  - Cameras
KW  - Real-time systems
KW  - Image edge detection
DO  - 10.1109/IROS.2018.8593390
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sliding window approaches have been widely used for object recognition tasks in recent years [19], [4], [5], [18]. They guarantee an investigation of the entire input image for the object to be detected and allow a localization of that object. Despite the current trend towards deep neural networks, sliding window methods are still used in combination with convolutional neural networks [22]. The risk of overlooking an object is clearly reduced compared to alternative detection approaches which detect objects based on shape, edges or color. Nevertheless, the sliding window technique strongly increases the computational effort as the classifier has to verify a large number of object candidates. This paper proposes a sliding window approach which also uses depth information from a stereo camera. This leads to a greatly decreased number of object candidates without significantly reducing the detection accuracy. A theoretical investigation of the conventional sliding window approach is presented first. Other publications to date only mentioned rough estimations of the computational cost. A mathematical derivation clarifies the number of object candidates with respect to parameters such as image and object size. Subsequently, the proposed disparity sliding window approach is presented in detail. The approach is evaluated on pedestrian detection with annotations and images from the KITTI [10] object detection benchmark. Furthermore, a comparison with two state-of-the-art methods is made. Code is available in C++ and Python https://github.com/julimueller/disparity-sliding-window.
ER  - 

TY  - CONF
TI  - Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5785
EP  - 5792
AU  - I. Alonso
AU  - A. C. Murillo
PY  - 2018
KW  - image annotation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - image modalities
KW  - sparse labeling data
KW  - human interaction reduction
KW  - environment monitoring data
KW  - sparse annotation augmentation
KW  - dense ground-truth
KW  - label augmentation
KW  - adaptive superpixel segmentation propagation
KW  - dense semantic segmentation models
KW  - pixel level labeling
KW  - life applicability
KW  - common deep learning models
KW  - deep learning approaches
KW  - image pixel
KW  - multilevel superpixels
KW  - effective learning
KW  - Image segmentation
KW  - Semantics
KW  - Labeling
KW  - Training
KW  - Biological system modeling
KW  - Monitoring
KW  - Deep learning
DO  - 10.1109/IROS.2018.8594185
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.
ER  - 

TY  - CONF
TI  - Real-Time Segmentation with Appearance, Motion and Geometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5793
EP  - 5800
AU  - M. Siam
AU  - S. Eikerdawy
AU  - M. Gamal
AU  - M. Abdel-Razek
AU  - M. Jagersand
AU  - H. Zhang
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - distance measurement
KW  - Global Positioning System
KW  - image motion analysis
KW  - image segmentation
KW  - mobile robots
KW  - motion estimation
KW  - object detection
KW  - remotely operated vehicles
KW  - robot vision
KW  - domain knowledge
KW  - planar scenes
KW  - high altitude unmanned aerial vehicles
KW  - homography compensated flow
KW  - urban scenes
KW  - autonomous driving
KW  - depth estimates
KW  - segmentation accuracy
KW  - geometric priors
KW  - UAV imagery
KW  - baseline network
KW  - sparse depth
KW  - motion segmentation solution
KW  - assisted systems
KW  - traffic monitoring
KW  - unmanned aerial vehicles imagery
KW  - two-stream convolutional network
KW  - geometric cues
KW  - computational efficiency trade-offs
KW  - real-time segmentation
KW  - GPS-IMU sensory data
KW  - KITTI-MoSeg
KW  - Motion segmentation
KW  - Computer vision
KW  - Real-time systems
KW  - Convolutional codes
KW  - Autonomous vehicles
KW  - Unmanned aerial vehicles
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594088
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at1.
ER  - 

TY  - CONF
TI  - VarNet: Exploring Variations for Unsupervised Video Prediction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5801
EP  - 5806
AU  - B. Jin
AU  - Y. Hu
AU  - Y. Zeng
AU  - Q. Tang
AU  - S. Liu
AU  - J. Ye
PY  - 2018
KW  - image motion analysis
KW  - image sequences
KW  - object detection
KW  - video signal processing
KW  - VarNet
KW  - video frame prediction
KW  - inter-frame variations
KW  - adjacent frames
KW  - long-term video prediction
KW  - KITTI dataset
KW  - unsupervised video prediction framework-variation network
KW  - PSNR
KW  - SSIM
KW  - KTH
KW  - Generators
KW  - Training
KW  - Predictive models
KW  - Decoding
KW  - Video sequences
KW  - Neural networks
KW  - Generative adversarial networks
DO  - 10.1109/IROS.2018.8594264
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised video prediction is a very challenging task due to the complexity and diversity in natural scenes. Prior works directly predicting pixels or optical flows either have the blurring problem or require additional assumptions. We highlight that the crux for video frame prediction lies in precisely capturing the inter-frame variations which encompass the movement of objects and the evolution of the surrounding environment. We then present an unsupervised video prediction framework - Variation Network (VarNet) to directly predict the variations between adjacent frames which are then fused with current frame to generate the future frame. In addition, we propose an adaptively re-weighting mechanism for loss function to offer each pixel a fair weight according to the amplitude of its variation. Extensive experiments for both short-term and long-term video prediction are implemented on two advanced datasets - KTH and KITTI with two evaluating metrics - PSNR and SSIM. For the KTH dataset, the VarNet outperforms the state-of-the-art works up to 11.9% on PSNR and 9.5% on SSIM. As for the KITTI dataset, the performance boosts are up to 55.1% on PSNR and 15.9% on SSIM. Moreover, we verify that the generalization ability of our model excels other state-of-the-art methods by testing on the unseen CalTech Pedestrian dataset after being trained on the KITTI dataset. Source code and video are available at https://github.com/jinbeibei/VarNet.
ER  - 

TY  - CONF
TI  - Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5807
EP  - 5812
AU  - B. Bovcon
AU  - M. Kristan
PY  - 2018
KW  - cameras
KW  - collision avoidance
KW  - control engineering computing
KW  - convolutional neural nets
KW  - edge detection
KW  - image segmentation
KW  - mobile robots
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - water edge
KW  - stereo extensions
KW  - joint stereo-view semantic segmentation
KW  - unmanned surface vehicles
KW  - scene semantic segmentation problem
KW  - single-view model
KW  - consistent class labels assignment
KW  - monocular CNN
KW  - class-label posterior map
KW  - stereo-based obstacle detection
KW  - Semantics
KW  - Image segmentation
KW  - Cameras
KW  - Image edge detection
KW  - Sea surface
KW  - Graphical models
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594238
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.
ER  - 

TY  - CONF
TI  - Efficient Absolute Orientation Revisited
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5813
EP  - 5818
AU  - M. Lourakis
AU  - G. Terzakis
PY  - 2018
KW  - attitude measurement
KW  - computer vision
KW  - matrix decomposition
KW  - optimisation
KW  - singular value decomposition
KW  - fast optimal attitude matrix algorithm
KW  - optimal linear attitude estimator method
KW  - 3D point sets
KW  - OLAE method
KW  - computer vision
KW  - similarity transformation
KW  - absolute orientation estimation
KW  - attitude estimation techniques
KW  - FOAM-based solution
KW  - singular-value matrix decompositions
KW  - absolute orientation algorithm
KW  - robotics
KW  - Quaternions
KW  - Estimation
KW  - Symmetric matrices
KW  - Eigenvalues and eigenfunctions
KW  - Matrix decomposition
KW  - Covariance matrices
KW  - Computer vision
DO  - 10.1109/IROS.2018.8594296
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.
ER  - 

TY  - CONF
TI  - Active Structure-from-Motion for 3d Straight Lines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5819
EP  - 5825
AU  - A. Mateus
AU  - O. Tahri
AU  - P. Miraldo
PY  - 2018
KW  - mobile robots
KW  - observability
KW  - robot vision
KW  - visual servoing
KW  - Active Structure-from-Motion
KW  - planning
KW  - Image-Based Visual Servoing
KW  - control scheme
KW  - straight lines
KW  - control law
KW  - control effort
KW  - 3D straight lines
KW  - convergence rate
KW  - 3D parameter estimation
KW  - Three-dimensional displays
KW  - Cameras
KW  - Convergence
KW  - Eigenvalues and eigenfunctions
KW  - Robots
KW  - Observers
DO  - 10.1109/IROS.2018.8593793
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A reliable estimation of 3D parameters is a must for several applications like planning and control, in which is included Image-Based Visual Servoing. This control scheme depends directly on 3D parameters, e.g. depth of points, and/or depth and direction of 3D straight lines. Recently, a framework for Active Structure-from-Motion was proposed, addressing the former feature type. However, straight lines were not addressed. These are 1D objects, which allow for more robust detection, and tracking. In this work, the problem of Active Structure-from-Motion for 3D straight lines is addressed. An explicit representation of these features is presented, and a change of variables is proposed. The latter allows the dynamics of the line to respect the conditions for observability of the framework. A control law is used with the purpose of keeping the control effort reasonable, while achieving a desired convergence rate. The approach is validated first in simulation for a single line, and second using a real robot setup. The latter set of experiments are conducted first for a single line, and then for three lines.
ER  - 

TY  - CONF
TI  - Stereo Camera Localization in 3D LiDAR Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Kim
AU  - J. Jeong
AU  - A. Kim
PY  - 2018
KW  - cameras
KW  - Global Positioning System
KW  - image matching
KW  - image reconstruction
KW  - mobile robots
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - stereo disparity map
KW  - average localization error
KW  - stereo camera localization
KW  - Global Positioning System
KW  - 3D LiDAR maps
KW  - simultaneous localization and mapping techniques
KW  - SLAM techniques
KW  - 3D light detection and ranging sensors
KW  - visual positioning algorithm
KW  - GPS signal
KW  - visual tracking
KW  - six degree of freedom
KW  - DOF
KW  - camera pose estimation
KW  - KITTI dataset
KW  - Cameras
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Global Positioning System
DO  - 10.1109/IROS.2018.8594362
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As simultaneous localization and mapping (SLAM) techniques have flourished with the advent of 3D Light Detection and Ranging (LiDAR) sensors, accurate 3D maps are readily available. Many researchers turn their attention to localization in a previously acquired 3D map. In this paper, we propose a novel and lightweight camera-only visual positioning algorithm that involves localization within prior 3D LiDAR maps. We aim to achieve the consumer level global positioning system (GPS) accuracy using vision within the urban environment, where GPS signal is unreliable. Via exploiting a stereo camera, depth from the stereo disparity map is matched with 3D LiDAR maps. A full six degree of freedom (DOF) camera pose is estimated via minimizing depth residual. Powered by visual tracking that provides a good initial guess for the localization, the proposed depth residual is successfully applied for camera pose estimation. Our method runs online, as the average localization error is comparable to ones resulting from state-of-the-art approaches. We validate the proposed method as a stand-alone localizer using KITTI dataset and as a module in the SLAM framework using our own dataset.
ER  - 

TY  - CONF
TI  - Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5834
EP  - 5840
AU  - N. Kingry
AU  - M. Jung
AU  - E. Derse
AU  - R. Dai
PY  - 2018
KW  - cameras
KW  - energy harvesting
KW  - feature extraction
KW  - Haar transforms
KW  - image classification
KW  - image colour analysis
KW  - image texture
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - solar power
KW  - terrain mapping
KW  - wavelet transforms
KW  - outdoor mobile robots
KW  - feature extraction
KW  - visual-spectrum images
KW  - on-board camera
KW  - Haar wavelet transform
KW  - color information
KW  - textural information
KW  - ANN
KW  - high dynamic range imagery
KW  - energy consumption
KW  - traversability criteria
KW  - energy harvesting capabilities
KW  - vision-based artificial neural network
KW  - sequential methodology
KW  - solar irradiance map
KW  - terrain classes
KW  - solar-powered mobile robots
KW  - real-time terrain classification
KW  - solar irradiance mapping
KW  - vision-based terrain classification
KW  - Image color analysis
KW  - Feature extraction
KW  - Neural networks
KW  - Training
KW  - Image segmentation
KW  - Wavelet transforms
KW  - Sensors
KW  - Field Robotics
KW  - Image Processing
KW  - Solar Mapping
KW  - Terrain Classification
KW  - Solar Robotics
DO  - 10.1109/IROS.2018.8593635
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.
ER  - 

TY  - CONF
TI  - Structured Skip List: A Compact Data Structure for 3D Reconstruction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - S. Li
AU  - M. Cheng
AU  - Y. Liu
AU  - S. Lu
AU  - Y. Wang
AU  - V. Adrian Prisacariu
PY  - 2018
KW  - data reduction
KW  - data structures
KW  - image reconstruction
KW  - data management methods
KW  - Structured Skip List
KW  - Structured Skip List
KW  - high storage efficiency
KW  - storage efficiency analysis
KW  - hash allocation list
KW  - voxel allocation
KW  - data collision
KW  - storage space
KW  - structured information
KW  - semiordered method
KW  - SSL
KW  - real-time indoor 3D reconstruction
KW  - data management method
KW  - store nonempty voxels
KW  - massive index data
KW  - low storage efficiency
KW  - data order
KW  - unordered methods
KW  - ordered methods
KW  - 3D reconstruction algorithm
KW  - compact data structure
KW  - Three-dimensional displays
KW  - Indexes
KW  - Data structures
KW  - Image reconstruction
KW  - Resource management
KW  - Solid modeling
KW  - Pipelines
DO  - 10.1109/IROS.2018.8594075
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The model produced by 3D reconstruction algorithm is usually represented by voxels. The management of these voxels is usually divided into two categories: ordered and unordered methods. The ordered method holds too many empty voxels to maintain data order which leads to a low storage efficiency. On the contrary, the unordered method keeps massive index data to only store nonempty voxels. In this paper, we design a new data management method for real-time indoor 3D reconstruction, called Structured Skip List (SSL). The SSL can be treated as a semi-ordered method, because the advantages of both the ordered and unordered methods are taken into account: 1) it only holds nonempty voxels similar to the unordered method; 2) the structured information is introduced to reduce the storage space of index data. By these designs, the SSL has a better performance on storage efficiency. To handle the data collision in voxel allocation, a hash allocation list (HAL) is proposed. The length of each Skip List is kept balanced by fusing the IMU (Inertial Measurement Unit) information for a high operation efficiency. The storage efficiency analysis of different data management methods is shown in this paper. What's more, exhaustive investigation is carried out on several datasets with these methods. The experimental result demonstrates that our design can achieve a high storage efficiency with little time loss compared to the state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Towards Real-Time Unsupervised Monocular Depth Estimation on CPU
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5848
EP  - 5854
AU  - M. Poggi
AU  - F. Aleotti
AU  - F. Tosi
AU  - S. Mattoccia
PY  - 2018
KW  - embedded systems
KW  - estimation theory
KW  - feature extraction
KW  - image reconstruction
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - microprocessor chips
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - stereo image processing
KW  - robotic navigation
KW  - autonomous navigation
KW  - deep learning
KW  - low-power constraints
KW  - embedded system
KW  - single input image
KW  - image reconstruction problem
KW  - KITTI image
KW  - depth map
KW  - CPU
KW  - unsupervised monocular depth estimation
KW  - features extraction
KW  - time 1.7 s
KW  - frequency 8.0 Hz
KW  - frequency 40.0 Hz
KW  - Estimation
KW  - Feature extraction
KW  - Computer architecture
KW  - Training
KW  - Decoding
KW  - Image resolution
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593814
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised depth estimation from a single image is a very attractive technique with several implications in robotic, autonomous navigation, augmented reality and so on. This topic represents a very challenging task and the advent of deep learning enabled to tackle this problem with excellent results. However, these architectures are extremely deep and complex. Thus, real-time performance can be achieved only by leveraging power-hungry GPUs that do not allow to infer depth maps in application fields characterized by low-power constraints. To tackle this issue, in this paper we propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image. Similarly to state-of-the-art, we train our network in an unsupervised manner casting depth estimation as an image reconstruction problem. Extensive experimental results on the KITTI dataset show that compared to the top performing approach our network has similar accuracy but a much lower complexity (about 6% of parameters) enabling to infer a depth map for a KITTI image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard CPU. Moreover, by trading accuracy for efficiency, our network allows to infer maps at about 2 Hz and 40 Hz respectively, still being more accurate than most state-of-the-art slower methods. To the best of our knowledge, it is the first method enabling such performance on CPUs paving the way for effective deployment of unsupervised monocular depth estimation even on embedded systems.
ER  - 

TY  - CONF
TI  - A Plug-In Feed-Forward Control for Sloshing Suppression in Robotic Teleoperation Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5855
EP  - 5860
AU  - L. Biagiotti
AU  - D. Chiaravalli
AU  - L. Moriello
AU  - C. Melchiorri
PY  - 2018
KW  - compensation
KW  - containers
KW  - end effectors
KW  - feedforward
KW  - industrial robots
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - sloshing
KW  - telerobotics
KW  - trajectory control
KW  - position-orientation trajectory
KW  - dynamic filter design
KW  - sloshing dynamics suppression
KW  - lateral accelerations
KW  - active compensation
KW  - liquid oscillations
KW  - filtering technique
KW  - design philosophy
KW  - robot end-effector
KW  - liquid container
KW  - liquid handling robotic systems
KW  - robotic teleoperation tasks
KW  - feed-forward control
KW  - motion capture system
KW  - harmonic smoother
KW  - Liquids
KW  - Containers
KW  - Robots
KW  - Acceleration
KW  - Trajectory
KW  - Mathematical model
KW  - Vibrations
DO  - 10.1109/IROS.2018.8593962
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, the problem of suppressing sloshing dynamics in liquid handling robotic systems has been faced by designing a dynamic filter that starting from the desired motion of the liquid container calculates the complete position/orientation trajectory for the robot end-effector. Specifically, a design philosophy mixing a filtering technique that suppresses the frequency contributions of the reference motion that may cause liquid oscillations and an active compensation of lateral accelerations by a proper container re-orientation has been adopted. In principle, the latter contribution requires the knowledge of acceleration of the reference trajectory, but because of the use of an harmonic smoother that performs a shaping of the original motion, it is possible to obtain the value of the acceleration in runtime. In this way, the proposed methods can be applied also to reference motions that are not known in advance, e.g. commands directly provided by a human operator. This possibility has been demonstrated by means of a number of experimental tests in which the user teleoperates the robot carrying the container with the liquid by simply moving in the free space its hand, whose 3D position is detected by a motion capture system.
ER  - 

TY  - CONF
TI  - Elastic Structure Preserving Impedance (ESπ)Control for Compliantly Actuated Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5861
EP  - 5868
AU  - M. Keppler
AU  - D. Lakatos
AU  - C. Ott
AU  - A. Albu-Schaffer
PY  - 2018
KW  - closed loop systems
KW  - damping
KW  - end effectors
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - stability
KW  - compliantly actuated robots
KW  - possibly nonlinear spring characteristics
KW  - damping range
KW  - end-effector interaction behavior
KW  - external loads approach
KW  - classical Cartesian impedance control
KW  - closed-loop dynamics
KW  - elastic structure preserving impedance control
KW  - stability analysis
KW  - Lyapunov function
KW  - Robot kinematics
KW  - Impedance
KW  - Springs
KW  - Damping
KW  - Dynamics
KW  - Actuators
DO  - 10.1109/IROS.2018.8593415
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a new approach for Cartesian impedance control of compliantly actuated robots with possibly nonlinear spring characteristics. It reveals a remarkable stiffness and damping range in the experimental evaluation. The most interesting contribution, is the way the desired closed-loop dynamics is designed. Our control concept allows to add a desired stiffness and damping directly on the end-effector, while leaving the system structure intact. The intrinsic inertial and elastic properties of the system are preserved. This is achieved by introducing new motor coordinates that reflect the desired spring and damper terms. Theoretically, by means of additional motor inertia shaping it is possible to make the end-effector interaction behavior with respect to external loads approach, arbitrarily close, the interaction behavior that is achievable by classical Cartesian impedance control on rigid robots. The physically motivated design approach allows for an intuitive understanding of the resulting closed-loop dynamics. We perform a passivity and stability analysis on the basis of al physically motivated storage and Lyapunov function.
ER  - 

TY  - CONF
TI  - An Efficient and Time-Optimal Trajectory Generation Approach for Waypoints Under Kinematic Constraints and Error Bounds
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5869
EP  - 5876
AU  - J. Lin
AU  - N. Somani
AU  - B. Hu
AU  - M. Rickert
AU  - A. Knoll
PY  - 2018
KW  - manipulator kinematics
KW  - nonlinear programming
KW  - path planning
KW  - time optimal control
KW  - trajectory control
KW  - motion planners
KW  - optimization scale
KW  - trajectory results
KW  - seven-segment acceleration profile
KW  - nonlinear constraint optimization problem
KW  - robot manipulator
KW  - error bounds
KW  - kinematic constraints
KW  - time-optimal trajectory generation approach
KW  - Trajectory
KW  - Splines (mathematics)
KW  - Optimization
KW  - Manipulators
KW  - Acceleration
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593577
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an approach to generate the time-optimal trajectory for a robot manipulator under certain kinematic constraints such as joint position, velocity, acceleration, and jerk limits. This problem of generating a trajectory that takes the minimum time to pass through specified waypoints is formulated as a nonlinear constraint optimization problem. Unlike prior approaches that model the motion of consecutive waypoints as a Cubic Spline, we model this motion with a seven-segment acceleration profile, as this trajectory results in a shorter overall motion time while staying within the bounds of the robot manipulator's constraints. The optimization bottleneck lies in the complexity that increases exponentially with the number of waypoints. To make the optimization scale well with the number of waypoints, we propose an approach that has linear complexity. This approach first divides all waypoints to consecutive batches, each with an overlap of two waypoints. The overlapping waypoints then act as a bridge to concatenate the optimization results of two consecutive batches. The whole trajectory is effectively optimized by successively optimizing every batch. We conduct experiments on practical scenarios and trajectories generated by motion planners to evaluate the effectiveness of our proposed approach over existing state-of-the-art approaches.
ER  - 

TY  - CONF
TI  - Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5877
EP  - 5884
AU  - W. Merkt
AU  - V. Ivan
AU  - S. Vijayakumar
PY  - 2018
KW  - collision avoidance
KW  - convergence
KW  - humanoid robots
KW  - mobile robots
KW  - Newton method
KW  - trajectory control
KW  - problem encoding
KW  - warm-starting trajectory optimization
KW  - motion planner
KW  - local minima
KW  - motion planning
KW  - near-optimal warm-start initializations
KW  - global convergence
KW  - quasiNewton solvers
KW  - probabilistic inference solvers
KW  - NASA Valkyrie robot
KW  - Task analysis
KW  - Collision avoidance
KW  - Planning
KW  - Robots
KW  - Trajectory optimization
DO  - 10.1109/IROS.2018.8593977
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.
ER  - 

TY  - CONF
TI  - A Self-Tuning Impedance Controller for Autonomous Robotic Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5885
EP  - 5891
AU  - P. Balatti
AU  - D. Kanoulas
AU  - G. F. Rigano
AU  - L. Muratore
AU  - N. G. Tsagarakis
AU  - A. Ajoudani
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot programming
KW  - robot vision
KW  - appropriate restoring forces
KW  - unstructured environments
KW  - complex interactions
KW  - autonomous robotic manipulation
KW  - self-tuning impedance controller
KW  - debris removal task
KW  - selective Cartesian axes
KW  - impedance parameters
KW  - autonomous tuning
KW  - robot state machine
KW  - interaction values
KW  - interaction expectancy value
KW  - novel self-regulating impedance controller
KW  - task-dependent regulation
KW  - task conditions
KW  - robot programmers
KW  - damping
KW  - stiffness
KW  - quasistatic performance
KW  - impedance control techniques
KW  - imposed displacements
KW  - Impedance
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Grasping
KW  - Damping
DO  - 10.1109/IROS.2018.8593860
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Complex interactions with unstructured environments require the application of appropriate restoring forces in response to the imposed displacements. Impedance control techniques provide effective solutions to achieve this, however, their quasi-static performance is highly dependent on the choice of parameters, i.e. stiffness and damping. In most cases, such parameters are previously selected by robot programmers to achieve a desired response, which limits the adaptation capability of robots to varying task conditions. To improve the generality of interaction planning through task-dependent regulation of the parameters, this paper introduces a novel self-regulating impedance controller. The regulation of the parameters is achieved based on the robot's local sensory data, and on an interaction expectancy value. This value combines the interaction values from the robot state machine and visual feedback, to authorize the autonomous tuning of the impedance parameters in selective Cartesian axes. The effectiveness of the proposed method is validated experimentally in a debris removal task.
ER  - 

TY  - CONF
TI  - Robust Fixed-Wing UAV Guidance with Circulating Artificial Vector Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5892
EP  - 5899
AU  - A. M. C. Rezende
AU  - V. M. Gonçalves
AU  - G. V. Raffo
AU  - L. C. A. Pimenta
PY  - 2018
KW  - aircraft control
KW  - asymptotic stability
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - Lyapunov methods
KW  - robust control
KW  - vectors
KW  - constrained input controls
KW  - asymptotic stability
KW  - control law
KW  - robust fixed-wing UAV guidance
KW  - guidance vector field strategy
KW  - unmanned aerial vehicle
KW  - closed curve
KW  - control system
KW  - aircraft model
KW  - artificial vector fields
KW  - Convergence
KW  - Uncertainty
KW  - Atmospheric modeling
KW  - Aircraft
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Shape
DO  - 10.1109/IROS.2018.8594371
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a guidance vector field strategy to control a fixed-wing UAV (unmanned aerial vehicle)subject to uncertainty in order to converge to and circulate a closed curve in ℝ3. The control system is designed based on a reference model of the airplane with constrained input controls. The law is independent of the vector field's structure, however, some analysis considers a consolidated vector field approach. Asymptotic stability is proven with Lyapunov Theory and ultimate bounds are found when bounded uncertainties are taken into account. The control law is continuous except in the surroundings of the unavoidable field's singularities. A theorem ensures asymptotic convergence when a switch is made. Simulations with a 6 DOF, 12 states realistic aircraft model demonstrate the efficiency of the strategy and its advantages.
ER  - 

TY  - CONF
TI  - Development of MR Clutch for a Prospective 5 DOF Robot* This work was supported in part by Canada Foundation for Innovation (CFI) and Natural Sciences and Engineering Research Council (NSERC) of Canada under grant No.25031 and RGPIN-346166.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5900
EP  - 5905
AU  - S. Pisetskiy
AU  - M. R. Kermani
PY  - 2018
KW  - clutches
KW  - design engineering
KW  - Hall effect transducers
KW  - intelligent sensors
KW  - machine control
KW  - magnetorheology
KW  - torque control
KW  - intrinsic torque control
KW  - mechanical design
KW  - prospective 5 DOF robot
KW  - MR clutch
KW  - magneto-rheological clutch
KW  - prospective 5 degrees of freedom robot
KW  - embedded Hall sensors
KW  - Torque
KW  - Magnetic sensors
KW  - Stators
KW  - Rotors
KW  - Robots
KW  - Wires
DO  - 10.1109/IROS.2018.8593582
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an improved design approach for the construction of a Magneto-Rheological (MR) clutch intended to be used in a prospective 5 degrees of freedom robot. The MR clutch features embedded Hall sensors for intrinsic torque control. After a brief description of the MR clutch principles, the details of the mechanical design are discussed. Simulation and preliminary experimental results demonstrate the main characteristics and advantages of the proposed MR clutch.
ER  - 

TY  - CONF
TI  - Real-Time Quad-Rotor Path Planning for Mobile Obstacle Avoidance Using Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Szmuk
AU  - C. A. Pascucci
AU  - B. AÇikmeşe
PY  - 2018
KW  - attitude control
KW  - collision avoidance
KW  - convex programming
KW  - helicopters
KW  - propellers
KW  - mobile obstacle avoidance
KW  - on-board convex-optimization-based path planning
KW  - multirotors
KW  - fixed-pitch propellers
KW  - fixed-pitch actuators
KW  - uni-directional thrust
KW  - commanded total thrust
KW  - sufficient independent attitude control authority
KW  - indoor flight demonstration
KW  - second-order cone programming problems
KW  - real-time quad-rotor path planning
KW  - real-time 3-dimensional path planning
KW  - Trajectory
KW  - Real-time systems
KW  - Software
KW  - Acceleration
KW  - Vehicle dynamics
KW  - Attitude control
DO  - 10.1109/IROS.2018.8594351
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we employ convex optimization to perform real-time 3-dimensional path planning on-board a quad-rotor and demonstrate its real-time capabilities. Building on our previous work, we make the following modifications: (1)we assume the obstacles are mobile, and (2)we introduce a simple framework to continuously recompute and update the trajectory. The contribution of this paper is to demonstrate the feasibility of real-time on-board convex-optimization-based path planning. For multi-rotors with fixed-pitch propellers, this path planning problem has two sources of non-convexity. First, since fixed-pitch actuators produce uni-directional thrust, the commanded total thrust must be maintained above a non-zero minimum in order to retain sufficient independent attitude control authority. The second source of non-convexity is due to the keep-out zones that envelop each obstacle. To circumvent the non-convexities introduced by these control and state constraints, we employ lossless and successive con-vexification, respectively. Consequently, we cast the original problem as a sequence of Second-Order Cone Programming problems, which can be solved quickly and reliably on-board. We conclude by presenting indoor flight demonstration and timing results of a scenario with three mobile obstacles. In this scenario, our algorithm assumes that the obstacles move with constant acceleration, and is re-executed regularly to account for uncertainties in the motion of the obstacles. The results show that new trajectories can be computed at rates in excess of 10 Hz, quickly enough to adapt to the uncertainty introduced in our flight demonstration.
ER  - 

TY  - CONF
TI  - Embedded and controllable shape morphing with twisted-and-coiled actuators*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5912
EP  - 5917
AU  - J. Sun
AU  - B. Pawlowski
AU  - J. Zhao
PY  - 2018
KW  - actuators
KW  - muscle
KW  - prosthetics
KW  - robot designs
KW  - adaptive morphology
KW  - soft materials
KW  - steady-state shape
KW  - embedded shape morphing
KW  - controllable shape morphing
KW  - twisted-and-coiled actuators
KW  - thermoplastic material
KW  - variable stiffness
KW  - mechanical design
KW  - artificial muscle
KW  - Shape
KW  - Programmable logic arrays
KW  - Actuators
KW  - Strain
KW  - Force
KW  - Mathematical model
KW  - Robots
DO  - 10.1109/IROS.2018.8593651
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Shape morphing, meaning a structure can first morph and then lock into another shape, can be applied to robot designs to endow robots with adaptive morphology for increased functionality and adaptivity. In this paper, we introduce a novel shape morphing scheme enabled by a new artificial muscle: twisted and coiled actuators (TCAs). This new actuator is purely soft, low cost, and electrically driven. Embedding a TCA and a thermoplastic material with variable stiffness into soft materials, we create a miniature shape-morphing link. We also establish a general model to predict the steady-state shape of the link given an input power applied to the TCA. Experiments are conducted to characterize parameters and verify the proposed model. Finally, we demonstrate this shape-morphing link can serve as a link in a mechanism to change the trajectory of its foot or endpoint. We envision that such a new shape-morphing scheme can enable robots to leverage the same mechanical design for different functions.
ER  - 

TY  - CONF
TI  - Soft Robotic Burrowing Device with Tip-Extension and Granular Fluidization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5918
EP  - 5923
AU  - N. D. Naclerio
AU  - C. M. Hubicki
AU  - Y. O. Aydin
AU  - D. I. Goldman
AU  - E. W. Hawkes
PY  - 2018
KW  - fluidisation
KW  - granular materials
KW  - mobile robots
KW  - sand
KW  - underground equipment
KW  - granular fluidization
KW  - soft robotic burrowing device
KW  - mobile robots
KW  - interaction forces
KW  - pressure-driven thin film body
KW  - tip-extension
KW  - pressurized fluid
KW  - Electron tubes
KW  - Force
KW  - Robots
KW  - Strips
KW  - Fluidization
KW  - Pneumatic systems
KW  - Fabrics
DO  - 10.1109/IROS.2018.8593530
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robots of all shapes and sizes move through the air, water, and over ground. However, few robots can move through the ground. Not only are the forces resisting movement much greater than in air or water, but the interaction forces are more complicated. Here we propose a soft robotic device that burrows through dry sand while requiring an order of magnitude less force than a similarly sized intruding body. The device leverages the principles of both tip-extension and granular fluidization. Like roots, the device extends from its tip; the principle of tip-extension eliminates skin drag on the sides of the body, because the body is stationary with respect to the medium. We implement this with an everting, pressure-driven thin film body. The second principle, granular fluidization, enables a granular medium to adopt a dynamic fluid-like state when pressurized fluid is passed through it, reducing the forces acting on an object moving through it. We realize granular fluidization with a flow of air through the core of the body that mixes with the medium at the tip. The proposed device could lead to applications such as search and rescue in mudslides or shallow subterranean exploration. Further, because it creates a physical conduit with its body, electrical lines, fluids, or even tools could be passed through this channel.
ER  - 

TY  - CONF
TI  - Liquid Metal-Microelectronics Integration for a Sensorized Soft Robot Skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5924
EP  - 5929
AU  - T. Hellebrekers
AU  - K. B. Ozutemiz
AU  - J. Yin
AU  - C. Majidi
PY  - 2018
KW  - actuators
KW  - elastomers
KW  - flexible electronics
KW  - gallium alloys
KW  - grippers
KW  - indium alloys
KW  - integrated circuits
KW  - liquid metals
KW  - microsensors
KW  - robots
KW  - sensors
KW  - shape memory effects
KW  - skin
KW  - tactile sensors
KW  - temperature sensors
KW  - robot arm
KW  - sensorized soft gripper
KW  - shape-memory actuated soft gripper
KW  - microelectronic skin
KW  - individual sensors
KW  - mechanical loading
KW  - room temperature liquid metal alloy
KW  - eutectic gallium indium
KW  - temperature sensing
KW  - solid-state electronics
KW  - stretchable skin
KW  - elastomeric skin
KW  - integrated circuits
KW  - microelectronic sensors
KW  - natural mechanics
KW  - signal processing
KW  - power regulation
KW  - sensorized soft robot skin
KW  - liquid metal-microelectronics integration
KW  - temperature 293 K to 298 K
KW  - Grippers
KW  - Robot sensing systems
KW  - Temperature sensors
KW  - Skin
KW  - Liquids
KW  - Metals
DO  - 10.1109/IROS.2018.8593944
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Progress in soft robotics depends on the integration of electronics for sensing, power regulation, and signal processing. Commercially available microelectronics satisfy these functions and are small enough to preserve the natural mechanics of the host system. Here, we present a method for incorporating microelectronic sensors and integrated circuits (ICs) into the elastomeric skin of a soft robot. The thin stretchable skin contains various solid-state electronics for orientation, pressure, proximity, and temperature sensing, and a microprocessor. The components are connected by thin-film copper traces wetted with eutectic gallium indium (EGaIn), a room temperature liquid metal alloy that allows the circuit to maintain conductivity as it deforms under mechanical loading. In this paper, we characterize the function of the individual sensors in air and water, discuss the integration of the microelectronic skin with a shape-memory actuated soft gripper, and demonstrate the sensorized soft gripper in conjunction with a 4 degree-of-freedom (DOF) robot arm.
ER  - 

TY  - CONF
TI  - Development of a Hybrid Gripper with Soft Material and Rigid Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5930
EP  - 5935
AU  - W. Park
AU  - S. Seo
AU  - J. Bae
PY  - 2018
KW  - bending
KW  - finite element analysis
KW  - grippers
KW  - manipulators
KW  - motion control
KW  - pneumatic actuators
KW  - hybrid gripper
KW  - robotic manipulators
KW  - conventional robotic grippers
KW  - rigid components
KW  - gripping motion
KW  - soft grippers
KW  - bending motion
KW  - fingertip force
KW  - morphological structure
KW  - soft pneumatic actuators
KW  - underactuated mechanism
KW  - finite element methods
KW  - FEM
KW  - SPAs
KW  - three-fingered gripper
KW  - soft components
KW  - Grippers
KW  - Force
KW  - Shape
KW  - Strain
KW  - Robots
KW  - Actuators
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594232
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For decades, various robotic grippers have been developed due to its necessity for the robotic manipulators. In case of the conventional robotic grippers with rigid components, an underactuated mechanism was required to satisfy gripping motion. Recently, soft grippers have been studied actively, which have realize bending motion with a simple morphological structure itself and inherent compliance to the environment. In this field of study, it has been rarely investigated to improve the fingertip force and actuation speed with specified design parameters. Thus, in this study, a hybrid gripper, which consists of both soft and rigid components, was suggested based on the key design principles: 1) the ratio of rigid parts against the soft chamber, 2) the cross-sectional shape of the chamber. The suggested principles were verified using the finite element methods (FEMs). As a result, the improved performance of the hybrid gripper was verified in terms of the fingertip force and the actuation speed, compared with the performance of the previously developed soft pneumatic actuators (SPAs). As an application, the three-fingered gripper was manufactured and tested by grasping different types of objects.
ER  - 

TY  - CONF
TI  - Design for Control of a Soft Bidirectional Bending Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - R. A. Bilodeau
AU  - M. C. Yuen
AU  - J. C. Case
AU  - T. L. Buckner
AU  - R. Kramer-Bottiglio
PY  - 2018
KW  - bending
KW  - capacitive sensors
KW  - closed loop systems
KW  - finite element analysis
KW  - pneumatic actuators
KW  - strain sensors
KW  - sensor effectiveness
KW  - design evaluation process
KW  - simple control strategies
KW  - closed-loop control
KW  - soft bidirectional bending actuator
KW  - SCAPAs
KW  - controllable design
KW  - antagonistic actuators
KW  - embedded capacitive strain sensors
KW  - sensor-controlled antagonistic pneumatic actuators
KW  - soft robotic actuators
KW  - manufacturing processes
KW  - finite element analysis
KW  - state reconstruction
KW  - single conductive fabric sheet
KW  - Actuators
KW  - Capacitive sensors
KW  - Fabrics
KW  - Strain
KW  - Robot sensing systems
KW  - Sensor systems
KW  - soft material robotics
KW  - hydraulic/pneumatic actuators
KW  - sensor-based control
DO  - 10.1109/IROS.2018.8594293
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.
ER  - 

TY  - CONF
TI  - Sliding-Layer Laminates: A Robotic Material Enabling Robust and Adaptable Undulatory Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5944
EP  - 5951
AU  - M. Jiang
AU  - N. Gravish
PY  - 2018
KW  - elasticity
KW  - hydrodynamics
KW  - marine control
KW  - mobile robots
KW  - motion control
KW  - sliding-layer laminates
KW  - robotic material enabling robust
KW  - adaptable undulatory locomotion
KW  - continuum robots
KW  - undulatory actuation
KW  - body materials
KW  - flexible movement
KW  - resistive forces
KW  - surrounding fluid
KW  - solid environments
KW  - robot designs
KW  - passive propulsive elements
KW  - wings
KW  - laminate design paradigm
KW  - f1exible-yet-stiff robotic materials
KW  - SLLs
KW  - design principles
KW  - morphable materials
KW  - swimming robot
KW  - passive tail
KW  - water swimming
KW  - steady swimming
KW  - robot tail
KW  - locomotion modes
KW  - confined swimming
KW  - confined environments
KW  - high stiffness
KW  - stiff tail designs
KW  - soft tail designs
KW  - complex underwater environments
KW  - robot locomotor
KW  - flexible-yet-stiff materials
KW  - Laminates
KW  - Structural beams
KW  - Springs
KW  - Jamming
KW  - Service robots
KW  - Laser beams
DO  - 10.1109/IROS.2018.8594421
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Continuum robots that move through undulatory actuation must be composed of body materials that can enable flexible movement yet also provide resistive forces to the surrounding fluid, granular, or solid environments. This need for “f1exible-yet-stiff” materials is notably important in robot designs that use passive propulsive elements such as tails and wings. Here we explore a laminate design paradigm for “f1exible-yet-stiff” robotic materials through sliding layer laminates (SLLs). We present design principles motivated by theory and experiment and illustrate a taxonomy of SLL enabled morphable materials capable of up to 7 fold change in stiffness. Lastly, we demonstrate the applicability of SLLs to undulatory continuum robots: a swimming robot with a passive tail. We target two desired robot locomotor behaviors: fast open water swimming, and steady swimming through narrow channels emulating underwater caverns and pipes. We demonstrate how tuning the stiffness of the robot tail maximizes thrust generation in these two locomotion modes. Soft tails are optimal in confined swimming because they generate short amplitude high wavenumber oscillations, while stiff tails in confined environments either collide with the walls or do not generate sufficient thrust. However, stiff tails are far better in unconfined environments which enable large stroke amplitudes requiring high stiffness. Through this demonstration we show that stiff or soft tail designs alone are incapable of effective locomotion in complex underwater environments challenge.
ER  - 

TY  - CONF
TI  - Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5952
EP  - 5957
AU  - Y. Mori
AU  - M. Zhu
AU  - H. Kim
AU  - A. Wada
AU  - M. Mitsuzuka
AU  - Y. Tajitsu
AU  - S. Kawamura
PY  - 2018
KW  - bending
KW  - dexterous manipulators
KW  - feedback
KW  - medical robotics
KW  - pipelines
KW  - pneumatic control equipment
KW  - pneumatic systems
KW  - position control
KW  - sensors
KW  - tactile sensors
KW  - vibrations
KW  - flexible material
KW  - flexible angle estimation sensor
KW  - flexible sensor
KW  - pneumatically driven flexible finger
KW  - Robot sensing systems
KW  - Optical sensors
KW  - Cameras
KW  - Optical fiber amplifiers
KW  - Voltage measurement
KW  - Three-dimensional displays
KW  - Printers
DO  - 10.1109/IROS.2018.8594081
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.
ER  - 

TY  - CONF
TI  - Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5958
EP  - 5963
AU  - H. Habibi
AU  - C. Yang
AU  - R. Kang
AU  - I. D. Walker
AU  - I. S. Godage
AU  - X. Dong
AU  - D. T. Branson
PY  - 2018
KW  - compliant mechanisms
KW  - continuum mechanics
KW  - finite element analysis
KW  - manipulator dynamics
KW  - shear modulus
KW  - large deformation continuum surfaces
KW  - soft continuum robotic arms
KW  - 3D integrated surface-arm model
KW  - lumped-mass methodology
KW  - soft robotics
KW  - Mathematical model
KW  - Robots
KW  - Load modeling
KW  - Deformable models
KW  - Strain
KW  - Actuators
KW  - Springs
DO  - 10.1109/IROS.2018.8594033
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.
ER  - 

TY  - CONF
TI  - Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5964
EP  - 5971
AU  - F. Rovida
AU  - D. Wuthier
AU  - B. Grossmann
AU  - M. Fumagalli
AU  - V. Krüger
PY  - 2018
KW  - control engineering computing
KW  - industrial robots
KW  - motion control
KW  - robot programming
KW  - trees (mathematics)
KW  - programming complexity
KW  - industrial robots
KW  - complex motions
KW  - self-contained primitive blocks
KW  - semantic skill
KW  - concurrent motion primitives
KW  - modeling skills
KW  - motion generators
KW  - behavior trees
KW  - task level programming
KW  - Task analysis
KW  - Generators
KW  - Robot kinematics
KW  - Force
KW  - Planning
KW  - Grippers
KW  - industrial robots
KW  - skills
KW  - reactive system
KW  - behavior tress
KW  - motio generators
KW  - assembly
DO  - 10.1109/IROS.2018.8594319
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.
ER  - 

TY  - CONF
TI  - Enhanced Explosive Motion for Torque Controlled Actuators Through Field Weakening Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - W. Roozing
AU  - N. Kashiri
AU  - N. G. Tsagarakis
PY  - 2018
KW  - actuators
KW  - machine control
KW  - motor drives
KW  - permanent magnet motors
KW  - robots
KW  - synchronous motors
KW  - torque control
KW  - surface permanent magnet synchronous machine motor drives
KW  - operating modes
KW  - constraints
KW  - system dynamics
KW  - reference torque
KW  - robotics applications
KW  - motor torque reference
KW  - motor drives
KW  - field weakening control
KW  - torque controlled actuators
KW  - enhanced explosive motion
KW  - peak velocity
KW  - Torque
KW  - Robots
KW  - Permanent magnet motors
KW  - Actuators
KW  - Synchronous motors
KW  - AC motors
KW  - Voltage control
DO  - 10.1109/IROS.2018.8593608
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a method to increase the peak output speed of surface permanent magnet synchronous machine (SPMSM) motor drives with application in robotics using field weakening control. Contrary to most existing works, the strategy is stateless and operates using only a motor torque reference as input, making it suitable for robotics applications in which reference torque and speed are continuously and rapidly changing. Based on the system dynamics and constraints, we obtain four different operating modes. The strategy is extensively validated using three different experiments, which show an increase in peak velocity of up to 33%. The results demonstrate that the proposed strategy is effective in extending the dynamic performance and explosive motion capabilities of robots.
ER  - 

TY  - CONF
TI  - Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5980
EP  - 5986
AU  - M. Rigotti-Thompson
AU  - M. Torres-Torriti
AU  - F. A. Cheein
AU  - G. Troni
PY  - 2018
KW  - active disturbance rejection control
KW  - end effectors
KW  - feedforward
KW  - H∞ control
KW  - hydraulic actuators
KW  - loading equipment
KW  - mining
KW  - mobile robots
KW  - PD control
KW  - vehicle dynamics
KW  - wheels
KW  - active disturbance rejection control
KW  - skid-steer loader
KW  - H∞ control
KW  - PD control
KW  - ADRC
KW  - inertial sensors
KW  - hydraulic arm dynamics
KW  - wheels
KW  - end-effector
KW  - front-end loaders
KW  - robotic mining mobile manipulators
KW  - material spillage
KW  - hydraulic actuators
KW  - autonomous machines
KW  - feedforward action
KW  - proportional-derivative control
KW  - Manipulator dynamics
KW  - Force
KW  - Dynamics
KW  - Mathematical model
KW  - Hydraulic actuators
KW  - Wheels
DO  - 10.1109/IROS.2018.8594172
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H∞ control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat® 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.
ER  - 

TY  - CONF
TI  - Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - D. Kim
AU  - J. Lee
AU  - J. Ahn
AU  - O. Campbell
AU  - H. Hwang
AU  - L. Sentis
PY  - 2018
KW  - force control
KW  - friction
KW  - humanoid robots
KW  - legged locomotion
KW  - mechanical contact
KW  - quadratic programming
KW  - robot dynamics
KW  - robust control
KW  - centroidal momentum dynamics
KW  - computationally-robust whole-body controller
KW  - quadratic program
KW  - passive-ankle bipedal robot
KW  - dynamic locomotion behaviors
KW  - smooth contact transitions
KW  - friction cone constraints
KW  - task accelerations
KW  - computational robustness
KW  - floating base dynamics
KW  - internal force constraints
KW  - contact reaction forces
KW  - operational task priorities
KW  - algorithmic computations
KW  - prioritized whole-body controllers
KW  - humanoid robots
KW  - multiobjective control
KW  - contact constraints
KW  - Task analysis
KW  - Null space
KW  - Dynamics
KW  - Acceleration
KW  - Robots
KW  - Force
KW  - Torque
DO  - 10.1109/IROS.2018.8593767
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.
ER  - 

TY  - CONF
TI  - Continuously Shaping Projections and Operational Space Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5995
EP  - 6002
AU  - N. Dehio
AU  - D. Kubus
AU  - J. J. Steil
PY  - 2018
KW  - least squares approximations
KW  - robots
KW  - projection operators
KW  - multiobjective robot control
KW  - dynamic task priority rearrangement
KW  - projection shaping
KW  - damped least squares
KW  - idempotent projectors
KW  - shaping operators
KW  - stack-of-tasks prioritization scheme
KW  - single task dimensions continuous priority rearrangement
KW  - Task analysis
KW  - Aerospace electronics
KW  - Jacobian matrices
KW  - Robots
KW  - Interference
KW  - Torque
KW  - Nickel
DO  - 10.1109/IROS.2018.8593400
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.
ER  - 

TY  - CONF
TI  - Dual-Arm Relative Tasks Performance Using Sparse Kinematic Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6003
EP  - 6009
AU  - S. Tarbouriech
AU  - B. Navarro
AU  - P. Fraisse
AU  - A. Crosnier
AU  - A. Cherubini
AU  - D. Sallé
PY  - 2018
KW  - manipulator kinematics
KW  - mobile robots
KW  - robotic assembly
KW  - dual-arm relative tasks performance
KW  - standard controllers
KW  - hierarchical sparse QP architecture
KW  - coordinated task
KW  - sparse kinematic control strategy
KW  - autonomous assembly units
KW  - dual-arm robots
KW  - production lines
KW  - Task analysis
KW  - Kinematics
KW  - Robot kinematics
KW  - Jacobian matrices
KW  - Manipulators
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594320
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To make production lines more flexible, dual-arm robots are good candidates to be deployed in autonomous assembly units. In this paper, we propose a sparse kinematic control strategy, that minimizes the number of joints actuated for a coordinated task between two arms. The control strategy is based on a hierarchical sparse QP architecture. We present experimental results that highlight the capability of this architecture to produce sparser motions (for an assembly task) than those obtained with standard controllers.
ER  - 

TY  - CONF
TI  - Jet-HR1: Stepping Posture Optimization for Bipedal Robot Over Large Ditch Based on a Ducted-fan Propulsion System*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6010
EP  - 6015
AU  - B. Liu
AU  - Z. Huang
AU  - J. Wei
AU  - C. Shi
AU  - J. Ota
AU  - Y. Zhang
PY  - 2018
KW  - aerospace propulsion
KW  - ducts
KW  - fans
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - optimisation
KW  - ducted-fan propulsion system
KW  - prototype robot
KW  - stepping posture optimization
KW  - bipedal robot
KW  - two-dimensional gaits
KW  - Jet-HRl
KW  - jet humanoid robot
KW  - Legged locomotion
KW  - Foot
KW  - Fans
KW  - Propulsion
KW  - Gravity
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594055
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper reports the latest progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over a broad ditch with a height difference between the two sides. This work focuses on the methods of calculating the boundary and optimizing stepping posture to use less thrust and keep the robot balanced while stepping over the ditch. With the proposed methods and new two-dimensional gaits, the prototype robot, named Jet-HRl (Jet Humanoid Robot ver.l) was able to completely step over a broad ditch with 450mm in width (up to 97% of the robot's leg's length), and a height difference of 100mm between two sides.
ER  - 

TY  - CONF
TI  - User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6016
EP  - 6022
AU  - G. Chalvatzaki
AU  - X. S. Papageorgiou
AU  - P. Maragos
AU  - C. S. Tzafestas
PY  - 2018
KW  - assisted living
KW  - gait analysis
KW  - geriatrics
KW  - human-robot interaction
KW  - intelligent robots
KW  - laser ranging
KW  - medical robotics
KW  - multi-robot systems
KW  - stability
KW  - state estimation
KW  - on-line gait characterization
KW  - robotic MAD
KW  - IMM-PDA-PF
KW  - intelligent robotic mobility assistive device
KW  - human-robot formation controller
KW  - gait cycle
KW  - pathological gait parametrization
KW  - human gait phases
KW  - on-line estimation
KW  - single laser-range-finder
KW  - user-adaptive human-robot system
KW  - pathological gait characterization
KW  - augmented human state estimation
KW  - intelligent robotic walker
KW  - user-adaptive human-robot formation control
KW  - Legged locomotion
KW  - Pathology
KW  - State estimation
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594360
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.
ER  - 

TY  - CONF
TI  - Passivity Based Iterative Learning of Admittance-Coupled Dynamic Movement Primitives for Interaction with Changing Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6023
EP  - 6028
AU  - A. Kramberger
AU  - E. Shahriari
AU  - A. Gams
AU  - B. Nemec
AU  - A. Ude
AU  - S. Haddadin
PY  - 2018
KW  - adaptive control
KW  - feedback
KW  - iterative learning control
KW  - learning systems
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - admittance-coupled dynamic movement primitives
KW  - compact task representations
KW  - sensor-based goal adaptations
KW  - adaptive motion capabilities
KW  - learning process
KW  - environmental changes
KW  - contact wrench feedback dynamics
KW  - iterative learning approach
KW  - system passivity analysis
KW  - Kuka LWR robot
KW  - nonrigid contact
KW  - passivity based iterative learning
KW  - reference power tracking
KW  - Robots
KW  - Impedance
KW  - Trajectory
KW  - Force feedback
KW  - Dynamics
KW  - Task analysis
KW  - Admittance
DO  - 10.1109/IROS.2018.8593647
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Encoding desired motions into dynamic movement primitives (DMPs) is a common way for generating compact task representations that are able to handle sensor-based goal adaptations. At the same time, a robot should not only express adaptive motion capabilities at planning level, but use also contact wrench feedback in the adaptation and learning process of the DMP. Despite first approaches exist in this direction, no fully integrated approach has been proposed so far. In this paper, we introduce a new class of admittance-coupled DMPs that addresses environmental changes by including contact wrench feedback dynamics into the DMP formalism. Moreover, a novel iterative learning approach is devised that is based on monitoring the overall system passivity analysis in terms of reference power tracking. Simulations and experimental results with the Kuka LWR robot maintaining a non-rigid contact with the environment (wiping a surface) are shown for supporting the validity of our approach.
ER  - 

TY  - CONF
TI  - Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6029
EP  - 6036
AU  - C. Mueller
AU  - J. Venicx
AU  - B. Hayes
PY  - 2018
KW  - learning (artificial intelligence)
KW  - robots
KW  - concept constrained learning from demonstration
KW  - robust robot learning
KW  - constrained learning
KW  - LfD process
KW  - conceptually-grounded constraints
KW  - robust skill learning
KW  - CC-LfD
KW  - conceptual constraints
KW  - skill repair
KW  - Trajectory
KW  - Maintenance engineering
KW  - Task analysis
KW  - Training
KW  - Service robots
KW  - Planning
DO  - 10.1109/IROS.2018.8594133
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by leveraging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.
ER  - 

TY  - CONF
TI  - Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6037
EP  - 6042
AU  - R. B. Warrier
AU  - S. Devasia
PY  - 2018
KW  - augmented reality
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - regression analysis
KW  - robot dynamics
KW  - robot programming
KW  - telerobotics
KW  - human motor dynamics
KW  - kernel-based regression approach
KW  - inverse human-dynamics response
KW  - human-in-the-loop demonstrator
KW  - kernel-based human-dynamics inversion
KW  - precision robot motion-primitives
KW  - human demonstrator
KW  - robot controller
KW  - multiple iterations
KW  - assisted teleoperation
KW  - augmented reality display
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Gaussian processes
KW  - Biological system modeling
KW  - Kernel
KW  - Estimation
DO  - 10.1109/IROS.2018.8594164
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.
ER  - 

TY  - CONF
TI  - Associative Skill Memory Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6043
EP  - 6048
AU  - H. Girgin
AU  - E. Ugur
PY  - 2018
KW  - force feedback
KW  - Gaussian processes
KW  - grippers
KW  - haptic interfaces
KW  - hidden Markov models
KW  - humanoid robots
KW  - mobile robots
KW  - neurophysiology
KW  - regression analysis
KW  - perturbed movements
KW  - torque trajectories
KW  - Parametric Hidden Markov Models
KW  - force feedback model
KW  - associative skill memory models
KW  - ASMs
KW  - stereotypical movements
KW  - stereotypical sensory events
KW  - dynamic movement primitives
KW  - noisy perception
KW  - stored sensory trajectories
KW  - haptic measurements
KW  - tactile measurements
KW  - perturbed movement deviates
KW  - stored single sensory trajectory instances
KW  - sensory event models
KW  - Hidden Markov models
KW  - Robot sensing systems
KW  - Trajectory
KW  - Task analysis
KW  - Force feedback
KW  - Force
DO  - 10.1109/IROS.2018.8593450
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Associative Skill Memories (ASMs) were formulated to encode stereotypical movements along with their stereotypical sensory events to increase the robustness of underlying dynamic movement primitives (DMPs) against noisy perception and perturbations. In ASMs, the stored sensory trajectories, such as the haptic and tactile measurements, are used to compute how much a perturbed movement deviates from the desired one, and to correct the movement if possible. In our work, we extend ASMs: rather than using stored single sensory trajectory instances, our system generates sensory event models and exploits those models to correct the perturbed movements during executions with the aim of generalizing to novel configurations. In particular, measured force and the torque trajectories are modelled using Parametric Hidden Markov Models, and then reproduced by Gaussian Mixture Regression. With Baxter robot, we demonstrate that our proposed force feedback model can be used to correct a trajectory while pushing an object with a mass never experienced before, and which otherwise slips away from the gripper because of noise. In the end, we discuss how far this skill can be generalized using the force model and possible future improvements.
ER  - 

TY  - CONF
TI  - Towards Intelligent Arbitration of Diverse Active Learning Queries
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6049
EP  - 6056
AU  - K. Bullard
AU  - A. L. Thomaz
AU  - S. Chernova
PY  - 2018
KW  - decision theory
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - query processing
KW  - diverse active learning queries
KW  - optimal queries
KW  - learning agent
KW  - active learner
KW  - decision-theoretic arbitration strategies
KW  - decision-theoretic strategy
KW  - intelligent arbitration
KW  - rule-based arbitration strategies
KW  - passive learning
KW  - Task analysis
KW  - Training
KW  - Grounding
KW  - Robots
KW  - Feature extraction
KW  - Hafnium
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8594279
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Active learning literature has explored the selection of optimal queries by a learning agent with respect to given criteria, but prior work in classification has focused only on obtaining labels for queried samples. In contrast, proficient learners, like humans, integrate multiple forms of information during learning. This work seeks to enable an active learner to reason about multiple query types concurrently, aimed at soliciting both instance and feature information from the teacher, and to autonomously arbitrate between queries of different types. We contribute the design of rule-based and decision-theoretic arbitration strategies and evaluate all against baselines of more traditional passive and active learning. Our findings show that all arbitration strategies lead to more efficient learning, compared to the baselines. Moreover, given a dynamically changing environment and constrained questioning budget (typical in human settings), the decision-theoretic strategy statistically outperforms all other methods since it reasons about both what query to make and when to make a query, in order to most effectively utilize its questioning budget.
ER  - 

TY  - CONF
TI  - Segmenting and Sequencing of Compliant Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. M. Hagos
AU  - M. Suomalainen
AU  - V. Kyrki
PY  - 2018
KW  - end effectors
KW  - expectation-maximisation algorithm
KW  - force sensors
KW  - hidden Markov models
KW  - human-robot interaction
KW  - motion control
KW  - probability
KW  - nonhomogeneous hidden Markov model
KW  - expectation-maximization algorithm
KW  - cartesian impedance controller parameter
KW  - KUKA LWR4+ arm
KW  - parameter estimation
KW  - HMM model
KW  - hidden phase transition probabilities
KW  - segmented phase
KW  - compliant motions
KW  - Hidden Markov models
KW  - Task analysis
KW  - Motion segmentation
KW  - Adaptation models
KW  - Computational modeling
KW  - Impedance
DO  - 10.1109/IROS.2018.8593710
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an approach for segmenting a task consisting of compliant motions into phases, learning a primitive for each segmented phase of the task, and reproducing the task by sequencing primitives online based on the learned model. As compliant motions can “probe” the environment, using the interaction between the robot and the environment to detect phase transitions can make the transitions less prone to positional errors. This intuition leads us to model a task with a non-homogeneous Hidden Markov Model (HMM), wherein hidden phase transition probabilities depend on the interaction with the environment (wrench measured by an F/T sensor). Expectation-maximization algorithm is employed in estimating the parameters of the HMM model. During reproduction, the phase changes of a task are detected online using the forward algorithm, with the parameters learned from demonstrations. Cartesian impedance controller parameters are learned from the demonstrations to reproduce each phase of the task. The proposed approach is studied with a KUKA LWR4+ arm in two setups. Experiments show that the method can successfully segment and reproduce a task consisting of compliant motions with one or more demonstrations, even when demonstrations do not have the same starting position and external forces occur from different directions. Finally, we demonstrate that the method can also handle rotational motions.
ER  - 

TY  - CONF
TI  - An Uncertainty-Aware Minimal Intervention Control Strategy Learned from Demonstrations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6065
EP  - 6071
AU  - J. Silvério
AU  - Y. Huang
AU  - L. Rozo
AU  - D. G. caldwell
PY  - 2018
KW  - learning (artificial intelligence)
KW  - motion control
KW  - robots
KW  - robots
KW  - human environments
KW  - active compliance
KW  - minimal intervention control principle
KW  - task demonstrations
KW  - proper gain estimation
KW  - unpredictable robot motions
KW  - robot compliant
KW  - data-efficient strategy
KW  - torque-controlled robot
KW  - uncertainty-aware minimal intervention control strategy
KW  - Robots
KW  - Uncertainty
KW  - Hidden Markov models
KW  - Task analysis
KW  - Impedance
KW  - Probabilistic logic
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594220
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motivated by the desire to have robots physically present in human environments, in recent years we have witnessed an emergence of different approaches for learning active compliance. Some of the most compelling solutions exploit a minimal intervention control principle, correcting deviations from a goal only when necessary, and among those who follow this concept, several probabilistic techniques have stood out from the rest. However, these approaches are prone to requiring several task demonstrations for proper gain estimation and to generating unpredictable robot motions in the face of uncertainty. Here we present a Programming by Demonstration approach for uncertainty-aware impedance regulation, aimed at making the robot compliant - and safe to interact with - when the uncertainty about its predicted actions is high. Moreover, we propose a data-efficient strategy, based on the energy observed during demonstrations, to achieve minimal intervention control, when the uncertainty is low. The approach is validated in an experimental scenario, where a human collaboratively moves an object with a 7-DoF torque-controlled robot.
ER  - 

TY  - CONF
TI  - Generative Low-Shot Network Expansion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6072
EP  - 6077
AU  - A. Hayat
AU  - M. Kliger
AU  - S. Fleishman
AU  - D. Cohen-Or
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pattern classification
KW  - conventional deep learning classifiers
KW  - pre-trained deep network
KW  - base network
KW  - low-shot training scenarios
KW  - compact generative model
KW  - generative low-shot network expansion
KW  - hard distillation method
KW  - memory footprint
KW  - Training
KW  - Training data
KW  - Data models
KW  - Memory management
KW  - Task analysis
KW  - Robots
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8594004
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Conventional deep learning classifiers are static in the sense that they are trained on a predefined set of classes and learning to classify a novel class typically requires re-training. In this work, we address the problem of Low-Shot network-expansion learning. We introduce a learning framework which enables expanding a pre-trained (base) deep network to classify novel classes when the number of examples for the novel classes is particularly small. We present a simple yet powerful hard distillation method where the base network is augmented with additional weights to classify the novel classes, while keeping the weights of the base network unchanged. We show that since only a small number of weights needs to be trained, the hard distillation excels in low-shot training scenarios. Furthermore, hard distillation avoids detriment to classification performance on the base classes. Finally, we show that low-shot network expansion can be done with a very small memory footprint by using a compact generative model of the base classes training data with only a negligible degradation relative to learning with the full training set.
ER  - 

TY  - CONF
TI  - Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6078
EP  - 6085
AU  - X. Cheng
AU  - Z. Jia
AU  - A. Bhatia
AU  - R. M. Aronson
AU  - M. T. Mason
PY  - 2018
KW  - control engineering computing
KW  - decision trees
KW  - fasteners
KW  - industrial robots
KW  - pattern classification
KW  - production engineering computing
KW  - robotic assembly
KW  - sensors
KW  - support vector machines
KW  - technical challenges
KW  - affordable intelligent screwdriving system
KW  - online stage
KW  - result classification
KW  - state transition graph
KW  - labeled screwdriving dataset
KW  - multiple sensor signals
KW  - classification algorithms
KW  - sensor reduction
KW  - accurate result classifiers
KW  - linear discriminant analysis
KW  - feature subset selection
KW  - optimal feature subset
KW  - corresponding sensor signals
KW  - stage classifier
KW  - optimal sensor subset
KW  - sensor selection
KW  - stage & result classifications
KW  - automated miniature screwdriving
KW  - consumer electronics industry every year
KW  - screwdriving process
KW  - challenging tasks
KW  - robotic threaded fastening systems
KW  - system cost
KW  - Robot sensing systems
KW  - Fasteners
KW  - Joining processes
KW  - Fault detection
KW  - Torque
KW  - Reliability
DO  - 10.1109/IROS.2018.8593520
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.
ER  - 

TY  - CONF
TI  - Evaluating Methods for End-User Creation of Robot Task Plans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6086
EP  - 6092
AU  - C. Paxton
AU  - F. Jonathan
AU  - A. Hundt
AU  - B. Mutlu
AU  - G. D. Hager
PY  - 2018
KW  - manipulators
KW  - multi-robot systems
KW  - path planning
KW  - end-user creation
KW  - perception-driven task plans
KW  - collaborative robots
KW  - generalizable robot task plans
KW  - behavior tree-based CoSTAR system
KW  - pick-and-place assembly tasks
KW  - SmartMove
KW  - Task analysis
KW  - Planning
KW  - User interfaces
KW  - Service robots
KW  - Grippers
KW  - Collaboration
DO  - 10.1109/IROS.2018.8594127
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.
ER  - 

TY  - CONF
TI  - A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6093
EP  - 6098
AU  - H. Nakamoto
AU  - M. Ohtake
AU  - K. Komoda
AU  - A. Sugahara
AU  - A. Ogawa
PY  - 2018
KW  - force control
KW  - grippers
KW  - motion control
KW  - robust control
KW  - trajectory control
KW  - vacuum pumps
KW  - robust pinching
KW  - Amazon Robotics Challenge 2017
KW  - suction air
KW  - vacuum pump
KW  - pad characteristics
KW  - gripper system
KW  - trajectory planning
KW  - trajectory control
KW  - suction force
KW  - passive linear motion mechanism
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593887
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Suction is an effective method for picking various objects because it makes trajectory planning and control easy. However, suction has not been used due to misalignment and leakage of suction air when handling a variety of shapes. We therefore develop a hand to handle these characteristics. First, we model the vacuum pump and pad characteristics to allow evaluation of momentum and suction force in the case of leakage. Utilizing this, we select a configuration suitable for the items in the Amazon Robotics Challenge 2017. In addition, we design a mechanism for switching from suction to pinching for grasping items that cannot be sucked. Moreover, robust pinching is made possible by equipping the fingertips with a passive linear motion mechanism. In the Amazon Robotics Challenge 2017, it was shown possible to stably grasp items with irregularities and items with large moments. Furthermore, items that cannot be grasped by suction can also be grasped robustly by switching to the pinching mechanism.
ER  - 

TY  - CONF
TI  - Mass Manufacturing of Self-Actuating Robots: Integrating Sensors and Actuators Using Flexible Electronics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6099
EP  - 6104
AU  - A. Dementyev
AU  - J. Qi
AU  - J. Ou
AU  - J. Paradiso
PY  - 2018
KW  - actuators
KW  - bending
KW  - flexible electronics
KW  - microcontrollers
KW  - piezoelectric actuators
KW  - printed circuits
KW  - shape memory effects
KW  - air-pouch actuators
KW  - maximum bend angle
KW  - supporting electronics
KW  - flexible printed circuit
KW  - self-sensing robots
KW  - mass manufacturing
KW  - self-actuating robots
KW  - integrating sensors
KW  - nonstandard manufacturing techniques
KW  - electrical systems
KW  - mechanical systems
KW  - novel manufacturing technique
KW  - flexible electronics factory
KW  - standard industrial machines
KW  - air pouches
KW  - shape memory alloy
KW  - polyamide-based flexible circuit
KW  - Actuators
KW  - Robot sensing systems
KW  - Manufacturing
KW  - Shape memory alloys
KW  - Shape
DO  - 10.1109/IROS.2018.8593631
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Currently, the manufacturing of self-actuating and self-sensing robots requires non-standard manufacturing techniques and assembly steps to integrate electrical and mechanical systems. In this work, we developed a novel manufacturing technique, where such robots can be produced at a flexible electronics factory. We developed the technique using standard industrial machines, processes, and materials. Using a lamination process, we were able to integrate air pouches or shape memory alloy (SMA) inside a polyamide-based flexible circuit to produce bending actuators. The bend angle of the actuators is sensed with a chain of inertial measurement units integrated on the actuator. Air-pouch actuators can produce a force of a 2.24N, and a maximum bend angle of 74 degrees. To demonstrate, we manufactured a five-legged robot with the developed actuators and bend sensors, with all the supporting electronics (e.g., microcontrollers, radio) directly integrated into the flexible printed circuit. Such robots are flat and lightweight (15 grams) and thus conveniently compact for transportation and storage. We believe that our technique can allow inexpensive and fast prototyping and deployment of self-actuating and self-sensing robots.
ER  - 

TY  - CONF
TI  - Achieving Flexible Assembly Using Autonomous Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Gilday
AU  - J. Hughes
AU  - F. Iida
PY  - 2018
KW  - mobile robots
KW  - recycling
KW  - robotic assembly
KW  - single shot pre-fabrication methods
KW  - assembling
KW  - dis-assembly processes
KW  - agile development
KW  - resource usage
KW  - build process
KW  - robotic platform
KW  - assembly method
KW  - cost function
KW  - alternative fabrication methods
KW  - flexible assembly
KW  - autonomous robotic systems
KW  - prefabrication
KW  - speed advantages
KW  - autonomous flexible reassembly
KW  - simple Lego bricks
KW  - Robots
KW  - Grippers
KW  - Fabrication
KW  - Morphology
KW  - Robotic assembly
KW  - Optimization
KW  - Force
DO  - 10.1109/IROS.2018.8593852
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Prefabrication of structures is currently used in a limited capacity, due to the lack of flexibility, despite the potential cost and speed advantages. Autonomous flexible reassembly enables structures to be developed which can be continuously and iteratively dis-assembled and re-assembled providing far more flexibility in comparison to single shot pre-fabrication methods. Dis-assembly of structures should be considered when assembling, due to the asymmetry of assembly and dis-assembly processes, to ensure structures can be recycled and re-assembled. This allows for agile development, significantly reducing the time and resource usage during the build process. In this work, a framework for flexible re-assembly is developed and a robotic platform is developed to implement and test this framework with simple Lego bricks. The tradeoffs in terms of time, resource use and probability of success of this new assembly method can be understood by using a cost function to compare to alternative fabrication methods.
ER  - 

TY  - CONF
TI  - Human Pose Estimation in Presence of Occlusion Using Depth Camera Sensors, in Human-Robot Coexistence Scenarios
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - A. Casalino
AU  - S. Guzman
AU  - A. Maria Zanchettin
AU  - P. Rocco
PY  - 2018
KW  - cameras
KW  - human-robot interaction
KW  - image filtering
KW  - image sensors
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - robot vision
KW  - human-robot coexistence scenario
KW  - collaborative robotics
KW  - industrial scenario
KW  - vision sensors
KW  - cognitive software layers
KW  - human intentions
KW  - human pose estimation algorithms
KW  - partial occlusion
KW  - dual arm robot
KW  - depth camera sensors
KW  - particle filter techniques
KW  - Pose estimation
KW  - Kinematics
KW  - Service robots
KW  - Mathematical model
KW  - Collaboration
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593816
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Collaborative robotics over the last few years has gained increasing interest in the industrial scenario. Co-bots can be equipped with vision sensors and cognitive software layers, allowing the robot to figure out human intentions. To make this level of perception possible, human pose estimation algorithms are required. Several techniques have been already proposed to tackle this problem, which however present some weaknesses in particular when occlusions occur. This work proposes an algorithm for human pose estimation in the situations of partial occlusion, based on particle filter techniques. We have proved its validity in a realistic human-robot coexistence scenario, where a human and a dual arm robot have to perform tasks in a shared workspace.
ER  - 

TY  - CONF
TI  - Feasibility of the UR5 Industrial Robot for Robotic Rehabilitation of the Upper Limbs After Stroke
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - E. Kyrkjebø
AU  - M. Johan Laastad
AU  - Ø. Stavdahl
PY  - 2018
KW  - human-robot interaction
KW  - industrial robots
KW  - injuries
KW  - medical robotics
KW  - motion control
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - human-robot collaboration
KW  - upper limbs
KW  - robot-assisted therapy
KW  - rehabilitation treatment
KW  - robotic rehabilitation devices
KW  - high-effort one-to-one interactions
KW  - physical rehabilitation
KW  - stroke patients
KW  - UR5 collaborative industrial robot
KW  - therapeutic treatment
KW  - rehabilitation exercises
KW  - high-intensity movements
KW  - neurological injuries
KW  - Service robots
KW  - Robot sensing systems
KW  - Training
KW  - Task analysis
KW  - Safety
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594413
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot-assisted therapy is an emerging form of rehabilitation treatment for motor recovery of the upper limbs after neurological injuries such as stroke or spinal cord injury. Robotic rehabilitation devices have the potential to reduce the physical strain put on therapists due to the high-effort one-to-one interactions between the therapist and patient involving repetitive high-intensity movements to restore arm and hand functions. Numerous custom robotic devices have been developed in recent years to aid in physical rehabilitation of stroke patients, but most commercially available systems are high-cost devices because of low production volumes and high development costs. In this paper, we analyse the safety and functionality of the UR5 collaborative industrial robot from universal Robots equipped with an external force/torque sensor in a real-time control system for typical rehabilitation exercises. The aim of the paper is to show that a new class of general-purpose industrial robots designed for human-robot collaboration may prove a viable alternative to custom designs. Experiments show that robotic rehabilitation of the upper limbs using a standard industrial robot manipulator UR5 may be feasible. Results have the potential to make robotic rehabilitation more available as a high-quality therapeutic treatment for more patients.
ER  - 

TY  - CONF
TI  - Safety-Related Tasks Within the Set-Based Task-Priority Inverse Kinematics Framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6130
EP  - 6135
AU  - P. Di Lillo
AU  - F. Arrichiello
AU  - G. Antonelli
AU  - S. Chiaverini
PY  - 2018
KW  - collision avoidance
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - equality-based task
KW  - task-priority inverse kinematics algorithm
KW  - set-based task-priority inverse kinematics framework
KW  - Jaco2 manipulator
KW  - RGB-D sensor
KW  - obstacle detection
KW  - obstacle avoidance tasks
KW  - joint-limits
KW  - set-based tasks
KW  - operational space
KW  - robotic arm
KW  - motion control
KW  - safety-related tasks
KW  - Task analysis
KW  - Manipulators
KW  - Robot sensing systems
KW  - Kinematics
KW  - Collision avoidance
KW  - Safety
DO  - 10.1109/IROS.2018.8593884
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a framework that allows the motion control of a robotic arm automatically handling different kinds of safety-related tasks. The developed controller is based on a Task-Priority Inverse Kinematics algorithm that allows the manipulator's motion while respecting constraints defined either in the joint or in the operational space in the form of equality-based or set-based tasks. This gives the possibility to define, among the others, tasks as joint-limits, obstacle avoidance or limiting the workspace in the operational space. Additionally, an algorithm for the real-time computation of the minimum distance between the manipulator and other objects in the environment using depth measurements has been implemented, effectively allowing obstacle avoidance tasks. Experiments with a Jaco2 manipulator, operating in an environment where an RGB-D sensor is used for the obstacles detection, show the effectiveness of the developed system.
ER  - 

TY  - CONF
TI  - Model-Based Engineering, Safety Analysis and Risk Assessment for Personal Care Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6136
EP  - 6141
AU  - N. Yakymets
AU  - M. Sango
AU  - S. Dhouib
AU  - R. Gelin
PY  - 2018
KW  - control engineering computing
KW  - fault trees
KW  - humanoid robots
KW  - risk management
KW  - safety
KW  - safety-critical software
KW  - service robots
KW  - specification languages
KW  - Unified Modeling Language
KW  - model-based engineering
KW  - risk assessment
KW  - personal care robots
KW  - couple model-based system engineering
KW  - robotic system life-cycle
KW  - Papyrus UML modeler
KW  - Safety Architect
KW  - failure mode
KW  - effects analysis
KW  - fault tree analysis
KW  - safety artefacts
KW  - modeling environment
KW  - humanoid personal care robot
KW  - safety analysis
KW  - Safety
KW  - Unified modeling language
KW  - Tools
KW  - Analytical models
KW  - Risk management
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594115
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a method and associate platform to couple model-based system engineering and safety analysis at the early phases of robotic system (RS) life-cycle. The method is compatible with IEC12100 and ISO13482. The platform is based on Papyrus UML modeler and supports RobotML, a domain specific language for RSs, as well as tools for safety analysis and risk assessment, Sophia and Safety Architect. It includes an ability (a) to model architecture of RSs; (b) to automatically run safety analysis (e.g. failure mode and effects analysis, fault tree analysis, etc.); (c) to save and reuse safety artefacts; (d) to represent safety analysis results in the modeling environment. We illustrate the proposed method by considering a humanoid personal care robot from SoftBank Robotics developed in the scope of the ROMEO2 project.
ER  - 

TY  - CONF
TI  - Computation of Safe Path Velocity for Collaborative Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6142
EP  - 6148
AU  - C. Sloth
AU  - H. G. Petersen
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - industrial robots
KW  - ISO standards
KW  - manufacturing systems
KW  - motion control
KW  - occupational safety
KW  - velocity control
KW  - safe path velocity
KW  - collaborative robot
KW  - safety requirements
KW  - collaborative method
KW  - safe collisions
KW  - point-wise maximal path velocity
KW  - post impact safety
KW  - ISO/TS 15066
KW  - power and force limiting
KW  - industrial manufacturing
KW  - Robots
KW  - Collision avoidance
KW  - Force
KW  - Safety
KW  - Collaboration
KW  - Effective mass
KW  - Limiting
DO  - 10.1109/IROS.2018.8594217
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a method for numerically computing the highest path velocity that a collaborative robot can attain, while complying with safety requirements. The safety requirements are obtained from ISO/TS 15066 that describes a collaborative method called power and force limiting, which specifies safe collisions between humans and robots. In particular, we assume that a path is given and compute the point-wise maximal path velocity that ensures a safe impact, i.e., the paper provides no considerations on the post impact safety.
ER  - 

TY  - CONF
TI  - Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6149
EP  - 6154
AU  - N. Patel
AU  - A. Nandini Saridena
AU  - A. Choromanska
AU  - P. Krishnamurthy
AU  - F. Khorrami
PY  - 2018
KW  - learning (artificial intelligence)
KW  - object detection
KW  - remotely operated vehicles
KW  - indoor environments
KW  - Udacity dataset
KW  - image conditioned energy based generative adversarial network
KW  - on-line monitoring framework
KW  - assured autonomy
KW  - Adversarial Learning-Based On-Line Anomaly Monitoring
KW  - autonomous ground vehicle
KW  - sensor data
KW  - action condition video prediction framework
KW  - anomalous actuator commands
KW  - proper actuator commands
KW  - generative adversarial network
KW  - SFAM
KW  - system-focused anomaly detection
KW  - CFAM
KW  - controller-focused anomaly detection
KW  - sensor inputs
KW  - unmanned ground vehicle
KW  - learning-based control systems
KW  - Generators
KW  - Convolution
KW  - Actuators
KW  - Monitoring
KW  - Anomaly detection
KW  - Robot sensing systems
KW  - Computer architecture
DO  - 10.1109/IROS.2018.8593375
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.
ER  - 

TY  - CONF
TI  - Inspection System for Automatic Measurement of Level Differences in Belt Conveyors Using Inertial Measurement Unit
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6155
EP  - 6161
AU  - A. Y. Yasutomi
AU  - H. Enoki
AU  - S. Yamaguchi
AU  - K. Tamura
PY  - 2018
KW  - belts
KW  - conveyors
KW  - inspection
KW  - maintenance engineering
KW  - sensors
KW  - transportation
KW  - belt conveyor inspection system
KW  - liquid container
KW  - conveyor maintenance
KW  - sensor progressing
KW  - cost-effective
KW  - human errors
KW  - automatic inspection
KW  - system disassembly
KW  - spillage
KW  - belt lines
KW  - transport systems
KW  - inertial measurement unit
KW  - automatic measurement
KW  - Belts
KW  - Inspection
KW  - Angular velocity
KW  - Batteries
KW  - Containers
KW  - Fixtures
KW  - Event detection
DO  - 10.1109/IROS.2018.8593906
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Belt conveyors are transport systems composed by a plurality of belt lines. When those systems are used to transport fragile materials or liquid containers, it is necessary to minimize the oscillations of the transported objects in order to avoid damage, spillage and particle degradation. Those oscillations are regularly caused by steps (i.e. differences in level) at the joints of the belt lines, and for that reason, it is necessary to inspect those steps during installation and maintenance. Regular inspections involve the visual verification of the steps, which stops production, takes significant time, occasionally requires system disassembly and is subjected to human errors. In this paper, a novel belt conveyor inspection system which is able to detect and measure the steps at the joints of the belt lines is presented. This system consists in the acquirement of data of the belt conveyor with an inertial measurement unit (IMU), and the processing of this data with original algorithms for zero offset filtering, sensor progressing direction detection, step event detection and step height calculation. The presented system had successfully detected and measured the steps of a complex belt conveyor with an accuracy of ±0.3 mm. It is demonstrated that this cost-effective and ready to use system enables an automatic and prompt inspection of the whole belt conveyor system at once, thus reducing the workload, time and errors of the belt conveyor inspection.
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning on Autonomous Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - D. Isele
AU  - A. Nakhaei
AU  - K. Fujimura
PY  - 2018
KW  - learning (artificial intelligence)
KW  - remotely operated vehicles
KW  - road traffic control
KW  - road vehicles
KW  - intersection handling behaviors
KW  - autonomous vehicle
KW  - safety critical applications
KW  - learning process
KW  - safe reinforcement learning
KW  - Safety
KW  - Autonomous vehicles
KW  - Trajectory
KW  - Games
KW  - Pipelines
KW  - Noise measurement
KW  - Standards
DO  - 10.1109/IROS.2018.8593420
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There have been numerous advances in reinforcement learning, but the typically unconstrained exploration of the learning process prevents the adoption of these methods in many safety critical applications. Recent work in safe reinforcement learning uses idealized models to achieve their guarantees, but these models do not easily accommodate the stochasticity or high-dimensionality of real world systems. We investigate how prediction provides a general and intuitive framework to constraint exploration, and show how it can be used to safely learn intersection handling behaviors on an autonomous vehicle.
ER  - 

TY  - CONF
TI  - Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Lee
AU  - B. Min
PY  - 2018
KW  - control engineering computing
KW  - direction-of-arrival estimation
KW  - multi-robot systems
KW  - networked control systems
KW  - security of data
KW  - statistical analysis
KW  - networked multirobot systems
KW  - parametric statistical tool
KW  - wireless network
KW  - DoA-aided attack detection scheme
KW  - multirobot testbed
KW  - distributed direction of arrival estimation-aided cyberattack detection
KW  - Direction-of-arrival estimation
KW  - Robot sensing systems
KW  - Multi-robot systems
KW  - Antenna measurements
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594465
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.
ER  - 

TY  - CONF
TI  - Evaluating Robotic Devices of Non-Wearable Transferring Aids Using Whole-Body Robotic Simulator of the Elderly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Matsumoto
AU  - K. Ogata
AU  - I. Kajitani
AU  - K. Homma
AU  - Y. Wakita
PY  - 2018
KW  - assisted living
KW  - geriatrics
KW  - handicapped aids
KW  - medical robotics
KW  - patient care
KW  - service robots
KW  - quantitative physical evaluation
KW  - whole-body robotic system
KW  - assistive robotic devices
KW  - physical assistance
KW  - nursing care
KW  - elderly person
KW  - whole-body robotic simulator
KW  - nonwearable transferring aids
KW  - Safety
KW  - Legged locomotion
KW  - Receivers
KW  - Senior citizens
KW  - Medical services
DO  - 10.1109/IROS.2018.8594022
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes the development of a whole-body robotic simulator of an elderly person for evaluating robotics devices for nursing care. To improve the quality of life of the elderly persons, physical assistance such as transfer, movement, and bathroom assistance is important. It is also important to reduce the workload of caregivers in an aging society. In recent years, assistive robotic devices for nursing care have been developed and commercialized for such purposes. However, such devices have not become popular in the care facilities yet. One of the reasons is that it is still difficult to evaluate the effects of the devices on the care receivers and caregivers. In particular, it is necessary to quantitatively evaluate the effect of the devices on the human body from the viewpoint of safety and comfort. We have developed a whole-body robotic system to simulate the pose and motion of the elderly persons. The purpose of this system is to realize quantitative physical evaluation of robotics devices for nursing care of the human body. The experimental results of the preliminary evaluation of assistive robotic devices are also presented.
ER  - 

TY  - CONF
TI  - Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - L. Yang
AU  - Y. Zhang
AU  - C. Vong
AU  - L. Zhang
PY  - 2018
KW  - cellular transport
KW  - collision avoidance
KW  - fluorescence
KW  - goods distribution
KW  - microrobots
KW  - mobile robots
KW  - nanoparticles
KW  - particle swarm optimisation
KW  - path planning
KW  - position control
KW  - quantum dots
KW  - tracking
KW  - trajectory control
KW  - Mag-Spore
KW  - fluorescence microscopy
KW  - fluorescence imaging
KW  - observer-based trajectory tracking controller
KW  - multifunctional magnetic Spores
KW  - microrobotic cargo delivery possesses
KW  - complex environmental conditions
KW  - obstructed optical feedback
KW  - automated control approach
KW  - microrobotic cargo carrier
KW  - multifunctional magnetic spore
KW  - Magnetic resonance imaging
KW  - Automation
KW  - Magnetic multilayers
KW  - Carbon
KW  - Stem cells
KW  - Optimization
DO  - 10.1109/IROS.2018.8593790
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.
ER  - 

TY  - CONF
TI  - Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - W. Wang
AU  - V. Kishore
AU  - L. Koens
AU  - E. Lauga
AU  - M. Sitti
PY  - 2018
KW  - microrobots
KW  - mobile robots
KW  - microchannels
KW  - pairwise interactions
KW  - local interactions
KW  - collective behaviors
KW  - mobile microrobot collectives
KW  - multiple spinning microrafts
KW  - air-water interface
KW  - object manipulation
KW  - spinning mobile microrobots
KW  - size 100.0 mum
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593519
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.
ER  - 

TY  - CONF
TI  - Fabrication and Locomotion of Flexible Nanoswimmers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6193
EP  - 6198
AU  - B. Jang
AU  - A. Aho
AU  - B. J. Nelson
AU  - S. Pané
PY  - 2018
KW  - hinges
KW  - magnetic fields
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - 1-link swimmer
KW  - semisoft tail
KW  - nanoscale swimmers
KW  - sophisticated locomotion mechanisms
KW  - hinges
KW  - soft joints
KW  - small-scale robots
KW  - flexible nanoswimmers
KW  - magnetic fields
KW  - oscillating magnetic field frequency
KW  - undulatory locomotion
KW  - 2-link swimmer
KW  - soft hinge
KW  - rigid magnetic head
KW  - Nickel
KW  - Magnetic fields
KW  - Gold
KW  - Resonant frequency
KW  - Magnetosphere
KW  - Fabrication
KW  - Fasteners
DO  - 10.1109/IROS.2018.8594047
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Small-scale robots with soft joints and hinges have recently attracted interest because these components allow for more sophisticated locomotion mechanisms. Here, we investigate two different types of nanoscale swimmers as depicted in Figure 1. One consists of a rigid magnetic head linked to a semi-soft tail (1-link swimmer). Another consists of a rigid magnetic head and tail connected by a soft hinge (2-link swimmer). Both swimmers exhibit undulatory locomotion under an applied oscillating magnetic field. The speeds of the swimmers are assessed as a function of the oscillating magnetic field frequency and the sweeping angle. We find that a resonance-like frequency increases as the length decreases, and, in general, the speed increases as the sweeping angle increases. Last, we show that 2-link swimmers can also swim in a corkscrew-like pattern under rotating magnetic fields.
ER  - 

TY  - CONF
TI  - Gait Learning for Soft Microrobots Controlled by Light Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6199
EP  - 6206
AU  - A. von Rohr
AU  - S. Trimpe
AU  - A. Marco
AU  - P. Fischer
AU  - S. Palagi
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - control system synthesis
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - microrobots
KW  - optimisation
KW  - self-adaptive microrobotic systems
KW  - light-controlled soft microrobots
KW  - probabilistic learning control
KW  - gait learning
KW  - light fields
KW  - analytical control design
KW  - gait optimization
KW  - locomotion models
KW  - data-driven approaches
KW  - Bayesian optimization
KW  - Gaussian processes
KW  - BO
KW  - GPs
KW  - Robots
KW  - Cost function
KW  - Kernel
KW  - Strain
KW  - Laser beams
KW  - Tuning
DO  - 10.1109/IROS.2018.8594092
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.
ER  - 

TY  - CONF
TI  - A Novel Monocular-Based Navigation Approach for UAV Autonomous Transmission-Line Inspection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - J. Bian
AU  - X. Hui
AU  - X. Zhao
AU  - M. Tan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - image registration
KW  - inspection
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - path planning
KW  - poles and towers
KW  - power overhead lines
KW  - robot vision
KW  - UAV autonomous navigation approach
KW  - pan-tilt monocular-based navigation scheme
KW  - neural network
KW  - homography matrix
KW  - distance variation
KW  - point set registration model
KW  - tower detection
KW  - overhead transmission lines
KW  - UAV autonomous transmission-line inspection
KW  - Poles and towers
KW  - Inspection
KW  - Navigation
KW  - Power transmission lines
KW  - Kernel
KW  - Cameras
KW  - Safety
DO  - 10.1109/IROS.2018.8593926
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a unique and robust UAV autonomous navigation approach along one side of overhead transmission lines for inspection. To this end, we establish a perspective model and develop a novel Pan/Tilt monocular-based navigation scheme. Simultaneously, the following three key issues are addressed. First, to locate the effective landmark - transmission tower timely and reliably, we customize a neural network for tower detection and combine it with a fast and smooth tracking. Second, to provide UAV with a robust and precise heading, we detect the transmission lines and compute and optimize their vanishing point. Third, to keep a safe distance from transmission lines, we optimize a homography matrix to restore the parallel nature of transmission lines and perceive the distance variation by a point set registration model. Finally, by the designed UAV platform, we test the whole system in a real-world transmission-line inspection scenario under different weather condition and achieve an encouraging result. Our approach provides great flexibility for refined inspection and effectively improves inspection safety.
ER  - 

TY  - CONF
TI  - Ceiling Effects for Surface Locomotion of Small Rotorcraft
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6214
EP  - 6219
AU  - Y. H. Hsiao
AU  - P. Chirarattananon
PY  - 2018
KW  - aerodynamics
KW  - aerospace robotics
KW  - helicopters
KW  - mobile robots
KW  - propellers
KW  - small rotorcraft
KW  - ceiling effects
KW  - surface locomotion
KW  - energy saving strategy
KW  - flying robots
KW  - spinning propeller
KW  - classical momentum theory
KW  - blade element method
KW  - bimodal aerial locomotion
KW  - Propellers
KW  - Robots
KW  - Blades
KW  - Rotors
KW  - Aerodynamics
KW  - Spinning
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593726
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motivated by the potential of bimodal aerial and surface locomotion as an energy saving strategy for small flying robots, we investigate the effects of a flat overhang surface in the vicinity of a spinning propeller. We employ the classical momentum theory and the blade element method to describe the “ceiling effects” in regards to the generated thrust, power, and rotational speed of the propeller in terms of a normalized distance between the ceiling and the propeller. Validating experiments were performed on a benchtop setup, and the results are in agreement with the proposed models. The presence of a ceiling was found to reduce the power consumption by more than a factor of three for the same thrust force. Overall, our findings show promise, paving the way for the use of perching maneuvers by small rotorcraft to extend their missions.
ER  - 

TY  - CONF
TI  - Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. M. Popek
AU  - M. S. Johannes
AU  - K. C. Wolfe
AU  - R. A. Hegeman
AU  - J. M. Hatch
AU  - J. L. Moore
AU  - K. D. Katyal
AU  - B. Y. Yeh
AU  - R. J. Bamberger
PY  - 2018
KW  - autonomous aerial vehicles
KW  - biomimetics
KW  - control system synthesis
KW  - helicopters
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - sensors
KW  - AGRASP
KW  - multirotor aerial vehicles
KW  - robotics perception
KW  - vision-based path planning
KW  - highly-constrained sensor
KW  - autonomous grasping robotic aerial system for perching
KW  - biomimetically-inspired manipulation
KW  - perch structures
KW  - innovative manipulator design
KW  - active grasp
KW  - passive grip
KW  - quadrotor autonomously detection
KW  - onboard sensing
KW  - onboard processing
KW  - Manipulators
KW  - Tendons
KW  - Robot sensing systems
KW  - Bars
KW  - Grasping
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593669
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.
ER  - 

TY  - CONF
TI  - Energy-Efficient Trajectory Generation for a Hexarotor with Dual- Tilting Propellers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6226
EP  - 6232
AU  - F. Morbidi
AU  - D. Bicego
AU  - M. Ryll
AU  - A. Franchi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - matrix algebra
KW  - optimal control
KW  - propellers
KW  - trajectory control
KW  - hexarotor
KW  - maneuverability
KW  - control allocation matrix
KW  - brushless motors
KW  - angular accelerations
KW  - optimal control problem
KW  - underactuation degree
KW  - dual- tilting propellers
KW  - energy-efficient trajectory generation
KW  - Propellers
KW  - Trajectory
KW  - Brushless motors
KW  - Batteries
KW  - Silicon
KW  - Force
KW  - Resource management
DO  - 10.1109/IROS.2018.8594419
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we consider a non-conventional hexarotor whose propellers can be simultaneously tilted about two orthogonal axes: in this way, its underactuation degree can be easily adapted to the task at hand. For a given tilt profile, the minimum-energy trajectory between two prescribed boundary states is explicitly determined by solving an optimal control problem with respect to the angular accelerations of the six brushless motors. We also perform, for the first time, a systematic study of the singularities of the control allocation matrix of the hexarotor, showing the presence of subtle singular configurations that should be carefully avoided in the design phase. Numerical experiments conducted with the FAST-Hex platform illustrate the theory and delineate the pros and cons of dual-tilting paradigm in terms of maneuverability and energy efficiency.
ER  - 

TY  - CONF
TI  - Towards Autonomous Stratospheric Flight: A Generic Global System Identification Framework for Fixed-Wing Platforms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6233
EP  - 6240
AU  - J. Lee
AU  - T. Muskardin
AU  - C. R. Pacz
AU  - P. Oettershagen
AU  - T. Stastny
AU  - I. Sa
AU  - R. Siegwart
AU  - K. Kondak
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - error analysis
KW  - interpolation
KW  - Mach number
KW  - parameter estimation
KW  - Mach numbers
KW  - parameter identification techniques
KW  - fixed-wing platforms
KW  - flight test data
KW  - aerodynamic model
KW  - autonomous stratospheric flight
KW  - generic global system identification
KW  - high altitude long endurance fixed-wing aerial vehicles
KW  - extrapolation analysis
KW  - error analysis
KW  - autonomous missions
KW  - time efficient model
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Aircraft
KW  - Mathematical model
KW  - Databases
KW  - Data models
KW  - Unmanned aerial vehicles
DO  - 10.1109/IROS.2018.8594126
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - System identification of High Altitude Long Endurance fixed-wing aerial vehicles is challenging as its operating flight envelope covers wide ranges of altitudes and Mach numbers. We present a new global system identification framework geared towards such fixed-wing aerial platforms where the aim is to build a global aerodynamic model without many repetitions of local system identification procedures or the use of any aerodynamic database. Instead we apply parameter identification techniques to virtually created system identification data and update the identified parameters with available flight test data. The proposed framework was evaluated using data set outside the flight envelope of the available flight test data, i.e. at different airspeeds considering both interpolation and extrapolation scenarios. The error analysis has shown that the obtained longitudinal aerodynamic model can accurately predict the pitch rate and pitch angle, mostly within a tolerance of +1.5 degrees/s and +2 degrees respectively. Such a cost and time efficient model development framework enables high fidelity simulation and precise control which ultimately leads to higher success rates in autonomous missions.
ER  - 

TY  - CONF
TI  - Design and Implementation of Cloud-Like Soft Drone S-Cloud
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Hwan Song
AU  - H. Wook Shon
AU  - G. Yang Yeon
AU  - H. Ryeol Choi
PY  - 2018
KW  - aerodynamics
KW  - airships
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - flow control
KW  - helium
KW  - prototypes
KW  - rotors (mechanical)
KW  - soft blimp part
KW  - center-pierced torus-shaped part
KW  - flow control mechanism
KW  - co-axial rotors
KW  - 2-axis crossed flaps
KW  - cloud-like soft drone S-cloud
KW  - translational motion
KW  - helium gas
KW  - collision damage
KW  - altitude control
KW  - attitude control
KW  - vehicle translational movements
KW  - Newton-Euler formulation
KW  - prototypes
KW  - He
KW  - Rotors
KW  - Force
KW  - Drones
KW  - Helium
KW  - Vehicle dynamics
KW  - Buoyancy
DO  - 10.1109/IROS.2018.8593601
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study presents a new drone, called S-CLOUD, developed for safe and long flight time. It provides 3-axial (x, y, and z)translational motion and stable hovering for more than an hour after takeoff. S-CLOUD consists of two parts; soft blimp part and driving one. The soft blimp is a center-pierced torus-shaped part filled with Helium gas. Thus, it is safe to fly near people because it is light and soft, and all its rotating parts are at the center of the vehicle, which does not get damaged on collision. The driving part is plugged into the center of the soft blimp and includes the flow control mechanism, which consists of co-axial rotors and 2-axis crossed flaps. It controls the altitude, attitude, and translational movements of the vehicle. Its dynamic and reaction features against disturbances are derived using Newton-Euler formulation, and the simulation results are discussed. Finally, a prototype of S-CLOUD is fabricated and its feasibility is experimentally validated with practical applications.
ER  - 

TY  - CONF
TI  - Recovery Control for Quadrotor UAV Colliding with a Pole
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6247
EP  - 6254
AU  - G. Dicker
AU  - I. Sharf
AU  - P. Rustagi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - collision avoidance
KW  - helicopters
KW  - mobile robots
KW  - robot dynamics
KW  - robot vision
KW  - telerobotics
KW  - inertial onboard sensing
KW  - propeller-protected quadrotor UAV
KW  - collision recovery control solutions
KW  - poles
KW  - operator error
KW  - wind gusts
KW  - onboard cameras
KW  - microUAVs
KW  - air quality measurement
KW  - civil infrastructure inspection
KW  - police surveillance
KW  - disaster response
KW  - postcollision dynamics
KW  - onboard vision failure
KW  - Force
KW  - Collision avoidance
KW  - Mathematical model
KW  - Geometry
KW  - Drones
KW  - Aerodynamics
KW  - Propellers
DO  - 10.1109/IROS.2018.8594512
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Small quadrotor UAVs are projected to fly increasingly in urban environments for a wide variety of applications such as disaster response, police surveillance, civil infrastructure inspection, and air quality measurement. Micro UAVs can detect and avoid obstacles using onboard cameras; nevertheless, disturbances such as wind gusts, operator error, or failure of onboard vision can still result in dangerous collisions with objects. In the urban setting, the most predominant obstacles are walls and poles. With the aim of developing collision recovery control solutions for quadrotor UAVs, this paper investigates the collision dynamics between a propeller-protected quadrotor UAV and a vertical pole. Simulations provide insight into a quadrotor's post-collision dynamics and experimental trials demonstrate the feasibility of autonomously recovering to stable flight using only inertial onboard sensing in real-time.
ER  - 

TY  - CONF
TI  - ArduSoar: An Open-Source Thermalling Controller for Resource-Constrained Autopilots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6255
EP  - 6262
AU  - S. Tabor
AU  - I. Guilliard
AU  - A. Kolobov
PY  - 2018
KW  - aerospace components
KW  - aerospace simulation
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - resource-constrained autopilots
KW  - autonomous soaring capability
KW  - soaring controller
KW  - autopilot software suite
KW  - algorithmic standpoint
KW  - ArduPlane autopilot
KW  - parameter tuning
KW  - open-source thermalling controller
KW  - fixed-wing UAV
KW  - ArduSoars robustness
KW  - Aircraft
KW  - Atmospheric modeling
KW  - Computational modeling
KW  - Kalman filters
KW  - Mathematical model
KW  - Heating systems
KW  - Earth
DO  - 10.1109/IROS.2018.8593510
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous soaring capability has the potential to significantly increase time aloft for fixed-wing UAVs. In this paper, we introduce ArduSoar, the first soaring controller integrated into a major autopilot software suite for small UAVs. We describe ArduSoar from the algorithmic standpoint, outline its integration with the ArduPlane autopilot, discuss parameter tuning for it, and conduct a series of flight tests on real sUAVs that show ArduSoar's robustness even in highly nonideal atmospheric conditions.
ER  - 

TY  - CONF
TI  - Incremental Learning-Based Adaptive Object Recognition for Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6263
EP  - 6268
AU  - M. O. Turkoglu
AU  - F. B. Ter Haar
AU  - N. van der Stap
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - incremental learning-based adaptive object recognition
KW  - autonomous navigation
KW  - general object interaction
KW  - human-robot teaming
KW  - robot assists
KW  - localization system
KW  - deep learning
KW  - robotic perception
KW  - mobile robotic tasks
KW  - Three-dimensional displays
KW  - Object recognition
KW  - Image segmentation
KW  - Mobile robots
KW  - Training
KW  - Semantics
DO  - 10.1109/IROS.2018.8593810
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D visual understanding of the surrounding environment is vital for successful mobile robotic tasks such as autonomous navigation or general object interaction. However, current systems have limited perceptual capabilities in the sense that they are not very well adaptable to unknown environments. Human operators, on the other hand, are experts in adapting to previously unknown information. Hence, human-robot teaming in which the human helps the robot to adapt to new environments and the robot assists in automated object recognition to efficiently feed the control environment of the operator is advantageous. In this work, we propose an object recognition and localization system for mobile robots, based on deep learning, and we study the adaptation of the resulting robotic perception to a new environment. We propose two methods to teach the robot a new object category: using prior knowledge and using limited operator input. We conducted several experiments to show the feasibility of proposed methods.
ER  - 

TY  - CONF
TI  - Object Detection and Pose Estimation Based on Convolutional Neural Networks Trained with Synthetic Data
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6269
EP  - 6276
AU  - J. Josifovski
AU  - M. Kerzel
AU  - C. Pregizer
AU  - L. Posniak
AU  - S. Wermter
PY  - 2018
KW  - convolutional neural nets
KW  - image resolution
KW  - image texture
KW  - object detection
KW  - object recognition
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - robot vision
KW  - solid modelling
KW  - instance-based object detection
KW  - fine pose estimation
KW  - robotic tasks
KW  - CNN-based approaches
KW  - general object recognition tasks
KW  - fully-annotated training images
KW  - neural models
KW  - interest-point-based approaches
KW  - category-based coarse pose estimation
KW  - fine-resolution instance-based 3D pose estimation
KW  - convolutional neural networks
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Pose estimation
KW  - Training
KW  - Data models
KW  - Training data
DO  - 10.1109/IROS.2018.8594379
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Instance-based object detection and fine pose estimation is an active research problem in computer vision. While the traditional interest-point-based approaches for pose estimation are precise, their applicability in robotic tasks relies on controlled environments and rigid objects with detailed textures. CNN-based approaches, on the other hand, have shown impressive results in uncontrolled environments for more general object recognition tasks like category-based coarse pose estimation, but the need of large datasets of fully-annotated training images makes them unfavourable for tasks like instance-based pose estimation. We present a novel approach that combines the robustness of CNNs with a fine-resolution instance-based 3D pose estimation, where the model is trained with fully-annotated synthetic training data, generated automatically from the 3D models of the objects. We propose an experimental setup in which we can carefully examine how the model trained with synthetic data performs on real images of the objects. Results show that the proposed model can be trained only with synthetic renderings of the objects' 3D models and still be successfully applied on images of the real objects, with precision suitable for robotic tasks like object grasping. Based on the results, we present more general insights about training neural models with synthetic images for application on real-world images.
ER  - 

TY  - CONF
TI  - Towards Event-Driven Object Detection with Off-the-Shelf Deep Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Iacono
AU  - S. Weber
AU  - A. Glover
AU  - C. Bartolozzi
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - data compression
KW  - data visualisation
KW  - humanoid robots
KW  - image colour analysis
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - data compression
KW  - visual algorithms
KW  - event-driven object detection
KW  - iCub robotic platform
KW  - mature frame-based algorithms
KW  - bootstraps event-based dataset annotation
KW  - temporal integration
KW  - visual events
KW  - off-the-shelf deep-learning
KW  - compressed event-camera data
KW  - recognition algorithms
KW  - visual technologies
KW  - dense arrays
KW  - moving objects
KW  - contrast changes
KW  - pixel data
KW  - dynamic range
KW  - computer vision
KW  - Cameras
KW  - Robot vision systems
KW  - Visualization
KW  - Training
KW  - Object detection
DO  - 10.1109/IROS.2018.8594119
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Event cameras are an emerging technology in computer vision, offering extremely low latency and bandwidth, as well as a high temporal resolution and dynamic range. Inherent data compression is achieved as pixel data is only produced by contrast changes at the edges of moving objects. However, current trends in state-of-the-art visual algorithms rely on deep-learning with networks designed to process colour and intensity information contained in dense arrays, but are notoriously computationally heavy. While the combination of these visual technologies could lead to fast, efficient, and accurate detection and recognition algorithms, it is uncertain whether the compressed event-camera data actually contain the required information for these techniques to discriminate between objects and a cluttered background. This paper presents a pilot study in which off-the-shelf deep-learning is applied to visual events for object detection on the iCub robotic platform, and analyses the impact of temporal integration of the event data. We also present a novel pipeline that bootstraps event-based dataset annotation from mature frame-based algorithms, in order to more quickly generate the required datasets.
ER  - 

TY  - CONF
TI  - Material Recognition Using a Capacitive Proximity Sensor with Flexible Spatial Resolution
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6284
EP  - 6290
AU  - H. Alagi
AU  - A. Heiligl
AU  - S. E. Navarro
AU  - T. Kroegerl
AU  - B. Hein
PY  - 2018
KW  - capacitive sensors
KW  - dielectric materials
KW  - mobile robots
KW  - neural nets
KW  - tactile sensors
KW  - conductive dielectric materials
KW  - artificial neural network
KW  - data frames
KW  - electrode combinations
KW  - flexible spatial resolution
KW  - capacitive proximity sensor
KW  - nonconductive dielectric materials
KW  - data sets
KW  - material recognition
KW  - exciter frequency
KW  - capacitive tactile
KW  - Electrodes
KW  - Robot sensing systems
KW  - Permittivity
KW  - Spatial resolution
KW  - Permittivity measurement
KW  - Shape
DO  - 10.1109/IROS.2018.8593789
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present an approach for material recognition using capacitive tactile and proximity sensors. By variating the spatial resolution and the exciter frequency during the measurement in mutual capacitive mode, information about the dielectrical properties of different objects was captured and provided as data frames. For material recognition an artificial neural network was set up and fed with various data sets of different electrode combinations and exciter frequencies. The influence of the electrode combinations and shapes on the recognition accuracy was investigated. It is shown that seven objects of conductive and non-conductive dielectric materials have been ranged with an overall accuracy of about 71%-94%.
ER  - 

TY  - CONF
TI  - Interactive Training of Object Detection Without ImageNet
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - E. Martinson
PY  - 2018
KW  - human computer interaction
KW  - interactive systems
KW  - object detection
KW  - robot vision
KW  - service robots
KW  - ImageNet
KW  - robotic tasks
KW  - service robots operating
KW  - robot perception
KW  - interactive training process
KW  - zero hand labeling
KW  - object detection
KW  - Robots
KW  - Training
KW  - Labeling
KW  - Object detection
KW  - Task analysis
KW  - Image segmentation
KW  - Cameras
DO  - 10.1109/IROS.2018.8593614
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For many robotic tasks, particularly those of service robots operating in human environments, the scope of object detection needs is greater than the available data. Either public datasets do not contain the entire set of objects needed for the task, and/or it is a commercial application that cannot use public datasets for training. Instead of hiring people to hand-label more data to support the integration of new objects into robot perception, we propose an interactive training process requiring zero hand labeling. With as little as 4 minutes of interaction with the robot per object, we demonstrate 99% precision and 57% recall in stationary object detection tasks.
ER  - 


TY  - CONF
TI  - Action Selection for Interactive Object Segmentation in Clutter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6297
EP  - 6304
AU  - T. Patten
AU  - M. Zillich
AU  - M. Vincze
PY  - 2018
KW  - image colour analysis
KW  - image motion analysis
KW  - image segmentation
KW  - RGB-D data
KW  - higher quality segmentation
KW  - probabilistic segmentation approach
KW  - segmentation uncertainty
KW  - probabilistic segmentation framework
KW  - scene motion
KW  - object existence
KW  - object models
KW  - nonprehensile actions
KW  - static object segmentation
KW  - scene representation
KW  - indoor human environments
KW  - complex surroundings
KW  - interactive object segmentation
KW  - Motion segmentation
KW  - Tracking
KW  - Probabilistic logic
KW  - Object segmentation
KW  - Octrees
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593918
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter.
ER  - 

TY  - CONF
TI  - Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Kohn
AU  - A. Blank
AU  - D. Puljiz
AU  - L. Zenkel
AU  - O. Bieber
AU  - B. Hein
AU  - J. Franke
PY  - 2018
KW  - control engineering computing
KW  - image reconstruction
KW  - image segmentation
KW  - industrial manipulators
KW  - man-machine systems
KW  - mobile robots
KW  - object recognition
KW  - real-time systems
KW  - robot vision
KW  - telerobotics
KW  - virtual reality
KW  - model segmentation
KW  - autonomous mobile robot systems
KW  - human-machine interfaces
KW  - virtual reality-technologies
KW  - mixed reality-technologies
KW  - multimodal teleoperation
KW  - real-time remote control
KW  - noise-reduced visualization
KW  - object recognition
KW  - operator-supporting teleoperation
KW  - real-time feedback
KW  - industrial articulated robotic arm
KW  - real-time environment reconstruction
KW  - VR-based teleoperation
KW  - known object segmentation
KW  - point-cloud visualization
KW  - long distance UDP/IP communication
KW  - Cameras
KW  - Calibration
KW  - Solid modeling
KW  - Robot vision systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594053
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.
ER  - 

TY  - CONF
TI  - DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6311
EP  - 6318
AU  - G. Dubey
AU  - R. Madaan
AU  - S. Scherer
PY  - 2018
KW  - collision avoidance
KW  - graph theory
KW  - image segmentation
KW  - image sensors
KW  - mobile robots
KW  - motion control
KW  - neural nets
KW  - robot vision
KW  - stereo image processing
KW  - multiple disparity images
KW  - C-space expansion
KW  - disparity space representation
KW  - generic obstacles
KW  - wire pixels
KW  - confidence map
KW  - semantic segmentation paradigm
KW  - convolutional neural network
KW  - monocular wire detection
KW  - generic obstacle avoidance
KW  - robust autonomous aerial vehicles
KW  - depth estimation
KW  - DROAN - disparity-space representation
KW  - Wires
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Cameras
KW  - Trajectory
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8593499
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.
ER  - 

TY  - CONF
TI  - Robocentric Visual-Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6319
EP  - 6326
AU  - Z. Huai
AU  - G. Huang
PY  - 2018
KW  - distance measurement
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - Monte Carlo methods
KW  - motion estimation
KW  - nonlinear filters
KW  - position measurement
KW  - SLAM (robots)
KW  - robocentric EKF-based VINS
KW  - standard world-centric frameworks
KW  - R-VIO
KW  - real-world experiments
KW  - state-of-the-art VINS
KW  - robocentric visual-inertial odometry
KW  - visual-inertial navigation systems
KW  - consistent localization
KW  - challenging environments
KW  - monocular vision
KW  - moving local frame
KW  - standard world-centric VINS
KW  - global gravity vector
KW  - multistate constraint Kalman filter framework
KW  - visual-inertial odometry algorithm
KW  - global pose
KW  - high-accuracy relative motion
KW  - robocentric formulation
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Computational efficiency
KW  - Navigation
KW  - Standards
KW  - Gravity
KW  - Quaternions
DO  - 10.1109/IROS.2018.8593643
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel robocentric formulation of visual-inertial navigation systems (VINS)within a multi-state constraint Kalman filter (MSCKF)framework and develop an efficient, lightweight, robocentric visual-inertial odometry (R-VIO)algorithm for consistent localization in challenging environments using only monocular vision. The key idea of the proposed approach is to deliberately reformulate the 3D VINS with respect to a moving local frame (i.e., robocentric), rather than a fixed global frame of reference as in the standard world-centric VINS, and instead utilize high-accuracy relative motion estimates for global pose update. As an immediate advantage of using this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align its orientation with the global gravity vector. More importantly, we analytically show that the proposed robocentric EKF-based VINS does not undergo the observability mismatch issue as in the standard world-centric frameworks which was identified as the main cause of inconsistency of estimation. The proposed R-VIO is extensively tested through both Monte Carlo simulations and real-world experiments using different sensor platforms in different environments and shown to achieve competitive performance with the state-of-the-art VINS algorithms in terms of consistency, accuracy and efficiency.
ER  - 

TY  - CONF
TI  - Appearance-Based Along-Route Localization for Planetary Missions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6327
EP  - 6334
AU  - I. Grixa
AU  - P. Schulz
AU  - W. Stürzl
AU  - R. Triebel
PY  - 2018
KW  - image matching
KW  - image registration
KW  - image sequences
KW  - mobile robots
KW  - object recognition
KW  - planetary rovers
KW  - robot vision
KW  - SLAM (robots)
KW  - image preprocessing steps
KW  - recognition framework SeqSLAM
KW  - appearance-based along-route localization algorithm
KW  - planetary missions
KW  - direct sequence-based approach
KW  - Moon-analogue mission
KW  - planetary rover
KW  - image similarity metrics wrt
KW  - translational viewpoint differences
KW  - rotational viewpoint differences
KW  - route traversal conditions
KW  - matching locations
KW  - flexible mechanism
KW  - frame matches
KW  - homing mechanism
KW  - autonomous navigation
KW  - real-time localization
KW  - individual frames
KW  - image sequences
KW  - robust place recognition
KW  - Navigation
KW  - Lighting
KW  - Cameras
KW  - Moon
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - mobile robotics
KW  - field robotics
KW  - place-recognition
KW  - autonomous route navigation
DO  - 10.1109/IROS.2018.8594518
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose an appearance-based along-route localization algorithm that relies on robust place recognition by matching image sequences instead of individual frames. Our approach extends state of the art place recognition framework SeqSLAM in several aspects to realize real-time localization along routes for autonomous navigation. First, our method is online in that we only rely on the recently observed image frames. Second, we provide a homing mechanism based on rotations computed from frame matches. And third, we use a more flexible mechanism to search for matching locations, not restricting the search to straight lines in the cost matrix as in SeqSLAM, but allowing for a wide variety of route traversal conditions such as varying velocities or rotational and translational viewpoint differences. We investigate different image preprocessing steps as well as image similarity metrics wrt. their influence on illumination and viewpoint invariance for a more robust place recognition. On a new challenging dataset, recorded in real world experiments with a planetary rover, in the course of a Moon-analogue mission on Sicily's Mount Etna, we show the feasibility of our direct, sequence-based approach to along-route localization.
ER  - 

TY  - CONF
TI  - A Monocular Indoor Localiser Based on an Extended Kalman Filter and Edge Images from a Convolutional Neural Network
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Unicomb
AU  - R. Ranasinghe
AU  - L. Dantanarayana
AU  - G. Dissanayake
PY  - 2018
KW  - cameras
KW  - convolutional neural nets
KW  - edge detection
KW  - image fusion
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - camera location estimation
KW  - extended Kalman filter
KW  - 6 DOF pose estimation
KW  - visual simultaneous localisation-and-mapping algorithms
KW  - prebuilt map
KW  - ground plane edge image extraction
KW  - motion model
KW  - unsigned distance function
KW  - indoor environment
KW  - monocular images
KW  - monocular indoor localiser
KW  - EKF framework
KW  - CNN
KW  - convolutional neural network
KW  - Image edge detection
KW  - Cameras
KW  - Robot vision systems
KW  - Feature extraction
KW  - Convolution
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594337
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The main contribution of this paper is an extended Kalman filter (EKF)based algorithm for estimating the 6 DOF pose of a camera using monocular images of an indoor environment. In contrast to popular visual simultaneous localisation and mapping algorithms, the technique proposed relies on a pre-built map represented as an unsigned distance function of the ground plane edges. Images from the camera are processed using a Convolutional Neural Network (CNN)to extract a ground plane edge image. Pixels that belong to these edges are used in the observation equation of the EKF to estimate the camera location. Use of the CNN makes it possible to extract ground plane edges under significant changes to scene illumination. The EKF framework lends itself to use of a suitable motion model, fusing information from any other sensors such as wheel encoders or inertial measurement units, if available, and rejecting spurious observations. A series of experiments are presented to demonstrate the effectiveness of the proposed technique.
ER  - 

TY  - CONF
TI  - Automated Map Reading: Image Based Localisation in 2-D Maps Using Binary Semantic Descriptors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6341
EP  - 6348
AU  - P. Panphattarasap
AU  - A. Calway
PY  - 2018
KW  - cartography
KW  - image classification
KW  - image matching
KW  - image representation
KW  - visual databases
KW  - compact binary descriptors
KW  - localisation accuracy
KW  - 2-D map
KW  - location tagged descriptors
KW  - descriptor estimates
KW  - human-system interaction
KW  - human map reading
KW  - variable imaging conditions
KW  - semantic features
KW  - image database matching
KW  - 2-D cartographic map
KW  - semantic matching
KW  - binary semantic descriptors
KW  - image based localisation
KW  - automated map reading
KW  - Semantics
KW  - Buildings
KW  - Junctions
KW  - Roads
KW  - Databases
KW  - Feature extraction
KW  - Meters
DO  - 10.1109/IROS.2018.8594253
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We describe a novel approach to image based localisation in urban environments which uses semantic matching between images and a 2-D cartographic map. This contrasts with the majority of existing approaches which use image to image database matching. We use highly compact binary descriptors to represent locations, indicating the presence or not of semantic features, which significantly increases scalability and has the potential for greater invariance to variable imaging conditions. The approach is also more akin to human map reading, making it better suited to human-system interaction. In this initial study we use semantic features relating to buildings and road junctions in discrete viewing directions. CNN classifiers are used to detect the features in images and we match descriptor estimates with location tagged descriptors derived from the 2-D map to give localisation. The descriptors are not sufficiently discriminative on their own, but when concatenated sequentially along a route, their combination becomes highly distinctive and allows localisation even when using non-perfect classifiers. Performance is further improved by taking into account left or right turns over a route. Experimental results obtained using Google StreetView and OpenStreetMap data show that the approach has considerable potential, achieving localisation accuracy of around 85% using routes corresponding to approximately 200 meters.
ER  - 

TY  - CONF
TI  - Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6349
EP  - 6356
AU  - I. Kenmogne
AU  - V. Drevelle
AU  - E. Marchand
PY  - 2018
KW  - autonomous aerial vehicles
KW  - constraint handling
KW  - control engineering computing
KW  - distance measurement
KW  - iterative methods
KW  - least squares approximations
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - tree searching
KW  - pose uncertainty domains
KW  - interval constraint propagation techniques
KW  - simulated two-robots configurations
KW  - unmanned aerial vehicles
KW  - bounded error measurements
KW  - distances measurements
KW  - ground station
KW  - camera images
KW  - UAV
KW  - cooperative localization
KW  - branch and bound algorithm
KW  - nonlinear iterative weighted least squares
KW  - Cameras
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Position measurement
KW  - Base stations
DO  - 10.1109/IROS.2018.8593742
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.
ER  - 

TY  - CONF
TI  - Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6357
EP  - 6363
AU  - M. P. Das
AU  - Z. Dong
AU  - S. Scherer
PY  - 2018
KW  - augmented reality
KW  - calibration
KW  - cameras
KW  - human-robot interaction
KW  - image registration
KW  - image sensors
KW  - inspection
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - mixed-reality headsets
KW  - headset orientation
KW  - structure inspection
KW  - marker-free self-localization
KW  - onboard depth sensor
KW  - simple point cloud registration
KW  - camera image
KW  - inspection information
KW  - joint point cloud and image-based localization
KW  - JPIL
KW  - human-robot interaction
KW  - time 20.0 min
KW  - Three-dimensional displays
KW  - Headphones
KW  - Inspection
KW  - Cameras
KW  - Virtual reality
KW  - Solid modeling
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594318
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a method of structure inspection using mixed-reality headsets to reduce the human effort in reporting accurate inspection information such as fault locations in 3D coordinates. Prior to every inspection, the headset needs to be localized. While external pose estimation and fiducial marker based localization would require setup, maintenance, and manual calibration; marker-free self-localization can be achieved using the onboard depth sensor and camera. However, due to limited depth sensor range of portable mixed-reality headsets like Microsoft HoloLens, localization based on simple point cloud registration (sPCR) would require extensive mapping of the environment. Also, localization based on camera image would face same issues as stereo ambiguities and hence depends on viewpoint. We thus introduce a novel approach to Joint Point Cloud and Image-based Localization (JPIL) for mixed-reality headsets that uses visual cues and headset orientation to register small, partially overlapped point clouds and save significant manual labor and time in environment mapping. Our empirical results compared to sPCR show average 10 fold reduction of required overlap surface area that could potentially save on average 20 minutes per inspection. JPIL is not only restricted to inspection tasks but also can be essential in enabling intuitive human-robot interaction for spatial mapping and scene understanding in conjunction with other agents like autonomous robotic systems that are increasingly being deployed in outdoor environments for applications like structural inspection.
ER  - 

TY  - CONF
TI  - Probabilistic Dense Reconstruction from a Moving Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6364
EP  - 6371
AU  - Y. Ling
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - image sequences
KW  - probability
KW  - SLAM (robots)
KW  - stereo image processing
KW  - TUM RGB-D SLAM
KW  - ICL-NUIM dataset
KW  - spatial correlations
KW  - visual scale changes
KW  - insufficient parallaxes
KW  - motion stereo
KW  - spatial stereo
KW  - single monocular camera
KW  - online dense reconstruction
KW  - probabilistic approach
KW  - moving camera
KW  - probabilistic dense reconstruction
KW  - outdoor experiments
KW  - dense 3D models
KW  - inlier probability expectations
KW  - depth estimates
KW  - probabilistic scheme
KW  - monocular depth estimation
KW  - temporal correlations
KW  - Image reconstruction
KW  - Cameras
KW  - Estimation
KW  - Visualization
KW  - Robot vision systems
KW  - Probabilistic logic
KW  - Simultaneous localization and mapping
DO  - 10.1109/IROS.2018.8593618
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a probabilistic approach for online dense reconstruction using a single monocular camera moving through the environment. Compared to spatial stereo, depth estimation from motion stereo is challenging due to insufficient parallaxes, visual scale changes, pose errors, etc. We utilize both the spatial and temporal correlations of consecutive depth estimates to increase the robustness and accuracy of monocular depth estimation. An online, recursive, probabilistic scheme to compute depth estimates, with corresponding covariances and inlier probability expectations, is proposed in this work. We integrate the obtained depth hypotheses into dense 3D models in an uncertainty-aware way. We show the effectiveness and efficiency of our proposed approach by comparing it with state-of-the-art methods in the TUM RGB-D SLAM & ICL-NUIM dataset. Online indoor and outdoor experiments are also presented for performance demonstration.
ER  - 

TY  - CONF
TI  - Summarizing Large Scale 3D Mesh
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - I. B. Salah
AU  - S. Kramm
AU  - C. Demonceaux
AU  - P. Vasseur
PY  - 2018
KW  - mesh generation
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - vision-based summarizing process
KW  - HD 3D maps
KW  - large-scale 3D map
KW  - semantic information
KW  - geometric information
KW  - photometric information
KW  - autonomous navigation
KW  - semantic mapping
KW  - 3D sensor devices
KW  - Three-dimensional displays
KW  - Navigation
KW  - Entropy
KW  - Semantics
KW  - Visualization
KW  - Optimization
KW  - Robots
DO  - 10.1109/IROS.2018.8593372
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent progress in 3D sensor devices and in semantic mapping allows to build very rich HD 3D maps very useful for autonomous navigation and localization. However, these maps are particularly huge and require important memory capabilities as well computational resources. In this paper, we propose a new method for summarizing a 3D map (Mesh)as a set of compact spheres in order to facilitate its use by systems with limited resources (smartphones, robots, UAVs,...). This vision-based summarizing process is applied in a fully automatic way using jointly photometric, geometric and semantic information of the studied environment. The main contribution of this research is to provide a very compact map that maximizes the significance of its content while maintaining the full visibility of the environment. Experimental results in summarizing large-scale 3D map demonstrate the feasibility of our approach and evaluate the performance of the algorithm.
ER  - 

TY  - CONF
TI  - A Robust Control Method for the Elbow of the Humanoid Robot TEO Based on a Fractional Order Controller
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6378
EP  - 6383
AU  - J. Muñoz
AU  - C. A. Monje
AU  - F. Martín
AU  - C. Balaguer
PY  - 2018
KW  - humanoid robots
KW  - manipulators
KW  - PD control
KW  - robust control
KW  - robust control method
KW  - humanoid robot TEO
KW  - fractional order controller
KW  - elbow joint
KW  - fractional order PD controller
KW  - robust performance
KW  - humanoid right arm
KW  - Gain
KW  - Humanoid robots
KW  - Tuning
KW  - Robustness
KW  - Elbow
DO  - 10.1109/IROS.2018.8593732
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for the control of the elbow joint of the humanoid robot TEO, based on a fractional order PD controller. Due to the graphical nature of the proposed method, a few basic operations are enough to tune the controller, offering very competitive results compared to classic methods. The experiments show a robust performance of the system to mass changes at the tip of the humanoid right arm.
ER  - 

TY  - CONF
TI  - FPGA-Based Velocity Estimation for Control of Robots with Low-Resolution Encoders
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6384
EP  - 6389
AU  - J. Y. Wu
AU  - Z. Chen
AU  - A. Deguet
AU  - P. Kazanzides
PY  - 2018
KW  - closed loop systems
KW  - field programmable gate arrays
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - Cartesian impedance control
KW  - FPGA-based velocity estimation
KW  - low-resolution encoders
KW  - robot control algorithms
KW  - robot joint velocities
KW  - encoder edges
KW  - low velocities
KW  - low resolution encoders
KW  - measurement delay
KW  - closed-loop control
KW  - joint position control
KW  - frequent velocity updates
KW  - common encoder imperfections
KW  - Velocity measurement
KW  - Estimation
KW  - Delays
KW  - Silicon
KW  - Acceleration
KW  - Robots
DO  - 10.1109/IROS.2018.8594139
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot control algorithms often rely on measurements of robot joint velocities, which can be estimated by measuring the time between encoder edges. When encoder edges occur infrequently, such as at low velocities and/or with low resolution encoders, this measurement delay may affect the stability of closed-loop control. This is evident in both the joint position control and Cartesian impedance control of the da Vinci Research Kit (dVRK), which contains several low-resolution encoders. We present a hardware-based method that gives more frequent velocity updates and is not affected by common encoder imperfections such as non-uniform duty cycles and quadrature phase error. The proposed method measures the time between consecutive edges of the same type but, unlike prior methods, is implemented for the rising and falling edges of both channels. Additionally, it estimates acceleration to enable software compensation of the measurement delay. The method is shown to improve Cartesian impedance control of the dVRK.
ER  - 

TY  - CONF
TI  - Active Disturbance Rejection Control of a Flying-Wing Tailsitter in Hover Flight
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6390
EP  - 6396
AU  - Y. Yang
AU  - J. Zhu
AU  - X. Zhang
AU  - X. Wang
PY  - 2018
KW  - active disturbance rejection control
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - helicopters
KW  - motion control
KW  - observers
KW  - position control
KW  - active disturbance rejection control
KW  - flying-wing tailsitter
KW  - hover flight
KW  - tailsitter unmanned aerial vehicle
KW  - vehicle aerodynamics
KW  - accurate vertical flying
KW  - attitude controller
KW  - tracking differentiator
KW  - vertical takeoff and landing
KW  - tailsitter design
KW  - position controller
KW  - VTOL
KW  - six-degrees-of-freedom model
KW  - 6-DOF model
KW  - outdoor stationary hovering
KW  - ADRC
KW  - extended state observer
KW  - ESO
KW  - TD
KW  - Propellers
KW  - Aerodynamics
KW  - Attitude control
KW  - Aircraft
KW  - Earth
KW  - Unmanned aerial vehicles
KW  - Gravity
DO  - 10.1109/IROS.2018.8594470
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the development and hovering control of a tailsitter unmanned aerial vehicle (UAV) that merges long endurance and vertical takeoff and landing (VTOL) abilities. The designed tailsitter contains one flying-wing with two motors and two elevons. Vehicle aerodynamics and a six-degrees-of-freedom (6-DOF) model are especially developed for the tailsitter. To achieve a good performance in outdoor stationary hovering and accurate vertical flying, the active disturbance rejection control (ADRC) for attitude controller is proposed. With signals from extended state observer (ESO) and tracking differentiator (TD), ADRC decouples the system model into a controllable chain of integrators. Based on the decoupled system dynamics, the motion of tailsitter can be easily handled by developed position controller. Experimental results are presented to corroborate the effectiveness of the controller in disturbance rejection.
ER  - 

TY  - CONF
TI  - Underwater Modeling, Experiments and Control Strategies of FroBot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6397
EP  - 6403
AU  - Y. Yi
AU  - F. Zhenhui
AU  - Z. Zhongjing
AU  - Z. Jianqing
PY  - 2018
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - propulsion
KW  - robot dynamics
KW  - underwater vehicles
KW  - two-degree-of-freedom robotic swing-legs
KW  - 2DOF
KW  - Frobot model
KW  - Frobot underwater
KW  - caudal fins
KW  - Morison equation
KW  - control applications
KW  - CPGs control strategy
KW  - optimal control strategy
KW  - dynamic model
KW  - dual swing-legs propulsion mechanism
KW  - Legged locomotion
KW  - Mathematical model
KW  - Dynamics
KW  - Propulsion
KW  - Force
KW  - Acceleration
DO  - 10.1109/IROS.2018.8594455
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.
ER  - 

TY  - CONF
TI  - Feedback Linearizing Controller for a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6404
EP  - 6410
AU  - J. C. Cambera
AU  - V. Feliu-Batlle
PY  - 2018
KW  - closed loop systems
KW  - compensation
KW  - flexible manipulators
KW  - friction
KW  - linearisation techniques
KW  - position control
KW  - springs (mechanical)
KW  - state feedback
KW  - vibration control
KW  - single link flexible arm
KW  - passive gravity compensation mechanism
KW  - flexible link robotics
KW  - input state feedback linearization controller
KW  - gravity compensation system
KW  - springs
KW  - double loop control scheme
KW  - motor position control
KW  - flexible link arm tip positioning
KW  - joint friction
KW  - vibration cancellation
KW  - Gravity
KW  - Springs
KW  - Torque
KW  - DC motors
KW  - Actuators
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594409
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite the benefits that the spring based gravity compensation mechanism has brought to the field of rigid robotic manipulators, there have been no substantial efforts toward transferring these developments to the field of flexible link robotics. In this paper, we present an input state feedback linearization controller for the tip positioning of a flexible link arm with a gravity compensation system based on springs. The controller is implemented into a double loop control scheme, in which the inner loop addresses the motor position control in presence of joint friction, and the outer loop deals with vibration cancellation and the tracking of fourth-order trajectories for the tip position of the flexible arm. Taking into considerations the interacting forces between the flexible link and the gravity compensation mechanism, and also the characteristics of the control law, we propose a sensory system to measure all the relevant signals. The proposed controller is tested on an experimental prototype built in our laboratory.
ER  - 

TY  - CONF
TI  - A Practical Method to Speed-Up the Experimental Procedure of Iterative Learning Controllers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6411
EP  - 6416
AU  - O. Koçan
AU  - A. Manecy
AU  - C. Poussot-Vassal
PY  - 2018
KW  - adaptive control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - iterative learning control
KW  - vehicle dynamics
KW  - traditional practice
KW  - ILC experiments
KW  - ILC signal
KW  - experimental data
KW  - accurate linear model
KW  - total experimental time
KW  - predicted system data
KW  - practical method
KW  - experimental procedure
KW  - iterative learning controllers
KW  - practical approach
KW  - lengthy experimentational processes
KW  - iterative learning control
KW  - low-order identified models
KW  - Trajectory
KW  - Data models
KW  - Optimization
KW  - Attitude control
KW  - Process control
KW  - Predictive models
KW  - Tracking
DO  - 10.1109/IROS.2018.8594025
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a practical approach for fastening the lengthy experimentational processes that may occur with iterative learning control (ILC) upto a certain level using simple low-order identified models. The traditional practice in ILC experiments is to update the ILC signal by directly using the experimental data after each run of the process which corresponds to one ILC update per one run. When considered from the point of experimental time, even conducting a moderate number of ILC updates can take quite long with this procedure. Since an accurate linear model can adequately represent the actual system upto a certain amplitude and/or frequency of the desired reference, we propose that the total experimental time can be reduced by updating the ILC signal via predicted system data until the limits of the linear model. This approach allows one to carry out large number of ILC updates while not needing to carry out the same amount of real experiments. Consequently, a significant number of experiments that would be needed for achieving the same results can be skipped with a simulation approach. The efficiency of the proposed method was tested through experimentation with three different UAV reference trajectories and the results demonstrated that it is possible to attain significant amount of tracking precision in several flight experiments.
ER  - 

TY  - CONF
TI  - System Identification and Closed-Loop Control of a Hydraulically Amplified Self-Healing Electrostatic (HASEL) Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6417
EP  - 6423
AU  - C. Schunk
AU  - L. Pearson
AU  - E. Acome
AU  - T. G. Morrissey
AU  - N. Correll
AU  - C. Keplinger
AU  - M. E. Rentschler
AU  - J. S. Humbert
PY  - 2018
KW  - closed loop systems
KW  - hydraulic actuators
KW  - PI control
KW  - robots
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - HASEL actuator
KW  - Proportional-Integral controller
KW  - closed-loop control
KW  - Hydraulically Amplified Self-healing Electrostatic actuator
KW  - system identification method
KW  - closed-loop controller
KW  - soft robotic actuators
KW  - high-speed videography based motion tracking
KW  - mass-spring-damper model
KW  - Actuators
KW  - Strain
KW  - Sensors
KW  - Data acquisition
KW  - Capacitance
KW  - Electrodes
KW  - Dielectric liquids
DO  - 10.1109/IROS.2018.8593797
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a system identification method and the development of a closed-loop controller for a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator. Our efforts focus on developing a reliable and consistent way to identify system models for these soft robotic actuators using high-speed videography based motion tracking. Utilizing a mass-spring-damper model we are able to accurately capture the behavior of a HASEL actuator. We use the resulting plant model to design a Proportional-Integral controller that demonstrates improved closed-loop tracking and steady-state error performance.
ER  - 

TY  - CONF
TI  - Motion Control of Piezo-Driven Stage via a Chattering-Free Sliding Mode Controller with Hysteresis Compensation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6424
EP  - 6430
AU  - Y. Fan
AU  - Y. He
AU  - D. Zhang
AU  - U. Tan
PY  - 2018
KW  - compensation
KW  - control nonlinearities
KW  - hysteresis
KW  - Lyapunov methods
KW  - motion control
KW  - nonlinear control systems
KW  - piezoelectric actuators
KW  - stability
KW  - trajectory control
KW  - uncertain systems
KW  - variable structure systems
KW  - hysteresis compensation
KW  - trajectory tracking
KW  - piezo-driven stage
KW  - hysteresis nonlinearity
KW  - hysteresis model
KW  - motion control
KW  - chattering-free sliding mode controller
KW  - disturbance estimator
KW  - Lyapunov analysis
KW  - Hysteresis
KW  - Uncertainty
KW  - Sliding mode control
KW  - Stability analysis
KW  - Feedforward systems
KW  - Integrated circuit modeling
DO  - 10.1109/IROS.2018.8593442
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel sliding mode controller for trajectory tracking of the piezo-driven stage. The tracking performance of piezoelectric actuator is mainly affected by the hysteresis nonlinearity. Sliding mode control is a possible solution to achieve better tracking performance. However, conventional sliding mode control generates discontinuous control signal which results in chattering. Hence, the hysteresis nonlinearity is first compensated with a hysteresis model, and an uncertainty and disturbance estimator is designed and included to devise a smooth control action. The stability of the proposed method is demonstrated via Lyapunov analysis. Both simulation and experiment are also conducted to verify the effectiveness of the proposed approach. The results are compared with a conventional sliding mode controller and a proportional-integral control with notch filter (PIC-NF).
ER  - 

TY  - CONF
TI  - A Universal Gripper Using Optical Sensing to Acquire Tactile Information and Membrane Deformation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Sakuma
AU  - F. Von Drigalski
AU  - M. Ding
AU  - J. Takamatsu
AU  - T. Ogasawara
PY  - 2018
KW  - deformation
KW  - grippers
KW  - jamming
KW  - membranes
KW  - refractive index
KW  - tactile sensors
KW  - granular-jamming-based gripper
KW  - semitransparent membrane
KW  - irregularly shaped objects
KW  - membrane deformation
KW  - acquire tactile information
KW  - optical sensing
KW  - rectangular objects
KW  - cylindrical objects
KW  - universal gripper
KW  - fully transparent filling
KW  - granular bodies
KW  - refractive index
KW  - Grippers
KW  - Cameras
KW  - Strain
KW  - Grasping
KW  - Prototypes
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8593697
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The universal gripper has attracted attention due to its simple structure and advanced grasping ability for irregularly shaped objects. In this research, we propose a novel design for a granular-jamming-based gripper which uses a transparent filling and a semi-transparent membrane to allow optical sensing to detect both deformation of the membrane and the object being grasped. By adjusting the refractive index of an oil mixture to the refractive index of the granular bodies, we produced a fully transparent filling that allows the use of a camera inside the universal gripper. In this paper, we present the materials and development of our prototype, and describe the experimental confirmation of the prototype's performance. We showed that our prototype was able to grasp cylindrical and rectangular objects between 10 to 70 mm length while also tracking the deformation of the gripper.
ER  - 

TY  - CONF
TI  - Towards a Soft Fingertip with Integrated Sensing and Actuation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6437
EP  - 6444
AU  - B. W. McInroe
AU  - C. L. Chen
AU  - K. Y. Goldberg
AU  - K. Y. Goldberg
AU  - R. Bajcsy
AU  - R. S. Fearing
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - haptic interfaces
KW  - manipulator dynamics
KW  - pneumatic actuators
KW  - tactile sensors
KW  - tactile data
KW  - SOFTcell
KW  - pneumatic actuation
KW  - optical sensing
KW  - novel controllable stiffness tactile device
KW  - soft robotics
KW  - high-dimensional nonlinear soft systems
KW  - complex coupling
KW  - shape changes
KW  - tactile sensing
KW  - environmental geometry
KW  - low intrinsic stiffness
KW  - unstructured environments
KW  - safe interaction
KW  - soft material robots
KW  - integrated sensing
KW  - soft fingertip
KW  - Cameras
KW  - Tactile sensors
KW  - Optical sensors
KW  - Strain
DO  - 10.1109/IROS.2018.8594032
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft material robots are attractive for safe interaction with humans and unstructured environments due to their compliance and low intrinsic stiffness and mass. These properties enable new capabilities such as the ability to conform to environmental geometry for tactile sensing and to undergo large shape changes for actuation. Due to the complex coupling between sensing and actuation in high-dimensional nonlinear soft systems, prior work in soft robotics has primarily focused on either sensing or actuation. This paper presents SOFTcell, a novel controllable stiffness tactile device that incorporates both optical sensing and pneumatic actuation. We report details on the device's design and implementation and analyze results from characterization experiments on sensitivity and performance, which show that SOFTcell can controllably increase its effective modulus from 4.4kPa to 46.1kPa. Additionally, we demonstrate the utility of SOFTcell for grasping in a reactive control task in which tactile data is used to detect fingertip shear as a grasped object slips, and cell pressurization is used to prevent the slip without the need to adjust fingertip position.
ER  - 

TY  - CONF
TI  - Learning Oscillator-Based Gait Controller for String-Form Soft Robots Using Parameter-Exploring Policy Gradients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6445
EP  - 6452
AU  - M. Ishige
AU  - T. Umedachi
AU  - T. Taniguchi
AU  - Y. Kawahara
PY  - 2018
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - mobile robots
KW  - actor-critic
KW  - oscillators
KW  - harness global entrainment
KW  - appropriate mechanosensor feedback
KW  - reinforcement learning technique
KW  - parameter-exploring policy gradients
KW  - string-form soft robots
KW  - oscillator-based gait controller
KW  - soft-bodied robots
KW  - appropriate learning method
KW  - episode based parameter updates
KW  - exploration noise
KW  - physical model
KW  - PEPG
KW  - simulation models
KW  - Robot sensing systems
KW  - Oscillators
KW  - Reinforcement learning
KW  - Force
KW  - Actuators
KW  - Springs
DO  - 10.1109/IROS.2018.8594338
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a methodology to design mechanosensor feedback to oscillator-based controller for worm-like soft-bodied robots. A reinforcement learning technique, i.e., PEPG, is employed to embed appropriate mechanosensor feedback to harness global entrainment among the controller, the body dynamics, and the environment without explicitly designing the interaction between the oscillators. Another reinforcement learning, actor-critic, was applied to train the controller for the simulation models to analyze the effectiveness of PEPG in the system. Furthermore, the gait controller was trained under different body dynamics, i.e., the physical model of a caterpillar and an earthworm. We found that PEPG is suitable for the system probably because it does not add exploration noise to actions and it conducts episode based parameter updates. The simulation results show the proposed method can acquire distinct behavior, i.e., caterpillars' crawling, inching and earthworms' crawling, under different body dynamics. The outcome implies, that by utilizing appropriate learning method, desired functionality can be achieved in soft-bodied robots without explicitly designing their behavior.
ER  - 

TY  - CONF
TI  - A Partially Filled Jamming Gripper for Underwater Recovery of Objects Resting on Soft Surfaces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6461
EP  - 6468
AU  - S. Licht
AU  - E. Collins
AU  - G. Badlissi
AU  - D. Rizzo
PY  - 2018
KW  - compliance control
KW  - end effectors
KW  - grippers
KW  - seawater
KW  - sediments
KW  - underwater vehicles
KW  - partially filled jamming gripper
KW  - soft surfaces
KW  - partially filled membrane
KW  - submerged objects
KW  - soft substrates
KW  - jamming grippers
KW  - particle jamming
KW  - end effector membrane
KW  - internal membrane pressure
KW  - deep sea shipwrecks
KW  - downward force
KW  - maximum lifting force
KW  - gripper membrane
KW  - soft sediment
KW  - irregular objects
KW  - grasping
KW  - fresh water tank experiment
KW  - seawater
KW  - compliant foam
KW  - fine loose sediment
KW  - waterlogged timbers
KW  - compliance control
KW  - underwater object recovery
KW  - Grippers
KW  - Jamming
KW  - Force
KW  - Manifolds
KW  - Solids
KW  - Substrates
KW  - Sediments
KW  - soft robotics
KW  - universal jamming grippers
KW  - marine archeology
DO  - 10.1109/IROS.2018.8593361
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we demonstrate a universal jamming gripper with a partially filled membrane that can pick up submerged objects resting on soft substrates. Jamming grippers take advantage of the phenomenon of particle jamming to control the compliance of an end effector membrane. Changes in internal membrane pressure are used to transition the membrane between hard and soft states. The effort was motivated by the need for tools to sample artifacts on deep sea shipwrecks, which are often found resting on waterlogged timbers, or partially buried in fine, loose sediment. Limiting downward force protects the target, and reduces the likelihood that it will be pushed down in to the substrate, which could lead to a failed grasp. In benchtop tests, the downward force, and the ratio of maximum lifting force to downward force, are shown to be strongly dependent on the initial volume of particles and fluid in the gripper membrane. The gripper achieves lifting forces 6.7 times the downward force on targets with high aspect ratios. Experiments in a fresh water tank demonstrate the ability to grasp objects resting on soft sediment, and compliant foam. Finally, experiments at sea demonstrate that the end effector functions at depths of more than 1000m seawater, successfully grasping a range of irregular objects.
ER  - 

TY  - CONF
TI  - CLASH: Compliant Low Cost Antagonistic Servo Hands
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6469
EP  - 6476
AU  - W. Friedl
AU  - H. Höppner
AU  - F. Schmidt
AU  - M. A. Roa
AU  - M. Grebenstein
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - grippers
KW  - actuators
KW  - grippers
KW  - hand-in-hand grasping
KW  - variable stiffness actuation
KW  - underactuated fingers
KW  - differential coupling mechanism
KW  - DLR Awiwi hand
KW  - lightweight hands
KW  - antagonistic modular hands
KW  - rapid prototyping
KW  - CLASH hands
KW  - compliant low cost antagonistic servo hands
KW  - Tendons
KW  - Thumb
KW  - Force
KW  - Servomotors
KW  - Grasping
KW  - Couplings
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593903
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the first two members of the new generation of CLASH hands, which exploit low cost actuation and rapid prototyping to create antagonistic modular and lightweight hands and grippers. The hands approach the robustness of the DLR Awiwi hand with a much lower complexity and cost. To reduce the number of required actuators, a differential coupling mechanism for underactuated fingers was developed, along with a new mechanism that uses variable stiffness actuation in order to increase the workspace of underactuated fingers. The hands provide a research platform for both hand-in-hand and robotic grasping. Design aspects are discussed, and an initial experimental validation verifies the hands' performance.
ER  - 

TY  - CONF
TI  - FBG-Based Control of a Continuum Manipulator Interacting with Obstacles*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6477
EP  - 6483
AU  - S. Sefati
AU  - R. J. Murphy
AU  - F. Alambeigi
AU  - M. Pozin
AU  - I. Iordachita
AU  - R. H. Taylor
AU  - M. Armand
PY  - 2018
KW  - bone
KW  - Bragg gratings
KW  - dexterous manipulators
KW  - feedback
KW  - fibre optic sensors
KW  - medical robotics
KW  - patient treatment
KW  - FBG feedback
KW  - FBG-based control
KW  - continuum dexterous manipulators
KW  - constraint environments
KW  - shape sensing methods
KW  - optimization-based control algorithm
KW  - FBG tip position feedback
KW  - feedback control algorithm
KW  - CDM interaction
KW  - CDM collisions
KW  - soft obstacles
KW  - hard obstacles
KW  - CDM tip
KW  - fiber Bragg grating shape sensing unit
KW  - CDM shape
KW  - bone degradation
KW  - osteolysis less-invasive treatment
KW  - hard lesions
KW  - soft lesions
KW  - jacobian information
KW  - Shape
KW  - Manipulators
KW  - Jacobian matrices
KW  - Robot sensing systems
KW  - Strain
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594407
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tracking and controlling the shape of continuum dexterous manipulators (CDM) in constraint environments is a challenging task. The imposed constraints and interaction with unknown obstacles may conform the CDM's shape and therefore demands for shape sensing methods which do not rely on direct line of sight. To address these issues, we integrate a novel Fiber Bragg Grating (FBG) shape sensing unit into a CDM, reconstruct the shape in real-time, and develop an optimization-based control algorithm using FBG tip position feedback. The CDM is designed for less-invasive treatment of osteolysis (bone degradation). To evaluate the performance of the feedback control algorithm when the CDM interacts with obstacles, we perform a set of experiments similar to the real scenario of the CDM interaction with soft and hard lesions during the treatment of osteolysis. In addition, we propose methods for identification of the CDM collisions with soft or hard obstacles using the jacobian information. Results demonstrate successful control of the CDM tip based on the FBG feedback and indicate repeatability and robustness of the proposed method when interacting with unknown obstacles.
ER  - 

TY  - CONF
TI  - Modeling and Trajectory Tracking Control of a New Parallel Flexible Link Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6484
EP  - 6489
AU  - M. Morlock
AU  - N. Meyer
AU  - M. Pick
AU  - R. Seifried
PY  - 2018
KW  - control system synthesis
KW  - elastic deformation
KW  - end effectors
KW  - finite element analysis
KW  - flexible manipulators
KW  - geometry
KW  - manipulator dynamics
KW  - tracking
KW  - trajectory control
KW  - arbitrary geometries
KW  - modal truncation
KW  - Component Mode Synthesis
KW  - underactuated robot
KW  - flexible model
KW  - trajectory tracking control
KW  - kinematic loop
KW  - elastic deformations
KW  - linear finite element models
KW  - parallel flexible link robot
KW  - compliant lightweight robot
KW  - end-effector
KW  - Robots
KW  - Strain
KW  - Finite element analysis
KW  - Trajectory tracking
KW  - Kinematics
KW  - Mathematical model
KW  - Shape
DO  - 10.1109/IROS.2018.8594008
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A completely new compliant lightweight robot is presented with a kinematic loop and a highly flexible link. It is explained how to model such parallel robots accurately but still computationally efficient. The elastic deformations are described with the floating frame of reference approach. For the flexible components this allows to use linear finite element models, which can represent arbitrary geometries. These models are further reduced by modal truncation and a Component Mode Synthesis minimizing the number of elastic degrees of freedom, which is necessary for real-time control purposes. The obtained model of the underactuated robot is non-minimum phase for the end-effector as output. Thus, for the applied trajectory tracking controller which is based on servo constraints, the concept of stable inversion is used. The performance is compared to a relocated minimum phase output. Corresponding simulations are validated by first experimental results showing the need for and high accuracy of the flexible model and the trajectory tracking control.
ER  - 

TY  - CONF
TI  - Deep Sequential Models for Sampling-Based Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6490
EP  - 6497
AU  - Y. Kuo
AU  - A. Barbu
AU  - B. Katz
PY  - 2018
KW  - collision avoidance
KW  - computational geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - sampling methods
KW  - deep sequential models
KW  - sequence model
KW  - sampling-based planner
KW  - efficient plans
KW  - planner state
KW  - neural-network-based models
KW  - fewer rejected samples
KW  - multiagent environments
KW  - graphical models
KW  - Hidden Markov models
KW  - Computational modeling
KW  - Planning
KW  - Adaptation models
KW  - Space exploration
KW  - Uncertainty
KW  - Sensors
DO  - 10.1109/IROS.2018.8593947
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.
ER  - 

TY  - CONF
TI  - A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6498
EP  - 6505
AU  - J. Denny
AU  - K. Chen
AU  - H. Zhou
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - topology
KW  - homotopic similarity
KW  - homotopy equivalence
KW  - naive application
KW  - local planning
KW  - sampling-based motion planning
KW  - topologically distinct portions
KW  - topologically distinct paths
KW  - robotic motion planning
KW  - homotopy classes
KW  - topology-based path similarity metric
KW  - path deformation roadmaps
KW  - multiple homotopically distinct paths
KW  - Measurement
KW  - Planning
KW  - Strain
KW  - Algorithms
KW  - Merging
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594325
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.
ER  - 

TY  - CONF
TI  - RG-Trees: Trajectory-Free Feedback Motion Planning Using Sparse Random Reference Governor Trees
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6506
EP  - 6511
AU  - F. Golbol
AU  - M. M. Ankarali
AU  - A. Saranli
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - mobile robots
KW  - motion control
KW  - robust control
KW  - sampling methods
KW  - trajectory control
KW  - trees (mathematics)
KW  - trajectory-free feedback motion planning
KW  - high dimensional configuration spaces
KW  - complex environments
KW  - open-loop trajectories
KW  - feedback control policies
KW  - dynamic robot
KW  - planned path
KW  - spatial constraints
KW  - statistical sampling techniques
KW  - control methods
KW  - feedback control theory perspective
KW  - constraint enforcement
KW  - feedback motion planner
KW  - trajectory-free novel feedback motion planning algorithm
KW  - random trees
KW  - tree part
KW  - collision-free region
KW  - connected simple polygonal regions
KW  - reference governor part
KW  - tree structure
KW  - RG-trees
KW  - sparse random reference governor
KW  - sampling based methods
KW  - Robots
KW  - Heuristic algorithms
KW  - Planning
KW  - Collision avoidance
KW  - Dynamics
KW  - Aerospace electronics
KW  - Navigation
DO  - 10.1109/IROS.2018.8594447
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling based methods resulted in feasible and effective motion planning algorithms for high dimensional configuration spaces and complex environments. A vast majority of such algorithms as well as their application rely on generating a set of open-loop trajectories first, which are then tracked by feedback control policies. However, controlling a dynamic robot to follow the planned path, while respecting the spatial constraints originating from the obstacles is still a challenging problem. There are some studies which combine statistical sampling techniques and feedback control methods which address this challenge using different approaches. From the feedback control theory perspective, Reference Governors proved to be a useful framework for constraint enforcement. Very recently, Arslan and Koditschek (2017) introduced a feedback motion planner that utilizes Reference Governors that provably solves the motion planning problem in simplified spherical worlds. In this context, here we propose a “trajectory-free” novel feedback motion planning algorithm which combines the two ideas: random trees and reference governors. Random tree part of the algorithm generates a collision-free region as a set of connected simple polygonal regions. Then, reference governor part navigates the dynamic robot from one region to the adjacent region in the tree structure, ensuring it stays inside the current region and asymptotically reaches to the connected region. Eventually, our algorithm robustly routes the robot from the start location to the goal location without collision. We demonstrate the validity and feasibility of the algorithm on simulation studies.
ER  - 

TY  - CONF
TI  - Real-Time Motion Planning in Changing Environments Using Topology-Based Encoding of Past Knowledge
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6512
EP  - 6517
AU  - R. Fisher
AU  - B. Rosman
AU  - V. Ivan
PY  - 2018
KW  - collision avoidance
KW  - encoding
KW  - graph theory
KW  - mobile robots
KW  - reachability analysis
KW  - topology
KW  - approximate Reeb graph
KW  - BKPIECE algorithms
KW  - topology-based encoding
KW  - trajectory planning
KW  - complex environments
KW  - DRM-connect algorithm
KW  - dynamic reachability maps
KW  - lazy collision checking
KW  - fallback strategy
KW  - RRT-connect algorithm
KW  - sparser roadmaps
KW  - motion planning
KW  - changing environments
KW  - Task analysis
KW  - Trajectory
KW  - Planning
KW  - Heuristic algorithms
KW  - Robots
KW  - Topology
KW  - Maintenance engineering
DO  - 10.1109/IROS.2018.8593879
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Trajectory planning and replanning in complex environments often reuses very little information from the previous solutions. This is particularly evident when the motion is repeated multiple times with only a limited amount of variation between each run. To address this issue, we propose the DRM-connect algorithm, a combination of dynamic reachability maps (DRM) with lazy collision checking and a fallback strategy based on the RRT-connect algorithm which is used to repair the roadmap through further exploration. This fallback allows us to use much sparser roadmaps. Furthermore, we investigate using an approximate Reeb graph to capture the topology-persistent features of the past solutions of the problem utilising this sparsity. We evaluate DRM-connect with a Reeb graph on reaching tasks, and we compare it to state-of-the-art methods. We show that the proposed method outperforms both RRT-connect and BKPIECE algorithms in the number of collision checks required and we show that our method has the potential to scale to systems with higher number degrees of freedom.
ER  - 

TY  - CONF
TI  - Distributionally Robust Sampling-Based Motion Planning Under Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6518
EP  - 6523
AU  - T. Summers
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - Gaussian distribution
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - stochastic processes
KW  - obstacle avoidance
KW  - unpredictable obstacle motion
KW  - uncertain obstacle location
KW  - kinodynamic motion planning
KW  - distributionally robust RRT
KW  - DR-RRT
KW  - Gaussian distributions
KW  - distributionally robust sampling
KW  - distributionally robust incremental sampling
KW  - Uncertainty
KW  - Planning
KW  - Trajectory
KW  - Robots
KW  - Feedback control
KW  - Probabilistic logic
KW  - Stochastic processes
DO  - 10.1109/IROS.2018.8593893
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a distributionally robust incremental sampling-based method for kinodynamic motion planning under uncertainty, which we call distributionally robust RRT (DR-RRT). In contrast to many approaches that assume Gaussian distributions for uncertain parameters, here we consider moment-based ambiguity sets of distributions with given mean and covariance. Chance constraints for obstacle avoidance and internal state bounds are then enforced under the worst-case distribution in the ambiguity set, which gives a coherent assessment of constraint violation risks. The method generates risk-bounded trajectories and feedback control laws for robots operating in dynamic, cluttered, and uncertain environments, explicitly incorporating localization error, stochastic process disturbances, unpredictable obstacle motion, and uncertain obstacle location. We show that the algorithm is probabilistically complete under mild assumptions. Numerical experiments illustrate the effectiveness of the algorithm.
ER  - 

TY  - CONF
TI  - Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Mesesan
AU  - M. A. Roa
AU  - E. Icer
AU  - M. Althoff
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - trees (mathematics)
KW  - path planning problems
KW  - C-space planners
KW  - configuration space
KW  - robot end-effector
KW  - collision-free paths
KW  - workspace information
KW  - global planner
KW  - task-space RRTs
KW  - workspace decomposition
KW  - hierarchical path planner
KW  - Task analysis
KW  - Path planning
KW  - End effectors
KW  - Partitioning algorithms
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593870
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.
ER  - 

TY  - CONF
TI  - Kinodynamic Comfort Trajectory Planning for Car-Like Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6532
EP  - 6539
AU  - H. Shin
AU  - D. Kim
AU  - S. Yoon
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - concave programming
KW  - force control
KW  - mobile robots
KW  - object detection
KW  - trajectory control
KW  - translational force
KW  - direct collocation method
KW  - smooth trajectory
KW  - kinodynamic comfort trajectory planning
KW  - car-like robots
KW  - personal autonomous mobility
KW  - comfortability
KW  - kinodynamic comfort path planning method
KW  - nonconvex objective function
KW  - bidirectional obstacle detection
KW  - obstacle avoidance
KW  - smooth trajectory generation
KW  - Robots
KW  - Acceleration
KW  - Planning
KW  - Trajectory optimization
KW  - System dynamics
KW  - Linear programming
DO  - 10.1109/IROS.2018.8593397
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As personal autonomous mobility is getting to be more widely adopted, it is more important to consider comfortability of stuffs and persons carried by such mobility. In this work, we define the comfort of a trajectory as forces, specifically, translational force, received to objects carried by a robot while following the trajectory by measuring impulse. To maximize such a comfort, we propose a novel, kinodynamic comfort path planning method based on our definition of comfort. Our work is based on direct collocation method for handling our nonconvex objective function. We also introduce Bidirectional Obstacle Detection(BOD)that identifies the distances along the perpendicular directions to the trajectory. This is mainly designed for avoiding obstacles while minimizing forces causing discomfort. Our experimental results show that our method can compute trajectories whose comfort measures can be up to 18 times higher than those computed by prior related objectives, e.g., squared velocity used for generating smooth trajectory.
ER  - 

TY  - CONF
TI  - Expert-Guided Kinodynamic RRT Path Planner for Non-Holonomic Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6540
EP  - 6545
AU  - J. M. Sanz
AU  - M. Hernando
AU  - G. Zaragoza
AU  - A. Brunete
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - nonholonomic robots
KW  - EGK-RRT
KW  - expert-guided kinodynamic RRT path planner
KW  - expert-guided kinodynamic RRT algorithm
KW  - deterministic control sequences
KW  - Robots
KW  - Navigation
KW  - Heuristic algorithms
KW  - Aerospace electronics
KW  - Path planning
KW  - Planning
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593924
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, an Expert-Guided Kinodynamic RRT algorithm (EGK-RRT) is presented. It aims to consider how a human pilot would navigate a kinodynamic robot. One of the characteristics of this algorithm is the fact that, unlike the original RRT for kinodynamic systems, it generates deterministic control sequences which can be reproduced as long as the sequence of references (sampled states) are known. Here, the performance of the proposed algorithm is tested against the basic RRT, showing that the EGK-RRT greatly improves in terms of execution speed. In addition to this, the influence of using a visibility check and an inertia estimation in order to select the nearest neighbor is also analyzed, demonstrating that a combination of both factors leads to a better overall performance, both in execution speed and in quality of the generated path.
ER  - 

TY  - CONF
TI  - Robot Imitation Through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - R. Fernandez-Fernandez
AU  - J. G. Victores
AU  - D. Estevez
AU  - C. Balaguer
PY  - 2018
KW  - evolutionary computation
KW  - humanoid robots
KW  - human-robot interaction
KW  - optimisation
KW  - robot vision
KW  - trajectory control
KW  - optimization problem
KW  - continuous goal-directed actions
KW  - robot joint trajectories
KW  - online evolved trajectories
KW  - force features
KW  - iron actions
KW  - TEO full-sized humanoid robot
KW  - motor execution
KW  - CGDA execution
KW  - online evolutionary strategies
KW  - evolutionary algorithms
KW  - robot imitation framework
KW  - Trajectory
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Force
KW  - Planning
KW  - Paints
DO  - 10.1109/IROS.2018.8593724
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Continuous Goal-Directed Actions (CGDA)is a robot imitation framework that encodes actions as the changes they produce on the environment. While it presents numerous advantages with respect to other robot imitation frameworks in terms of generalization and portability, final robot joint trajectories for the execution of actions are not necessarily encoded within the model. This is studied as an optimization problem, and the solution is computed through evolutionary algorithms in simulated environments. Evolutionary algorithms require a large number of evaluations, which had made the use of these algorithms in real world applications very challenging. This paper presents online evolutionary strategies, as a change of paradigm within CGDA execution. Online evolutionary strategies shift and merge motor execution into the planning loop. A concrete online evolutionary strategy, Online Evolved Trajectories (OET), is presented. OET drastically reduces computational times between motor executions, and enables working in real world dynamic environments and/or with human collaboration. Its performance has been measured against Full Trajectory Evolution (FTE)and Incrementally Evolved Trajectories (IET), obtaining the best overall results. Experimental evaluations are performed on the TEO full-sized humanoid robot with “paint” and “iron” actions that together involve vision, kinesthetic and force features.
ER  - 

TY  - CONF
TI  - Probabilistic Learning of Torque Controllers from Kinematic and Force Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Silvério
AU  - Y. Huang
AU  - L. Rozo
AU  - S. Calinon
AU  - D. G. Caldwell
PY  - 2018
KW  - control engineering computing
KW  - force control
KW  - Gaussian distribution
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - position control
KW  - torque control
KW  - kinematic constraints
KW  - task representation
KW  - task space
KW  - Gaussian distributions
KW  - 7- DoF torque-controlled manipulators
KW  - joint space
KW  - torque control commands
KW  - operational configuration space
KW  - force constraints
KW  - probabilistic learning
KW  - Task analysis
KW  - Torque
KW  - Aerospace electronics
KW  - Probabilistic logic
KW  - Force
KW  - End effectors
DO  - 10.1109/IROS.2018.8594103
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When learning skills from demonstrations, one is often required to think in advance about the appropriate task representation (usually in either operational or configuration space). We here propose a probabilistic approach for simultaneously learning and synthesizing torque control commands which take into account task space, joint space and force constraints. We treat the problem by considering different torque controllers acting on the robot, whose relevance is learned probabilistically from demonstrations. This information is used to combine the controllers by exploiting the properties of Gaussian distributions, generating new torque commands that satisfy the important features of the task. We validate the approach in two experimental scenarios using 7- DoF torque-controlled manipulators, with tasks that require the consideration of different controllers to be properly executed.
ER  - 

TY  - CONF
TI  - Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6560
EP  - 6565
AU  - K. C. Mbanisi
AU  - H. Kimpara
AU  - T. Meier
AU  - M. Gennert
AU  - Z. Li
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - road vehicles
KW  - vehicle dynamics
KW  - human-vehicle interaction simulation framework
KW  - driving motions
KW  - vehicle maneuver motion primitives
KW  - driving decision-making
KW  - vehicle design
KW  - human demonstration
KW  - vehicle dynamics
KW  - motion control
KW  - motion primitive library
KW  - longitudinal vehicle control
KW  - motion reproduction
KW  - dynamic motion primitives
KW  - imitation learning methods
KW  - fixed-base driving simulation
KW  - vehicle maneuver motion planning
KW  - Vehicles
KW  - Computational modeling
KW  - Task analysis
KW  - Motion segmentation
KW  - Vehicle dynamics
KW  - Hidden Markov models
KW  - Dynamics
DO  - 10.1109/IROS.2018.8593976
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - High-fidelity computational human models provide a safe and cost-efficient method for studying driver experience in vehicle maneuvers and for validation of vehicle design. Compared to passive human models, active human models capable of reproducing the decision-making, as well as vehicle maneuver motion planning and control, will be able to support realistic simulation of human-vehicle interaction. In this paper, we propose an integrated human-vehicle interaction simulation framework which learns vehicle maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions. Specifically, we recruited six experienced drivers and recorded their vehicle maneuver motions on a fixed-base driving simulation testbed. We further segmented and classified the collected data based on their similarity in joint coordination. Using a combination of imitation learning methods, we extracted the regularity and variability of vehicle maneuver motions across subjects, and learned the dynamic motion primitives to be used for motion reproduction in simulation. We present an implementation of the framework on lower-extremity joint coordination in pedal activation for longitudinal vehicle control. Our research efforts lead to a motion primitive library which enables planning natural driver motions, and will be integrated with the driving decision-making, motion control, and vehicle dynamics in the proposed framework for simulating human-vehicle interaction.
ER  - 

TY  - CONF
TI  - Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6566
EP  - 6573
AU  - Y. S. Liang
AU  - D. Pellier
AU  - H. Fiorino
AU  - S. Pesty
AU  - M. Cakmak
PY  - 2018
KW  - human-robot interaction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - teaching
KW  - user interfaces
KW  - teaching strategies
KW  - end-user programming
KW  - learning task
KW  - human teachers
KW  - fetch mobile manipulator
KW  - warehouses
KW  - robotic shelf organization
KW  - online user study
KW  - goal inference approach
KW  - system implementation
KW  - grocery store shelf images
KW  - Task analysis
KW  - Programming
KW  - Manipulators
KW  - Shape
KW  - Packaging
KW  - Education
DO  - 10.1109/IROS.2018.8593518
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.
ER  - 

TY  - CONF
TI  - Incremental Skill Learning of Stable Dynamical Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6574
EP  - 6581
AU  - M. Saveriano
AU  - D. Lee
PY  - 2018
KW  - control engineering computing
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - regression analysis
KW  - robot programming
KW  - stability
KW  - trajectory control
KW  - control input
KW  - Gaussian process regression
KW  - incremental skill learning
KW  - online adaptation
KW  - assistive robotic applications
KW  - motion trajectories
KW  - dynamical systems
KW  - skill acquisition
KW  - autonomous DS
KW  - stability properties
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Training
KW  - Training data
KW  - Gaussian processes
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594474
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Efficient skill acquisition, representation, and online adaptation to different scenarios has become of fundamental importance for assistive robotic applications. In the past decade, dynamical systems (DS) have arisen as a flexible and robust tool to represent learned skills and to generate motion trajectories. This work presents a novel approach to incrementally modify the dynamics of a generic autonomous DS when new demonstrations of a task are provided. A control input is learned from demonstrations to modify the trajectory of the system while preserving the stability properties of the reshaped DS. Learning is performed incrementally through Gaussian process regression, increasing the robot's knowledge of the skill every time a new demonstration is provided. The effectiveness of the proposed approach is demonstrated with experiments on a publicly available dataset of complex motions.
ER  - 

TY  - CONF
TI  - Deeply Informed Neural Sampling for Robot Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6582
EP  - 6588
AU  - A. H. Qureshi
AU  - M. C. Yip
PY  - 2018
KW  - collision avoidance
KW  - computational complexity
KW  - feedforward neural nets
KW  - geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - sampling methods
KW  - obstacle geometry
KW  - computational complexity
KW  - configuration space
KW  - optimal path solution
KW  - hand-crafted heuristics
KW  - high-dimensional spaces
KW  - neural network-based adaptive sampler
KW  - raw point cloud data
KW  - workspace encoding
KW  - collision-free optimal paths
KW  - point-mass robot
KW  - 6-link robotic manipulator
KW  - dropout-based stochastic deep feedforward neural network
KW  - DeepSMPs neural architecture
KW  - deep sampling-based motion planner
KW  - robot motion planning
KW  - deeply informed neural sampling
KW  - contractive autoencoder
KW  - rigid-body
KW  - Planning
KW  - Robots
KW  - Encoding
KW  - Three-dimensional displays
KW  - Convergence
KW  - Switched mode power supplies
KW  - Transforms
DO  - 10.1109/IROS.2018.8593772
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.
ER  - 

TY  - CONF
TI  - Inverse Learning of Robot Behavior for Collaborative Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Trivedi
AU  - P. Doshi
PY  - 2018
KW  - behavioural sciences computing
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - planning (artificial intelligence)
KW  - robots decision making
KW  - TurtleBots
KW  - Phantom X arms
KW  - line robots behavior
KW  - collaborative planning problem
KW  - colored-ball sorting task
KW  - unripe fruit
KW  - ripe fruit
KW  - IRL
KW  - inverse reinforcement learning
KW  - Task analysis
KW  - Planning
KW  - Robot kinematics
KW  - Sorting
KW  - Teamwork
DO  - 10.1109/IROS.2018.8593745
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.
ER  - 

TY  - CONF
TI  - Multi-Cable Rolling Locomotion with Spherical Tensegrities Using Model Predictive Control and Deep Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - B. Cera
AU  - A. M. Agogino
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - differential equations
KW  - feedback
KW  - learning (artificial intelligence)
KW  - open loop systems
KW  - predictive control
KW  - robust control
KW  - trajectory control
KW  - generated optimal MPC trajectories
KW  - supervised deep learning
KW  - contextual policy
KW  - benchmark single-cable policy performance
KW  - resulting multicable state-action trajectories
KW  - dynamic rolling
KW  - multicable actuation trajectories
KW  - Class-1 tensegrity systems
KW  - structured dynamics
KW  - spherical tensegrity topology
KW  - robust control policies
KW  - model-based approach
KW  - model predictive control
KW  - spherical tensegrities
KW  - multicable rolling locomotion
KW  - end-to-end feedback policy
KW  - Mathematical model
KW  - Predictive control
KW  - Topology
KW  - Robot kinematics
KW  - Dynamics
KW  - Optimization
DO  - 10.1109/IROS.2018.8594401
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a model-based approach for creating robust control policies for rolling locomotion with a spherical tensegrity topology. Utilizing the structured dynamics of Class-1 tensegrity systems, we turn to model predictive control (MPC) to generate optimal multi-cable actuation trajectories for dynamic rolling. Although the resulting multi-cable state-action trajectories successfully outperform the benchmark single-cable policy performance in speed, computational constraints prevent MPC from being applied in real-time. To address this, we demonstrate that a contextual policy trained using supervised deep learning on the generated optimal MPC trajectories can be used as an end-to-end feedback policy for real-time directed rolling locomotion.
ER  - 

TY  - CONF
TI  - Integrating Path Planning and Pivoting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6601
EP  - 6608
AU  - S. Cruciani
AU  - C. Smith
PY  - 2018
KW  - end effectors
KW  - path planning
KW  - manipulator
KW  - pivoting strategy
KW  - Baxter robot
KW  - path planning
KW  - motion planning
KW  - in-hand manipulation
KW  - end-effector
KW  - Grippers
KW  - Task analysis
KW  - Friction
KW  - End effectors
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593584
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we propose a method for integrating motion planning and in-hand manipulation. Commonly addressed as a separate step from the final execution, in-hand manipulation allows the robot to reorient an object within the end-effector for the successful outcome of the goal task. A joint achievement of repositioning the object and moving the manipulator towards its desired final pose saves time in the execution and introduces more flexibility in the system. We address this problem using a pivoting strategy (i.e. in-hand rotation)for repositioning the object and we integrate this strategy with a path planner for the execution of a complex task. This method is applied on a Baxter robot and its efficacy is shown by experimental results.
ER  - 

TY  - CONF
TI  - Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6609
EP  - 6614
AU  - R. Higo
AU  - Y. Yamakawa
AU  - T. Senoo
AU  - M. Ishikawa
PY  - 2018
KW  - dexterous manipulators
KW  - manipulator dynamics
KW  - robot vision
KW  - continuous high-speed operation
KW  - one-face turn motion
KW  - high-speed multifingered hand
KW  - high-speed vision system
KW  - Rubiks cube handling
KW  - robotic hand regrasping function
KW  - time 1.0 s
KW  - time 10.0 s
KW  - Gravity
KW  - Face
KW  - Robot sensing systems
KW  - Turning
KW  - Trajectory
KW  - Orbits
DO  - 10.1109/IROS.2018.8593538
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.
ER  - 

TY  - CONF
TI  - Contingent Contact-Based Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6615
EP  - 6621
AU  - E. Páll
AU  - A. Sieverling
AU  - O. Brock
PY  - 2018
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robust control
KW  - POMDP-based planners
KW  - contingent contact-based motion planning
KW  - contact sensing capability
KW  - manipulation planner
KW  - conformant planners
KW  - high-dimensional configuration spaces
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Planning
KW  - Partitioning algorithms
KW  - Vegetation
DO  - 10.1109/IROS.2018.8594365
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A robot with contact sensing capability can reduce uncertainty relative to the environment by deliberately moving into contact and matching the resulting contact measurement to different possible states in the world. We present a manipulation planner that finds and sequences these actions by reasoning explicitly about the uncertainty over the robot's state. The planner incrementally constructs a policy that covers all possible contact states during a manipulation and finds contingencies for each of them. In contrast to conformant planners (without contingencies), the planned contingent policies are more robust. We demonstrate this in simulated and real-world manipulation experiments. In contrast to POMDP-based planners, we show that our planner can be directly applied to high-dimensional configuration spaces.
ER  - 

TY  - CONF
TI  - A Lightweight Redundant Manipulator with High Stable Wireless Communication and Compliance Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6622
EP  - 6627
AU  - L. Han
AU  - L. Yan
AU  - W. Xu
PY  - 2018
KW  - compliance control
KW  - control engineering computing
KW  - dexterous manipulators
KW  - force control
KW  - intelligent manufacturing systems
KW  - motion control
KW  - position control
KW  - production engineering computing
KW  - protocols
KW  - redundant manipulators
KW  - servomechanisms
KW  - wireless sensor networks
KW  - Zigbee
KW  - 7-DOF manipulator
KW  - application layer protocol
KW  - ZigBee
KW  - absolute magnetic encoder
KW  - incremental magnetic encoder
KW  - hall sensors
KW  - Industry 4.0
KW  - distributed networked-manufacturing system
KW  - joint servo controllers
KW  - intelligent manufacturing system
KW  - manipulator body
KW  - high stable wireless communication link
KW  - motion controller
KW  - lightweight redundant manipulator
KW  - wireless impedance control experiments
KW  - electrical cables
KW  - wireless compliance control frame
KW  - force control requirements
KW  - communication stability
KW  - wireless communication module
KW  - central controller
KW  - communication cables
KW  - Manipulators
KW  - ZigBee
KW  - Wireless communication
KW  - Servomotors
KW  - Wireless sensor networks
KW  - Impedance
KW  - Sensors
KW  - 7-DOF manipulator
KW  - Multilevel control system
KW  - ZigBee
KW  - Wireless compliance Control
DO  - 10.1109/IROS.2018.8593500
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For traditional manipulators, there is a large number of electrical cables between the motion controller and the joint servo controllers. It is very inconvenient for maintenance, update, and safe operation. In this paper, we develop a lightweight redundant manipulator with high stable wireless communication link and compliance control. The motion controller, servo controller, and communication link are taken as a whole system to be optimized. The manipulator body and the motion controller are physically separated. It is very helpful for building distributed networked-manufacturing system or intelligent manufacturing system for Industry 4.0. The control system can be quickly updated by changing the object's identification without reconnect the communication cables. The mechanical part of the manipulator contains modular joints and links. Each joint is integrated with hall sensors, an incremental magnetic encoder, an absolute magnetic encoder and current sensors. The electrical part includes a central controller, seven joint servo controllers, and a wireless communication module based on ZigBee. By designing the application layer protocol, the communication stability is improved. In order to achieve the force control requirements in fine operation like assembly. A wireless compliance control frame is then designed. The compliance control method is realized on the central controller, by which the generated control commands are sent to the joint servo controllers through a wireless link. The problems caused by large electrical cables are then solved. Finally, the prototype and the experimental system are developed. Some experiments are carried out, including wireless communication test, trajectory tracking experiments, load carrying experiments, and wireless impedance control experiments. Results verify the functions and performance of the developed 7-DOF manipulator.
ER  - 

TY  - CONF
TI  - A Cable-Driven Redundant Spatial Manipulator with Improved Stiffness and Load Capacity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6628
EP  - 6633
AU  - T. Liu
AU  - Z. Mu
AU  - H. Wang
AU  - W. Xu
AU  - Y. Li
PY  - 2018
KW  - control system synthesis
KW  - dexterous manipulators
KW  - end effectors
KW  - flexible manipulators
KW  - Jacobian matrices
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - redundant manipulators
KW  - cable transmission mechanisms
KW  - load capacity experiments
KW  - relatively high stiffness
KW  - cable-driven redundant spatial manipulator
KW  - flexible manipulability
KW  - revolute rigid manipulators
KW  - mechanism design
KW  - manipulator dexterity
KW  - end-effector accuracy
KW  - active-passive-linkage segments
KW  - active-passive segment
KW  - manipulator kinematic equations
KW  - motion planning
KW  - Jacobian matrix
KW  - Denavit-Hartenberg method
KW  - D-H method
KW  - CRSM
KW  - Couplings
KW  - Kinematics
KW  - Springs
KW  - Task analysis
KW  - End effectors
KW  - Cable-driven
KW  - Redundant manipulator
KW  - Stiffness
KW  - Load capacity
KW  - Kinematic
DO  - 10.1109/IROS.2018.8593679
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With a light and slender body, a cable-driven redundant spatial manipulator (CRSM) has flexible manipulability and high maneuverability in confined environment. However, compared with revolute rigid manipulators, such type of manipulators generally has low stiffness and weak load capacity. In this paper, we propose a new mechanism design to improve the stiffness and load capacity without sacrificing the manipulator dexterity and the end-effector accuracy. The manipulator is composed of 3 active-passive-linkage segments and 1 active tool end-effector. Each active-passive segment has 2 degrees of freedom (DOFs) driven by three evenly distributed cables. Pretension mechanism and linkage cables are designed to keep strict equal angles of adjacent joints. A separable control box, which contains all the motors and cable transmission mechanisms is also designed with a quick release-and-lock mechanism. Therefore, the robotic arm can be easily removed and installed. Based on the equal angle characteristic, kinematic equations of manipulator are established with Denavit-Hartenberg (D-H) method and the Jacobian matrix is also simplified. Further analysis of the workspace supplies the guidance for the task design and motion planning. Finally, a prototype system is developed to perform the stiffness and load capacity experiments. Experimental results show that the developed CRSM has relatively high stiffness and load capacity.
ER  - 

TY  - CONF
TI  - Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Zhang
AU  - S. Ma
AU  - Y. Li
PY  - 2018
KW  - legged locomotion
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - system states
KW  - system trajectory
KW  - nonprehensile
KW  - manipulation strategies
KW  - multilimb robot
KW  - control strategy
KW  - point contacts
KW  - contact velocity constraint
KW  - force constraint
KW  - system forces
KW  - system dynamic models
KW  - Robot kinematics
KW  - Force
KW  - Acceleration
KW  - Humanoid robots
KW  - Legged locomotion
KW  - Friction
DO  - 10.1109/IROS.2018.8593914
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.
ER  - 

TY  - CONF
TI  - Assisted Telemanipulation: A Stack-Of-Tasks Approach to Remote Manipulator Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Stoyanov
AU  - R. Krug
AU  - A. Kiselev
AU  - D. Sun
AU  - A. Loutfi
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - haptic interfaces
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - telerobotics
KW  - assisted telemanipulation
KW  - stack-of-tasks approach
KW  - remote manipulator control
KW  - assisted teleoperation
KW  - robot arm
KW  - hierarchical nature
KW  - SoT framework
KW  - operator commands
KW  - assistive tasks
KW  - joint limit
KW  - obstacle avoidance
KW  - automatic gripper alignment
KW  - teleoperation problem
KW  - assistive control
KW  - manual control
KW  - real-time stack-of-tasks whole-body motion control framework
KW  - teleoperated pick-and-place tasks
KW  - telemanipulation system
KW  - Task analysis
KW  - Grippers
KW  - Robot kinematics
KW  - Manipulators
KW  - Acceleration
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594457
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This article presents an approach for assisted teleoperation of a robot arm, formulated within a real-time stack-of-tasks (SoT)whole-body motion control framework. The approach leverages the hierarchical nature of the SoT framework to integrate operator commands with assistive tasks, such as joint limit and obstacle avoidance or automatic gripper alignment. Thereby some aspects of the teleoperation problem are delegated to the controller and carried out autonomously. The key contributions of this work are two-fold: the first is a method for unobtrusive integration of autonomy in a telemanip-ulation system; and the second is a user study evaluation of the proposed system in the context of teleoperated pick-and-place tasks. The proposed approach of assistive control was found to result in higher grasp success rates and shorter trajectories than achieved through manual control, without incurring additional cognitive load to the operator.
ER  - 

TY  - CONF
TI  - Adaptive Admittance Control in Task-Priority Framework for Contact Force Control in Autonomous Underwater Floating Manipulation* This work is part of a project titled “Force/position control system to enable compliant manipulation from a floating I-AUV”, which received funding from the European Union's Horizon 2020 research and innovation programme, under the Marie Sklodowska-Curie grant agreement no. 750063.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6646
EP  - 6651
AU  - P. Cieślak
AU  - P. Ridao
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cooperative systems
KW  - end effectors
KW  - force control
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - manipulators
KW  - mobile robots
KW  - position control
KW  - task-priority kinematic control algorithm
KW  - custom force control strategy
KW  - impedance control
KW  - TP algorithm
KW  - inequality tasks
KW  - singular configurations
KW  - force control part
KW  - impedance concept
KW  - exerted force
KW  - stable contact
KW  - control architecture
KW  - adaptive admittance control
KW  - task-priority framework
KW  - contact force control
KW  - underwater vehicle-manipulator system
KW  - end-effector configuration
KW  - floating-base manipulation
KW  - Force control
KW  - Task analysis
KW  - Force
KW  - Impedance
KW  - Robots
KW  - Heuristic algorithms
KW  - Inspection
DO  - 10.1109/IROS.2018.8593542
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a control architecture for an underwater vehicle-manipulator system (UVMS) to enable simultaneous tracking of end-effector configuration and contact force during floating-base manipulation. The main feature of the architecture is its combination of a task-priority (TP) kinematic control algorithm with a custom force control strategy, based on impedance (admittance) control. The TP algorithm used in the work includes recent treatment of equality and inequality tasks as well as original concepts to handle operation in singular configurations of the system. In the force control part the impedance concept is extended to allow for direct control over the value of exerted force and torque. Additional feed-forward signal is used to ensure stable contact. The performance of the control architecture is demonstrated by experiments in a test tank, with GIRONA500 I-AUV performing pipe inspection.
ER  - 

TY  - CONF
TI  - Optimizing Sensor Placement: A Mixture Model Framework Using Stable Poses and Sparsely Precomputed Pose Uncertainty Predictions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6652
EP  - 6659
AU  - T. M. Iversen
AU  - D. Kraft
PY  - 2018
KW  - image sensors
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - sensor placement
KW  - computer vision system
KW  - mixture model framework
KW  - sensor placement optimization
KW  - robotics tasks
KW  - pose estimation
KW  - probability distribution
KW  - primesense carmine
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Computational modeling
KW  - Task analysis
KW  - Optimization
KW  - Measurement
DO  - 10.1109/IROS.2018.8594121
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.
ER  - 

TY  - CONF
TI  - Robust 6D Object Pose Estimation in Cluttered Scenes Using Semantic Segmentation and Pose Regression Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6660
EP  - 6666
AU  - A. S. Periyasamy
AU  - M. Schwarz
AU  - S. Behnke
PY  - 2018
KW  - clutter
KW  - data acquisition
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - regression analysis
KW  - robot vision
KW  - pose regression networks
KW  - cluttered scenes
KW  - cropped object-centered
KW  - object poses
KW  - cluttered bin-picking scenes
KW  - semantic segmentation
KW  - synthetic data generation procedure
KW  - fast data acquisition method
KW  - estimation methods
KW  - real-world bin-picking settings
KW  - object pose estimation
KW  - Pose estimation
KW  - Semantics
KW  - Three-dimensional displays
KW  - Training
KW  - Image segmentation
KW  - Solid modeling
KW  - Robots
DO  - 10.1109/IROS.2018.8594406
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Object pose estimation is a crucial prerequisite for robots to perform autonomous manipulation in clutter. Real-world bin-picking settings such as warehouses present additional challenges, e.g., new objects are added constantly. Most of the existing object pose estimation methods assume that 3D models of the objects is available beforehand. We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure. This work builds on previous work on semantic segmentation of cluttered bin-picking scenes to isolate individual objects in clutter. An additional network is trained on synthetic scenes to estimate object poses from a cropped object-centered encoding extracted from the segmentation results. The proposed method is evaluated on a synthetic validation dataset and cluttered realworld scenes.
ER  - 

TY  - CONF
TI  - Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6667
EP  - 6674
AU  - P. D. H. Nguyen
AU  - T. Fischer
AU  - H. J. Chang
AU  - U. Pattacini
AU  - G. Metta
AU  - Y. Demiris
PY  - 2018
KW  - calibration
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - neural nets
KW  - robot vision
KW  - stereo image processing
KW  - robotic manipulation tasks
KW  - physical iCub robot
KW  - joint measurements
KW  - systematic error
KW  - accurate joint estimates
KW  - visuomotor predictor
KW  - image-to-image translation approach
KW  - physical robot
KW  - sensing error
KW  - unavoidable sources
KW  - underlying head configuration
KW  - stereo image pair
KW  - visuomotor deep neural network predictor
KW  - hand-eye coordination task
KW  - iCub humanoid
KW  - complex robots
KW  - accurate hand-eye coordination
KW  - visuomotor learning
KW  - Robot kinematics
KW  - Head
KW  - Task analysis
KW  - Robot sensing systems
KW  - Visualization
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594519
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.
ER  - 

TY  - CONF
TI  - Proprioception-Based Grasping for Unknown Objects Using a Series-Elastic-Actuated Gripper
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6675
EP  - 6681
AU  - T. Chen
AU  - M. Ciocarlie
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - grippers
KW  - mechanoception
KW  - MIMO systems
KW  - motion control
KW  - series-elastic-actuated gripper
KW  - stable fingertip grasps
KW  - proprioceptive gripper
KW  - proprioception-based grasping
KW  - multi-input-multi-output control
KW  - MIMO control
KW  - sensors
KW  - Robot sensing systems
KW  - Grippers
KW  - Grasping
KW  - Pulleys
KW  - Springs
KW  - Sea measurements
DO  - 10.1109/IROS.2018.8593787
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasping unknown objects has been an active research topic for decades. Approaches range from using various sensors (e.g. vision, tactile) to gain information about the object, to building passively compliant hands that react appropriately to contacts. In this paper, we focus on grasping unknown objects using proprioception (the combination of joint position and torque sensing). Our hypothesis is that proprioception alone can be the basis for versatile performance, including multiple types of grasps for objects with multiple shapes and sizes, and transitions between grasps. Using a series-elastic-actuated gripper, we propose a method for performing stable fingertip grasps for unknown objects with unknown contacts, formulated as multi-input-multi-output (MIMO) control. We also show that the proprioceptive gripper can perform enveloping grasps, as well as the transition from fingertip grasps to enveloping grasps.
ER  - 

TY  - CONF
TI  - Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6682
EP  - 6689
AU  - S. Li
AU  - S. Lyu
AU  - J. Trinkle
PY  - 2018
KW  - Bayes methods
KW  - Kalman filters
KW  - manipulators
KW  - particle filtering (numerical methods)
KW  - quadratic programming
KW  - state estimation
KW  - RBPF
KW  - contact states
KW  - Kalman filters
KW  - constrained Rao-Blackwellized Particle Filter
KW  - robotic sensors
KW  - robotic manipulation task
KW  - multibody dynamic system
KW  - Bayesian filtering methods
KW  - state estimation
KW  - quadratic programming problem
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Kalman filters
KW  - State estimation
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594268
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.
ER  - 

TY  - CONF
TI  - A Gripper for Object Search and Grasp Through Proximity Sensing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - N. Yamaguchi
AU  - S. Hasegawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - calibration
KW  - grippers
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - object grasp
KW  - object search
KW  - calibration method
KW  - proximity sensors
KW  - sensor reaction
KW  - robot motions
KW  - proximity sensing
KW  - sensor information
KW  - primitive motions
KW  - gripper
KW  - Robot sensing systems
KW  - Rubber
KW  - Grippers
KW  - Calibration
KW  - Search problems
DO  - 10.1109/IROS.2018.8593572
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots need to adapt themselves to various surroundings in order to achieve robust object search and grasp in unknown environments. For this adaptation, robot motions should be implemented as combination of primitive motions which are based on sensor reaction. Among various sensing methods, non contact sensing is required as a means of preventing operation failures such as pushing objects. Especially, proximity sensors have been proved effective in avoiding occlusion problems. In this paper, we first develop a gripper on which proximity sensors are mounted all around, and then calculate distance between the gripper and objects using proposed calibration method. This enables robots to recognize detailed shapes of objects surrounding the gripper. We also propose primitive motions for object search and grasp, and describe the contents of each motion. The motions are based on sensor information obtained from the gripper. We verify the effectiveness of our system through an experiment in which a real robot performs complex tasks by combination of the primitive motions.
ER  - 

TY  - CONF
TI  - Exploring Vestibulo-Ocular Adaptation in a Closed-Loop Neuro-Robotic Experiment Using STDP. A Simulation Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Naveros
AU  - J. A. Garrido
AU  - A. Arleo
AU  - E. Ros
AU  - N. R. Luque
PY  - 2018
KW  - brain models
KW  - closed loop systems
KW  - control engineering computing
KW  - humanoid robots
KW  - neural nets
KW  - neural system
KW  - Neuro-robotic Platform
KW  - NRP
KW  - vestibulo ocular cerebellar adaptatIon
KW  - STDP mechanisms
KW  - cerebellar molecular layer
KW  - r-VOR adaptation
KW  - spiking cerebellar model
KW  - r-VOR task
KW  - perception-action closed-loop
KW  - vestibulo-ocular reflex
KW  - humanoid robot
KW  - iCub robot
KW  - cerebellar properties
KW  - Robot sensing systems
KW  - Neurons
KW  - Adaptation models
KW  - Transfer functions
KW  - Task analysis
KW  - Optical fiber networks
DO  - 10.1109/IROS.2018.8594019
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Studying and understanding the computational primitives of our neural system requires for a diverse and complementary set of techniques. In this work, we use the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar adaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms located at the cerebellar molecular layer and the vestibular nuclei respectively. This simulation study adopts an experimental setup (rotatory VOR)widely used by neuroscientists to better understand the contribution of certain specific cerebellar properties (i.e. distributed STDP, neural properties, coding cerebellar topology, etc.)to r-VOR adaptation. The work proposes and describes an embodiment solution for which we endow a simulated humanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and we face the humanoid to an r-VOR task. The results validate the adaptive capabilities of the spiking cerebellar model (with STDP)in a perception-action closed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.
ER  - 

TY  - CONF
TI  - Interspecies Retargeting of Homologous Body Posture Based on Skeletal Morphing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6712
EP  - 6719
AU  - K. Ayusawa
AU  - Y. Ikegami
AU  - A. Murai
AU  - Y. Yoshiyasu
AU  - E. Yoshida
AU  - S. Oota
AU  - Y. Nakamura
PY  - 2018
KW  - biomechanics
KW  - computerised tomography
KW  - image morphing
KW  - medical image processing
KW  - physiological models
KW  - skeletal morphing
KW  - bone geometry homology
KW  - mammalian species
KW  - biomechanical functions
KW  - human skeletal models
KW  - mouse skeletal models
KW  - human body posture
KW  - mammalian skeletal system
KW  - human musculoskeletal system
KW  - homologous body posture
KW  - Bones
KW  - Mice
KW  - Joints
KW  - Geometry
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594240
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper aims to develop a methodology of transferring the knowledge obtained from the experiments of laboratory animals to human musculoskeletal system. To achieve the goal, we propose a method for estimating the homologous posture of the mammalian skeletal system corresponding to the human body posture. We hypothesize the homology of bone geometry between mammalian species implies that of biomechanical functions. The method relies on this homology and determines the homologous postures according to the anatomical landmarks of bone geometry. This paper shows the results of the analysis on homologous postures between the human and mouse skeletal models to validate our hypothesis. A pilot study also introduces comparison of mechanical functions between the two models by using the homologous postures.
ER  - 

TY  - CONF
TI  - Neurorobotic Approach to Study Huntington Disease Based on a Mouse Neuromusculoskeletal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6720
EP  - 6727
AU  - S. Oota
AU  - Y. Okamura-Oho
AU  - K. Ayusawa
AU  - Y. Ikegami
AU  - A. Murai
AU  - E. Yoshida
AU  - Y. Nakamura
PY  - 2018
KW  - biomechanics
KW  - cognition
KW  - diseases
KW  - genetics
KW  - medical robotics
KW  - muscle
KW  - neurophysiology
KW  - altered genetic code
KW  - macroscopic neuro-musculoskeletal model
KW  - neurorobotic approach
KW  - mouse neuromusculoskeletal model
KW  - biological system
KW  - neurorobotics view
KW  - early onset symptoms
KW  - neurodegenerative disease
KW  - genetically engineered Huntington disease model mice
KW  - progressive impaired motor functions
KW  - crystalized motion profile
KW  - normal mice
KW  - abnormal mice
KW  - whole-body level motor coordination
KW  - long-term objective
KW  - human mind
KW  - cognitive functions
KW  - soft neurorobotic suit
KW  - HD model mice
KW  - molecular mechanisms
KW  - macroscopic neuromusculoskeletal model
KW  - Mice
KW  - Diseases
KW  - Joints
KW  - Robots
KW  - Kinematics
KW  - Bones
KW  - Biological system modeling
DO  - 10.1109/IROS.2018.8594491
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motor functions of the biological system has been forged through 4 billion years evolution. From a neurorobotics view, it is important not only to know how well it works, but also how it fails. To quantitatively describe early onset symptoms of a neurodegenerative disease, we analyzed phenotypes of genetically engineered Huntington disease (HD) model mice, which reveal progressive impaired motor functions. We devised a simple yet sensitive paradigm called the crystalized motion profile (CMP), by which we successfully detected subtle difference between normal and abnormal mice in terms of whole-body level motor coordination. Our long-term objective is to remodel human mind and body to regain impaired motor and cognitive functions with ageing. To do so, we are developing a soft neurorobotic suit that provides integrated cognitive and physical interventions to users. Our analysis on the HD model mice is important as the first step to bridge between molecular mechanisms (altered genetic code) and the macroscopic neuro-musculoskeletal model. With this, we can extrapolate from knowledge of non-human mammals to human to derive the remodeling.
ER  - 

TY  - CONF
TI  - Temporally Smooth Privacy-Protected Airborne Videos
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6728
EP  - 6733
AU  - O. Sarwar
AU  - A. Cavallaro
AU  - B. Rinner
PY  - 2018
KW  - data privacy
KW  - image restoration
KW  - spatiotemporal phenomena
KW  - video signal processing
KW  - recreational videography
KW  - drones
KW  - privacy filters
KW  - flicker
KW  - privacy-protected airborne videos
KW  - identification attacks
KW  - spatiotemporal hopping blur filter
KW  - Face
KW  - Privacy
KW  - Videos
KW  - Probes
KW  - Distortion
KW  - Detectors
KW  - Smoothing methods
DO  - 10.1109/IROS.2018.8594493
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recreational videography from small drones can capture bystanders who may be uncomfortable about appearing in those videos. Existing privacy filters, such as scrambling and hopping blur, address this issue through de-identification but generate temporal distortions that manifest themselves as flicker. To address this problem, we present a robust spatiotemporal hopping blur filter that protects privacy through de-identification of face regions. The proposed filter is meant for on-board installation and produces temporally smooth and pleasant videos. We apply hopping blur to protect each frame against identification attacks, and minimise artefacts and flicker introduced by the hopping blur. We evaluate the proposed filter against different identification attacks and by assessing the quality of the resulting videos using a subjective test and objective measures.
ER  - 

TY  - CONF
TI  - Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6734
EP  - 6739
AU  - M. Car
AU  - A. Ivanovic
AU  - M. Orsag
AU  - S. Bogdan
PY  - 2018
KW  - aerospace robotics
KW  - force control
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - rotors
KW  - whole body locomotion
KW  - tactile perception
KW  - finite state automaton
KW  - aerial robot peg-in-hole insertion tasks
KW  - impedance based force control
KW  - dual arm multidegree of freedom manipulator
KW  - kinematic constraints
KW  - dual arm manipulator
KW  - multirotor base
KW  - multistage strategy
KW  - impedance control
KW  - peg-in-hole approach
KW  - multirotor platform
KW  - canonical peg-in-hole manipulation task
KW  - Force
KW  - Impedance
KW  - Task analysis
KW  - Manipulator dynamics
KW  - Rotors
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593808
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.
ER  - 

TY  - CONF
TI  - Flatness-Based Model Predictive Control for Quadrotor Trajectory Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6740
EP  - 6745
AU  - M. Greeff
AU  - A. P. Schoellig
PY  - 2018
KW  - control system synthesis
KW  - convex programming
KW  - feedback
KW  - feedforward
KW  - helicopters
KW  - nonlinear control systems
KW  - nonlinear programming
KW  - position control
KW  - predictive control
KW  - quadratic programming
KW  - stability
KW  - trajectory control
KW  - quadrotor trajectory tracking
KW  - trajectory tracking performance
KW  - constraint satisfaction
KW  - differentially flat nonlinear systems
KW  - FMPC couples feedback model predictive control
KW  - linear model predictive control
KW  - couple model predictive control
KW  - nonlinear model
KW  - control approaches
KW  - flatness-based model predictive control approach
KW  - Feedforward systems
KW  - Predictive control
KW  - Feedback linearization
KW  - Robustness
KW  - Computational modeling
KW  - Predictive models
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594012
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of model predictive control for quadro-tor applications requires balancing trajectory tracking performance and constraint satisfaction with fast computation. This paper proposes a Flatness-based Model Predictive Control (FMPC) approach that can be applied to quadrotors, and more generally, differentially flat nonlinear systems. Our proposed FMPC couples feedback model predictive control with feedforward linearization. The proposed approach has the computational advantage that, similar to linear model predictive control, it only requires solving a convex quadratic program instead of a nonlinear program. However, unlike linear model predictive control, we still account for the nonlinearity in the model through the use of an inverse term. In simulation, we demonstrate improved robustness over approaches that couple model predictive control with feedback linearization. In experiments using quadrotor vehicles, we also demonstrate improved trajectory tracking compared to classical linear and nonlinear model predictive control approaches.
ER  - 

TY  - CONF
TI  - Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6746
EP  - 6752
AU  - A. Suarez
AU  - P. Sanchez-Cuevas
AU  - M. Fernandez
AU  - M. Perez
AU  - G. Heredia
AU  - A. Ollero
PY  - 2018
KW  - actuators
KW  - autonomous aerial vehicles
KW  - feedback
KW  - industrial manipulators
KW  - inspection
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - pendulums
KW  - position control
KW  - torque control
KW  - inspection operations
KW  - multirotor blades
KW  - environmental obstacles
KW  - inspection tasks
KW  - long reach aerial manipulator
KW  - hexarotor platform
KW  - compliant joint arm
KW  - one-meter-length link
KW  - passive pendulum configuration
KW  - force/torque estimation-control
KW  - joint deflection
KW  - visual inspection
KW  - wearable exoskeleton interface
KW  - aerial manipulator kinematics
KW  - aerial manipulator dynamics
KW  - Manipulator dynamics
KW  - Inspection
KW  - Robot sensing systems
KW  - Visualization
KW  - Exoskeletons
KW  - Cameras
DO  - 10.1109/IROS.2018.8593940
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.
ER  - 

TY  - CONF
TI  - Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6753
EP  - 6760
AU  - T. Baca
AU  - D. Hert
AU  - G. Loianno
AU  - M. Saska
AU  - V. Kumar
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - feedback
KW  - mobile robots
KW  - multi-robot systems
KW  - predictive control
KW  - state feedback
KW  - trajectory control
KW  - prediction horizon
KW  - decentralized collision avoidance system
KW  - fast nonlinear feedback
KW  - virtual UAV
KW  - translational dynamics
KW  - nonlinear state feedback
KW  - linear model predictive controller
KW  - optimal trajectory tracking
KW  - unmanned aerial vehicles
KW  - model predictive trajectory tracking
KW  - priority-based collision resolution strategy
KW  - tracking mechanism
KW  - in-advance collision-free planning
KW  - linear MPC
KW  - Trajectory
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Robot kinematics
KW  - Planning
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594266
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.
ER  - 

TY  - CONF
TI  - Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6769
EP  - 6775
AU  - D. Cellucci
AU  - N. Cramer
AU  - S. S. -. Swei
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - pressure control
KW  - pressure sensors
KW  - state estimation
KW  - wind tunnels
KW  - pressure sensors
KW  - NASA Langley Research Center
KW  - distributed algorithm
KW  - wind tunnel
KW  - commercial air transportation
KW  - self-aware autonomous aerial vehicles
KW  - lattice-based subcomponents
KW  - 14-foot wingspan
KW  - skin panels
KW  - flexible aerostructure
KW  - aerodynamic state estimation
KW  - modular distributed pressure sensing skin
KW  - autonomous systems
KW  - adaptable self-state estimation
KW  - robust self-state estimation
KW  - autonomous aerial transportation
KW  - pressure distribution
KW  - Robot sensing systems
KW  - Pressure sensors
KW  - Skin
KW  - Aerodynamics
KW  - NASA
DO  - 10.1109/IROS.2018.8593664
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.
ER  - 

TY  - CONF
TI  - Light-Weight Object Detection and Decision Making via Approximate Computing in Resource-Constrained Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6776
EP  - 6781
AU  - P. Pandey
AU  - Q. He
AU  - D. Pompili
AU  - R. Tron
PY  - 2018
KW  - decision making
KW  - Markov processes
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - light-weight object detection
KW  - approximate computing
KW  - resource-constrained mobile robots
KW  - autonomous flights
KW  - indoor environments
KW  - point clouds
KW  - computer vision algorithms
KW  - mobile autonomous platforms
KW  - video data
KW  - decision making
KW  - geometric maps
KW  - Markov decision process framework
KW  - Object detection
KW  - Proposals
KW  - Roads
KW  - Support vector machines
KW  - Computer vision
KW  - Cameras
DO  - 10.1109/IROS.2018.8594200
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most of the current solutions for autonomous flights in indoor environments rely on purely geometric maps (e.g., point clouds). There has been, however, a growing interest in supplementing such maps with semantic information (e.g., object detections) using computer vision algorithms. Unfortunately, there is a disconnect between the relatively heavy computational requirements of these computer vision solutions, and the limited computation capacity available on mobile autonomous platforms. In this paper, we propose to bridge this gap with a novel Markov Decision Process framework that adapts the parameters of the vision algorithms to the incoming video data rather than fixing them a priori. As a concrete example, we test our framework on a object detection and tracking task, showing significant benefits in terms of energy consumption without considerable loss in accuracy, using a combination of publicly available and novel datasets.
ER  - 

TY  - CONF
TI  - SOS: Stereo Matching in O(1) with Slanted Support Windows
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6782
EP  - 6789
AU  - V. Tankovich
AU  - M. Schoenberg
AU  - S. R. Fanello
AU  - A. Kowdle
AU  - C. Rhemann
AU  - M. Dzitsiuk
AU  - M. Schmidt
AU  - J. Valentin
AU  - S. Izadi
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image matching
KW  - image reconstruction
KW  - image texture
KW  - stereo image processing
KW  - stereo matching
KW  - slanted support windows
KW  - computer vision
KW  - triangulation-based depth cameras
KW  - structured light systems
KW  - active research topic
KW  - trade-off accuracy
KW  - fronto-parallel assumptions
KW  - search space
KW  - active stereo configuration
KW  - local methods
KW  - PatchMatch Stereo
KW  - computational cost
KW  - local smoothness
KW  - entire stereo pipeline
KW  - high quality depth maps
KW  - Microsoft Windows
KW  - Cameras
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Correlation
KW  - Image resolution
KW  - Optimization
DO  - 10.1109/IROS.2018.8593800
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Depth cameras have accelerated research in many areas of computer vision. Most triangulation-based depth cameras, whether structured light systems like the Kinect or active (assisted) stereo systems, are based on the principle of stereo matching. Depth from stereo is an active research topic dating back 30 years. Despite recent advances, algorithms usually trade-off accuracy for speed. In particular, efficient methods rely on fronto-parallel assumptions to reduce the search space and keep computation low. We present SOS (Slanted O(1) Stereo), the first algorithm capable of leveraging slanted support windows without sacrificing speed or accuracy. We use an active stereo configuration, where an illuminator textures the scene. Under this setting, local methods - such as PatchMatch Stereo - obtain state of the art results by jointly estimating disparities and slant, but at a large computational cost. We observe that these methods typically exploit local smoothness to simplify their initialization strategies. Our key insight is that local smoothness can in fact be used to amortize the computation not only within initialization, but across the entire stereo pipeline. Building on these insights, we propose a novel hierarchical initialization that is able to efficiently perform search over disparity and slants. We then show how this structure can be leveraged to provide high quality depth maps. Extensive quantitative evaluations demonstrate that the proposed technique yields significantly more precise results than current state of the art, but at a fraction of the computational cost. Our prototype implementation runs at 4000 fps on modern GPU architectures.
ER  - 

TY  - CONF
TI  - The RobotriX: An Extremely Photorealistic and Very-Large-Scale Indoor Dataset of Sequences with Robot Trajectories and Interactions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6790
EP  - 6797
AU  - A. Garcia-Garcia
AU  - P. Martinez-Gonzalez
AU  - S. Oprea
AU  - J. A. Castro-Vargas
AU  - S. Orts-Escolano
AU  - J. Garcia-Rodriguez
AU  - A. Jover-Alvarez
PY  - 2018
KW  - control engineering computing
KW  - image colour analysis
KW  - image resolution
KW  - learning (artificial intelligence)
KW  - rendering (computer graphics)
KW  - robot vision
KW  - trajectory control
KW  - virtual reality
KW  - RobotriX
KW  - extremely photorealistic indoor dataset
KW  - very-large-scale indoor dataset
KW  - robot trajectories
KW  - deep learning techniques
KW  - robotic vision problems
KW  - hyperrealistic indoor scenes
KW  - robot agents
KW  - Unreal Engine
KW  - virtual reality headset
KW  - robotic hands
KW  - ground truth labels
KW  - 3D robotic vision tasks
KW  - large-scale data-driven techniques
KW  - UnrealCV
KW  - full HD resolution
KW  - RGB-D
KW  - 2D robotic vision tasks
KW  - Robots
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Deep learning
KW  - Image resolution
KW  - Rendering (computer graphics)
KW  - Layout
DO  - 10.1109/IROS.2018.8594495
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Enter the RobotriX, an extremely photorealistic indoor dataset designed to enable the application of deep learning techniques to a wide variety of robotic vision problems. The RobotriX consists of hyperrealistic indoor scenes which are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline using UnrealCV to generate raw data and ground truth labels. By taking this approach, we were able to generate a dataset of 38 semantic classes across 512 sequences totaling 8M stills recorded at +60 frames per second with full HD resolution. For each frame, RGB-D and 3D information is provided with full annotations in both spaces. Thanks to the high quality and quantity of both raw information and annotations, the RobotriX will serve as a new milestone for investigating 2D and 3D robotic vision tasks with large-scale data-driven techniques.
ER  - 

TY  - CONF
TI  - Real-Time Object Pose Estimation with Pose Interpreter Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6798
EP  - 6805
AU  - J. Wu
AU  - B. Zhou
AU  - R. Russell
AU  - V. Kee
AU  - S. Wagner
AU  - M. Hebert
AU  - A. Torralba
AU  - D. M. S. Johnson
PY  - 2018
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image representation
KW  - image segmentation
KW  - object recognition
KW  - pose estimation
KW  - object pose estimation
KW  - CNN-based approaches
KW  - synthetic pose data
KW  - object masks
KW  - RGB images
KW  - 6-DoF object
KW  - pose interpreter network
KW  - Pose estimation
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Quaternions
KW  - Real-time systems
KW  - Training
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593662
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we introduce pose interpreter networks for 6-DoF object pose estimation. In contrast to other CNN-based approaches to pose estimation that require expensively annotated object pose data, our pose interpreter network is trained entirely on synthetic pose data. We use object masks as an intermediate representation to bridge real and synthetic. We show that when combined with a segmentation model trained on RGB images, our synthetically trained pose interpreter network is able to generalize to real data. Our end-to-end system for object pose estimation runs in real-time (20 Hz) on live RGB data, without using depth information or ICP refinement.
ER  - 

TY  - CONF
TI  - Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - S. Hamidreza Kasaei
AU  - L. Seabra Lopes
AU  - A. Maria Tomé
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - object category learning
KW  - learning recognition
KW  - evaluation approaches
KW  - recognition approaches
KW  - multicontext scenarios
KW  - recognition methods
KW  - unconstrained human environments
KW  - autonomous robots
KW  - object categories
KW  - human-centric environment
KW  - explicit context information
KW  - open-ended object recognition
KW  - context change
KW  - Robots
KW  - Visualization
KW  - Protocols
KW  - Histograms
KW  - Context modeling
KW  - Three-dimensional displays
KW  - Training
DO  - 10.1109/IROS.2018.8593922
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.
ER  - 

TY  - CONF
TI  - Fast Cylinder and Plane Extraction from Depth Cameras for Visual Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6813
EP  - 6820
AU  - P. F. Proença
AU  - Y. Gao
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - pose estimation
KW  - cylinder and plane extraction
KW  - pose optimization residuals
KW  - probabilistic RGB-D odometry framework
KW  - curve-aware deteriorates performance
KW  - plane extraction approach
KW  - single CPU core
KW  - organized point clouds
KW  - cylinder segments
KW  - CAPE
KW  - visual odometry
KW  - Histograms
KW  - Eigenvalues and eigenfunctions
KW  - Cameras
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Probabilistic logic
KW  - Principal component analysis
DO  - 10.1109/IROS.2018.8593516
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents CAPE, a method to extract planes and cylinder segments from organized point clouds, which processes 640 × 480 depth images on a single CPU core at an average of 300 Hz, by operating on a grid of planar cells. While, compared to state-of-the-art plane extraction, the latency of CAPE is more consistent and 4-10 times faster, depending on the scene, we also demonstrate empirically that applying CAPE to visual odometry can improve trajectory estimation on scenes made of cylindrical surfaces (e.g. tunnels), whereas using a plane extraction approach that is not curve-aware deteriorates performance on these scenes. To use these geometric primitives in visual odometry, we propose extending a probabilistic RGB-D odometry framework based on points, lines and planes to cylinder primitives. Following this framework, CAPE runs on fused depth maps and the parameters of cylinders are modelled probabilistically to account for uncertainty and weight accordingly the pose optimization residuals.
ER  - 

TY  - CONF
TI  - Attention-Aware Cross-Modal Cross-Level Fusion Network for RGB-D Salient Object Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6821
EP  - 6826
AU  - H. Chen
AU  - Y. Li
AU  - D. Su
PY  - 2018
KW  - convolutional neural nets
KW  - feature extraction
KW  - image colour analysis
KW  - image fusion
KW  - object detection
KW  - geometric saliency cues
KW  - selection module
KW  - public datasets
KW  - attention-aware cross-modal cross-level fusion block
KW  - RGB-D fusion network
KW  - informative cross-modal cross-level combination
KW  - multimodal fusion stage
KW  - depth features/decisions
KW  - depth information
KW  - RGB-D sensors
KW  - convolutional neural networks
KW  - RGB-D salient object detection
KW  - attention-aware cross-modal cross-level fusion network
KW  - Object detection
KW  - Feature extraction
KW  - Fuses
KW  - Task analysis
KW  - Computer architecture
KW  - Visualization
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594373
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Convolutional neural networks have achieved wide success in RGB saliency detection. Recently, the advent of RGB-D sensors such as Kinect provide additional geometric saliency cues. However, the key challenge for RGB-D salient object detection that how to fuse RGB and depth information sufficiently is still under-studied. Traditional works mainly follow the two-stream architecture and combine RGB and depth features/decisions in an early or late point. The multi-modal fusion stage is performed by directly concatenating the features from two modalities without selection. In this work, we address this question by proposing a novel network with a distinguished insight: A selection module is significantly helpful for more informative and sufficient cross-modal cross-level combination. To this end, we introduce a top-down RGB-D fusion network which integrates an attention-aware cross-modal cross-level fusion block in each level to select discriminative features from each level and each modality. Extensive experiments on public datasets show that the proposed network is able to solve the key problems in RGB-D fusion and achieves state-of-the-art performance on RGB-D salient object detection.
ER  - 

TY  - CONF
TI  - Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6827
EP  - 6834
AU  - L. Meng
AU  - F. Tung
AU  - J. J. Little
AU  - J. Valentin
AU  - C. W. de Silva
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - image texture
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - pose estimation
KW  - regression analysis
KW  - virtual reality
KW  - RGB-D
KW  - computer vision applications
KW  - self-driving cars
KW  - virtual reality
KW  - recent random forests
KW  - pixel comparison features
KW  - 3D world locations
KW  - 2D image locations
KW  - point features
KW  - geometric information
KW  - motion blur
KW  - line segments
KW  - uncertainty driven regression forests
KW  - Cameras
KW  - Forestry
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Training
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593505
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Camera relocalization plays a vital role in many robotics and computer vision applications, such as self-driving cars and virtual reality. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these point features are only sampled randomly in images, without considering geometric information such as lines, leading to large errors with the existence of poorly textured areas or in motion blur. Line segments are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.
ER  - 

TY  - CONF
TI  - Incremental Object Database: Building 3D Models from Multiple Partial Observations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6835
EP  - 6842
AU  - F. Furrer
AU  - T. Novkovic
AU  - M. Fehr
AU  - A. Gawel
AU  - M. Grinvald
AU  - T. Sattler
AU  - R. Siegwart
AU  - J. Nieto
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - mobile agents
KW  - object detection
KW  - solid modelling
KW  - multiple partial observations
KW  - incremental object database
KW  - indoor scenes
KW  - merged models
KW  - object model
KW  - observed instances
KW  - segmented RGB-D images
KW  - global segmentation map
KW  - 3D models
KW  - mobile agent
KW  - Image segmentation
KW  - Databases
KW  - Three-dimensional displays
KW  - GSM
KW  - Shape
KW  - Image reconstruction
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594391
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Collecting 3D object data sets involves a large amount of manual work and is time consuming. Getting complete models of objects either requires a 3D scanner that covers all the surfaces of an object or one needs to rotate it to completely observe it. We present a system that incrementally builds a database of objects as a mobile agent traverses a scene. Our approach requires no prior knowledge of the shapes present in the scene. Object-like segments are extracted from a global segmentation map, which is built online using the input of segmented RGB-D images. These segments are stored in a database, matched among each other, and merged with other previously observed instances. This allows us to create and improve object models on the fly and to use these merged models to reconstruct also unobserved parts of the scene. The database contains each (potentially merged) object model only once, together with a set of poses where it was observed. We evaluate our pipeline with one public dataset, and on a newly created Google Tango dataset containing four indoor scenes with some of the objects appearing multiple times, both within and across scenes.
ER  - 

TY  - CONF
TI  - Hybrid Bayesian Eigenobjects: Combining Linear Subspace and Deep Network Methods for 3D Robot Vision
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6843
EP  - 6850
AU  - B. Burchfiel
AU  - G. Konidaris
PY  - 2018
KW  - Bayes methods
KW  - eigenvalues and eigenfunctions
KW  - image representation
KW  - neural nets
KW  - regression analysis
KW  - robot vision
KW  - stereo image processing
KW  - linear subspace methods
KW  - deep convolutional prediction
KW  - nonlinear object representations
KW  - Hybrid Bayesian Eigenobjects
KW  - deep network methods
KW  - 3D robot vision
KW  - HBEO
KW  - 3D geometry
KW  - Three-dimensional displays
KW  - Robots
KW  - Bayes methods
KW  - Pose estimation
KW  - Databases
KW  - Principal component analysis
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593795
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We introduce Hybrid Bayesian Eigenobjects (HBEOs), a novel representation for 3D objects designed to allow a robot to jointly estimate the pose, class, and full 3D geometry of a novel object observed from a single viewpoint in a single practical framework. By combining both linear subspace methods and deep convolutional prediction, HBEOs efficiently learn nonlinear object representations without directly regressing into high-dimensional space. HBEOs also remove the onerous and generally impractical necessity of input data voxelization prior to inference. We experimentally evaluate the suitability of HBEOs to the challenging task of joint pose, class, and shape inference on novel objects and show that, compared to preceding work, HBEOs offer dramatically improved performance in all three tasks along with several orders of magnitude faster runtime performance.
ER  - 

TY  - CONF
TI  - Submap-Based Pose-Graph Visual SLAM: A Robust Visual Exploration and Localization System* The work in this paper is supported by the National Natural Science Foundation of China (61603103, 61673125), the Natural Science Foundation of Guangdong of China (2016A030310293), and the Major Scientific and Technological Special Project of Guangdong of China (2016B090910003).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6851
EP  - 6856
AU  - W. Chen
AU  - L. Zhu
AU  - Y. Guan
AU  - C. R. Kube
AU  - H. Zhang
PY  - 2018
KW  - graph theory
KW  - mean square error methods
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - VSLAM algorithms
KW  - robust visual exploration
KW  - visual simultaneous localization and mapping
KW  - submap-based pose-graph visual SLAM
KW  - robust exploration
KW  - visual front-end
KW  - submap-based VSLAM system
KW  - Image edge detection
KW  - Optimization
KW  - Robustness
KW  - Visualization
KW  - Merging
KW  - Robots
KW  - Tracking
KW  - Monocular VSLAM
KW  - Submap-based Backend
KW  - Robustness
DO  - 10.1109/IROS.2018.8594097
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For VSLAM (Visual Simultaneous Localization and Mapping), localization is a challenging task, especially for some challenging situations: textureless frames, motion blur, etc. To build a robust exploration and localization system in a given space, a submap-based VSLAM system is proposed in this paper. Our system uses a submap back-end and a visual front-end. The main advantage of our system is its robustness with respect to tracking failure, a common problem in current VSLAM algorithms. The robustness of our system is compared with the state-of-the-art in terms of average tracking percentage. The precision of our system is also evaluated in terms of ATE (absolute trajectory error) RMSE (root mean square error) comparing the state-of-the-art. The ability of our system in solving the “kidnapped” problem is demonstrated. Our system can improve the robustness of visual localization in challenging situations.
ER  - 

TY  - CONF
TI  - Active Object Perceiver: Recognition-Guided Policy Learning for Object Searching on Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6857
EP  - 6863
AU  - X. Ye
AU  - Z. Lin
AU  - H. Li
AU  - S. Zheng
AU  - Y. Yang
PY  - 2018
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - robot vision
KW  - AI2-THOR dataset
KW  - action prediction mechanism
KW  - deep reinforcement learning
KW  - visual navigation
KW  - indoor environment
KW  - mobile robots
KW  - recognition-guided policy learning
KW  - active object perceiver
KW  - object searching task
KW  - physical robot
KW  - object recognition module
KW  - deep neural network
KW  - Robots
KW  - Task analysis
KW  - Object recognition
KW  - Navigation
KW  - Search problems
KW  - Visualization
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593720
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR)and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.
ER  - 

TY  - CONF
TI  - Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6864
EP  - 6871
AU  - C. Zhao
AU  - L. Sun
AU  - P. Purkait
AU  - T. Duckett
AU  - R. Stolkin
PY  - 2018
KW  - distance measurement
KW  - Gaussian processes
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion estimation
KW  - neural nets
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - learning monocular visual odometry
KW  - monocular SLAM
KW  - simultaneous localization
KW  - neural network
KW  - dual-stream L-VO network
KW  - 6DOF relative pose
KW  - bivariate Gaussian modeling
KW  - KITTI odometry
KW  - visual SLAM system
KW  - dense 2D flow
KW  - fully deep learning approach
KW  - dense 3D flow
KW  - dense 3D mapping
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Visual odometry
KW  - Two dimensional displays
KW  - Deep learning
KW  - Cameras
KW  - Training
DO  - 10.1109/IROS.2018.8594151
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 % for average translational error and 0.0143°/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.
ER  - 

TY  - CONF
TI  - Key-Frame Strategy During Fast Image-Scale Changes and Zero Motion in VIO Without Persistent Features
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6872
EP  - 6879
AU  - E. Allak
AU  - A. Hardt-Stremayr
AU  - S. Weiss
PY  - 2018
KW  - computational complexity
KW  - distance measurement
KW  - feature extraction
KW  - image sequences
KW  - inertial navigation
KW  - Kalman filters
KW  - motion estimation
KW  - robot vision
KW  - video signal processing
KW  - common special motion
KW  - feature displacement
KW  - fast motion
KW  - zero motion phases
KW  - frame selection approach
KW  - motion scenarios
KW  - motion case identification
KW  - subsequent case-specific heuristics
KW  - state vectoraltogether
KW  - persistent features
KW  - VIO algorithm
KW  - motion spectrum
KW  - fast scale change
KW  - frame strategy
KW  - fast image-scale changes
KW  - regular motion
KW  - special treatment
KW  - bad data
KW  - corrupted data
KW  - clean data
KW  - visual-inertial odometry frameworks
KW  - Computational complexity
KW  - Cameras
KW  - Computed tomography
KW  - Feature extraction
KW  - Kalman filters
KW  - Quaternions
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594170
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many of today's Visual-Inertial Odometry (VIO) frameworks work well under regular motion but have issues and need special treatment under special motion. Here, special does not imply bad or corrupted data but stands for increased difficulty to treat clean data. Common special motion for VIO are large feature displacement due to fast motion close to a scene and zero motion phases not providing sufficient baseline. In this paper we present a feature and frame selection approach which seamlessly handles all motion scenarios without the need of (error prone) motion case identification and subsequent case-specific heuristics. We further show that this approach allows to eliminate features in the state vector (persistent features)altogether while still being able to inherently handle zero motion phases. This reduces computational complexity while maintaining the ability to hover in place. We integrate our frame selection approach into our own VIO algorithm and compare its performance against three state-of-the-art algorithms with real data on a real platform. While our approach shows slightly higher global drift it is the only algorithm that can reliably estimate the pose over a large motion spectrum from fast scale change down to zero motion.
ER  - 

TY  - CONF
TI  - Unit Quaternion-Based Parameterization for Point Features in Visual Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6880
EP  - 6886
AU  - J. Maley
AU  - G. Huang
PY  - 2018
KW  - covariance matrices
KW  - geometry
KW  - image representation
KW  - recursive estimation
KW  - SLAM (robots)
KW  - point features
KW  - visual navigation
KW  - Cartesian 3D representation
KW  - homogeneous points
KW  - error state
KW  - unit-quaternion error covariance
KW  - initial feature observations
KW  - initial error-states
KW  - unit quaternion-based representation
KW  - unit quaternion-based parameterization
KW  - initial infinite depth uncertainty
KW  - Quaternions
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Navigation
KW  - Convergence
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594206
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose to use unit quaternions to represent point features in visual navigation. Contrary to the Cartesian 3D representation, the unit quaternion can well represent features at both large and small distances from the camera without suffering from convergence problems. Contrary to inverse-depth, homogeneous points, or anchored homogeneous points, the unit quaternion has error state of minimum dimension of three. In contrast to prior representations, the proposed method does not need to approximate an initial infinite depth uncertainty. In fact, the unit-quaternion error covariance can be initialized from the initial feature observations without prior information, and the initial error-states are not only bounded, but the bound is identical for all scene geometries. To the best of our knowledge, this is the first time bearing-only recursive estimation (in covariance form) of point features has been possible without using measurements to initialize error covariance. The proposed unit quaternion-based representation is validated on numerical examples.
ER  - 

TY  - CONF
TI  - Edge-Based Robust RGB-D Visual Odometry Using 2-D Edge Divergence Minimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Kim
AU  - P. Kim
AU  - S. Lee
AU  - H. J. Kim
PY  - 2018
KW  - edge detection
KW  - gradient methods
KW  - image colour analysis
KW  - image matching
KW  - image registration
KW  - image sequences
KW  - image texture
KW  - least squares approximations
KW  - minimisation
KW  - motion estimation
KW  - motion estimation
KW  - ICP-based optimization
KW  - edge matching criterion
KW  - edge registration problem
KW  - iterative re-weight least squares
KW  - IRLS
KW  - sub-sampling method
KW  - image sequences
KW  - VO algorithm
KW  - iterative closest points framework
KW  - image gradient vectors
KW  - image edge regions
KW  - edge-based robust RGB-D visual odometry
KW  - 2-D edge divergence minimization
KW  - Image edge detection
KW  - Cameras
KW  - Brightness
KW  - Motion estimation
KW  - Minimization
KW  - Visual odometry
KW  - Lighting
DO  - 10.1109/IROS.2018.8593594
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an edge-based robust RGB-D visual odometry (VO) using 2-D edge divergence minimization. Our approach focuses on enabling the VO to operate in more general environments subject to low texture and changing brightness, by employing image edge regions and their image gradient vectors within the iterative closest points (ICP) framework. For more robust and stable ICP-based optimization, we propose a robust edge matching criterion with image gradient vectors. In addition, to reduce a bad effect of outlier residuals, we propose an improved edge registration problem of 2-D edge divergence minimization in the manner of an iterative re-weight least squares (IRLS) motion estimation. To accelerate the proposed approach, a pixel sub-sampling method is employed. We evaluate estimation performance of our method in changing brightness conditions and low-textured scenes. Our approach shows more robust motion estimation than state-of-the-art methods while maintaining comparable accuracy in challenging image sequences at real-time (25 Hz) operation.
ER  - 

TY  - CONF
TI  - Event-Based Moving Object Detection and Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Mitrokhin
AU  - C. Fermüller
AU  - C. Parameshwara
AU  - Y. Aloimonos
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image sensors
KW  - image sequences
KW  - motion compensation
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - dynamic component
KW  - temporal model inconsistencies
KW  - independent motion detection
KW  - feature tracking
KW  - motion-compensate
KW  - event stream representation
KW  - asynchronous cameras
KW  - asynchronous event stream
KW  - extremely low resolution
KW  - modern event-based vision sensors
KW  - high temporal resolution
KW  - real-time motion analysis
KW  - Dynamic Vision Sensor
KW  - object detection
KW  - Tracking
KW  - Three-dimensional displays
KW  - Cameras
KW  - Optical imaging
KW  - Motion compensation
KW  - Voltage control
KW  - Sensors
DO  - 10.1109/IROS.2018.8593805
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Event-based vision sensors, such as the Dynamic Vision Sensor (DVS), are ideally suited for real-time motion analysis. The unique properties encompassed in the readings of such sensors provide high temporal resolution, superior sensitivity to light and low latency. These properties provide the grounds to estimate motion efficiently and reliably in the most sophisticated scenarios, but these advantages come at a price - modern event-based vision sensors have extremely low resolution, produce a lot of noise and require the development of novel algorithms to handle the asynchronous event stream. This paper presents a new, efficient approach to object tracking with asynchronous cameras. We present a novel event stream representation which enables us to utilize information about the dynamic (temporal)component of the event stream. The 3D geometry of the event stream is approximated with a parametric model to motion-compensate for the camera (without feature tracking or explicit optical flow computation), and then moving objects that don't conform to the model are detected in an iterative process. We demonstrate our framework on the task of independent motion detection and tracking, where we use the temporal model inconsistencies to locate differently moving objects in challenging situations of very fast motion.
ER  - 

TY  - CONF
TI  - A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Giftthaler
AU  - M. Neunert
AU  - M. Stäuble
AU  - J. Buchli
AU  - M. Diehl
PY  - 2018
KW  - closed loop systems
KW  - computational complexity
KW  - iterative methods
KW  - linear quadratic control
KW  - nonlinear control systems
KW  - predictive control
KW  - iterative algorithms
KW  - unconstrained nonlinear optimal control
KW  - iLQR algorithm
KW  - closed-loop forward integration
KW  - linear complexity
KW  - multiple shooting algorithms
KW  - nonlinear model predictive control applications
KW  - computational complexity
KW  - high-dimensional underactuated robot
KW  - iterative Gauss-Newton shooting methods
KW  - Optimal control
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Prediction algorithms
KW  - Robots
KW  - System dynamics
KW  - Convergence
KW  - Numerical Optimal Control
KW  - Trajectory Optimization
KW  - Multiple Shooting
KW  - Quadrupedal Robots
KW  - Nonlinear Model Predictive Control
KW  - Differential Dynamic Programming
DO  - 10.1109/IROS.2018.8593840
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.
ER  - 

TY  - CONF
TI  - Controller Synthesis for Discrete-Time Polynomial Systems via Occupation Measures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6911
EP  - 6918
AU  - W. Han
AU  - R. Tedrake
PY  - 2018
KW  - computational complexity
KW  - control system synthesis
KW  - convex programming
KW  - discrete time systems
KW  - linear programming
KW  - Liouville equation
KW  - multidimensional systems
KW  - nonlinear control systems
KW  - reachability analysis
KW  - set theory
KW  - stability
KW  - state feedback
KW  - discrete-time polynomial systems
KW  - occupation measures
KW  - discrete-time polynomial dynamical systems
KW  - occupation measure approach
KW  - discrete-time controlled Liouville equation
KW  - controller synthesis problem
KW  - infinite-dimensional linear programming problem
KW  - finite-dimensional semidefinite programming problems
KW  - sums-of-squares polynomials
KW  - nonlinear controllers
KW  - relaxed problems
KW  - convex problems
KW  - discrete-time autonomous polynomial systems
KW  - controllable set
KW  - nonlinear state feedback controllers
KW  - state feedback control laws
KW  - controller design
KW  - computational complexity
KW  - backward reachable set
KW  - Volume measurement
KW  - Trajectory
KW  - State feedback
KW  - Mathematical model
KW  - Topology
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594400
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we design nonlinear state feedback controllers for discrete-time polynomial dynamical systems via the occupation measure approach. We propose the discrete-time controlled Liouville equation, and use it to formulate the controller synthesis problem as an infinite-dimensional linear programming problem on measures, which is then relaxed as finite-dimensional semidefinite programming problems on moments of measures and their duals on sums-of-squares polynomials. Nonlinear controllers can be extracted from the solutions to the relaxed problems. The advantage of the occupation measure approach is that we solve convex problems instead of generally non-convex problems, and the computational complexity is polynomial in the state and input dimensions, and hence the approach is more scalable. In addition, we show that the approach can be applied to over-approximating the backward reachable set of discrete-time autonomous polynomial systems and the controllable set of discrete-time polynomial systems under known state feedback control laws. We illustrate our approach on several dynamical systems.
ER  - 

TY  - CONF
TI  - Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6919
EP  - 6925
AU  - O. Ogunmolu
AU  - N. Gans
AU  - T. Summers
PY  - 2018
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - minimax techniques
KW  - mobile robots
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - model mismatch
KW  - model uncertainties
KW  - high-risk scenarios
KW  - robustness capacity
KW  - minimax iterative dynamic game
KW  - robust policies
KW  - carefully designed deep neural network policy
KW  - policy robustness
KW  - adversarial disturbances
KW  - ocally robust optimal multistage policy
KW  - nonlinear robot control tasks
KW  - multistage decision policies
KW  - high-dimensional state spaces
KW  - complex control tasks
KW  - meta-learning-deep policies
KW  - Robustness
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Games
KW  - Task analysis
KW  - Uncertainty
KW  - Approximation algorithms
DO  - 10.1109/IROS.2018.8594037
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.
ER  - 

TY  - CONF
TI  - Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - H. Kim
AU  - J. Kwon
AU  - Y. Oh
AU  - B. J. You
AU  - W. Yang
PY  - 2018
KW  - biomechanics
KW  - control engineering computing
KW  - elastic constants
KW  - haptic interfaces
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - vibrations
KW  - human intention based stiffness estimation
KW  - HRI device
KW  - frequency analysis
KW  - input response simulation
KW  - vibration magnitude
KW  - virtual wall collision
KW  - control distribution ratios
KW  - physical collaboration operations
KW  - human-robot interaction device
KW  - weighted hybrid admittance-impedance control
KW  - Impedance
KW  - Admittance
KW  - Force
KW  - Manipulators
KW  - Stability analysis
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594435
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.
ER  - 

TY  - CONF
TI  - Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6932
EP  - 6937
AU  - K. Haninger
AU  - D. Surdilovic
PY  - 2018
KW  - end effectors
KW  - fault diagnosis
KW  - fault tolerant control
KW  - force control
KW  - industrial manipulators
KW  - robotic assembly
KW  - trajectory control
KW  - multimodal environment dynamics
KW  - interactive robots
KW  - environmental uncertainty
KW  - contact force
KW  - subtask completion
KW  - task monitoring approach
KW  - complex assembly tasks
KW  - discrete environment dynamic modes
KW  - semistructured environments
KW  - interactive tasks
KW  - impedance control
KW  - admittance controlled robots
KW  - force/position measurements
KW  - admittance controlled robot
KW  - gear assembly task
KW  - fault detection
KW  - force trajectories
KW  - position trajectories
KW  - end-effector physical compliance
KW  - Dynamics
KW  - Task analysis
KW  - Force
KW  - Robot sensing systems
KW  - Admittance
KW  - Estimation
DO  - 10.1109/IROS.2018.8593650
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.
ER  - 

TY  - CONF
TI  - Estimating an Articulated Tool's Kinematics via Visuo-Tactile Based Robotic Interactive Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6938
EP  - 6944
AU  - Q. Li
AU  - A. Ückermann
AU  - R. Haschke
AU  - H. Ritter
PY  - 2018
KW  - dexterous manipulators
KW  - feedback
KW  - haptic interfaces
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - sensor fusion
KW  - tactile sensors
KW  - visuo-tactile based robotic interactive manipulation
KW  - autonomous robots
KW  - single passive observation
KW  - articulated toy
KW  - dual arm robotic setup
KW  - tactile finger
KW  - visuo-tactile servoing controller
KW  - flipping task
KW  - tactile feedback
KW  - compact control loop
KW  - kinematic parameters
KW  - vision feedback
KW  - articulated tools kinematics
KW  - data fusion method
KW  - fingertips motion trajectory
KW  - Tools
KW  - Robot kinematics
KW  - Kinematics
KW  - Task analysis
KW  - End effectors
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594295
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The usage of articulated tools for autonomous robots is still a challenging task. One of the difficulties is to automatically estimate the tool's kinematics model. This model cannot be obtained from a single passive observation, because some information, such as a rotation axis (hinge), can only be detected when the tool is being used. Inspired by a baby using its hands while playing with an articulated toy, we employ a dual arm robotic setup and propose an interactive manipulation strategy based on visual-tactile servoing to estimate the tool's kinematics model. In our proposed method, one hand is holding the tool's handle stably, and the other arm equipped with tactile finger flips the movable part of the articulated tool. An innovative visuo-tactile servoing controller is introduced to implement the flipping task by integrating the vision and tactile feedback in a compact control loop. In order to deal with the temporary invisibility of the movable part in camera, a data fusion method which integrates the visual measurement of the movable part and the fingertip's motion trajectory is used to optimally estimate the orientation of the tool's movable part. The important tool's kinematic parameters are estimated by geometric calculations while the movable part is flipped by the finger. We evaluate our method by flipping a pivoting cleaning head (flap) of a wiper and estimating the wiper's kinematic parameters. We demonstrate that the flap of the wiper is flipped robustly, even the flap is shortly invisible. The orientation of the flap is tracked well compared to the ground truth data. The kinematic parameters of the wiper are estimated correctly.
ER  - 

TY  - CONF
TI  - Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6945
EP  - 6951
AU  - T. Gawron
AU  - M. M. Michalek
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - motion control
KW  - robust control
KW  - input constraints
KW  - control input signals
KW  - admissible funnels
KW  - planning process
KW  - constrained motion
KW  - car-like robots
KW  - VFO control strategy
KW  - parallelized planning
KW  - car-like kinematics
KW  - mobile robotics
KW  - intelligent vehicles
KW  - feedback control algorithms
KW  - motion execution
KW  - VFO control law
KW  - state constraints
KW  - motion planning algorithms
KW  - robot actuation
KW  - open loop control signals
KW  - parallelized deterministic sampling-based algorithm
KW  - vector field orientation
KW  - steering dynamics
KW  - modeling uncertainties
KW  - Robots
KW  - Planning
KW  - Kinematics
KW  - Electron tubes
KW  - Vehicle dynamics
KW  - Uncertainty
KW  - Feedback control
DO  - 10.1109/IROS.2018.8594402
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.
ER  - 

TY  - CONF
TI  - ASPiC: An Acting System Based on Skill Petri Net Composition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6952
EP  - 6958
AU  - C. Lesire
AU  - F. Pommereau
PY  - 2018
KW  - path planning
KW  - Petri nets
KW  - robots
KW  - ASPiC
KW  - acting system
KW  - skill Petri net composition
KW  - high-level action
KW  - executable commands
KW  - autonomous robots
KW  - formal model
KW  - robot skills
KW  - control-flow Petri net model
KW  - autonomous surface vehicle
KW  - area protection mission
KW  - Petri nets
KW  - Robots
KW  - Analytical models
KW  - Adaptation models
KW  - Tools
KW  - Planning
KW  - Inductors
DO  - 10.1109/IROS.2018.8594328
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.
ER  - 

TY  - CONF
TI  - Static Kinematics for an Antagonistically Actuated Robot Based on a Beam-Mechanics-Based Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6959
EP  - 6964
AU  - A. Stilli
AU  - E. Kolokotronis
AU  - J. Fraś
AU  - A. Ataka
AU  - K. Althoefer
AU  - H. A. Wurdemann
PY  - 2018
KW  - manipulator kinematics
KW  - pneumatic actuators
KW  - static kinematics
KW  - beam-mechanics-based model
KW  - soft robotic structures
KW  - industrial revolution
KW  - soft robotics
KW  - traditional robots
KW  - rigid links
KW  - joints
KW  - soft robots
KW  - stiffness mechanism embodies
KW  - pneumatic air actuation
KW  - variable stiffness values
KW  - soft stiffness controllable robot
KW  - mathematical model
KW  - stiffness levels
KW  - soft robotic manipulator
KW  - interaction forces
KW  - analytical model
KW  - robotic actuation system
KW  - actuated robot
KW  - Manipulators
KW  - Tendons
KW  - Force
KW  - Soft robotics
KW  - Mathematical model
KW  - Service robots
DO  - 10.1109/IROS.2018.8593674
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft robotic structures might play a major role in the 4th industrial revolution. Researchers have successfully demonstrated advantages of soft robotics over traditional robots made of rigid links and joints in several application areas including manufacturing, healthcare and surgical interventions. However, soft robots have limited ability to exert higher forces when it comes to interaction with the environment, hence, change their stiffness on demand over a wide range. One stiffness mechanism embodies tendon-driven and pneumatic air actuation in an antagonistic way achieving variable stiffness values. In this paper, we apply a beam-mechanics-based model to this type of soft stiffness controllable robot. This mathematical model takes into account the various stiffness levels of the soft robotic manipulator as well as interaction forces with the environment at the tip of the manipulator. The analytical model is implemented into a robotic actuation system made of motorised linear rails with load cells (obtaining applied forces to the tendons) and a pressure regulator. Here, we present and analyse the performance and limitations of our model.
ER  - 

TY  - CONF
TI  - A Novel Soft Elbow Exosuit to Supplement Bicep Lifting Capacity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6965
EP  - 6971
AU  - C. M. Thalman
AU  - Q. P. Lam
AU  - P. H. Nguyen
AU  - S. Sridar
AU  - P. Polygerinos
PY  - 2018
KW  - bending
KW  - biomechanics
KW  - electromyography
KW  - medical robotics
KW  - pneumatic actuators
KW  - torque
KW  - measurable assistance
KW  - bicep lifting capacity
KW  - supplemental lifting assistance
KW  - muscle activity
KW  - bicep muscle
KW  - repetitive lifting
KW  - pneumatically pressurized soft actuators
KW  - high force-to-weight ratio
KW  - analytical model
KW  - bending behavior
KW  - consecutive actuators
KW  - theoretical model
KW  - elbow joint torque value
KW  - surface electromyography sensors
KW  - active assistance
KW  - soft elbow exosuit
KW  - nylon fabrics
KW  - motion capture system
KW  - concentric contractions
KW  - isometric contractions
KW  - pressure 300.0 kPa
KW  - SN
KW  - Actuators
KW  - Elbow
KW  - Torque
KW  - Shape
KW  - Force
KW  - Injuries
KW  - Muscles
DO  - 10.1109/IROS.2018.8594403
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates the design of a soft elbow exosuit capable of providing supplemental lifting assistance by reducing muscle activity of the bicep muscle. The aim is to improve the efficiency and endurance of workers who are tasked with repetitive lifting. The design consists of an array of pneumatically pressurized soft actuators, which are encased in nylon fabric that allows for a high force-to-weight ratio of 211.SN/g. An analytical model governing the bending behavior of two consecutive actuators and torque generated by the exosuit is developed, with test results showing less than 10% error from the theoretical model. An elbow joint torque value of 27.6N.m is achieved at 300kPa, which is comparable to the 30N.m maximum set by OSHA requirements in the USA. Further testing with a healthy participant is performed using surface electromyography (sEMG) sensors and a motion capture system to assess the capabilities of the exosuit to provide active assistance to the bicep during isometric and concentric contractions. Measurable assistance to lifting is observed with minimal obstruction to the user's range of motion for all experiments.
ER  - 

TY  - CONF
TI  - Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6972
EP  - 6979
AU  - E. Misimi
AU  - A. Olofsson
AU  - A. Eilertsen
AU  - E. R. Øye
AU  - J. R. Mathiassen
PY  - 2018
KW  - grippers
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - solid modelling
KW  - complex processing tasks
KW  - current robot learning policies
KW  - consistent learning policy
KW  - skilled operators
KW  - robotic automation
KW  - variable outcomes
KW  - tedious nature
KW  - laborious nature
KW  - human operators
KW  - food industries
KW  - ocean space
KW  - huge demand
KW  - mechanical structures
KW  - complex geometrical 3D shapes
KW  - high biological variation
KW  - deformable food raw materials
KW  - compliant food raw materials
KW  - robotic handling
KW  - complex 3D shapes
KW  - compliant food objects
KW  - inconsistent demonstrations
KW  - LfD learning policy
KW  - effective robot handling
KW  - gripper finger configuration
KW  - RGB-D images
KW  - food compliant objects
KW  - robotic grasping
KW  - robust learning policy
KW  - Grasping
KW  - Visualization
KW  - Service robots
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Compliant food objects
KW  - Learning from Demonstration
KW  - Robotic handling
KW  - Multifingered gripper
DO  - 10.1109/IROS.2018.8594368
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.
ER  - 

TY  - CONF
TI  - Closed-Loop Temperature Control of Nylon Artificial Muscles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6980
EP  - 6985
AU  - C. S. Haines
AU  - G. Niemeyer
PY  - 2018
KW  - closed loop systems
KW  - coils
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - polymer fibres
KW  - temperature control
KW  - temperature measurement
KW  - temperature measurement
KW  - electrothermal heating
KW  - muscle temperature monitoring
KW  - overheat protection
KW  - nested controller
KW  - wire resistance
KW  - metal wire
KW  - coiled polymer fibers
KW  - coiled actuators
KW  - nylon artificial muscles
KW  - closed-loop temperature control
KW  - Muscles
KW  - Temperature measurement
KW  - Wires
KW  - Force
KW  - Heating systems
KW  - Resistance
DO  - 10.1109/IROS.2018.8593599
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Coiled actuators made from polymer fibers are fast becoming popular due to their low-cost and ease of fabrication. Unfortunately, reliable real-time temperature measurement has been frustrated by the small fiber diameter of typical actuators. By using coiled polymer fibers wrapped with a metal wire, we demonstrate the ability to concurrently drive a muscle by electrothermal heating, and monitor muscle temperature through the wire resistance. This simple method enables convenient overheat protection for these muscles, as well as the possibility for closed-loop temperature control. Using this platform, we demonstrate a nested controller using temperature and position feedback to improve contraction speed, and investigate the cooling rates of various configurations that increase total force output.
ER  - 

TY  - CONF
TI  - Acoustic Sensing for Soft Pneumatic Actuators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6986
EP  - 6991
AU  - G. Zöller
AU  - V. Wall
AU  - O. Brock
PY  - 2018
KW  - microphones
KW  - pneumatic actuators
KW  - sensors
KW  - microphone-based sensor solution
KW  - PneuFlex actuator
KW  - soft pneumatic actuators
KW  - acoustic sensing
KW  - contacted material
KW  - sensing method
KW  - sound signature
KW  - contact locations
KW  - contact force
KW  - Robot sensing systems
KW  - Microphones
KW  - Pneumatic actuators
KW  - Force
DO  - 10.1109/IROS.2018.8594396
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel sensing method for soft pneumatic actuators. The method uses a single microphone, embedded into the actuator's air chamber. Contact with the environment induces sound (vibration) in the actuator. The materials and the shape of the actuator reflect, refract, and attenuate the sound as it propagates inside the actuator. This produces a unique sound signature for different types of events, enabling the sensing of contact locations, contact force, and the type of contacted material. Sensing is insensitive to the inflation state of the actuator and to background noise. We demonstrate the robustness and versatility of the microphone-based sensor solution in experiments with a PneuFlex actuator. The proposed sensorization avoids the fundamental challenges of sensorizing soft pneumatic actuators, because the placement of a microphone does not negatively affect the compliance of the actuator and because a single microphone suffices for sensorization of the entire actuator, eliminating the need for an application-specific sensor layout.
ER  - 

TY  - CONF
TI  - Flexible Fabric Actuator Realizing 3D Movements Like Human Body Surface for Wearable Devices
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6992
EP  - 6997
AU  - Y. Funabora
PY  - 2018
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - muscle
KW  - pneumatic actuators
KW  - wearable computers
KW  - wearable devices
KW  - continuous control system
KW  - human body surface
KW  - rubber swath
KW  - fabric actuator
KW  - 3D movements
KW  - motions
KW  - McKibben artificial muscles
KW  - Muscles
KW  - Actuators
KW  - Fabrics
KW  - Rubber
KW  - Weaving
KW  - Regulators
DO  - 10.1109/IROS.2018.8594359
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new flexible fabric actuator realizing three dimensional movements for wearable devices is proposed in this paper. Such actuators must be lightweight and highly flexible, producing movements with high degree of freedom to assist/follow human natural motions. Improving the structure and control system of a fabric actuator from the previous research, the flexible fabric actuator with continuous control is developed. This paper presents new configuration of thin artificial muscles on a flexible rubber swath, a continuous control system to control the fabric actuator smoothly, and control methods to realize six basic movements of human body (forward and backward bends, left and right bends, left and right twists)with less number of muscles. The experiment results indicate the possibility that the proposed fabric actuator woven thin McKibben artificial muscles is a viable technology for use in wearable devices.
ER  - 

TY  - CONF
TI  - Soft Biomimetic Prosthetic Hand: Design, Manufacturing and Preliminary Examination
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - J. Fras
AU  - K. Althoefer
PY  - 2018
KW  - artificial limbs
KW  - biomechanics
KW  - biomimetics
KW  - manipulators
KW  - human hand
KW  - complex mechanical structure
KW  - prosthetic devices
KW  - handled object
KW  - mechanical compliance
KW  - synergistic finger movement
KW  - current control system
KW  - soft biomimetic prosthetic hand
KW  - Actuators
KW  - Exoskeletons
KW  - Manufacturing
KW  - Shape
KW  - Thumb
KW  - Joints
KW  - Sensors
DO  - 10.1109/IROS.2018.8593666
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The human hand is a complex structure. It is strong but precise. It consists of a very complex mechanical structure that enables the hand to adapt and efficiently handle objects of various shapes, weights and textures. Today's prosthetic devices, struggling to provide similar functions, become overly complex and expensive. They are composed of multiple, precise parts, including miniaturised actuators and sensors as well as complex control, to satisfy the manipulation tasks required. In this paper we propose a soft pneumatic hand that adapts passively to the handled object due to its mechanical compliance. It is pressure driven and enables individual fingers to be controlled independently for dexterity or in groups when a synergistic finger movement is needed. The hand has a truly anatomical shape, is easy to replace and cheap in production. The design can be easily adjusted in terms of shape and size in order to fit each individual user. The paper presents the design, manufacturing technology, current control system and preliminary tests of the hand's capabilities.
ER  - 

TY  - CONF
TI  - A Novel All-in-One Manufacturing Process for a Soft Sensor System and its Application to a Soft Sensing Glove
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7004
EP  - 7009
AU  - S. Kim
AU  - D. Jeong
AU  - J. Oh
AU  - W. Park
AU  - J. Bae
PY  - 2018
KW  - biomechanics
KW  - data gloves
KW  - gallium alloys
KW  - manufacturing processes
KW  - sensors
KW  - virtual reality
KW  - wearable computers
KW  - manufacturing process
KW  - soft sensor system
KW  - soft sensing glove
KW  - attractive application
KW  - wearable devices
KW  - soft sensors
KW  - rigid sensing units
KW  - wearable sensor systems
KW  - assembly process
KW  - bulky electrode part
KW  - novel fabrication process
KW  - Fabrication
KW  - Robot sensing systems
KW  - Electrodes
KW  - Sensor systems
KW  - Writing
KW  - Wiring
DO  - 10.1109/IROS.2018.8594389
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A sensing glove is an attractive application of wearable devices. Soft sensors are emerging to replace rigid sensing units, especially for wearable sensor systems, due to its inherent softness, flexibility, and stretchability. However, the fabrication process for the soft sensors is usually complex, time-consuming, labor-intensive, and has low production rate. To integrate a sensor system, an assembly process is essential, which may make the system bulky. Moreover, a solution for the electrode parts has rarely been suggested, although a bulky electrode part may obstruct the user's movement and degrade performance of the sensor. Thus, in this study, a novel fabrication process is suggested based on direct ink writing (DIW) of eutectic gallium-indium (EGaIn), which forms all the items in the sensor system from the sensing units, wiring, and the electrode part. A sensing glove for 2D finger motions was fabricated, and its performance was verified in terms of linearity, dynamic response, and accuracy. The sensing glove can be used as an easily-wearable and an intuitive interface to the virtual reality environment.
ER  - 

TY  - CONF
TI  - On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7033
EP  - 7038
AU  - M. Shahbazi
AU  - N. Kashiri
AU  - D. Caldwell
AU  - N. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - interpolation
KW  - path planning
KW  - polynomials
KW  - position control
KW  - splines (mathematics)
KW  - spline trajectories
KW  - time curves
KW  - quaternion coefficients
KW  - unitariness condition
KW  - quaternion representation
KW  - on-line update mechanism
KW  - anthropomorphic robot upper-body
KW  - real-time compatibility
KW  - constrained angular velocity
KW  - orientation planning algorithms
KW  - task space trajectory generation
KW  - robotics applications
KW  - continuous acceleration profiles
KW  - realtime implementation
KW  - Quaternions
KW  - Interpolation
KW  - Acceleration
KW  - Robots
KW  - Splines (mathematics)
KW  - Trajectory
KW  - Planning
DO  - 10.1109/IROS.2018.8593657
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.
ER  - 

TY  - CONF
TI  - Coverage Path Planning with Adaptive Viewpoint Sampling to Construct 3D Models of Complex Structures for the Purpose of Inspection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7047
EP  - 7054
AU  - R. Almadhoun
AU  - T. Taha
AU  - D. Gan
AU  - J. Dias
AU  - Y. Zweiri
AU  - L. Seneviratne
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image sampling
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - search problems
KW  - adaptive search space coverage path planner
KW  - unmanned aerial vehicle
KW  - coverage path planning
KW  - adaptive sampling
KW  - onboard sensors
KW  - reference model
KW  - accurate 3D models
KW  - complex structure
KW  - adaptive viewpoint sampling
KW  - Sensors
KW  - Adaptation models
KW  - Path planning
KW  - Solid modeling
KW  - Entropy
KW  - Clustering algorithms
KW  - Octrees
DO  - 10.1109/IROS.2018.8593719
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a coverage path planning algorithm with adaptive viewpoint sampling to construct accurate 3D models of complex large structures using Unmanned Aerial Vehicle (UAV). The developed algorithm, Adaptive Search Space Coverage Path Planner (ASSCPP), utilizes an existing 3D reference model of the complex structure and the onboard sensors' noise models to generate paths that are evaluated based on the traveling distance and the quality of the model. The algorithm generates a set of viewpoints by performing adaptive sampling that directs the search towards areas with low accuracy and low coverage. The algorithm predicts the coverage percentage obtained by following the generated coverage path using the reference model. A set of experiments were conducted in real and simulated environments with structures of different complexities to test the validity of the proposed algorithm.
ER  - 


TY  - CONF
TI  - Solving Markov Decision Processes with Reachability Characterization from Mean First Passage Times
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7063
EP  - 7070
AU  - S. Debnath
AU  - L. Liu
AU  - G. Sukhatme
PY  - 2018
KW  - decision making
KW  - decision theory
KW  - iterative methods
KW  - Markov processes
KW  - reachability analysis
KW  - robots
KW  - Markov decision processes
KW  - reachability characterization
KW  - reachability landscape
KW  - MFPT-VI
KW  - MFPT-PI
KW  - mean first passage time based value iteration
KW  - mean first passage time based policy iteration
KW  - robotic decision-making
KW  - numerical evaluation
KW  - Convergence
KW  - Markov processes
KW  - Mathematical model
KW  - Approximation algorithms
KW  - Planning
KW  - Linear systems
KW  - Standards
DO  - 10.1109/IROS.2018.8594383
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new mechanism for efficiently solving the Markov decision processes (MDPs) is proposed in this paper. We introduce the notion of reachability landscape where we use the Mean First Passage Time (MFPT) as a means to characterize the reachability of every state in the state space. We show that such reachability characterization very well assesses the importance of states and thus provides a natural basis for effectively prioritizing states and approximating policies. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based Policy Iteration (MFPT-PI) - that have been modified from the state-of-the-art solution methods. To validate our design, we have performed numerical evaluations in robotic decision-making scenarios, by comparing the proposed new methods with corresponding classic baseline mechanisms. The evaluation results showed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art solutions in terms of both practical runtime and number of iterations. Aside from the advantage of fast convergence, this new solution method is intuitively easy to understand and practically simple to implement.
ER  - 

TY  - CONF
TI  - Hybrid Bio-Inspired Architecture for Walking Robots Through Central Pattern Generators Using Open Source FPGAs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7071
EP  - 7076
AU  - J. C. Linares
AU  - A. Barrientos
AU  - E. M. Márquez
PY  - 2018
KW  - control engineering computing
KW  - data acquisition
KW  - field programmable gate arrays
KW  - gait analysis
KW  - legged locomotion
KW  - microprocessor chips
KW  - public domain software
KW  - hybrid bio-inspired architecture
KW  - central pattern generators
KW  - robotic control approach
KW  - animal nervous system control
KW  - CNS-PNS
KW  - high level control
KW  - low level control
KW  - open source tools
KW  - binomial brain-peripheral nervous system
KW  - open source FPGA
KW  - digital circuits
KW  - microprocessors
KW  - Field programmable gate arrays
KW  - Level control
KW  - Legged locomotion
KW  - Microprocessors
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594288
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a new robotic control approach inspired in the animal nervous system control. The system implements the binomial Brain-Peripheral Nervous System (CNS-PNS) combining the use of microprocessors as the high level control, or brain, and FPGAs as the low level control, or nervous system. Thanks to the new open source tools for FPGAs, we are able to apply them in the field of robotics in new ways that were impossible before. In this paper, we will demonstrate that our approach is not only able to control the movements of robots using digital circuits built inside an FPGA, but is also capable of generating, synthesizing and uploading them inside the FPGA in real time and on demand.
ER  - 

TY  - CONF
TI  - Towards an Autonomous Robotic Dragonfly: At-Scale Lift Experiments Modeling Dragonfly Forewings
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. A. K. Szabo
AU  - G. M. T. D'Eleuterio
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - bending
KW  - carbon fibres
KW  - design engineering
KW  - mobile robots
KW  - piezoelectric actuators
KW  - polymer films
KW  - robot kinematics
KW  - sensors
KW  - hindwing pair
KW  - Sympetrum san-guineum
KW  - flapping kinematics
KW  - carbon-fiber support structure
KW  - polyester film
KW  - polymide-film joints
KW  - piezoelectric bending-beam actuator
KW  - lift sensor
KW  - Sympetrum sanguineum
KW  - autonomous robotic dragonfly
KW  - artificial dragonfly forewings
KW  - Insects
KW  - Aerodynamics
KW  - Actuators
KW  - Resonant frequency
KW  - Frequency measurement
KW  - Carbon
KW  - Power supplies
DO  - 10.1109/IROS.2018.8594331
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We report on lift experiments conducted at scale for an artificial platform mimicking the dragonfly species: Sympetrum sanguineum. The platform, as well as the lift sensor, was custom designed and built. The flapping mechanism consisted of a piezoelectric bending-beam actuator, transmission using carbon-fiber elements and polymide-film joints, and wings constructed of polyester film with carbon-fiber support structure. The flapping kinematics of the Sympetrum san-guineum was replicated as closely as possible although only a pair of forewings were used in these experiments. The lift generated, when accounting for the addition of a pair of hindwings, is sufficient to allow for the hovering of a real-life dragonfly. The results, the first at-scale fully transient measurements of artificial dragonfly forewings, show that the lift curves quantitatively as well as qualitatively validate existing 2D and 3D computer simulations of dragonfly forewings.
ER  - 

TY  - CONF
TI  - Ultrasonic and Electrostatic Self-Cleaning Microstructured Adhesives for Robotic Grippers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7083
EP  - 7088
AU  - V. Alizadehyazdi
AU  - E. McQueney
AU  - K. Tanaka
AU  - M. Spenko
PY  - 2018
KW  - adhesion
KW  - adhesives
KW  - cleaning
KW  - dust
KW  - electrostatics
KW  - glass
KW  - grippers
KW  - industrial robots
KW  - mobile robots
KW  - ultrasonic cleaning
KW  - perching robots
KW  - electrostatic cleaning
KW  - electrostatic repulsion
KW  - climbing robots
KW  - ultrasonic cleaning
KW  - noncontact cleaning method
KW  - robotic gripper
KW  - contaminated directional gecko-like adhesive
KW  - Cleaning
KW  - Electrostatics
KW  - Surface contamination
KW  - Grippers
KW  - Electrodes
KW  - Substrates
KW  - Rough surfaces
DO  - 10.1109/IROS.2018.8594091
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces electrostatic and ultrasonic techniques to clean dust and other contaminants from the surface of a gecko-like, microstrutured adhesive. The result is a non-destructive, non-contact cleaning method that will afford robotic grippers, climbing robots, and perching robots the ability to operate in real-world environments. Experimental results show that the cleaning efficiency for three different sizes of glass beads, 53-75 μm, 75-90 μm, and 90-106 μm, ranges between 75-99% when using a combination of electrostatic and ultrasonic cleaning. This is a far higher efficiency than when using electrostatic repulsion alone. Experiments also demonstrate an approximately 33% recovery in shear stress on a flat glass for a contaminated directional gecko-like adhesive after contact with a dusty table when electrostatic/ultrasonic cleaning was used. Finally, by applying this method on a robotic gripper, we observed an 18% recovery in normal adhesion on a flat glass substrate.
ER  - 

TY  - CONF
TI  - Evolving a Sensory-Motor Interconnection for Dynamic Quadruped Robot Locomotion Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7089
EP  - 7095
AU  - A. Aulia Saputra
AU  - W. Hong Chin
AU  - J. Botzheim
AU  - N. Kubota
PY  - 2018
KW  - legged locomotion
KW  - optimisation
KW  - robot dynamics
KW  - trees (mathematics)
KW  - dynamic quadruped robot locomotion
KW  - sensory-motor coordination model
KW  - sensory neurons
KW  - neural oscillator
KW  - bacterial programming
KW  - sensory-motor interconnection structure
KW  - tree structure optimization
KW  - gene transfer process
KW  - bacterial mutation
KW  - Neurons
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Microorganisms
KW  - Robot kinematics
KW  - Optimization
DO  - 10.1109/IROS.2018.8593671
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a novel biologically inspired evolving neural oscillator for quadruped robot locomotion to minimize constraints during the locomotion process. The proposed sensory-motor coordination model is formed by the interconnection between motor and sensory neurons. The model utilizes Bacterial Programming to reconstruct the number of joints and neurons in each joint based on environmental conditions. Bacterial Programming is inspired by the evolutionary process of bacteria that includes bacterial mutation and gene transfer process. In this system, either the number of joints, the number of neurons, or the interconnection structure are changing dynamically depending on the sensory information from sensors equipped on the robot. The proposed model is simulated in computer for realizing the optimization process and the optimized structure is then applied to a real quadruped robot for locomotion process. The optimizing process is based on tree structure optimization to simplify the sensory-motor interconnection structure. The proposed model was validated by series of real robot experiments in different environmental conditions.
ER  - 

TY  - CONF
TI  - Learning-based Path Tracking Control of a Flapping-wing Micro Air Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7096
EP  - 7102
AU  - J. Lee
AU  - S. Ryu
AU  - T. Kim
AU  - W. Kim
AU  - H. J. Kim
PY  - 2018
KW  - aerodynamics
KW  - aerospace simulation
KW  - autonomous aerial vehicles
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - predictive control
KW  - vehicle dynamics
KW  - autonomous flight
KW  - neural network
KW  - MPC
KW  - Reynolds number
KW  - model predictive control
KW  - model-based control strategy
KW  - FWMAV
KW  - flapping-wing microair vehicle
KW  - path tracking control
KW  - Batteries
KW  - Training
KW  - Neural networks
KW  - Dynamics
KW  - Data models
KW  - Trajectory
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594387
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flapping-wing micro air vehicles (FWMAVs) become promising research platforms due to their advantages such as various maneuverability, and concealment. However, unsteady flow at low Reynolds number around the wings makes their dynamics time-varying and highly non-linear. It makes autonomous flight of FWMAV as a big challenge. In this paper, we suggest a model-based control strategy for FWMAV using learning architecture. For this task, we construct a ground station for logging flight data and control inputs, and train dynamics with a neural network. Then, we apply model predictive control (MPC) to the trained model. We validate our method by hardware experiments.
ER  - 

TY  - CONF
TI  - Improving the Parallel Execution of Behavior Trees
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7103
EP  - 7110
AU  - M. Colledanchise
AU  - L. Natale
PY  - 2018
KW  - computer games
KW  - control system synthesis
KW  - finite state machines
KW  - mobile robots
KW  - trees (mathematics)
KW  - control architectures
KW  - concurrent programming
KW  - CBTs
KW  - autonomous agents
KW  - computer game
KW  - robotics industry
KW  - finite state machines
KW  - parallel execution
KW  - concurrent BTs
KW  - parallel operator
KW  - behavior trees
KW  - Task analysis
KW  - Robots
KW  - Synchronization
KW  - Games
KW  - Programming
KW  - Monitoring
KW  - Concurrent computing
DO  - 10.1109/IROS.2018.8593504
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Behavior Trees (BTs) have become a popular framework for designing controllers of autonomous agents in the computer game and in the robotics industry. One of the key advantages of BTs lies in their modularity, where independent modules can be composed to create more complex ones. In the classical formulation of BTs, modules can be composed using one of the three operators: Sequence, Fallback, and Parallel. The Parallel operator is rarely used despite its strong potential against other control architectures such as Finite State Machines. This is due to the fact that concurrent actions may lead to unexpected problems similar to the ones experienced in concurrent programming. In this paper, we outline how to tackle the aforementioned problem by introducing Concurrent BTs (CBTs) as a generalization of BTs in which we include the notions of progress and resource usage. We show how CBTs allow safe concurrent executions of actions and we analyze the approach from a mathematical standpoint. To illustrate the use of CBTs, we provide a set of use cases in realistic robotics scenarios.
ER  - 

TY  - CONF
TI  - Guess What I Attend: Interface-Free Object Selection Using Brain Signals
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7111
EP  - 7116
AU  - H. Kolkhorst
AU  - M. Tangermann
AU  - W. Burgard
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - signal detection
KW  - user training
KW  - event-related potentials
KW  - interface-free object selection
KW  - brain signals
KW  - brain activity
KW  - user goals
KW  - intuitive communication
KW  - human-robot cooperation scenarios
KW  - natural brain responses
KW  - target object detection
KW  - object selection
KW  - information geometry
KW  - Electroencephalography
KW  - Covariance matrices
KW  - Task analysis
KW  - Information geometry
KW  - Switches
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593992
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interpreting the brain activity to identify user goals or to ground a robot's hypotheses about them is a promising direction for non-intrusive and intuitive communication. Such a capability can be of particular relevance in the context of human-robot cooperation scenarios. This paper proposes a novel approach to utilize the natural brain responses to highlighted objects in the scene for object selection. By this, it circumvents the need for additional interfaces or user training. Our approach uses methods from information geometry to classify the target/non-target response of these event-related potentials. Online experiments carried out with a real robot demonstrate an accurate detection of target objects solely based on the user's attention.
ER  - 

TY  - CONF
TI  - Mobile Continuum Robot with Unlimited Extensible Sections
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7117
EP  - 7122
AU  - A. Kanada
AU  - T. Mashimo
PY  - 2018
KW  - bending
KW  - buckling
KW  - DC motors
KW  - force control
KW  - gears
KW  - mobile robots
KW  - motion control
KW  - pulleys
KW  - typical continuum robots
KW  - restricted section length
KW  - locomotion
KW  - mobile continuum robot design
KW  - virtually unlimited extensible sections
KW  - driving unit
KW  - gear
KW  - long flexible tube
KW  - traveling distance
KW  - multiple driving units
KW  - DC motors
KW  - crawling locomotion performance
KW  - 3D printer
KW  - helical groove
KW  - tendon-driven robots
KW  - Electron tubes
KW  - DC motors
KW  - Gears
KW  - Trajectory
KW  - Springs
KW  - End effectors
DO  - 10.1109/IROS.2018.8594340
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.
ER  - 

TY  - CONF
TI  - Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7123
EP  - 7130
AU  - S. Kitagawa
AU  - K. Wada
AU  - S. Hasegawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - control engineering computing
KW  - convolutional neural nets
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - selective dual-arm grasping
KW  - pruning grasping points
KW  - robot experience
KW  - robot grasping
KW  - dual-arm robots
KW  - humanoid robots
KW  - dual-arm manipulation
KW  - single-arm limitation
KW  - multistage learning method
KW  - self-supervised approach
KW  - convolutional neural networks
KW  - CNN
KW  - semantic segmentation
KW  - automatic annotation
KW  - Grasping
KW  - Semantics
KW  - Image segmentation
KW  - Manipulators
KW  - Task analysis
KW  - Learning systems
DO  - 10.1109/IROS.2018.8593752
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.
ER  - 

TY  - CONF
TI  - Bimanual Assembly of Two Parts with Relative Motion Generation and Task Related Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7131
EP  - 7136
AU  - S. Stavridis
AU  - Z. Doulgeri
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - motion control
KW  - optimisation
KW  - robotic assembly
KW  - end-effector frame
KW  - stack-of- tasks hierarchical solver
KW  - collision avoidance
KW  - optimization
KW  - relative motion generation
KW  - bimanual assembly
KW  - YuMi bimanual robot
KW  - task priority strategy
KW  - Task analysis
KW  - Collision avoidance
KW  - End effectors
KW  - Ellipsoids
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593928
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Bimanual assembly of two parts require that a relative target pose is reached prior to the joining operation. Rather than utilizing one arm as a fixture for holding one of the parts while the other performs the assembly, motion generation in the relative end-effector frame is proposed that involves both arms. The proposed approach considers bimanual motion in a dynamic and uncertain environment addressing avoidance of collision with obstacles as well as the robot itself and the environment. Moreover, configurations that optimize the motion and force capabilities for the sucessful and efficient completion of the task are taken into account. A task priority strategy is adopted achieving online performance. Experimental results on the YuMi bimanual robot using the Stack-Of- Tasks hierarchical solver validate the performance of the proposed approach in a folding assembly task.
ER  - 

TY  - CONF
TI  - Dual-Arm Coordinated Motion Planning and Compliance Control for Capturing Moving Objects with Large Momentum
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7137
EP  - 7144
AU  - L. Yan
AU  - Y. Yang
AU  - W. Xu
AU  - S. Vijayakumar
PY  - 2018
KW  - compliance control
KW  - force control
KW  - Jacobian matrices
KW  - manipulators
KW  - motion control
KW  - optimal control
KW  - path planning
KW  - trajectory control
KW  - dual-arm coordinated motion planning
KW  - dual-arm robot
KW  - operational force control
KW  - dual-arm capturing motion
KW  - object tracking
KW  - compliance control
KW  - null-space projected relative Jacobian
KW  - collocation trajectory optimization
KW  - Planning
KW  - Force
KW  - Robot kinematics
KW  - Jacobian matrices
KW  - Trajectory
KW  - Tracking
DO  - 10.1109/IROS.2018.8593853
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Capturing a moving object with large momentum by a dual-arm robot is especially challenging because of the requirement of dual-arm coordinated motion planning for tracking the moving object, and the operational force control for contact and momentum transfer. In this paper, we present a dual-arm coordinated motion planning and compliance control method with a unique null-space projected relative Jacobian and relative operational force between the two arms. The proposed method is able to plan dual-arm capturing motion and control the capturing force without disturbing the tracking motion. We have also adopted a direct collocation trajectory optimization method to generate optimal trajectory to decrease the object's momentum with minimum effort. Simulation and experiment of dual-arm robots picking up a moving box on a mobile platform are carried out to verify the proposed method.
ER  - 

TY  - CONF
TI  - A Model Predictive Control Approach for Vision-Based Object Grasping via Mobile Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - M. Logothetis
AU  - G. C. Karras
AU  - S. Heshmati-Alamdari
AU  - P. Vlantis
AU  - K. J. Kyriakopoulos
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - robot vision
KW  - reach-to-grasp motion
KW  - optimal grasping regions
KW  - vision-based object grasping
KW  - motion control architecture
KW  - mobile manipulator system
KW  - partial point cloud
KW  - onboard RGB-D sensor system
KW  - KUKA Youbot
KW  - static obstacles
KW  - reach-to-grasp scenarios
KW  - model predictive control approach
KW  - nonlinear model predictive control scheme
KW  - Grasping
KW  - Three-dimensional displays
KW  - Manipulators
KW  - Grippers
KW  - Robot sensing systems
KW  - Predictive control
DO  - 10.1109/IROS.2018.8593759
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design of a vision-based object grasping and motion control architecture for a mobile manipulator system. The optimal grasping areas of the object are estimated using the partial point cloud acquired from an onboard RGB-D sensor system. The reach-to-grasp motion of the mobile manipulator is handled via a Nonlinear Model Predictive Control scheme. The controller is formulated accordingly in order to allow the system to operate in a constrained workspace with static obstacles. The goal of the proposed scheme is to guide the robot's end-effector towards the optimal grasping regions with guaranteed input and state constraints such as occlusion and obstacle avoidance, workspace boundaries and field of view constraints. The performance of the proposed strategy is experimentally verified using an 8 Degrees of Freedom KUKA Youbot in different reach-to-grasp scenarios.
ER  - 

TY  - CONF
TI  - A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7151
EP  - 7157
AU  - T. Furukawa
AU  - G. Dissanayake
AU  - T. Attia
AU  - J. Hodges
PY  - 2018
KW  - Bayes methods
KW  - image fusion
KW  - image sensors
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - object detection
KW  - probability
KW  - remotely operated vehicles
KW  - robot vision
KW  - mobile robot
KW  - multistage Bayesian approaches
KW  - multistage localization approach
KW  - global coordinate frame
KW  - multistage target observation approach
KW  - target engagement
KW  - multiple sensors
KW  - Bayesian framework
KW  - simultaneous robot localization
KW  - sensors on-board
KW  - target detection
KW  - associated detection probability
KW  - extended Kalman filter
KW  - unmanned ground vehicle
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Bayes methods
KW  - Mobile robots
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8593747
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.
ER  - 

TY  - CONF
TI  - Coupling Mobile Base and End-Effector Motion in Task Space
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Welschehold
AU  - C. Dornhege
AU  - F. Paus
AU  - T. Asfour
AU  - W. Burgard
PY  - 2018
KW  - approximation theory
KW  - collision avoidance
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - couple robot base
KW  - kinematic constraints
KW  - mobile manipulators
KW  - model-based dynamic systems
KW  - in-depth knowledge
KW  - motion planning
KW  - task space
KW  - end-effector motion
KW  - coupling mobile base
KW  - kinematically feasible trajectories
KW  - robots kinematic design
KW  - arbitrary dynamical systems
KW  - End effectors
KW  - Trajectory
KW  - Task analysis
KW  - Grippers
KW  - Dynamics
KW  - Planning
DO  - 10.1109/IROS.2018.8593534
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic systems are a practical alternative to motion planning in executing robot actions. They are of particular interest in Learning from Demonstration, as here we aim to carry out actions in a certain fashion, without a model or in-depth knowledge about the world, which might be difficult to achieve with a planner. Using model-based dynamic systems in task space enables robots to flexibly reproduce demonstrated actions. Nevertheless, when dealing with mobile manipulators, we face the challenge of including the kinematic constraints of the robot in the action models. In this paper we propose to couple robot base and end-effector motions generated by arbitrary dynamical systems modulating the base velocity, while respecting the robots kinematic design. To this end we learn an approximation of the inverse reachability in closed form. In real-world robot experiments we demonstrate that we are able to maintain kinematically feasible trajectories in the presence of obstacles and in configurations differing profoundly from the training scene.
ER  - 

TY  - CONF
TI  - Motion Planning for an Underwater Mobile Manipulator by Exploiting Loose Coupling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7164
EP  - 7171
AU  - D. Youakim
AU  - A. Dornbush
AU  - M. Likhachev
AU  - P. Ridao
PY  - 2018
KW  - autonomous underwater vehicles
KW  - manipulators
KW  - motion control
KW  - path planning
KW  - trajectory control
KW  - intervention autonomous underwater vehicle
KW  - MR-MHA *
KW  - multirepresentation multiheuristic A*
KW  - realistic simulated underwater intervention environment
KW  - intervention mission
KW  - generated trajectories
KW  - high-dimensional underwater manipulator
KW  - search-based planner
KW  - motion coordination
KW  - complex manipulation tasks
KW  - floating-based intervention
KW  - task-priority redundancy control framework
KW  - GIRONA 500
KW  - SAUVIM
KW  - autonomous manipulation skills
KW  - I-AUV
KW  - underwater mobile manipulator
KW  - motion planning
KW  - Task analysis
KW  - Planning
KW  - Manipulators
KW  - Search problems
KW  - Trajectory
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593604
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Intervention Autonomous Underwater Vehicle or I-AUV has recently started to grab researchers attention in the last 20 years. Only three I-AUVs have demonstrated autonomous manipulation skills: ALIVE, SAUVIM and GIRONA 500. While prior systems rely on variations of the task-priority redundancy control framework, our recent research showed preliminary results using motion planning for floating-based intervention in the presence of obstacles. With the increasing need for autonomously performing more complex manipulation tasks, two main challenges need to be addressed: the high-dimensionality of the system, and the motion coordination between the mobile base and the working arm. The latter challenge is of high importance if accurate execution is required, especially considering the floating nature of the AUV and the control challenges that come with it. Our approach relies on exploiting the loose coupling between the AUV and the arm. In particular we present an approach based on MR-MHA * (Multi-Representation, Multi-Heuristic A*), and we show how it can generate efficient trajectories by exploiting decoupling. We show for the first time the use of a search-based planner on a high-dimensional underwater manipulator. In addition, we support our claims with experimental analysis of the generated trajectories with respect to various metrics in different environments. Furthermore, we demonstrate the ability of our approach to conduct a full intervention mission in a realistic simulated underwater intervention environment.
ER  - 

TY  - CONF
TI  - Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - R. S. Novin
AU  - A. Yazdani
AU  - T. Hermans
AU  - A. Merryweather
PY  - 2018
KW  - collision avoidance
KW  - hospitals
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - predictive control
KW  - probability
KW  - PAM robot
KW  - probabilistic method
KW  - 2-wheel walker
KW  - autonomous learning
KW  - fall prevention
KW  - maneuvers mobility aids
KW  - patient assistant mobile robot
KW  - dynamic model learning
KW  - collision-free manipulation
KW  - 4-legged walker
KW  - hybrid MPC-based manipulation planning algorithm
KW  - one-wheel point-mass model
KW  - hybrid control system
KW  - motion interactions
KW  - minimal force
KW  - approximate dynamic model
KW  - Legged locomotion
KW  - Dynamics
KW  - Planning
KW  - Manipulator dynamics
KW  - Grippers
DO  - 10.1109/IROS.2018.8593989
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.
ER  - 

TY  - CONF
TI  - Capacitive Proximity Sensor Skin for Contactless Material Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7179
EP  - 7184
AU  - Y. Ding
AU  - H. Zhang
AU  - U. Thomas
PY  - 2018
KW  - capacitance measurement
KW  - capacitive sensors
KW  - distance measurement
KW  - electric impedance measurement
KW  - frequency measurement
KW  - signal processing
KW  - time-of-flight sensors
KW  - capacitance based sensor system
KW  - characteristic impedance spectrum measurement
KW  - absolute distance based capacitance measurement capabilities
KW  - ToF sensors
KW  - human-machine-interaction
KW  - signal processing
KW  - frequency based capacitance measurement capabilities
KW  - distance sensing methods
KW  - capacitive proximity sensing skins
KW  - contactless material detection
KW  - Robot sensing systems
KW  - Impedance
KW  - Frequency measurement
KW  - Electrodes
KW  - Current measurement
KW  - Impedance measurement
DO  - 10.1109/IROS.2018.8594376
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a method for contactless material detection with capacitive proximity sensing skins. Our new approach extends the current state-of-the-art proximity and distance sensing methods and measures the characteristic impedance spectrum of an object to obtain material properties. By this, we gain further material information besides of the near field information in a contactless and non-destructive way. The measurement method requires sensors that provide absolute distance and frequency based capacitance measurement capabilities and can be applied to similar systems. The sensor system described in this paper measures proximity with a capacitance based sensor and absolute distance based on time-of-flight (ToF)sensors. Attached on a robot, we gain information about the robot's near field environment. The information is important not only for human- machine- interaction, but also for grasping and manipulation. We focus on signal processing and evaluate our method with measurements of numerous different materials and present a solution to differentiate between them.
ER  - 

TY  - CONF
TI  - Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7185
EP  - 7192
AU  - J. S. Dyrstad
AU  - E. Ruud Øye
AU  - A. Stahl
AU  - J. Reidar Mathiassen
PY  - 2018
KW  - convolutional neural nets
KW  - grippers
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - virtual reality
KW  - teaching
KW  - gripper
KW  - domain randomization approach
KW  - depth imaging
KW  - 3D occupancy grid
KW  - robot imitation learning
KW  - deep 3D convolutional neural network
KW  - virtual robot
KW  - grasp real fish
KW  - virtual reality
KW  - human supervisor
KW  - Robots
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Grippers
KW  - Grasping
KW  - Cameras
KW  - Virtual reality
DO  - 10.1109/IROS.2018.8593954
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.
ER  - 

TY  - CONF
TI  - Seeing Behind the Scene: Using Symmetry to Reason About Objects in Cluttered Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7193
EP  - 7200
AU  - A. Ecins
AU  - C. Fermüller
AU  - Y. Aloimonos
PY  - 2018
KW  - feature extraction
KW  - geometry
KW  - image reconstruction
KW  - image segmentation
KW  - natural scenes
KW  - object detection
KW  - cluttered scenes
KW  - scene extraction
KW  - 3D reconstructions
KW  - objects segment
KW  - symmetry axes-planes
KW  - geometry
KW  - pointclouds
KW  - foreground segmentation problem
KW  - smooth surfaces
KW  - reflectional symmetries
KW  - natural scenes
KW  - symmetric objects
KW  - cluttered environments
KW  - Three-dimensional displays
KW  - Shape
KW  - Task analysis
KW  - Two dimensional displays
KW  - Pipelines
KW  - Surface treatment
KW  - Object segmentation
DO  - 10.1109/IROS.2018.8593822
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Symmetry is a common property shared by the majority of man-made objects. This paper presents a novel bottom-up approach for segmenting symmetric objects and recovering their symmetries from 3D pointclouds of natural scenes. Candidate rotational and reflectional symmetries are detected by fitting symmetry axes/planes to the geometry of the smooth surfaces extracted from the scene. Individual symmetries are used as constraints for the foreground segmentation problem that uses symmetry as a global grouping principle. Evaluation on a challenging dataset shows that our approach can reliably segment objects and extract their symmetries from incomplete 3D reconstructions of highly cluttered scenes, outperforming state-of-the-art methods by a wide margin.
ER  - 

TY  - CONF
TI  - Efficient Pose Estimation from Single RGB-D Image via Hough Forest with Auto-Context
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7201
EP  - 7206
AU  - H. Dong
AU  - Dilip K. Prasad
AU  - Q. Yuan
AU  - J. Zhou
AU  - E. Asadi
AU  - I. Chen
PY  - 2018
KW  - feature extraction
KW  - image classification
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - object detection
KW  - pose estimation
KW  - probability
KW  - regression analysis
KW  - 6D pose
KW  - public datasets
KW  - high efficient learning approach
KW  - robotic grasps
KW  - cascaded Hough forests
KW  - pose distribution
KW  - classification framework
KW  - joint regression
KW  - Hough space
KW  - object class probability
KW  - random forest
KW  - cluttered environment
KW  - textured texture-less
KW  - auto-context
KW  - single RGB-D image
KW  - efficient pose estimation
KW  - Training
KW  - Forestry
KW  - Vegetation
KW  - Three-dimensional displays
KW  - Reservoirs
KW  - Pose estimation
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594064
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a high efficient learning approach to estimating 6D (Degree of Freedom) pose of the textured or texture-less objects for grasping purposes in a cluttered environment where the objects might be partially occluded. The method comprises three main steps. Given a single RGB-D image, we first deploy appropriate features and the random forest to deduce the object class probability and cast votes for the 6D pose in Hough space by joint regression and classification framework, adopting reservoir sampling and summarizing the pose distribution by clustering. Next, we integrate the auto-context into cascaded Hough forests to improve the efficiency of learning. Extensive experiments on various public datasets and robotic grasps indicate that our method presents some improvements over the state-of-art and reveals the capability for estimating poses in practical applications efficiently.
ER  - 

TY  - CONF
TI  - Plenoptic Monte Carlo Object Localization for Robot Grasping Under Layered Translucency
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - Z. Zhou
AU  - Z. Sui
AU  - O. C. Jenkins
PY  - 2018
KW  - approximation theory
KW  - cameras
KW  - Gaussian distribution
KW  - image colour analysis
KW  - manipulators
KW  - Monte Carlo methods
KW  - robot vision
KW  - stained glass panels
KW  - object poses
KW  - Monte Carlo object localization algorithm
KW  - localizing objects
KW  - manipulating objects
KW  - translucent materials
KW  - Lytro first generation light field camera
KW  - robot grasping
KW  - layered translucency
KW  - human environments
KW  - robot perception
KW  - open challenges
KW  - transparent objects
KW  - drinking glasses
KW  - refractive media
KW  - partial occlusions
KW  - Michigan progress fetch robot
KW  - plenoptic Monte Carlo object localization
KW  - depth likelihood volume
KW  - PMCL
KW  - Three-dimensional displays
KW  - Cameras
KW  - Glass
KW  - Monte Carlo methods
KW  - Pose estimation
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593629
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to fully function in human environments, robot perception needs to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL)as a method for localizing object poses in the presence of translucency using plenoptic (light-field)observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.
ER  - 

TY  - CONF
TI  - Pose Estimation for Objects with Rotational Symmetry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7215
EP  - 7222
AU  - E. Corona
AU  - K. Kundu
AU  - S. Fidler
PY  - 2018
KW  - CAD
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - solid modelling
KW  - neural network
KW  - test time
KW  - symmetry-labeled objects
KW  - unlabeled CAD models
KW  - pose estimation
KW  - widely explored problem
KW  - poses
KW  - training time
KW  - 3D CAD models
KW  - rotational symmetry
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Training
KW  - Shape
KW  - Neural networks
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594282
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pose estimation is a widely explored problem, enabling many robotic tasks such as grasping and manipulation. In this paper, we tackle the problem of pose estimation for objects that exhibit rotational symmetry, which are common in man-made and industrial environments. In particular, our aim is to infer poses for objects not seen at training time, but for which their 3D CAD models are available at test time. Previous work has tackled this problem by learning to compare captured views of real objects with the rendered views of their 3D CAD models, by embedding them in a joint latent space using neural networks. We show that sidestepping the issue of symmetry in this scenario during training leads to poor performance at test time. We propose a model that reasons about rotational symmetry during training by having access to only a small set of symmetry-labeled objects, whereby exploiting a large collection of unlabeled CAD models. We demonstrate that our approach significantly outperforms a naively trained neural network on a new pose dataset containing images of tools and hardware.
ER  - 

TY  - CONF
TI  - Fully Convolutional Grasp Detection Network with Oriented Anchor Box
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7223
EP  - 7230
AU  - X. Zhou
AU  - X. Lan
AU  - H. Zhang
AU  - Z. Tian
AU  - Y. Zhang
AU  - N. Zheng
PY  - 2018
KW  - feature extraction
KW  - feedforward neural nets
KW  - grippers
KW  - human-robot interaction
KW  - image classification
KW  - image colour analysis
KW  - image matching
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object recognition
KW  - regression analysis
KW  - robot vision
KW  - parallel-plate robotic gripper
KW  - RGB images
KW  - oriented anchor box mechanism
KW  - matching strategy
KW  - end-to-end fully convolutional neural network
KW  - feature extractor
KW  - deep convolutional neural network
KW  - multigrasp predictor regresses
KW  - predefined oriented rectangles
KW  - anchor boxes
KW  - standard Cornell Grasp Dataset
KW  - image-wise split
KW  - object-wise split
KW  - latest state-of-the-art approach
KW  - grasping poses
KW  - convolutional grasp detection network
KW  - Feature extraction
KW  - Robots
KW  - Computational modeling
KW  - Grippers
KW  - Solid modeling
KW  - Computer architecture
KW  - Predictive models
DO  - 10.1109/IROS.2018.8594116
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.
ER  - 

TY  - CONF
TI  - A Probabilistic Approach to Benchmarking and Performance Evaluation of Robot Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7231
EP  - 7236
AU  - P. U. Lima
PY  - 2018
KW  - path planning
KW  - probability
KW  - robots
KW  - performance degradation
KW  - probabilistic approach
KW  - performance evaluation
KW  - robot system
KW  - human-robot interaction
KW  - task planning
KW  - robotics
KW  - benchmarking evaluation
KW  - performance assessment problem
KW  - Task analysis
KW  - Robots
KW  - Benchmark testing
KW  - Reliability
KW  - Measurement
KW  - Approximation algorithms
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594345
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Problem benchmarks are used in experimental science as a reference against which results of experiments using distinct approaches to solve the problem are compared and evaluated in relative terms. In Robotics, just formulating a general performance assessment problem is difficult per se, as robot systems are composed of very diverse subsystems (e.g., localisation, human-robot interaction, task planning, motion planning). This paper introduces a probabilistic approach to benchmarking and evaluating performance of robot systems, which uses probability theory as the common language to quantify the performance of distinct functionalities of a robot system and their impact on the performance of a task carried out by that system. The approach can be used to analyse the performance of a task plan from the performances if its composing functionalities, or to (re)plan when a performance degradation in functionality is predicted to cause performance degradation of the task plan beyond acceptable limits.
ER  - 

TY  - CONF
TI  - Improving Repeatability of Experiments by Automatic Evaluation of SLAM Algorithms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7237
EP  - 7243
AU  - F. Amigoni
AU  - V. Castelli
AU  - M. Luperto
PY  - 2018
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM algorithms
KW  - robotics
KW  - repeatability
KW  - Simultaneous Localization And Mapping
KW  - Simultaneous localization and mapping
KW  - Buildings
KW  - Measurement
KW  - Data models
KW  - Lasers
DO  - 10.1109/IROS.2018.8594189
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The development of good experimental methodologies for robotics takes often inspiration from general principles of experimental practice. Repeatability prescribes that experiments should involve several trials in order to guarantee that results are not achieved by chance, but are systematic, and statistically significant trends can be identified. In this paper, we propose an approach to improve the repeatability of experiments performed in robotics. In particular, we focus on the domain of SLAM (Simultaneous Localization And Mapping) and we introduce a system that exploits simulations to generate a large number of test data on which SLAM algorithms are automatically evaluated in order to obtain consistent results, according to the principle of repeatability.
ER  - 

TY  - CONF
TI  - A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7244
EP  - 7251
AU  - Z. Zhang
AU  - D. Scaramuzza
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - quantitative trajectory evaluation
KW  - trajectory alignment
KW  - specific sensing modality
KW  - error metrics
KW  - absolute trajectory error
KW  - relative error
KW  - visual odometry
KW  - Trajectory
KW  - Cameras
KW  - Noise measurement
KW  - Tutorials
KW  - Sensors
KW  - Visualization
DO  - 10.1109/IROS.2018.8593941
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this tutorial, we provide principled methods to quantitatively evaluate the quality of an estimated trajectory from visual(-inertial) odometry (VO/VIO), which is the foundation of benchmarking the accuracy of different algorithms. First, we show how to determine the transformation type to use in trajectory alignment based on the specific sensing modality (i.e., monocular, stereo and visual-inertial). Second, we describe commonly used error metrics (i.e., the absolute trajectory error and the relative error) and their strengths and weaknesses. To make the methodology presented for VO/VIO applicable to other setups, we also generalize our formulation to any given sensing modality. To facilitate the reproducibility of related research, we publicly release our implementation of the methods described in this tutorial.
ER  - 

TY  - CONF
TI  - Long-Duration Autonomy for Small Rotorcraft UAS Including Recharging
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7252
EP  - 7258
AU  - C. Brommer
AU  - D. Malyuta
AU  - D. Hentzen
AU  - R. Brockers
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - surveillance
KW  - autonomous small rotorcraft
KW  - autonomous operation
KW  - UAS
KW  - recharging station
KW  - vision-based precision landing
KW  - human operators
KW  - mission execution
KW  - emergency response
KW  - unmanned aerial vehicle surveillance
KW  - Global Positioning System
KW  - Batteries
KW  - Magnetometers
KW  - Sensors
KW  - Monitoring
KW  - Three-dimensional displays
KW  - State estimation
DO  - 10.1109/IROS.2018.8594111
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many unmanned aerial vehicle surveillance and monitoring applications require observations at precise locations over long periods of time, ideally days or weeks at a time (e.g. ecosystem monitoring), which has been impractical due to limited endurance and the requirement of humans in the loop for operation. To overcome these limitations, we propose a fully autonomous small rotorcraft UAS that is capable of performing repeated sorties for long-term observation missions without any human intervention. We address two key technologies that are critical for such a system: full platform autonomy including emergency response to enable mission execution independently from human operators, and the ability of vision-based precision landing on a recharging station for automated energy replenishment. Experimental results of up to 11 hours of fully autonomous operation in indoor and outdoor environments illustrate the capability of our system.
ER  - 

TY  - CONF
TI  - Real-Time Feature Depth Estimation for Image-Based Visual ServOing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7314
EP  - 7320
AU  - X. Li
AU  - H. Zhao
AU  - H. Ding
PY  - 2018
KW  - cameras
KW  - feature selection
KW  - nonlinear control systems
KW  - observability
KW  - observers
KW  - reduced order systems
KW  - robot vision
KW  - stability
KW  - visual servoing
KW  - nonlinear reduced-order observer structure
KW  - global asymptotic convergence property
KW  - restrictive observability condition
KW  - depth observer
KW  - camera calibration error
KW  - image-based visual servoing schemes
KW  - interaction matrix
KW  - real-time feature depth estimation
KW  - Observers
KW  - Cameras
KW  - Convergence
KW  - Visual servoing
KW  - Acceleration
DO  - 10.1109/IROS.2018.8593402
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Without the 3-D geometry of the target and robust to camera calibration error, image-based visual servoing schemes have gained a lot of attention. However, the depth of the selected feature, which is involved in the interaction matrix relating the time variation of the feature to the velocity twist of the camera, must be estimated correctly to guarantee the stability of the controller. To this end, this paper proposes a new nonlinear reduced-order observer structure to recover the feature depth in real time. Compared with the existing works, the proposed observer has a global asymptotic convergence property and fast convergence rate, and the convergence rate can be easily adjusted only using a single gain parameter. In addition, the proposed observer has a less restrictive observability condition and stronger robustness to noisy measurements. Extensive comparative numerical simulations are carried out to validate the effectiveness of the proposed depth observer.
ER  - 

TY  - CONF
TI  - Fast Convergence for Object Detection by Learning how to Combine Error Functions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7329
EP  - 7335
AU  - B. Schnieders
AU  - K. Tuvls
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - neural nets
KW  - object detection
KW  - union metric
KW  - estimated pickup rate
KW  - convergence time
KW  - optimally weighted Euclidean distance loss
KW  - object detection network
KW  - robotic pickup operation
KW  - approximate measure
KW  - detecting objects
KW  - fully convolutional segmentation network
KW  - RoboCup@Work challenge environment
KW  - on-line trained auxiliary network
KW  - dependent loss metrics
KW  - Converge-fast-auxnet
KW  - object detection neural networks
KW  - convergence speed
KW  - error functions
KW  - fast convergence
KW  - Object detection
KW  - Training
KW  - Convergence
KW  - Task analysis
KW  - Mathematical model
KW  - Euclidean distance
DO  - 10.1109/IROS.2018.8594179
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.
ER  - 

TY  - CONF
TI  - Towards Real-Time Physical Human-Robot Interaction Using Skeleton Information and Hand Gestures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - O. Mazhar
AU  - S. Ramdani
AU  - B. Navarro
AU  - R. Passama
AU  - A. Cherubini
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - feedforward neural nets
KW  - gesture recognition
KW  - human-robot interaction
KW  - robot vision
KW  - l physical human-robot interaction
KW  - dynamic gestures
KW  - human-robot interaction scenarios
KW  - intelligent human intention detection
KW  - hand gesture recognition
KW  - hand images
KW  - 3D skeletal joint coordinates
KW  - state-of-the-art 2D skeleton extraction library
KW  - time-of-flight depth camera
KW  - meaningful gesture
KW  - reliable 3D skeleton extraction
KW  - human operator
KW  - skeleton information
KW  - towards real-time physical human-robot interaction
KW  - Robot sensing systems
KW  - Skeleton
KW  - Robot kinematics
KW  - Gesture recognition
KW  - Human-robot interaction
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594385
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For successful physical human-robot interaction, the capability of a robot to understand its environment is imperative. More importantly, the robot should extract from the human operator as much information as possible. A reliable 3D skeleton extraction is essential for a robot to predict the intentions of the operator while s/he moves toward the robot or performs a meaningful gesture. For this purpose, we have integrated a time-of-flight depth camera with a state-of-the-art 2D skeleton extraction library namely Openpose, to obtain 3D skeletal joint coordinates reliably. We have also developed a robust and rotation invariant (in the coronal plane)hand gesture detector using a convolutional neural network. At run time (after having been trained)the detector does not require any pre-processing of the hand images. A complete pipeline for skeleton extraction and hand gesture recognition is developed and employed for real-time physical human-robot interaction, demonstrating the promising capability of the designed framework. This work establishes a firm basis and will be extended for the development of intelligent human intention detection in physical human-robot interaction scenarios, to efficiently recognize a variety of static as well as dynamic gestures.
ER  - 

TY  - CONF
TI  - LiDAR and Camera Calibration Using Motions Estimated by Sensor Fusion Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7342
EP  - 7349
AU  - R. Ishikawa
AU  - T. Oishi
AU  - K. Ikeuchi
PY  - 2018
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - image sensors
KW  - motion estimation
KW  - motion measurement
KW  - optical radar
KW  - sensor fusion
KW  - camera imaging
KW  - automatic targetless camera-LiDAR calibration method
KW  - 2D-3D calibration
KW  - scaled camera motion calculation
KW  - three-dimensional point cloud
KW  - motion estimation
KW  - sensor-fusion odometry method
KW  - hand-eye calibration framework
KW  - LiDAR reflectance data
KW  - Cameras
KW  - Calibration
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Two dimensional displays
KW  - Estimation
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8593360
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a targetless and automatic camera-LiDAR calibration method. Our approach extends the hand-eye calibration framework to 2D-3D calibration. The scaled camera motions are accurately calculated using a sensor-fusion odometry method. We also clarify the suitable motions for our calibration method. Whereas other calibrations require the LiDAR reflectance data and an initial extrinsic parameter, the proposed method requires only the three-dimensional point cloud and the camera image. The effectiveness of the method is demonstrated in experiments using several sensor configurations in indoor and outdoor scenes. Our method achieved higher accuracy than comparable state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7350
EP  - 7355
AU  - S. M. Ahmed
AU  - Y. Z. Tan
AU  - C. M. Chew
AU  - A. A. Mamun
AU  - F. S. Wong
PY  - 2018
KW  - computer vision
KW  - edge detection
KW  - feature extraction
KW  - image recognition
KW  - image representation
KW  - image segmentation
KW  - stereo image processing
KW  - robotic welding
KW  - weld seams
KW  - point cloud
KW  - welding paths
KW  - Harris 3D
KW  - unorganized point clouds
KW  - edge detection method
KW  - local neighborhood
KW  - adaptive density
KW  - corner detector
KW  - clusters curvature vectors
KW  - RGB-D semantic segmentation
KW  - 3D washer models
KW  - recall scores
KW  - automatic weld seam detection
KW  - Three-dimensional displays
KW  - Image edge detection
KW  - Welding
KW  - Feature extraction
KW  - Corner detection
KW  - Clustering algorithms
KW  - Detectors
DO  - 10.1109/IROS.2018.8593910
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds. Our edge detection method evaluates symmetry in a local neighborhood and uses an adaptive density based threshold to differentiate 3D edge points. We extend this algorithm to propose a novel corner detector that clusters curvature vectors and uses their geometrical statistics to classify a point as corner. We perform rigorous evaluation of the algorithms on RGB-D semantic segmentation and 3D washer models from the ShapeNet dataset and report higher precision and recall scores. Finally, we also demonstrate how our edge and corner detectors can be used as a novel approach towards automatic weld seam detection for robotic welding. We propose to generate weld seams directly from a point cloud as opposed to using 3D models for offline planning of welding paths. For this application, we show a comparison between Harris 3D and our proposed approach on a panel workpiece.
ER  - 

TY  - CONF
TI  - Automatic Fall Risk Assessment for Challenged Users Obtained from a Rollator Equipped with Force Sensors and a RGB-D Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7356
EP  - 7361
AU  - J. Ballesteros
AU  - J. M. Peula
AU  - A. B. Martinez
AU  - C. Urdiales
PY  - 2018
KW  - force sensors
KW  - gait analysis
KW  - handicapped aids
KW  - patient rehabilitation
KW  - risk management
KW  - medical staff
KW  - rehabilitation process
KW  - preferred environments
KW  - assistive navigation
KW  - imminent fall risk estimator
KW  - automatic fall risk assessment
KW  - challenged users
KW  - force sensors
KW  - RGB-d camera
KW  - rollator
KW  - cognitive disability
KW  - physical disability
KW  - Tinetti mobility test
KW  - walking speed
KW  - Wearable sensors
KW  - Force sensors
KW  - Senior citizens
KW  - Foot
KW  - Legged locomotion
KW  - Assistive devices
DO  - 10.1109/IROS.2018.8594122
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fall risk assessments provide a useful tool to prevent morbidity and mortality provoked by falls. Nowadays, these assessments are usually performed manually by the medical staff. This approach has three main drawbacks: (i) it is time consuming, so it is only performed a few times per volunteer during their rehabilitation process; (ii) it requires supervision by medical staff, so assessment at home or preferred environments is not feasible; and (iii) fall risk is evaluated in a global way, so imminent fall risk is not available for decision making in assistive navigation. In this paper we propose an imminent fall risk estimator for rollator's users that can be automatically obtained on the fly. Its main advantages are: (i) it can be used in everyday conditions in any environment; (ii) it does not require assistance of medical staff; and (iii) it is suitable for a variety of users with minimal configuration changes. We have validated our estimator with a set of volunteers (n=10) presenting different physical and cognitive disabilities. Although the number of volunteer is limited, results show that our estimator is coherent to two traditional, well accepted assessments: the Tinetti Mobility Test and the walking speed.
ER  - 

TY  - CONF
TI  - ARIADNE with Ambiguity Resolution: Visual Marker Based Rapid Initialization of PPP-AR
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7362
EP  - 7368
AU  - K. Watanabe
PY  - 2018
KW  - agriculture
KW  - Global Positioning System
KW  - carrier phase ambiguity resolution
KW  - precise point positioning
KW  - real-time kinematic positioning
KW  - accurate fiducial marker
KW  - ARIADNE
KW  - Earth-fixed coordinates
KW  - mining
KW  - precise agriculture
KW  - ground base station
KW  - visual marker
KW  - PPP-AR
KW  - initialization process
KW  - positioning accuracy
KW  - initial convergence time
KW  - Global navigation satellite system
KW  - Position measurement
KW  - Antenna measurements
KW  - Antennas
KW  - Convergence
KW  - Cameras
DO  - 10.1109/IROS.2018.8593863
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precise Point Positioning (PPP) offers advantages over Real-Time Kinematic (RTK) positioning in that it needs no ground base station or a rover to provide a communication channel with the base station. Therefore, PPP is expected to be applied in various fields, such as precise agriculture, intelligent transportation, construction, and mining. One major drawback of PPP is that it takes several tens of minutes for initial convergence to reach an adequate level of accuracy, and how to shorten the convergence time remains the key issue regarding the proliferation of PPP. In our previous work, we proposed a method of drastically reducing this initial convergence time of PPP (called “ARIADNE”) by using an accurate fiducial marker whose position in Earth-fixed coordinates has been accurately measured using an onboard camera. In this contribution, in order to improve both the positioning accuracy and reliability, we introduce some new techniques to ARIADNE: (1) carrier phase ambiguity resolution (AR); and (2) estimating displacement of the marker's orientation. AR results in doubling the positioning accuracy, while displacement estimation enables the detection of any change in the marker's installation orientation and compensation for the effect thereof in the initialization process. Analytical results based on actual data acquired with a prototype system show that the above method and techniques work very well with a realistic setup of PPP-AR and marker performance, and successfully reduce the initial convergence time from tens of minutes to less than a minute.
ER  - 

TY  - CONF
TI  - Fast Trajectory Planning for Automated Vehicles Using Gradient-Based Nonlinear Model Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7369
EP  - 7374
AU  - F. Gritschneder
AU  - K. Graichen
AU  - K. Dietmayer
PY  - 2018
KW  - gradient methods
KW  - mobile robots
KW  - nonlinear control systems
KW  - optimisation
KW  - path planning
KW  - predictive control
KW  - road vehicles
KW  - automated vehicles
KW  - motion trajectory planning
KW  - dynamically changing environment
KW  - nonlinear system dynamics
KW  - automated driving
KW  - nonlinear system model
KW  - optimization algorithms
KW  - gradient-based nonlinear model predictive control
KW  - standard PC
KW  - Mathematical model
KW  - Planning
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Optimization
KW  - Task analysis
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8593913
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion trajectory planning is one crucial aspect for automated vehicles, as it governs the own future behavior in a dynamically changing environment. A good utilization of a vehicle's characteristics requires the consideration of the nonlinear system dynamics within the optimization problem to be solved. In particular, real-time feasibility is essential for automated driving, in order to account for the fast changing surrounding, e.g. for moving objects. The key contributions of this paper are the presentation of a fast optimization algorithm for trajectory planning including the nonlinear system model. Further, a new concurrent operation scheme for two optimization algorithms is derived and investigated. The proposed algorithm operates in the submillisecond range on a standard PC. As an exemplary scenario, the task of driving along a challenging reference course is demonstrated.
ER  - 

TY  - CONF
TI  - Humanoid Navigation Planning in Large Unstructured Environments Using Traversability - Based Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7375
EP  - 7382
AU  - Y. Lin
AU  - D. Berenson
PY  - 2018
KW  - collision avoidance
KW  - humanoid robots
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - planning (artificial intelligence)
KW  - robot kinematics
KW  - humanoid navigation planning
KW  - unstructured environments
KW  - disaster response efforts
KW  - navigation planners
KW  - considering palm contacts
KW  - impractical planning times
KW  - library-based method
KW  - easy-to-traverse part
KW  - discrete planners
KW  - easily-traversable segments
KW  - discrete-search planner
KW  - motion plans
KW  - standard discrete planning
KW  - navigation planning problems
KW  - traversability -based segmentation
KW  - Planning
KW  - Motion segmentation
KW  - Torso
KW  - Navigation
KW  - Humanoid robots
KW  - Foot
DO  - 10.1109/IROS.2018.8593694
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humanoids' abilities to navigate stairs and uneven terrain make them well-suited for disaster response efforts. However, humanoid navigation in such environments is currently limited by the capabilities of navigation planners. Such planners typically consider only footstep locations, but planning with palm contacts may be necessary to cross a gap, avoid an obstacle, or maintain balance. However, considering palm contacts greatly increases the branching factor of the search, leading to impractical planning times for large environments. In previous work we explored using library-based methods to address difficult navigation planning problems requiring palm contacts, but such methods are not efficient when navigating an easy-to-traverse part of the environment. To maximize planning efficiency, we would like to use discrete planners when an area is easy to traverse and switch to the library-based method only when traversal becomes difficult. Thus, in this paper we present a method that 1) Plans a guiding torso path which accounts for the difficulty of traversing the environment as predicted by learned regressors; and 2) Decomposes the guiding path into a set of segments, each of which is assigned a motion mode (i.e. a set of feet and hands to use) and a planning method. Easily-traversable segments are assigned a discrete-search planner, while other segments are assigned a library-based method that fits existing motion plans to the environment near the given segment. Our results suggest that this segmentation approach greatly outperforms standard discrete planning and that using the library-based method for more difficult segments gives a benefit over using discrete planning.
ER  - 

TY  - CONF
TI  - Guaranteed Coverage with a Blind Unreliable Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7383
EP  - 7390
AU  - J. S. Lewis
AU  - D. A. Feshbach
AU  - J. M. O'Kane
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - guaranteed coverage
KW  - blind unreliable robot
KW  - coverage planning
KW  - simple mobile robot
KW  - heuristic algorithm
KW  - specially-constructed graph
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Planning
KW  - Navigation
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594048
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach.
ER  - 

TY  - CONF
TI  - Single Leg Dynamic Motion Planning with Mixed-Integer Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - Y. Ding
AU  - C. Li
AU  - H. Park
PY  - 2018
KW  - actuators
KW  - approximation theory
KW  - convex programming
KW  - integer programming
KW  - Jacobian matrices
KW  - legged locomotion
KW  - path planning
KW  - quadratic programming
KW  - robot dynamics
KW  - trigonometrical terms
KW  - Jacobian matrix
KW  - optimization problem
KW  - mixed-integer quadratically-constrained program
KW  - convex outer approximation
KW  - torque ellipsoid
KW  - semidefinite program
KW  - bilinear terms
KW  - McCormick envelope convex relaxation
KW  - actuator torque
KW  - leg dynamic motion planning
KW  - MIQCP
KW  - SDP
KW  - mixed-integer convex programming
KW  - Torque
KW  - Dynamics
KW  - Planning
KW  - Legged locomotion
KW  - Ellipsoids
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594161
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a mixed-integer convex programming formulation for dynamic motion planning. Many dynamic constraints such as the actuator torque constraint are nonlinear and non-convex due to the trigonometrical terms from the Jacobian matrix. This often causes the optimization problem to converge to local optima or even infeasible set. In this paper, we convexify the torque constraint by formulating a mixed-integer quadratically-constrained program (MIQCP). More specifically, the workspace is discretized into a union of disjoint polytopes and torque constraint is enforced upon a convex outer approximation of the torque ellipsoid, obtained by solving a semidefinite program (SDP). Bilinear terms are approximated by McCormick envelope convex relaxation. The proposed MIQCP framework could be solved efficiently to global optimum and the generated trajectories could exploit the rich features of the rough terrain without any initial guess from the designer. The demonstrated experiment results prove that this approach is currently capable of planning consecutive jumps that navigates a single-legged robot through challenging terrains.
ER  - 

TY  - CONF
TI  - Multi-Layer Coverage Path Planner for Autonomous Structural Inspection of High-Rise Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Jung
AU  - S. Song
AU  - P. Youn
AU  - H. Myung
PY  - 2018
KW  - autonomous aerial vehicles
KW  - inspection
KW  - path planning
KW  - structural engineering
KW  - travelling salesman problems
KW  - autonomous structural inspection
KW  - high-rise structures
KW  - buildings
KW  - towers
KW  - unmanned aerial vehicle
KW  - multi-layer coverage path planner
KW  - 3D coverage path planning
KW  - traveling salesman problem
KW  - Inspection
KW  - Three-dimensional displays
KW  - Path planning
KW  - Planning
KW  - Unmanned aerial vehicles
KW  - Solid modeling
KW  - Spirals
DO  - 10.1109/IROS.2018.8593537
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a novel 3D coverage path planning method, which is efficient and practical for inspection of high-rise structures such as buildings or towers, using an unmanned aerial vehicle (UAV) is presented. Our approach basically focuses on developing a model-based path planner for structural inspection with a prior map, which is opposite to a non-model based exploration. The proposed method uses a volumetric map which is made before the path planning. With the map, the whole structure is divided into several layers for efficient path planning. Firstly, in each layer, a set of the normal vectors of the center point of every voxel is calculated, and then the opposing vectors become viewpoints. Due to too many viewpoints and an overlapped inspection surface, we down-sample them with a voxel grid filter. Then, the shortest tour connecting the reduced viewpoints must be computed with the Traveling Salesman Problem (TSP) solver. Lastly, all the paths in each layer are combined to form the complete path. The results are verified using simulations with a rotary wing UAV and compared with other state-of-the-art algorithm. It is proven that our method performs much better for structural inspection with respect to computation time as well as the coverage completeness.
ER  - 

TY  - CONF
TI  - Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7403
EP  - 7409
AU  - C. S. Swaminathan
AU  - T. P. Kucner
AU  - M. Magnusson
AU  - L. Palmieri
AU  - A. J. Lilienthal
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - flow-aware tralatory planning
KW  - motion pattern uncertainty
KW  - flow-aware trajectory
KW  - dynamic environments
KW  - flow model uncertainty
KW  - flow-aware planning
KW  - statistical model
KW  - map flow patterns
KW  - biasing functions
KW  - RRT* planning algorithm
KW  - CLiFF-map model
KW  - flow-compliant trajectories
KW  - flow motion patterns
KW  - Trajectory
KW  - Robots
KW  - Planning
KW  - Cost function
KW  - Uncertainty
KW  - Vehicle dynamics
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8593905
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.
ER  - 

TY  - CONF
TI  - Efficient and Asymptotically Optimal Kinodynamic Motion Planning via Dominance-Informed Regions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Z. Littlefield
AU  - K. E. Bekris
PY  - 2018
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - search problems
KW  - trees (mathematics)
KW  - dominance-informed regions
KW  - high quality path
KW  - search-based methods
KW  - sampling-based methods
KW  - DIRT
KW  - dominance-informed region tree
KW  - spatial exploration
KW  - robot dynamics
KW  - collision checking
KW  - informed search principles
KW  - asymptotically optimal kinodynamic motion planner
KW  - physics-based simulation
KW  - successful successor state
KW  - Task analysis
KW  - Trajectory
KW  - Planning
KW  - Aerospace electronics
KW  - Robots
KW  - Dynamics
KW  - Cost function
DO  - 10.1109/IROS.2018.8593672
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planners have been recently developed that provide path quality guarantees for robots with dynamics. This work aims to improve upon their efficiency, while maintaining their properties. Inspired by informed search principles, one objective is to use heuristics. Nevertheless, comprehensive and fast spatial exploration of the state space is still important in robotics. For this reason, this work introduces Dominance-Informed Regions (DIR), which express both whether parts of the space are unexplored and whether they lies along a high quality path. Furthermore, to speed up the generation of a successful successor state, which involves collision checking or physics-based simulation, a proposed strategy generates the most promising successor in an informed way, while maintaing properties. Overall, this paper introduces a new informed and asymptotically optimal kinodynamic motion planner, the Dominance-Informed Region Tree (DIRT). The method balances exploration-exploitation tradeoffs without many explicit parameters. It is shown to outperform sampling-based and search-based methods for robots to significant dynamics.
ER  - 

TY  - CONF
TI  - High-Speed and Intelligent Pre-Grasp Motion by a Robotic Hand Equipped with Hierarchical Proximity Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7424
EP  - 7431
AU  - Y. Hirai
AU  - Y. Suzuki
AU  - T. Tsuji
AU  - T. Watanabe
PY  - 2018
KW  - manipulators
KW  - motion measurement
KW  - optical sensors
KW  - photodetectors
KW  - shape measurement
KW  - size measurement
KW  - high-speed intelligent pre-grasp motion
KW  - hierarchical optical proximity sensor
KW  - robotic hand manipulation
KW  - shape recognition
KW  - size recognition
KW  - photodetectors
KW  - high-speed feedback control
KW  - robot fingertips
KW  - vision sensors
KW  - time 1.0 s
KW  - Robot sensing systems
KW  - Phototransistors
KW  - Grasping
KW  - Photoconductivity
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594261
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quickness, preciseness and robustness are required in manipulation tasks of robotic hands for automation of manufacturing sites. Previous researches have found that sensing from fingertips equipped with proximity sensors is available for the requirements, because it complements blind areas of vision sensors. In this paper, we develop a novel optical proximity sensor for robot fingertips which provides two levels of proximity information with different purposes, sampling rates, information quantity and quality. The lower-level information from the sensor is for high-speed feedback control of a robotic hand, and the higher-level information is for recognizing the shape and size of an object. A prototype of the sensor with 5 × 5 matrix of photo detectors is presented, and its availability is shown through basic characteristic tests. A motion experiment using a robotic hand equipped with the prototype sensors is also conducted. The result confirms that the robotic hand can adjust the position and orientation of the fingertips to various objects and then correct the grasping form according to the object size within 1s.
ER  - 

TY  - CONF
TI  - Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Di Carlo
AU  - P. M. Wensing
AU  - B. Katz
AU  - G. Bledt
AU  - S. Kim
PY  - 2018
KW  - convex programming
KW  - legged locomotion
KW  - predictive control
KW  - robot dynamics
KW  - torque control
KW  - torque-controlled quadruped robot
KW  - convex model-predictive control
KW  - MIT cheetah 3
KW  - dynamic locomotion
KW  - ground reaction force planning problems
KW  - convex optimization
KW  - robot dynamics
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Dynamics
KW  - Predictive control
KW  - Convex functions
KW  - Predictive models
DO  - 10.1109/IROS.2018.8594448
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.
ER  - 

TY  - CONF
TI  - Towards an Adaptive-Compliance Aerial Manipulator for Contact- Based Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Hamaza
AU  - I. Georgilas
AU  - T. Richardson
PY  - 2018
KW  - actuators
KW  - autonomous aerial vehicles
KW  - inspection
KW  - manipulators
KW  - adaptive-compliance aerial manipulator
KW  - contact-based interaction
KW  - unmanned aerial vehicles
KW  - UAV
KW  - initial flight tests
KW  - novel adaptively compliant actuator
KW  - pick placement
KW  - remote sensors
KW  - structural testing
KW  - contact-based inspection
KW  - key results
KW  - active compliant manipulator
KW  - manipulator controller gains
KW  - physical pulses
KW  - vibration sensors
KW  - initial results
KW  - compliant aerial actuator
KW  - Manipulator dynamics
KW  - End effectors
KW  - Sensors
KW  - Force
KW  - Task analysis
KW  - Inspection
DO  - 10.1109/IROS.2018.8593576
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As roles for unmanned aerial vehicles (UAVs)continue to diversify, the ability to sense and interact closely with the environment becomes increasingly important. Within this paper we report on the initial flight tests of a novel adaptively compliant actuator which will allow a UAV to carry out such tasks as the “pick and placement” of remote sensors, structural testing and contact-based inspection. Three key results are discussed and presented; the ability to physically apply forces with the UAV through the use of an active compliant manipulator; the ability to tailor these forces through tuning of the manipulator controller gains; and the ability to apply a rapid series of physical pulses in order to excite remotely placed sensors, e.g. vibration sensors. A series of over sixty flight tests have been used to generate initial results which clearly demonstrate the potential of this new type of compliant aerial actuator.
ER  - 

TY  - CONF
TI  - Optimal Input Waveform for an Indirectly Controlled Limit Cycle Walker
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7454
EP  - 7459
AU  - L. Li
AU  - I. Tokuda
AU  - F. Asano
PY  - 2018
KW  - control system synthesis
KW  - gait analysis
KW  - legged locomotion
KW  - limit cycles
KW  - numerical analysis
KW  - optimal control
KW  - oscillators
KW  - robot dynamics
KW  - torque
KW  - wheels
KW  - control mechanisms
KW  - limit cycle walker
KW  - forcing energy reduction
KW  - gait interval
KW  - Arnold tongues
KW  - optimal control design
KW  - numerical analysis
KW  - phase response curve
KW  - phase oscillators
KW  - rimless wheels
KW  - active wobbling mass
KW  - joint torques
KW  - underactuated locomotion robot
KW  - optimal input waveform
KW  - optimal forcing waveform
KW  - Wheels
KW  - Perturbation methods
KW  - Limit-cycles
KW  - Legged locomotion
KW  - Trajectory
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594488
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precisely manipulating the center of mass (CoM) of the underactuated locomotion robot can't be easily achieved by common control mechanisms which apply only joint torques. A novel and indirect method has been recently introduced using an active wobbling mass attached to limit cycle walkers. The next important issue is to design an optimal control input to reduce the forcing energy. In this paper, we use combined rimless wheels as a simplified example to apply our method, which is based on the theory of phase oscillators. First, we introduce the typical modeling and control of this underactuated robot. Second, we obtain the phase response curve by numerically applying perturbations at different phases of the walker's gait interval and calculating the deviations from the unperturbed. Third, we analytically derive an optimal forcing waveform for the wobbling mass to entrain the combined rimless wheel based on the phase response curve. As an ecological extension, an ideal forcing waveform for m: 1 entrainment was further generated. Finally, the proposed method was evaluated by locking range of the Arnold tongues. The results show that the optimal forcing waveform we derived achieves the best performance for 1:1 entrainment among all the candidates. One of the strongest advantages of our method is the easiness of its implementation, prompting its applicability to a wide variety of locomotion systems.
ER  - 

TY  - CONF
TI  - A Comparative Study on Sigma-Point Kalman Filters for Trajectory Estimation of Hybrid Aerial-Aquatic Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7460
EP  - 7465
AU  - R. T. S. da Rosa
AU  - P. J. D. O. Evald
AU  - P. L. J. Drews
AU  - A. A. Neto
AU  - A. C. Horn
AU  - R. Z. Azzolin
AU  - S. S. C. Botelho
PY  - 2018
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - detailed dynamic model simulation
KW  - nonlinear algorithm
KW  - derivative-free nonlinear Kalman Filters
KW  - Cubature Kalman Filter
KW  - CKF
KW  - nonlinear probabilistic estimators
KW  - average execution time
KW  - Monte Carlo simulations
KW  - in-production HUAUV prototype
KW  - state augmentation
KW  - sensor data filtering
KW  - trajectory estimation
KW  - high dimensional state spaces
KW  - comparative study
KW  - sigma-point Kalman
KW  - aerial-aquatic vehicles
KW  - nonlinear state estimation methods
KW  - transformed unscented Kalman filter
KW  - root-mean square error
KW  - hybrid unmanned aerial underwater vehicles
KW  - HUAUV
KW  - Kalman filters
KW  - Trajectory tracking
KW  - State estimation
KW  - Vehicle dynamics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593556
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a study on nonlinear state estimation methods for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) is presented. Based on a detailed dynamic model simulation, we analyse and elect the best nonlinear algorithm among those presented in the state-of-the-art literature addressing local derivative-free nonlinear Kalman Filters (KFs): the Unscented Kalman Filter (UKF), the Cubature Kalman Filter (CKF) and the Transformed Unscented Kalman Filter (TUKF). Here, these three nonlinear probabilistic estimators were compared in terms of the Root Mean Square Error (RMSE) and the average execution time over Monte Carlo simulations. We simulated real-world conditions for our in-production HUAUV prototype using Inertial Measurement Unit (IMU) data and state augmentation for sensor data filtering and trajectory estimation. We have concluded that the CKF proved to be the most interesting KF to low-cost on-board applications for high dimensional state spaces.
ER  - 

TY  - CONF
TI  - Constrained Motion Cueing for Driving Simulators Using a Real-Time Nonlinear MPC Scheme
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7466
EP  - 7471
AU  - A. Lamprecht
AU  - J. Haecker
AU  - K. Graichen
PY  - 2018
KW  - nonlinear control systems
KW  - optimisation
KW  - predictive control
KW  - road traffic control
KW  - real-time nonlinear MPC scheme
KW  - motion cueing algorithm
KW  - MCA
KW  - nonlinear model predictive control
KW  - realistic motion feeling
KW  - realtime gradient algorithm
KW  - augmented Lagrangian method
KW  - constrained motion cueing
KW  - driving simulators
KW  - Acceleration
KW  - Fasteners
KW  - Real-time systems
KW  - Trajectory
KW  - Vehicles
KW  - Software algorithms
KW  - Minimization
DO  - 10.1109/IROS.2018.8594246
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This contribution presents a motion cueing algorithm (MCA) for driving simulators using nonlinear model predictive control (MPC). The goal of the MCA is to generate a realistic motion feeling while keeping the simulator within its workspace limits. The approach relies on a realtime gradient algorithm in combination with the augmented Lagrangian method in order to directly incorporate the system constraints into the optimization. Simulation results for a reference trajectory with typical driving situations demonstrate the performance as well as the computational efficiency of the approach.
ER  - 

TY  - CONF
TI  - Robust Humanoid Control Using a QP Solver with Integral Gains
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7472
EP  - 7479
AU  - R. Cisneros
AU  - M. Benallegue
AU  - A. Benallegue
AU  - M. Morisawa
AU  - H. Audren
AU  - P. Gergondet
AU  - A. Escande
AU  - A. Kheddar
AU  - F. Kanehiro
PY  - 2018
KW  - humanoid robots
KW  - Lyapunov methods
KW  - quadratic programming
KW  - robot dynamics
KW  - robust control
KW  - torque control
KW  - low-frequency bounded disturbances
KW  - Lyapunov-stable torque control
KW  - dynamical model
KW  - dynamic constraints
KW  - QP solver
KW  - kinetic joint friction
KW  - robust humanoid control
KW  - torque controlled humanoid robots
KW  - multiobjective weighted tasks
KW  - optimal dynamically-feasible reference
KW  - exponential convergence
KW  - joint torque feedback
KW  - nonmodelled torque bias
KW  - quadratic programming
KW  - HRP-5P robot
KW  - Torque
KW  - Humanoid robots
KW  - Convergence
KW  - Acceleration
KW  - Torque control
KW  - Task analysis
KW  - Robust control
KW  - Torque control
KW  - Passivity
KW  - Quadratic programming
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8593417
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.
ER  - 

TY  - CONF
TI  - Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7480
EP  - 7485
AU  - D. Kim
AU  - Y. Park
PY  - 2018
KW  - intelligent sensors
KW  - nearest neighbour methods
KW  - recurrent neural nets
KW  - skin
KW  - tactile sensors
KW  - recurrent neural network
KW  - Preisach model
KW  - multiple contact locations
KW  - k-nearest neighbors algorithm
KW  - artificial neural network
KW  - machine learning techniques
KW  - soft robotics applications
KW  - soft artificial skin sensors
KW  - artificial intelligence
KW  - soft tactile sensors
KW  - Sensors
KW  - Force
KW  - Hysteresis
KW  - Microchannels
KW  - Estimation
KW  - Wires
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593440
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.
ER  - 

TY  - CONF
TI  - A Biomimetic Soft Robot for Inspecting Pipeline with Significant Diameter Variation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7486
EP  - 7491
AU  - X. Zhang
AU  - T. Pan
AU  - H. L. Heung
AU  - P. W. Y. Chiu
AU  - Z. Li
PY  - 2018
KW  - biomimetics
KW  - diseases
KW  - industrial robots
KW  - inspection
KW  - pipelines
KW  - central pattern generator-based control system
KW  - pipeline inspection robots
KW  - earthworm-like soft robot
KW  - CPG-based control system
KW  - pipeline navigation
KW  - gastrointestinal tract inspection
KW  - tubular environment
KW  - biomimetic soft robot
KW  - Pipelines
KW  - Inspection
KW  - Actuators
KW  - Soft robotics
KW  - Mobile robots
KW  - Valves
DO  - 10.1109/IROS.2018.8594390
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Navigation through tubular environment is fundamental in tasks such as pipeline inspection, gastrointestinal tract inspection, etc. Conventional pipeline inspection robots are mostly made by rigid materials and could not well adapt to the large size variation of the environment. Soft robots provide an additional solution for inspection of pipelines, especially with significant size variation. In this work, we present a soft robot for pipeline inspection, which consists of an earthworm-like soft robot and a Central Pattern Generator (CPG)-based control system. An analytical model is developed to predict the maximum pipe diameter that the robot could adapt to. For the current prototype, the robot could adapt to size change of three times. Experimental results show that this robot could navigate through pipelines with sharp turnings and with large diameter change.
ER  - 

TY  - CONF
TI  - Continuum Manipulator with Redundant Backbones and Constrained Bending Curvature for Continuously Variable Stiffness
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7492
EP  - 7499
AU  - B. Zhao
AU  - W. Zhang
AU  - Z. Zhang
AU  - X. Zhu
AU  - K. Xu
PY  - 2018
KW  - bending
KW  - design engineering
KW  - elasticity
KW  - medical robotics
KW  - redundant manipulators
KW  - continuously constrained bending curvature
KW  - hyper-redundant articulated vertebrate structure
KW  - slender manipulators
KW  - surgical robots
KW  - snake-like manipulators
KW  - continuously variable stiffness
KW  - redundant backbones
KW  - redundantly arranged elastic backbones
KW  - simple continuum manipulator design
KW  - Manipulators
KW  - Electron tubes
KW  - Kinematics
KW  - Friction
KW  - Tendons
KW  - Strips
KW  - Lead
DO  - 10.1109/IROS.2018.8593437
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Snake-like manipulators can navigate and perform manipulation in confined spaces. Their recent implementations in surgical robots attracted a lot of attentions. These slender manipulators usually possess either a hyper-redundant articulated vertebrate structure or a continuum one. Primary design considerations usually converge to a balance between proper workspace and acceptable stiffness. Efforts have hence been constantly made to achieve higher or adjustable stiffness for a manipulator to widen its applications. This paper presents a simple continuum manipulator design with variable stiffness based on redundantly arranged elastic backbones and continuously constrained bending curvature. The design concepts, kinematics, a preliminary formulation for stiffness adjustment, system construction and experimental characterizations are elaborated. The results showed that the manipulator's stiffness can be increased up to 4.71 times of the value without the curvature constraining rod, indicating the efficacy of the proposed idea.
ER  - 

TY  - CONF
TI  - A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7500
EP  - 7506
AU  - A. Benouhiba
AU  - K. Rabenorosoa
AU  - P. Rougeot
AU  - M. Ouisse
AU  - N. Andreff
PY  - 2018
KW  - cantilevers
KW  - electroactive polymer actuators
KW  - manipulator kinematics
KW  - polymers
KW  - millicontinuum soft robots
KW  - active flexible polymer actuator
KW  - multisegment robot
KW  - 3D arrangement
KW  - robot capability
KW  - three-segment CSR
KW  - two-segment CSR
KW  - single segment robot
KW  - multiphysics model
KW  - millimeter-size Continuum Soft Robot
KW  - multisegment electro-active polymer
KW  - Strain
KW  - Nonhomogeneous media
KW  - Soft robotics
KW  - Fabrication
KW  - Deformable models
KW  - Microactuators
DO  - 10.1109/IROS.2018.8593609
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.
ER  - 

TY  - CONF
TI  - A Compact Wheeled Robot that Can Jump while Rolling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7507
EP  - 7512
AU  - K. Misu
AU  - A. Yoshii
AU  - H. Mochiyama
PY  - 2018
KW  - buckling
KW  - elasticity
KW  - mobile robots
KW  - robot dynamics
KW  - strips
KW  - wheels
KW  - elastic strip
KW  - snap-through buckling
KW  - jumping angle
KW  - jumping mechanism
KW  - wheels
KW  - robot jumping
KW  - animals jump
KW  - rolling
KW  - compact wheeled robot
KW  - Mobile robots
KW  - Strips
KW  - Blades
KW  - Wheels
KW  - Force
KW  - Steel
DO  - 10.1109/IROS.2018.8593895
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we study a compact wheeled robot that can jump while rolling. Some robots are capable of jumping or rolling, but as far as we know, those robots are not focused on jumping while rolling. We know that animals jump while running to escape from predators. Robots can move quickly by jumping while rolling. We consider a model of a robot jumping while rolling and evaluate the proposed robot. The proposed robot has two wheels and a jumping mechanism based on snap-through buckling of an elastic strip. The proposed robot can jump about 5.9 cm high and 22 cm wide on average while maintaining a traveling speed of about 1.2 m/s. The proposed robot can change the jumping angle without greatly decreasing the impulse for the moving speed.
ER  - 

TY  - CONF
TI  - Soft LEGO: Bottom-Up Design Platform for Soft Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7513
EP  - 7520
AU  - J. Lee
AU  - J. Eom
AU  - W. Choi
AU  - K. Cho
PY  - 2018
KW  - assembling
KW  - bending
KW  - design engineering
KW  - finite element analysis
KW  - grippers
KW  - mobile robots
KW  - pneumatic actuators
KW  - rapid prototyping (industrial)
KW  - Taguchi methods
KW  - three-dimensional printing
KW  - soft LEGO bricks
KW  - soft robotics
KW  - pneumatically inflatable soft brick
KW  - assembled soft bricks
KW  - bottom-up design platform
KW  - flexible bending brick
KW  - air channel brick
KW  - Taguchi method
KW  - finite-element analysis
KW  - multimaterial 3-dimensional printer
KW  - Soft robotics
KW  - Hoses
KW  - Actuators
KW  - Pins
KW  - Toy manufacturing industry
KW  - Joining processes
DO  - 10.1109/IROS.2018.8593546
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.
ER  - 

TY  - CONF
TI  - Soft Snake Robots: Investigating the Effects of Gait Parameters on Locomotion in Complex Terrains
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Branyan
AU  - Y. Menğüç
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - gait-curvature combination
KW  - half-activation gait
KW  - soft robot
KW  - soft-bodied robots
KW  - locomotion strategies
KW  - compliant materials
KW  - complex terrains
KW  - gait parameters
KW  - soft snake robot
KW  - Actuators
KW  - Soft robotics
KW  - Snake robots
KW  - Navigation
KW  - Friction
KW  - Solenoids
DO  - 10.1109/IROS.2018.8593404
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Compliant materials used to create soft robots can better replicate biological structures than typical rigid materials. We can look to nature for developing locomotion strategies for these soft-bodied robots. In this work, snakes were used as inspiration to create an inextensible, soft robot which was used as a platform to test gaits in terrain composed of granular media ranging from fine sand to stone. Snakes vary the speed and amplitude of the traveling wave used in lateral undulation to navigate different environments. We used these gait parameters to develop and test a set of custom gaits that varied the phase offset of the sequence of waves as well as using the best performing gait to test how the amplitude of the wave effects locomotion over the selected terrains. These tests provide preliminary evidence that altering these parameters effects the robot's ability to traverse different terrains. The developed robot is also tested in environments specific to applications for snake robots to show how a soft snake robot can be potentially more effective in these environment. The highest performing gait-curvature combination was the half-activation gait (where the back actuator was activated half as long as the front)with a 135° swept angle. It reached a velocity of 2.2 mm/s or 0.011 body-lengths/s on paper, which was the best performing terrain.
ER  - 

TY  - CONF
TI  - Inverse Error Function Trajectories for Image Reconstruction*This material is based upon work supported by the National Science Foundation under Grant No. 1662029
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7527
EP  - 7532
AU  - R. Katoch
AU  - B. Fusaro
AU  - J. Ueda
PY  - 2018
KW  - cameras
KW  - error analysis
KW  - Gaussian processes
KW  - image motion analysis
KW  - image restoration
KW  - mobile robots
KW  - optical transfer function
KW  - inverse error function trajectories
KW  - image reconstruction
KW  - mobile robots
KW  - visual stimuli
KW  - camera trajectories
KW  - camera motion
KW  - motion blur effects
KW  - image quality
KW  - Gaussian blur kernel
KW  - image capturing
KW  - linear error
KW  - polynomial error
KW  - time analysis
KW  - point-spread function
KW  - Trajectory
KW  - Cameras
KW  - Image reconstruction
KW  - Robot vision systems
KW  - Optical imaging
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8594315
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Capturing clear images while a camera is moving fast, is integral to the development of mobile robots that can respond quickly and effectively to visual stimuli. This paper proposes to generate camera trajectories, with position and time constraints, that result in higher reconstructed image quality. The degradation in of an image captured during motion is known as motion blur. Three main methods exist for mitigating the effects of motion blur: (i) controlling optical parameters, (ii) controlling camera motion, and (iii) image reconstruction. Given control of a camera's motion, trajectories can be generated that result in an expected blur kernel or point-spread function. This work compares the motion blur effects and reconstructed image quality of three trajectories: (i) linear, (ii) polynomial, and (iii) inverse error. Where inverse error trajectories result in Gaussian blur kernels. Residence time analysis provides a basis for characterizing the motion blur effects of the trajectories.
ER  - 

TY  - CONF
TI  - Faster Collision Checks for Car-Like Robot Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7533
EP  - 7538
AU  - B. C. Heinrich
AU  - D. Fassbender
AU  - H. Wuensche
PY  - 2018
KW  - collision avoidance
KW  - geometry
KW  - mobile robots
KW  - motion control
KW  - rear disc
KW  - faster collision checks
KW  - system knowledge
KW  - nonholonomic motion
KW  - motion planning
KW  - frontal disc
KW  - car-like robot motion planning
KW  - predictive algorithm
KW  - Collision avoidance
KW  - Trajectory
KW  - Shape
KW  - Planning
KW  - Robot kinematics
KW  - Tuning
DO  - 10.1109/IROS.2018.8594454
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe how collision checking for car-like robots can be sped up utilizing system knowledge. Their non-holonomic motion, while being a challenge for motion planning, is utilized here to place discs which are used as an approximation of the robot's shape in a predictive manner. For ease of comparison, we assume the robot to be rectangular, i. e., we use bounding boxes. Our algorithm is compared to a widely-used baseline and shows similar performance in terms of under- and oversampling while being approximately 20-40 % faster. Another feature of the algorithm is its predictive nature: with the frontal disc, we already check for collisions that would occur with the rear disc in the next sample, assuming near-constant curvature. While this might be conservative in some cases where large steering rates are necessary, in our evaluation even tight corridors could be navigated without negative effects.
ER  - 

TY  - CONF
TI  - C-MPDM: Continuously-Parameterized Risk-Aware MPDM by Quickly Discovering Contextual Policies
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7547
EP  - 7554
AU  - D. Mehta
AU  - G. Ferrer
AU  - E. Olson
PY  - 2018
KW  - decision making
KW  - gradient methods
KW  - operations research
KW  - optimisation
KW  - continuously-parameterized risk-aware MPDM
KW  - on-line forward roll-out process
KW  - computational cost
KW  - continuous-valued parameters
KW  - iterative gradient-based algorithm
KW  - multipolicy decision making systems
KW  - social environment
KW  - promising policy parameters
KW  - contextual policies
KW  - Robots
KW  - Cost function
KW  - Real-time systems
KW  - Trajectory
KW  - Decision making
KW  - Backpropagation
DO  - 10.1109/IROS.2018.8593642
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Risk-aware Multi-Policy Decision Making (MPDM)is a powerful framework for reliable navigation in a dynamic social environment where rather than evaluating individual trajectories, a “library” of policies (reactive controllers)is evaluated by anticipating potentially dangerous future outcomes using an on-line forward roll-out process. There is a core tension in Multi-Policy Decision Making (MPDM)systems - it is desirable to add more policies to the system for flexibility in finding good policies, however, this increases computational cost. As a result, MPDM was limited to small (perhaps 5-10)discrete policies - a significant performance bottleneck. In this paper, we radically enhance the expressivity of MPDM by allowing policies to have continuous-valued parameters, while simultaneously satisfying real-time constraints by quickly discovering promising policy parameters through a novel iterative gradient-based algorithm. Our evaluation includes results from extensive simulation and real-world experiments in semi-crowded environments.
ER  - 

TY  - CONF
TI  - Skating with a Force Controlled Quadrupedal Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7555
EP  - 7561
AU  - M. Bjelonic
AU  - C. Dario Bellicoso
AU  - M. Efe Tiryaki
AU  - M. Hutter
PY  - 2018
KW  - end effectors
KW  - force control
KW  - legged locomotion
KW  - locomotives
KW  - motion control
KW  - robot dynamics
KW  - torque control
KW  - wheels
KW  - motion planner
KW  - legged robot
KW  - gliding motions
KW  - Virtual Model Controller
KW  - optimal contact force distribution
KW  - torque-controllable robot ANY mal
KW  - passive wheels
KW  - ice skates
KW  - flat terrain
KW  - inclined terrain
KW  - skating motions
KW  - force controlled quadrupedal robot
KW  - wheeled systems
KW  - flat environments
KW  - locomotion domains
KW  - end-effectors
KW  - motion controller
KW  - Legged locomotion
KW  - Force
KW  - Torso
KW  - Wheels
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594504
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Traditional legged robots are capable of traversing challenging terrain, but lack of energy efficiency when compared to wheeled systems operating on flat environments. The combination of both locomotion domains overcomes the trade-off between mobility and efficiency. Therefore, this paper presents a novel motion planner and controller which together enable a legged robot equipped with skates to perform skating maneuvers. These are achieved by an appropriate combination of planned reaction forces and gliding motions. Our novel motion controller formulates a Virtual Model Controller and an optimal contact force distribution which takes into account the nonholonomic constraints introduced by the skates. This approach has been tested on the torque-controllable robot ANY mal equipped with passive wheels and ice skates as end-effectors. We conducted experiments on flat and inclined terrain, whereby we show that skating motions reduces the cost of transport by up to 80 % with respect to traditional walking gaits.
ER  - 

TY  - CONF
TI  - A Comparative Analysis of Contact Models in Trajectory Optimization for Manipulation*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. O. Onol
AU  - P. Long
AU  - T. Padlr
PY  - 2018
KW  - manipulators
KW  - optimisation
KW  - manipulation
KW  - contact-implicit trajectory optimization
KW  - variable smooth contact model
KW  - optimization process
KW  - Task analysis
KW  - Robots
KW  - Force
KW  - Trajectory optimization
KW  - Computational modeling
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594284
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We consider three different approaches: (1)a contact model that is based on complementarity constraints, (2)a smooth contact model, and our proposed method (3) a variable smooth contact model. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time. In each case, the optimization process is initialized by setting all torque variables to zero, namely, without a meaningful initial guess. For simulations, we consider a pushing task with varying complexity for a 7 degrees-of-freedom robot arm. Our results demonstrate that the optimization based on the proposed variable smooth contact model provides a good trade-off between the physical fidelity and quality of motions at the cost of increased computation time.
ER  - 

TY  - CONF
TI  - Combining Method of Alternating Projections and Augmented Lagrangian for Task Constrained Trajectory Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7568
EP  - 7575
AU  - A. Kumar Singh
AU  - R. Ghabcheloo
AU  - A. Muller
AU  - H. Pandya
PY  - 2018
KW  - collision avoidance
KW  - convex programming
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - similar nature trajectory
KW  - off-the-shelf nonlinear solver
KW  - similar task constraint residuals
KW  - SciPy alternative
KW  - alternating projections
KW  - Augmented Lagrangian
KW  - task constrained trajectory optimization
KW  - task space constraints
KW  - joint configurations
KW  - implicitly defined manifold
KW  - task constrained motion planning
KW  - optimization problem
KW  - nonlinear equality constraints
KW  - nonlinear optimization techniques
KW  - custom optimizer
KW  - task constraints
KW  - efficient convex optimization
KW  - feasible solution
KW  - common robotic benchmark problems
KW  - cyclic motion
KW  - joint space
KW  - Task analysis
KW  - Planning
KW  - Trajectory optimization
KW  - Cost function
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593557
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning for manipulators under task space constraints is difficult as it constrains the joint configurations to always lie on an implicitly defined manifold. It is possible to view task constrained motion planning as an optimization problem with non-linear equality constraints, which can be solved by general non-linear optimization techniques. In this paper, we present a novel custom optimizer which exploits the underlying structure present in many task constraints. At the core of our approach are some simple reformulations, which when coupled with the method of alternating projection, leads to an efficient convex optimization based routine for computing a feasible solution to the task constraints. We subsequently build on this result and use the concept of Augmented Lagrangian to guide the feasible solutions towards those that also minimize the user defined cost function. We show that the proposed optimizer is fully distributive and thus, can be easily parallelized. We validate our formulation on some common robotic benchmark problems. In particular, we show that the proposed optimizer achieves cyclic motion in the joint space corresponding to a similar nature trajectory in the task space. Furthermore, as a baseline, we compare the proposed optimizer with an off-the-shelf non-linear solver provide in open source package SciPy. We show that for similar task constraint residuals and smoothness cost, it can be upto more than three times faster than the SciPy alternative.
ER  - 

TY  - CONF
TI  - A Software Framework for Planning Under Partial Observability
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Hoerger
AU  - H. Kurniawati
AU  - A. Elfes
PY  - 2018
KW  - application program interfaces
KW  - decision theory
KW  - Markov processes
KW  - mobile robots
KW  - path planning
KW  - planning (artificial intelligence)
KW  - software tools
KW  - robotics tasks
KW  - software tools
KW  - software toolkit
KW  - POMDP solvers
KW  - robot motion planning
KW  - partial observability problems
KW  - software framework
KW  - reliable robot operation
KW  - partially observable Markov decision process
KW  - abstract solver API
KW  - online POMDP planning toolkit
KW  - OPPT
KW  - Planning
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Observability
KW  - Computer architecture
KW  - Standards
DO  - 10.1109/IROS.2018.8593714
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.
ER  - 

TY  - CONF
TI  - Adaptive Path Following of Snake Robot on Ground with Unknown and Varied Friction Coefficients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7583
EP  - 7588
AU  - G. Wang
AU  - W. Yang
AU  - Y. Shen
AU  - H. Shao
PY  - 2018
KW  - adaptive control
KW  - control nonlinearities
KW  - control system synthesis
KW  - friction
KW  - mobile robots
KW  - motion control
KW  - parameter estimation
KW  - varied friction coefficients
KW  - underactuated bio-inspired snake robots
KW  - adaptive controller
KW  - 8-link snake robot
KW  - adaptive path following
KW  - backstepping technique
KW  - parameter estimation
KW  - control design input
KW  - LaSalle-Yoshizawa theorem
KW  - Snake robots
KW  - Friction
KW  - Tuning
KW  - Backstepping
KW  - Adaptation models
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8594466
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates the straight path following problem for a class of underactuated bio-inspired snake robots on ground with unknown and varied friction coefficients. Existing works usually design control input requiring the exact values of these friction coefficients, which however rely on the specific operating terrain and may not always be known a priori. By virtue of backstepping technique, we present a novel adaptive controller that can compensate for unknown and varied friction coefficients in real-time. Moreover, it is proved via LaSalle-Yoshizawa theorem that the path following errors converge to zero asymptotically and all the parameter estimates are bounded. Simulations and experiments on an 8-link snake robot are carried out to illustrate the effectiveness of the proposed controller.
ER  - 

TY  - CONF
TI  - Analytical Model of Thermal Soaring: Towards Energy Efficient Path Planning for Flying Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7589
EP  - 7594
AU  - J. Khaghani
AU  - M. Nekoui
AU  - R. Nasiri
AU  - M. N. Ahmadabadi
PY  - 2018
KW  - aerospace robotics
KW  - biomimetics
KW  - continuous systems
KW  - discrete systems
KW  - mobile robots
KW  - path planning
KW  - simple hybrid control strategy
KW  - flying robot
KW  - energy efficient flying
KW  - thermal soaring behavior
KW  - energy efficient locomotion types
KW  - flying animals
KW  - energy efficient path planning
KW  - Mathematical model
KW  - Birds
KW  - Thermal loading
KW  - Analytical models
KW  - Robots
KW  - Aerodynamics
KW  - Thermal variables control
KW  - Bio-inspired model
KW  - Thermal soaring
KW  - Path planning
KW  - Flying locomotion
KW  - Hybrid controller
DO  - 10.1109/IROS.2018.8593907
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Developing analytical models of efficient locomotion in biology is one of the most interesting goals in bio- inspired robotics. This paper presents a mathematical framework in order to model one of the most energy efficient locomotion types in flying animals; i.e., thermal soaring. Unlike the legged locomotion, in flying, modeling the environmental effects on animals' behaviors is very important. In doing so, we develop our model by assuming thermals as bubbles of rising air. According to pieces of real evidence, this kind of modeling is more compatible with the nature of thermal soaring. Moreover, we present a simple hybrid control strategy for obtaining the optimal path in order to maximize benefit from the updraft of air-flow. By using this control strategy, the flying robot can plan a path for traveling between thermals without flapping; i.e., energy efficient flying. So as to investigate the compatibility of presented model and controller with reality, we set their parameters based on the biological evidences. As a result, in simulations, it is observed that the generated flying behavior is comparable with the thermal soaring behavior of real birds. This observation provides a confirmation for generality and applicability of the presented approach.
ER  - 

TY  - CONF
TI  - Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7595
EP  - 7600
AU  - Y. Yalikun
AU  - Y. Noguchi
AU  - N. Kamamichi
AU  - Y. Tanaka
PY  - 2018
KW  - microactuators
KW  - microrobots
KW  - mobile robots
KW  - muscle
KW  - robot dynamics
KW  - stimulation frequency
KW  - atmospheric-operable walking robot
KW  - maximum walking speed
KW  - bio actuated walker
KW  - biological microbio-actuator
KW  - grants-in-aid
KW  - output force
KW  - stimulation voltage
KW  - muscle-tissue of earthworm
KW  - Japan society
KW  - atmospheric-operable 3d printed walking bio-robot
KW  - control property
KW  - Legged locomotion
KW  - Force
KW  - Muscles
KW  - Actuators
KW  - Strain measurement
KW  - Force measurement
DO  - 10.1109/IROS.2018.8594343
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.
ER  - 

TY  - CONF
TI  - PiRat: An Autonomous Framework for Studying Social Behaviour in Rats and Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7601
EP  - 7608
AU  - S. Heath
AU  - C. A. Ramirez-Brinez
AU  - J. Arnold
AU  - O. Olsson
AU  - J. Taufatofua
AU  - P. Pounds
AU  - J. Wiles
AU  - E. Leonardis
AU  - E. Gygi
AU  - E. Leija
AU  - L. K. Quinn
AU  - A. A. Chiba
PY  - 2018
KW  - mobile robots
KW  - position control
KW  - social stimulus
KW  - rat-robot studies
KW  - social behaviour
KW  - rat-robot interaction studies
KW  - novel rat-sized robot
KW  - PiRat
KW  - robotic behavior
KW  - robot rat
KW  - reproducible behaviour
KW  - closed-loop rat-robot framework
KW  - autonomous framework
KW  - Rats
KW  - Robot sensing systems
KW  - Brushless DC motors
DO  - 10.1109/IROS.2018.8594060
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of robots, as a social stimulus, provides several advantages over using another animal. In particular, for rat-robot studies, robots can produce social behaviour that is reproducible across trials. In the current work, we outline a framework for rat-robot interaction studies, that consists of a novel rat-sized robot (PiRat), models of robotic behavior, and a position tracking system for both robot and rat. We present the design of the framework, including constraints on autonomy, latency, and control. We pilot tested our framework by individually running the robot rat with eight different rats, first through a habituation stage, and then with PiRat performing two different types of behaviour - avoiding and frequently approaching. We evaluate the performance of the framework on latency and autonomy, and on the ability to influence the behaviour of individual rats. We find that the framework performs well on its constraints, engages some of the rats (according to the number of meetings), and features a control scheme that produces reproducible behaviour in rats. These features represent a first demonstration of a closed-loop rat-robot framework.
ER  - 

TY  - CONF
TI  - Tarzan: Design, Prototyping, and Testing of a Wire-Borne Brachiating Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7609
EP  - 7614
AU  - E. Davies
AU  - A. Garlow
AU  - S. Farzan
AU  - J. Rogers
AU  - A. Hu
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - swing-up maneuver
KW  - distributed electronics packages
KW  - brachiating robot design
KW  - prototype robot
KW  - remote sensing packages
KW  - payload mounting point
KW  - minimal power consumption
KW  - locking hand design
KW  - ladder brachiation modes
KW  - parallel wires
KW  - elevated wire networks
KW  - wire-borne brachiating robot
KW  - ladder locomotion modes
KW  - Wires
KW  - Grippers
KW  - Wrist
KW  - Thumb
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593823
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A novel brachiating robot design is presented for the purpose of traversing elevated wire networks. The robot is capable of moving along a single wire and between parallel wires, thereby enabling traversal of a two-dimensional space. Several novel features distinguish this design compared to previous brachiating robots. These include the ability to transition to and from both “rope” and “ladder” brachiation modes through an integrated wrist, a locking hand design for minimal power consumption, and distributed electronics packages that communicate wirelessly. A payload mounting point is installed, offering space for a variety of remote sensing packages. Experimental results using a prototype robot demonstrate that the system can reliably brachiate along a single wire, and can also reliably perform a swing-up maneuver after failed swing attempts or when transitioning between the rope and ladder locomotion modes. Energy expenditure for a single swing is quantified using experimental data. Overall, the proposed robot design is shown to provide a promising platform for traversal of wire networks in two dimensions.
ER  - 

TY  - CONF
TI  - Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7622
EP  - 7627
AU  - P. Čížek
AU  - J. Kubík
AU  - J. Faigl
PY  - 2018
KW  - accelerometers
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - terrain mapping
KW  - interrupt mode
KW  - hexapod walking robot
KW  - inertial measurements
KW  - multilegged walking robots
KW  - proprioceptive terrain sensing
KW  - terrain irregularities
KW  - inertial data
KW  - online foot strike detection
KW  - foot strike event detector
KW  - data processing
KW  - accelerometers
KW  - terrain traversal
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Accelerometers
KW  - Servomotors
KW  - Reliability
DO  - 10.1109/IROS.2018.8594010
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.
ER  - 

TY  - CONF
TI  - TacWhiskers: Biomimetic Optical Tactile Whiskered Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7628
EP  - 7634
AU  - N. F. Lepora
AU  - M. Pearson
AU  - L. Cramphorn
PY  - 2018
KW  - biomimetics
KW  - mobile robots
KW  - tactile sensors
KW  - optical cutaneous tactile sensor
KW  - static Tac Whisker array
KW  - immotile tactile vibrissae
KW  - dynamic Tac Whisker array
KW  - dynamic sensor output
KW  - Tac Whiskers
KW  - biomimetic optical tactile whiskered robots
KW  - vibrissal tactile sensor
KW  - 3D-printed optical cutaneous tactile sensor
KW  - TacTip
KW  - active object localization task
KW  - Pins
KW  - Rodents
KW  - Tendons
KW  - Dynamics
KW  - Tactile sensors
DO  - 10.1109/IROS.2018.8593653
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Here we propose and investigate a novel vibrissal tactile sensor - the Tac Whisker array - based on modifying a 3D-printed optical cutaneous (fingertip) tactile sensor - the TacTip. Two versions are considered: a static Tac Whisker array analogous to immotile tactile vibrissae (e.g. rodent microvib-rissae) and a dynamic Tac Whisker array analogous to motile tactile vibrissae (e.g. rodent macrovibrissae). Performance is assessed on an active object localization task. The whisking motion of the dynamic Tac Whisker leads to millimetre-scale location perception, whereas perception with the static Tac Whisker array is relatively poor when making dabbing contacts. The dynamic sensor output is dominated by a self-generated motion signal, which can be compensated by comparing to a reference signal. Overall, the Tac Whisker arrays give a new class of tactile whiskered robots that benefit from being relatively inexpensive and customizable. Furthermore, the biomimetic basis for the Tac Whiskers fits well with building an embodied model of the rodent sensory system for investigating animal perception.
ER  - 

TY  - CONF
TI  - Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7635
EP  - 7640
AU  - Z. Yan
AU  - L. Sun
AU  - T. Duckctr
AU  - N. Bellotto
PY  - 2018
KW  - image classification
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - probability
KW  - radar tracking
KW  - robot vision
KW  - service robots
KW  - stereo image processing
KW  - online transfer learning
KW  - 3D LiDAR-based human detection
KW  - mobile robot
KW  - service robots
KW  - multisensor tracking system
KW  - 2D LiDAR
KW  - human trajectory
KW  - 3D LiDAR-based human classification
KW  - trajectory probability
KW  - RGB-D camera
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Detectors
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8593899
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.
ER  - 

TY  - CONF
TI  - An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - Y. Furuta
AU  - K. Okada
AU  - Y. Kakiuchi
AU  - M. Inaba
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - robot agent
KW  - local-rule-aware home assistive tasks
KW  - semantic map
KW  - long-term episodic memory
KW  - home environments
KW  - global society
KW  - probabilistic object localization map
KW  - Fetch robots
KW  - semantic common knowledge
KW  - PR2 robot
KW  - robotic system
KW  - time 41.0 d
KW  - Task analysis
KW  - Probabilistic logic
KW  - Semantics
KW  - Planning
KW  - Robot sensing systems
KW  - Solid modeling
KW  - Service Robots
KW  - Learning and Adaptive Systems
KW  - Big Data in Robotics and Automation
DO  - 10.1109/IROS.2018.8594481
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.
ER  - 

TY  - CONF
TI  - Dynamic Dumbbell - Novel Muscle Training Robot with Programmable Exercise Load
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Lee
AU  - S. Oh
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - force control
KW  - gears
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - high performance force control algorithm
KW  - rotary series elastic actuator
KW  - planetary-geared elastic actuator
KW  - mechanical engineering
KW  - muscle training robot
KW  - exercise load model
KW  - advanced muscular exercise
KW  - Dynamic Dumbbell
KW  - programmable exercise load
KW  - Dynamic dumbbell
KW  - Dynamics
KW  - Muscles
KW  - Torque
KW  - Robots
KW  - Force
KW  - Load modeling
KW  - Gears
DO  - 10.1109/IROS.2018.8593779
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, Dynamic Dumbbell, a novel robotic device for advanced muscular exercise of upper limb is presented. The type of exercise load is classified and designed in terms of mechanical engineering to be implemented in Dynamic Dumbbell. The exercise load model, which is named as programmable exercise load, is realized by Dynamic Dumbbell. To generate the programmable exercise load, two of compact Planetary-geared Elastic Actuator, which is a rotary Series Elastic Actuator (SEA), are utilized in Dynamic Dumbbell. The SEAs are controlled using high performance force control algorithm. Experimental results verifies the effectiveness of the proposed Dynamic Dumbbell and programmable exercise load.
ER  - 

TY  - CONF
TI  - Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7654
EP  - 7659
AU  - Y. Kawasaki
AU  - A. Yorozu
AU  - M. Takahashi
PY  - 2018
KW  - human-robot interaction
KW  - image recognition
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - sensors
KW  - path-planning
KW  - sensor characteristics
KW  - autonomous navigation
KW  - sensor data
KW  - human recognition reliability
KW  - human-robot interaction
KW  - multiple people
KW  - initiate interaction
KW  - multimodal potential field
KW  - Robot sensing systems
KW  - Reliability
KW  - Task analysis
KW  - Character recognition
KW  - Robot kinematics
KW  - Cameras
DO  - 10.1109/IROS.2018.8594289
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.
ER  - 

TY  - CONF
TI  - Estimating Door Shape and Manipulation Model for Daily Assistive Robots Based on the Integration of Visual and Touch Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7660
EP  - 7666
AU  - K. Nagahama
AU  - K. Takeshita
AU  - H. Yaguchi
AU  - K. Yamazaki
AU  - T. Yamamoto
AU  - M. Inaba
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - service robots
KW  - visual touch information
KW  - door manipulation
KW  - door candidates
KW  - target door
KW  - appropriate shape
KW  - single click
KW  - single user instruction
KW  - unknown door
KW  - daily assistive robots
KW  - manipulation model
KW  - door shape
KW  - Shape
KW  - Robot kinematics
KW  - Trajectory
KW  - Visualization
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593391
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a method for a robot to manipulate an unknown door based on a single user instruction. The primary contributions of this paper are (i) to reduce the user instruction to a single click and (ii) to develop an efficient method to estimate an appropriate shape and manipulation model for a target door by integrating visual and touch information obtained by a robot. The proposed method first detects door candidates using a 3-D camera and then estimates the manipulation model of each candidate based on prior learning results. During door manipulation, the system integrates visual and touch information to estimate the shape and manipulation model to generate an appropriate motion. We evaluated the proposed method experimentally, and the results prove that the proposed method is effective.
ER  - 

TY  - CONF
TI  - Designing for Robust Movement in a Child-Friendly Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7667
EP  - 7674
AU  - J. Taufatofua
AU  - S. Heath
AU  - C. A. Ramirez-Brinez
AU  - K. Sommer
AU  - G. Durantin
AU  - W. Kong
AU  - J. Wiles
AU  - P. Pounds
PY  - 2018
KW  - design
KW  - humanoid robots
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - safety
KW  - torque-limited stepper motors
KW  - robotic agents
KW  - social interaction
KW  - mechanical features
KW  - child-friendly robot
KW  - social robot
KW  - mechanical design
KW  - torso-mounted
KW  - back-drivable
KW  - Safety
KW  - Manipulators
KW  - Actuators
KW  - Prototypes
KW  - Torque
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593414
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion is a critical aspect of communication, required to create natural interactions between humans and robots. Robots for the classroom pose several constraints on motion, which make them challenging to design, including maintaining the safety of the child and the robot, responding in a timely fashion, and creating motions that are expressive and not scary. In this paper we present the mechanical design of a social robot and demonstrate that it is capable of safe motion within the proximity of children through analysis and empirical testing of the arms. The robot has a novel mechanical design for its two arms, which include torso-mounted, back-drivable, torque-limited stepper motors. The results suggest that our design succeeds at increasing safety levels while enabling the use of socially acceptable speeds of motion during the interaction. This study implies that the design of robotic agents for social interaction with children should consider the design of mechanical features that enable safe contact between the human and the robot while not limiting the robot to slow motions that would impair the timing of the interaction.
ER  - 

TY  - CONF
TI  - Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7675
EP  - 7682
AU  - T. Yamamoto
AU  - K. Terada
AU  - A. Ochiai
AU  - F. Saito
AU  - Y. Asahara
AU  - K. Murase
PY  - 2018
KW  - home computing
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - wheels
KW  - international competition
KW  - aging population
KW  - intelligent sensing
KW  - household work
KW  - actual home environment
KW  - HSR users
KW  - technical knowledge
KW  - standard platform
KW  - international robot competitions
KW  - HSR's development background
KW  - omnidirectional mobile base
KW  - domestic mobile manipulator
KW  - human support robot
KW  - whole body motion control system
KW  - field test
KW  - quality of life
KW  - intelligent software
KW  - World Robot Summit
KW  - dual-wheel caster-drive mechanism
KW  - RoboCup@Home
KW  - HSR's operational movement
KW  - Robot kinematics
KW  - Manipulators
KW  - Task analysis
KW  - Sensors
KW  - Software
KW  - Hardware
DO  - 10.1109/IROS.2018.8593798
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.
ER  - 

TY  - CONF
TI  - Robot Artist Performs Cartoon Style Facial Portrait Painting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7683
EP  - 7688
AU  - R. C. Luo
AU  - Y. J. Liu
PY  - 2018
KW  - art
KW  - face recognition
KW  - image colour analysis
KW  - painting
KW  - rendering (computer graphics)
KW  - facial features
KW  - hand-painted strokes
KW  - painting strategy
KW  - basic colors
KW  - eye-in-hand system
KW  - cartoon facial components
KW  - face detection
KW  - human portrait photos
KW  - cartoon style transformation stage
KW  - colorful painting
KW  - stages-cartoon style transformation
KW  - robot cartoonist
KW  - human cartoonist
KW  - visual feedback system
KW  - cartoon stylization painting
KW  - robot artist
KW  - cartoon style facial portrait painting
KW  - face portrait
KW  - Painting
KW  - Image color analysis
KW  - Face
KW  - Shape
KW  - Facial features
KW  - Image segmentation
KW  - Cartoon face
KW  - robot painting
DO  - 10.1109/IROS.2018.8594147
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a face portrait with cartoon stylization painting and associated algorithms with the visual feedback system to paint like a human cartoonist. The robot cartoonist creates the artwork in two stages-cartoon style transformation and robot artist for colorful painting. In the cartoon style transformation stage, it transfers human portrait photos to cartoon style by face detection and alignment, which can effectively decompose the face into individual components then replace by cartoon facial components. In the second stage, the robot uses an eye-in-hand system to obtain five basic colors (cyan, magenta, yellow, white and black) to automatically mix a variety of colors automatically. For painting strategy, we start with the outline of the face, which we use non-photorealistic rendering (NPR) to generate hand-painted strokes. After that, the robot artist will implement painting the facial features. We also demonstrate the success of this proposed research.
ER  - 

TY  - CONF
TI  - Robust Plant Phenotyping via Model-Based Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7689
EP  - 7696
AU  - P. Sodhi
AU  - H. Sun
AU  - B. Póczos
AU  - D. Wettergreen
PY  - 2018
KW  - agriculture
KW  - biology computing
KW  - botany
KW  - crops
KW  - genetic algorithms
KW  - genetics
KW  - industrial plants
KW  - probability
KW  - solid modelling
KW  - robust plant phenotyping
KW  - observable plant traits
KW  - labour intensive error prone
KW  - automated manner
KW  - noninvasive manner
KW  - plant breeding methods
KW  - nonideal sensing conditions
KW  - high throughput plant phenotyping
KW  - state-of-the-art 3D phenotyping algorithms
KW  - hand-tuned parameters
KW  - novel model-based optimization approach
KW  - estimating plant physical traits
KW  - plant units
KW  - plant models
KW  - probability distribution approach
KW  - phenotyping objective
KW  - plant structure
KW  - work furthers field-based robotic phenotyping capabilities
KW  - plant biologists
KW  - crop yields
KW  - Three-dimensional displays
KW  - Imaging
KW  - Optimization
KW  - Robot sensing systems
KW  - Green products
KW  - Image reconstruction
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594245
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Plant phenotyping is the measurement of observable plant traits. Current methods for phenotyping in the field are labour intensive and error prone. High throughput plant phenotyping in an automated and noninvasive manner is crucial to accelerating plant breeding methods. Occlusions and non-ideal sensing conditions is a major problem for high throughput plant phenotyping with most state-of-the-art 3D phenotyping algorithms relying heavily on heuristics or hand-tuned parameters. To address this problem, we present a novel model-based optimization approach for estimating plant physical traits from plant units called phytomers. The proposed approach involves sampling parameterized 3D plant models from an underlying probability distribution. It then optimizes, making the mass of this probability distribution approach true parameters of the model. Reformulating the phenotyping objective as a search in the space of plant models lets us reason about the plant structure in a holistic manner without having to rely on hand-tuned parameters. This makes our approach robust to noise and occlusions as frequently encountered in real world environments. We evaluate our approach for plant units taken across simulated, greenhouse and field environments. This work furthers field-based robotic phenotyping capabilities paving the way for plant biologists to study the coupled effect of genetics and environment on improving crop yields.
ER  - 

TY  - CONF
TI  - Registering Reconstructions of the Two Sides of Fruit Tree Rows
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Roy
AU  - W. Dong
AU  - V. Isler
PY  - 2018
KW  - agricultural products
KW  - feature extraction
KW  - image reconstruction
KW  - image registration
KW  - three dimensionalreconstructions
KW  - reconstruction registeration
KW  - partial reconstructions
KW  - side-views
KW  - measuring traits
KW  - yield mapping
KW  - orchard rows
KW  - fruit tree
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Vegetation
KW  - Principal component analysis
KW  - Shape
KW  - Semantics
KW  - Cameras
DO  - 10.1109/IROS.2018.8594167
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider the problem of building accurate three dimensional (3D)reconstructions of orchard rows. This problem arises in many applications including yield mapping and measuring traits (e.g. trunk diameters)for phenotyping. While 3D reconstructions of side views can be obtained using standard methods, merging the two side-views is difficult due to the lack of overlap between the two partial reconstructions. We present a novel method that utilizes global features to constrain the solution. Specifically, we use information from the silhouettes and the ground plane for alignment. The method is evaluated using multiple simulated and real datasets. For additional information and demonstration of experimental results please see https://www.youtube.com/watch?v=6mGMF2gFv4M.
ER  - 

TY  - CONF
TI  - Design of an Autonomous Precision Pollination Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7711
EP  - 7718
AU  - N. Ohi
AU  - K. Lassak
AU  - R. Watson
AU  - J. Strader
AU  - Y. Du
AU  - C. Yang
AU  - G. Hedrick
AU  - J. Nguyen
AU  - S. Harper
AU  - D. Reynolds
AU  - C. Kilic
AU  - J. Hikes
AU  - S. Mills
AU  - C. Castle
AU  - B. Buzzo
AU  - N. Waterland
AU  - J. Gross
AU  - Y. Park
AU  - X. Li
AU  - Y. Gu
PY  - 2018
KW  - greenhouses
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - precision robotic pollination systems
KW  - natural pollinators
KW  - uniformity
KW  - human population
KW  - ongoing development
KW  - autonomous robot
KW  - BrambleBee
KW  - ecology
KW  - visual perception
KW  - robust autonomous pollination system
KW  - autonomous precision pollination robot
KW  - Cameras
KW  - End effectors
KW  - Agriculture
KW  - Robot vision systems
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594444
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named “BrambleBee”, which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.
ER  - 

TY  - CONF
TI  - Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7727
EP  - 7734
AU  - T. Tourrette
AU  - M. Deremetz
AU  - O. Naud
AU  - R. Lenain
AU  - J. Laneurit
AU  - V. De Rudnicki
PY  - 2018
KW  - agricultural safety
KW  - agriculture
KW  - environmental factors
KW  - hazardous materials
KW  - mobile robots
KW  - off-road vehicles
KW  - soil
KW  - spraying
KW  - ultra wideband technology
KW  - UWB
KW  - Ultra Wide Band technology
KW  - soil compaction
KW  - safety aspects
KW  - chemical products
KW  - human activities
KW  - environmental impact
KW  - autonomous robots
KW  - hazardous products
KW  - agricultural application
KW  - off-road mobile robots
KW  - production levels
KW  - human health
KW  - human operators
KW  - smart spraying
KW  - radio beacons
KW  - Mobile robots
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Spraying
KW  - Agriculture
DO  - 10.1109/IROS.2018.8593978
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.
ER  - 

TY  - CONF
TI  - Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7743
EP  - 7749
AU  - J. Bell
AU  - B. A. MacDonald
AU  - H. SeokAhn
PY  - 2018
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - pedestrians
KW  - road safety
KW  - high visibility clothing
KW  - neural networksresearch
KW  - detection methods
KW  - lidar range data
KW  - lidar intensity data
KW  - lidar sensor
KW  - pedestrian detection
KW  - strong cue
KW  - retro-reflective strips
KW  - contract UOAX1414
KW  - business innovation
KW  - new zealand ministry
KW  - 3D lidar sensors
KW  - industrial environments
KW  - pedestrian safety
KW  - Laser radar
KW  - Safety
KW  - Sensors
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Clothing
KW  - Strips
DO  - 10.1109/IROS.2018.8593835
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.
ER  - 

TY  - CONF
TI  - UNDERWORLDS: Cascading Situation Assessment for Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7750
EP  - 7757
AU  - S. Lemaignan
AU  - Y. Sallami
AU  - C. Wallhridge
AU  - A. Clodic
AU  - T. Belpaeme
AU  - R. Alami
PY  - 2018
KW  - manipulators
KW  - mobile robots
KW  - spatio-temporal situation assessment
KW  - novel lightweight framework
KW  - cascading situation assessment
KW  - temporal granularities
KW  - cascading representations
KW  - temporal events
KW  - real-time distributed data structures
KW  - UNDERWORLDS
KW  - Robots
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Computer architecture
KW  - Tools
KW  - Software
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594094
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We introduce UNDERWORLDS, a novel lightweight framework for cascading spatio-temporal situation assessment in robotics. UNDERWORLDS allows programmers to represent the robot's environment as real-time distributed data structures, containing both scene graphs (for representation of 3D geometries) and timelines (for representation of temporal events). UNDERWORLDS supports cascading representations: the environment is viewed as a set of worlds that can each have different spatial and temporal granularities, and may inherit from each other. UNDERWORLDS also provides a set of high-level client libraries and tools to introspect and manipulate the environment models. This article presents the design and architecture of this open-source tool, and explores some applications, along with examples of use.
ER  - 

TY  - CONF
TI  - OpenSeqSLAM2.0: An Open Source Toolbox for Visual Place Recognition Under Changing Conditions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7758
EP  - 7765
AU  - B. Talbot
AU  - S. Garg
AU  - M. Milford
PY  - 2018
KW  - image recognition
KW  - mobile robots
KW  - navigation
KW  - object recognition
KW  - public domain software
KW  - robot vision
KW  - SLAM (robots)
KW  - open source toolbox
KW  - changing conditions
KW  - traversed route
KW  - inclement conditions
KW  - navigating robots
KW  - robotic systems
KW  - environmental conditions
KW  - fully open-source toolbox
KW  - open access
KW  - source code
KW  - visual place recognition problem
KW  - open source platform
KW  - OpenSeqSLAM2.0
KW  - Visualization
KW  - Robots
KW  - Tools
KW  - Open source software
KW  - Search methods
KW  - Trajectory
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8593761
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visually recognising a traversed route - regardless of whether seen during the day or night, in clear or inclement conditions, or in summer or winter - is an important capability for navigating robots. Since SeqSLAM was introduced in 2012, a large body of work has followed exploring how robotic systems can use the algorithm to meet the challenges posed by navigation in changing environmental conditions. The following paper describes OpenSeqSLAM2.0, a fully open-source toolbox for visual place recognition under changing conditions. Beyond the benefits of open access to the source code, OpenSeqSLAM2.0 provides a number of tools to facilitate exploration of the visual place recognition problem and interactive parameter tuning. Using the new open source platform, it is shown for the first time how comprehensive parameter characterisations provide new insights into many of the system components previously presented in ad hoc ways and provide users with a guide to what system component options should be used under what circumstances and why.
ER  - 

TY  - CONF
TI  - HERO: Accelerating Autonomous Robotic Tasks with FPGA
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7766
EP  - 7772
AU  - X. Shi
AU  - L. Cao
AU  - D. Wang
AU  - L. Liu
AU  - G. You
AU  - S. Liu
AU  - C. Wang
PY  - 2018
KW  - convolutional neural nets
KW  - field programmable gate arrays
KW  - mobile robots
KW  - path planning
KW  - SLAM (robots)
KW  - motion planning tasks
KW  - HERO platform
KW  - CNN inference
KW  - autonomous robotic tasks
KW  - Heterogeneous Extensible Robot Open platform
KW  - OpenCL programming
KW  - SLAM
KW  - convolutional neural network inference
KW  - FPGA acceleration
KW  - heterogeneous computing
KW  - simultaneous localization and mapping
KW  - VGG-16
KW  - ResNet-50
KW  - Field programmable gate arrays
KW  - Kernel
KW  - Acceleration
KW  - Simultaneous localization and mapping
KW  - Task analysis
KW  - Planning
DO  - 10.1109/IROS.2018.8593522
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The Heterogeneous Extensible Robot Open (HERO) platform is designed for autonomous robotic research. While bringing in the flexible computational capacities by CPU and FPGA, it addresses the challenges of heterogeneous computing by embracing OpenCL programming. We propose heterogeneous computing approaches for three fundamental robotic tasks: simultaneous localization and mapping (SLAM), motion planning and convolutional neural network (CNN) inference. With FPGA acceleration, the SLAM and motion planning tasks are performed 2-4 times faster on the HERO platform against fine-tuned software implementation. For CNN inference, it can process 20-30 images per second with the network of VGG-16 or ResNet-50. We expect the open platform and the developing experiences shared in this paper can facilitate future robotic research, especially for those compute intensive tasks of perception, movement and manipulation.
ER  - 

TY  - CONF
TI  - Procedurally Provisioned Access Control for Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - R. White
AU  - H. I. Christensen
AU  - G. Caiazza
AU  - A. Cortesi
PY  - 2018
KW  - authorisation
KW  - Internet of Things
KW  - middleware
KW  - public domain software
KW  - robot programming
KW  - robotic systems
KW  - industrial IoT
KW  - domestic IoT
KW  - development lifecycle
KW  - ROS2
KW  - secure real world robotic deployments
KW  - procedural provisioning access control policies
KW  - secure DDS
KW  - middleware infrastructures
KW  - next generation open source robotic software stack
KW  - Service robots
KW  - Access control
KW  - Middleware
KW  - Tools
KW  - Cryptography
DO  - 10.1109/IROS.2018.8594462
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.
ER  - 

TY  - CONF
TI  - XBotCloud: A Scalable Cloud Computing Infrastructure for XBot Powered Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Muratore
AU  - B. Lennox
AU  - N. G. Tsagarakis
PY  - 2018
KW  - cloud computing
KW  - control engineering computing
KW  - software agents
KW  - Web services
KW  - computational resources
KW  - robotic platforms
KW  - Amazon Web Services Cloud Security
KW  - XBotCloud
KW  - cross-robot flexibility
KW  - XBotCloud performances
KW  - robot local control unit
KW  - Real-Time modules
KW  - moderate execution time constraints
KW  - cloud services
KW  - cloud server
KW  - XBotCore Real-Time cross-robot software component
KW  - hard Real-Time execution/communication performance
KW  - soft Time execution/communication performance
KW  - XBot framework
KW  - cloud robotics concept
KW  - mobile robots
KW  - untethered robots
KW  - on-board computational resources
KW  - scalable cloud computing infrastructure
KW  - Cloud computing
KW  - Robot sensing systems
KW  - Software as a service
KW  - Task analysis
KW  - Servers
DO  - 10.1109/IROS.2018.8593587
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Limitations with the on-board computational resources installed on untethered robots such as humanoids and mobile robots in general affects significantly the performance and capabilities of these machines. An approach to address this issue is to make use of the cloud robotics concept and take advantage of the extensive computational resources of the cloud. XBotCloud is a recently developed component of the XBot framework. It tackles the above challenges by introducing the tools and mechanisms to enable users and robots to exploit the computational resources of the cloud allowing the execution of services with low, soft or hard Real-Time execution/communication performance. The latter is ensured thanks to the functionality provided by the XBotCore Real-Time cross-robot software component of the XBot framework. XBotCloud addresses also one of the main challenges related with cloud robotics: security. To avoid remote attacks it takes advantage of the Amazon Web Services (AWS)Cloud Security and it uses an internal VPN Network to handle the connectivity between the robot and the cloud server. The full implementation of the framework is presented and its functionality is demonstrated in realistic tasks involving pipelines that mix the execution of cloud services with moderate execution time constraints and Real-Time modules running on the robot local control unit. XBotCloud performances and cross-robot flexibility are experimentally validated on two different robotic platforms, the WALK-MAN humanoid and the CENTAURO upper body/full-body.
ER  - 

TY  - CONF
TI  - Learning to Touch Objects Through Stage-Wise Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. de La Bourdonnaye
AU  - C. Teulière
AU  - J. Triesch
AU  - T. Chateau
PY  - 2018
KW  - end effectors
KW  - learning (artificial intelligence)
KW  - stage-wise deep reinforcement learning
KW  - complex behaviors
KW  - manipulation robotics
KW  - high-level modules
KW  - object palm-touching task
KW  - weakly-supervised learning
KW  - informative shaping reward
KW  - informative supervised reward
KW  - efficient learning
KW  - Task analysis
KW  - Robot kinematics
KW  - End effectors
KW  - Cameras
KW  - Robot vision systems
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593362
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning complex behaviors through reinforcement learning is particularly challenging when reward is only available upon successful completion of the full behavior. In manipulation robotics, so-called shaping rewards are often used to overcome this problem. However, these usually require human engineering or (partial)world models describing, e.g., the kinematics of the robot or high-level modules for perception. Here we propose an alternative method to learn an object palm-touching task through a weakly-supervised and stagewise learning of simpler tasks. First, the robot learns to fixate the object with its cameras. Second, the robot learns eye-hand coordination by learning to fixate its end effector. Third, using the previously acquired skills an informative shaping reward can be computed which facilitates efficient learning of the object palm-touching task. We demonstrate in simulation that learning the full task with this shaping reward is comparable to learning with an informative supervised reward.
ER  - 

TY  - CONF
TI  - Bayesian Information Recovery from CNN for Probabilistic Inference
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7795
EP  - 7802
AU  - D. Kopitkov
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - Gaussian distribution
KW  - image classification
KW  - image fusion
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - target tracking
KW  - probabilistic inference approach
KW  - light conditions
KW  - trajectory estimation
KW  - simulated unreal engine environment
KW  - uncertainty covariance
KW  - robot localization problem
KW  - robot pose
KW  - hidden state mean prediction
KW  - high-level state information
KW  - inference task
KW  - CNN feature likelihood
KW  - Bayesian framework
KW  - spatially-varying Gaussian distribution
KW  - generative viewpoint-dependent model
KW  - CNN classifier
KW  - visual observations
KW  - system hidden state
KW  - combinatorial data association
KW  - hand-engineered image features
KW  - high-dimensional visual measurements
KW  - Bayesian information recovery
KW  - Robots
KW  - Trajectory
KW  - Cameras
KW  - Bayes methods
KW  - Estimation
KW  - Uncertainty
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594506
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.
ER  - 

TY  - CONF
TI  - Catenary Tether Shape Analysis for a UAV - USV Team
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7803
EP  - 7809
AU  - K. A. Talke
AU  - M. De Oliveira
AU  - T. Bewley
PY  - 2018
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - hydrodynamics
KW  - marine vehicles
KW  - polynomials
KW  - position control
KW  - dynamic heave events
KW  - tether length
KW  - convenient curves
KW  - nondimensional relative position parameter
KW  - catenary analysis
KW  - catenary tether shape analysis
KW  - UAV - USV team
KW  - quasistatic catenary curve
KW  - semislack tether
KW  - unmanned surface vehicle
KW  - empirical analysis
KW  - system robustness
KW  - vertical heave
KW  - optimum condition
KW  - cable length
KW  - stationary unmanned air vehicle
KW  - heave robustness analysis
KW  - lookup table
KW  - Unmanned aerial vehicles
KW  - Winches
KW  - Robustness
KW  - Mathematical model
KW  - Shape
KW  - Vehicle dynamics
KW  - Sea surface
DO  - 10.1109/IROS.2018.8594280
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The quasi-static catenary curve of a semi-slack tether between an essentially stationary unmanned air vehicle (UAV) and a small unmanned surface vehicle (USV) is investigated and characterized. An empirical analysis, performed over a discretized space of vertical and horizontal separations of the two vehicles, determines an optimum cable length & tension for maximizing system robustness during the vertical heave of the USV due to high seas. Operating at this optimum condition allows for equal displacements of the USV in the up and down directions, minimizing the possibility of both fouling (with the tether touching the water) and excessive downforce on the UAV (with the tether pulled taut) during dynamic heave events. Scaling the horizontal offset, tether length, and tension by the flying height collapses all empirical results into convenient curves depending only on a nondimensional relative position parameter (Δx/Δy), accurately fit by low order polynomials. This eliminates the need for a lookup table, and decreases computation time during implementation. The heave robustness analysis results in a recommended operating relative position of Δx/Δy ≈ .46. Experimental results are presented and confirm the catenary analysis for the proposed tether.
ER  - 

TY  - CONF
TI  - Inertial Velocity and Attitude Estimation for Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Svacha
AU  - K. Mohta
AU  - M. Watterson
AU  - G. Loianno
AU  - V. Kumar
PY  - 2018
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - drag
KW  - helicopters
KW  - inertial navigation
KW  - Kalman filters
KW  - linear drag parameters
KW  - drag forces
KW  - linear drag model
KW  - IMU
KW  - inertial measurement unit
KW  - quadrotor UAV
KW  - body-fixed z axis
KW  - attitude estimation
KW  - inertial velocity
KW  - Aerodynamics
KW  - Sensors
KW  - Accelerometers
KW  - Estimation
KW  - Magnetometers
KW  - Kalman filters
KW  - Velocity measurement
DO  - 10.1109/IROS.2018.8593616
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.
ER  - 

TY  - CONF
TI  - Quadtree-Accelerated Real-Time Monocular Dense Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Wang
AU  - W. Ding
AU  - S. Shen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image fusion
KW  - image motion analysis
KW  - image reconstruction
KW  - image resolution
KW  - mobile robots
KW  - path planning
KW  - quadtrees
KW  - robot vision
KW  - stereo image processing
KW  - real-time monocular dense mapping
KW  - truncated signed distance function
KW  - dense 3D maps
KW  - resolution depth maps
KW  - pixels
KW  - dynamic belief propagation
KW  - pixel selection
KW  - depth map
KW  - intensity image
KW  - quadtree structure
KW  - single localized moving camera
KW  - high-quality dense depth maps
KW  - robotic navigation
KW  - Cameras
KW  - Three-dimensional displays
KW  - Belief propagation
KW  - Estimation
KW  - Optimization
KW  - Real-time systems
KW  - Image resolution
DO  - 10.1109/IROS.2018.8594101
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.
ER  - 

TY  - CONF
TI  - The Deformable Quad-Rotor Enabled and Wasp-Pedal-Carrying Inspired Aerial Gripper
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - N. Zhao
AU  - Y. Luo
AU  - H. Deng
AU  - Y. Shen
AU  - H. Xu
PY  - 2018
KW  - aerodynamics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - controllability
KW  - deformation
KW  - grippers
KW  - helicopters
KW  - mobile robots
KW  - stability
KW  - aerial gripper design
KW  - REMS
KW  - quadrotor body
KW  - quadrotor deformation
KW  - rigid elements based morphing structure
KW  - aerodynamic flow
KW  - wasp grasping behavior
KW  - stability
KW  - unmanned aerial vehicles
KW  - Grippers
KW  - Grasping
KW  - Strain
KW  - Payloads
KW  - Rotors
KW  - Manipulators
KW  - Gravity
DO  - 10.1109/IROS.2018.8594330
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper presents the development of a novel deformable quad-rotor enabled aerial gripper. The mechanism of our deformable quad-rotor is based on simultaneous expansion or contraction of the quad-rotor body, which is generated by controlling a rigid elements based morphing structure (REMS). Such deformation results in a highly deformable quad-rotor that can not only perform morphological adaptation in response to environmental changes and obstacles, but also improve the flight performance by contracting to facilitate the agility/maneuverability or by expanding to enhance the stability. Meanwhile, inspired by the wasp grasping behavior, such controllable expansion and contraction from the REMS ingeniously enable a new function of aerial gripper. In this paper, we start to detail the mechanism and design of the REMS based deformable quad-rotor, then present the quad-rotor deformation enabled aerial gripper design, its dynamics modeling, the grasping function and analysis. The simulation was conducted in order to graphically show the elicited aerodynamic flow situation during expansion or contraction of the quad-rotor with and without carrying payload. Experiments were further implemented to validate the grasping function of the gripper and the flight performance of the quad-rotor. Finally, two case studies on the new aerial gripper were performed. All results demonstrate the excellent performance of the deformable quad-rotor enabled aerial gripper, that is, it has the advantages of both flight maneuverability and grasping capability during performing tasks.
ER  - 

TY  - CONF
TI  - Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7831
EP  - 7837
AU  - K. Pereida
AU  - A. P. Schoellig
PY  - 2018
KW  - adaptive control
KW  - helicopters
KW  - mobile robots
KW  - optimisation
KW  - predictive control
KW  - robust control
KW  - trajectory control
KW  - uncertain systems
KW  - wind disturbances
KW  - cost function
KW  - optimal reference input
KW  - quadrotor
KW  - MPC
KW  - trajectory tracking error
KW  - predictive approach
KW  - adaptive control strategies
KW  - unmodeled dynamics
KW  - dynamic environments
KW  - automated systems
KW  - adaptive model predictive control
KW  - nonadaptive approach
KW  - Adaptation models
KW  - Predictive models
KW  - Trajectory tracking
KW  - Uncertainty
KW  - Adaptive control
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594267
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L1 adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.
ER  - 

TY  - CONF
TI  - Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7838
EP  - 7844
AU  - J. M. Gómez-de-Gabriel
AU  - J. M. Gandarias
AU  - F. J. Pérez-Maldonado
AU  - F. J. García-Núñcz
AU  - E. J. Fernández-García
AU  - A. J. García-Cerezo
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - convolutional neural nets
KW  - grippers
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - rescue robots
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous wristband placement
KW  - robotic system
KW  - automatic wristband placement
KW  - remote sensor readings
KW  - continuous health monitoring
KW  - unmanned aerial manipulator
KW  - automatic wrist detection
KW  - RGB-D camera
KW  - convolutional neural network
KW  - Faster R-CNN
KW  - passive detachable gripper
KW  - VGG-16 neural network
KW  - target localization
KW  - trajectory planning
KW  - machine learning
KW  - parallel delta manipulator
KW  - search-and-rescue aerial manipulator
KW  - search and rescue operations
KW  - unmanned aerial vehicles
KW  - Manipulators
KW  - Wrist
KW  - Cameras
KW  - Grippers
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594202
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.
ER  - 

TY  - CONF
TI  - Nonlinear Adaptive Control of Quadrotor Multi-Flipping Maneuvers in the Presence of Time-Varying Torque Latency
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Chen
AU  - N. O. Pérez-Arancibia
PY  - 2018
KW  - adaptive control
KW  - aerodynamics
KW  - aircraft control
KW  - closed loop systems
KW  - control nonlinearities
KW  - control system synthesis
KW  - delays
KW  - helicopters
KW  - least squares approximations
KW  - linear systems
KW  - nonlinear control systems
KW  - position control
KW  - robust control
KW  - time-varying systems
KW  - torque control
KW  - recursive least-squares algorithm
KW  - high-performance linear controller
KW  - adaptive controller
KW  - nonlinear adaptive control scheme
KW  - linear time-varying model
KW  - linear time-invariant model
KW  - backstepping-based control scheme
KW  - LTV latency model
KW  - time-varying angular speed
KW  - torque delay
KW  - backstepping-based nonlinear controller
KW  - controller synthesis methods
KW  - high-speed multiflips
KW  - aerobatic maneuvers
KW  - closed-loop control schemes
KW  - stability robustness
KW  - time-varying torque
KW  - quadrotor multiflipping maneuvers
KW  - Torque
KW  - Aerodynamics
KW  - Linear systems
KW  - Adaptation models
KW  - Vehicle dynamics
KW  - Angular velocity
KW  - Propellers
DO  - 10.1109/IROS.2018.8594265
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dynamics of quadrotors are affected by time-varying torque latency, which can greatly alter the stability robustness and performance of the closed-loop control schemes employed for flight; this issue is especially relevant during the execution of aerobatic maneuvers such as high-speed multi-flips. To address this problem, we propose two controller synthesis methods associated with two different modeling approaches. In the first approach, we describe torque latency with a linear time-invariant (LTI)model, identified through ground experiments, which is then used to design a backstepping-based nonlinear controller. In the second approach, we employ an improved linear time-varying (LTV)model with a priori unknown parameters, which is used to synthesize and implement a novel nonlinear adaptive control scheme updated in real time using the recursive least-squares (RLS)algorithm. Empirical observations suggest that the torque delay affecting the system depends on the time-varying angular speed of the flyer and its derivative. This phenomenon is explained by the fact that the aerodynamic forces produced by, and acting on, the rotating propellers vary with the local velocity of the incident flows. Hence, in the proposed adaptive structure, we define the parameters of the LTV latency model as linear functions of the angular speed reference and its derivative. Experimental results compellingly demonstrate the efficacy of the methods introduced in this paper; compared to the highperformance linear controller in [1]-[3], the backstepping-based control scheme and adaptive controller decrease the average root mean square (RMS)value of the control error by 17.82 % and 38.42 %, respectively.
ER  - 

TY  - CONF
TI  - NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7860
EP  - 7865
AU  - D. Calero
AU  - E. Fernández
AU  - M. E. Parés
AU  - E. Angelats
PY  - 2018
KW  - cameras
KW  - geophysical image processing
KW  - image colour analysis
KW  - image sensors
KW  - vegetation mapping
KW  - vegetation index estimation
KW  - Microsoft Kinect V2
KW  - vegetation monitoring purposes
KW  - ROS point cloud generation tools
KW  - active IR camera
KW  - active RGB-D sensor technology
KW  - RGB camera
KW  - NDVI point cloud generator tool
KW  - 3D NDVI maps
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8594175
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this manuscript, a NDVI point cloud generator tool based on low-cost active RGB-D sensor is presented. Taking advantage of currently available ROS point cloud generation tools and RGB-D sensor technology (like Microsoft Kinect), that includes an inbuilt active IR camera and a RGB camera, 3D NDVI maps can be quickly and easily generated for vegetation monitoring purposes. When using low-cost sensors for vegetation index estimation, it is necessary to apply a rigorous methodology for extracting reliable information. In this paper, the methodology for NDVI generation using a low-cost sensor as well as experiments to evaluate its performance is presented. The experiments performed show that it is possible to obtain a reliable NDVI point cloud from a Kinect V2.
ER  - 

TY  - CONF
TI  - Unsupervised Object Proposal Using Depth Boundary Density and Density Uniformity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7866
EP  - 7871
AU  - T. Hosono
AU  - S. Tarashima
AU  - J. Shimamura
AU  - T. Kinebuchi
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image texture
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object recognition
KW  - RGB-D object proposal methods
KW  - robot-computer vision area
KW  - bounding box
KW  - object recognition
KW  - density uniformity
KW  - unsupervised object proposal
KW  - depth boundary density difference
KW  - depth images
KW  - overlapping objects
KW  - texture objects
KW  - RGB images
KW  - object region extraction methods
KW  - window scoring
KW  - Proposals
KW  - Computational efficiency
KW  - Microsoft Windows
KW  - Object detection
KW  - Feature extraction
KW  - Search problems
KW  - Image edge detection
DO  - 10.1109/IROS.2018.8594408
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Object proposal that detects candidate bounding boxes of objects in images is an effective way of accelerating object recognition in the robot/computer vision area. We propose an accurate and fast object proposal method using depth images. Existing proposal methods can be roughly divided into two categories: window scoring and object region extraction. The window scoring methods usually have higher efficiency than object region extraction methods. The previous methods using RGB images detect an excessive number of boxes due to edges of texture objects. These methods also may misdetect overlapping objects as one candidate bounding box. To tackle these problems, we propose a novel and effective objectness measure using depth images. The proposed method evaluates objectness by using depth boundary density difference between inner and outer regions of a candidate bounding box. We also consider the uniformity of the outer boundary density in a candidate bounding box to divide overlapping objects into individual candidate bounding boxes. Our reasonable assumption here is that the depth boundary of an object has a closed loop. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging toy-dataset [1] of complex crowded scenes.
ER  - 

TY  - CONF
TI  - LIMO: Lidar-Monocular Visual Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7872
EP  - 7879
AU  - J. Graeter
AU  - A. Wilczynski
AU  - M. Lauer
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - mobile robots
KW  - motion estimation
KW  - object tracking
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - visual localization
KW  - depth extraction algorithm
KW  - camera feature tracks
KW  - outlier rejection
KW  - sensor combination
KW  - LIMO
KW  - lidar-monocular visual odometry
KW  - higher level functionality
KW  - autonomous driving
KW  - precise motion estimate
KW  - powerful algorithms
KW  - great majority
KW  - binocular imagery
KW  - bundle adjustment
KW  - LIDAR measurements
KW  - Feature extraction
KW  - Laser radar
KW  - Cameras
KW  - Estimation
KW  - Three-dimensional displays
KW  - Calibration
KW  - Visual odometry
DO  - 10.1109/IROS.2018.8594394
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Higher level functionality in autonomous driving depends strongly on a precise motion estimate of the vehicle. Powerful algorithms have been developed. However, their great majority focuses on either binocular imagery or pure LIDAR measurements. The promising combination of camera and LIDAR for visual localization has mostly been unattended. In this work we fill this gap, by proposing a depth extraction algorithm from LIDAR measurements for camera feature tracks and estimating motion by robustified keyframe based Bundle Adjustment. Semantic labeling is used for outlier rejection and weighting of vegetation landmarks. The capability of this sensor combination is demonstrated on the competitive KITTI dataset, achieving a placement among the top 15. The code is released to the community.
ER  - 


TY  - CONF
TI  - DLWV2: A Deep Learning-Based Wearable Vision-System with Vibrotactile-Feedback for Visually Impaired People to Reach Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Shih
AU  - Y. Chen
AU  - C. Tung
AU  - C. Sun
AU  - C. Cheng
AU  - L. Chan
AU  - S. Varadarajan
AU  - M. Sun
PY  - 2018
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object tracking
KW  - BVI people
KW  - extended deep learning-based 2.5-D detector
KW  - Visually Impaired people
KW  - Vibrotactile-feedback
KW  - distance-based vibrotactile feedback
KW  - 2.5-D object ground-truth
KW  - 3-D object locations
KW  - 3-D object tracker
KW  - object detection
KW  - DLWV2
KW  - Deep Learning-based Wearable Vision-system
KW  - Cameras
KW  - Target tracking
KW  - Detectors
KW  - Training
KW  - Real-time systems
KW  - Object detection
DO  - 10.1109/IROS.2018.8593711
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We develop a Deep Learning-based Wearable Vision-system with Vibrotactile-feedback (DLWV2)to guide Blind and Visually Impaired (BVI)people to reach objects. The system achieves high accuracy in object detection and tracking in 3-D using an extended deep learning-based 2.5-D detector and a 3-D object tracker with the ability to track 3-D object locations even outside the camera field-of-view. We train our detector with a large number of images with 2.5-D object ground-truth (i.e., 2-D object bounding boxes and distance from the camera to objects). A novel combination of HTC Vive Tracker with our system enables us to automatically obtain the ground-truth labels for training while requiring very little human effort to set up the system. Moreover, our system processes frames in real-time through a client-server computing platform such that BVI people can receive realtime vibrotactile guidance. We conduct a thorough user study on 12 BVI people in new environments with object instances which are unseen during training. Our system outperforms the non-assistive guiding strategy with statistic significance in both time and the number of contacting irrelevant objects. Finally, the interview with BVI users confirms that our system with distance-based vibrotactile feedback is mostly preferred, especially for objects requiring gentle manipulation such as a bottle with water inside.
ER  - 

TY  - CONF
TI  - PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7912
EP  - 7917
AU  - P. Guo
AU  - W. Hu
AU  - H. Ren
AU  - Y. Zhang
PY  - 2018
KW  - computational geometry
KW  - image registration
KW  - iterative methods
KW  - principal component analysis
KW  - Manhattan world assumption
KW  - transformation estimation
KW  - overlap estimation
KW  - ICP
KW  - rotation angle
KW  - PCAOT
KW  - Manhattan point cloud registration method
KW  - robot mapping
KW  - iterative closest point
KW  - robot localization
KW  - principal coordinate alignment with overlap tuning
KW  - 3D cuboid
KW  - Three-dimensional displays
KW  - Estimation
KW  - Tuning
KW  - Iterative closest point algorithm
KW  - Mathematical model
KW  - Filtering
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594514
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Point cloud registration is a popular research topic and has been widely used in many tasks, such as robot mapping and localization. It is a challenging problem when the overlap is small, or the rotation is large. The problem has not been well solved by existing methods such as the iterative closest point (ICP) and its variants. In this paper, a novel method named principal coordinate alignment with overlap tuning (PCAOT) is proposed based on the Manhattan world assumption. It solves two key problems together, the transformation estimation and the overlap estimation. The overlap is represented by a 3D cuboid and the transformation is computed only within the overlap region. Instead of finding point correspondence as in traditional methods, we estimate the rotation by principal coordinates alignment, which is faster and less sensitive than ICP and its variants to small overlaps and large rotations. Evaluations demonstrate that our method achieves much better results than the ICP and its variants when the overlap ratio is smaller than 50%, or the rotation angle is larger than 60°. Especially, it is effective when the overlap ratio is less than 30%, or the rotation angle is larger than 90°.
ER  - 

TY  - CONF
TI  - Minimal Construct: Efficient Shortest Path Finding for Mobile Robots in Polygonal Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7918
EP  - 7923
AU  - M. Missura
AU  - D. D. Lee
AU  - M. Bennewitz
PY  - 2018
KW  - collision avoidance
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - mobile robots
KW  - polygonal maps
KW  - navigational software
KW  - shortest collision-free path
KW  - Dijkstra algorithm
KW  - visibility graph algorithm
KW  - minimal construct
KW  - visibility graph-based shortest path algorithms
KW  - shortest path finding
KW  - A* algorithm
KW  - Navigation
KW  - Heuristic algorithms
KW  - Mobile robots
KW  - Software
KW  - Complexity theory
KW  - Standards
DO  - 10.1109/IROS.2018.8594124
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With the advent of polygonal maps finding their way into the navigational software of mobile robots, the Visibility Graph can be used to search for the shortest collision-free path. The nature of the Visibility Graph-based shortest path algorithms is such that first the entire graph is computed in a relatively time-consuming manner. Then, the graph can be searched efficiently any number of times for varying start and target state combinations with the A* or the Dijkstra algorithm. However, real-world environments are typically too dynamic for a map to remain valid for a long time. With the goal of obtaining the shortest path quickly in an ever changing environment, we introduce a rapid path finding algorithm-Minimal Construct-that discovers only a necessary portion of the Visibility Graph around the obstacles that actually get in the way. Collision tests are computed only for lines that seem heuristically promising. This way, shortest paths can be found much faster than with a state-of-the-art Visibility Graph algorithm and as our experiments show, even grid-based A* searches are outperformed in most cases with the added benefit of smoother and shorter paths.
ER  - 

TY  - CONF
TI  - Trajectory Planning for Heterogeneous Robot Teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7924
EP  - 7931
AU  - M. Debord
AU  - W. Hönig
AU  - N. Ayanian
PY  - 2018
KW  - collision avoidance
KW  - graph theory
KW  - helicopters
KW  - mobile robots
KW  - trajectory optimisation (aerospace)
KW  - trajectory planning method
KW  - heterogeneous mobile robot teams
KW  - graph-planning techniques
KW  - trajectory optimization
KW  - differential drive robots
KW  - inter-robot collision constraints
KW  - close-proximity flight
KW  - rotorcraft
KW  - quadrotors
KW  - Collision avoidance
KW  - Trajectory
KW  - Robot kinematics
KW  - Mobile robots
KW  - Schedules
DO  - 10.1109/IROS.2018.8593876
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We describe a trajectory planning method for heterogeneous mobile robot teams in known environments. We consider two core problems that arise with heterogeneous robot teams: asymmetric inter-robot collision constraints and varying dynamic limits. Asymmetric collision constraints are important for close-proximity flight of rotorcraft due to the downwash effect, which complicates spatial coordination. Varying dynamic limits complicate temporal coordination between robots and must be taken into account during planning. Our method builds upon a hybrid planner that combines graph-planning techniques with trajectory optimization and scales well to large homogeneous robot teams. We extend the hybrid planning approach to include the additional spatial and temporal coordination to support heterogeneous teams. Our method scales well with the number of robots and robot types and we demonstrate our approach on a team of 15 physical robots of 4 different types, including quadrotors and differential drive robots.
ER  - 

TY  - CONF
TI  - A Motion Planning Approach for Marsupial Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. G. Stankiewicz
AU  - S. Jenkins
AU  - G. E. Mullins
AU  - K. C. Wolfe
AU  - M. S. Johannes
AU  - J. L. Moore
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - free-space regions
KW  - topological graph planning
KW  - high-level motion plan
KW  - low-level path planner
KW  - motion planning approach
KW  - marsupial robotic systems
KW  - automatic coordination
KW  - heterogeneous multirobot teams
KW  - marsupial-based subset
KW  - carrier robots
KW  - passenger robots
KW  - high-level watershed segmentation
KW  - Robot kinematics
KW  - Planning
KW  - Trajectory
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
DO  - 10.1109/IROS.2018.8593392
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.
ER  - 

TY  - CONF
TI  - Motion Planning and Goal Assignment for Robot Fleets Using Trajectory Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7939
EP  - 7946
AU  - J. Salvado
AU  - R. Krug
AU  - M. Mansouri
AU  - F. Pecora
PY  - 2018
KW  - integer programming
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal control
KW  - path planning
KW  - quadratic programming
KW  - mixed integer quadratic programming
KW  - autonomous robots
KW  - automating fleets
KW  - trajectory optimization
KW  - robot fleets
KW  - fleet-wide boolean decision variables
KW  - phase solves
KW  - two-phase approach
KW  - nonholonomic robots
KW  - Optimal Control
KW  - fleet management problem
KW  - performance criterion
KW  - motion planning
KW  - goal assignment
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Aerospace electronics
KW  - Indexes
KW  - Trajectory
KW  - Geometry
DO  - 10.1109/IROS.2018.8594118
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper is concerned with automating fleets of autonomous robots. This involves solving a multitude of problems, including goal assignment, motion planning, and coordination, while maximizing some performance criterion. While methods for solving these sub-problems have been studied, they address only a facet of the overall problem, and make strong assumptions on the use-case, on the environment, or on the robots in the fleet. In this paper, we formulate the overall fleet management problem in terms of Optimal Control. We describe a scheme for solving this problem in the particular case of fleets of non-holonomic robots navigating in an environment with obstacles. The method is based on a two-phase approach, whereby the first phase solves for fleet-wide boolean decision variables via Mixed Integer Quadratic Programming, and the second phase solves for real-valued variables to obtain an optimized set of trajectories for the fleet. Examples showcasing the features of the method are illustrated, and the method is validated experimentally.
ER  - 

TY  - CONF
TI  - Re-Establishing Communication in Teams of Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7947
EP  - 7954
AU  - I. Vandermeulen
AU  - R. Groß
AU  - A. Kolling
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - probability
KW  - tree searching
KW  - wireless connection
KW  - constrained optimization problem
KW  - branch-and-bound approach
KW  - locally available information
KW  - belief
KW  - mobile robots
KW  - Task analysis
KW  - Robot kinematics
KW  - Search problems
KW  - Mobile robots
KW  - Markov processes
DO  - 10.1109/IROS.2018.8594460
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As communication is important for cooperation, teams of mobile robots need a way to re-establish a wireless connection if they get separated. We develop a method for mobile robots to maintain a belief of each other's positions using locally available information. They can use their belief to plan paths with high probabilities of reconnection. This approach also works for subteams cooperatively searching for a robot or group of robots that they would like to reconnect with. The problem is formulated as a constrained optimization problem which is solved using a branch-and-bound approach. We present simulation results showing the effectiveness of this strategy at reconnecting teams of up to five robots and compare the results to two other strategies.
ER  - 

TY  - CONF
TI  - Multi-Agent Planning for Coordinated Robotic Weed Killing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7955
EP  - 7960
AU  - W. McAllister
AU  - D. Osipychev
AU  - G. Chowdhary
AU  - A. Davis
PY  - 2018
KW  - agriculture
KW  - crops
KW  - environmental factors
KW  - industrial robots
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - multiagent planning
KW  - coordinated robotic Weed killing
KW  - coordinated multiagent weeding
KW  - partial environmental information
KW  - coordination strategies
KW  - weeding performance
KW  - autonomous agricultural robots
KW  - system performance
KW  - Weed World
KW  - coordinated weeding policies
KW  - realistic weed generation
KW  - initial seed bank densities
KW  - weeding process
KW  - required number
KW  - Agriculture
KW  - Robot kinematics
KW  - Optimization
KW  - Immune system
KW  - Chemicals
KW  - Soil
DO  - 10.1109/IROS.2018.8593429
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a strategy for coordinated multi-agent weeding under conditions of partial environmental information. The goal of this work is to demonstrate the feasibility of coordination strategies for improving the weeding performance of autonomous agricultural robots. We show that, given a sufficient number of agents, the algorithm can successfully weed fields with various initial seed bank densities, even when multiple days are allowed to elapse before weeding commences. Furthermore, the use of coordination between agents is demonstrated to strongly improve system performance as the number of agents increases, enabling the system to eliminate all the weeds in the field, as in the case of full environmental information, when the planner without coordination failed to do so. As a domain to test our algorithms, we have developed an open source simulation environment, Weed World, which allows real-time visualization of coordinated weeding policies, and includes realistic weed generation. In this work, experiments are conducted to determine the required number of agents and their required transit speed, for given initial seed bank densities and varying allowed days before the start of the weeding process.
ER  - 

TY  - CONF
TI  - Intelligent Robotic IoT System (IRIS)Testbed
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. A. Tran
AU  - P. Ghosh
AU  - Y. Gu
AU  - R. Kim
AU  - D. D'Souza
AU  - N. Ayanian
AU  - B. Krishnamachari
PY  - 2018
KW  - Global Positioning System
KW  - intelligent robots
KW  - IP networks
KW  - middleware
KW  - mobile radio
KW  - mobile robots
KW  - multi-robot systems
KW  - personal area networks
KW  - protocols
KW  - robot vision
KW  - SLAM (robots)
KW  - wireless LAN
KW  - IPv6 network stack
KW  - individual robots
KW  - system implementation details
KW  - Intelligent robotic IoT system
KW  - modular source testbed
KW  - portable source testbed
KW  - open-source testbed
KW  - robotic wireless network research
KW  - IRIS
KW  - Time Difference of Arrival localization system
KW  - Time Difference of Arrival localization system
KW  - static global positioning system
KW  - multirobot testbeds
KW  - multirobot testbeds
KW  - Programmable Wireless Communication Stack
KW  - scalable source testbed
KW  - lightweight publish-subscribe overlay protocol
KW  - ROMANO
KW  - modular architecture
KW  - Iris recognition
KW  - Iris
KW  - Robot kinematics
KW  - Protocols
KW  - Transceivers
KW  - Ultrasonic imaging
DO  - 10.1109/IROS.2018.8593636
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the Intelligent Robotic IoT System (IRIS), a modular, portable, scalable, and open-source testbed for robotic wireless network research. There are two key features that separate IRIS from most of the state-of-the-art multi-robot testbeds. (1)Portability: IRIS does not require a costly static global positioning system such as a VICON system nor time-intensive vision-based SLAM for its operation. Designed with an inexpensive Time Difference of Arrival (TDoA)localization system with centimeter level accuracy, the IRIS testbed can be deployed in an arbitrary uncontrolled environment in a matter of minutes. (2)Programmable Wireless Communication Stack: IRIS comes with a modular programmable low-power IEEE 802.15.4 radio and IPv6 network stack on each node. For the ease of administrative control and communication, we also developed a lightweight publish-subscribe overlay protocol called ROMANO that is used for bootstrapping the robots (also referred to as the IRISbots), collecting statistics, and direct control of individual robots, if needed. We detail the modular architecture of the IRIS testbed design along with the system implementation details and localization performance statistics.
ER  - 

TY  - CONF
TI  - SEAR: A Polynomial- Time Multi-Robot Path Planning Algorithm with Expected Constant-Factor Optimality Guarantee
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. D. Han
AU  - E. J. Rodriguez
AU  - J. Yu
PY  - 2018
KW  - computational complexity
KW  - graph theory
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - statistical distributions
KW  - polynomial-time multirobot path planning algorithm
KW  - expected constant-factor optimality guarantee
KW  - arbitrary initial goal arrangements
KW  - continuous 2D domains
KW  - continuous 3D domains
KW  - uniformly randomly distributed
KW  - microMVP platform
KW  - nonholonomic robots
KW  - near-optimal solutions
KW  - nonpolynomial time
KW  - initial goal configuration footprints
KW  - constant-factor expansion
KW  - Robots
KW  - Path planning
KW  - Collision avoidance
KW  - Labeling
KW  - Routing
KW  - Pipelines
KW  - Planning
DO  - 10.1109/IROS.2018.8594417
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We study the labeled multi-robot path planning problem in continuous 2D and 3D domains in the absence of obstacles where robots must not collide with each other. For an arbitrary number of robots in arbitrary initial and goal arrangements, we derive a polynomial time, complete algorithm that produces solutions with constant-factor optimality guarantees on both makespan and distance optimality, in expectation, under the assumption that the robot labels are uniformly randomly distributed. Our algorithm only requires a small constant-factor expansion of the initial and goal configuration footprints for solving the problem, i.e., the problem can be solved in a fairly small bounded region. Beside theoretical guarantees, we present a thorough computational evaluation of the proposed solution. In addition to the baseline implementation, adapting an effective (but non-polynomial time) routing subroutine, we also provide a highly efficient implementation that quickly computes near-optimal solutions. Hardware experiments on the microMVP platform composed of non-holonomic robots confirms the practical applicability of our algorithmic pipeline.
ER  - 

TY  - CONF
TI  - Towards Peak Torque Minimization for Modular Self-Folding Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7975
EP  - 7982
AU  - M. Yao
AU  - H. Cui
AU  - X. Xiao
AU  - C. H. Belke
AU  - J. Paik
PY  - 2018
KW  - mobile robots
KW  - torque
KW  - trees (mathematics)
KW  - two-dimensional patterns
KW  - robotic inertia
KW  - modular architecture
KW  - minimal bounding box
KW  - robotic base selection
KW  - modular origami robot
KW  - modular robotic systems
KW  - peak torque minimization
KW  - modular self-folding robots
KW  - capacitated spanning tree heuristic algorithms
KW  - Mori
KW  - Robots
KW  - Torque
KW  - Planning
KW  - Shape
KW  - Heuristic algorithms
KW  - Computer architecture
KW  - Force
DO  - 10.1109/IROS.2018.8593648
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Modular self-folding robots are versatile systems that can change their own shape from two-dimensional patterns at instant commands. This reconfigurability is commonly restrained by power limitation in autonomous environments, The robotic systems with insufficient torque may lead to inaccurate movements and even transformation failures. This paper presents methodology for optimized reconfiguration planning with torque limitation in modular self-folding robots. We determine reconfiguration schemes with optimal initial pattern and robotic base that result in minimal peak torque by minimizing robotic inertia of the modular architecture. We present minimal bounding box and capacitated spanning tree heuristic algorithms to generate optimal initial patterns and propose 3 heuristic rules for robotic base selection. Our approach is demonstrated in simulation by applying the algorithms to the robotic concept of Mori, a modular origami robot. The simulation results show that the proposed algorithms yield reconfiguration schemes with low peak torque, thereby appropriate for real-time applications in modular robotic systems.
ER  - 

TY  - CONF
TI  - Passive Nonlinear Impedance Control for Port-Hamiltonian Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7983
EP  - 7988
AU  - Y. Okura
AU  - K. Fujimoto
PY  - 2018
KW  - closed loop systems
KW  - control system synthesis
KW  - feedback
KW  - nonlinear control systems
KW  - numerical analysis
KW  - controlled system
KW  - passive nonlinear impedance control
KW  - port-Hamiltonian system
KW  - nonholonomic system
KW  - fully actuated mechanical systems
KW  - closed loop system
KW  - numerical simulation
KW  - two-wheeled vehicle
KW  - feedback controller
KW  - generalized canonical transformation
KW  - Impedance
KW  - Control systems
KW  - Mechanical systems
KW  - Symmetric matrices
KW  - Man-machine systems
KW  - Mathematical model
KW  - Robots
DO  - 10.1109/IROS.2018.8594087
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a procedure to design a passive nonlinear impedance control for port-Hamiltonian systems. By expressing the system with the port-Hamiltonian system, the proposed method can be applied to the nonholonomic system as well as fully actuated mechanical systems. The feedback controller for nonlinear impedance control is acquired by utilizing the results of generalized canonical transformation for port-Hamiltonian system. In addition, we investigate the passivity of the closed loop system and discuss the characteristics of the controlled system. A numerical simulation of two-wheeled vehicle shows the effectiveness of the proposed control method.
ER  - 

TY  - CONF
TI  - Riding and Speed Governing for Parallel Two-Wheeled Scooter Based on Sequential Online Learning Control by Humanoid Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Kimura
AU  - S. Nozawa
AU  - H. Mizohana
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - cascade control
KW  - closed loop systems
KW  - control engineering computing
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - motorcycles
KW  - torque control
KW  - velocity control
KW  - wheels
KW  - foot torque control
KW  - speed governing control
KW  - parallel two-wheeled scooter
KW  - sequential online tuning
KW  - controller gains
KW  - sequential online learning control method
KW  - SGD-based open-loop learning control
KW  - HRP2-JSK humanoid robot
KW  - cascade connection
KW  - minibatch-based closed-loop learning control
KW  - Motorcycles
KW  - Tuning
KW  - Foot
KW  - Humanoid robots
KW  - Damping
KW  - Control systems
KW  - Torque
DO  - 10.1109/IROS.2018.8593685
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The sequential online tuning for controller gains is required for the continuous action of the riding into parallel two-wheeled scooter and the speed governing after riding by humanoid robot. The implemented controllers are different between the riding and the speed governing, and these tuning strategies are also different. In particular, the riding requires the immediate tuning in the short riding phase and the speed governing requires the accurate tuning to regulate the speed of humanoid robot. To the above requirements, this paper proposes the Sequential Online Learning Control (SOLC)method composed of the cascade connection of SGD-based open-loop Learning Control (SLC)and Mini-batch-based closed-loop Learning Control (MLC). SLC contributes the damping gain online tuning for the foot torque control during execution of riding, and MLC contributes the PID gains online tuning for the speed governing control. Finally, we show the validity of SOLC through the sequential experiment of riding and speed governing for parallel two-wheeled scooter by life-sized humanoid robot HRP2-JSK.
ER  - 

TY  - CONF
TI  - Dynamic Modelling and Motion Planning for the Nonprehensile Manipulation and Locomotion Tasks of the Quadruped Rsbot*This work is supported by the project of Robotics Innovation Based on Advanced Materials under Ritsumeikan Global Innovation Research Organization (R-GIRO)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Zhang
AU  - S. Ma
AU  - Y. Li
PY  - 2018
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - Drive Mode
KW  - Inchworm Mode
KW  - Scoot Mode
KW  - universal model
KW  - dynamic equation
KW  - contact force constraints
KW  - system state variables
KW  - system state paths
KW  - robot motions
KW  - nonprehensile manipulation
KW  - locomotion tasks
KW  - quadruped robot
KW  - dynamic modelling
KW  - motion planning method
KW  - state acceleration constraints
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Force
KW  - Friction
KW  - Mathematical model
KW  - Planning
DO  - 10.1109/IROS.2018.8593712
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the dynamic modelling and motion planning method for a quadruped robot that uses its legs for nonprehensile manipulation as well as locomotion. Three different working modes named Drive Mode, Inchworm Mode and Scoot Mode are proposed to enable the robot to move forward together with the object. We firstly introduce a universal model for these modes and deduce its dynamic equation. Then the contact force constraints are combined and mapped to the system state variables. Based on the acquired state acceleration constraints, the motion planning problem can be solved by designing system state paths in the phase space. After that, we described the mathematical problems within the three working modes and generate the robot motions accordingly. Finally, experimental results obtained through simulations and physical tests are reported to demonstrate the effectiveness of our method.
ER  - 

TY  - CONF
TI  - Fuzzy-Based Feedback Control of a Tip-Mounted Module for Robot-Assisted Endoscopy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Gafford
AU  - H. Aihara
AU  - C. Thompson
AU  - C. Walsh
AU  - R. Wood
PY  - 2018
KW  - actuators
KW  - biomedical optical imaging
KW  - cancer
KW  - closed loop systems
KW  - dexterous manipulators
KW  - endoscopes
KW  - feedback
KW  - medical robotics
KW  - position control
KW  - surgery
KW  - telerobotics
KW  - three-term control
KW  - intestinal perforation
KW  - sensory feedback
KW  - tip-mounted robotic system
KW  - commercially-available endoscopic tools
KW  - feedback sensing
KW  - on-board actuators
KW  - tool motion
KW  - endoscope motion
KW  - alternative high-energy-density actuation strategies
KW  - monolithic circuit-inspired manufacturing processes
KW  - printed-circuit-inspired manufacturing processes
KW  - distally-mounted module
KW  - proximal motor package
KW  - fuzzy-tuned PID/PWM controller
KW  - closed-loop position-controlled trajectory execution
KW  - distal loop closure
KW  - endoscope-mounted robotic module
KW  - proximal actuation
KW  - controller performance
KW  - feedback control
KW  - robot-assisted endoscopy
KW  - nascent endoscopic therapeutic procedures
KW  - endoscopic submucosal dissection
KW  - mid-size cancerous neoplasia
KW  - gastrointestinal tract
KW  - distal dexterity
KW  - cognitive loading
KW  - tip-mounted module
KW  - realtime rate-based teleoperation
KW  - endoscopic module for on-demand robotic assistance
KW  - Robot sensing systems
KW  - Actuators
KW  - Tools
KW  - Endoscopes
KW  - Cooling
DO  - 10.1109/IROS.2018.8593764
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nascent endoscopic therapeutic procedures, such as endoscopic submucosal dissection, enable unparalleled access to and removal of mid-size cancerous neoplasia from within the gastrointestinal tract. However, the remote locations of these lesions often incur substantial distal dexterity which imparts appreciable cognitive loading on the clinician and opens up the possibility of adverse events such as intestinal perforation due to limited dexterity and a lack of sensory feedback. In this work, we introduce a mm-scale, tip-mounted robotic system, EndoMODRA (Endoscopic Module for On-Demand Robotic Assistance), which interfaces with commercially-available endoscopic tools and provides additional dexterity and feedback sensing using on-board actuators and sensors, decoupling tool motion from endoscope motion. Leveraging alternative high-energy-density actuation strategies and monolithic, printed-circuit-inspired manufacturing processes, all actuation and sensing is fully contained within the distally-mounted module, obviating the need for a continuous mechanical transmission to a proximal motor package. We develop a fuzzy-tuned PID/PWM controller for closing the loop distally to enable closed-loop position-controlled trajectory execution using onboard actuation and sensing, realizing fully -distal loop closure in an endoscope-mounted robotic module with no proximal actuation or sensing component. Controller performance is validated on a fully-integrated module with on-board sensing, demonstrating the ability to execute pre-determined trajectories as well as real-time rate-based teleoperation.
ER  - 

TY  - CONF
TI  - A Real- Time Solver for Time-Optimal Control of Omnidirectional Robots with Bounded Acceleration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8027
EP  - 8032
AU  - D. Balaban
AU  - A. Fischer
AU  - J. Biswas
PY  - 2018
KW  - approximation theory
KW  - boundary-value problems
KW  - closed loop systems
KW  - maximum principle
KW  - mobile robots
KW  - optimisation
KW  - bounded acceleration
KW  - boundary value problem
KW  - optimization problem
KW  - parameterized control space
KW  - two-stage optimal control solver
KW  - real- time solver
KW  - time-optimal control
KW  - omnidirectional robots
KW  - TOC-ORBA problem
KW  - approximate solutions
KW  - exact solutions
KW  - Pontryagin's maximum principle
KW  - closed loop controller
KW  - TSOCS
KW  - Acceleration
KW  - Robot kinematics
KW  - Trajectory
KW  - Mobile robots
KW  - Optimal control
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594306
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We are interested in the problem of time-optimal control of omnidirectional robots with bounded acceleration (TOC-ORBA). While there exist approximate solutions for such problems, and exact solutions with unbounded acceleration, exact solvers to the TOC-ORBA problem have remained elusive until now. In this paper, we present a real-time solver for true time-optimal control of omnidirectional robots with bounded acceleration. We first derive the general parameterized form of the solution to the TOC-ORBA problem by application of Pontryagin's maximum principle. We then frame the boundary value problem of TOC-ORBA as an optimization problem over the parameterized control space. To overcome local minima and poor initial guesses to the optimization problem, we introduce a two-stage optimal control solver (TSOCS): The first stage computes an upper bound to the total time for the TOC-ORBA problem and holds the time constant while optimizing the parameters of the trajectory to approach the boundary value conditions. The second stage uses the parameters found by the first stage, and relaxes the constraint on the total time to solve for the parameters of the complete TOC-ORBA problem. Furthermore, we implement TSOCS as a closed loop controller to overcome actuation errors on real robots in realtime. We empirically demonstrate the effectiveness of TSOCS in simulation and on real robots, showing that 1) it runs in real time, generating solutions in less than 0.5ms on average; 2) it generates faster trajectories compared to an approximate solver; and 3) it is able to solve TOC-ORBA problems with nonzero final velocities that were previously unsolvable in real-time.
ER  - 

TY  - CONF
TI  - A Variable Degree-of-Freedom and Self-Sensing Soft Bending Actuator Based on Conductive Liquid Metal and Thermoplastic Polymer Composites
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Hao
AU  - Z. Liu
AU  - Z. Xie
AU  - X. Fang
AU  - T. Wang
AU  - L. Wen
PY  - 2018
KW  - grippers
KW  - liquid metals
KW  - plastic deformation
KW  - pneumatic actuators
KW  - polymers
KW  - shape memory effects
KW  - self-sensing soft bending actuator
KW  - conductive liquid metal
KW  - thermoplastic polymer composites
KW  - thermoplastic shape memory epoxy
KW  - bending strain
KW  - pneumatic actuators
KW  - contact force
KW  - Actuators
KW  - Robot sensing systems
KW  - Force
KW  - Resistance
KW  - Force sensors
KW  - Shape
KW  - Yarn
DO  - 10.1109/IROS.2018.8593658
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a soft actuator embedded with conductive liquid metal and shape memory epoxy (SME) which function together to enable self-sensing, tunable mechanical degrees of freedom (DoF), and variable stiffness. We embedded thermoplastic shape memory epoxy in the bottom portion of the actuator. Different sections of the SME could be selectively softened by an implanted conductive silver yarn located at different positions. When an electric current passes through the conductive silver yarn, it induces a phase transition that changes the epoxy from stiff state to compliant state. Each section of SME could be softened within 5 s by applying a current of 200 mA to the silver yarn. To acquire the strain curvature, eGaIn was infused into a microchannel surrounding the chambers of the soft actuator. A spiral-shaped eGaIn sensor was also attached to the tip of the actuator to perceive the contact with reliable dynamic force response. Systematic experiments were performed to characterize the stiffness, tunable DoF, and sensing property. We show the ability of the soft composite actuator to support a weight of 200g at the tip (as a cantilever) while maintaining the shape and the ability to recover its original shape after large bending deformation. In particular, seven different motion patterns could be achieved under the same pneumatic pressure of the actuator due to selectively heating the SME sections. A gripper which was fabricated by assembling two actuators to a base was able to grasp the weight up to 56 times of a single actuator through an appropriate motion pattern. For demonstration purposes, the gripper was used to grasp various objects by adjusting the DoF and stiffness with real-time feedback of the bending strain and the contact force.
ER  - 

TY  - CONF
TI  - A New Manufacturing Process for Soft Robots and Soft/Rigid Hybrid Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8039
EP  - 8046
AU  - H. D. Yang
AU  - A. T. Asbeck
PY  - 2018
KW  - adhesion
KW  - adhesives
KW  - design engineering
KW  - inflatable structures
KW  - robots
KW  - textiles
KW  - multichambered inflatable structures
KW  - thermal adhesive film
KW  - heat press
KW  - bond strength
KW  - soft-rigid hybrid robotic arm
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593688
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel manufacturing process for creating monolithic, multi-chambered inflatable structures including both soft and rigid components. Specifically, our process involves stacking layers of textiles or plastics and thermal adhesive film, then bonding the structure with a heat press or in an oven. Several different ways of arranging textiles and thermal adhesive film in order to achieve airtight structures are presented. Since this process only uses materials that bend, but do not stretch, it permits the easy inclusion of rigid structures such as circuit boards, plates that constrain inflatable chambers to bend in specified locations, and rigid pieces that enable sections of a robot to be connected in a modular fashion. Additionally, the process permits folding layers before their assembly, leading to more complex geometries. We present three different possible seam types, and enumerate the different types of corners that can be constructed without leaking. We present measurements of the ability of these structures to support pressure and measurements of the strength of bonds between textiles and other materials. Finally, we present two examples of robots constructed using this manufacturing method, including a hybrid soft/rigid robotic arm and a soft robot that can roll along the ground.
ER  - 

TY  - CONF
TI  - Magnetic-Field-Inspired Navigation for Soft Continuum Manipulator*This work was supported in part by King's College London, the EPSRC in the framework of the NCNR (National Centre for Nuclear Robotics) project (EP/R02572X/1), the STIFF-FLOP project grant from the European Communities Seventh Framework Programme under grant agreement 287728, and the Indonesia Endowment Fund for Education, Ministry of Finance Republic of Indonesia.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 168
EP  - 173
AU  - A. Ataka
AU  - A. Shiva
AU  - H. K. Lam
AU  - K. Althoefer
PY  - 2018
KW  - collision avoidance
KW  - manipulators
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - 2-segment soft continuum arm
KW  - unknown environments
KW  - reactive navigation method
KW  - magnetic fields
KW  - soft continuum manipulator
KW  - magnetic-field-inspired navigation
KW  - Manipulators
KW  - Navigation
KW  - Force
KW  - Wires
KW  - Collision avoidance
KW  - Service robots
DO  - 10.1109/IROS.2018.8593592
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Taking inspiration from the properties of magnetic fields, we propose a reactive navigation method for soft continuum manipulators operating in unknown environments. The proposed navigation method outperforms previous works since it is able to successfully achieve collision-free movements towards the goal in environments with convex obstacles without relying on a priori information of the obstacles' shapes and locations. Simulations for the kinematic model of a soft continuum manipulator and preliminary experiments with a 2-segments soft continuum arm are performed, showing promising results and the potential for our approach to be applied widely.
ER  - 

TY  - CONF
TI  - Real-Time Shape Estimation of an Elastic Rod Using a Robot Manipulator Equipped with a Sense of Force
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8067
EP  - 8073
AU  - N. Nakagawa
AU  - H. Mochiyama
PY  - 2018
KW  - elasticity
KW  - end effectors
KW  - force control
KW  - manipulators
KW  - position control
KW  - rods (structures)
KW  - time shape estimation
KW  - robot manipulator equipped
KW  - real-time method
KW  - optical sensing devices
KW  - force/torque information
KW  - discretized Kirchhoff elastic rod model
KW  - three-dimensional shape
KW  - force information
KW  - manipulator end-effector
KW  - elastic strip
KW  - typical elastic rod
KW  - average calculation time
KW  - strip shape
KW  - size 142.0 mm
KW  - Shape
KW  - Manipulators
KW  - Gravity
KW  - Torque
KW  - Estimation
KW  - Sensors
DO  - 10.1109/IROS.2018.8593946
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a real-time method for estimating the shape of an elastic rod using a robot manipulator equipped with a sense of force. The proposed method does not use optical sensing devices, such as cameras or lasers, but relies only upon the sense of force in the manipulator. In the proposed method, the deformation of an elastic rod is calculated from the obtained force/torque information using the discretized Kirchhoff elastic rod model, and the three-dimensional shape of the rod is then estimated. Furthermore, by integrating the force information with the orientation of the manipulator end-effector, the proposed method can evaluate the effect of gravity on the shape estimation accurately. Experiments were carried out to verify the proposed method, where a thin elastic strip was employed as a typical elastic rod, attached to the end-effector of the robot manipulator, bent and twisted into various shapes. The results show that the proposed method that compensates for gravity is better than a method without gravity compensation, and it estimated the 142 mm length strip shape with a position error no greater than 7.76 mm and an average calculation time of 4.24 ms.
ER  - 

TY  - CONF
TI  - FOCS: Planning by Fusion of Optimal Control & Search and its Application to Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8082
EP  - 8088
AU  - P. Micelli
AU  - M. Likhachev
PY  - 2018
KW  - graph theory
KW  - optimal control
KW  - path planning
KW  - car-like vehicle
KW  - Hamilton-Jacobi-Bellman equation
KW  - FOCS
KW  - minimum-time path
KW  - returned path
KW  - sub-optimality
KW  - path planning
KW  - Search-based Planning
KW  - Optimal Control & Search
KW  - Planning
KW  - Optimal control
KW  - Robots
KW  - Optimized production technology
KW  - Heuristic algorithms
KW  - Dynamic programming
KW  - Search problems
DO  - 10.1109/IROS.2018.8594487
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Both Optimal Control and Search-based Planning are used extensively for path planning and have their own set of advantages and disadvantages. In this paper, we propose an algorithm FOCS (Fusion of Optimal Control and Search) that combines these two classes of approaches together. FOCS finds a path exploiting the advantages of both approaches while providing a bound on the sub-optimality of its solution. The returned path is a concatenation of the path found in the implicit graph constructed by search and the path generated by following the negative gradient of the value function obtained as a solution of the Hamilton-Jacobi-Bellman equation. We analyze the algorithm and illustrate its effectiveness in finding a minimum-time path for a car-like vehicle in different environments.
ER  - 

TY  - CONF
TI  - Quotient-Space Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8089
EP  - 8096
AU  - A. Orthey
AU  - A. Escande
AU  - E. Yoshida
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - quotient-space motion planning
KW  - OMPL
KW  - robot
KW  - Quotient-space roadMap Planner
KW  - roadmap-based motion planning algorithm
KW  - nested quotient-space decomposition
KW  - open motion planning library
KW  - Planning
KW  - Manipulators
KW  - Runtime
KW  - Visualization
KW  - Probabilistic logic
KW  - Manifolds
DO  - 10.1109/IROS.2018.8593554
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A motion planning algorithm computes the motion of a robot by computing a path through its configuration space. To improve the runtime of motion planning algorithms, we propose to nest robots in each other, creating a nested quotient-space decomposition of the configuration space. Based on this decomposition we define a new roadmap-based motion planning algorithm called the Quotient-space roadMap Planner (QMP). The algorithm starts growing a graph on the lowest dimensional quotient space, switches to the next quotient space once a valid path has been found, and keeps updating the graphs on each quotient space simultaneously until a valid path in the configuration space has been found. We show that this algorithm is probabilistically complete and outperforms a set of state-of-the-art algorithms implemented in the open motion planning library (OMPL).
ER  - 

TY  - CONF
TI  - Computing a Collision-Free Path Using the Monogenic Scale Space
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8097
EP  - 8102
AU  - K. Holmquist
AU  - O. Şenel
AU  - M. Felsberg
PY  - 2018
KW  - collision avoidance
KW  - Laplace equations
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - static obstacles
KW  - dynamic obstacles
KW  - mobile robot
KW  - safe path
KW  - goal position
KW  - Laplace equation
KW  - collision-free path
KW  - rectangular bounded domain
KW  - monogenic scale space
KW  - environment map
KW  - nonconvex environments
KW  - functionalities
KW  - Kernel
KW  - Laplace equations
KW  - Mathematical model
KW  - Mobile robots
KW  - Magnetic domains
KW  - Magnetic resonance imaging
DO  - 10.1109/IROS.2018.8593583
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robots have been used for various purposes with different functionalities which require them to freely move in environments containing both static and dynamic obstacles to accomplish given tasks. One of the most relevant capabilities in terms of navigating a mobile robot in such an environment is to find a safe path to a goal position. This paper shows that there exists an accurate solution to the Laplace equation which allows finding a collision-free path and that it can be efficiently calculated for a rectangular bounded domain such as a map which is represented as an image. This is accomplished by the use of the monogenic scale space resulting in a vector field which describes the attracting and repelling forces from the obstacles and the goal. The method is shown to work in reasonably convex domains and by the use of tessellation of the environment map for non-convex environments.
ER  - 

TY  - CONF
TI  - Automatic Parameter Tuning of Motion Planning Algorithms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8103
EP  - 8109
AU  - J. Cano
AU  - Y. Yang
AU  - B. Bodin
AU  - V. Nagarajan
AU  - M. O'Boyle
PY  - 2018
KW  - Bayes methods
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - sampling methods
KW  - random sampling
KW  - AUC-Bandit
KW  - random forest
KW  - motion planning algorithms
KW  - RRT-connect
KW  - table-top-reaching scenario
KW  - BKPIECE
KW  - random scenarios
KW  - parameter configurations
KW  - automatic parameter tuning
KW  - motion planning
KW  - default parameter values
KW  - Bayesian optimisation
KW  - KUKA LWR robotic arm
KW  - Planning
KW  - Tuning
KW  - Optimization
KW  - Bayes methods
KW  - Manipulators
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594183
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning algorithms attempt to find a good compromise between planning time and quality of solution. Due to their heuristic nature, they are typically configured with several parameters. In this paper we demonstrate that, in many scenarios, the widely used default parameter values are not ideal. However, finding the best parameters to optimise some metric(s) is not trivial because the size of the parameter space can be large. We evaluate and compare the efficiency of four different methods (i.e. random sampling, AUC-Bandit, random forest, and bayesian optimisation) to tune the parameters of two motion planning algorithms, BKPIECE and RRT-connect. We present a table-top-reaching scenario where the seven degrees-of-freedom KUKA LWR robotic arm has to move from an initial to a goal pose in the presence of several objects in the environment. We show that the best methods for BKPIECE (AUC-Bandit) and RRT-Connect (random forest) improve the performance by 4.5x and 1.26x on average respectively. Then, we generate a set of random scenarios of increasing complexity, and we observe that optimal parameters found in simple environments perform well in more complex scenarios. Finally, we find that the time required to evaluate parameter configurations can be reduced by more than 2/3 with low error. Overall, our results demonstrate that for a variety of motion planning problems it is possible to find solutions that significantly improve the performance over default configurations while requiring very reasonable computation times.
ER  - 

TY  - CONF
TI  - Perception-Driven Sparse Graphs for Optimal Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8110
EP  - 8117
AU  - T. Sayre-McCord
AU  - S. Karaman
PY  - 2018
KW  - collision avoidance
KW  - graph theory
KW  - mobile robots
KW  - optimal control
KW  - optimisation
KW  - robot vision
KW  - trajectory control
KW  - motion plan generation
KW  - planning subproblem
KW  - mapping subproblem
KW  - optimal motion planning
KW  - perception-driven sparse graphs
KW  - optimal trajectory
KW  - plan graphs
KW  - visual sensors
KW  - Planning
KW  - Trajectory
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8594209
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most existing motion planning algorithms assume that a map (of some quality) is fully determined prior to generating a motion plan. In many emerging applications of robotics, e.g., fast-moving agile aerial robots with constrained embedded computational platforms and visual sensors, dense maps of the world are not immediately available, and they are computationally expensive to construct. We propose a new algorithm for generating plan graphs which couples the perception and motion planning processes for computational efficiency. In a nutshell, the proposed algorithm iteratively switches between the planning sub-problem and the mapping sub-problem, each updating based on the other until a valid trajectory is found. The resulting trajectory retains a provable property of providing an optimal trajectory with respect to the full (unmapped) environment, while utilizing only a fraction of the sensing data in computational experiments.
ER  - 

TY  - CONF
TI  - Social Cohesion in Autonomous Driving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8118
EP  - 8125
AU  - N. C. Landolfi
AU  - A. D. Dragan
PY  - 2018
KW  - automobiles
KW  - control engineering computing
KW  - mobile robots
KW  - road safety
KW  - road traffic
KW  - statistical analysis
KW  - traffic information systems
KW  - social cohesion
KW  - autonomous driving
KW  - autonomous car
KW  - perception issues
KW  - incorrect dynamics models
KW  - obscure rules
KW  - human traffic systems
KW  - exact failure mode
KW  - socially cohesive cars
KW  - nearby human drivers
KW  - socially acceptable behavior
KW  - Automobiles
KW  - Roads
KW  - Autonomous automobiles
KW  - Trajectory
KW  - Autonomous vehicles
DO  - 10.1109/IROS.2018.8593682
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous cars can perform poorly for many reasons. They may have perception issues, incorrect dynamics models, be unaware of obscure rules of human traffic systems, or follow certain rules too conservatively. Regardless of the exact failure mode of the car, often human drivers around the car are behaving correctly. For example, even if the car does not know that it should pull over when an ambulance races by, other humans on the road will know and will pull over. We propose to make socially cohesive cars that leverage the behavior of nearby human drivers to act in ways that are safer and more socially acceptable. The simple intuition behind our algorithm is that if all the humans are consistently behaving in a particular way, then the autonomous car probably should too. We analyze the performance of our algorithm in a variety of scenarios and conduct a user study to assess people's attitudes towards socially cohesive cars. We find that people are surprisingly tolerant of mistakes that cohesive cars might make in order to get the benefits of driving in a car with a safer, or even just more socially acceptable behavior.
ER  - 

TY  - CONF
TI  - Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Forer
AU  - S. B. Banisetty
AU  - L. Yliniemi
AU  - M. Nicolescu
AU  - D. Feil-Seifer
PY  - 2018
KW  - human-robot interaction
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - Pareto optimisation
KW  - path planning
KW  - nonlinear multiobjective optimization
KW  - socially assistive robots
KW  - complex environments
KW  - stochastic human environments
KW  - subtle social norms
KW  - socially-aware navigation
KW  - multiobjective optimization tool
KW  - PaC-cET
KW  - nonlinear human navigation behavior
KW  - autonomously-sensed distance-based features
KW  - social costs
KW  - finely-tuned linear combination
KW  - optimized future trajectory point
KW  - PaCcET-based trajectory planner
KW  - human-robot interaction community
KW  - Pareto concavity elimination transformation
KW  - model-based approaches
KW  - Navigation
KW  - Trajectory
KW  - Optimization
KW  - Robot sensing systems
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593825
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For socially assistive robots (SAR)to be accepted into complex and stochastic human environments, it is important to account for subtle social norms. In this paper, we propose a novel approach to socially-aware navigation (SAN)which garnered an immense interest in the Human-Robot Interaction (HRI)community. We use a multi-objective optimization tool called the Pareto Concavity Elimination Transformation (PaC-cET)to capture the non-linear human navigation behavior, a novel contribution to the community. A candidate point on a trajectory is scored (1)for its progress towards the goal, and (2)based on autonomously-sensed distance-based features that capture the social norms and associated social costs. Rather than use a finely-tuned linear combination of these costs, we use PaCcET to select an optimized future trajectory point, associated with a non-linear combination of the costs. Existing research in this domain concentrates on geometric reasoning, model-based, and learning approaches, which have their own pros and cons. This approach is distinct from prior work in this area. We showed in a simulation that the PaCcET-based trajectory planner not only is able to avoid collisions and reach the intended destination in static and dynamic environments but also considers a human's personal space i.e. rules of proxemics in the trajectory selection process.
ER  - 

TY  - CONF
TI  - Constrained Path Planning Using Quadratic Programming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8134
EP  - 8139
AU  - F. Fusco
AU  - O. Kermorgant
AU  - P. Martinet
PY  - 2018
KW  - iterative methods
KW  - manipulator kinematics
KW  - path planning
KW  - quadratic programming
KW  - kinematic loops
KW  - local motions
KW  - iterative scheme
KW  - geometric loop-closure
KW  - CS
KW  - lower-dimensional manifold
KW  - contact forces
KW  - quadratic optimization
KW  - quadratic programming
KW  - constrained configuration space
KW  - constrained path planning
KW  - sampling-based planning algorithms
KW  - Manifolds
KW  - Jacobian matrices
KW  - Optimization
KW  - Planning
KW  - End effectors
KW  - Interpolation
DO  - 10.1109/IROS.2018.8593373
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling-based planning algorithms have been extensively exploited to solve a wide variety of problems. In recent years, many efforts have been dedicated to extend these tools to solve problems involving constraints, such as geometric loop-closure, which lead the valid Configuration Space (CS) to collapse to a lower-dimensional manifold. One proposed solution considers an approximation of the constrained Configuration Space that is obtained by relaxing constraints up to a desired tolerance. The resulting set has then non-zero measure, allowing to exploit classical planning algorithms to search for a path connecting two given states. When constraints involve kinematic loops in the system, relaxation generally bears to undesired contact forces, which need to be compensated during execution by a proper control action. We propose a new tool that exploits relaxation to plan in presence of constraints. Local motions inside the approximated manifold are found as the result of an iterative scheme that uses Quadratic Optimization to proceed towards a new sample without falling outside the relaxed region. By properly guiding the exploration, paths are found with smaller relaxation factors and the need of a dedicated controller to compensate errors is reduced. We complete the analysis by showing the feasibility of the approach with experiments on a real platform.
ER  - 

TY  - CONF
TI  - Ladder Climbing with a Snake Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Takemori
AU  - M. Tanaka
AU  - F. Matsuno
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - gait design method
KW  - ladder climbing method
KW  - snake robot
KW  - Snake robots
KW  - Shape
KW  - Propulsion
KW  - Modeling
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594411
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a method that allows a snake robot to climb a ladder. We propose a ladder climbing method for a snake robot that has a smooth surface shape. We design a novel gait for the snake using a gait design method that configures the target form of the snake robot by connecting simple shapes. The climbing motion is executed via shift control and the corresponding motion required to catch the next step on the ladder. In addition, we developed a snake robot that has a smooth exterior body surface through construction of pectinate-shaped parts of the links. We demonstrated the effectiveness of both the proposed gait and the design of the snake robot experimentally.
ER  - 

TY  - CONF
TI  - Modeling of Robotic Fish Propelled by a Servo/IPMC Hybrid Tail
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8146
EP  - 8151
AU  - Z. Chen
AU  - P. Hou
AU  - Z. Ye
PY  - 2018
KW  - actuators
KW  - biomimetics
KW  - electroactive polymer actuators
KW  - mobile robots
KW  - motion control
KW  - muscle
KW  - propulsion
KW  - robot dynamics
KW  - servomotors
KW  - steering systems
KW  - IPMC soft actuator
KW  - two-link tail motion dynamics
KW  - body motion dynamics
KW  - servo motor
KW  - propelled fluid
KW  - actuation dynamics
KW  - ionic polymer-metal composite artificial muscle
KW  - servo-IPMC hybrid tail
KW  - flapping motion
KW  - robotic fish propulsion
KW  - steering system
KW  - turning speed
KW  - Fish
KW  - Servomotors
KW  - Dynamics
KW  - Actuators
KW  - Two dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593640
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents modeling of robotic fish propelled by a hybrid tail with Servo and IPMC actuated two joints. The first joint is driven by a servo motor, which generates flapping motion for main propulsion. The second joint is actuated by a soft actuator, or ionic polymer-metal composite (IPMC) artificial muscle, which directs the propelled fluid for steering. A dynamic model is developed to capture the 2D motion dynamics of the robotic fish. The model fully captures the actuation dynamics of the IPMC soft actuator, two-link tail motion dynamics, and body motion dynamics. Experimental results have shown that the robotic fish is capable of swimming forward (up to 0.45 body length/second) and turning left and right (up to 40 degree/sec) with a small turning radius (less than half a body length). Finally, the dynamic model has been validated with experimental data, in terms of steady-state forward speed and turning speed versus the flapping frequency.
ER  - 

TY  - CONF
TI  - Blade-Type Crawler Capable of Running on the Surface of Water as Bio-Inspired by a Basilisk Lizard
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Yamada
AU  - T. Nakamura
PY  - 2018
KW  - blades
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - hard-to-reach-locations
KW  - water surface
KW  - basilisk lizard
KW  - blade-type crawler robot
KW  - terrain adaptability
KW  - Crawlers
KW  - Blades
KW  - Wheels
KW  - Rough surfaces
KW  - Surface roughness
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8594397
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For unmanned rescue, observation, and/or research, vehicles with high terrain adaptability, high speed, and high reliability are needed to reach hard-to-reach-locations. In order to extend the areas that can be explored, we propose a method and a robot capable of running on the surface of water without having to bypass the puddles and streams that exist on uneven terrain. The method that enables the robot to run on the water surface is bio-inspired by the basilisk lizard that can walk on the surface of water. We developed a blade-type crawler robot with a simple and reliable mechanism, capable of traversing uneven terrain at high speed. The robot with the method was tested on a real water surface and the result confirmed the ability of the robot to run on the water surface.
ER  - 

TY  - CONF
TI  - Bio-Inspired Design of a Gliding-Walking Multi-Modal Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8158
EP  - 8164
AU  - W. D. Shin
AU  - J. Park
AU  - H. Park
PY  - 2018
KW  - aerospace robotics
KW  - design engineering
KW  - legged locomotion
KW  - Pteromyini
KW  - multimodal robot gliding
KW  - multimodal robot walking
KW  - multimodal locomotion robot
KW  - regulated motor torques
KW  - robot design
KW  - flexible membrane
KW  - terrestrial locomotion
KW  - aerial locomotion
KW  - flying squirrel
KW  - bio-inspired design
KW  - Legged locomotion
KW  - Aerodynamics
KW  - Muscles
KW  - Drag
KW  - Stability analysis
KW  - Thermal stability
DO  - 10.1109/IROS.2018.8594210
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Versatile multi-modal robots are advantageous for their wider operational environments. By taking design principles from observation of Pteromyini, commonly known as the flying squirrel, which shows balanced performances in both aerial and terrestrial locomotion, a novel robotic platform with the ability of gliding and walking is designed. The flexible membrane and gliding method of Pteromyini have been applied to the robot design. The legs of the robot were optimized to perform with regulated motor torques in both walking and gliding. The robot glided with an average gliding ratio of 1.88 and controlled its angle-of-attack for slowing down to land safely. The robot was able to walk utilizing different gait patterns. These results demonstrated our robot's balanced multi-modal locomotion of gliding and walking.
ER  - 

TY  - CONF
TI  - Design of Lizard-Inspired Robot with Lateral Body Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Kim
AU  - H. Kim
AU  - Y. Kim
AU  - H. S. Kim
AU  - J. Kim
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - bipedal running
KW  - 4-bar mechanism
KW  - hind leg
KW  - revolute joints
KW  - dynamic model
KW  - lizard-inspired robot
KW  - lateral body motion
KW  - Legged locomotion
KW  - Dynamics
KW  - Foot
KW  - Atmospheric modeling
KW  - Force
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594086
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new lizard-inspired robot is presented in this paper, which enables to maintain its moving direction by lateral body motions even during high-speed bipedal running. First, a dynamic model for lizard-inspired robot is derived to simulate the lateral body motion of real lizard. Based upon the simulation using dynamic model, the lizard-inspired robot is tactfully built so that its hind leg is optimally designed on a 4-bar mechanism and its body is simplified to consist of two body links and a tail connected by two revolute joints. The experiments verify that the proposed robot can maintain its moving direction via proper lateral motions during high-speed bipedal running similar to that of real lizard.
ER  - 

TY  - CONF
TI  - Natural Dynamics Exploitation of Dynamic Soaring: Towards Bio-Inspired and Energy Efficient Flying Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8171
EP  - 8176
AU  - M. Nekoui
AU  - J. Khaghani
AU  - R. Nasiri
AU  - M. N. Ahmadabadi
PY  - 2018
KW  - biomimetics
KW  - energy conservation
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - energy efficient flying locomotion
KW  - flying robots
KW  - robust gaits
KW  - albatross dynamic soaring
KW  - biological perspectives
KW  - trajectory control
KW  - mechanical energy regulation
KW  - bio-inspired locomotion
KW  - seabirds
KW  - stability
KW  - Mechanical energy
KW  - Aerodynamics
KW  - Trajectory
KW  - Mathematical model
KW  - Birds
KW  - Robots
KW  - Bio-inspired locomotion
KW  - Energy efficiency
KW  - Natural dynamics exploitation
KW  - Dynamic soaring
KW  - Cyclic tasks
DO  - 10.1109/IROS.2018.8594137
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Albatross has an energy efficient flying pattern (dynamic soaring) among seabirds. This interesting point encourages us to exploit its flying natural dynamics so as to control the flying robots on energy efficient and robust gaits. In doing so, we study the albatross dynamic soaring from analytical and biological perspectives and realize that to generate the dynamic soaring instead of trajectory control, the mechanical energy should be regulated. Accordingly, the control objective is set to mechanical energy regulation, and the bank angle and lift coefficient are computed to satisfy this objective. The presented method is simulated on a standard albatross model and generates two different types of dynamic soaring; O-shaped and a-shaped patterns. In addition, by means of simulations, it is investigated that the presented method is robust in face of variations in initial conditions and unexpected disturbances in the environment's model; i.e., they cannot disturb the stability and cyclic behavior of the system. Moreover, the simulation results are compared with pieces of natural evidence from albatross and interesting similarities are observed.
ER  - 

TY  - CONF
TI  - Development of High-Speed Type Peristaltic Crawling Robot for Long-Distance and Complex-Line Sewer Pipe Inspection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8177
EP  - 8183
AU  - Y. Mano
AU  - R. Ishikawa
AU  - Y. Yamada
AU  - T. Nakamura
PY  - 2018
KW  - electroactive polymer actuators
KW  - inspection
KW  - mobile robots
KW  - pipelines
KW  - sanitary engineering
KW  - sewer pipe inspection
KW  - locomotion
KW  - artificial muscle fastening
KW  - high-speed type peristaltic crawling robot
KW  - Muscles
KW  - Cameras
KW  - Robot vision systems
KW  - Mathematical model
KW  - Inspection
KW  - Contracts
DO  - 10.1109/IROS.2018.8593436
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Currently, serious accidents are caused frequently by the aging of sewer pipes. Therefore, to inspect sewer pipes, we developed a peristaltic crawling robot that reproduces the locomotion of an earthworm. This robot can drive for more than 100m, and it can be used for the maintenance of sewer pipes (100A pipes). However, the speed of the robot is low. There are two causes. First, the units of the previous robot have steps of artificial muscle fastening. These steps increase the diameter of the artificial muscles. A smaller diameter of the artificial muscles is advantageous for the speed of the robot inside the pipes. Second, the previous robot has slow air response. In this study, we used large-sized solenoid valves to overcome this drawback.
ER  - 

TY  - CONF
TI  - Learning and Generation of Actions from Teleoperation for Domestic Service Robots*This work was supported by JST, CREST
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8184
EP  - 8191
AU  - K. Iwata
AU  - T. Aoki
AU  - T. Horii
AU  - T. Nakamura
AU  - T. Nagai
PY  - 2018
KW  - Gaussian processes
KW  - hidden Markov models
KW  - home automation
KW  - intelligent robots
KW  - mobile robots
KW  - motion control
KW  - service robots
KW  - telerobotics
KW  - autonomous household chores
KW  - body motions
KW  - object-dependent Gaussian process
KW  - domestic household chores
KW  - domestic service robots
KW  - motion primitives
KW  - teleoperation
KW  - motion learning
KW  - reference-point Gaussian process
KW  - hidden semiMarkov model
KW  - Task analysis
KW  - Trajectory
KW  - Motion segmentation
KW  - Service robots
KW  - End effectors
DO  - 10.1109/IROS.2018.8593892
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a method for motion learning aimed at the execution of autonomous household chores by service robots in real environments. For robots to act autonomously in a real environment, it is necessary to define the appropriate actions for the environment. However, it is difficult to define these actions manually. Therefore, body motions that are common to multiple actions are defined as motion primitives. Complex actions can then be learned by combining these motion primitives. For learning motion primitives, we propose a reference-point and object-dependent Gaussian process hidden semi-Markov model (RPOD-GP-HSMM). For verification, a robot is teleoperated to perform the actions included in several domestic household chores. The robot then learns the associated motion primitives from the robot's body information and object information.
ER  - 

TY  - CONF
TI  - Proxemics and Approach Evaluation by Service Robot Based on User Behavior in Domestic Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8192
EP  - 8199
AU  - S. M. Bhagya
AU  - P. Samarakoon
AU  - H. P. Chapa Sirithunge
AU  - M. A. V. J. Muthugala
AU  - J. Muthugala
AU  - A. G. Buddhika
AU  - P. Jayasekara
PY  - 2018
KW  - control engineering computing
KW  - fuzzy reasoning
KW  - human-robot interaction
KW  - intelligent robots
KW  - interactive systems
KW  - service robots
KW  - user behavior
KW  - intelligent service robots
KW  - human-friendly interactive features
KW  - MIRob platform
KW  - fuzzy interference system
KW  - domestic environment
KW  - proxemics
KW  - Service robots
KW  - Robot sensing systems
KW  - Navigation
KW  - Robot kinematics
KW  - Wrist
KW  - Task analysis
KW  - Proxemics
KW  - Human behavior
KW  - Human-robot interaction
KW  - Service robots
KW  - Human-centered robotics
DO  - 10.1109/IROS.2018.8593713
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Intelligent service robots are used at a significant level to uplift the living standards of domestic users. These robots are expected to possess human-friendly interactive features. Service robots should be able to provide a variety of tasks to support independent living of users in domestic environments. Therefore, a service robot often needs to approach users to execute these services and the approach toward the users should be human friendly. In order to achieve this, proxemics planner of a service robot should be cable of deciding the approaching proxemics based on user behavior. This paper proposes a method to decide the approaching proxemics based on the behavior of the user. A fuzzy interference system has been designed to decide the proxemics based on the user behavior identified through body parameters. This leads to an effective interaction mechanism initiated by a robot in such a way that the approaching scenario looks more humanlike. The proposed concept has been implemented on MIRob platform and experiments were conducted in an artificially created domestic environment. The experimental results of the proposed system have been compared with results of a human study to evaluate the performance of the system.
ER  - 

TY  - CONF
TI  - Robot Approaching and Engaging People in a Human-Robot Companion Framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8200
EP  - 8205
AU  - E. Repiso
AU  - A. Garrell
AU  - A. Sanfeliu
PY  - 2018
KW  - gradient methods
KW  - human-robot interaction
KW  - path planning
KW  - encounter point
KW  - human-robot group
KW  - user study
KW  - ESFM
KW  - extended social force model
KW  - dynamic environment
KW  - navigation behaviour
KW  - human-robot companion framework
KW  - gradient descent method
KW  - Robots
KW  - Force
KW  - Task analysis
KW  - Dynamics
KW  - Measurement
KW  - Collision avoidance
KW  - Navigation
DO  - 10.1109/IROS.2018.8594149
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a new model to make robots capable of approaching and engaging people with a human-like behavior, while they are walking in a side-by-side formation with a person. This method extends our previous work [1], which allows the robot to adapt its navigation behaviour according to the person being accompanied and the dynamic environment. In the current work, the robot is able to predict the best encounter point between the human-robot group and the approached person. Then, in the encounter point the robot modifies its position to achieve an engagement with both people. The encounter point is computed using a gradient descent method that takes into account all people predictions. Moreover, we make use of the Extended Social Force Model (ESFM), and it is modified to include the dynamic goal. The method has been validated over several situations and in real-life experiments, in addition, a user study has been realized to reveal the social acceptability of the robot in this task.
ER  - 

TY  - CONF
TI  - A 7-Dof Wire-Driven Lightweight Arm with Wide Wrist Motion Range
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Tsumaki
AU  - Y. Suzuki
AU  - N. Sasaki
AU  - E. Obara
AU  - S. Kanazawa
PY  - 2018
KW  - health and safety
KW  - motion control
KW  - prototypes
KW  - robots
KW  - sensors
KW  - human safety
KW  - wrist mechanism
KW  - wide wrist motion range
KW  - sensors
KW  - robot prototype
KW  - integrated wrist-elbow mechanisms
KW  - shoulder mechanism
KW  - robot safety
KW  - robot arms
KW  - 7-DOF wire-driven lightweight arm
KW  - Wires
KW  - Wrist
KW  - Shoulder
KW  - Manipulators
KW  - Collision avoidance
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593515
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Till date, various seven-degrees-of-freedom (7-DOF)robot arms have been developed globally. In general, the robot arms utilized in factories are required to possess speed, power, and accuracy. They are isolated from humans using a fence to ensure human safety. However, a home robot should work near humans at an appropriate speed without a fence. One approach to meeting this requirement involves the installation of various sensors on the robot to control and stop the robot safely even if a collision has occurred. However, a robot system is complicated and expensive. In order to give inherent safety to the robot, we should lighten the robot arm. In this study, a 7-DOF lightweight arm with a wide wrist-motion range is introduced. The weight of movable parts is approximately 2.87 kg. To achieve such properties, we propose the use of three mechanisms: a shoulder mechanism with hollow cylinders, a wrist mechanism with a wide workspace, and an integrated wrist and elbow mechanisms of high power. To verify its feasibility, a prototype of the robot is designed and developed. The experimental results demonstrate its powerful performance and wide workspace of the wrist.
ER  - 

TY  - CONF
TI  - RAMCIP - A Service Robot for MCI Patients at Home
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Peleka
AU  - A. Kargakos
AU  - E. Skartados
AU  - I. Kostavelis
AU  - D. Giakoumis
AU  - I. Sarantopoulos
AU  - Z. Doulgeri
AU  - M. Foukarakis
AU  - M. Antona
AU  - S. Hirche
AU  - E. Ruffaldi
AU  - B. Stanczyk
AU  - A. Zompas
AU  - J. Hernandez-Farigola
AU  - N. Roberto
AU  - K. Rejdak
AU  - D. Tzovaras
PY  - 2018
KW  - assisted living
KW  - cognition
KW  - diseases
KW  - geriatrics
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - service robots
KW  - daily activities
KW  - Mild Cognitive Impairments
KW  - discreet assistance
KW  - MCI patients
KW  - service robot
KW  - home
KW  - RAMCIP robot
KW  - cognitive training games
KW  - robotic manipulations
KW  - discreet user monitoring
KW  - medication activities
KW  - proactive assistance provision
KW  - human-robot communication
KW  - Service robots
KW  - Information technology
KW  - Intelligent robots
KW  - Computer science
KW  - Companies
KW  - Random access memory
DO  - 10.1109/IROS.2018.8594214
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This video features RAMCIP, a new service robot developed to provide proactive and discreet assistance to elderly with Mild Cognitive Impairments (MCI), supporting their daily activities at home. Starting with a thorough analysis of needs and requirements of the target population, the RAMCIP robot was developed as an integrated ensemble of advanced H/W and S/W components, realizing the robot skills of perception, cognition, safe navigation, grasping, manipulation, and human-robot communication, ample to operate in real, rather challenging domestic environments. The RAMCIP use-cases include proactive assistance provision to user's cooking, eating and medication activities, through discreet user monitoring and robot interventions by reminders and robotic manipulations., RAMCIP can bring the medicine, recognize fallen objects and electric appliance that has been forgotten turned on. It also recognizes the user walking in low-light conditions and turns on the light, as well as detects cases of emergency such as a fall. The robot provides also the user with cognitive training games and stimulates the user to contact with relatives through video-calls. Pilot trials of the RAMCIP robot have been performed in real homes of more than ten different users, in Barcelona, Spain; the video at hand exhibits the robot performing the target use cases.
ER  - 

TY  - CONF
TI  - Nonlinear Analysis of an Indirectly Controlled Sliding Locomotion Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Li
AU  - F. Asano
AU  - I. Tokuda
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - vibrations
KW  - wheels
KW  - indirectly controlling mechanism
KW  - indirectly controlled locomotion robots
KW  - inefficient locomotion
KW  - Arnold tongue
KW  - energy efficiency
KW  - indirectly controlled sliding locomotion
KW  - active wobbling mass
KW  - slippery road surface
KW  - stable energy efficient locomotion
KW  - sliding locomotion robot
KW  - nonlinear analysis
KW  - Force
KW  - Legged locomotion
KW  - Tongue
KW  - Robot kinematics
KW  - Frequency estimation
KW  - Friction
DO  - 10.1109/IROS.2018.8593401
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With the purpose of achieving stable and energy efficient locomotion on the slippery road surface, a sliding locomotion robot without joint torque but indirectly controlled by an active wobbling mass is recently proposed. In this paper, we deepen the analysis of the mechanism of the indirectly controlled sliding locomotion for further optimization and generalization. First, we derive the equations of dynamics and control. Second, we estimate the natural frequency of the robot, the moving speed and energy efficiency are also evaluated with respect to forcing amplitude and frequency of the wobbling mass. Third, the Arnol'd tongue is introduced to analyze the relationship between achieving efficient locomotion and being entrained. In addition, phase oscillation and synchronization phenomenon are analyzed via hysteresis plot to further interpret the unusual shapes of the Arnol'd tongues. Finally, we analyze the entrained, however, inefficient locomotion by reconfirming the rolling constraints from the mechanical energy dissipation point of view. Our results help better understanding of the indirectly controlling mechanism, and the methods can be applied to other indirectly controlled locomotion robots.
ER  - 

TY  - CONF
TI  - Planning Topological Navigation for Complex Indoor Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Martín
AU  - J. Ginés
AU  - D. Vargas
AU  - F. J. Rodríguez-Lera
AU  - V. Matellán
PY  - 2018
KW  - humanoid robots
KW  - mobile robots
KW  - multi-robot systems
KW  - planning (artificial intelligence)
KW  - artificial intelligence planning
KW  - topological navigation planning
KW  - symbolic representation
KW  - European Robotics League
KW  - humanoid robot Pepper
KW  - high level acting
KW  - high level reasoning
KW  - mobile robot
KW  - complex indoor environments
KW  - Navigation
KW  - Planning
KW  - Task analysis
KW  - Measurement
KW  - Robot kinematics
KW  - Indoor environments
DO  - 10.1109/IROS.2018.8594038
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The ability to move around the environment is one of the most important capabilities of a mobile robot. Although navigation is considered an already achieved capacity, there is still much work to be done to integrate navigation with high level reasoning and acting. Navigate in indoor environments also involve complex actions, such as opening doors, use elevators, and many others. We propose a topological navigation system based on Artificial Intelligence (AI) Planning. Starting from a symbolic representation of the environment, navigation tasks are divided into phases, in which different actions are required. This approach has demonstrated to be very effective to plan the operations of a robot at indoor environments. The final result is method compact, efficient and scalable. Our system has been successfully tested at European Robotics League in the humanoid robot Pepper.
ER  - 

TY  - CONF
TI  - Joint Stem Detection and Crop-Weed Classification for Plant-Specific Treatment in Precision Farming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8233
EP  - 8238
AU  - P. Lottes
AU  - J. Behley
AU  - N. Chebrolu
AU  - A. Milioto
AU  - C. Stachniss
PY  - 2018
KW  - agricultural robots
KW  - agriculture
KW  - agrochemicals
KW  - control engineering computing
KW  - convolutional neural nets
KW  - crops
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - spraying
KW  - crop production
KW  - robots
KW  - mechanical treatments
KW  - class-wise stem detection
KW  - conventional weed control
KW  - spraying process
KW  - convolutional network
KW  - farming process
KW  - agrochemicals
KW  - environmental impact
KW  - pixel-wise semantic segmentation
KW  - Agriculture
KW  - Decoding
KW  - Image segmentation
KW  - Feature extraction
KW  - Semantics
KW  - Task analysis
KW  - Robots
DO  - 10.1109/IROS.2018.8593678
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Applying agrochemicals is the default procedure for conventional weed control in crop production, but has negative impacts on the environment. Robots have the potential to treat every plant in the field individually and thus can reduce the required use of such chemicals. To achieve that, robots need the ability to identify crops and weeds in the field and must additionally select effective treatments. While certain types of weed can be treated mechanically, other types need to be treated by (selective) spraying. In this paper, we present an approach that provides the necessary information for effective plant-specific treatment. It outputs the stem location for weeds, which allows for mechanical treatments, and the covered area of the weed for selective spraying. Our approach uses an end-to-end trainable fully convolutional network that simultaneously estimates stem positions as well as the covered area of crops and weeds. It jointly learns the class-wise stem detection and the pixel-wise semantic segmentation. Experimental evaluations on different real-world datasets show that our approach is able to reliably solve this problem. Compared to state-of-the-art approaches, our approach not only substantially improves the stem detection accuracy, i.e., distinguishing crop and weed stems, but also provides an improvement in the semantic segmentation performance.
ER  - 

TY  - CONF
TI  - Seeing the Wood for the Trees: Reliable Localization in Urban and Natural Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8239
EP  - 8246
AU  - G. Tinchev
AU  - S. Nobili
AU  - M. Fallon
PY  - 2018
KW  - feature extraction
KW  - geophysical image processing
KW  - image matching
KW  - image segmentation
KW  - robot vision
KW  - vegetation mapping
KW  - reliable localization
KW  - urban environments
KW  - natural environments
KW  - current state-of-the-art global approaches
KW  - structure-poor vegetated areas
KW  - orchards
KW  - environments clutter
KW  - repeatable extraction
KW  - distinctive landmarks
KW  - natural forests
KW  - tree trunks
KW  - foliage intertwines
KW  - planar structure
KW  - place recognition
KW  - feature extraction module segments
KW  - reliable object-sized segments
KW  - heavy clutter
KW  - foliage-heavy forest
KW  - urban scenarios
KW  - random forest
KW  - shape descriptor
KW  - Feature extraction
KW  - Vegetation
KW  - Three-dimensional displays
KW  - Forestry
KW  - Reliability
KW  - Clutter
KW  - Hidden Markov models
DO  - 10.1109/IROS.2018.8594042
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we introduce Natural Segmentation and Matching (NSM), an algorithm for reliable localization, using laser, in both urban and natural environments. Current state-of-the-art global approaches do not generalize well to structure-poor vegetated areas such as forests or orchards. In these environments clutter and perceptual aliasing prevents repeatable extraction of distinctive landmarks between different test runs. In natural forests, tree trunks are not distinctive, foliage intertwines and there is a complete lack of planar structure. In this paper we propose a method for place recognition which uses a more involved feature extraction process which is better suited to this type of environment. First, a feature extraction module segments stable and reliable object-sized segments from a point cloud despite the presence of heavy clutter or tree foliage. Second, repeatable oriented key poses are extracted and matched with a reliable shape descriptor using a Random Forest to estimate the current sensor's position within the target map. We present qualitative and quantitative evaluation on three datasets from different environments - the KITTI benchmark, a parkland scene and a foliage-heavy forest. The experiments show how our approach can achieve place recognition in woodlands while also outperforming current state-of-the-art approaches in urban scenarios without specific tuning.
ER  - 

TY  - CONF
TI  - Extracting Phenotypic Characteristics of Corn Crops Through the Use of Reconstructed 3D Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8247
EP  - 8254
AU  - D. Zermas
AU  - V. Morellas
AU  - D. Mulla
AU  - N. Papanikolopoulos
PY  - 2018
KW  - agriculture
KW  - crops
KW  - financial management
KW  - image reconstruction
KW  - image segmentation
KW  - solid modelling
KW  - social elements
KW  - cultivation process
KW  - financial losses
KW  - crop yield
KW  - hybrid plants
KW  - motion technology
KW  - segmentation process
KW  - corn crops
KW  - phenotypic characteristics
KW  - 3D point cloud
KW  - reconstructed 3D models
KW  - financial elements
KW  - Three-dimensional displays
KW  - Agriculture
KW  - Solid modeling
KW  - Estimation
KW  - Computational modeling
KW  - Image segmentation
KW  - Vegetation
DO  - 10.1109/IROS.2018.8594356
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Financial and social elements of modern societies are closely connected to the cultivation of corn. Due to its massive production, deficiencies during the cultivation process directly translate to major financial losses. Since proper surveillance in a large scale is still very challenging, the companies that specialize in optimizing crop yield are trying to address the problem at its root by developing hybrid plants able to resist the harsh conditions of the field. The selection of the best hybrid is not easy and every year hundreds of test plants with different phenotypic characteristics are planted while their performance is quantified by inconsistent and rough measurements gathered by humans. We propose a pipeline that takes advantage of the structure from motion technology to create a detailed 3D point cloud of a few plants and segment it into the basic elements of the scene; the ground, the plants, the plant stems, and the plant leaves. The focus is on the segmentation process through which several phenotypic characteristics of individual plants can be extracted. As an example, we show the results for the plant counting and plant height estimation processes where we achieve an accuracy of 88.1% and 89.2%.
ER  - 

TY  - CONF
TI  - A Novel Autonomous Robot for Greenhouse Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Grimstad
AU  - R. Zakaria
AU  - T. Dung Le
AU  - P. J. From
PY  - 2018
KW  - agriculture
KW  - cameras
KW  - greenhouses
KW  - mobile robots
KW  - robot vision
KW  - autonomous robot
KW  - low-cost 3D camera
KW  - greenhouse headland
KW  - greenhouse heating system
KW  - agricultural robot
KW  - greenhouse applications
KW  - Green products
KW  - Rails
KW  - Mobile robots
KW  - Tools
KW  - Wheels
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594233
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel agricultural robot for greenhouse applications. In many greenhouses, including the greenhouse used in this work, sets of pipes run along the floor between plant rows. These pipes are components of the greenhouse heating system, and doubles as rails for trolleys used by workers. A flat surface separates the start of each rail set at the greenhouse headland. If a robot is to autonomously drive along plant rows, and also be able to move from one set of rails to the next, it must be able to locomote both on rails and on flat surfaces. This puts requirements on mechanical design and navigation, as the robot must cope with two very different operational environments. The robot presented in this paper has been designed to overcome these challenges and allows for autonomous operation both in open environments and on rails by using only low-cost sensors. The robot is assembled using a modular system created by the authors and tested in a greenhouse during ordinary operation. Using the robot, we map the environment and automatically determine the starting point of each rail in the map. We also show how we are able to identify rails and estimate the robots pose relative to theses using only a low-cost 3D camera. When a rail is located, the robot makes the transition from floor to rail and travels along the row of plants before it moves to the next rail set which it has identified in the map. The robot is used for UV treatment of cucumber plants.
ER  - 

TY  - CONF
TI  - The use of dynamic sensing strategies to improve detection for a pepper harvesting robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8286
EP  - 8293
AU  - P. Kurtser
AU  - Y. Edan
PY  - 2018
KW  - agricultural products
KW  - agriculture
KW  - feature extraction
KW  - greenhouses
KW  - industrial robots
KW  - least squares approximations
KW  - object detection
KW  - profitability
KW  - robot vision
KW  - predicted profitability
KW  - viewpoint location
KW  - pepper harvesting robot
KW  - dynamic sensing strategies
KW  - harvesting utility cost function
KW  - occlusion level detection
KW  - fruit
KW  - image analysis
KW  - Robot sensing systems
KW  - Heuristic algorithms
KW  - Prediction algorithms
KW  - Cameras
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593746
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the use of dynamic sensing strategies to improve detection results for a pepper harvesting robot. The algorithm decides if an additional viewpoint is needed and selects the best-fit viewpoint location from a predefined set of locations based on the predicted profitability of such an action. The suggestion of a possible additional viewpoint is based on image analysis for fruit and occlusion level detection, prediction of the expected number of additional targets sensed from that viewpoint, and final decision if choosing the additional viewpoint is beneficial. The developed heuristic was applied on 96 greenhouse images of 30 sweet peppers and resulted in up to 19% improved detection. The harvesting utility cost function decreased by up to 10% compared to the conventional single viewpoint strategy.
ER  - 

TY  - CONF
TI  - Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 603
EP  - 610
AU  - K. Lima
AU  - E. R. B. Marques
AU  - J. Pinto
AU  - J. B. Sousa
PY  - 2018
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - control engineering computing
KW  - public domain software
KW  - software packages
KW  - specification languages
KW  - unmanned aerial vehicles
KW  - task orchestration language
KW  - autonomous vehicle networks
KW  - extensible programming language
KW  - Dolphin program
KW  - orchestrated execution
KW  - multiple vehicles
KW  - one-vehicle tasks
KW  - event-based task flow
KW  - Dolphin language
KW  - autonomous vehicles
KW  - unmanned underwater vehicles
KW  - Groovy DSL
KW  - software packages
KW  - robotic toolkits
KW  - open-source toolchain
KW  - Task analysis
KW  - Dolphins
KW  - DSL
KW  - Autonomous vehicles
KW  - Engines
KW  - Runtime
KW  - Java
DO  - 10.1109/IROS.2018.8594059
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).
ER  - 

TY  - CONF
TI  - π-SoC: Heterogeneous SoC Architecture for Visual Inertial SLAM Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8302
EP  - 8307
AU  - J. Tang
AU  - B. Yu
AU  - S. Liu
AU  - Z. Zhang
AU  - W. Fang
AU  - Y. Zhang
PY  - 2018
KW  - energy consumption
KW  - mobile computing
KW  - mobile robots
KW  - optimisation
KW  - SLAM (robots)
KW  - system-on-chip
KW  - visual inertial SLAM applications
KW  - autonomous vehicles
KW  - robotics
KW  - core technologies
KW  - battery-powered mobile devices
KW  - energy budget
KW  - energy consumption
KW  - energy efficiency
KW  - visual inertial SLAM workloads
KW  - 60 FPS performance
KW  - heterogeneous SoC architecture
KW  - simultaneous localization and mapping
KW  - hardware accelerator
KW  - IO interface
KW  - memory hierarchy
KW  - Simultaneous localization and mapping
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Instruction sets
KW  - Power demand
KW  - Graphics processing units
KW  - Computer architecture
DO  - 10.1109/IROS.2018.8594181
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles and robotics. One of the core technologies enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. Hence, performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. Previous attempts to optimize SLAM performance and energy efficiency usually involve optimizing one function and fail to approach the problem systematically. In this paper, we first study the characteristics of visual inertial SLAM workloads on existing heterogeneous SoCs. Then based on the initial findings, we propose π-SoC, a heterogeneous SoC design that systematically optimize the IO interface, the memory hierarchy, as well as the the hardware accelerator. We implemented this system on a Xilinx Zynq UltraScale MPSoC and was able to deliver over 60 FPS performance with average power less than 5 W.
ER  - 

TY  - CONF
TI  - vTSL - A Formally Verifiable DSL for Specifying Robot Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8308
EP  - 8314
AU  - C. Heinzemann
AU  - R. Lange
PY  - 2018
KW  - constraint handling
KW  - control engineering computing
KW  - formal specification
KW  - formal verification
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot programming
KW  - specification languages
KW  - vTSL
KW  - formally verifiable DSL
KW  - robot tasks
KW  - preprogramming
KW  - automated planning
KW  - symbolic learning
KW  - robotic application
KW  - user-defined tasks
KW  - integrity constraints
KW  - robotic platform
KW  - verifiable task specification language
KW  - task-specific constraints
KW  - robotic systems
KW  - Task analysis
KW  - DSL
KW  - Semantics
KW  - Planning
KW  - Loading
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593559
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Preprogramming of tasks still plays an important role in complex robotic systems despite the advances in automated planning and symbolic learning. Often, it is desired that end-users implement further tasks to adapt the robotic application to their needs. These user-defined tasks have to meet safety and integrity constraints for protecting the robotic platform and its users. We introduce a verifiable task specification language (vTSL) that enables to automatically prove that a task specification satisfies a set of predefined or task-specific constraints. We illustrate our approach using an example of a self-driving vehicle for intra-logistics and report experiences with two commercial applications.
ER  - 

TY  - CONF
TI  - GPU-Accelerated Next-Best-View Coverage of Articulated Scenes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 603
EP  - 610
AU  - S. Obwald
AU  - M. Bennewitz
PY  - 2018
KW  - embedded systems
KW  - graphics processing units
KW  - mobile robots
KW  - path planning
KW  - rendering (computer graphics)
KW  - robot vision
KW  - costmap computation
KW  - path planning
KW  - simulation
KW  - viewpoint candidates
KW  - multiple device classes
KW  - multiGPU servers
KW  - utility map
KW  - robots
KW  - complex articulated scenes
KW  - GPU-accelerated next-best-view coverage
KW  - next-best-view algorithms
KW  - mapping tasks
KW  - articulated environments
KW  - obstructed areas
KW  - degrees of freedom
KW  - embedded devices
KW  - next-best-view approach
KW  - embedded systems
KW  - graphics processing units
KW  - OpenGL
KW  - Graphics processing units
KW  - Task analysis
KW  - Cameras
KW  - Robot sensing systems
KW  - Planning
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594054
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Next-best-view algorithms are commonly used for covering known scenes, for example in search, maintenance, and mapping tasks. In this paper, we consider the problem of planning a strategy for covering articulated environments where the robot also has to manipulate objects to inspect obstructed areas. This problem is particularly challenging due to the many degrees of freedom resulting from the articulation. We propose to exploit graphics processing units present in many embedded devices to parallelize the computations of a greedy next-best-view approach. We implemented algorithms for costmap computation, path planning, as well as simulation and evaluation of viewpoint candidates in OpenGL for Embedded Systems and benchmarked the implementations on multiple device classes ranging from smartphones to multi-GPU servers. We introduce a heuristic for estimating a utility map from images rendered with strategically placed spherical cameras and show in simulation experiments that robots can successfully explore complex articulated scenes with our system.
ER  - 

TY  - CONF
TI  - A 3D Convolutional Neural Network Towards Real-Time Amodal 3D Object Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8331
EP  - 8338
AU  - H. Sun
AU  - Z. Meng
AU  - X. Du
AU  - M. H. Ang
PY  - 2018
KW  - convolutional neural nets
KW  - image colour analysis
KW  - object detection
KW  - object recognition
KW  - regression analysis
KW  - 3D Convolutional Neural Network
KW  - 3D detectors
KW  - object categories
KW  - object locations
KW  - real-time amodal 3D object detection
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Object detection
KW  - Proposals
KW  - Solid modeling
KW  - Detectors
KW  - Shape
DO  - 10.1109/IROS.2018.8593837
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We focus on the task of amodal 3D object detection, which is to predict object locations, dimensions, poses and categories in the real world. We introduce a 3D Convolutional Neural Network that takes a volumetric representation of an indoor scene as input and predicts 3D object bounding boxes, object categories, and orientations. Unlike prior state-of-the-arts, our approach does not depend on region proposal techniques to hypothesize object locations. We treat detection and recognition as one regression problem in a single network. Our elegant model is extremely fast and all predictions are reasoned from the global context of a point cloud in a continuous pipeline. We evaluate our approach on two standard datasets: the NYUv2 RGBD dataset and the SUN RGBD dataset. Experiments show that our approach is faster than start-of-the-art 3D detectors by several orders of magnitude towards real-time amodal 3D object detection.
ER  - 

TY  - CONF
TI  - Sinc-Based Dynamic Movement Primitives for Encoding Point-to-point Kinematic Behaviors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8339
EP  - 8345
AU  - D. Papageorgiou
AU  - A. Sidiropoulos
AU  - Z. Doulgeri
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - robot kinematics
KW  - robot programming
KW  - simple learning technique
KW  - sinc functions
KW  - sinc-based dynamic movement primitives
KW  - point-to-point kinematic behaviors
KW  - Complexity theory
KW  - Kinematics
KW  - Biological system modeling
KW  - Computational modeling
KW  - Frequency modulation
KW  - Encoding
DO  - 10.1109/IROS.2018.8594479
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work proposes the utilization of sinc functions as kernels of Dynamic Movement Primitives (DMP) models for encoding point-to-point kinematic behaviors. The proposed method presents a number of advantages with respect to the state of the art, as it (i) involves a simple learning technique, (ii) provides a method to determine the minimum required number of basis functions, based on the frequency content of the demonstrated motion and (iii) provides the ability to pre-define the reproduction accuracy of the learned behavior. The ability of the proposed model to accurately reproduce the behavior is demonstrated through simulations and experiments. Comparisons with the Gaussian-based DMP model show the proposed method's superiority in terms of computational complexity of learning and accuracy for a specific number of kernels.
ER  - 

TY  - CONF
TI  - An Optimization-Based Approach to Dual-Arm Motion Planning with Closed Kinematics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8346
EP  - 8351
AU  - A. Völz
AU  - K. Graichen
PY  - 2018
KW  - collision avoidance
KW  - constraint handling
KW  - humanoid robots
KW  - manipulator kinematics
KW  - mobile robots
KW  - optimisation
KW  - probability
KW  - dual-arm motion planning
KW  - collision-free motions
KW  - dual-arm robot
KW  - kinematic constraints
KW  - closed kinematic chain
KW  - constrained problems
KW  - sampling-based planners
KW  - random sample
KW  - closure constraint
KW  - equality constraints
KW  - gripped object
KW  - optimization-based planning approach
KW  - probability
KW  - augmented Lagrangian method
KW  - constraints handling
KW  - RRT
KW  - CHOMP
KW  - TrajOpt
KW  - trajectory optimization approach
KW  - twelve degrees of freedom
KW  - Kinematics
KW  - Planning
KW  - Collision avoidance
KW  - Manipulators
KW  - Optimization
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593927
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the optimization-based planning of collision-free motions for a dual-arm robot with kinematic constraints. Such problems arise, for example, when the robot has to move an object with both arms, whereby the two arms and the gripped object form a closed kinematic chain. Such constrained problems are hard to solve with sampling-based planners, because the probability that a random sample satisfies the closure constraint is practically zero. In contrast, the solution of optimization problems with equality constraints is a well-understood field of research. This paper formulates the motion planning task as optimization problem and proposes a numerical solution using the augmented Lagrangian method for handling constraints. The planner is compared to RRTs, CHOMP and TrajOpt on a set of randomly generated problems for a dual-arm robot with twelve degrees of freedom highlighting the advantages of optimization-based planning.
ER  - 

TY  - CONF
TI  - Smooth Point-to-Point Trajectory Planning in $SE$ (3)with Self-Collision and Joint Constraints Avoidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - R. Grassmann
AU  - L. Johannsmeier
AU  - S. Haddadin
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - smooth point-to-point trajectory planning
KW  - joint constraints avoidance
KW  - serial robotic structures
KW  - time-optimal SE(3) trajectory
KW  - robot end-effector
KW  - 4th order dynamics flexible joint robots
KW  - self-collision avoidance
KW  - point-to-point trajectory planner
KW  - Trajectory
KW  - End effectors
KW  - Interpolation
KW  - Planning
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594339
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we introduce a novel point-to-point trajectory planner for serial robotic structures that combines the ability to avoid self-collisions and to respect motion constraints, while complying with the requirement of being C4 continuous. The latter property makes our approach also suited for 4th order dynamics flexible joint robots, which gained significant practical relevance recently. In particular, we address the problem of generating a smooth, kinematically nearly time-optimal SE(3) trajectory while simultaneously avoiding potential collisions of the robot end-effector with its base as well as respecting the Cartesian unreachable states induced by the joint limits of the proximal kinematic structure.
ER  - 

TY  - CONF
TI  - Collision-Free Path Planning of Dual-Manipulator System Based on Energy Conversion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8360
EP  - 8366
AU  - C. Su
AU  - R. Wei
AU  - M. Zhang
AU  - H. Rose
AU  - J. Xu
PY  - 2018
KW  - collision avoidance
KW  - elasticity
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - springs (mechanical)
KW  - dual-manipulator moves
KW  - original paths
KW  - ends-fixed elastic ropes
KW  - manipulators
KW  - initial paths
KW  - elastic potential energy
KW  - manipulator bodies
KW  - virtual spring
KW  - energy perspective
KW  - dual-manipulator path-planning problem
KW  - energy conversion
KW  - dual-manipulator system
KW  - collision-free path planning
KW  - Manipulators
KW  - Path planning
KW  - Springs
KW  - Potential energy
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593696
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper is a preliminary exploration of how to solve the dual-manipulator path-planning problem from an energy perspective. A virtual spring is set up between the two manipulator bodies and becomes compressed as they move into the area of danger, thus producing elastic potential energy. The initial paths of the manipulators are modelled as two ends-fixed elastic ropes. The elastic potential energy stored in the virtual spring is distributed between the two elastic ropes in a certain proportion so as to deform them. In this way, the original paths of the two manipulators will deviate toward the direction of their respective bases thereby avoiding any collision crisis that may potentially occur. When the dual-manipulator moves away from the danger area, the elastic potential energy caused by the deviation of the elastic ropes will be converted back into energy stored by the virtual spring, such that the elastic ropes revert to their original state and drive the manipulators back to their initial paths. Simple but representative simulations are established and results of the simulations show the reliability of our proposed method.
ER  - 

TY  - CONF
TI  - CROC: Convex Resolution of Centroidal Dynamics Trajectories to Provide a Feasibility Criterion for the Multi Contact Planning Problem
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Fernbach
AU  - S. Tonneau
AU  - M. Taïx
PY  - 2018
KW  - approximation theory
KW  - computational geometry
KW  - legged locomotion
KW  - linear programming
KW  - motion control
KW  - path planning
KW  - sampling methods
KW  - trajectory control
KW  - CROC
KW  - feasibility criterion
KW  - multicontact planning problem
KW  - transition feasibility problem
KW  - legged robot
KW  - conservative reformulation
KW  - convex reformulation
KW  - Bezier curve
KW  - transition problem
KW  - sampling-based contact planner
KW  - motion generation methods
KW  - center of mass trajectory
KW  - convex resolution of centroidal dynamics trajectories
KW  - free control point
KW  - contact sequences
KW  - motion synthesis problems
KW  - linear program
KW  - Trajectory
KW  - Dynamics
KW  - Planning
KW  - Acceleration
KW  - Legged locomotion
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593888
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We tackle the transition feasibility problem, that is the issue of determining whether there exists a feasible motion connecting two configurations of a legged robot. To achieve this we introduce CROC, a novel method for computing centroidal dynamics trajectories in multi-contact planning contexts. Our approach is based on a conservative and convex reformulation of the problem, where we represent the center of mass trajectory as a Bezier curve comprising a single free control point as a variable. Under this formulation, the transition problem is solved efficiently with a Linear Program (LP)of low dimension. We use this LP as a feasibility criterion, incorporated in a sampling-based contact planner, to discard efficiently unfeasible contact plans. We are thus able to produce robust contact sequences, likely to define feasible motion synthesis problems. We illustrate this application on various multi-contact scenarios featuring HRP2 and HyQ. We also show that we can use CROC to compute valuable initial guesses, used to warm-start non-linear solvers for motion generation methods. This method could also be used for the 0 and 1-Step capturability problem. The source code of CROC is available under an open source BSD-2 License.
ER  - 

TY  - CONF
TI  - Variations on a Theme: “It's a Poor Sort of Memory that Only Works Backwards”
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8390
EP  - 8396
AU  - F. Bálint-Benczédi
AU  - M. Beetz
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - rendering (computer graphics)
KW  - mobile robots
KW  - virtual scene rendering approach
KW  - episodic memories
KW  - robotic agent
KW  - knowledge based approach
KW  - model learning
KW  - Task analysis
KW  - Games
KW  - Engines
KW  - Rendering (computer graphics)
KW  - Mobile robots
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594001
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Adapting the perceptual capabilities of mobile robots to new objects or new environments can be a time consuming task. In this paper we focus on specializing perceptual capabilities of mobile robots to new objects through a knowledge based, virtual scene rendering approach. Episodic memories of a robotic agent, gathered during the execution of a task are considered to be the main "theme". Variations of this theme are then generated based on background knowledge about the objects and data gathered with the purpose of learning new models for detection and recognition. We demonstrate the applicability of our approach by adapting the perceptual capabilities of a mobile robot performing pick and place tasks, to recognize new sets of objects.
ER  - 

TY  - CONF
TI  - Attitude Estimation from Polarimetric Cameras
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8397
EP  - 8403
AU  - M. Rastgoo
AU  - C. Demonceaux
AU  - R. Seulin
AU  - O. Morel
PY  - 2018
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - cameras
KW  - image sensors
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - robotic applications
KW  - attitude estimation
KW  - polarimetric camera
KW  - path planning applications
KW  - visual systems
KW  - perspective cameras
KW  - depth cameras
KW  - catadioptric cameras
KW  - systems capture information
KW  - sky regions
KW  - visual cue
KW  - vision applications
KW  - sky information
KW  - polarimetric sensors
KW  - visual sensors
KW  - navigation applications
KW  - unmanned aerial vehicle
KW  - Cameras
KW  - Scattering
KW  - Robot vision systems
KW  - Sun
KW  - Estimation
KW  - Atmospheric modeling
DO  - 10.1109/IROS.2018.8593575
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the robotic field, navigation and path planning applications benefit from a wide range of visual systems (e.g, perspective cameras, depth cameras, catadioptric cameras, etc.). In outdoor conditions, these systems capture information in which sky regions cover a major segment of the images acquired. However, sky regions are discarded and are not considered as visual cue in vision applications. In this paper, we propose to estimate attitude of Unmanned Aerial Vehicle (UAV) from sky information using a polarimetric camera. Theoretically, we provide a framework estimating the attitude from the skylight polarized patterns. We showcase this formulation on both simulated and real-word data sets which proved the benefit of using polarimetric sensors along with other visual sensors in robotic applications.
ER  - 

TY  - CONF
TI  - The Earth Ain't Flat: Monocular Reconstruction of Vehicles on Steep and Graded Roads from a Moving Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8404
EP  - 8410
AU  - J. A. Ansari
AU  - S. Sharma
AU  - A. Majumdar
AU  - J. K. Murthy
AU  - K. M. Krishna
PY  - 2018
KW  - cameras
KW  - image reconstruction
KW  - pose estimation
KW  - road vehicles
KW  - SLAM (robots)
KW  - stereo image processing
KW  - traffic engineering computing
KW  - local bundle-adjustment like procedure
KW  - 3D pose
KW  - semantic cues
KW  - moving ego vehicle
KW  - shape estimation
KW  - plain roads
KW  - monocular localization demonstrations
KW  - autonomous driving systems
KW  - traffic participants
KW  - moving camera
KW  - monocular reconstruction
KW  - arbitrarily-shaped roads
KW  - monocular object localization
KW  - road plane configurations
KW  - local ground plane
KW  - local planar patches
KW  - monocular camera
KW  - Shape
KW  - Roads
KW  - Three-dimensional displays
KW  - Cameras
KW  - Image reconstruction
KW  - Automobiles
KW  - Surface reconstruction
DO  - 10.1109/IROS.2018.8593698
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate localization of other traffic participants is a vital task in autonomous driving systems. State-of-the-art systems employ a combination of sensing modalities such as RGB cameras and LiDARs for localizing traffic participants, but monocular localization demonstrations have been confined to plain roads. We demonstrate - to the best of our knowledge - the first results for monocular object localization and shape estimation on surfaces that are non-coplanar with the moving ego vehicle mounted with a monocular camera. We approximate road surfaces by local planar patches and use semantic cues from vehicles in the scene to initialize a local bundle-adjustment like procedure that simultaneously estimates the 3D pose and shape of the vehicles, and the orientation of the local ground plane on which the vehicle stands. We also demonstrate that our approach transfers from synthetic to real data, without any hyperparameter-/fine-tuning. We evaluate the proposed approach on the KITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations. The proposed approach significantly improves the state-of-the-art for monocular object localization on arbitrarily-shaped roads.
ER  - 

TY  - CONF
TI  - Towards a Context Enhanced Framework for Multi Object Tracking in Human Robot Collaboration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 168
EP  - 173
AU  - S. C. Akkaladevi
AU  - M. Plasch
AU  - C. Eitzinger
AU  - A. Pichler
AU  - B. Rinner
PY  - 2018
KW  - human-robot interaction
KW  - manipulators
KW  - object detection
KW  - object tracking
KW  - robot vision
KW  - uninterrupted completion
KW  - functional accuracy
KW  - multiple objects
KW  - HRC setting
KW  - robust object tracker
KW  - functional role
KW  - object tacker
KW  - robotic manipulation
KW  - HRC assembly process
KW  - multiobject tracking
KW  - goal-oriented human robot collaborative scenario
KW  - context enhanced framework
KW  - Robot kinematics
KW  - Cognition
KW  - Task analysis
KW  - Object tracking
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593842
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In a goal-oriented Human Robot Collaborative (HRC) scenario, where the goal is to complete an assembly process, a robust object tracker might not necessarily fulfill its functional role due to the dynamic nature of HRC. Moreover, for an efficient HRC, the functional role of the object tacker should not only be limited to localizing and tracking objects for robotic manipulation. It should also help to determine the current state of the assembly process and verify if the chosen action has been successfully performed and thus to enable an uninterrupted completion of an HRC assembly process. We present a Context Enhanced Framework for Multi Object Tracking, that i) allows uninterrupted completion of an assembly process, ii) improves the overall functional accuracy of the object tracker from 49 percent to 96 percent, and iii) enables the object tracker to handle multiple instance of multiple objects in a HRC setting.
ER  - 

TY  - CONF
TI  - Lane Marking Quality Assessment for Autonomous Driving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - B. Li
AU  - D. Song
AU  - H. Li
AU  - A. Pike
AU  - P. Carlson
PY  - 2018
KW  - cameras
KW  - Global Positioning System
KW  - image processing
KW  - optical radar
KW  - road vehicles
KW  - traffic engineering computing
KW  - road curvature
KW  - background road surfaces
KW  - dual-modal algorithm
KW  - lane marking quality assessment
KW  - autonomous driving
KW  - future transportation systems
KW  - inspection vehicle
KW  - frontal-view camera
KW  - global positioning system receiver
KW  - light detection and ranging system
KW  - LIDAR
KW  - Roads
KW  - Measurement
KW  - Laser radar
KW  - Cameras
KW  - Shape
KW  - Global Positioning System
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593855
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Measuring the quality of roads and ensuring they are ready for autonomous driving is important for future transportation systems. Here we focus on developing metrics and algorithms to assess lane marking (LM)qualities from an egocentric view of an inspection vehicle equipped with a global positioning system (GPS)receiver, a frontal-view camera, and a light detection and ranging (LIDAR)system. We propose three quality metrics for LMs: correctness, shape, and visibility. The correctness metric measures the divergence between the expected LMs based on prior map inputs and the actual sensor inputs. The shape metric evaluates smoothness in road curvature and width range. The visibility metric evaluates the contrast between LMs and background road surfaces. We propose a dual-modal algorithm to compute these metrics. We have implemented the algorithms and tested them under KITTI dataset. The results show that our metrics can successfully detect LM anomalies in all testing scenarios.
ER  - 

TY  - CONF
TI  - Real-time 3D Reconstruction Using a Combination of Point-Based and Volumetric Fusion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8449
EP  - 8455
AU  - Z. Xia
AU  - J. Kim
AU  - Y. S. Park
PY  - 2018
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - iterative methods
KW  - object detection
KW  - stereo image processing
KW  - 3D reconstruction technologies
KW  - point-based and volumetric representation
KW  - Kinect sensors
KW  - Xtion sensors
KW  - augmented reality
KW  - robotic teleoperation
KW  - medical diagnosis
KW  - KinectFusion
KW  - KinFu
KW  - GPU-based region growing method
KW  - weighted iterative closest point algorithm
KW  - moving object
KW  - fast motion camera
KW  - truthful reconstruction
KW  - low-cost commodity sensors
KW  - volumetric fusion
KW  - camera tracking
KW  - Cameras
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Sensors
KW  - Real-time systems
KW  - Iterative closest point algorithm
KW  - Systematics
DO  - 10.1109/IROS.2018.8594061
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Real-time 3D reconstruction using low-cost commodity sensors like Kinect or Xtion has been successfully applied in a wide range of fields like augmented reality, robotic teleoperation, and medical diagnosis. Due to the assumption of static scene, popular 3D reconstruction technologies such as KinectFusion and KinFu, find truthful reconstruction with fast motion camera or segmenting a moving object to be a challenge. In this paper, we propose a weighted iterative closest point (ICP) algorithm that uses both depth and RGB information to enhance the stability of camera tracking. Additionally, a GPU-based region growing method that combines depth, normal and intensity level as similarity criteria, is also applied to segment foreground moving objects accurately. For real-time processing and GPU memory efficiency, we also design a combination of point-based and volumetric representation to reconstruct moving objects and static scene, respectively. Both qualitative and quantitative results show that our proposed method improves real-time 3D reconstruction on the performance of camera tracking and segmentation of moving objects with reduced computational complexity.
ER  - 

TY  - CONF
TI  - P-CAP: Pre-Computed Alternative Paths to Enable Aggressive Aerial Maneuvers in Cluttered Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8456
EP  - 8463
AU  - J. Zhang
AU  - R. G. Chadha
AU  - V. Velivela
AU  - S. Singh
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - data structures
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - probability
KW  - search problems
KW  - p-CAP
KW  - pre-computed alternative paths
KW  - cluttered environments
KW  - fast autonomous flight
KW  - autonomous navigation
KW  - complex environment
KW  - continuous heuristic search
KW  - k-connected grid
KW  - probabilistic scheme
KW  - onboard sensors
KW  - prior map information
KW  - data structure
KW  - flight experiments
KW  - unstructured environments
KW  - aggressive aerial maneuvers
KW  - graph
KW  - forests-like environments
KW  - obstacles avoidance
KW  - Navigation
KW  - Sensors
KW  - Switches
KW  - Collision avoidance
KW  - Forestry
KW  - Gold
KW  - Planning
DO  - 10.1109/IROS.2018.8593826
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous heuristic search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle progresses, modification of the graph with data from onboard sensors is expensive as is search on the graph, especially if the paths must be kino-dynamically feasible. We suggest that computation needed to find safe paths during fast flight can be greatly reduced if we precompute and carefully arrange a dense set of alternative paths before the flight. Any prior map information can be used to prune the alternative paths to come up with a data structure that enables very fast online computation to deal with obstacles that are not on the map but only detected by onboard sensors. To test this idea, we have conducted a large number of flight experiments in structured (large industrial facilities) and unstructured (forests-like) environments. We show that even in the most unstructured environments, this method enables flight at a speed up to 10m/s while avoiding obstacles detected from onboard sensors.
ER  - 

TY  - CONF
TI  - Motion Planning for a Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8464
EP  - 8470
AU  - J. Levin
AU  - A. Paranjape
AU  - M. Nahon
PY  - 2018
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - feedback
KW  - mobile robots
KW  - robot dynamics
KW  - trees (mathematics)
KW  - cruise-to-hover transition
KW  - hover-to-cruise transition
KW  - motion planner
KW  - motion planning
KW  - aerobatic fixed-wing
KW  - fixed-wing unmanned aerial vehicle
KW  - static obstacles
KW  - goal region
KW  - rapidly-exploring random trees algorithm
KW  - Aircraft
KW  - Trajectory
KW  - Libraries
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Heuristic algorithms
KW  - Planning
DO  - 10.1109/IROS.2018.8593670
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A motion planner is developed for guiding a small aerobatic fixed-wing unmanned aerial vehicle to a desired goal region in a highly constrained, three-dimensional, known environment with static obstacles. The planner is based on the Rapidly-Exploring Random Trees (RRT) algorithm, and pieces together feasible trajectories from a library of motion primitives. Among other more conventional motion primitives, the library includes three extreme maneuvers: a cruise-to-hover transition, a hover-to-cruise transition, and an aggressive turn-around. The algorithm is efficient; it can be run in real-time to rapidly generate a plan starting from the aircraft's configuration at run-time. The motion planner is closely coupled to a feedback controller. Simulations using an aircraft dynamics model demonstrate the effectiveness of the system to guide and control the aircraft to a desired goal region. Preliminary flight test results are also presented.
ER  - 

TY  - CONF
TI  - First Experimental Results on Motion Planning for Transportation in Aerial Long-Reach Manipulators with Two Arms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8471
EP  - 8477
AU  - A. Caballero
AU  - A. Suarez
AU  - F. Real
AU  - V. M. Vega
AU  - M. Bejar
AU  - A. Rodriguez-Castaño
AU  - A. Ollero
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - manipulators
KW  - mobile robots
KW  - search problems
KW  - transportation
KW  - aerial robotic system
KW  - RRT* algorithms
KW  - motion planning problem
KW  - dual arm
KW  - aerial platform
KW  - passive revolute joint
KW  - long-reach manipulation
KW  - long-bar extension
KW  - aerial long-reach manipulators
KW  - cluttered environment
KW  - transportation
KW  - Manipulators
KW  - Planning
KW  - Trajectory
KW  - Transportation
KW  - Bars
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594123
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the motion planning of a novel aerial robotic system with a long-bar extension and two arms for long-reach manipulation in cluttered environments. The novel aerial long-reach manipulator includes a passive revolute joint between the aerial platform and the dual arm. This feature minimises the torque induced to the aerial system in case of unexpected collisions of the manipulator. The motion planning problem is addressed considering jointly the complete set of configuration variables for the aerial platform and the dual arm. Furthermore, the planner has been built over the fundamentals of RRT* algorithms in order to optimise the performance of the trajectories in terms of energy and time. The proposed planning method has been experimentally validated in a realistic industrial scenario, the transportation of a long bar through a cluttered environment consisting of several pipe structures.
ER  - 

TY  - CONF
TI  - Sparse 3D Topological Graphs for Micro-Aerial Vehicle Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - H. Oleynikova
AU  - Z. Taylor
AU  - R. Siegwart
AU  - J. Nieto
PY  - 2018
KW  - autonomous aerial vehicles
KW  - computational geometry
KW  - graph theory
KW  - image colour analysis
KW  - mobile robots
KW  - path planning
KW  - topology
KW  - Euclidean signed distance field
KW  - 3D generalized Voronoi diagram
KW  - RGB-D sensing
KW  - global planning
KW  - skeleton diagram
KW  - topological information
KW  - noisy sensor data
KW  - sparse map representations
KW  - compact map representations
KW  - MAV
KW  - microaerial vehicle planning
KW  - sparse 3D topological graphs
KW  - Planning
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Skeleton
KW  - Robot sensing systems
KW  - Topology
DO  - 10.1109/IROS.2018.8594152
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Micro-Aerial Vehicles (MAVs) have the advantage of moving freely in 3D space. However, creating compact and sparse map representations that can be efficiently used for planning for such robots is still an open problem. In this paper, we take maps built from noisy sensor data and construct a sparse graph containing topological information that can be used for 3D planning. We use a Euclidean Signed Distance Field, extract a 3D Generalized Voronoi Diagram (GVD), and obtain a thin skeleton diagram representing the topological structure of the environment. We then convert this skeleton diagram into a sparse graph, which we show is resistant to noise and changes in resolution. We demonstrate global planning over this graph, and the orders of magnitude speed-up it offers over other common planning methods. We validate our planning algorithm in real maps built onboard an MAV, using RGB-D sensing.
ER  - 

TY  - CONF
TI  - Motion Planning for a UAV with a Straight or Kinked Tether
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8486
EP  - 8492
AU  - X. Xiao
AU  - J. Dufek
AU  - M. Suhail
AU  - R. Murphy
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - robot vision
KW  - confined environment
KW  - cluttered environment
KW  - tethered aerial vehicles
KW  - tethered agent
KW  - nonfree space
KW  - motion planning frameworks
KW  - motion planning strategies
KW  - motion planning algorithms
KW  - UAV
KW  - robotic locomotion
KW  - reachable configuration space
KW  - marsupial heterogeneous robotic teams
KW  - Fotokite Pro
KW  - Planning
KW  - Visualization
KW  - Casting
KW  - Cameras
KW  - Robot sensing systems
KW  - Unmanned aerial vehicles
DO  - 10.1109/IROS.2018.8594461
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.
ER  - 

TY  - CONF
TI  - Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8493
EP  - 8498
AU  - P. Maini
AU  - K. Yu
AU  - P. B. Sujit
AU  - P. Tokekar
PY  - 2018
KW  - aerospace robotics
KW  - integer programming
KW  - linear programming
KW  - multi-robot systems
KW  - path planning
KW  - tree searching
KW  - terrain
KW  - persistent monitoring
KW  - heterogeneous team
KW  - aerial robots
KW  - ground robots
KW  - MILP formulation
KW  - branch-and-cut framework
KW  - separation algorithm
KW  - Fuels
KW  - Monitoring
KW  - Unmanned aerial vehicles
KW  - Routing
KW  - Robot sensing systems
KW  - Kernel
DO  - 10.1109/IROS.2018.8593508
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.
ER  - 

TY  - CONF
TI  - A Mobility Model Based on Improved Artificial Potential Fields for Swarms of UAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8499
EP  - 8504
AU  - E. Falomir
AU  - S. Chaumette
AU  - G. Guerrini
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - information sharing
KW  - path planning
KW  - obstacles avoidance
KW  - mobility model
KW  - swarms
KW  - UAV
KW  - involved UAVs collaborate
KW  - mobility strategies
KW  - autonomous UAVs
KW  - collaborative tasks
KW  - multiple platforms
KW  - artificial potential fields principle
KW  - APF principle
KW  - Path planning
KW  - Sensors
KW  - Adaptation models
KW  - Collaboration
KW  - Task analysis
KW  - Laser radar
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593738
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A combination of several autonomous UAVs can be used to perform collaborative tasks. Such a combination is referred to as a swarm of drones. The use of multiple platforms can extend the system global capacities thanks to the resulting variety of embedded sensors and to information sharing. In this case, path planning and thus obstacles avoidance is still a major task. To deal with this issue, mobility models have to be implemented. Our contribution presented in this paper is a mobility model for swarms of UAVs based on the Artificial Potential Fields (APF) principle. In our model, the involved UAVs collaborate by sharing data about the obstacles that they detected. By doing so, a UAV which is not close enough to an obstacle to detect it thanks to its own sensors will still have the proper data to take this obstacle into account in its path planning. To validate our mobility strategies with realistic constraints we simulate the performances of existing sensors and transmitters, and consider real-world environment.
ER  - 

TY  - CONF
TI  - UAV/UGV Search and Capture of Goal-Oriented Uncertain Targets*This research was supported in part by ISF grant #1337/15 and part by a grant from MOST, Israel and the JST Japan
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8505
EP  - 8512
AU  - M. Sinay
AU  - N. Agmon
AU  - O. Maksimov
AU  - G. Levy
AU  - M. Bitan
AU  - S. Kraus
PY  - 2018
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - probability
KW  - remotely operated vehicles
KW  - UAV/UGV collaborative efforts
KW  - stochastic-temporal belief
KW  - attacker capture
KW  - defender real-time algorithmic framework
KW  - probability optimization
KW  - goal-oriented uncertain targets
KW  - UAV/UGV search
KW  - Games
KW  - Uncertainty
KW  - Search problems
KW  - Real-time systems
KW  - Task analysis
KW  - Mathematical model
KW  - Roads
DO  - 10.1109/IROS.2018.8594273
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers a new, complex problem of UAV/UGV collaborative efforts to search and capture attackers under uncertainty. The goal of the defenders (UAV/UGV team) is to stop all attackers as quickly as possible, before they arrive at their selected goal. The uncertainty considered is twofold: the defenders do not know the attackers' location and destination, and there is also uncertainty in the defenders' sensing. We suggest a real-time algorithmic framework for the defenders, combining entropy and stochastic-temporal belief, that aims at optimizing the probability of a quick and successful capture of all of the attackers. We have empirically evaluated the algorithmic framework, and have shown its efficiency and significant performance improvement compared to other solutions.
ER  - 

TY  - CONF
TI  - Lightweight Collision Avoidance for Resource-Constrained Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Shahriari
AU  - I. Švogor
AU  - D. St-Onge
AU  - G. Beltrame
PY  - 2018
KW  - collision avoidance
KW  - control system synthesis
KW  - mobile robots
KW  - motion control
KW  - resource-constrained robot
KW  - controller design
KW  - lightweight collision avoidance strategy
KW  - embedded control
KW  - reference control input
KW  - dynamic environment
KW  - low level motion control
KW  - on-board sensors
KW  - vehicle
KW  - physical robots
KW  - low computational requirements
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Navigation
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8593841
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the safest and most reliable strategies for vehicle's collision avoidance is embedded control at low level to guarantee safe motion in all situations using on-board sensors. In this paper, we propose a novel lightweight collision avoidance strategy that can be implemented as a low level motion control to achieve safe motion while simultaneously tracking the robot's reference control input. This strategy is designed to be general so that it can be easily integrated with most control designs, with the primary target of resource-constrained robot swarms that act in real-time, dynamic environments. The main advantages of our approach are a very simple structure and low computational requirements. We verified the effectiveness of the proposed collision avoidance strategy through two simulated scenarios and with physical robots. We believe our design can be directly used in many areas, such as autonomous driving, intelligent transportation and planetary exploration.
ER  - 

TY  - CONF
TI  - An Improved Formulation for Model Predictive Control of Legged Robots for Gait Planning and Feedback Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Yuan
AU  - Z. Li
PY  - 2018
KW  - feedback
KW  - legged locomotion
KW  - numerical stability
KW  - pendulums
KW  - predictive control
KW  - robot dynamics
KW  - robust control
KW  - gait planning
KW  - feedback control
KW  - MPC scheme
KW  - long prediction horizons
KW  - low dimensional models
KW  - model predictive control scheme
KW  - numerical stability
KW  - linear inverted pendulum model
KW  - LIPM
KW  - legged robots dynamics
KW  - external disturbance
KW  - robustness
KW  - Optimization
KW  - Legged locomotion
KW  - Numerical models
KW  - Acceleration
KW  - Planning
KW  - Numerical stability
DO  - 10.1109/IROS.2018.8594309
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Predictive control methods for walking commonly use low dimensional models, such as a Linear Inverted Pendulum Model (LIPM), for simplifying the complex dynamics of legged robots. This paper identifies the physical limitations of the modeling methods that do not account for external disturbances, and then analyzes the issues of numerical stability of Model Predictive Control (MPC)using different models with variable receding horizons. We propose a new modeling formulation that can be used for both gait planning and feedback control in an MPC scheme. The advantages are the improved numerical stability for long prediction horizons and the robustness against various disturbances. Benchmarks were rigorously studied to compare the proposed MPC scheme with the existing ones in terms of numerical stability and disturbance rejection. The effectiveness of the controller is demonstrated in both MATLAB and Gazebo simulations.
ER  - 

TY  - CONF
TI  - Cable-Driven Actuation for Highly Dynamic Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8543
EP  - 8550
AU  - J. Hwangbo
AU  - V. Tsounis
AU  - H. Kolvenbach
AU  - M. Hutter
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - control engineering computing
KW  - cooling
KW  - legged locomotion
KW  - pulleys
KW  - robot dynamics
KW  - torque control
KW  - cable-pulley system
KW  - light-weight
KW  - primary cooling element
KW  - power density
KW  - active elements
KW  - total leg weight
KW  - resulting robotic leg
KW  - low inertia
KW  - high torque transparency
KW  - low manufacturing cost
KW  - Capler-Leg system
KW  - experimental setup
KW  - cable-pulley design
KW  - cable-driven actuation
KW  - highly dynamic robotic systems
KW  - articulated robotic limb
KW  - single-stage cable-pulley transmission
KW  - high-gap radius motor
KW  - Torque
KW  - Legged locomotion
KW  - Pulleys
KW  - Mechanical cables
KW  - Creep
KW  - Resistance
DO  - 10.1109/IROS.2018.8593569
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and experimental evaluations of an articulated robotic limb called Capler-Leg. The key element of Capler-Leg is its single-stage cable-pulley transmission combined with a high-gap radius motor. Our cable-pulley system is designed to be as light-weight as possible and to additionally serve as the primary cooling element, thus significantly increasing the power density and efficiency of the overall system. The total weight of active elements on the leg, i.e. the stators and the rotors, contribute more than 60 % of the total leg weight, which is an order of magnitude higher than most existing robots. The resulting robotic leg has low inertia, high torque transparency, low manufacturing cost, no backlash, and a low number of parts. The Capler-Leg system itself, serves as an experimental setup for evaluating the proposed cable-pulley design in terms of robustness and efficiency. A continuous jump experiment shows a remarkable 96.5 % recuperation rate, measured at the battery output. This means that almost all the mechanical energy output during push-off is returned back to the battery during touch-down.
ER  - 

TY  - CONF
TI  - A Control Architecture with Online Predictive Planning for Position and Torque Controlled Walking of Humanoid Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Dafarra
AU  - G. Nava
AU  - M. Charbonneau
AU  - N. Guedelha
AU  - F. Andrade
AU  - S. Traversaro
AU  - L. Fiorio
AU  - F. Romano
AU  - F. Nori
AU  - G. Metta
AU  - D. Pucci
PY  - 2018
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - path planning
KW  - position control
KW  - predictive control
KW  - robot kinematics
KW  - torque control
KW  - inverse kinematics algorithm
KW  - iCub
KW  - center of mass trajectory
KW  - table-cart model
KW  - predictive controller
KW  - footstep positions
KW  - robot kinematic model
KW  - control loops
KW  - layered control architecture
KW  - humanoid robots
KW  - torque controlled walking
KW  - online predictive planning
KW  - stack-of-task QP-based torque controller
KW  - position controlled walking
KW  - Legged locomotion
KW  - Trajectory
KW  - Computer architecture
KW  - Mathematical model
KW  - Humanoid robots
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594277
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A common approach to the generation of walking patterns for humanoid robots consists in adopting a layered control architecture. This paper proposes an architecture composed of three nested control loops. The outer loop exploits a robot kinematic model to plan the footstep positions. In the mid layer, a predictive controller generates a Center of Mass trajectory according to the well-known table-cart model. Through a whole-body inverse kinematics algorithm, we can define joint references for position controlled walking. The outcomes of these two loops are then interpreted as inputs of a stack-of-task QP-based torque controller, which represents the inner loop of the presented control architecture. This resulting architecture allows the robot to walk also in torque control, guaranteeing higher level of compliance. Real world experiments have been carried on the humanoid robot iCub.
ER  - 

TY  - CONF
TI  - Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8567
EP  - 8573
AU  - C. Brooks
AU  - M. Atreya
AU  - D. Szafir
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - recurrent neural nets
KW  - proactive robot assistants
KW  - freeform collaborative tasks
KW  - multimodal recognition
KW  - generic subtasks
KW  - successful human-robot collaboration
KW  - shared understanding
KW  - current goals
KW  - nonlinear tasks
KW  - freeform tasks
KW  - explicit task model
KW  - robot partners
KW  - meaningful task knowledge
KW  - multimodal recurrent neural networks
KW  - short-term memory units
KW  - real-time subtask recognition
KW  - context-aware assistance
KW  - generic assembly tasks
KW  - specific subtasks
KW  - individual modalities
KW  - high-level representations
KW  - nonlinear connection layer
KW  - multimodal subtask recognition system
KW  - predictive assistance
KW  - human partner
KW  - human-robot team
KW  - assembly task
KW  - similar subtasks
KW  - freeform assembly scenario
KW  - RNN
KW  - Task analysis
KW  - Robot kinematics
KW  - Fasteners
KW  - Feature extraction
KW  - Activity recognition
KW  - Recurrent neural networks
DO  - 10.1109/IROS.2018.8594180
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.
ER  - 

TY  - CONF
TI  - Virtual Borders: Accurate Definition of a Mobile Robot's Workspace Using Augmented Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8574
EP  - 8581
AU  - D. Sprute
AU  - K. Tönnies
AU  - M. König
PY  - 2018
KW  - augmented reality
KW  - human-robot interaction
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - service robots
KW  - mobile robot
KW  - human-aware navigation
KW  - nonexpert users
KW  - vacuum cleaning
KW  - human-robot interface
KW  - augmented reality application
KW  - teaching time
KW  - baseline methods
KW  - user-defined virtual borders
KW  - Education
KW  - Navigation
KW  - Robot kinematics
KW  - Visualization
KW  - Robot sensing systems
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593615
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of interactively controlling the workspace of a mobile robot to ensure a human-aware navigation. This is especially of relevance for non-expert users living in human-robot shared spaces, e.g. home environments, since they want to keep the control of their mobile robots, such as vacuum cleaning or companion robots. Therefore, we introduce virtual borders that are respected by a robot while performing its tasks. For this purpose, we employ a RGB-D Google Tango tablet as human-robot interface in combination with an augmented reality application to flexibly define virtual borders. We evaluated our system with 15 non-expert users concerning accuracy, teaching time and correctness and compared the results with other baseline methods based on visual markers and a laser pointer. The experimental results show that our method features an equally high accuracy while reducing the teaching time significantly compared to the baseline methods. This holds for different border lengths, shapes and variations in the teaching process. Finally, we demonstrated the correctness of the approach, i.e. the mobile robot changes its navigational behavior according to the user-defined virtual borders.
ER  - 

TY  - CONF
TI  - Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - Y. Wu
AU  - R. Wang
AU  - L. F. D'Haro
AU  - R. E. Banchs
AU  - K. P. Tee
PY  - 2018
KW  - human computer interaction
KW  - human-robot interaction
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - linear decay system
KW  - seamless learning
KW  - multimodal robot apprenticeship
KW  - imitation learning
KW  - linearly decayed DMP
KW  - human-robot dialogue system
KW  - robot learning
KW  - robots
KW  - single demonstration modality
KW  - multimodal learning approach
KW  - natural interaction modalities
KW  - Task analysis
KW  - Trajectory
KW  - Ontologies
KW  - Convergence
KW  - Robot learning
KW  - Kernel
DO  - 10.1109/IROS.2018.8593634
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.
ER  - 

TY  - CONF
TI  - A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - V. K. Narayanan
AU  - T. Miyashita
AU  - Y. Horikawa
AU  - N. Hagita
PY  - 2018
KW  - decision making
KW  - Gaussian processes
KW  - indoor navigation
KW  - mobile robots
KW  - path planning
KW  - signal processing
KW  - wireless sensor networks
KW  - social robot navigation
KW  - networked service
KW  - wireless networks
KW  - Gaussian Process
KW  - robotic wheelchair operation
KW  - sub-optimal path
KW  - communication-aware planning constraints
KW  - connectivity issues
KW  - human-populated indoor environments
KW  - transient-goal driven communication-aware navigation strategy
KW  - human-aware planning constraints
KW  - radio signal strength constraints
KW  - decision making capabilities
KW  - shopping mall
KW  - Robot sensing systems
KW  - Navigation
KW  - Transient analysis
KW  - Mobile robots
KW  - Fading channels
KW  - Wireless communication
DO  - 10.1109/IROS.2018.8593827
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots deployed in large human-populated indoor environments such as shopping malls, airports etc., inadvertently communicate via wireless networks for enhanced perception and decision making capabilities. Owing to highly dynamic signal attenuation characteristics in such environments, connectivity issues may arise during robotic navigation, leading to disruption in information flow causing potential danger. Exact modeling of signal propagation for estimating spatial signal variation is usually challenging. Moreover, the presence of dynamic humans also add a layer of temporal signal variation complexities. Thus, this paper introduces a generative approach for embedding radio signal strength constraints within networked service/social robot navigation in large human-populated environments. Initially, we propose a Gaussian Process based online spatio-temporal signal strength prediction model that, as opposed to the current state of the art, also aims to take into account the temporal fading arising due to the presence of human crowds. We then devise a transient-goal driven navigation strategy to realize a sub-optimal path towards a goal, that is aimed at resolving both communication-aware and human-aware planning constraints. Evaluations of the proposed signal prediction model demonstrate the advantages of our approach with respect to the current state of the art. The efficacy of the navigation strategy in also demonstrated simulations and using hardware experiments conducted on a robotic wheelchair operating in a large shopping mall.
ER  - 

TY  - CONF
TI  - Walking Assistance and Resistance of Walking Motion by Trunk and Pelvis Motion Assist
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8597
EP  - 8602
AU  - K. Hashimoto
AU  - T. Tanaka
AU  - T. Kusaka
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - legged locomotion
KW  - motion control
KW  - walking assistance device
KW  - human gait motion
KW  - whole-body exercise
KW  - lower body
KW  - upper body motion
KW  - pelvic rotational motion
KW  - periodic input control
KW  - walking resistance
KW  - walking motion
KW  - Legged locomotion
KW  - Pelvis
KW  - Oscillators
KW  - Force
KW  - Control systems
KW  - Shafts
KW  - Knee
DO  - 10.1109/IROS.2018.8593531
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The aim of this study was to develop a walking assistance device by controlling trunk and pelvis motion. Human gait motion is a whole-body exercise that includes both lower body and upper body motion. Therefore, focusing on trunk and pelvic rotational motion, assist and resist the walking by applying external forces. By introducing periodic input control, control the timing of the supplementary force, and assist the walking. As an experimental result, the walking assistance improves gait by decreasing energy loss, and the walking resistance applies a load during walking.
ER  - 

TY  - CONF
TI  - Optimizing Contextual Ergonomics Models in Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. G. Marin
AU  - M. S. Shourijeh
AU  - P. E. Galibarov
AU  - M. Damsgaard
AU  - L. Fritzsch
AU  - F. Stulp
PY  - 2018
KW  - biomechanics
KW  - ergonomics
KW  - Gaussian processes
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - muscle
KW  - physiological models
KW  - accurate biomechanical simulations
KW  - robot control loops
KW  - high-dimensional musculoskeletal model
KW  - human-robot interaction
KW  - current ergonomic assessment procedures
KW  - ergonomic scores
KW  - ergonomic scoring
KW  - Gaussian process latent variable models
KW  - Ergonomics
KW  - Biological system modeling
KW  - Context modeling
KW  - Task analysis
KW  - Data models
KW  - Muscles
DO  - 10.1109/IROS.2018.8594132
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Current ergonomic assessment procedures require observation and manual annotation of postures by an expert, after which ergonomic scores are inferred from these annotations. Our aim is to automate this procedure and to enable robots to optimize their behavior with respect to such scores. A particular challenge is that ergonomic scoring requires accurate biomechanical simulations which are computationally too expensive to use in robot control loops or optimization. To address this, we learn Contextual Ergonomics Models, which are Gaussian Process Latent Variable Models that have been trained with full musculoskeletal simulations for specific tasks contexts. Contextual Ergonomics Models enable search in a low-dimensional latent space, whilst the cost function can be defined in terms of the full high-dimensional musculoskeletal model, which can be quickly reconstructed from the latent space. We demonstrate how optimizing Contextual Ergonomics Models leads to significantly reduced muscle activation in an experiment with eight subjects performing a drilling task.
ER  - 

TY  - CONF
TI  - Drivers' Manoeuvre Prediction for Safe HRI
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - E. J. Lopez Pulgarin
AU  - G. Herrmann
AU  - U. Leonards
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - road safety
KW  - road traffic control
KW  - traffic engineering computing
KW  - safe HRI
KW  - autonomous vehicles
KW  - decision-making systems
KW  - vehicles robots
KW  - human-robot interaction
KW  - autonomous agent
KW  - human driver interacts
KW  - motion tracking data
KW  - manoeuvre classification
KW  - drivers manoeuvre prediction
KW  - human-vehicle interaction
KW  - Task analysis
KW  - Vehicles
KW  - Robots
KW  - Roads
KW  - Decision making
KW  - Predictive models
KW  - Training
DO  - 10.1109/IROS.2018.8593957
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Machines with high levels of autonomy such as robots and our growing need to interact with them creates challenges to ensure safe operation. The recent interest to create autonomous vehicles through the integration of control and decision-making systems makes such vehicles robots too. We therefore applied estimation and decision-making mechanisms currently investigated for human-robot interaction to human-vehicle interaction. In other words, we define the vehicle as an autonomous agent with which the human driver interacts, and focus on understanding the human intentions and decision-making processes. These are then integrated into the ro-bot`s/vehicle's own control and decision-making system not only to understand human behaviour while it occurs but to predict the next actions. To obtain knowledge about the human's intentions, this work relies heavily on the use of motion tracking data (i.e. skeletal tracking, body posture)gathered from drivers whilst driving. We use a data-driven approach to both classify current driving manoeuvres and predict future manoeuvres, by using a fixed prediction window and augmenting a standard set of manoeuvres. Results are validated against drivers of different sizes, seat preferences and levels of driving expertise to evaluate the robustness of the methods; precision and recall metrics higher than 95% for manoeuvre classification and 90% for manoeuvre prediction with time-windows of up to 1.3 seconds are obtained. The idea of prediction adds a highly novel aspect to human-robot/human-vehicle interaction, allowing for decision and control at a later point.
ER  - 

TY  - CONF
TI  - Human Gaze Following for Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8615
EP  - 8621
AU  - A. Saran
AU  - S. Majumdar
AU  - E. S. Short
AU  - A. Thomaz
AU  - S. Niekum
PY  - 2018
KW  - control engineering computing
KW  - face recognition
KW  - gaze tracking
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - single 2D image
KW  - human gaze predictions
KW  - human-robot interaction tasks
KW  - fluent interactions
KW  - mutual gaze prediction
KW  - gaze heat map statistics
KW  - referential gaze
KW  - deep learning approach
KW  - human gaze fixations
KW  - Task analysis
KW  - Real-time systems
KW  - Head
KW  - Cameras
KW  - Robot vision systems
KW  - Videos
DO  - 10.1109/IROS.2018.8593580
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Gaze provides subtle informative cues to aid fluent interactions among people. Incorporating human gaze predictions can signify how engaged a person is while interacting with a robot and allow the robot to predict a human's intentions or goals. We propose a novel approach to predict human gaze fixations relevant for human-robot interaction tasks-both referential and mutual gaze-in real time on a robot. We use a deep learning approach which tracks a human's gaze from a robot's perspective in real time. The approach builds on prior work which uses a deep network to predict the referential gaze of a person from a single 2D image. Our work uses an interpretable part of the network, a gaze heat map, and incorporates contextual task knowledge such as location of relevant objects, to predict referential gaze. We find that the gaze heat map statistics also capture differences between mutual and referential gaze conditions, which we use to predict whether a person is facing the robot's camera or not. We highlight the challenges of following a person's gaze on a robot in real time and show improved performance for referential gaze and mutual gaze prediction.
ER  - 

TY  - CONF
TI  - Incorporating Kinematic Properties into Fused Deposition Toolpath Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8622
EP  - 8627
AU  - S. Lensgraf
AU  - R. R. Mettu
PY  - 2018
KW  - layered manufacturing
KW  - optimisation
KW  - production engineering computing
KW  - rapid prototyping (industrial)
KW  - solid modelling
KW  - three-dimensional printing
KW  - fused deposition toolpath optimization
KW  - toolpath planning
KW  - fused deposition 3D printing slice
KW  - slicing-based methods
KW  - wasted motion
KW  - extruder
KW  - prints local features
KW  - local search
KW  - 3D printing process
KW  - accurate kinematic model
KW  - real-world fabrication time
KW  - toolpath optimization algorithm
KW  - real-world improvement
KW  - model characterization
KW  - 2D layers
KW  - toolpaths
KW  - Printers
KW  - Motion segmentation
KW  - Kinematics
KW  - Fabrication
KW  - Acceleration
KW  - Optimization
KW  - Planning
DO  - 10.1109/IROS.2018.8594398
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The most widely used methods for toolpath planning in fused deposition 3D printing slice the input model into successive 2D layers in order to construct the toolpath. Unfortunately slicing-based methods can incur a substantial amount of wasted motion (i.e., the extruder is moving while not printing), particularly when features of the model are spatially separated. In recent work we have introduced a new paradigm that constructs the toolpath in 3D and prints local features to minimize wasted motion. Our algorithm is based on a local search and we have demonstrated substantial improvements in the efficiency of the resulting toolpaths. Our approach is amenable to incorporating physical constraints of the 3D printing process, and, in this paper we extend our approach to incorporate kinematic properties into toolpath optimization. With an accurate kinematic model of the extruder, our algorithm is able to model the real-world fabrication time of the model with a high degree of accuracy. To our knowledge, this toolpath optimization algorithm is the first to encode real-world fabrication time as the objective function. We demonstrate the real-world improvement in fabrication time that is possible with our algorithm on a benchmark of almost 600 models. We find improvement in nearly every toolpath generated for our benchmark set (with a mean of 3.2%), but substantially larger improvements for some models. To rationalize these results, we introduce a metric for model characterization that we call “oriented compactness” and show that it correlates positively with our observations. We believe this metric can be an important tool in the setup of fabrication (e.g., by guiding an orientation search of the model).
ER  - 

TY  - CONF
TI  - A Natural Adaptive Control Law for Robot Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Lee
AU  - J. Kwon
AU  - F. C. Park
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - geometry
KW  - manipulators
KW  - natural adaptive control law
KW  - robot manipulators
KW  - robot parameters
KW  - coordinate-invariant differential geometric structure
KW  - Adaptive control
KW  - Symmetric matrices
KW  - Robot kinematics
KW  - Lead
KW  - Manipulators
KW  - Measurement
DO  - 10.1109/IROS.2018.8593727
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Existing adaptive robot control laws typically require an engineering choice of a constant adaptation gain matrix, which often involves repeated and time-consuming trial and error. Moreover, physical consistency of the estimated inertial parameters or the uniform positive definiteness of the estimated robot mass matrix cannot in general be guaranteed without nonsmooth corrections, e.g., projection to the boundary of the feasible parameter set. In this paper we present a natural adaptive control law that mitigates many of these difficulties, by exploiting the coordinate-invariant differential geometric structure of the space of physically consistent inertial parameters. Our approach provides a more generalizable and physically consistent adaptation law for the robot parameters without significant additional computations compared to existing methods. Simulation results showing markedly improved tracking error convergence over existing adaptive control laws are provided as validation.
ER  - 

TY  - CONF
TI  - Map-based Deep Imitation Learning for Obstacle Avoidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8644
EP  - 8649
AU  - Y. Liu
AU  - A. Xu
AU  - Z. Chen
PY  - 2018
KW  - collision avoidance
KW  - decision making
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - mobile robots
KW  - deep imitation learning algorithm
KW  - egocentric local occupancy maps
KW  - fast feed-forward inferences
KW  - policy robustness
KW  - optimal decision making
KW  - obstacle avoidance policy
KW  - map-based deep imitation learning
KW  - value iteration networks
KW  - near-optimal continuous action commands
KW  - planning-based scenarios
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Mobile robots
KW  - Training
KW  - Neural networks
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593683
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Making an optimal decision to avoid obstacles while heading to the goal is one of the fundamental challenges for mobile robots equipped with limited computational resources. In this paper, we present a deep imitation learning algorithm that develops a computationally efficient obstacle avoidance policy based on egocentric local occupancy maps. The trained model embedded with a variant of the value iteration networks is able to provide near-optimal continuous action commands through fast feed-forward inferences and generalize well to unseen planning-based scenarios. To improve the policy robustness, we augment the training data set with artificially generated maps, which effectively alleviates the shortage of catastrophic samples in normal demonstrations. Extensive experiments on a Segway robot show the effectiveness of the proposed approach in terms of solution optimality, robustness as well as computation time.
ER  - 

TY  - CONF
TI  - Wireframe Mapping for Resource-Constrained Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Caccavale
AU  - M. Schwager
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - simulation mapping
KW  - wireframe mapping
KW  - resource-constrained robots
KW  - wireframe representation
KW  - particle filter
KW  - sparse wireframe map structure
KW  - map representation
KW  - wireframe structure
KW  - occupancy grid map
KW  - discrete map errors
KW  - Simultaneous localization and mapping
KW  - Uncertainty
KW  - Two dimensional displays
KW  - Geometry
KW  - Navigation
DO  - 10.1109/IROS.2018.8594057
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel wireframe map structure for resource-constrained robots operating in a rectilinear 2D environment. The wireframe representation compactly represents geometry, in addition to transient situations such as occlusions and boundaries of unexplored regions. We formulate a particle filter to suit this sparse wireframe map structure. Functions for calculating the likelihood of scans, merging wireframes, and resampling are developed to accommodate this map representation. The wireframe structure with the particle filter allows for severe discrete map errors to be corrected, leading to accurate maps with small storage requirements. We show in a simulation study that the algorithm attains a map of an environment with 1 % error, compared to an occupancy grid map obtained with GMapping which attained 23% error with the same storage requirements. A simulation mapping a large environment demonstrates the algorithms scalability.
ER  - 

TY  - CONF
TI  - Accelerating Goal-Directed Reinforcement Learning by Model Characterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Debnath
AU  - G. Sukhatme
AU  - L. Liu
PY  - 2018
KW  - learning (artificial intelligence)
KW  - approximate model
KW  - hybrid approach
KW  - goal-directed reinforcement learning
KW  - model-based reinforcement learning
KW  - model characterization
KW  - model-free reinforcement learning
KW  - mean-first passage time
KW  - Reinforcement learning
KW  - Computational modeling
KW  - Markov processes
KW  - Acceleration
KW  - Convergence
KW  - Learning systems
DO  - 10.1109/IROS.2018.8593728
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a hybrid approach aimed at improving the sample efficiency in goal-directed reinforcement learning. We do this via a two-step mechanism where firstly, we approximate a model from Model-Free reinforcement learning. Then, we leverage this approximate model along with a notion of reachability using Mean First Passage Times to perform Model-Based reinforcement learning. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Q-Learning (MFPT-Q)and Mean First Passage Time based DYNA (MFPT-DYNA), that have been fundamentally modified from the state-of-the-art reinforcement learning techniques. Preliminary results have shown that our hybrid approaches converge with much fewer iterations than their corresponding state-of-the-art counterparts and therefore requiring much fewer samples and much fewer training trials to converge.
ER  - 

TY  - CONF
TI  - Improving Trajectory Optimization Using a Roadmap Framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8674
EP  - 8681
AU  - S. Dai
AU  - M. Orton
AU  - S. Schaffert
AU  - A. Hofmann
AU  - B. Williams
PY  - 2018
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - sampling methods
KW  - trajectory control
KW  - trajectory optimization process
KW  - sampling-based planners
KW  - motion planning system
KW  - multiquery roadmap
KW  - sparse roadmap framework
KW  - optimization-based motion planners
KW  - Planning
KW  - Trajectory optimization
KW  - Robots
KW  - Dynamics
KW  - Task analysis
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594274
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an evaluation of several representative sampling-based and optimization-based motion planners, and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimization into a sparse roadmap framework. Through experiments in 4 common application scenarios with 5000 test cases each, we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge, this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art motion planners, which are based on a significant amount of experiments. We then combine different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior performance over other standard sampling-based planners' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem, our approach allows for extensions such as persistent control policy information associated with a trajectory across planning problems. Also, the sub-optimality resulting from the sparsity of roadmap, as well as the unexpected disturbances from the environment, can both be overcome by the real-time trajectory optimization process.
ER  - 

TY  - CONF
TI  - PH Model-Based Shape Reconstruction of Heterogeneous Continuum Closed Loop Kinematic Chain: An Application to Skipping Rope
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8682
EP  - 8688
AU  - I. Singh
AU  - Y. Amara
AU  - O. Lakhal
AU  - A. Melingui
AU  - R. Merzouki
PY  - 2018
KW  - closed loop systems
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - position control
KW  - skipping rope
KW  - soft robotics
KW  - demanding field
KW  - shape reconstruction method
KW  - kinematic behavior
KW  - heterogeneous continuum robot
KW  - closed loop kinematic configuration
KW  - Pythagorean Hodograph curves
KW  - Compact Bionic Handling Arms
KW  - intermediate flexible rope
KW  - PH model-based shape reconstruction
KW  - heterogeneous continuum closed loop kinematic chain
KW  - continuum robots
KW  - Manipulators
KW  - Shape
KW  - Kinematics
KW  - Biological system modeling
KW  - Electron tubes
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593934
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft robotics is a swiftly growing research area these days. Modeling continuum robots accurately is still a demanding field. The paper aims to propose a shape reconstruction method and the estimation of the kinematic behavior of heterogeneous continuum robot in closed loop kinematic configuration, by using Pythagorean Hodograph (PH) curves. The validation of the model approach has been tested on cooperative continuum robots, namely Compact Bionic Handling Arms (CBHA), driving an intermediate flexible rope (a passive flexible link), by using a 3D tracking system. Experimental comparison of the proposed approach with the existing approaches is performed in terms of accuracy as well as the time cost.
ER  - 

TY  - CONF
TI  - Optimal Feedback Control Based on Analytical Linear Models Extracted from Neural Networks Trained for Nonlinear Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8689
EP  - 8694
AU  - Y. Duan
AU  - S. Ikemoto
AU  - K. Hosoda
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - linear systems
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - optimal control
KW  - robots
KW  - neural network
KW  - mathematical models
KW  - control theory
KW  - optimal feedback control
KW  - analytical linear models
KW  - nonlinear systems
KW  - robots
KW  - soft structures
KW  - flexible musculoskeletal systems
KW  - systematic design policy
KW  - conventional robotics
KW  - linear system models
KW  - Mathematical model
KW  - Neural networks
KW  - Computational modeling
KW  - Manipulators
KW  - Control theory
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8593507
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A number of researches have been focusing on the development and control of robots with soft structures such as flexible musculoskeletal systems. Thus far, it has been reported that these robots can achieve high adaptability to environments despite their extremely simple controllers. However, because these robots are difficult to model mathematically, there is still no systematic design policy, in which control theory has been playing a role in conventional robotics, for constituting simple controllers. To tackle this problem, we propose a new approach using a neural network to obtain mathematical models. In particular, with this method, the control theory is applied to linear system models extracted from a network trained to express the forward dynamics of a robot. Through simulations, the validity and advantage of the proposed method was successfully confirmed.
ER  - 

TY  - CONF
TI  - Learning to Grasp by Extending the Peri-Personal Space Graph
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8695
EP  - 8700
AU  - J. Juett
AU  - B. Kuipers
PY  - 2018
KW  - dexterous manipulators
KW  - graph theory
KW  - grippers
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - robot model
KW  - infant learning
KW  - human infants
KW  - robotic learning agent
KW  - analogous models
KW  - deliberate grasp action
KW  - Palmar reflex
KW  - PPS graph
KW  - peri-personal space graph model
KW  - grasp learning
KW  - jerky submotions
KW  - gripper fingers
KW  - Manipulators
KW  - Reliability
KW  - Grippers
KW  - Robot sensing systems
KW  - Visualization
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593938
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a robot model of early reach and grasp learning, inspired by infant learning without prior knowledge of the geometry, kinematics, or dynamics of the arm. Human infants at reach onset are capable of using a sequence of jerky submotions to bring the hand to the position of a nearby object. A robotic learning agent can produce qualitatively similar behavior by using a graph representation to encode a set of safe, potentially useful arm states and feasible moves between them. These observations show that the Peri-Personal Space (PPS) Graph model is sufficient for early reaching and suggest that infants may use analogous models during this phase. In this paper, we show that the PPS Graph, with a simulated Palmar reflex (a reflex in infants that closes the fingers when the palm is touched), allows accidental grasps to occur during continued reaching practice. Given these occasional events, the agent can bootstrap to a simple deliberate grasp action. In particular, the agent must learn three new necessary conditions for a grasp: the hand should be open as the grasp begins, the final motion of the hand should be led by the gripper opening so that it reaches the target first, and the wrist must be oriented such that the gripper fingers may close around the target object, often requiring the opening to be perpendicular to the object's major axis. Combined with the existing capability to reach and interact with target objects, knowledge of these conditions allows the agent to learn increasingly reliable purposeful grasps. The first two conditions are addressed in this paper, and allow 45% of grasps to succeed. This work contributes toward the larger goal of foundational robot learning after the model of infant learning, with minimal prior knowledge of its own anatomy or its environment. The ability to grasp will allow the agent to control the motion and position of objects, providing a richer representation for its environment and new experiences to learn from.
ER  - 

TY  - CONF
TI  - Impedance Control of a High Performance Twisted-Coiled Polymer Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8701
EP  - 8706
AU  - T. Luong
AU  - K. Kim
AU  - S. Seo
AU  - J. H. Park
AU  - Y. Kim
AU  - S. Y. Yang
AU  - K. H. Cho
AU  - J. C. Koo
AU  - H. R. Choi
AU  - H. Moon
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - control nonlinearities
KW  - control system synthesis
KW  - damping
KW  - digital control
KW  - force control
KW  - manipulators
KW  - motion control
KW  - position control
KW  - stability
KW  - worst position error
KW  - impedance control
KW  - angular position reference
KW  - control system
KW  - backstepping control law
KW  - torque-based law
KW  - variable stiffness
KW  - position control
KW  - model-based impedance controller
KW  - Joule heating capability
KW  - nylon fibers
KW  - embedded controller
KW  - high performance super-coiled polymer actuators
KW  - 1-link robotic arm
KW  - high performance twisted-coiled polymer actuator
KW  - Actuators
KW  - Impedance
KW  - Mathematical model
KW  - Force
KW  - Damping
KW  - Strain
KW  - Water heating
DO  - 10.1109/IROS.2018.8593937
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a 1-link robotic arm that is antagonistically driven by one pair of a high performance super-coiled polymer actuators with an embedded controller. The actuator which is made from Spandex and nylon fibers is low-cost, easy to fabricate and light-weight. Moreover, it can generate large displacement and provide Joule heating capability. The main contribution of the paper is the model-based impedance controller, which enables position control of the antagonistic joint with variable stiffness and damping. The impedance control is a torque-based law, which in turn depends on a proposed backstepping control law to control the force of each actuator. The control system is proved to be stable using dissipativity stability theory and verified through experiments. Experimental results show that our system can track the angular position reference with the worst position error of 0.43deg and root-mean squared error of 0.16deg at steady state for sinusoidal waveform tracking (with the frequency of 0.1Hz), and the worst position error of 0.2deg for set-point regulation.
ER  - 

TY  - CONF
TI  - Jumping Motion Generation of a Humanoid Robot Utilizing Human-Like Joint Elasticity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8707
EP  - 8714
AU  - T. Otani
AU  - K. Hashimoto
AU  - H. Ueta
AU  - M. Sakaguchi
AU  - Y. Kawakami
AU  - H. O. Lim
AU  - A. Takanishi
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - human-like joint elasticity
KW  - jumping motion generation
KW  - leaf springs
KW  - joint mechanism
KW  - joint stiffness
KW  - active pushing-off
KW  - countermovement jump method
KW  - spring behavior
KW  - active joint driving
KW  - high-power movement
KW  - humanoid robots
KW  - Elasticity
KW  - Legged locomotion
KW  - Springs
KW  - Humanoid robots
KW  - Trajectory
KW  - Force
DO  - 10.1109/IROS.2018.8594085
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To improve the movement ability of humanoid robots, instead of traditional methods dependent on only power of actuators, there is possibility that utilizing elasticity inspired from collaboration of muscle and tendon of human is effective to achieve high-power movement. In this study, we aimed to realize a jumping motion that accumulates energy more appropriately in spring by combining active joint driving with spring behavior like human tendons and muscles. We proposed a countermovement jump method using the resonance with the leg's active pushing-off movement and leg stiffness. To achieve active pushing-off and joint stiffness, we developed a new joint mechanism using leaf springs and an actuator unit with a worm gear. We then performed experiments to evaluate the effectiveness of the proposed mechanism and methods. Finally, the robot achieved a countermovement jump using active kicking and leg's elasticity.
ER  - 

TY  - CONF
TI  - Secure Data Recording and Bio-Inspired Functional Integrity for Intelligent Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8723
EP  - 8728
AU  - S. Taurer
AU  - B. Dieber
AU  - P. Schartner
PY  - 2018
KW  - data recording
KW  - digital forensics
KW  - intelligent robots
KW  - security of data
KW  - modern robots
KW  - complex machines
KW  - bio-inspired functional integrity
KW  - secure data recording
KW  - uncontrolled environment
KW  - flight data recorder
KW  - intelligent robots
KW  - transparent function
KW  - Digital signatures
KW  - Intelligent robots
KW  - Public key
KW  - Forensics
DO  - 10.1109/IROS.2018.8593994
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As modern robots become more intelligent, also their use will broaden in public and professional areas. While the aim is to make robots beneficial to humans and society, using those complex machines in complex environments will eventually lead to incidents. To enable forensic investigations, ethical evaluations and transparent function of intelligent robots in a society, we contribute the concept of a secure robot data recorder that is similar to a flight data recorder in airplanes. However, since robots work in a highly networked and uncontrolled environment, our concept pays special attention to security and tamper proofness. In addition, we extend the concept with an approach inspired by cockroaches to increase the functional integrity of the robot. We present a prototype implementation along with discussions on the required properties and limits of secure data recording.
ER  - 

TY  - CONF
TI  - Rendering of Virtual Volumetric Shapes Using an Electromagnetic-Based Haptic Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Adel
AU  - M. M. Micheal
AU  - M. A. Self
AU  - S. Abdennadher
AU  - I. S. M. Khalil
PY  - 2018
KW  - electromagnetic forces
KW  - haptic interfaces
KW  - rendering (computer graphics)
KW  - statistical analysis
KW  - virtual reality
KW  - virtual reality
KW  - magnetic dipole
KW  - rendering algorithm
KW  - position feedback
KW  - augmented reality
KW  - statistical evidence
KW  - virtual three dimensional object
KW  - 3D virtual objects
KW  - exerted magnetic force
KW  - impedance-type haptic rendering
KW  - electromagnetic coils
KW  - electromagnetic forces
KW  - wearable orthopedic finger splint
KW  - controlled magnetic forces
KW  - electromagnetic-based haptic interface
KW  - virtual volumetric shapes
KW  - Magnetic moments
KW  - Coils
KW  - Magnetic forces
KW  - Haptic interfaces
KW  - Rendering (computer graphics)
KW  - Force
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593699
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mid-Air haptic devices have become an active area of research because of their potential impact to augmented/virtual reality. In this work, we develop an electromagnetic-based haptic interface to provide controlled magnetic forces on a wearable orthopedic finger splint with a single magnetic dipole. We model the electromagnetic forces exerted on the finger splint, optimize the design of the electromagnetic coils, and develop an impedance-type haptic rendering algorithm using position feedback. This rendering algorithm capitalizes on minimizing the error between the exerted magnetic force and the desired constraint force of a virtual three-dimensional (3D)object based on the position of the finger splint. In order to investigate the influence of incorporating position feedback, we conduct a comparative study for the same group of participants with (Case I)and without (Case II)position feedback. Our experimental results show that position feedback enables participants to achieve success rate of 66.87 ± 15.0% (n=160) in distinguishing between the geometry of four 3D virtual objects. This rate is decreased to 55.15±15.8% (n=160) in the absence of position feedback. Our analysis shows statistical evidence to conclude that the mean success rate for Case I is greater than that of Case II, at α = 0.1 and 90% confidence level.
ER  - 

TY  - CONF
TI  - Master-Slave Coordination Using Virtual Constraints for a Redundant Dual-Arm Haptic Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8751
EP  - 8757
AU  - M. M. Ghazaei Ardakani
AU  - M. Karlsson
AU  - K. Nilsson
AU  - A. Robertsson
AU  - R. Johansson
PY  - 2018
KW  - force feedback
KW  - redundant manipulators
KW  - master-slave coordination
KW  - virtual constraints
KW  - redundant dual-arm haptic interface
KW  - force interaction
KW  - immersive haptic interface
KW  - task demonstration
KW  - robotic systems
KW  - haptic feedback
KW  - Robot kinematics
KW  - Task analysis
KW  - Haptic interfaces
KW  - Manipulators
KW  - Kinematics
KW  - Tools
DO  - 10.1109/IROS.2018.8594260
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Programming robots for tasks involving force interaction is difficult, since both the knowledge of the task and the dynamics of the robots are necessary. An immersive haptic interface for task demonstration is proposed, where the operator can sense and act through the robot. This is achieved by coupling two robotic systems with virtual constraints such that they have the same coordinates in the operational space disregarding a fixed offset. Limitations caused by the singular configurations or the reach of the robots are naturally reflected to either side as haptic feedback.
ER  - 

TY  - CONF
TI  - Gaussian Process Dynamic Programming for Optimizing Ungrounded Haptic Guidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8758
EP  - 8764
AU  - J. M. Walker
AU  - A. M. Okamura
AU  - M. J. Kochenderfer
PY  - 2018
KW  - dynamic programming
KW  - Gaussian processes
KW  - gyroscopes
KW  - haptic interfaces
KW  - human-robot interaction
KW  - Gaussian process dynamic programming
KW  - ungrounded haptic guidance
KW  - human-robot interactions
KW  - haptic devices
KW  - ungrounded control moment gyroscope haptic device
KW  - cued haptic direction
KW  - Haptic interfaces
KW  - Torque
KW  - Brushless motors
KW  - Quaternions
KW  - Task analysis
KW  - Gaussian processes
KW  - Robots
DO  - 10.1109/IROS.2018.8594395
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Adapting robot actions to human motions can make human-robot interactions (HRI) more effective. Here, we aim to optimize guidance from haptic devices based on a user's response to produce better task performance. We used Gaussian processes to model the motions a human user made in response to applied torques from an ungrounded control moment gyroscope haptic device. We then used Gaussian process dynamic programming to generate optimized haptic cues to guide the user to rotate the device toward 3D targets. We compared the performance of naive and optimized policies in simulations and with a human user, and found that dynamic programming can significantly improve haptic guidance in cases where human responses are highly variable or inconsistent with the cued haptic direction.
ER  - 

TY  - CONF
TI  - A Novel Input Device for Robotic Prosthetic Hand: Design and Preliminary Results
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Kim
AU  - D. Lee
AU  - H. Park
AU  - J. Park
AU  - J. Bae
PY  - 2018
KW  - biomechanics
KW  - biomedical electrodes
KW  - electromyography
KW  - medical robotics
KW  - medical signal processing
KW  - multilayer perceptrons
KW  - prosthetics
KW  - signal classification
KW  - medical electrodiagnostic techniques
KW  - EMG signal
KW  - impedance change
KW  - skin
KW  - noncontact manner
KW  - hand movements
KW  - novel input device
KW  - robotic prosthetic hand
KW  - capacitance change
KW  - data processing
KW  - deformation
KW  - electrode
KW  - sensor
KW  - multilayer perceptron
KW  - classification success rates
KW  - Skin
KW  - Electrodes
KW  - Capacitance
KW  - Muscles
KW  - Robot sensing systems
KW  - Electromyography
KW  - Input devices
DO  - 10.1109/IROS.2018.8593809
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel input device for a robotic prosthetic hand based on capacitance change. The proposed device can sense the deformation of the skin due to the activity of the muscle by measuring the capacitance change between the skin and the electrode. Therefore, it can be used as a sensor for estimating a user's intention through medical electrodiagnostic techniques such as electromyogram (EMG)and force myography (FMG). The proposed device can acquire data in a non-invasive way and is advantageous with easier data processing than that for an EMG signal. Moreover, it is resistant to the impedance change of skin because the capacitance is measured in a non-contact manner, unlike the existing methods which work with direct contact with the skin such as EMG. Additionally, unlike FMG, the device is lightly attached to the skin without being strongly fixed with velcro, which offsets problems that occur while re-wearing the device. To demonstrate the feasibility of the proposed idea, three of the newly developed input devices were used to classify four hand movements (fist, scissors, paper, and rest)using a multilayer perceptron (MLP). As a result, the classification success rates for the fist, paper, scissor, and rest motions were obtained as 99.3%, 98.3%, 98.4%, and 99.1%, respectively.
ER  - 

TY  - CONF
TI  - Continuous State-Action-Observation POMDPs for Trajectory Planning with Bayesian Optimisation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 8779
EP  - 8786
AU  - P. Morere
AU  - R. Marchant
AU  - F. Ramos
PY  - 2018
KW  - belief networks
KW  - decision making
KW  - decision theory
KW  - Hilbert spaces
KW  - Markov processes
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - trees (mathematics)
KW  - trajectory planning
KW  - POMDP solvers
KW  - CBTS
KW  - dynamic sampling
KW  - robot parking problems
KW  - bayesian optimisation
KW  - partially observable Markov decision process
KW  - reproducing kernel Hilbert spaces
KW  - kCBTS
KW  - continuous belief tree search
KW  - RKHS
KW  - Trajectory
KW  - Planning
KW  - Robots
KW  - Optimization
KW  - Kernel
KW  - Bayes methods
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593850
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Decision making under uncertainty is a challenging task, especially when dealing with complex robotics scenarios. The Partially Observable Markov Decision Process (POMDP) framework, designed to solve this problem, was subject to much work lately. Most POMDP solvers, however, focus on planning in discrete state, action and/or observations spaces, which does not truly reflect the complexity of most real world problems. This paper addresses the issue by devising a method for solving POMDPs with continuous state, action and observations spaces. The proposed planner, Continuous Belief Tree Search (CBTS), uses Bayesian Optimisation (BO) to dynamically sample promising actions while constructing a belief tree. This dynamic sampling allows for richer action selection than offline action discretisation. CBTS is complemented by a novel trajectory generation technique, relying on the theory of Reproducing Kernel Hilbert Spaces (RKHS), yielding trajectories amenable for robotics applications. The resulting trajectory planner kCBTS outperforms other continuous planners on space modelling and robot parking problems.
ER  - 


