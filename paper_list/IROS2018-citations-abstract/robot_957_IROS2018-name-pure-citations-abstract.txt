total paper: 957
Title: Plenary sessions
Key Words: Artificial intelligence  Humanoid robots  Robot sensing systems  Collaboration  Biographies  Neural networks 
Abstract: Provides an abstract for each of the plenary presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.


Title: Forums
Key Words: Service robots  Artificial intelligence  Companies  Europe  Smart cities 
Abstract: Provides an abstract for each of the Forum presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.


Title: Workshops
Key Words: Conferences  Service robots  Diseases  Task analysis  Grasping  Robot sensing systems 
Abstract: Provides an abstract for each of the workshop presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.


Title: IROS 2018 Technical Program
Key Words: Conferences  Service robots  Diseases  Task analysis  Grasping  Robot sensing systems 
Abstract: Provides a schedule of conference events and a listing of which papers were presented in each session.


Title: Content List
Key Words: Conferences  Service robots  Diseases  Task analysis  Grasping  Robot sensing systems 
Abstract: Presents the table of contents/splash page of the proceedings record.


Title: IROS 2018 Author Index
Key Words: Conferences  Service robots  Diseases  Task analysis  Grasping  Robot sensing systems 
Abstract: Presents an index of the authors whose articles are published in the conference proceedings record.


Title: Index of papers
Key Words: Conferences  Service robots  Diseases  Task analysis  Grasping  Robot sensing systems 
Abstract: Presents the table of contents/splash page of the proceedings record.


Title: Real-time Convolutional Networks for Depth-based Human Pose Estimation
Key Words: convolutional neural nets  feature extraction  human-robot interaction  image colour analysis  inference mechanisms  learning (artificial intelligence)  pose estimation  convolutional neural networks models  human robot interaction  depth-based human pose estimation  pose inference  residual blocks  body landmark localization  depth imaging  human bodies  human detection  RGB images  Feature extraction  Pose estimation  Computational modeling  Three-dimensional displays  Shape  Detectors  Cameras 
Abstract: We propose to combine recent Convolutional Neural Networks (CNN) models with depth imaging to obtain a reliable and fast multi-person pose estimation algorithm applicable to Human Robot Interaction (HRI) scenarios. Our hypothesis is that depth images contain less structures and are easier to process than RGB images while keeping the required information for human detection and pose inference, thus allowing the use of simpler networks for the task. Our contributions are threefold. (i) we propose a fast and efficient network based on residual blocks (called RPM) for body landmark localization from depth images; (ii) we created a public dataset DIH comprising more than 170k synthetic images of human bodies with various shapes and viewpoints as well as real (annotated) data for evaluation; (iii) we show that our model trained on synthetic data from scratch can perform well on real data, obtaining similar results to larger models initialized with pre-trained networks. It thus provides a good trade-off between performance and computation. Experiments on real data demonstrate the validity of our approach.


Title: Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline
Key Words: feature extraction  human-robot interaction  image filtering  learning (artificial intelligence)  object detection  object tracking  pose estimation  robot vision  DetTA pipeline  people detection  dynamic information  social robot-person interaction  fully modular detection-tracking-analysis pipeline  temporal filtering  person attribute  track ID  person analysis  GPU-memory  power consumption  head pose  skeleton pose  deep learning methods  Robots  Pipelines  Skeleton  Head  Estimation  Detectors  Trajectory 
Abstract: In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.


Title: 3D Human Pose Estimation on a Configurable Bed from a Pressure Image
Key Words: convolutional neural nets  manipulators  Monte Carlo methods  pose estimation  stereo image processing  single pressure image  convolutional neural networks  flat beds  pressure-sensing mat  bedding materials  robots  configurable bed  3D human pose estimation  estimated kinematic model  pressure mat  mean joint position error  bed configurations  limb lengths  3D joint positions  size 77.0 mm  Three-dimensional displays  Pose estimation  Kinematics  Skeleton  Robot sensing systems  Two dimensional displays 
Abstract: Robots have the potential to assist people in bed, such as in healthcare settings, yet bedding materials like sheets and blankets can make observation of the human body difficult for robots. A pressure-sensing mat on a bed can provide pressure images that are relatively insensitive to bedding materials. However, prior work on estimating human pose from pressure images has been restricted to 2D pose estimates and flat beds. In this work, we present two convolutional neural networks to estimate the 3D joint positions of a person in a configurable bed from a single pressure image. The first network directly outputs 3D joint positions, while the second outputs a kinematic model that includes estimated joint angles and limb lengths. We evaluated our networks on data from 17 human participants with two bed configurations: supine and seated. Our networks achieved a mean joint position error of 77 mm when tested with data from people outside the training set, outperforming several baselines. We also present a simple mechanical model that provides insight into ambiguity associated with limbs raised off of the pressure mat, and demonstrate that Monte Carlo dropout can be used to estimate pose confidence in these situations. Finally, we provide a demonstration in which a mobile manipulator uses our network's estimated kinematic model to reach a location on a person's body in spite of the person being seated in a bed and covered by a blanket.


Title: Estimating Metric Poses of Dynamic Objects Using Monocular Visual-Inertial Fusion
Key Words: augmented reality  cameras  feature extraction  image fusion  image sequences  mobile robots  object detection  object tracking  pose estimation  robot vision  state estimation  metric pose estimation  state estimation  3D tracking performance  tracking accuracy  correlation analysis-based metric scale estimator  2D object tracker  monocular camera  visual-inertial system  monocular sensing suite  scale observability  fixed multicamera  visual-inertial tracking system  arbitrary dynamic object  monocular 3D object tracking system  monocular visual-inertial fusion  dynamic objects  Cameras  Three-dimensional displays  Visualization  Estimation  Two dimensional displays  Tracking 
Abstract: A monocular 3D object tracking system generally has only up-to-scale pose estimation results without any prior knowledge of the tracked object. In this paper, we propose a novel idea to recover the metric scale of an arbitrary dynamic object by optimizing the trajectory of the objects in the world frame, without motion assumptions. By introducing an additional constraint in the time domain, our monocular visual-inertial tracking system can obtain continuous six degree of freedom (6-DoF) pose estimation without scale ambiguity. Our method requires neither fixed multi-camera nor depth sensor settings for scale observability, instead, the IMU inside the monocular sensing suite provides scale information for both camera itself and the tracked object. We build the proposed system on top of our monocular visual-inertial system (VINS) to obtain accurate state estimation of the monocular camera in the world frame. The whole system consists of a 2D object tracker, an object region-based visual bundle adjustment (BA), VINS and a correlation analysis-based metric scale estimator. Experimental comparisons with ground truth demonstrate the tracking accuracy of our 3D tracking performance while a mobile augmented reality (AR) demo shows the feasibility of potential applications.


Title: Predicting Out-of-View Feature Points for Model-Based Camera Pose Estimation
Key Words: cameras  feature extraction  inspection  learning (artificial intelligence)  mobile robots  object tracking  particle filtering (numerical methods)  pose estimation  recurrent neural nets  rich feature information  recurrent neural network architecture  network training  autonomous inspection robots  model-based tracking  input image  object feature points  deep learning  model-based camera pose estimation  out-of-view feature points  optimisation based tracker  Cameras  Heating systems  Feature extraction  Pose estimation  Computational modeling  Two dimensional displays  Predictive models 
Abstract: In this work we present a novel framework that uses deep learning to predict object feature points that are out-of-view in the input image. This system was developed with the application of model-based tracking in mind, particularly in the case of autonomous inspection robots, where only partial views of the object are available. Out-of-view prediction is enabled by applying scaling to the feature point labels during network training. This is combined with a recurrent neural network architecture designed to provide the final prediction layers with rich feature information from across the spatial extent of the input image. To show the versatility of these out-of-view predictions, we describe how to integrate them in both a particle filter tracker and an optimisation based tracker. To evaluate our work we compared our framework with one that predicts only points inside the image. We show that as the amount of the object in view decreases, being able to predict outside the image bounds adds robustness to the final pose estimation.


Title: FSG: A statistical approach to line detection via fast segments grouping
Key Words: feature extraction  image segmentation  robot vision  fast segments grouping  line segment detection algorithms  segment grouping methods  vanishing points detection  statistical approach  high level robot localization task  plausible line candidates  robust line detection algorithm  FSG  low textured scenes  visual robotic tasks  line extraction  Image segmentation  Probabilistic logic  Estimation  Simultaneous localization and mapping  Task analysis  Detection algorithms 
Abstract: Line extraction is a preliminary step in various visual robotic tasks performed in low textured scenes such as city and indoor settings. Several efficient line segment detection algorithms such as LSD and EDLines have recently emerged. However, the state of the art segment grouping methods are not robust enough or not amenable for detecting lines in real-time. In this paper we present FSG, a fast and robust line detection algorithm. It is based on two independent components. A proposer that greedily cluster segments suggesting plausible line candidates and a probabilistic model that decides if a group of segments is an actual line. In the experiments we show that our procedure is more robust and faster than the best methods in the literature and achieves state-of-the art performance in a high level robot localization task such as vanishing points detection.


Title: Optimized Contrast Enhancements to Improve Robustness of Visual Tracking in a SLAM Relocalisation Context
Key Words: cameras  feature extraction  image colour analysis  image enhancement  image representation  mobile robots  robot vision  SLAM (robots)  video signal processing  optimized contrast enhancements  visual tracking  SLAM relocalisation context  indirect SLAM techniques  robotics community  feature points  multilayered image representation  contrast enhanced version  tracking process  detection  matching  dynamic contrast enhancements  dynamic light changing conditions  ORB-SLAM  light changed condition  reference video  Mutual information  Lighting  Robustness  Simultaneous localization and mapping  Cameras  Entropy  Visualization 
Abstract: Robustness of indirect SLAM techniques to light changing conditions remains a central issue in the robotics community. With the change in the illumination of a scene, feature points are either not extracted properly due to low contrasts, or not matched due to large differences in descriptors. In this paper, we propose a multi-layered image representation (MLI) in which each layer holds a contrast enhanced version of the current image in the tracking process in order to improve detection and matching. We show how Mutual Information can be used to compute dynamic contrast enhancements on each layer. We demonstrate how this approach dramatically improves the robustness in dynamic light changing conditions on both synthetic and real environments compared to default ORB-SLAM. This work focalises on the specific case of SLAM relocalisation in which a first pass on a reference video constructs a map, and a second pass with a light changed condition relocalizes the camera in the map.


Title: Key-frame Selection for Multi-robot Simultaneous Localization and Tracking in Robot Soccer Field
Key Words: entropy  mobile robots  multi-robot systems  robot vision  SLAM (robots)  traditional key-frame selection algorithms  temporal relationship  spatial relationship  pre-defined field  information entropy  selection ratio  key-frames  localization results  robot soccer field  optical images  extensive computation resources  key-frame selection algorithm  multiple robots simultaneous localization  multirobot soccer games  Entropy  Robot sensing systems  Object detection  Sports  Cameras  Legged locomotion 
Abstract: Optical images provide rich features but require extensive computation resources to process for SLAM. When there are limited computation resources on the robots, it becomes a heavy burden to process the images in real-time. This paper presents the design and implementation of key-frame selection algorithm for multiple robots simultaneous localization and tracking on the multi-robot soccer games which have pre-defined field and objects. Compared to traditional key-frame selection algorithms, this work makes use of the temporal and spatial relationship among objects on the pre-defined field to compute the information entropy. The selection ratio can be adjusted by two parameters: entropy threshold and the maximum moving distance. The experimental results show that the developed method can effectively detect the change of scene using selected key-frames. And comparing with the localization results using all the images, using less than 20% of all images after walking 11,203mm it only increase up to 0.87% trajectory errors.


Title: LIPS: LiDAR-Inertial 3D Plane SLAM
Key Words: graph theory  image representation  mobile robots  optical radar  optimisation  robot vision  SLAM (robots)  inertial preintegratation measurement  LiDAR-inertial 3D plane SLAM  simultaneous localization and mapping  singularity free plane factor  closest point plane representation  Simultaneous localization and mapping  Three-dimensional displays  Laser radar  Optimization  Lips 
Abstract: This paper presents the formalization of the closest point plane representation and an analysis of its incorporation in 3D indoor simultaneous localization and mapping (SLAM). We present a singularity free plane factor leveraging the closest point plane representation, and demonstrate its fusion with inertial preintegratation measurements in a graph-based optimization framework. The resulting LiDAR-inertial 3D plane SLAM (LIPS) system is validated both on a custom made LiDAR simulator and on a real-world experiment.


Title: Scan Similarity-based Pose Graph Construction method for Graph SLAM
Key Words: graph theory  mobile robots  pose estimation  robot vision  SLAM (robots)  scan similarity-based pose graph construction method  constructed graph  loop closure detection method  real world dataset  benchmark dataset  odometry estimation process  error accumulation phenomenon  pose graph SLAM  scan similarity computation method  graph accuracy  high quality graph  Simultaneous localization and mapping  Lasers  Estimation  Heuristic algorithms  Optimization 
Abstract: Scan similarity-based pose graph construction method for graph SLAM is proposed. To perform delicate pose graph SLAM, front-end that constructs a graph as well as back-end that optimizes the constructed graph is an important task. Generally, there is an error accumulation phenomenon during the odometry estimation process. This paper focuses on the method of creating a high quality graph by suggesting ways to improve the graph accuracy since the accumulated errors in the graph might degrade the performance of the entire graph SLAM. We deal with one of our previous works, dynamic keyframe selection technique, based on scan similarity computation method more precisely and suggest a loop closure detection method by exploiting previously proposed 2-D laser scan descriptor. To verify objective performance of the proposed method, the experimental results of the odometry estimation are shown by using the benchmark dataset and the real world dataset. Additionally, results of the pose graph SLAM are shown for the real world dataset which include the loop clorues.


Title: Egocentric Spatial Memory
Key Words: learning (artificial intelligence)  mobile robots  neurophysiology  recurrent neural nets  robot vision  place recognition  robotic control  3D virtual mazes  deep learning based mapping system  ESM network  external memory  recurrent neural network  spatially extended environment  2D global maps  integrated deep neural network architecture  egocentric perspective  spatial information  memory system  egocentric spatial memory  Computer architecture  Cameras  Navigation  Microprocessors  Sensors  Task analysis  Motion measurement 
Abstract: Egocentric spatial memory (ESM) defines a memory system with encoding, storing, recognizing and recalling the spatial information about the environment from an egocentric perspective. We introduce an integrated deep neural network architecture for modeling ESM. It learns to estimate the occupancy state of the world and progressively construct top-down 2D global maps from egocentric views in a spatially extended environment. During the exploration, our proposed ESM model updates belief of the global map based on local observations using a recurrent neural network. It also augments the local mapping with a novel external memory to encode and store latent representations of the visited places over longterm exploration in large environments which enables agents to perform place recognition and hence, loop closure. Our proposed ESM network contributes in the following aspects: (1) without feature engineering, our model predicts free space based on egocentric views efficiently in an end-to-end manner; (2) different from other deep learning-based mapping system, ESMN deals with continuous actions and states which is vitally important for robotic control in real applications. In the experiments, we demonstrate its accurate and robust global mapping capacities in 3D virtual mazes and realistic indoor environments by comparing with several competitive baselines.


Title: Predicting Objective Function Change in Pose-Graph Optimization
Key Words: graph theory  optimisation  SLAM (robots)  outlier detection  robust online incremental SLAM applications  graph pruning  information-theoretic metrics  pose-graph optimization scheme  Linear programming  Optimization  Simultaneous localization and mapping  Measurement errors  Noise measurement  Reliability 
Abstract: Robust online incremental SLAM applications require metrics to evaluate the impact of current measurements. Despite its prevalence in graph pruning, information-theoretic metrics solely are insufficient to detect outliers. The optimal value of the objective function is a better choice to detect outliers but cannot be computed unless the problem is solved. In this paper, we show how the objective function change can be predicted in an incremental pose-graph optimization scheme, without actually solving the problem. The predicted objective function change can be used to guide online decisions or detect outliers. Experiments validate the accuracy of the predicted objective function, and an application to outlier detection is also provided, showing its advantages over M-estimators.


Title: Efficient Long-term Mapping in Dynamic Environments
Key Words: graph theory  mobile robots  robot vision  SLAM (robots)  mapping problem  longterm SLAM datasets  graph coherency  intra-session loop closure detections  out-dated nodes  graph complexity  nonstatic entities  merging procedure  efficient ICP-based alignment  up-to-date state  2D point cloud data  local maps  graph SLAM paradigm  multiple mapping sessions  single mapping sessions  SLAM system  autonomous robots  dynamic environments  long-term robot operation  Simultaneous localization and mapping  Cloud computing  Three-dimensional displays  Two dimensional displays  Merging  Optimization 
Abstract: As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.


Title: Localization of Classified Objects in SLAM using Nonparametric Statistics and Clustering
Key Words: feature extraction  learning (artificial intelligence)  mobile robots  nonparametric statistics  object detection  pattern clustering  robot vision  SLAM (robots)  statistical analysis  nonparametric statistical approach  data association  mapping process  object detection  machine learning  semantic information  nonparametric statistics  classified objects  locating objects  SLAM  unsupervised clustering method  detected objects  Simultaneous localization and mapping  Semantics  Object detection  Cameras  Three-dimensional displays 
Abstract: Traditional Simultaneous Localization and Mapping (SLAM) approaches build maps based on points, lines or planes. These maps visually resemble the environment but without any semantic or information about the objects in the environment. Recent advancements in machine learning have made object detection highly accurate and reliable with large set of objects. Object detection can effectively help SLAM to incorporate semantics in the mapping process. One of the main obstacles is data association between detected objects over time. We demonstrate a nonparametric statistical approach to solve the data association between detected objects over consecutive frames. Then we use an unsupervised clustering method to identify the existence of objects in the map. The complete process can be run in parallel with SLAM. The performance of our algorithm is demonstrated on several public datasets, which shows promising results in locating objects in SLAM.


Title: A distributed vision-based consensus model for aerial-robotic teams
Key Words: autonomous aerial vehicles  geometry  mobile robots  object detection  position control  robot vision  target tracking  target position  PID-controlled steering responses  autonomous aerial robots  aerial-robotic teams  distributed vision-based consensus model  noisy detections  steering commands  ego-centric view  geometric constraints  Robot kinematics  Robot sensing systems  Cameras  Task analysis  Noise measurement 
Abstract: We present a distributed model for a team of autonomous aerial robots to collaboratively track a target without external control. The model uses distributed consensus to coordinate actions and to maintain formation via geometric constraints. Each robot uses its ego-centric view of a target and the relative distance from its two closest neighbors to infer its steering commands. To account for noisy and missing target detections, the robots exchange their estimated target position and formation configuration through shared PID-controlled steering responses. We show that the proposed model enables the team to maintain the view of a maneuvering target with varying acceleration under noisy detections and failures up to situations when all robots but one lose the target from their field of view.


Title: Fast Kinodynamic Bipedal Locomotion Planning with Moving Obstacles
Key Words: collision avoidance  humanoid robots  legged locomotion  motion control  pendulums  robot dynamics  robot kinematics  wheels  moving obstacles  bipedal robot  complex environments  footstep planning algorithms  footstep locations  biped dynamics  temporal duration  dynamically consistent description  PSP  collision-free route  nonholonomic wheeled robots  kinematic constraints  bipedal motion  body dynamic walking behavior  3D physics-based simulation  linear inverted pendulum model dynamics  dynamic constraints  kinodynamic bipedal locomotion planning  sampling-based kino-dynamic planning  LIPM  phase space planner  steering method  Planning  Heuristic algorithms  Robot kinematics  Legged locomotion  Collision avoidance 
Abstract: In this paper, we present a sampling-based kino-dynamic planning framework for a bipedal robot in complex environments. Unlike other footstep planning algorithms which typically plan footstep locations and the biped dynamics in separate steps, we handle both simultaneously. Three primary advantages of this approach are (1) the ability to differentiate alternate routes while selecting footstep locations based on the temporal duration of the route as determined by the Linear Inverted Pendulum Model (LIPM) dynamics, (2) the ability to perform collision checking through time so that collisions with moving obstacles are prevented without avoiding their entire trajectory, and (3) the ability to specify a minimum forward velocity for the biped. To generate a dynamically consistent description of the walking behavior, we exploit the Phase Space Planner (PSP) [1] [2]. To plan a collision-free route toward the goal, we adapt planning strategies from non-holonomic wheeled robots to gather a sequence of inputs for the PSP. This allows us to efficiently approximate dynamic and kinematic constraints on bipedal motion, to apply a sampling-based planning algorithm such as RRT or RRT*, and to use the Dubin's path [3] as the steering method to connect two points in the configuration space. The results of the algorithm are sent to a Whole Body Controller [1] to generate full body dynamic walking behavior. Our planning algorithm is tested in a 3D physics-based simulation of the humanoid robot Valkyrie.


Title: Artificial Invariant Subspace for Humanoid Robot Balancing in Locomotion
Key Words: damping  feedback  humanoid robots  legged locomotion  motion control  nonlinear control systems  robot dynamics  stability  humanoid robots  biped robots  swing foot  damped harmonic oscillators  continuous feedback control  nominal walking cycle  rigid body dynamics  NAO robot  artificial invariant subspace  locomotion  compliant actuators  damping  nonlinear controller  robustness  bio-inspired legged robots  predictive foot stepping  asymptotic convergence  flat terrains  Legged locomotion  Foot  Humanoid robots  Orbits  Perturbation methods  Robustness 
Abstract: Legged robots that make use of compliant actuators have demonstrated greater robustness of locomotion than their rigid counterparts. Stiffness and damping are key parameters that characterize the adaptation to perturbations. In this work, by drawing inspirations from controllable compliance and damping in existing soft and bio-inspired legged robots, we propose an approach to design a nonlinear controller for the balancing of humanoid robots with rigid bodies. Existing literature has proposed simplified dynamical models of biped robots in order to predict the timing and placement of swing foot for walking without falling. We further employ the properties of invariance to perturbations in damped harmonic oscillators and formulate continuous feedback control in combination with predictive foot stepping in order to achieve continuous adaptive recoveries of the nominal walking cycle from unexpected physical disturbances. Our method allows asymptotic convergence of the rigid body dynamics to a subspace with the desired energy level. We demonstrate the robustness of the proposed algorithm base on extensive push recovery experiments on a NAO robot on flat terrains.


Title: Real-time Control of Whole-body Robot Motion and Trajectory Generation for Physiotherapeutic Juggling in VR
Key Words: brain  control engineering computing  diseases  humanoid robots  medical computing  medical robotics  motion control  neurophysiology  patient rehabilitation  patient treatment  quadratic programming  trajectory control  virtual reality  whole-body robot motion  trajectory generation  physiotherapeutic juggling  motor rehabilitation  functional motor impairments  cerebellar ataxia  Parkinson's disease  juggling physiotherapy  brain plasticity  physical strain  juggling games  throwing motions  whole-body motion  real-time architecture  controller device  VR setting  physiotherapeutic robotic juggling  real-time operation  physical robot  virtual reality  humanoid robot COMAN wrist  quadratic program  real-time control  Trajectory  Real-time systems  Robot kinematics  Task analysis  Medical treatment  Switches 
Abstract: Motor rehabilitation is in increasingly high demand to deal with minor functional motor impairments resulting from stroke, cerebellar ataxia, or Parkinson's disease. Juggling physiotherapy has shown to induce brain plasticity and to improve coordination and balance in this context. The physiotherapy, however, relies on large number of repetitions to be effective which prompts to deploy robots to release the burden on therapists both in terms of time as well as physical strain. This paper provides a framework to enable juggling games for patients in interacting with robots through Virtual Reality (VR). A set of throwing motions is recorded from the therapist and is retargeted to the humanoid robot COMAN's wrist. The respective whole-body motion is then solved in a stack of Quadratic Programs (QP) in a real-time architecture that integrates OROCOS and Gazebo. The resulting motion is finally streamed to VR for animation of the robot and the thrown ball, which the user can catch in VR using a controller device. We regard the VR setting as an essential step towards physiotherapeutic robotic juggling, because it ensures safety of the patients and effective testing of the methods and already has potential for actual therapeutic intervention. The control framework, however, is already validated in this paper for switching to full real-time operation on the physical robot.


Title: Deep Neural Object Analysis by Interactive Auditory Exploration with a Humanoid Robot
Key Words: audio signal processing  humanoid robots  neural net architecture  signal classification  signal denoising  deep neural object analysis  interactive auditory exploration  humanoid robot  interactive auditory object analysis  robot elicits sensory information  robotic ears  neural network architecture  audio signals  microphone  material classification  weight prediction  Robot sensing systems  Humanoid robots  Robot kinematics  Mel frequency cepstral coefficient  Microsoft Windows  Plastics 
Abstract: We present a novel approach for interactive auditory object analysis with a humanoid robot. The robot elicits sensory information by physically shaking visually indistinguishable plastic capsules. It gathers the resulting audio signals from microphones that are embedded into the robotic ears. A neural network architecture learns from these signals to analyze properties of the contents of the containers. Specifically, we evaluate the material classification and weight prediction accuracy and demonstrate that the framework is fairly robust to acoustic real-world noise.


Title: Cloud services for robotic nurses? Assessing legal and ethical issues in the use of cloud services for healthcare robots
Key Words: cloud computing  ethical aspects  health care  legislation  medical robotics  mobile robots  security of data  cyber- aspects  data protection requirements  data security  healthcare cloud robotics  ethical issues  legal issues  robotic nurses  Cloud computing  Medical services  Robot kinematics  Robot sensing systems  Law 
Abstract: This paper explores ethical and legal implications arising from the intertwinement of cloud services, healthcare and robotics. It closes an existing gap in the literature by highlighting the distinctive ethical and legal concerns associated with the inter-dependence of the cyber- and the physical aspects of healthcare cloud robotics. The identified core concerns include uncertainties with regard to data protection requirements; distributed responsibilities for unintended harm; achievement of transparency and consent for cloud robot services especially for vulnerable robot users; secondary uses of cloud data derived from robot activities; data security; and wider social issues. The paper aims to raise awareness and stimulate reflection of the legal and ethical impacts on different stakeholders arising from the use of cloud services in healthcare robotics. We show that due to the complexity of these concerns the design and implementation of such robots in healthcare requires an interdisciplinary development and impact assessment process. In light of legal requirements and ethical responsibilities towards end-users and other stakeholders, we draw practical considerations for engineers developing cloud services for robots in healthcare.


Title: Towards Norm Realization in Institutions Mediating Human-Robot Societies
Key Words: human-robot interaction  social sciences computing  human-robot societies  norm realization  social interactions  robotic systems  robotic language  human language  human society  social norms  Robot kinematics  Grounding  Art  Cognition  Decision making  Semantics 
Abstract: Social norms are the understandings that govern the behavior of members of a society. As such, they regulate communication, cooperation and other social interactions. Robots capable of reasoning about social norms are more likely to be recognized as an extension of our human society. However, norms stated in a form of the human language are inherently vague and abstract. This allows for applying norms in a variety of situations, but if the robots are to adhere to social norms, they must be capable of translating abstract norms to the robotic language. In this paper we use a notion of institution to realize social norms in real robotic systems. We illustrate our approach in a case study, where we translate abstract norms into concrete constraints on cooperative behaviors of humans and robots. We investigate the feasibility of our approach and quantitatively evaluate the performance of our framework in 30 real experiments with user-based evaluation with 40 participants.


Title: “Oh! I am so sorry!”: Understanding User Physiological Variation while Spoiling a Game Task
Key Words: computer games  human-robot interaction  psychology  Jenga game  galvanic skin response  psychological questionnaires  multiple GSR parameters  user physiological variation  game task  tower fall down  Poles and towers  Games  Collision avoidance  Physiology  Robot sensing systems 
Abstract: This paper investigates how individuals react in a situation when an experimenter (human or robot) either tells them to stop in the middle of playing the Jenga game, or accidentally bumps into a table and makes the tower fall down. The mood of the participants and different physiological parameters (i.e., galvanic skin response (GSR) and facial temperature variation) are extracted and analysed based on the condition, experimenter, and psychological questionnaires (i.e., TEQ, TEIQ, RST-PQ). This study was a between participants study with 23 participants. Our results show that multiple GSR parameters (e.g., latency, amplitude, number of peaks) differ significantly based on the condition and the experimenter the participants interacted with. The temperature variation in three regions of interest (i.e., forehead, left, and right periorbital regions) are good indicators of how ready an individual is to react in an unforeseen situation.


Title: An Extended Bayesian User Model (BUM) for Capturing Cultural Attributes with a Social Robot
Key Words: Bayes methods  belief networks  decision making  human-robot interaction  pattern classification  pattern clustering  service robots  user modelling  human-robot interaction  extended Bayesian User Model  social robotics  culture-awareness  specific subtleties  highly accurate classification framework  share similar attributes  n-dimensional semantic attribute space  capture unitary attributes  Bayesian classifiers  robotic technologies  latest advances  heterogeneous information  unified representation  cultural attributes  Robot sensing systems  Cultural differences  Bayes methods  Statistics  Indexes  Computational modeling  Culture Aware Social Robots  Robot Perception  Multimodal Human-Robot Interaction  User Models 
Abstract: In this work we propose a Bayesian User Model which is able capture a unified representation of cultural attributes from heterogeneous information in the context of Human-Robot Interaction. Despite the latest advances in robotic technologies, virtually no robots are able to cope with the specificities of the “modus vivendi” of different cultures. We start by proposing Bayesian classifiers to capture unitary attributes of different users, clustering them in a n-dimensional semantic attribute space, aggregating groups of persons that share similar attributes. Results show a highly accurate classification framework, both capable of detecting specific subtleties in user's properties, and generalizing them into representative profiles. We then discuss its application towards adapting the actions of a robot and its potential impact on culture-awareness, demonstrating how the proposed framework can enable culture-awareness, exploring this new frontier in social robotics.


Title: Culturally aware Planning and Execution of Robot Actions
Key Words: cultural aspects  mobile robots  path planning  robot actions  cultural group  cultural adaptation  interpersonal distance  robot plans generation  cultural preferences  CARESSES project  assistive robots  culturally aware planning  Cultural differences  Robot sensing systems  Planning  Knowledge based systems  Computer architecture  Cognition 
Abstract: The way in which humans behave, speak and interact is deeply influenced by their culture. For example, greeting is done differently in France, in Sweden or in Japan; and the average interpersonal distance changes from one cultural group to the other. In order to successfully coexist with humans, robots should also adapt their behavior to the culture, customs and manners of the persons they interact with. In this paper, we deal with an important ingredient of cultural adaptation: how to generate robot plans that respect given cultural preferences, and how to execute them in a way that is sensitive to those preferences. We present initial results in this direction in the context of the CARESSES project, a joint EU-Japan effort to build culturally competent assistive robots.


Title: Trait-based Culture and its Organization: Developing a Culture Enabler for Artificial Agents
Key Words: artificial intelligence  multi-agent systems  social sciences computing  software agents  trait-based culture  culture enabler  artificial agent  human interests  human culture  trait types  trait module  Cultural differences  Global communication  Organizations  Knowledge based systems  Standards organizations  Intelligent robots  Buildings 
Abstract: Artificial agents might not understand human interests and actions if these agents cannot anticipate how a person understands a situation and, based on this, what could be his/her expectations. In many cases, understanding, expectations and behaviors are constrained, if not driven, by culture. Can we provide human culture to an artificial agent? Can we provide formal representations of different cultures? In this paper we discuss the (elusive) notion of culture and propose an approach based on the notion of trait which, we argue, allows building formal modules suitable to represent culture (broadly understood). We distinguish the trait types (knowledge, rule, behavior, interpretation) that such modules should contain and briefly discuss how they could be organized. Finally, we exemplify the role of a trait module in the flow of information internal to an agent highlighting surprising potentialities.


Title: CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism
Key Words: cultural aspects  face recognition  human-robot interaction  learning (artificial intelligence)  medical disorders  medical robotics  paediatrics  patient treatment  deep learning model  cultural backgrounds  image data  target culture  multicultural data  child-dependent settings  across-culture evaluations  target task  deep architecture  robot-assisted autism therapy  video data  automated engagement estimation  deep learning models  neu-rotypical peers  autism spectrum  engagement intensity estimation  face images  cultural differences  individual differences  estimation performance  model learning  target children  target engagement levels  poor estimation  child-independent models  Face  Autism  Deep learning  Estimation  Cultural differences  Task analysis  Robots 
Abstract: Many children on autism spectrum have atypical behavioral expressions of engagement compared to their neu-rotypical peers. In this paper, we investigate the performance of deep learning models in the task of automated engagement estimation from face images of children with autism. Specifically, we use the video data of 30 children with different cultural backgrounds (Asia vs. Europe) recorded during a single session of a robot-assisted autism therapy. We perform a thorough evaluation of the proposed deep architectures for the target task, including within- and across-culture evaluations, as well as when using the child-independent and child-dependent settings. We also introduce a novel deep learning model, named CultureNet, which efficiently leverages the multi-cultural data when performing the adaptation of the proposed deep architecture to the target culture and child. We show that due to the highly heterogeneous nature of the image data of children with autism, the child-independent models lead to overall poor estimation of target engagement levels. On the other hand, when a small amount of data of target children is used to enhance the model learning, the estimation performance on the held-out data from those children increases significantly. This is the first time that the effects of individual and cultural differences in children with autism have empirically been studied in the context of deep learning performed directly from face images.


Title: Object Assembly Guidance in Child-Robot Interaction using RGB-D based 3D Tracking
Key Words: gesture recognition  human computer interaction  humanoid robots  human-robot interaction  image colour analysis  mobile robots  object detection  object recognition  object tracking  particle filtering (numerical methods)  verbal response  3D object tracking algorithm  RGB-D data  object assembly task  autonomous humanoid robot  RGB-D based 3D  object assembly guidance  resulting Child-Robot Interaction scenario  assembly state estimation  gestural response  assembly part  degrees-of-freedom  depth data stream  particle filter  image plane  color stream  tracking-by-detection scheme  Three-dimensional displays  Task analysis  Robotic assembly  Robot kinematics  Tracking  Streaming media 
Abstract: This work examines how and to what benefit an autonomous humanoid robot can supervise a child in an object assembly task. In order to understand the child's actions, a novel 3D object tracking algorithm for RGB-D data is employed. The tracker consists of two stages: the first performs a tracking-by-detection scheme on the color stream, to locate the objects on the image plane, while the second uses a particle filter that operates on the depth data stream to refine the first stage output and infer the objects' rotations. Given the six degrees-of-freedom of the assembly part poses, the system is able to recognize which connections have been completed at any given time. This information is then used to select an appropriate verbal or gestural response for the robot. Experimental results show that (a) the tracking algorithm is accurate, fast and robust to severe occlusions and fast movements, (b) the proposed method of assembly state estimation is indeed effective, and (c) the resulting Child-Robot Interaction scenario is educational and enjoyable for the children involved.


Title: Reachset Conformance of Forward Dynamic Models for the Formal Analysis of Robots
Key Words: control engineering computing  human-robot interaction  program testing  reachability analysis  safety-critical software  human-robot co-existence scenario  robots  formal analysis  forward dynamic models  reachset conformance  reachability analysis  robotic models  model-based testing  safety-critical applications  classical robotic applications  design flaws  robotic systems  model-based design  Friction  Uncertainty  Manipulators  Mathematical model  Computational modeling  Robot sensing systems 
Abstract: Model-based design of robotic systems has many advantages, among them faster development cycles and reduced costs due to early detections of design flaws. Approximate models are sufficient for many classical robotic applications; however, they no longer suffice for safety-critical applications. For instance, a dangerous situation which has not been detected by model-based testing might occur in a human-robot co-existence scenario since models do not exactly replicate behaviors of real systems-this problem arises no matter how accurate a model is, since even disturbances and sensor noise can cause a mismatch. We address this issue by adding non-determinism to robotic models and by computing the whole set of possible behaviors using reachability analysis. By using reachset conformance, we automatically adjust the required non-determinism so that all recorded behaviors are captured. For the first time this approach is demonstrated for a real robot.


Title: Timestamp Offset Calibration for an IMU-Camera System Under Interval Uncertainty
Key Words: calibration  cameras  data acquisition  inertial systems  measurement uncertainty  time measurement  orientation estimation determination  data acqusition  sensors  robotics applications  IMU-camera system  timestamp offset calibration  calibration data  bounded-error approach  interval uncertainty  time 20.0 ms  Cameras  Calibration  Uncertainty  Sensor fusion  Electron tubes  Sensor systems 
Abstract: To properly fuse IMU and camera information for robotics applications, the relative timestamp offset between both sensors' data streams has to be considered. However, finding the exact timestamp offset is often impossible. Thus, it is necessary to additionally consider the offset's uncertainty if we want to produce reliable results. In order to find the offset and its uncertainty, we determine orientation estimates from IMU and camera under interval uncertainty. Subsequently, these intervals are used as a common representation for our bounded-error approach that finds an interval enclosing the true offset while also modeling the uncertainty. Calibration data can be acquired in a few seconds using a simple setup of IMU, camera and camera target. Results using both simulated and real data demonstrate that we are able to determine the offset to an accuracy of 20 ms with a computation time that is suitable for future online applications. Here, our approach could be used to monitor the timestamp offset in a guaranteed way. Additionally, our method can be adapted to determine an interval for the rotation between both sensors. While this increases the computation time drastically, it also enhances the accuracy of the timestamp offset to less than 10 ms.


Title: Fast and Accurate Semantic Mapping through Geometric-based Incremental Segmentation
Key Words: image segmentation  probability  SLAM (robots)  stereo image processing  SLAM framework  NYUv2 dataset  computational efficiency  frame-wise segmentation result  computationally intensive stages  segmentation label  updating class probabilities  processing components  geometric-based segmentation method  geometric-based incremental segmentation  Semantics  Three-dimensional displays  Image segmentation  Simultaneous localization and mapping  Cameras  Real-time systems  Two dimensional displays 
Abstract: We propose an efficient and scalable method for incrementally building a dense, semantically annotated 3D map in real-time. The proposed method assigns class probabilities to each region, not each element (e.g., surfel and voxel), of the 3D map which is built up through a robust SLAM framework and incrementally segmented with a geometric-based segmentation method. Differently from all other approaches, our method has a capability of running at over 30Hz while performing all processing components, including SLAM, segmentation, 2D recognition, and updating class probabilities of each segmentation label at every incoming frame, thanks to the high efficiency that characterizes the computationally intensive stages of our framework. By utilizing a specifically designed CNN to improve the frame-wise segmentation result, we can also achieve high accuracy. We validate our method on the NYUv2 dataset by comparing with the state of the art in terms of accuracy and computational efficiency, and by means of an analysis in terms of time and space complexity.


Title: Semantic Monocular SLAM for Highly Dynamic Environments
Key Words: cameras  feature extraction  image motion analysis  image sequences  mobile robots  object detection  object tracking  pose estimation  probability  robot vision  SLAM (robots)  static environment  semantic monocular SLAM framework  semantic information  explicit probabilistic model  dynamic environments  Virtual KITTI  Synthia datasets  pose estimation  Semantics  Simultaneous localization and mapping  Feature extraction  Dynamics  Cameras  Pose estimation  Probabilistic logic 
Abstract: Recent advances in monocular SLAM have enabled real-time capable systems which run robustly under the assumption of a static environment, but fail in presence of dynamic scene changes and motion, since they lack an explicit dynamic outlier handling. We propose a semantic monocular SLAM framework designed to deal with highly dynamic environments, combining feature-based and direct approaches to achieve robustness under challenging conditions. The proposed approach exploits semantic information extracted from the scene within an explicit probabilistic model, which maximizes the probability for both tracking and mapping to rely on those scene parts that do not present a relative motion with respect to the camera. We show more stable pose estimation in dynamic environments and comparable performance to the state of the art on static sequences on the Virtual KITTI and Synthia datasets.


Title: Path-Following through Control Funnel Functions
Key Words: control system synthesis  feedback  learning (artificial intelligence)  mobile robots  motion control  road vehicles  robot dynamics  robust control  trajectory control  vehicle dynamics  control feedback laws  control funnel functions  path following  reference trajectory  autonomous vehicles  robustness  timing law  mathematical model  vehicle dynamics  demonstration-based learning algorithm  autonomous vehicle  Parkour car  trajectory tracking  Trajectory  Robustness  Autonomous vehicles  Timing  Vehicle dynamics  Automobiles  Trajectory tracking 
Abstract: We present an approach to path following using so-called control funnel functions. Synthesizing controllers to “robustly” follow a reference trajectory is a fundamental problem for autonomous vehicles. Robustness, in this context, requires our controllers to handle a specified amount of deviation from the desired trajectory. Our approach considers a timing law that describes how fast to move along a given reference trajectory and a control feedback law for reducing deviations from the reference. We synthesize both feedback laws using “control funnel functions” that jointly encode the control law as well as its correctness argument over a mathematical model of the vehicle dynamics. We adapt a previously described demonstration-based learning algorithm to synthesize a control funnel function as well as the associated feedback law. We implement this law on top of a 1/8th scale autonomous vehicle called the Parkour car. We compare the performance of our path following approach against a trajectory tracking approach by specifying trajectories of varying lengths and curvatures. Our experiments demonstrate the improved robustness obtained from the use of control funnel functions.


Title: Online inference of human belief for cooperative robots
Key Words: belief networks  cognition  cognitive systems  cooperative systems  human-robot interaction  inference mechanisms  interactive systems  mobile robots  multi-robot systems  online inference  natural interaction  human-human cooperation  model-based belief filter  human action  cognitive processes  perception  action selection  double inference process  environmental state  human-robot cooperation experiment  situation awareness  cognitive states  Task analysis  Robots  Manufacturing  Collaboration  Probability distribution  Estimation  Mathematical model 
Abstract: For human-robot cooperation, inferring a hu-man's cognitive state is very important for an efficient and natural interaction. Similar to human-human cooperation, understanding what the partner plans and knowing, if he is situation aware, is necessary to prevent collisions, offer support at the right time, correct mistakes before they happen or choose the best actions for oneself as early as possible. We propose a model-based belief filter to extract relevant aspects of a human's mental state online during cooperation. It performs inference based on human actions and its own task knowledge, modeling cognitive processes like perception and action selection. In contrast to most prior work, we explicitly estimate the human belief instead of inferring only a single mode or intention. Since this is a double inference process, we focus on representing the human estimates of environmental state and task as well as corresponding uncertainties. We designed a human-robot cooperation experiment that allowed for a variety of cognitive states of both agents and collected data to test and evaluate the proposed belief filter. The results are promising, as our system can be used to provide reasonable predictions of the human action and insights into his situation awareness. At the same time it is inferring interpretable information about the underlying cognitive states - A belief about the human's belief about the environment.


Title: An Omnidirectional Jumper with Expanded Movability via Steering, Self-Righting and Take-off Angle Adjustment
Key Words: biomechanics  mobile robots  steering shares  modified active triggering mechanism  jumping performance  expanded locomotion capabilities  angle adjustment  self-righting  expanded movability  omnidirectional jumper  Robots  Couplings  Gears  Windings  Pulleys  Wheels  Energy storage 
Abstract: In this paper, we propose an omnidirectional jumper with expanded locomotion capabilities. The mechanisms for four functions-jumping, steering, self-righting and take-off angle adjustment-are designed using only two motors to maximize the jumping performance. Jumping uses the modified active triggering mechanism with one motor. Steering shares this motor and uses the wheel touching the ground. The take-off angle is adjusted by changing the angle between the body and the foot using another motor. Self-righting is possible by utilizing combinations of the movements that occur in the energy storing and angle adjustment processes. With these four functions, the robot is capable of jumping in all directions and can jump anywhere in between the maximum height and maximum distance. It can also jump multiple times by self-righting. The robot, with a mass of 64.4 g, jumps up to 113 cm in vertical height, and 170 cm in horizontal distance. This robot can be deployed to explore various environments. Moreover, the design method to implement more functions than the number of motors can be applied to design other small-scale robots.


Title: Delineating boundaries of feasibility between robot designs
Key Words: decision trees  learning (artificial intelligence)  mobile robots  pattern classification  planning (artificial intelligence)  sensors  actuators  classic search methods  planning problem  actuator resources  effective robots  robot designs  delineating boundaries  domain knowledge  design space  interactive tools  interactive process  boundary subject  compact implicit representation  decision tree learning method  discriminatory features  Robot sensing systems  Planning  Actuators  Task analysis  Tools  Decision trees 
Abstract: Motivated by the need for tools to aid in the design of effective robots, we examine how to determine the role that particular sensing and actuator resources play in enabling a robot to achieve useful ends. Rather than merely asking “will this sensor suffice?” we classify general modifications to the set of sensors and actuators based on the feasibility of accomplishing given tasks using these sets. The goal is to probe the boundary between modifications that are destructive on a given planning problem, and modifications that are not. Since this boundary itself can be impractically large, classic search methods are of no avail to summarize discriminatory features on this boundary. Instead, we propose a decision tree learning method to efficiently construct a compact implicit representation of the boundary. The idea is to allow the designer to use prior knowledge to constrain the search, then use the tool to probe the boundary subject to those constraints, gaining insight into the information necessary for a robot to ensure task achievement. Ultimately we envision a interactive process where additional constraints are repeatedly included as new light is shed. We aim to pave the way for interactive tools that help the roboticist navigate the complexities of the design space. We describe an implementation of this approach along with experimental results that show that the method can construct decision trees with explanatory value. Our experiments suggest that some domain knowledge (specifically picking features that emphasize monotonicity) substantially improves running-time with only negligible reduction in accuracy.


Title: Discrete Configuration Space Methods for Determining Modular Connector Area of Acceptance in Higher Dimensions
Key Words: collision avoidance  discrete systems  mobile robots  discrete configuration space methods  physical connectors  docking process  robotic control systems  automatic control systems  robotic self-reconfiguration  air-to-air refueling  configuration space obstacle model  modular connector area of acceptance  self-aligning geometry  Meyer's flooding algorithm  Connectors  Geometry  Robots  Contacts  Three-dimensional displays  Two dimensional displays  Image segmentation 
Abstract: Physical connectors with self-aligning geometry aid in the docking process for many robotic and automatic control systems such as robotic self-reconfiguration and air-to-air refueling. This self-aligning geometry provides a wider range of acceptable error tolerance in relative pose between the two rigid objects, increasing successful docking chances. We present a new method for computing the error range (or area of acceptance) for a pair of rigid connector objects with self-aligning geometry capable of higher dimensional analysis which was previously limited to three. The method is based on the configuration space obstacle model, which gives us a representation of the space of contact states between the two objects. Using an approach direction as analogous to gravity, and assuming the target docked configuration is stable, the set of misaligned points that lead to docking is the target configuration's watershed for an arbitrarily dimensioned configuration space obstacle. It is well known that the watershed of a height map on a discrete grid can be found using any number of algorithms from image segmentation. We present an implementation based on Meyer's flooding algorithm to determine this watershed and measure the AA for simple connectors in 2D and 3D. Results are presented for systems including unconstrained motion in SE(2) and motion constrained to four dimensions (ie. x,y,z,pitch) in SE(3).


Title: An Origami-Inspired Flexible Pneumatic Actuator
Key Words: architecture  hinges  mechanical testing  plates (structures)  pneumatic actuators  prototypes  rapid prototyping (industrial)  shear modulus  three-dimensional printing  prototype  origami-inspired flexible pneumatic actuator design  multimaterial additive manufacturing process  mechanical testing  airtight chamber  flexible origami-inspired architecture  short stroke displacements  material resistance  flexible hinges  rigid plates  Actuators  Geometry  Prototypes  Shape  Soft robotics  Three-dimensional printing 
Abstract: This paper presents a new actuator designed to produce forces under short stroke displacements. Two variants of the prototype have been manufactured using Multi-Material Additive Manufacturing process, based on a flexible origami-inspired architecture. The structure consists of an airtight chamber constituted by rigid plates combined with flexible hinges and surfaces in order to allow the generation of motion. We propose several insights on integration issues such as limited material resistance and maximum range of motion. Both versions of the prototype are then tested to assess their performances for single strokes and cyclic loading.


Title: Design and Development of Biaxial Active Nozzle with Flexible Flow Channel for Air Floating Active Scope Camera
Key Words: buckling  cameras  deformation  design engineering  jets  mobile robots  motion control  nozzles  pneumatic actuators  position control  service robots  shapes (structures)  flexible robot  shape deformation  air floating active scope camera  pneumatic actuators  geometric parameters  ASC  rescue operations  reaction force direction  flexible air tube  air jet direction  head motion  flexible flow channel  biaxial active nozzle  Electron tubes  Robots  Force  Shape  Cameras  Strain  Pneumatic systems 
Abstract: Long flexible continuum robots have a high potential for search and rescue operations that explore deep layered debris. A general problem of these robots is in the control of the head motion because their thin bodies limit the space available to mount multiple actuators. This paper develops a biaxial active nozzle which can rotate the air jet direction along a roll and pitch axis in order to control the direction of reaction force and the head motion of a long flexible robot. A major challenge is how to change the air jet direction without a large resistance to the flow, which reduces the reaction force induced by the air jet. We propose a nozzle whose outlet is connected with a flexible air tube. The direction of the air jet is controlled by the smooth shape deformation of the tube. The nozzle should be compact enough to be installed on a thin robot, although the shape deformation of the tube may cause buckling. The flexible tube is modeled and simulated by a multiple link model used to derive the geometric parameters of the nozzle so that the nozzle is compact and the tube does not buckle. Based on the derived parameters, the biaxial active nozzle was developed. A basic performance experiment shows that the nozzle can change the reaction force direction by deforming the tube shape, while the magnitude of the reaction force is almost constant. We integrated the proposed nozzle with a conventional Active Scope Camera (ASC). The range where the robot can look around in a vertical exploration was significantly improved, which was three times larger than the previous ASC whose head was controlled by pneumatic actuators. The rubble field test demonstrates that the integrated ASC could move over rubble (maximum height of 200 mm) and steer the course.


Title: Auxetic Sleeves for Soft Actuators with Kinematically Varied Surfaces
Key Words: actuators  auxetics  bending  Poisson ratio  prototypes  robot kinematics  radial expansion  bending  prototypes  auxetic sleeves  representative auxetic element  kinematic model  Poisson's ratio  RAE-based design scheme  RAE-patterned actuators  soft robots  soft actuator  Actuators  Auxetic materials  Kinematics  Finite element analysis  Shape  Strain  Stress 
Abstract: Soft actuators with auxetic, or negative Poisson's ratio (NPR), behavior offer a way to create soft robots with novel kinematic behavior. This paper presents an original framework for reinforcement of a soft actuator using a generalized NPR element, called a Representative Auxetic Element (RAE), and an experimental validation of the kinematic behavior that it enables. We build a generalized kinematic model that enables the design of RAE-patterned actuators and reveal the distinct auxetic behavior of RAE actuators with comparable model accuracy to the legacy McKibben actuators. A simple, reproducible way of designing and fabricating RAE actuators is described and varied prototypes are shown. This RAE-based design scheme can be used to create actuators with specified kinematics like bending, extension, and radial expansion, which can also vary across the actuator's surface both circumferentially and axially in a tractable, scalable manner.


Title: A Unified Controller for Region-reaching and Deforming of Soft Objects
Key Words: cameras  closed loop systems  deformation  end effectors  manipulators  mobile robots  robot vision  stability  uncertain deformation model  active deformable object manipulation  unified controller  soft objects  robotic manipulation  robot control  region reaching  region deforming  uncalibrated cameras  closed-loop system stability  end-effector  Strain  Deformable models  Cameras  End effectors  Robot vision systems  Adaptation models 
Abstract: Emerging applications of robotic manipulation of deformable objects have opened up new challenges in robot control. While several control techniques have been developed to manipulate deformable objects, the performance of existing methods is commonly limited by two issues: 1) implicit assumption that the physical contact between the end-effector and the object is always maintained, and 2) requirements of exact parameters of deformation model, which are difficult to obtain. This paper presents a new control scheme for robotic manipulation of deformable objects, which allows the robot to automatically contact then actively deform the deformable object by assessing the status of deformation in real time. Instead of designing multiple controllers and switching among them, the proposed method smoothly and stably integrates two control phases (i.e. region reaching and active deforming) into a single controller. The stability of the closed-loop system is rigorously proved with the consideration of the uncertain deformation model and uncalibrated cameras. Hence, the proposed control scheme enhances the autonomous capability of active deformable object manipulation. Experimental studies are conducted with different initial conditions to demonstrate the performance of the proposed controller.


Title: Dual-arm robotic manipulation of flexible cables
Key Words: cables (mechanical)  deformation  Fourier series  manipulator dynamics  manipulators  mobile robots  multi-robot systems  position control  velocity control  arm robotic manipulation  flexible cables  trivial task  multiple robot manipulators  local deformation model  shape parameters  dual-arm manipulator  cable shape manipulation  Shape  Strain  Power cables  Deformable models  Manipulators  Task analysis 
Abstract: Deforming a cable to a desired (reachable) shape is a trivial task for a human to do without even knowing the internal dynamics of the cable. This paper proposes a framework for cable shapes manipulation with multiple robot manipulators. The shape is parameterized by a Fourier series. A local deformation model of the cable is estimated on-line with the shape parameters. Using the deformation model, a velocity control law is applied on the robot to deform the cable into the desired shape. Experiments on a dual-arm manipulator are conducted to validate the framework.


Title: Towards vision-based manipulation of plastic materials
Key Words: deformation  manipulators  object tracking  plastic products  robot vision  vision-based manipulation  plastic materials  object deformation  visual tracking  visual error  deformable objects  kinetic sand shaping  Task analysis  Robots  Shape  Plastics  Visualization  Deformable models  Strain  Manipulation  visual servoing  human studies  learning 
Abstract: This paper represents a step towards vision-based manipulation of plastic materials. Manipulating deformable objects is made challenging by: 1) the absence of a model for the object deformation, 2) the inherent difficulty of visual tracking of deformable objects, 3) the difficulty in defining a visual error and 4) the difficulty in generating control inputs to minimise the visual error. We propose a novel representation of the task of manipulating deformable objects. In this preliminary case study, the shaping of kinetic sand, we assume a finite set of actions: pushing, tapping and incising. We consider that these action types affect only a subset of the state, i.e., their effect does not affect the entire state of the system (specialized actions). We report the results of a user study to validate these hypotheses and release the recorded dataset. The actions (pushing, tapping and incising) are clearly adopted during the task, although it is clear that 1) participants use also mixed actions and 2) actions' effects can marginally affect the entire state, requesting a relaxation of our specialized actions hypothesis. Moreover, we compute task errors and corresponding control inputs (in the image space) using image processing. Finally, we show how machine learning can be applied to infer the mapping from error to action on the data extracted from the user study.


Title: Online Shape Estimation based on Tactile Sensing and Deformation Modeling for Robot Manipulation
Key Words: dexterous manipulators  force control  image sensors  tactile sensors  deformation model  tactile sensor  deformable object  sensor model  online shape estimation  tactile sensing  deformation modeling  visual sensing  soft object  robot manipulation  shadow dexterous hand  BioTac sensors  RGB-D sensor  Strain  Robot sensing systems  Deformable models  Force  Shape  Computational modeling 
Abstract: Precise robot manipulation of deformable objects requires an accurate and fast estimation of their shape as they deform. So far, visual sensing has been mostly used to solve this issue, but vision sensors are sensitive to occlusions, which might be inevitable when manipulating an object with robot. To address this issue, we present a modular pipeline to track the shape of a soft object in an online manner by coupling tactile sensing with a deformation model. Using a model of a tactile sensor, we compute the magnitude and location of a contact force and apply it as an external force to the deformation model. The deformation model then updates the nodal positions of a mesh that describes the shape of the deformable object. The proposed sensor model and pipeline, are evaluated using a Shadow Dexterous Hand equipped with BioTac sensors on its fingertips and an RGB-D sensor.


Title: Accounting for Directional Rigidity and Constraints in Control for Manipulation of Deformable Objects without Physical Simulation
Key Words: biomechanics  collision avoidance  deformation  finite element analysis  grippers  motion control  physiological models  shear modulus  springs (mechanical)  stress analysis  directional rigidity  deformable objects  physical simulation  physical models  control loop  practical controller  deformable object manipulation  effective controller  accurate geometric model  gripper motion  novel stretching avoidance constraint  physical robot  Grippers  Deformable models  Computational modeling  Robots  Predictive models  Finite element analysis  Adaptation models 
Abstract: Deformable objects like cloth and rope are challenging to manipulate because it is difficult to predict the state of the object given a motion of the gripper(s) holding it. In much previous work, physical models (such as Mass-Spring or Finite-Element) have been used to model such affects. However, these models often require significant parameter tuning for each scenario and can be expensive to simulate inside a control loop. Furthermore, it is difficult to create a practical controller for deformable object manipulation that preserves constraints, especially avoiding overstretching the object. In this paper, we developed a more effective controller than previous work by (1) constructing a more accurate geometric model of how the direction of gripper motion and obstacles affect deformable objects; and (2) specifying a novel stretching avoidance constraint to prevent the object from being overstretched by the robot. Experiments comparing our new method to the previous method in simulation and on a physical robot suggest that our new model captures the behavior of the object more accurately. We also find that our controller is able to prevent tearing that would occur when using the previous method.


Title: A Series Elastic Tactile Sensing Array for Tactile Exploration of Deformable and Rigid Objects
Key Words: elasticity  manipulators  position control  tactile sensors  deformable objects  rigid objects  series elastic elements  sixteen compliant sensing elements  position-controlled robot manipulator  series elastic tactile array  contact location  tactile arrays  multiple sensing elements  vision-based sensors  robotic systems  tactile sensing arrays  tactile exploration  series elastic tactile sensing array  Magnetic sensors  Pins  Tactile sensors  Saturation magnetization 
Abstract: Tactile sensing arrays are used to detect contacts of robotic systems with the environment. They are particularly useful for scenarios in which vision-based sensors cannot be used. Thanks to the presence of multiple sensing elements, tactile arrays also provide spatial information about the contact location. In this work, we present our series elastic tactile array to enable tactile exploration for position-controlled robot manipulators. Sixteen compliant sensing elements are arranged as a 4×4 array. This allows the position-controlled robot to explore objects via palpation. Tactile sensing was accomplished by measuring the change of the magnetic field caused by neodymium magnets embedded into the series elastic elements. We demonstrate the efficacy of our sensor with two sets of experiments involving physical interaction scenarios. Firstly, we show that the sensor can be used to differentiate between rigid and deformable objects. Secondly, we show that point clouds of objects can be generated quickly with our sensor module attached to a position-controlled robot manipulator as an end-effector.


Title: Learning Symbolic Representations for Planning with Parameterized Skills
Key Words: control engineering computing  humanoid robots  intelligent robots  learning (artificial intelligence)  manipulators  critical capability  generally intelligent robot behavior  goal-directed planning  black-box motor skills  intelligent robots  parametrized motor skills  simple discrete abstract representation  fixed plan  abstract symbolic representation  robot manipulation task  angry birds  virtual domain  Planning  Task analysis  Probabilistic logic  Intelligent robots  Birds  Computer science 
Abstract: A critical capability required for generally intelligent robot behavior is the ability to sequence motor skills to reach a goal. This requires a (typically abstract) representation that supports goal-directed planning, which raises the question of how to construct such a representation. Previous work has addressed this question in the context of simple black-box motor skills, which are insufficiently flexible to support the wide range of behavior required of intelligent robots. We now extend that work to include parametrized motor skills, where a robot must both select an action to execute and also decide how to parametrize it. We show how to construct a representation suitable for planning with parametrized motor skills, and specify conditions which are sufficient to separate the selection of motor skills from the parametrization of those skills. Our method results in a simple discrete abstract representation for planning followed by a parameter selection process that operates on a fixed plan. We first demonstrate learning this representation in a virtual domain based on Angry Birds and then learn an abstract symbolic representation for a robot manipulation task.


Title: Regularizing Reinforcement Learning with State Abstraction
Key Words: learning (artificial intelligence)  optimisation  pattern clustering  deep reinforcement learning performance  optimal sub-policies  state space clustering  hierarchical reinforcement learning algorithm  near-optimal policy  state cluster  abstract state  continuous action reinforcement learning  similar optimal action  discrete reinforcement  state abstraction  learned policy  Reinforcement learning  Complexity theory  Convergence  Shape  Clustering algorithms  Task analysis  Partitioning algorithms 
Abstract: State abstraction in a discrete reinforcement learning setting clusters states sharing a similar optimal action to yield an easier to solve decision process. In this paper, we generalize the concept of state abstraction to continuous action reinforcement learning by defining an abstract state as a state cluster over which a near-optimal policy of simple shape exists. We propose a hierarchical reinforcement learning algorithm that is able to simultaneously find the state space clustering and the optimal sub-policies in each cluster. The main advantage of the proposed framework is to provide a straightforward way of regularizing reinforcement learning by controlling the behavioral complexity of the learned policy. We apply our algorithm on several benchmark tasks and a robot tactile manipulation task and show that we can match state-of-the-art deep reinforcement learning performance by combining a small number of linear policies.


Title: CReaM: Condensed Real-time Models for Depth Prediction using Convolutional Neural Networks
Key Words: convolutional neural nets  image classification  image segmentation  mobile robots  neurocontrollers  robot vision  CNNs  robotic vision community  semantic segmentation  surface curvature  robotic society  real-time structure prediction framework  NVIDIA-TX2  CReaM  real-time models  depth prediction  convolutional neural networks  classification  mobile platform  condensed model architectures  Real-time systems  Predictive models  Robots  Training  Modeling  Task analysis  Semantics 
Abstract: Since the resurgence of CNNs the robotic vision community has developed a range of algorithms that perform classification, semantic segmentation and structure prediction (depths, normals, surface curvature) using neural networks. While some of these models achieve state-of-the art results and super human level performance, deploying these models in a time critical robotic environment remains an ongoing challenge. Real-time frameworks are of paramount importance to build a robotic society where humans and robots integrate seamlessly. To this end, we present a novel real-time structure prediction framework that predicts depth at 30 frames per second on an NVIDIA-TX2. At the time of writing, this is the first piece of work to showcase such a capability on a mobile platform. We also demonstrate with extensive experiments that neural networks with very large model capacities can be leveraged in order to train accurate condensed model architectures in a “from teacher to student” style knowledge transfer.


Title: Generating Adaptive Attending Behaviors using User State Classification and Deep Reinforcement Learning
Key Words: behavioural sciences computing  gradient methods  learning (artificial intelligence)  mobile robots  pattern classification  deep deterministic policy gradient  user state classification  deep reinforcement learning  user information  adaptive attending behavior generation  DDPG  mobile robots  Legged locomotion  Reinforcement learning  Two dimensional displays  Cameras  Acceleration  Robot sensing systems 
Abstract: This paper describes a method of generating attending behaviors adaptively to the user state. The method classifies the user state based on user information such as the relative position and the orientation. For each classified state, the method executes the corresponding policy for behavior generation, which has been trained using a deep reinforcement learning, namely DDPG (deep deterministic policy gradient). We use as a state space of DDPG a distance-transformed local map with person information, and define reward functions suitable for respective user states. We conducted attending experiments both in a simulated and a real environment to show the effectiveness of the proposed method.


Title: A Bio-inspired Reinforcement Learning Rule to Optimise Dynamical Neural Networks for Robot Control
Key Words: humanoid robots  learning (artificial intelligence)  legged locomotion  motion control  neurocontrollers  recurrent neural nets  back-propagation  2D bipedal walking simulation  biological neural circuits  robot control  optimise dynamical neural networks  bio-inspired reinforcement  bio-inspired central pattern generator layer  recurrent neural network  learning rule  network weights  biological synapses  reinforcement learning approach  Neurons  Robots  Synapses  Oscillators  Task analysis  Biological neural networks 
Abstract: Most approaches for optimisation of neural networks are based on variants of back-propagation. This requires the network to be time invariant and differentiable; neural networks with dynamics are thus generally outside the scope of these methods. Biological neural circuits are highly dynamic yet clearly able to support learning. We propose a reinforcement learning approach inspired by the mechanisms and dynamics of biological synapses. The network weights undergo spontaneous fluctuations, and a reward signal modulates the centre and amplitude of fluctuations to converge to a desired network behaviour. We test the new learning rule on a 2D bipedal walking simulation, using a control system that combines a recurrent neural network, a bio-inspired central pattern generator layer and proportional-integral control, and demonstrate the first successful solution to this benchmark task.


Title: Teaching Robots to Predict Human Motion
Key Words: human-robot interaction  image motion analysis  learning (artificial intelligence)  pose estimation  robot vision  deep learning  superior prediction performance  human moves  human motion  teaching robots  motion GAN model  predicted sequence  generative adversarial networks  forecasting algorithms  high-level fidelity validation  motion predictor  historical sequence  OpenPose library  robot camera  computer vision techniques  prediction ability  human-robot interaction  historical human movements  Robots  Gallium nitride  Generative adversarial networks  Predictive models  Cameras  Skeleton  Decoding 
Abstract: Teaching a robot to predict and mimic how a human moves or acts in the near future by observing a series of historical human movements is a crucial first step in human-robot interaction and collaboration. In this paper, we instrument a robot with such a prediction ability by leveraging recent deep learning and computer vision techniques. First, our system takes images from the robot camera as input to produce the corresponding human skeleton based on real-time human pose estimation obtained with the OpenPose library. Then, conditioning on this historical sequence, the robot forecasts plausible motion through a motion predictor, generating a corresponding demonstration. Because of a lack of high-level fidelity validation, existing forecasting algorithms suffer from error accumulation and inaccurate prediction. Inspired by generative adversarial networks (GANs), we introduce a global discriminator that examines whether the predicted sequence is smooth and realistic. Our resulting motion GAN model achieves superior prediction performance to state-of-the-art approaches when evaluated on the standard H3.6M dataset. Based on this motion GAN model, the robot demonstrates its ability to replay the predicted motion in a human-like manner when interacting with a person.


Title: Variational Autoencoder for End-to-End Control of Autonomous Driving with Novelty Detection and Training De-biasing
Key Words: learning (artificial intelligence)  neural nets  traffic engineering computing  variational autoencoder  end-to-end control  autonomous driving  novelty detection  end-to-end training  deep neural networks  DNN training  sufficient training data  trained models  insufficient training data  biased training data  self-supervised learning  latent variables  insufficiently trained situations  training data imbalance  latent distributions  training pipeline  full-scale autonomous vehicle  end-to-end controller  Training  Autonomous vehicles  Aerospace electronics  Image reconstruction  Training data  Data models  Robots 
Abstract: This paper introduces a new method for end-to-end training of deep neural networks (DNNs) and evaluates it in the context of autonomous driving. DNN training has been shown to result in high accuracy for perception to action learning given sufficient training data. However, the trained models may fail without warning in situations with insufficient or biased training data. In this paper, we propose and evaluate a novel architecture for self-supervised learning of latent variables to detect the insufficiently trained situations. Our method also addresses training data imbalance, by learning a set of underlying latent variables that characterize the training data and evaluate potential biases. We show how these latent distributions can be leveraged to adapt and accelerate the training pipeline by training on only a fraction of the total dataset. We evaluate our approach on a challenging dataset for driving. The data is collected from a full-scale autonomous vehicle. Our method provides qualitative explanation for the latent variables learned in the model. Finally, we show how our model can be additionally trained as an end-to-end controller, directly outputting a steering control command for an autonomous vehicle.


Title: Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  pattern classification  virtual-to-real-world transfer learning  deep learning models  virtual environments  model training  real-world trail data  robots  wilderness trails  outdoor trails  classification models  Cameras  Robot vision systems  Deep learning  Training  Navigation  Data collection 
Abstract: Robots hold promise in many scenarios involving outdoor use, such as search-and-rescue, wildlife management, and collecting data to improve environment, climate, and weather forecasting. However, autonomous navigation of outdoor trails remains a challenging problem. Recent work has sought to address this issue using deep learning. Although this approach has achieved state-of-the-art results, the deep learning paradigm may be limited due to a reliance on large amounts of annotated training data. Collecting and curating training datasets may not be feasible or practical in many situations, especially as trail conditions may change due to seasonal weather variations, storms, and natural erosion. In this paper, we explore an approach to address this issue through virtual-to-real-world transfer learning using a variety of deep learning models trained to classify the direction of a trail in an image. Our approach utilizes synthetic data gathered from virtual environments for model training, bypassing the need to collect a large amount of real images of the outdoors. We validate our approach in three main ways. First, we demonstrate that our models achieve classification accuracies upwards of 95% on our synthetic data set. Next, we utilize our classification models in the control system of a simulated robot to demonstrate feasibility. Finally, we evaluate our models on real-world trail data and demonstrate the potential of virtual-to-real-world transfer learning.


Title: Robust Model-Predictive Deformation Control of a Soft Object by Using a Flexible Continuum Robot
Key Words: deformation  Jacobian matrices  manipulators  mobile robots  nonlinear control systems  predictive control  robust control  surgery  robust model-predictive deformation control  soft object  flexible continuum robot  soft tissues  prediction horizon-based controller  Strain  Jacobian matrices  Force  Deformable models  Uncertainty  End effectors 
Abstract: Flexible continuum robots have exhibited unique advantages in working in an unstructured environment. Many applications require robots to actively control the deformation of soft objects, such as soft tissues in surgery. Thus, this study presents a robust model-predictive deformation control of a soft object using a flexible continuum robot. A linear approximation model for mapping from actuation space of a continuum robot to deformation space of a soft object is established. Jacobian matrix is estimated online by using a robust Geman-McClure estimator. Then, the deformation of the soft object is regulated by using a prediction horizon-based controller with exponential weighting for model uncertainty. The proposed control approach is effective in manipulating a soft object with a flexible continuum robot that is in contact with obstacles.


Title: Closed-Loop Single-Beacon Passive Acoustic Navigation for Low-Cost Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  closed loop systems  computational complexity  hydrophones  inertial navigation  marine navigation  mobile robots  particle filtering (numerical methods)  position control  localization  autonomous underwater vehicles  Doppler velocity log  positional error  acoustic beacon  DVL-aided INS  LBL system  SandShark AUV  underwater navigation  computational complexity  phased-array beamforming  closed-loop operation  particle filter  vehicle-mounted passive hydrophone receiver-array  multiAUV operations  power requirements  inertial navigation system  robotic vehicle  Acoustics  Navigation  Array signal processing  Receivers  Acoustic measurements  Transponders  Time-frequency analysis 
Abstract: Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.


Title: Unscented Kalman Filter on Lie Groups for Visual Inertial Odometry
Key Words: distance measurement  Kalman filters  Lie groups  nonlinear filters  SLAM (robots)  state estimation  stereo image processing  unscented Kalman filter  Lie groups  visual information  inertial measurements  state estimation  robust estimation  computational efficiency  low-cost aerial vehicles  processor power  innovative filter  stereo visual inertial odometry building  invariant filtering theory  computational complexity  stereo multistate constraint Kalman filter  EuRoC dataset  MAV outdoor dataset  Cameras  Kalman filters  Visualization  Computational modeling  Uncertainty  Robustness  Noise measurement  Lie groups  unscented Kalman filter  visual inertial odometry  aerial vehicle  localization 
Abstract: Fusing visual information with inertial measurements for state estimation has aroused major interests in recent years. However, combining a robust estimation with computational efficiency remains challenging, specifically for low-cost aerial vehicles in which the quality of the sensors and the processor power are constrained by size, weight and cost. In this paper, we present an innovative filter for stereo visual inertial odometry building on: (i) the recently introduced stereo multistate constraint Kalman filter; (ii) the invariant filtering theory; and (iii) the unscented Kalman filter (UKF) on Lie groups. Our solution combines accuracy, robustness and versatility of the UKF. We then compare our approach to state-of-art solutions in terms of accuracy, robustness and computational complexity on the EuRoC dataset and a challenging MAV outdoor dataset.


Title: A Multi-Position Joint Particle Filtering Method for Vehicle Localization in Urban Area
Key Words: distance measurement  image matching  mobile robots  particle filtering (numerical methods)  path planning  probability  robot vision  flexible multiposition joint particle filtering  position error  anchor point  curving roads  ego-trajectory  probabilistic filtering method  flexible road map  long range navigation  error accumulation  visual odometry  traditional visual localization methods  autonomous vehicles  robust localization  urban area  vehicle localization  dense parallel road branches  Roads  Trajectory  Filtering  Urban areas  Wheels  Simultaneous localization and mapping  Navigation 
Abstract: Robust localization is a prerequisite for autonomous vehicles. Traditional visual localization methods like visual odometry suffer error accumulation on long range navigation. In this paper, a flexible road map based probabilistic filtering method is proposed to tackle this problem. To effectively match the ego-trajectory to various curving roads in map, a new representation based on anchor point (AP) which captures the main curving points on the trajectory is presented. Based on APs of the map and trajectory, a flexible Multi-Position Joint Particle Filtering (MPJPF) framework is proposed to correct the position error. The method features the capability of adaptively estimating a series of APs jointly and only updates the estimation at situations with low uncertainty. It explicitly avoids the drawbacks of obliging to determine the current position at large uncertain situations such as dense parallel road branches. The experiments carried out on KITTI benchmark demonstrate our success.


Title: Courteous Autonomous Cars
Key Words: automobiles  road traffic  traffic engineering computing  courteous autonomous cars  driving quality  cost function  purely selfish cost  interactive drivers  autonomous car  courtesy term  robot car  human behavior  courteous robot cars  human driver behavior  Autonomous automobiles  Vehicles  Cost function  Planning  Robot kinematics  Safety 
Abstract: Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.


Title: Joint Ego-motion Estimation Using a Laser Scanner and a Monocular Camera Through Relative Orientation Estimation and 1-DoF ICP
Key Words: automobiles  cameras  iterative methods  laser ranging  mobile robots  motion estimation  optical scanners  pose estimation  sensor fusion  SLAM (robots)  joint ego-motion estimation  laser scanner  monocular camera  autonomous vehicles  SLAM algorithms  sensor suite  laser range finder  3D point clouds  iterative closest point problem  sensor modality  orientation estimation  autonomous cars  pose estimation  autonomous robots  1-DoF ICP  data association  Cameras  Iterative closest point algorithm  Lasers  Three-dimensional displays  Robot vision systems  Image color analysis 
Abstract: Pose estimation and mapping are key capabilities of most autonomous vehicles and thus a number of localization and SLAM algorithms have been developed in the past. Autonomous robots and cars are typically equipped with multiple sensors. Often, the sensor suite includes a camera and a laser range finder. In this paper, we consider the problem of incremental ego-motion estimation, using both, a monocular camera and a laser range finder jointly. We propose a new algorithm, that exploits the advantages of both sensors-the ability of cameras to determine orientations well and the ability of laser range finders to estimate the scale and to directly obtain 3D point clouds. Our approach estimates the 5 degrees of freedom relative orientation from image pairs through feature point correspondences and formulates the remaining scale estimation as a new variant of the iterative closest point problem with only one degree of freedom. We furthermore exploit the camera information in a new way to constrain the data association between laser point clouds. The experiments presented in this paper suggest that our approach is able to accurately estimate the ego-motion of a vehicle and that we obtain more accurate frame-to-frame alignments than with one sensor modality alone.


Title: LandmarkBoost: Efficient visualContext Classifiers for Robust Localization
Key Words: image capture  image classification  image matching  image retrieval  nearest neighbour methods  pose estimation  search problems  stereo image processing  metric pose retrieval algorithms  image plane  state-of-the-art descriptor matching methods  visualContext classifiers  binary descriptors  robust localization  Landmark-Boost  boosting framework  contextual information  landmark observations  boosted classifier  landmark classification task  2D-3D matching methods  visual context  mobile platforms  nearest neighbor search  reliable pose retrieval algorithms  Visualization  Feature extraction  Measurement  Robots  Three-dimensional displays  Pose estimation  Context modeling 
Abstract: The growing popularity of autonomous systems creates a need for reliable and efficient metric pose retrieval algorithms. Currently used approaches tend to rely on nearest neighbor search of binary descriptors to perform the 2D-3D matching and guarantee realtime capabilities on mobile platforms. These methods struggle, however, with the growing size of the map, changes in viewpoint or appearance, and visual aliasing present in the environment. The rigidly defined descriptor patterns only capture a limited neighborhood of the keypoint and completely ignore the overall visual context. We propose LandmarkBoost - an approach that, in contrast to the conventional 2D-3D matching methods, casts the search problem as a landmark classification task. We use a boosted classifier to classify landmark observations and directly obtain correspondences as classifier scores. We also introduce a formulation of visual context that is flexible, efficient to compute, and can capture relationships in the entire image plane. The original binary descriptors are augmented with contextual information and informative features are selected by the boosting framework. Through detailed experiments, we evaluate the retrieval quality and performance of Landmark-Boost, demonstrating that it outperforms common state-of-the-art descriptor matching methods.


Title: Fire-Aware Planning of Aerial Trajectories and Ignitions
Key Words: aerospace computing  aerospace control  autonomous aerial vehicles  computer simulation  helicopters  ignition  path planning  trajectory control  wildfires  fire-aware planning  aerial trajectories  fire vectors  fire simulation  fire-aware planner  fire simulator predictions  ignition spheres  unmanned aerial system for prescribed fires  helicopter  UAS-Rx Android application  Ignition  Robots  Computational modeling  Planning  Sensors  Mathematical model  Trajectory 
Abstract: Prescribed fires can lessen wildfire severity and control invasive species, but they can also be risky and costly. Unmanned aerial systems can reduce those drawbacks by, for example, dropping ignition spheres to ignite the most hazardous areas. Existing systems, however, lack awareness of the fire vectors to operate autonomously, safely, and efficiently. In this work we address that limitation, introducing an approach that integrates a lightweight fire simulator and a planner for trajectories and ignition sphere drop waypoints. Both components are unique in that they are amenable to input from the system's sensors and the fire crew to increase fire awareness. We conducted a preliminary study that confirms that such inputs improve the accuracy of the fire simulation to counter the unpredictability of the target environment. The field study of the system showed that the fire-aware planner generated safe trajectories with effective ignitions leveraging the fire simulator predictions.


Title: Embedding Temporally Consistent Depth Recovery for Real-time Dense Mapping in Visual-inertial Odometry
Key Words: distance measurement  image reconstruction  interpolation  learning (artificial intelligence)  mobile robots  robot vision  SLAM (robots)  real-time dense mapping  visual-inertial odometry  dense scene information  fast self-localization  VIO-based SLAM systems  VIO depth estimations  subspace-based stabilization scheme  temporal consistency  edge-preserving depth interpolation  simultaneous localization and mapping  learning-based methods  embedding temporally consistent depth recovery  Simultaneous localization and mapping  Real-time systems  Feature extraction  Pipelines  Interpolation  Three-dimensional displays 
Abstract: Dense mapping is always the desire of simultaneous localization and mapping (SLAM), especially for the applications that require fast and dense scene information. Visual-inertial odometry (VIO) is a light-weight and effective solution to fast self-localization. However, VIO-based SLAM systems have difficulty in providing dense mapping results due to the spatial sparsity and temporal instability of the VIO depth estimations. Although there have been great efforts on real-time mapping and depth recovery from sparse measurements, the existing solutions for VIO-based SLAM still fail to preserve sufficient geometry details in their results. In this paper, we propose to embed depth recovery into VIO-based SLAM for real-time dense mapping. In the proposed method, we present a subspace-based stabilization scheme to maintain the temporal consistency and design a hierarchical pipeline for edge-preserving depth interpolation to reduce the computational burden. Numerous experiments demonstrate that our method can achieve an accuracy improvement of up to 49.1 cm compared to state-of-the-art learning-based methods for depth recovery and reconstruct sufficient geometric details in dense mapping when only 0.07% depth samples are available. Since a simple CPU implementation of our method already runs at 10-20 fps, we believe our method is very favorable for practical SLAM systems with critical computational requirements.


Title: Fractional-Order Trajectory-Following Control for Two-Legged Dynamic Walking
Key Words: control system synthesis  energy conservation  legged locomotion  motion control  PD control  position control  robot dynamics  simulated walker  two-legged dynamic walking  walking robots  energy consumption  energy efficiency  fractional-order trajectory-following control  proportional-derivative architecture  Legged locomotion  Mathematical model  Gravity  Aerodynamics  PD control  Trajectory 
Abstract: This research seeks greater efficiency for walking robots. Efficiency can be improved in two ways: better performance (i.e., less wasted motion) and reduced energy consumption. Fractional-order control is a pathway to both of these improvements because of the flexibility it offers in designing a control strategy. Compared to the existing proportional-derivative architecture, changing the order of the derivative - the number of derivatives taken - to real numbers other than 1 has yielded both types of improvement for a simulated walker. The evidence of better performance is the leg angles' improvement in maintaining a desired relationship with respect to one another. Depending on the controller chosen, the walker can also be made to achieve the original level of performance with reduced control signals and less torque delivered to the hip joint, implying greater energy efficiency.


Title: Walking on a Steep Slope Using a Rope by a Life-Size Humanoid Robot
Key Words: friction  humanoid robots  least squares approximations  mobile robots  motion control  friction force  linear least-square problem  life-size humanoid robot HRP-2  rope  steep slope  Legged locomotion  Friction  Robot kinematics  Humanoid robots  Force  Foot 
Abstract: In this paper, we propose methods for walking on a steep slope using a rope by a humanoid robot. There are two difficulties for walking on a steep slope without a rope. First, range of motion of ankle joints get limited. Second, feet of a robot slip on a steep slope. For these problems, using a rope is effective solution because the robot can receive enough friction force from the slope and walk on a steep slope by pulling a rope with proper tension. In addition, the robot pulling a rope on a slope can relax limitations of ankle joints. Therefore, we propose methods to determine tension of a grasped rope by solving a linear least-square problem considering deformability of a rope. With these methods, a life-size humanoid robot HRP-2 could walk on a steep slope which angle is 40 degree.


Title: Perception Based Locomotion System for a Humanoid Robot with Adaptive Footstep Compensation under Task Constraints
Key Words: adaptive control  collision avoidance  humanoid robots  interpolation  legged locomotion  path planning  task constraints  humanoid robot  adaptive footstep compensation  adaptive locomotion system  local error correction  perception based locomotion system  locomotion error  locomotion planning  point cloud  environmental measurements  plane estimation  space interpolation  collision avoidance  laser scans  Humanoid robots  Task analysis  Planning  Foot  Three-dimensional displays  Estimation 
Abstract: In order to accurately reach a target position while executing a task which imposes occlusion or constraints of the posture, a humanoid robot requires an adaptive locomotion system, which can comprehensively integrate localization, environmental mapping, global locomotion planning and local error correction. In this paper, we propose a method of constructing a perception based locomotion system for a humanoid robot. The major contribution of this paper is solving a problem of the locomotion error caused by the task constraints, by locally compensating footsteps and assessing the need for global footstep re-planning online based on environmental measurements. The proposed system provides an accurate and dense ground point cloud, called HeightField, using plane estimation and space interpolation, and obstacle point cloud for frequent collision avoidance by accumulating laser scans. This environmental perception enables a humanoid robot to plan footsteps globally even in the situation where the sight of the robot is limited and compensate footsteps while estimating landing state during locomotion online with the localization result. We evaluated the practicality of the proposed system by applying it to our humanoid robot carrying a heavy object in a construction site and confirmed that the proposed system contributed to improved locomotion abilities of a humanoid robot engaging in heavy-duty or dangerous tasks.


Title: Adaptive step rotation in biped walking
Key Words: legged locomotion  predictive control  quadratic programming  adaptive step rotation  biped walking  fixed feet rotation  nonlinear solvers  safe linear constraints  model predictive control schemes  robot walking  sequential quadratic program  Legged locomotion  Foot  Collision avoidance  Robot kinematics  Dynamics  Predictive control 
Abstract: We want to enable the robot to reorient its feet in order to face its direction of motion. Model Predictive Control schemes for biped walking usually assume fixed feet rotation since adapting them online leads to a nonlinear problem. Nonlinear solvers do not guarantee the satisfaction of nonlinear constraints at every iterate and this can be problematic for the real-time operation of robots. We propose to define safe linear constraints that are always inside the intersection of the nonlinear constraints. We make simulations of the robot walking on a crowd and compare the performance of the proposed method with respect to the original nonlinear problem solved as a Sequential Quadratic Program.


Title: Implementing Full-body Torque Control in Humanoid Robot with High Gear Ratio Using Pulse Width Modulation Voltage
Key Words: electric current control  gears  humanoid robots  legged locomotion  mobile robots  motion control  position control  robot dynamics  torque control  voltage control  full-body torque control  high gear ratio  pulse width modulation voltage  motor torque  current control  joint torque control  robot dynamics  humanoid robot  position control  legged robots  Torque  Robots  Resistance  Aerodynamics  Temperature sensors  Modeling  Torque control 
Abstract: Most state-of-the-art torque control-based legged robots show excellent performance, exceeding that of conventional position control-based robots. Many conventional position control-based legged robots have high gear ratios, but do not have joint torque sensors. In addition, some robots cannot generate current for controlling the motor torque. To apply torque control-based walking algorithms to a position control-based humanoid robot, we proposed current control using a motor thermal model and realized joint torque control by compensating for the joint dynamics and robot dynamics. We conducted experiments to verify the performance of the Hubo2 platform developed in 2008 by applying a full-body dynamics control framework. The results confirmed the possibility of using torque control algorithms with existing position-based robots.


Title: Towards Minimal Intervention Control with Competing Constraints
Key Words: control engineering computing  control system synthesis  learning (artificial intelligence)  linear quadratic control  optimal control  robot programming  trajectory control  task execution  trajectory constraints  information-theory  finite horizon linear quadratic regulator  Cartesian space  pure trajectory generation  imitation learning algorithms  simulated robot  robot null space  optimal control  minimal intervention control strategy  Aerospace electronics  Trajectory  Null space  Task analysis  Probabilistic logic  End effectors 
Abstract: As many imitation learning algorithms focus on pure trajectory generation in either Cartesian space or joint space, the problem of considering competing trajectory constraints from both spaces still presents several challenges. In particular, when perturbations are applied to the robot, the underlying controller should take into account the importance of each space for the task execution, and compute the control effort accordingly. However, no such controller formulation exists. In this paper, we provide a minimal intervention control strategy that simultaneously addresses the problems of optimal control and competing constraints between Cartesian and joint spaces. In light of the inconsistency between Cartesian and joint constraints, we exploit the robot null space from an information-theory perspective so as to reduce the corresponding conflict. An optimal solution to the aforementioned controller is derived and furthermore a connection to the classical finite horizon linear quadratic regulator (LQR) is provided. Finally, a writing task in a simulated robot verifies the effectiveness of our approach.


Title: Design and Evaluation of Torque Based Bipedal Walking Control System That Prevent Fall Over by Impulsive Disturbance
Key Words: legged locomotion  motion control  torque control  torque based bipedal walking control system  impulsive disturbance  bipedal robot control system  robust online walking controller  leg sweep disturbance  distributed system  sensorless whole body torque control method  Robot sensing systems  Torque  Legged locomotion  Actuators  Humanoid robots 
Abstract: In this paper, we develop a bipedal robot control system that has an ability to perform instantaneous high power and flexibility to absorb an impulsive disturbance. We utilize a sensor-less whole body torque control method executed in a high responsive realtime distributed system. This system also includes a robust online walking controller that can avoid fall over caused by a strong collision with the robot's legs. We evaluated the proposed control system by hitting a rubber ball or adding a leg sweep disturbance and verified the functionality of the absorbing motion and the balance restoring motion.


Title: Humanoid Robot COM Kinematics Estimation based on Compliant Inverted Pendulum Model and Robust State Estimator
Key Words: elastic constants  estimation theory  humanoid robots  mobile robots  pendulums  robot kinematics  state estimation  mechanical deformation  damper  limited structural stiffness  humanoid robot COM kinematics estimation  center of mass  sing-mass model  robust state estimator  compliant inverted pendulum model  Humanoid robots  Mathematical model  State estimation  Kinematics  Computational modeling 
Abstract: This work proposes a humanoid robot center of mass (COM) estimation framework based on the compliant inverted pendulum model and the robust estimator. Humanoids' limited structural stiffness and relatively long legs result in undesired flexibility, and this undesired motion hinders the state estimation. The models used in previous studies were either not suitable for estimation or too simple to express these key characteristics of humanoid robots. Here, to enhance the estimation performance, the compliant inverted pendulum model, which is developed by attaching a spring and damper to the original pendulum, is adopted. The additional elements can represent the mechanical deformation and undesired flexibility. This model can reflect the important characteristics of the humanoid robot while taking advantage of the merits of the sing-mass model. In addition, a robust state estimator that was proposed in our previous work is adopted to compensate for an estimation error caused by a modeling error. Using these two factors, an improved COM kinematics estimates could be obtained.


Title: Robotic Sewing and Knot Tying for Personalized Stent Graft Manufacturing
Key Words: closed loop systems  medical robotics  robot vision  servomechanisms  stents  surgery  textile technology  visual servoing  robotic system  stitch size planning  3D industrial sewing  successive knot  tension control  thread management  thread manipulator  stitch sizes  sewing accuracy  automated knot tying  closed-loop visual servoing control  customized robotic sewing device  3D structured object  personalized stent graft manufacturing  size 2.0 mm to 5.0 mm  Needles  Robot kinematics  Cameras  Yarn  Robot vision systems 
Abstract: This paper presents a versatile robotic system for sewing a 3D structured object. Leveraging on using a customized robotic sewing device and closed-loop visual servoing control, an all-in-one solution for sewing personalized stent graft is demonstrated. Stitch size planning and automated knot tying are proposed as two key functions of the system. By using effective stitch size planning, sub-millimetre sewing accuracy is achieved for stitch sizes ranging from 2mm to 5mm. In addition, a thread manipulator for thread management and tension control is also proposed to perform successive knot tying to secure each stitch. Detailed laboratory experiments have been performed to evaluate the proposed instruments and allied algorithms. The proposed framework can be generalised to a wide range of applications including 3D industrial sewing, as well as transferred to other clinical areas such as surgical suturing.


Title: Estimation of Interaction Forces in Robotic Surgery using a Semi-Supervised Deep Neural Network Model
Key Words: force feedback  image reconstruction  image representation  learning (artificial intelligence)  medical robotics  neural nets  surgery  unsupervised learning  video signal processing  interaction forces  force estimation task  LSTM network  RGB frame  CAE  Convolutional Auto-Encoder  Long-Short Term Memory network  encoder network  SemiSupervised Learning framework  SL techniques  UL  Unsupervised Learning method  video frame  compact representation  unlabeled video sequences  video sequence  Supervised Learning setting  Vision-Based Force Sensing  current Robot-Assisted Minimally Invasive Surgery systems  force feedback  semisupervised deep neural network model  robotic surgery  Video sequences  Force  Tools  Robot sensing systems  Surgery  Estimation  Vision Based Force Sensing  Robotic Surgery  Deep Neural Networks  Semi-Supervised Learning 
Abstract: Providing force feedback as a feature in current Robot-Assisted Minimally Invasive Surgery systems still remains a challenge. In recent years, Vision-Based Force Sensing (VBFS) has emerged as a promising approach to address this problem. Existing methods have been developed in a Supervised Learning (SL) setting. Nonetheless, most of the video sequences related to robotic surgery are not provided with ground-truth force data, which can be easily acquired in a controlled environment. A powerful approach to process unlabeled video sequences and find a compact representation for each video frame relies on using an Unsupervised Learning (UL) method. Afterward, a model trained in an SL setting can take advantage of the available ground-truth force data. In the present work, UL and SL techniques are used to investigate a model in a Semi-Supervised Learning (SSL) framework, consisting of an encoder network and a Long-Short Term Memory (LSTM) network. First, a Convolutional Auto-Encoder (CAE) is trained to learn a compact representation for each RGB frame in a video sequence. To facilitate the reconstruction of high and low frequencies found in images, this CAE is optimized using an adversarial framework and a L1-loss, respectively. Thereafter, the encoder network of the CAE is serially connected with an LSTM network and trained jointly to minimize the difference between ground-truth and estimated force data. Datasets addressing the force estimation task are scarce. Therefore, the experiments have been validated in a custom dataset. The results suggest that the proposed approach is promising.


Title: Cross-Scene Suture Thread Parsing for Robot Assisted Anastomosis based on Joint Feature Learning
Key Words: feature extraction  manipulators  medical computing  medical robotics  object detection  surgery  unsupervised learning  joint feature learning framework  background adaptation  surgical suture thread detection  unsupervised domain adaptation  labelled training data  partially labelled target domain  organs  adversarial learning  cross-scene suture thread parsing  task autonomy  robot-assisted anastomosis  automatic thread detection  surgical robots  robot manipulation  surgical settings  foreground adaptation  semisupervised domain adaptation  detection model learning  semantic identity  Yarn  Task analysis  Instruction sets  Adaptation models  Image segmentation  Surgery  Splines (mathematics) 
Abstract: Task autonomy is an important consideration for the development of future surgical robots. For robot-assisted anastomosis, suture thread detection is a prerequisite for subsequent robot manipulation. Previous works on automatic thread detection are focused on the learning of the models with specific surgical settings that are poorly generalisable to generic settings. In this paper, we propose a joint feature learning framework that caters for the foreground and background adaptation for surgical suture thread detection. The proposed method is developed in the context of semi-supervised and unsupervised domain adaptation, leveraging the labelled training data from the source domain to learn the detection model for unlabelled or partially labelled target domain, which can also be from different types of threads or organs. Based on adversarial learning, we further preserve the semantic identity and introduce curriculum adaptation to generate synthetic data. Experiments on four domain adaptation tasks for suture thread detection demonstrate the strength of the proposed method being able to generate good quality synthetic data and transfer between specific domains with limited or even no labelled data of the target domain.


Title: Unsupervised Trajectory Segmentation and Promoting of Multi-Modal Surgical Demonstrations
Key Words: feature extraction  image segmentation  medical robotics  robot kinematics  surgery  unsupervised learning  video signal processing  wavelet transforms  multimodal surgical demonstrations  surgical trajectory segmentation  robot learning  robot-assisted minimally invasive surgery  kinematic data  over-segmentation issue  unsupervised deep learning network  convolutional auto-encoder  videos  unsupervised trajectory segmentation method  JIGSAWS dataset  wavelet transform  feature extraction  Kinematics  Feature extraction  Surgery  Trajectory  Convolution  Visualization  Wavelet transforms 
Abstract: To improve the efficiency of surgical trajectory segmentation for robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. Unsupervised deep learning network, stacking convolutional auto-encoder, is employed to extract more discriminative features from videos in an effective way. To further improve the accuracy of segmentation, on one hand, wavelet transform is used to filter out the noises existed in the features from video and kinematic data. On the other hand, the segmentation result is promoted by identifying the adjacent segments with no state transition based on the predefined similarity measurements. Extensive experiments on a public dataset JIGSAWS show that our method achieves much higher accuracy of segmentation than state-of-the-art methods in the shorter time.


Title: Autonomous Localization, Navigation and Haustral Fold Detection for Robotic Endoscopy
Key Words: biological organs  biomedical optical imaging  cancer  endoscopes  medical image processing  medical robotics  surgery  autonomous localization  Haustral fold detection  robotic endoscopy  capsule endoscopes  minimally invasive devices  gastrointestinal abnormalities  colorectal cancer  real-time navigation system  observational devices  autonomous navigation  single minimally invasive device  vision system  autonomous lumen center tracking  haustral fold identification  multiple haustral folds  robotic endoscope platform  active simulator  real-time localization  center tracking algorithm  colonoscopy  in vivo video  surgical tools  mobility system  Endoscopes  Robot sensing systems  Colon  Navigation  Wheels  In vivo 
Abstract: Capsule endoscopes have gained popularity over the last decade as minimally invasive devices for diagnosing gastrointestinal abnormalities such as colorectal cancer. While this technology offers a less invasive and more convenient alternative to traditional scopes, these capsules are only able to provide observational capabilities due to their passive nature. With the addition of a reliable mobility system and a real-time navigation system, capsule endoscopes could transform from observational devices into active surgical tools, offering biopsy and therapeutic capabilities and even autonomous navigation in a single minimally invasive device. In this work, a vision system is developed to allow for autonomous lumen center tracking and haustral fold identification and tracking during colonoscopy. This system is tested for its ability to accurately identify and track multiple haustral folds across many frames in both simulated and in vivo video, and the lumen center tracking is tested onboard a robotic endoscope platform (REP) within an active simulator to demonstrate autonomous navigation. In addition, real-time localization is demonstrated using open source ORB-SLAM2. The vision system successfully identified 95.6% of Haustral folds in simulator frames and 70.6% in in vivo frames and false positives occurred in less than 1% of frames. The center tracking algorithm showed in vivo center estimates within a mean error of 6.6% of physician estimates and allowed for the REP to traverse 2 m of the active simulator in 6 minutes without intervention.


Title: Towards to a Robotic Assisted System for Percutaneous Nephrolithotomy
Key Words: biomedical ultrasonics  kidney  medical robotics  needles  skin  surgery  ultrasonic therapy  target kidney stone  surgeon  robotic assisted system  percutaneous nephrolithotomy  recommended treatment method  kidney stone removal  percutaneous access  targeted calyx  flank skin  surgical performance  ultrasound probe  respiratory motion  percutaneous target  Surgery  Needles  Probes  Robot sensing systems  Force  Robot kinematics 
Abstract: Percutaneous Nephrolithotomy is a recommended treatment method for large kidney stone removal. However, the first and most important step, i.e., getting the percutaneous access to create the tract between the targeted calyx and the flank skin, is challenging as the surgeon is often occupied by several tasks at a given time. Therefore, in this paper, we propose a robotic assisted system that collaborates with the surgeon and provides assistance in order for the surgeons to focus on more critical jobs resulting in better surgical performance. A procedure for this robot including three working stages is described. This procedure allows the surgeon to choose a suitable percutaneous target using an ultrasound probe based on his or her experience and the robot will track the respiratory motion of the target kidney stone and insert the needle automatically after the surgeon releases the probe. Experiments are conducted to demonstrate the procedure with the proposed assisted robot for PCNL.


Title: On Muscle Activation for Improving Robotic Rehabilitation after Spinal Cord Injury
Key Words: biomechanics  electromyography  injuries  medical robotics  neuromuscular stimulation  neurophysiology  patient rehabilitation  patient treatment  motor activation patterns  improved standing ability  SCI patients  healthy activity  improving robotic rehabilitation  spinal cord stimulation  motor complete spinal cord injury  recovered motor activity  motor training  spinal stimulation  bipedal standing  spinal rehabilitation therapies  healthy subjects  muscle activation patterns  SCI patient motor activity  healthy motor activity  healthy standing muscle activity  patient stand training  Electromyography  Muscles  Training  Electrical stimulation  Robot sensing systems  Feature extraction 
Abstract: Spinal cord stimulation (SCS) has recently enabled humans with motor complete spinal cord injury (SCI) to independently stand and recover some lost autonomic function. However, the nature of the recovered motor activity and the interplay between SCS and motor training are not well understood. Understanding the effect of stand training and spinal stimulation on motor activity during bipedal standing is important for designing spinal rehabilitation therapies that seek to combine spinal stimulation and rehabilitative robots. In this study, we examined electromyography (EMG) data gathered from two SCI patients and six healthy subjects as they attempted standing. We analyzed the muscle activation patterns and EMG waveform shape to quantify both the changes in SCI patient motor activity with training, and the differences between healthy motor activity and SCI patient motor activity under stimulation. We also looked for correlations between the similarity in SCI patients' motor activity to healthy subjects and their overall standing ability. We found that good standing in SCI patients does not emulate healthy standing muscle activity. Furthermore, patient stand training heavily influenced motor activation patterns, but not in ways that improved standing ability. These results indicate that current training techniques do not optimally influence motor activity, and robotic rehabilitation strategies for SCI patients should target essential features of motor activity to optimize functional performance, rather than emulate healthy activity.


Title: Printing Strain Gauges on Intuitive Surgical da Vinci Robot End Effectors
Key Words: biomedical equipment  biomedical measurement  end effectors  force feedback  medical robotics  needles  strain gauges  surgery  printing strain gauges  robotic surgery  strain gauge printing method  da Vinci surgical robot end effectors  additive deposition-based sensor fabrication method  vapor-deposition-based sensor fabrication method  sensor performance  minimally invasive procedures  Sensors  Surface treatment  End effectors  Shafts  Strain  Strain measurement  Surgery 
Abstract: Force feedback during robotic surgery is critical in order to minimize potential injury to the patient and decrease recovery time from surgical procedures. Here we describe the use of a novel strain gauge printing method to apply low profile, low cost sensors directly to the surface of da Vinci surgical robot end effectors (Intuitive Surgical, Inc.) to sense deflection and provide force feedback. This additive, vapor-deposition-based sensor fabrication method is used to deposit strain gauges directly onto the surfaces of the end effectors with minimal disruption to the device and without the need for adhesives or machining operations. Initial experiments characterize sensor performance and indicate the applicability of the proposed approach for force feedback during minimally invasive procedures.


Title: Group emotion recognition strategies for entertainment robots
Key Words: affective computing  cloud computing  emotion recognition  face recognition  humanoid robots  mobile robots  face API  human perceptions  assistive robotics  emotion API  Microsoft Azure cognitive services  Waseda entertainment robots  computer science  Ekman's extended Big Six emotional model  group emotion recognition strategies  affective computing  cloud-computing based solution  facial expression analysis  Face  Emotion recognition  Entertainment industry  Cameras  Humanoid robots  Mood  humanoid robot  entertainment robot  assistive robotics  emotion recognition 
Abstract: In this paper, a system to determine the emotion of a group of people via facial expression analysis is proposed for the Waseda Entertainment Robots. General models and standard methods for emotion definition and recognition are briefly described, as well as strategies for computing the group global emotion, knowing the individual emotions of group members. This work is based on Ekman's extended “Big Six” emotional model, popular in Computer Science and Affective Computing. Emotion recognition via facial expression analysis is performed with a cloud-computing based solution, using Microsoft Azure Cognitive services. First, the performances of both the Face API to detect faces, and Emotion API, to compute emotion via face expression analysis, are tested. After that, a solution to compute the emotion of a group of people has been implemented and its performances compared to human perceptions. This work presents concepts and strategies which can be generalized for applications within the scope of assistive robotics and, more broadly, affective computing, wherever it will be necessary to determine the emotion of a group of people.


Title: Learning How Pedestrians Navigate: A Deep Inverse Reinforcement Learning Approach
Key Words: collision avoidance  feature extraction  human-robot interaction  learning (artificial intelligence)  mobile robots  navigation  neural nets  trajectory control  mobile robots  human robot interaction  robot navigation algorithms  human navigation behaviors  maximum entropy deep inverse reinforcement learning  nonlinear reward function  deep neural network approximation  social affinity map  human motion trajectories  learned reward function  natural social navigation behaviors  deep inverse reinforcement learning approach  pedestrian trajectories  MEDIRL algorithm  feature extraction  collision avoidance  pedestrians navigation  Navigation  Robots  Trajectory  Reinforcement learning  Collision avoidance  Neural networks  Entropy 
Abstract: Humans and mobile robots will be increasingly cohabiting in the same environments, which has lead to an increase in studies on human robot interaction (HRI). One important topic in these studies is the development of robot navigation algorithms that are socially compliant to humans navigating in the same space. In this paper, we present a method to learn human navigation behaviors using maximum entropy deep inverse reinforcement learning (MEDIRL). We use a large open dataset of pedestrian trajectories collected in an uncontrolled environment as the expert demonstrations. Human navigation behaviors are captured by a nonlinear reward function through deep neural network (DNN) approximation. The developed MEDIRL algorithm takes feature inputs including social affinity map (SAM) that are extracted from human motion trajectories. We perform simulation experiments using the learned reward function, and the performance is evaluated comparing it with the real measured pedestrian trajectories in the dataset. The evaluation results show that the proposed method has acceptable prediction accuracy compared to other state-of-the-art methods, and it can generate pedestrian trajectories similar to real human trajectories with natural social navigation behaviors such as collision avoidance, leader-follower, and split-and-rejoin.


Title: Situated Human–Robot Collaboration: predicting intent from grounded natural language
Key Words: human-robot interaction  interactive systems  mobile robots  natural language processing  context models  collaborator  collaborative construction task  autonomous robot  task representations  naturalistic data sets  human-robot collaboration  grounded natural language  human teamwork  fluent interactions  nonverbal cues  robotic platforms  explicit commands  unequivocal representations  human partners  naturalistic speech  action selection  human-robot collaborative activities  separate speech  Task analysis  Collaboration  Context modeling  Natural languages  Tools  Robot kinematics 
Abstract: Research in human teamwork shows that a key element of fluid and fluent interactions is the interpretation of implicit verbal and non-verbal cues in context. This poses an issue to robotic platforms, however, as they have historically worked best when controlled through explicit commands that have employed structured, unequivocal representations of the external world and their human partners. In this work, we present a framework for effectively grounding situated and naturalistic speech to action selection during human-robot collaborative activities. This is accomplished by maintaining and incrementally updating separate “speech” and “context” models that jointly classify a collaborator's utterance. We evaluate the efficacy of the system on a collaborative construction task with an autonomous robot and human participants. We first demonstrate that our system is capable of acquiring and deploying new task representations from limited and naturalistic data sets, and without any prior domain knowledge of language or the task itself. Finally, we show that our system is capable of significantly improving performance on an unfamiliar task after a one-shot exposure.


Title: Social Coordination for Looking-Together Situations
Key Words: telerobotics  social coordination  looking-together situations  utility-maximizing behavior  joint utility  joint-utility computation  utility-yielding behavior  utility model  teleoperated robot  Robot kinematics  Wheelchairs  Legged locomotion  Computational modeling  Human-robot interaction 
Abstract: People engage in social coordination without explicitly communicating when they are conflicting over spatial resources, e.g., a shop clerk who yields to customers the best place to view products. In this study, we proposed a method that achieves such social coordination with a robot. Our idea is that the social coordination between two agents can be represented as utility-maximizing behavior for joint utility rather than just by a single agent utility. That is, given that each agent's reasonable behavior can be represented as utility-maximizing behavior for single agent utility, we model each agent's plans for himself as well as for the partner agent. Moreover, superiority relationships exist in this joint-utility computation. Since each agent knows such superiority relationships, social coordination can be modeled as utility-yielding behavior based on informed superiority. We specifically focus on looking-together situations for which we developed a utility model. With simulations, we investigate whether the above joint-utility-based modeling successfully reproduces social coordination in looking-together situations. We conducted an experiment in a situation where a tele-operated robot and a customer together look at products in a shop environment. Our experimental results show that our proposed method enables the robot to socially coordinate spatial resources, yielding significantly more thoughtful, less-self-centered, and appropriate impressions than the alternate robot.


Title: Policy Shaping with Supervisory Attention Driven Exploration
Key Words: interactive systems  learning (artificial intelligence)  mobile robots  policy shaping  robots  human supervision  human teacher  information-gathering actions  interactive reinforcement learning  interactive RL  Reinforcement learning  Task analysis  Negative feedback  Markov processes  Prediction algorithms  Intelligent robots 
Abstract: Robots deployed for long periods of time need to be able to explore and learn from their environment. One approach to this problem has been reinforcement learning (RL), in which robots receive rewards from the environment that allow them to choose optimal actions. To speed learning when human supervision is available, interactive reinforcement learning solicits feedback from a human teacher. However, this approach typically assumes that learning takes place under continuous supervision, which is unlikely to hold in long-term scenarios. We propose an extension to a method of interactive reinforcement learning, policy shaping, that takes into account human attention. Our approach enables better performance while unattended by favoring information-gathering actions when attended and actions that have received positive feedback when unattended. We test our approach in both simulation and on a robot, finding that our method learns faster than policy shaping and performs more safely than policy shaping while no one is paying attention to the robot.


Title: Friendly Motion Learning towards Sustainable Human Robot Interaction
Key Words: convolutional neural nets  human-robot interaction  learning (artificial intelligence)  sustainable human robot interaction  interaction motion features  machine learning technique  convolution neural network  interaction behavior  human impression  friendly motion learning  Robots  Convolution  Neural networks  Decoding  Feature extraction  Mathematical model  Human-robot interaction 
Abstract: For generating interactive behavior of robot to build a long-term relationship between humans and robots, we focus on the difference in familiarity of the human behaviors during conversation. It is difficult to extract interaction motion features correlated to such familiarity as a model in manual. Therefore, we use a machine learning technique: convolution neural network to learn and generate interaction behavior with different familiarity. In the evaluation experiment, we generated interaction behavior using a convolution neural network, which learned from the behaviors of friendship and unknown relationship, who have high and low familiarity respectively. We evaluated how much such interaction behavior affect the human impression by questionnaire survey.


Title: On the Robustness of Speech Emotion Recognition for Human-Robot Interaction with Deep Neural Networks
Key Words: emotion recognition  humanoid robots  human-robot interaction  neural nets  speech recognition  acoustic events  iCub robot platform  neural approaches  speech emotion recognition  deep neural networks  human-robot collaboration  research community  neural network-based architectures  neural SER models  in-domain data  noisy conditions  state-of-the-art neural acoustic emotion recognition models  human-robot interaction scenarios  room conditions  Robots  Training  Emotion recognition  Data models  Speech recognition  Acoustics  Feature extraction 
Abstract: Speech emotion recognition (SER) is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.


Title: Modeling Supervisor Safe Sets for Improving Collaboration in Human-Robot Teams
Key Words: cognition  human-robot interaction  mobile robots  multi-robot systems  optimisation  reachability analysis  human-robot teams  human supervisor collaborates  optimization  reachability theory  robots dynamic  robot behavior  human behavior  cognitive resources  Robots  Safety  Trajectory  Level set  Noise measurement  Optimal control  Optimization 
Abstract: When a human supervisor collaborates with a team of robots, the human's attention is divided, and cognitive resources are at a premium. We aim to optimize the distribution of these resources and the flow of attention. To this end, we propose the model of an idealized supervisor to describe human behavior. Such a supervisor employs a potentially inaccurate internal model of the the robots' dynamics to judge safety. We represent these safety judgements by constructing a safe set from this internal model using reachability theory. When a robot leaves this safe set, the idealized supervisor will intervene to assist, regardless of whether or not the robot remains objectively safe. False positives, where a human supervisor incorrectly judges a robot to be in danger, needlessly consume supervisor attention. In this work, we propose a method that decreases false positives by learning the supervisor's safe set and using that information to govern robot behavior. We prove that robots behaving according to our approach will reduce the occurrence of false positives for our idealized supervisor model. Furthermore, we empirically validate our approach with a user study that demonstrates a significant (p = 0.0328) reduction in false positives for our method compared to a baseline safety controller.


Title: Deep Semantic Lane Segmentation for Mapless Driving
Key Words: automobiles  feature extraction  image colour analysis  image segmentation  mobile robots  neural nets  object detection  path planning  road traffic  robot vision  deep semantic lane segmentation  autonomous driving systems  automated cars  sensor system  urban scenarios  deep neural network  lane semantics  road scene  mapless autonomous driving  street scenes  RGB images  lane detection  cityscapes dataset  Roads  Semantics  Neural networks  Image segmentation  Autonomous vehicles  Three-dimensional displays  Pipelines 
Abstract: In autonomous driving systems a strong relation to highly accurate maps is taken to be inevitable, although street scenes change frequently. However, a preferable system would be to equip the automated cars with a sensor system that is able to navigate urban scenarios without an accurate map. We present a novel pipeline using a deep neural network to detect lane semantics and topology given RGB images. On the basis of this classification, the information about the road scene can be extracted just from the sensor setup supporting mapless autonomous driving. In addition to superseding the huge effort of creating and maintaining highly accurate maps, our system reduces the need for precise localization. Using an extended Cityscapes dataset, we show accurate ego lane detection including lane semantics on challenging scenarios for autonomous driving.


Title: Closed-Loop Robot Task Planning Based on Referring Expressions
Key Words: adaptive control  closed loop systems  mobile robots  path planning  planning (artificial intelligence)  user interfaces  fetch-and-carry tasks  autonomous robots accessibility  user friendly  closed-loop robot task planning  complex task  automated planning  robotic systems  domain-independent planning system  goal formulation  referring expressions  adaptive control interface  manipulable objects  dynamic environments  Task analysis  Planning  Robots  Natural languages  Graphical user interfaces  Glass 
Abstract: Increasing the accessibility of autonomous robots also for inexperienced users requires user-friendly and high-level control opportunities of robotic systems. While automated planning is able to decompose a complex task into a sequence of steps which reaches an intended goal, it is difficult to formulate such a goal without knowing the internals of the planning system and the exact capabilities of the robot. This becomes even more important in dynamic environments in which manipulable objects are subject to change. In this paper, we present an adaptive control interface which allows users to specify goals based on an internal world model by incrementally building referring expressions to the objects in the world. We consider fetch-and-carry tasks and automatically deduce potential high-level goals from the world model to make them available to the user. Based on its perceptions our system can react to changes in the environment by adapting the goal formulation within the domain-independent planning system.


Title: Learning Robotic Grasping Strategy Based on Natural-Language Object Descriptions
Key Words: control engineering computing  dexterous manipulators  learning (artificial intelligence)  natural language processing  robotic grasping strategy  natural-language object descriptions  anthropomorphic robotic hand  natural-language descriptions  learning-based approach  natural language description  object features  natural-language processing technique  grasp type  human grasping taxonomy  AR10 robotic hand  Robots  Grasping  Taxonomy  Shape  Natural language processing  Kinematics  Task analysis 
Abstract: Given the description of an object, s physical attributes, humans can determine a proper strategy and grasp an object. This paper proposes an approach to determine grasping strategy for an anthropomorphic robotic hand simply based on natural-language descriptions of an object. A learning-based approach is proposed to help a robotic hand learn suitable grasp poses starting from the natural language description of the object. Object features are parsed from natural-language descriptions by using a customized natural-language processing technique. The most likely grasp type for the given object is learned from the human grasping taxonomy based on the parsed features. The grasping strategy generated by the proposed approach is evaluated both by simulation study and execution of the grasps on an AR10 robotic hand.


Title: PRISM: Pose Registration for Integrated Semantic Mapping
Key Words: mobile robots  multi-robot systems  navigation  pose estimation  service robots  SLAM (robots)  computer science department  modern SLAM algorithms  map data  tedious manual process  automatically generated maps  PRISM  semantic markup  pose registration  integrated semantic  robotics applications  hotel  room service  hospital  medication  patient  UT Austin  autonomous mobile robots  BWIBots  building-wide intelligence project  Robots  Semantics  Three-dimensional displays  Cameras  Two dimensional displays  Computational modeling  Navigation 
Abstract: Many robotics applications involve navigating to positions specified in terms of their semantic significance. A robot operating in a hotel may need to deliver room service to a named room. In a hospital, it may need to deliver medication to a patient's room. The Building-Wide Intelligence Project at UT Austin has been developing a fleet of autonomous mobile robots, called BWIBots, which perform tasks in the computer science department. Tasks include guiding a person, delivering a message, or bringing an object to a location such as an office, lecture hall, or classroom. The process of constructing a map that a robot can use for navigation has been simplified by modern SLAM algorithms. The attachment of semantics to map data, however, remains a tedious manual process of labeling locations in otherwise automatically generated maps. This paper introduces a system called PRISM to automate a step in this process by enabling a robot to localize door signs - a semantic markup intended to aid the human occupants of a building - and to annotate these locations in its map.


Title: 3D Deep Object Recognition and Semantic Understanding for Visually-Guided Robotic Service
Key Words: Bayes methods  convolutional neural nets  feature extraction  image reconstruction  learning (artificial intelligence)  neurocontrollers  object recognition  ontologies (artificial intelligence)  robot vision  service robots  semantic understanding  visually-guided robotic service  visually-guided robotic errand service  visual environments  deep learning architecture  FER-CNN  layer-wise independent feedback connections  reconstructed features  object categories  3D daily-life objects  recognition rate  ontology  feature extraction  3D deep object recognition  adaptive Bayesian recognition framework  Three-dimensional displays  Bayes methods  Robots  Object recognition  Deep learning  Feature extraction  Two dimensional displays 
Abstract: For the success of visually-guided robotic errand service, it is critical to ensure dependability under various ill-conditioned visual environments. To this end, we have developed Adaptive Bayesian Recognition Framework in which in-situ selection of multiple sets of optimal features or evidences as well as proactive collection of sufficient evidences are proposed to implement the principle of dependability. The framework has shown excellent performance with a limited number of objects in a scene. However, there arises a need to extend the framework for handling a larger number of objects without performance degradation, while avoiding difficulty in feature engineering. To this end, a novel deep learning architecture, referred to here as FER-CNN, is introduced and integrated into the Adaptive Bayesian Recognition Framework. FER-CNN has capability of not only extracting but also reconstructing a hierarchy of features with the layer-wise independent feedback connections that can be trained. Reconstructed features representing parts of 3D objects then allow them to be semantically linked to ontology for exploring object categories and properties. Experiments are conducted in a home environment with real 3D daily-life objects as well as with the standard ModelNet dataset. In particular, it is shown that FER-CNN allows the number of objects and their categories to be extended by 10 and 5 times, respectively, while registering the recognition rate for ModelNet10 and ModelNet40 by 97% and 89.5%, respectively.


Title: Semantic Mapping with Simultaneous Object Detection and Localization
Key Words: image sensors  mobile robots  object detection  particle filtering (numerical methods)  pose estimation  semantic mapping problem  CT-Map method  six degree-of-freedom pose  pose estimation  RGB-D sensor  Michigan progress fetch robot  particle filtering algorithm  CRF  conditional random field  contextual temporal mapping  object localization  object detection  Semantics  Object detection  Context modeling  Three-dimensional displays  Pose estimation  Simultaneous localization and mapping 
Abstract: We present a filtering-based method for semantic mapping to simultaneously detect objects and localize their 6 degree-of-freedom pose. For our method, called Contextual Temporal Mapping (or CT-Map), we represent the semantic map as a belief over object classes and poses across an observed scene. Inference for the semantic mapping problem is then modeled in the form of a Conditional Random Field (CRF). CT-Map is a CRF that considers two forms of relationship potentials to account for contextual relations between objects and temporal consistency of object poses, as well as a measurement potential on observations. A particle filtering algorithm is then proposed to perform inference in the CT-Map model. We demonstrate the efficacy of the CT-Map method with a Michigan Progress Fetch robot equipped with a RGB-D sensor. Our results demonstrate that the particle filtering based inference of CT-Map provides improved object detection and pose estimation with respect to baseline methods that treat observations as independent samples of a scene.


Title: Optimization-based Design and Analysis of Planar Rotary Springs
Key Words: actuators  finite element analysis  optimisation  robots  springs (mechanical)  torque  torsion  rotary series elastic actuator springs  rapid torsional loading  FEA  mechanical testing  planar rotary springs  optimization-based design method  robotics applications  Springs  Strain  Stress  Mathematical model  Robots  Actuators  Optimization 
Abstract: This paper develops new methods to design high performance rotary series elastic actuator springs for robotics applications. The approach is based on a spring arm mathematical model that was previously introduced by the authors. The key contribution is the development of an optimization-based design method which maximizes the springs' overall torque density through optimization of the arm profile. An improved analysis algorithm allows for rapid torsional loading response simulation with possible internal contacts between the spring arms. The proposed design and analysis algorithms are validated through FEA and prototype mechanical testing.


Title: Design of a 2 Motor 2 Degrees-of-Freedom Coupled Tendon-driven Joint Module
Key Words: actuators  control system synthesis  design engineering  mobile robots  position control  hybrid-actuated structure  internally-separately-actuated structure  internally-coaxially-actuated structure  externally-actuated structure  tendon coupling  torque reallocation  2 motor 2 degrees-of-freedom coupled tendon-driven joint module  anthropomorphic robot arm  2M2D coupled tendon-driven joint module  motor position  Pulleys  Tendons  Torque  Manipulators  Couplings  Routing 
Abstract: A 2 motor 2 degrees-of-freedom (2M2D) coupled tendon driven joint module is proposed as a basic component for robot arms. Torque reallocation via tendon coupling can enhance the output torque of one single joint. According to the motor position, the joint module is classified into four types: the externally-actuated structure, the internally-coaxially-actuated structure, the internally-separately-actuated structure, and the hybrid-actuated structure. The four structures are analyzed and compared, and their implementation design examples are given. Experiments comparing the proposed joint module with directly-actuated traditional joint suggested that the 2M2D coupled tendon-driven joint module can obtain high control accuracy, and the torque reallocation via tendon coupling is effective to improve output torque. Additionally, an anthropomorphic robot arm with low weight and high payload was developed to show the utility of the proposed joint module.


Title: A Differential Elastic Joint for Multi-linked Pipeline Inspection Robots
Key Words: actuators  elasticity  inspection  mobile robots  pipelines  pipes  rubber  service robots  springs (mechanical)  bi-directional series elasticity  series elastic actuators  slippery inner surfaces  vertical pipes  pipe wall  multilinked pipeline inspection robots  differential elastic joint  differential elastic actuator  active joint  in-pipe inspections  Springs  Gears  Torque  Robots  Wheels  Inspection  Actuators 
Abstract: This study presents a differential elastic joint for use in multi-linked pipeline inspection robots. Active joints to stretch against the pipe wall are essential for adapting robots to use in vertical pipes and slippery inner surfaces where a large traction force is required. Series elastic actuators with a high reduction system have typically been used to sense force/torque in such applications. However, compactness, power, and bi-directional series elasticity are required to conduct in-pipe inspections. In this study, we propose an active joint using a differential elastic actuator with a rubber spring for decreasing the size and increasing the stiffness of the joint. After describing the configuration of the differential elastic actuator that is suitable for our robot and the design theory of the rubber spring cross-section, we conducted experiments to verify its torque property.


Title: A Novel Design of Extended Coaxial Spherical Joint Module for a New Modular Type-Multiple DOFs Robotic Platform
Key Words: actuators  biomechanics  motion control  robot dynamics  robot kinematics  torque  design constraints  mechanical impedance reduction effect  E-CoSMo  extended coaxial spherical joint module  robot platform  coaxial spherical parallel mechanism  universal joint mechanism  mechanical performance  modular type-multiple DOFs robotic platform  single actuator  Conferences  Intelligent robots 
Abstract: In this study, we propose an extended coaxial spherical joint module (E-CoSMo) with three to four degrees of freedom (DOFs) for a multi-DOF robot platform. The E-CoSMo consists of a coaxial spherical parallel mechanism (CSPM) with three DOFs and one extended DOF based on a universal joint mechanism (UJM) coaxially connected to the CSPM. This structure enables the application of serial link configuration (such as shoulder-elbow) with wide and universal ROMs while allowing all four actuators to be placed in the base. This makes the inertia of the moving link part to be dramatically reduced and thus contributes to decreasing the mechanical impedance of the multi-DOF robot system. In addition, through the effective design of the coaxial spherical joint module, the output rotational torque in a specific axial direction reaches approximately three times then the torque of a single actuator. To optimally implement this, we applied an optimal design approach that considers the mechanical performance and design constraints. The mechanical impedance reduction effect through the proposed module is discussed. The feasibility of the E-CoSMo is also verified through a dynamic simulation. Finally, the proposed mechanism is verified using a fabricated prototype.


Title: A Novel Cable Actuation Mechanism for 2-DOF Hyper-redundant Bending Robot Composed of Pulleyless Rolling Joints
Key Words: actuators  buckling  cables (mechanical)  catheters  endoscopes  fixtures  medical robotics  motion control  production engineering computing  pulleys  redundant manipulators  surgery  three-dimensional printing  hyper-redundant bending robot composed  pulleyless rolling joint  surgical robots  wire cables  robot joints  miniature joint structure  cable driver design  3D printing  steerable endoscopes  Joints  Mechanical cables  Pulleys  Fasteners  Robots  Muscles  Hysteresis 
Abstract: Many surgical robots are remotely actuated by means of wire cables. In the past, the cables wound around circular pulleys at the robot joints did not constitute a problem of the cable driver structure. However, the pulleys inside the joints are removed recently in order to miniaturize the joints, so a specially designed cable driver suitable for the miniature joint structure is required for stable driving. In this paper, we propose a novel cable driver design for driving a pulleyless rolling joint and extend it to 2-DOF structure. Then, the proposed cable driver is manufactured using 3D printing with the 2-DOF bending joint, and an experiment is performed to evaluate them using the prototype. The cable driver proposed in this paper can drive pulleyless rolling joints stably with low cable tension. In addition, it can decouple yaw and pitch motion of the joints completely, therefore it can be applied to a variety of thin robots and instruments including steerable endoscopes and surgical robots.


Title: Design of Robotic Gripper with Constant Transmission Ratio Based on Twisted String Actuator: Concept and Evaluation
Key Words: actuators  grippers  industrial robots  materials handling  mobile robots  robots  twisted string actuator  robotic systems  object handling  manipulation  modern engineering  robustness  gripper design  exhibits nearly-constant transmission ratio  efficient robotic gripper  practical gripper  designed device  Grippers  Force  Actuators  Kinematics  Mathematical model  Service robots 
Abstract: Robotic systems for object handling and manipulation are hugely important for modern engineering and industry, with their efficiency, agility and robustness often depending on gripper design and performance. In this work, we investigate a gripper design that, when driven by a twisted string actuator, exhibits nearly-constant transmission ratio throughout its motion range. This allows for design of a highly-compact, modular and efficient robotic gripper driven by a low-power motor. We investigate kinematics of the device, experimentally verify developed models with a practical gripper testbed, and analyze transmission ratio and efficiency of the designed device. The resulting system has a nearly-constant transmission ratio of 550, with the constancy coefficient of 0.985.


Title: Stopper Angle Design for a Multi-link Articulated Wheeled In-pipe Robot with Underactuated Twisting Joints
Key Words: actuators  design engineering  drives  gears  mobile robots  motion control  pipes  robot kinematics  wheels  roll joint  single actuator  drive wheel  miter-geared differential mechanism  rear wheels  joint movement  helical movement  kinematic model  multilink articulated wheeled in-pipe robot  underactuated twisting joints  stopper angle design  roll angle  Mobile robots  Wheels  Robot kinematics  Kinematics  Pipelines  Actuators 
Abstract: In this paper, we present a multi-link articulated wheeled in-pipe robot that can drive the wheel and roll joint by using only a single actuator installed in each link. The proposed mechanism enables the robot to move forward or backward and helically in pipes owing to rotation of the drive wheel and twisting of the body. These two movements are generated by a miter-geared differential mechanism installed in each joint, and the magnitudes of these movements depend on the load applied to the wheels and roll joints. However, controlling of two outputs independently and aligning the rotation of the roll joints as desired are extremely challenging. Therefore, in this study, we switch those two movements by driving the rear wheels and the front wheels of the robot alternately. In addition, a stopper is used to constrain the roll joint movement. By calculating the angle of elevation of the robot's helical movement in the pipe by using a kinematic model, we can design a stopper to precisely adjust the roll angle. We verified that the robot can twist using the differential mechanism, and we validated experimentally the effectiveness of the stopper.


Title: Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning
Key Words: aerospace computing  aerospace robotics  aircraft control  control engineering computing  gradient methods  helicopters  learning (artificial intelligence)  mobile robots  robot vision  visual servoing  deep reinforcement learning algorithm  deep deterministic policy gradients  image-based visual servoing controller  IBVS policy  linear velocity commands  multirotor aerial robots  simulated flight scenarios  Gazebo-based simulation scenario  RL-IBVS controller  Visual servoing  Reinforcement learning  Unmanned aerial vehicles  Task analysis  Detectors  Cameras 
Abstract: In this paper, we propose a novel Image-Based Visual Servoing (IBVS) controller for multirotor aerial robots based on a recent deep reinforcement learning algorithm named Deep Deterministic Policy Gradients (DDPG). The proposed RL-IBVS controller is successfully trained in a Gazebo-based simulation scenario in order to learn the appropriate IBVS policy for directly mapping a state, based on errors in the image, to the linear velocity commands of the aerial robot. A thorough validation of the proposed controller has been conducted in simulated and real flight scenarios, demonstrating outstanding capabilities in object following applications. Moreover, we conduct a detailed comparison of the RL-IBVS controller with respect to classic and partitioned IBVS approaches.


Title: Perspective Correcting Visual Odometry for Agile MAVs using a Pixel Processor Array
Key Words: cameras  computer vision  distance measurement  image motion analysis  image sensors  sensor arrays  SCAMP-5 vision chip  Pixel Processor Array camera  visual odometry approach  agile MAVs  traditional image sensors  low frame rates  significant motion blur  motion capture system  direct comparison  PPA based approach  MAV  image alignment based odometry  perspective correction  HDR edge detection  computer vision tasks  Visual odometry  Cameras  Robot sensing systems  Arrays  Parallel processing  Visualization  Performance evaluation 
Abstract: This paper presents a visual odometry approach using a Pixel Processor Array (PPA) camera, specifically, the SCAMP-5 vision chip. In this device, each pixel is capable of storing data and performing computation, enabling a variety of computer vision tasks to be carried out directly upon the sensor itself. In this work the PPA performs HDR edge detection, perspective correction and image alignment based odometry, allowing the position and heading of a MAV to be tracked at several hundred frames per second. We evaluate our PPA based approach by direct comparison with a motion capture system for a variety of trajectories. These include rapid accelerations that would incur significant motion blur at low frame rates, and lighting conditions that would typically lead to under or over exposure of image detail. Such challenging conditions would often lead to unusable images when relying on traditional image sensors.


Title: C-blox: A Scalable and Consistent TSDF-based Dense Mapping Approach
Key Words: autonomous aerial vehicles  image reconstruction  image sensors  robot vision  SLAM (robots)  truncated signed distance field  TSDF subvolumes  lightweight micro aerial vehicle  scalable maps  map growth  bundle adjustment  feature-based camera tracking  dense 3D mapping  map consistency  delayed loop closure  accumulated camera tracking error  precise dense 3D maps  higher level decision making  robotic platforms  consistent dense map  Cameras  Simultaneous localization and mapping  Image reconstruction  Three-dimensional displays  Robot vision systems 
Abstract: In many applications, maintaining a consistent dense map of the environment is key to enabling robotic platforms to perform higher level decision making. Several works have addressed the challenge of creating precise dense 3D maps from visual sensors providing depth information. However, during operation over longer missions, reconstructions can easily become inconsistent due to accumulated camera tracking error and delayed loop closure. Without explicitly addressing the problem of map consistency, recovery from such distortions tends to be difficult. We present a novel system for dense 3D mapping which addresses the challenge of building consistent maps while dealing with scalability. Central to our approach is the representation of the environment as a collection of overlapping Truncated Signed Distance Field (TSDF) subvolumes. These subvolumes are localized through feature-based camera tracking and bundle adjustment. Our main contribution is a pipeline for identifying stable regions in the map, and to fuse the contributing subvolumes. This approach allows us to reduce map growth while still maintaining consistency. We demonstrate the proposed system on a publicly available dataset and simulation engine, and demonstrate the efficacy of the proposed approach for building consistent and scalable maps. Finally we demonstrate our approach running in real-time onboard a lightweight Micro Aerial Vehicle (MAV).


Title: Challenges of Autonomous Flight in Indoor Environments
Key Words: aircraft navigation  autonomous aerial vehicles  Global Positioning System  indoor navigation  sensors  indoor environments  GPS  velocity estimates  global navigation systems  drone research  indoor navigation  autonomous flight  onboard sensors  Indoor environments  Drones  Robots  Measurement  Global Positioning System  Collision avoidance  Cameras 
Abstract: Indoor navigation has been a major focus of drone research over the last few decades. The main reason for the term “indoor” came from the fact that in outdoor environments, drones could rely on global navigation systems such as GPS for their position and velocity estimates. By focusing on unknown indoor environments, the research had to focus on solutions using onboard sensors and processing. In this article, we present an overview of the state of the art and remaining challenges in this area, with a focus on small drones.


Title: A Deep Reinforcement Learning Technique for Vision-Based Autonomous Multirotor Landing on a Moving Platform
Key Words: attitude control  autonomous aerial vehicles  continuous systems  helicopters  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  robot vision  state-space methods  deep learning techniques  deep deterministic policy gradients algorithm  motion control  deep Q- learning  active domain  robotics-related tasks  multirotor control  attitude control  state space  continuous action space  deep reinforcement learning technique  vision-based autonomous multirotor landing maneuver  continuous state  continuous action domain  moving platform  Reinforcement learning  Unmanned aerial vehicles  Robots  Cameras  Aerospace electronics  Neural networks  Task analysis 
Abstract: Deep learning techniques for motion control have recently been qualitatively improved, since the successful application of Deep Q- Learning to the continuous action domain in Atari-like games. Based on these ideas, Deep Deterministic Policy Gradients (DDPG) algorithm was able to provide impressive results in continuous state and action domains, which are closely linked to most of the robotics-related tasks. In this paper, a vision-based autonomous multirotor landing maneuver on top of a moving platform is presented. The behaviour has been completely learned in simulation without prior human knowledge and by means of deep reinforcement learning techniques. Since the multirotor is controlled in attitude, no high level state estimation is required. The complete behaviour has been trained with continuous action and state spaces, and has provided proper results (landing at a maximum velocity of 2 m/s), Furthermore, it has been validated in a wide variety of conditions, for both simulated and real-flight scenarios, using a low-cost, lightweight and out-of-the-box consumer multirotor.


Title: Stereo Visual Odometry and Semantics based Localization of Aerial Robots in Indoor Environments
Key Words: distance measurement  image colour analysis  image segmentation  indoor environment  learning (artificial intelligence)  mobile robots  neural nets  object detection  particle filtering (numerical methods)  pose estimation  robot vision  SLAM (robots)  stereo image processing  indoor environments  particle filter localization approach  semantic information  mini-aerial robots  stereo VO algorithm  semantic measurements  pre-trained deep learning based object detector  3D point clouds  visual SLAM approach  stereo visual odometry  semantics based localization  DL  RGB spectrum  drift free pose estimation  Semantics  Three-dimensional displays  Unmanned aerial vehicles  Robots  Atmospheric measurements  Particle measurements  Prediction algorithms 
Abstract: In this paper we propose a particle filter localization approach, based on stereo visual odometry (VO) and semantic information from indoor environments, for mini-aerial robots. The prediction stage of the particle filter is performed using the 3D pose of the aerial robot estimated by the stereo VO algorithm. This predicted 3D pose is updated using inertial as well as semantic measurements. The algorithm processes semantic measurements in two phases; firstly, a pre-trained deep learning (DL) based object detector is used for real time object detections in the RGB spectrum. Secondly, from the corresponding 3D point clouds of the detected objects, we segment their dominant horizontal plane and estimate their relative position, also augmenting a prior map with new detections. The augmented map is then used in order to obtain a drift free pose estimate of the aerial robot. We validate our approach in several real flight experiments where we compare it against ground truth and a state of the art visual SLAM approach.


Title: Laser-Based Reactive Navigation for Multirotor Aerial Robots using Deep Reinforcement Learning
Key Words: autonomous aerial vehicles  collision avoidance  learning (artificial intelligence)  mobile robots  traditional motion planning algorithms  precise maps  fast reactive navigation algorithm  multirotor aerial robots  2D-laser range measurements  Gazebo-based simulation scenario  artificial potential field formulation  laser-based reactive navigation  collision avoidance capabilities  reactive navigation behavior  deep reinforcement learning  dynamic obstacles  static obstacles  Navigation  Robots  Unmanned aerial vehicles  Lasers  Heuristic algorithms  Reinforcement learning  Planning 
Abstract: Navigation in unknown indoor environments with fast collision avoidance capabilities is an ongoing research topic. Traditional motion planning algorithms rely on precise maps of the environment, where re-adapting a generated path can be highly demanding in terms of computational cost. In this paper, we present a fast reactive navigation algorithm using Deep Reinforcement Learning applied to multi rotor aerial robots. Taking as input the 2D-laser range measurements and the relative position of the aerial robot with respect to the desired goal, the proposed algorithm is successfully trained in a Gazebo-based simulation scenario by adopting an artificial potential field formulation. A thorough evaluation of the trained agent has been carried out both in simulated and real indoor scenarios, showing the appropriate reactive navigation behavior of the agent in the presence of static and dynamic obstacles.


Title: Drone Detection Using Depth Maps
Key Words: autonomous aerial vehicles  collision avoidance  image sensors  learning (artificial intelligence)  mobile robots  object detection  static obstacle avoidance  dynamic objects  field-of-view requirements  on-board small UAVs  relative altitude  azimuth  depth map-based approach  collision avoidance  depth map sequences  unmanned aerial vehicle navigation  collision-free path planning  FOV  deep learning-based drone detection model  sensing technologies  3D localization  Drones  Cameras  Three-dimensional displays  Atmospheric modeling  Sensors  Neural networks  Two dimensional displays 
Abstract: Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV) navigation. While solutions have been proposed for static obstacle avoidance, systems enabling avoidance of dynamic objects, such as drones, are hard to implement due to the detection range and field-of-view (FOV) requirements, as well as the constraints for integrating such systems on-board small UAVs. In this work, a dataset of 6k synthetic depth maps of drones has been generated and used to train a state-of-the-art deep learning-based drone detection model. While many sensing technologies can only provide relative altitude and azimuth of an obstacle, our depth map-based approach enables full 3D localization of the obstacle. This is extremely useful for collision avoidance, as 3D localization of detected drones is key to perform efficient collision-free path planning. The proposed detection technique has been validated in several real depth map sequences, with multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7 %, an average recall of 74.7 % and a record detection range of 9.5 meters.


Title: Real-Time Dance Generation to Music for a Legged Robot
Key Words: feedback  feedforward  humanoid robots  image motion analysis  legged locomotion  Markov processes  motion control  music  robot vision  synchronisation  music tempo  dance generation  feedforward delay controller  Markov chain  quadrupedal robot  robot whole-body controller reference input  feedback delay controller  time-shifting  delays  picked dance motion  base motions  stepping motions  dance motions  user-generated dance motion library  dance choreography  onboard microphone  live music  external stimuli  legged robot  Robot kinematics  Legged locomotion  Music  Delays  Trajectory  Real-time systems 
Abstract: The development of robots that can dance has received considerable attention. However, they are often either limited to a pre-defined set of movements and music or demonstrate little variance when reacting to external stimuli, such as microphone or camera input. In this paper, we contribute with a novel approach allowing a legged robot to listen to live music while dancing in synchronization with the music in a diverse fashion. This is achieved by extracting the beat from an onboard microphone in real-time, and subsequently creating a dance choreography by picking from a user-generated dance motion library at every new beat. Dance motions include various stepping and base motions. The process of picking from the library is defined by a probabilistic model, namely a Markov chain, that depends on the previously picked dance motion and the current music tempo. Finally, delays are determined online by time-shifting a measured signal and a reference signal, and minimizing the least squares error with the time-shift as parameter. Delays are then compensated for by using a combined feedforward and feedback delay controller which shifts the robot whole-body controller reference input in time. Results from experiments on a quadrupedal robot demonstrate the fast convergence and synchrony to the perceived music.


Title: Semantically Meaningful View Selection
Key Words: feature extraction  image classification  learning (artificial intelligence)  manipulators  neural nets  object recognition  pattern clustering  pose estimation  robot vision  meaningful view selection  high-level abstract tasks  lower-level concrete tasks  deep learning  image understanding  object recognition  robot sorting tasks  fixed top-down view  viewing angle  semantically informative view  semantic view selection  semantic knowledge  observed object  image dataset  semantic score  view image  camera  Cameras  Semantics  Robot vision systems  Task analysis  Feature extraction  Measurement 
Abstract: An understanding of the nature of objects could help robots to solve both high-level abstract tasks and improve performance at lower-level concrete tasks. Although deep learning has facilitated progress in image understanding, a robot's performance in problems like object recognition often depends on the angle from which the object is observed. Traditionally, robot sorting tasks rely on a fixed top-down view of an object. By changing its viewing angle, a robot can select a more semantically informative view leading to better performance for object recognition. In this paper, we introduce the problem of semantic view selection, which seeks to find good camera poses to gain semantic knowledge about an observed object. We propose a conceptual formulation of the problem, together with a solvable relaxation based on clustering. We then present a new image dataset consisting of around 10k images representing various views of 144 objects under different poses. Finally we use this dataset to propose a first solution to the problem by training a neural network to predict a “semantic score” from a top view image and camera pose. The views predicted to have higher scores are then shown to provide better clustering results than fixed top-down views.


Title: Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots
Key Words: aerospace control  autonomous aerial vehicles  dynamic programming  fires  learning (artificial intelligence)  Markov processes  Monte Carlo methods  optimal control  rescue robots  distributed deep reinforcement learning based strategy  UAVs  Markov decision process  deep RL approach  deep RL policy  forest sizes  simulated forest fire  unmanned aerial vehicles  aerial robots  Vegetation  Forestry  Sensors  Retardants  Monitoring  Lattices  Unmanned aerial vehicles 
Abstract: This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.


Title: Kitting in the Wild through Online Domain Adaptation
Key Words: learning (artificial intelligence)  object recognition  robot vision  visual perception  online adaptation algorithm  standard domain adaptation algorithms  batch-normalization layers  deep models  robot visual recognition algorithms  standard object recognition datasets  visual dataset  robotic kitting  vision systems  online domain adaptation  Robots  Adaptation models  Task analysis  Training  Data models  Visualization  Standards 
Abstract: Technological developments call for increasing perception and action capabilities of robots. Among other skills, vision systems that can adapt to any possible change in the working conditions are needed. Since these conditions are unpredictable, we need benchmarks which allow to assess the generalization and robustness capabilities of our visual recognition algorithms. In this work we focus on robotic kitting in unconstrained scenarios. As a first contribution, we present a new visual dataset for the kitting task. Differently from standard object recognition datasets, we provide images of the same objects acquired under various conditions where camera, illumination and background are changed. This novel dataset allows for testing the robustness of robot visual recognition algorithms to a series of different domain shifts both in isolation and unified. Our second contribution is a novel online adaptation algorithm for deep models, based on batch-normalization layers, which allows to continuously adapt a model to the current working conditions. Differently from standard domain adaptation algorithms, it does not require any image from the target domain at training time. We benchmark the performance of the algorithm on the proposed dataset, showing its capability to fill the gap between the performances of a standard architecture and its counterpart adapted offline to the given target domain.


Title: CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial Transformer Networks
Key Words: calibration  cameras  image processing  image sensors  learning (artificial intelligence)  optical radar  extrinsic calibration parameters  underlying geometric problem  photometric consistency  geometric consistency  camera calibration matrix K  LiDAR point cloud  calibration efforts  rigid body transformation  geometrically supervised deep network capable  calibration targets  calibration techniques  meaningful data  sensor rig  3D LiDAR  3D spatial transformer networks  geometrically supervised extrinsic calibration  Calibration  Three-dimensional displays  Cameras  Laser radar  Robot sensing systems  Training  Two dimensional displays 
Abstract: 3D LiDARs and 2D cameras are increasingly being used alongside each other in sensor rigs for perception tasks. Before these sensors can be used to gather meaningful data, however, their extrinsics (and intrinsics) need to be accurately calibrated, as the performance of the sensor rig is extremely sensitive to these calibration parameters. A vast majority of existing calibration techniques require significant amounts of data and/or calibration targets and human effort, severely impacting their applicability in large-scale production systems. We address this gap with CalibNet: a geometrically supervised deep network capable of automatically estimating the 6-DoF rigid body transformation between a 3D LiDAR and a 2D camera in real-time. CalibNet alleviates the need for calibration targets, thereby resulting in significant savings in calibration efforts. During training, the network only takes as input a LiDAR point cloud, the corresponding monocular image, and the camera calibration matrix K. At train time, we do not impose direct supervision (i.e., we do not directly regress to the calibration parameters, for example). Instead, we train the network to predict calibration parameters that maximize the geometric and photometric consistency of the input images and point clouds. CalibNet learns to iteratively solve the underlying geometric problem and accurately predicts extrinsic calibration parameters for a wide range of mis-calibrations, without requiring retraining or domain adaptation. The project page is hosted at https://epiception.github.io/CalibNet.


Title: Compact & Comprehensive Canonical Appearances Discovered Autonomously
Key Words: decision making  image representation  image sensors  learning (artificial intelligence)  mobile robots  path planning  robot vision  exploration approach  autonomous ground robot  depth sensor  bubble space representation  exploration path length  topological mapping  canonical appearances  appearance-based learning  Robot sensing systems  Decision making  Robot kinematics  Cognition  Lasers  Measurement 
Abstract: This paper presents an exploration approach for discovering canonical appearances in unknown environments using an autonomous ground robot equipped with a depth sensor. This approach is based on the previously proposed two-stage algorithm that alternates between local and global decision making for efficient topological mapping based on bubble space representation. Differing from it, the approach aims to identify vantage viewpoints with characterizing views for subsequent appearance-based learning as well as achieving complete coverage. This is demonstrated by a series of experiments using an outdoor benchmark data set including a comparative study with evaluation metrics including the exploration path length and number of canonical appearances discovered.


Title: Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision
Key Words: autonomous aerial vehicles  convolutional neural nets  image classification  learning (artificial intelligence)  mobile robots  path planning  probability  random processes  robot vision  target tracking  online search tasks  multitarget environments  dynamic targets  UAV-like vision  deep learning  dynamic search  strategic explorational agency  single deep network  navigational actions  dual-stream classification paradigm  sensory processing  agent location  static evolutions  dynamic evolutions  probabilistic placement  fully random target walks  herd-inspired behaviours  dual-stream architecture  unmanned aerial vehicle  convolutional neural network  multitarget behaviour classes  optimal navigational decision samples  long term map memory  Navigation  Robot sensing systems  Task analysis  History  Visualization  Vehicle dynamics  Reinforcement learning 
Abstract: This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish3 key source code and associated models.


Title: Hybrid Multi-camera Visual Servoing to Moving Target
Key Words: cameras  image sensors  position control  robot vision  stereo image processing  tracking  visual servoing  hybrid multicamera visual servoing  moving target  robotics  multiple visual sources  visual servoing approach  hybrid multicamera input data  robot arm  RGBD sensors  arm-mounted stereo camera  Eye-in-Hand  EtoH cameras  EinH sensor  EtoH sensors  adaptive visual input data  eye-to-hand visual input  Three-dimensional displays  Cameras  Visualization  Robot vision systems 
Abstract: Visual servoing is a well-known task in robotics. However, there are still challenges when multiple visual sources are combined to accurately guide the robot or occlusions appear. In this paper we present a novel visual servoing approach using hybrid multi-camera input data to lead a robot arm accurately to dynamically moving target points in the presence of partial occlusions. The approach uses four RGBD sensors as Eye-to-Hand (EtoH) visual input, and an arm-mounted stereo camera as Eye-in-Hand (EinH). A Master supervisor task selects between using the EtoH or the EinH, depending on the distance between the robot and target. The Master also selects the subset of EtoH cameras that best perceive the target. When the EinH sensor is used, if the target becomes occluded or goes out of the sensor's view-frustum, the Master switches back to the EtoH sensors to re-track the object. Using this adaptive visual input data, the robot is then controlled using an iterative planner that uses position, orientation and joint configuration to estimate the trajectory. Since the target is dynamic, this trajectory is updated every time-step. Experiments show good performance in four different situations: tracking a ball, targeting a bulls-eye, guiding a straw to a mouth and delivering an item to a moving hand. The experiments cover both simple situations such as a ball that is mostly visible from all cameras, and more complex situations such as the mouth which is partially occluded from some of the sensors.


Title: Detecting and Picking of Folded Objects with a Multiple Sensor Integrated Robot Hand
Key Words: control engineering computing  dexterous manipulators  image recognition  object detection  pressure sensors  robot vision  folded object  robotic picking  Suction Pinching Hand  proximity sensors  multiple sensor integrated robot hand  trial-and-error picking system  suction grasp  flex sensors  air pressure sensor  image recognition  Robot sensing systems  Uncertainty  Image recognition  Grippers  Hardware 
Abstract: Robotic picking of folded objects such as books is required for picking various objects. As a folded object is easily unfolded, it is difficult to carry it stably and place it in a desired pose due to its dangling part. For overcoming this difficulty, we propose a trial-and-error picking system using our Suction Pinching Hand, which can push the dangling part up with pinch grasp until the object lifted with suction grasp is folded. That system utilizes proximity sensors on the hand to predict whether folding will succeed with a current hand pose and decide whether to retry with another pose. Also, proximity sensors, flex sensors and an air pressure sensor are used to deal with uncertainty of the image recognition, the hand hardware and suction grasp. We evaluate our proposed system with experiments of picking and placing folded objects. It is confirmed that our proposed system realizes picking with the ability of our Suction Pinching Hand to carry folded objects stably and place them in desired poses. It is also proved that our proposed system is robust against the uncertainty.


Title: Information Sparsification in Visual-Inertial Odometry
Key Words: computational complexity  distance measurement  graph theory  mobile robots  SLAM (robots)  information sparsification  tightly couple visual measurements  inertial measurements  fixed-lag visual-inertial odometry framework  bound computational complexity  fixed-lag smoothers  densely connected linear  information-theoretic perspective  dense marginalization step  information content  nonlinear factor graph  information loss  information sparsity  VIO methods  EuRoC visual-inertial dataset  structural similarity  nonlinearity  computational complexity  Optimization  Markov processes  Microsoft Windows  Computational complexity  Cameras  Simultaneous localization and mapping  Visualization 
Abstract: In this paper, we present a novel approach to tightly couple visual and inertial measurements in a fixed-lag visual-inertial odometry (VIO) framework using information sparsification. To bound computational complexity, fixed-lag smoothers typically marginalize out variables, but consequently introduce a densely connected linear prior which significantly deteriorates accuracy and efficiency. Current state-of-the-art approaches account for the issue by selectively discarding measurements and marginalizing additional variables. However, such strategies are sub-optimal from an information-theoretic perspective. Instead, our approach performs a dense marginalization step and preserves the information content of the dense prior. Our method sparsifies the dense prior with a nonlinear factor graph by minimizing the information loss. The resulting factor graph maintains information sparsity, structural similarity, and nonlinearity. To validate our approach, we conduct real-time drone tests and perform comparisons to current state-of-the-art fixed-lag VIO methods in the EuRoC visual-inertial dataset. The experimental results show that the proposed method achieves competitive and superior accuracy in almost all trials. We include a detailed run-time analysis to demonstrate that the proposed algorithm is suitable for real-time applications.


Title: Towards Robust Visual Odometry with a Multi-Camera System
Key Words: cameras  distance measurement  image sampling  minimisation  photometry  pose estimation  position measurement  stereo image processing  robust visual odometry algorithm  robust VO algorithm  current pose tracker estimation  photometric error minimisation  plane-sweeping stereo cameras  near-infrared illumination  NIR illumination  single stereo configuration  multicamera setup  sliding window optimizer  sampled feature points  local mapper  multicamera system  Cameras  Tracking  Lighting  Visual odometry  Robot vision systems  Robustness  Simultaneous localization and mapping 
Abstract: We present a visual odometry (VO) algorithm for a multi-camera system and robust operation in challenging environments. Our algorithm consists of a pose tracker and a local mapper. The tracker estimates the current pose by minimizing photometric errors between the most recent keyframe and the current frame. The mapper initializes the depths of all sampled feature points using plane-sweeping stereo. To reduce pose drift, a sliding window optimizer is used to refine poses and structure jointly. Our formulation is flexible enough to support an arbitrary number of stereo cameras. We evaluate our algorithm thoroughly on five datasets. The datasets were captured in different conditions: daytime, night-time with near-infrared (NIR) illumination and nighttime without NIR illumination. Experimental results show that a multi-camera setup makes the VO more robust to challenging environments, especially night-time conditions, in which a single stereo configuration fails easily due to the lack of features.


Title: Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition
Key Words: entropy  feature extraction  geometry  image matching  image recognition  learning (artificial intelligence)  mobile robots  octrees  optical radar  robot vision  unsupervised learning  Generative Adversarial Network  adversarial feature  place recognition  global geometry map  Conditional Entropy Reduction module  unsupervised place feature  local 2D maps  dynamic octree mapping module  core modules  LiDAR inputs  end-to-end feature  geometry matching  traditional methods  LiDAR-based place recognition  unsupervised feature learning  feature size  place recognition task  North Campus Long-Term LiDAR dataset  feature learning process  place feature learning  Octrees  Laser radar  Task analysis  Decoding  Simultaneous localization and mapping  Generative adversarial networks 
Abstract: Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.


Title: DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments
Key Words: mobile robots  object detection  path planning  robot vision  SLAM (robots)  high-dynamic environments  ORB-SLAM2  dense semantic octo-tree map  dynamic objects  DS-SLAM combines semantic segmentation network  dense semantic map creation  local mapping  robust semantic visual SLAM  impressed SLAM systems  Semantics  Simultaneous localization and mapping  Image segmentation  Feature extraction  Heuristic algorithms  Three-dimensional displays  Optical flow 
Abstract: Simultaneous Localization and Mapping (SLAM) is considered to be a fundamental capability for intelligent mobile robots. Over the past decades, many impressed SLAM systems have been developed and achieved good performance under certain circumstances. However, some problems are still not well solved, for example, how to tackle the moving objects in the dynamic environments, how to make the robots truly understand the surroundings and accomplish advanced tasks. In this paper, a robust semantic visual SLAM towards dynamic environments named DS-SLAM is proposed. Five threads run in parallel in DS-SLAM: tracking, semantic segmentation, local mapping, loop closing and dense semantic map creation. DS-SLAM combines semantic segmentation network with moving consistency check method to reduce the impact of dynamic objects, and thus the localization accuracy is highly improved in dynamic environments. Meanwhile, a dense semantic octo-tree map is produced, which could be employed for high-level tasks. We conduct experiments both on TUM RGB-D dataset and in real-world environment. The results demonstrate the absolute trajectory accuracy in DS-SLAM can be improved one order of magnitude compared with ORB-SLAM2. It is one of the state-of-the-art SLAM systems in high-dynamic environments.


Title: A robust pose graph approach for city scale LiDAR mapping
Key Words: graph theory  image filtering  image reconstruction  Kalman filters  mobile robots  nonlinear filters  optical radar  optimisation  pose estimation  radar imaging  robot vision  SLAM (robots)  map quality  quantitative experimental results  robust optimization strategy  systematical initialization bias  factor graph  refined structure  urban environments  multitask acquisitions  scan-matching factors  graph optimization  cumulative drift  city scale LiDAR mapping  robust pose graph approach  Optimization  Three-dimensional displays  Laser radar  Global Positioning System  Feature extraction  Sensors  Urban areas 
Abstract: This paper presents a method for reconstructing globally consistent 3D High-Definition (HD) maps at city scale. Current approaches for eliminating cumulative drift are mainly based on the pose graph optimization under the constraint of scan-matching factors. The misaligned edges in the graph may have negative impacts on the results. To address this problem and further handle inconsistency caused by multi-task acquisitions in urban environments, we introduce a refined structure of the factor graph considering systematical initialization bias, where the scan-matching factors are twice validated through a novel classifier and a robust optimization strategy. In addition, we incorporate a multi-hypothesis extended Kalman filter (MH-EKF) to remove dynamic objects. Quantitative experimental results demonstrate that the proposed method outperforms state-of-the-art techniques in terms of map quality.


Title: Good Feature Selection for Least Squares Pose Optimization in VO/VSLAM
Key Words: computational complexity  control engineering computing  feature extraction  least squares approximations  optimisation  pose estimation  robot vision  SLAM (robots)  least squares pose optimization  pose estimation  pose tracking  NP-hard Max-logDet problem  feature selection  VO-VSLAM  integrating Max-logDet feature selection  Feature extraction  Optimization  Pose estimation  Simultaneous localization and mapping  Measurement uncertainty  Approximation algorithms 
Abstract: This paper aims to select features that contribute most to the pose estimation in VO/VSLAM. Unlike existing feature selection works that are focused on efficiency only, our method significantly improves the accuracy of pose tracking, while introducing little overhead. By studying the impact of feature selection towards least squares pose optimization, we demonstrate the applicability of improving accuracy via good feature selection. To that end, we introduce the Max-logDet metric to guide the feature selection, which is connected to the conditioning of least squares pose optimization problem. We then describe an efficient algorithm for approximately solving the NP-hard Max-logDet problem. Integrating Max-logDet feature selection into a state-of-the-art visual SLAM system leads to accuracy improvements with low overhead, as demonstrated via evaluation on a public benchmark.


Title: Dynamic Scaling Factors of Covariances for Accurate 3D Normal Distributions Transform Registration
Key Words: covariance analysis  image registration  iterative methods  normal distribution  stereo image processing  transforms  NDT-D2D  3D normal distributions transform registration  distribution-to-distribution normal distributions transform  PNDT-D2D  distribution-to-distribution probabilistic NDT  objective function  fast point set registrations  dynamic scaling factors  Linear programming  Gaussian distribution  Correlation  Probabilistic logic  Three-dimensional displays  Transforms  Robots 
Abstract: Distribution-to-distribution normal distributions transform (NDT-D2D) is one of the fast point set registrations. Since the normal distributions transform (NDT) is a set of normal distributions generated by discrete and regular cells, local minima of the objective function is an issue of NDT-D2D. Also, we found that the objective function based on L2 distance between distributions has a negative correlation with rotational alignment. To overcome the problems, we present a method using dynamic scaling factors of covariances to improve the accuracy of NDT-D2D. Two scaling factors are defined for the preceding and current NDTs respectively, and they are dynamically varied in each iteration of NDT-D2D. We implemented the proposed method based on conventional NDT-D2D and probabilistic NDT-D2D and compared to the NDT-D2D with fixed scaling factors using KITTI benchmark data set. Also, we experimented estimating odometry with an initial guess as an application of distribution-to-distribution probabilistic NDT (PNDT-D2D) with the proposed method. As a result, the proposed method improves both translational and rotational accuracy of the NDT-D2D and PNDT-D2D.


Title: HMAPs - Hybrid Height- Voxel Maps for Environment Representation
Key Words: mobile robots  optical radar  path planning  robot vision  SLAM (robots)  2.5D representation  Microsoft Kinect One  SLAM approach  complex elements  Velodyne VLP-16 LiDAR  updated grid representation  complex environments  reliable method  occupied space  free space  HVoxel  height-voxel elements  3D point-clouds  mobile robot  grid-based mapping approach  environment representation  hybrid height- voxel maps  HMAP  Two dimensional displays  Three-dimensional displays  Simultaneous localization and mapping  Pipelines  Ray tracing  Planning  Indexing 
Abstract: This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.


Title: Kalman Filter Based Observer for an External Force Applied to Medium-sized Humanoid Robots
Key Words: force sensors  humanoid robots  Kalman filters  legged locomotion  medium-sized humanoid robot  external force observer  force/torque sensors  small robots  medium-sized humanoid robots  robot structure  Kalman filter formulation  force components  robot hardware  robot inertial measurement unit  Nao humanoid robot  external force  force-sensing resistors  Force  Humanoid robots  Robot sensing systems  Observers  Force measurement 
Abstract: External force observer for humanoid robots has been widely studied in the literature. However, most of the proposed approaches generally rely on information from six-axis force/torque sensors, which the small or medium-sized humanoid robots usually do not have. As a result, those approaches cannot be applied to this category of humanoid robots, which is widely used nowadays in education or research. In this paper, we improve the external force observer in [1] to handle the case of an external force applied in any direction and at an arbitrary point of the robot structure. The new observer is based on Kalman filter formulation and it allows the estimation of the three force components. The observer is simple to implement and can easily run in real time using the embedded processor of a medium-sized humanoid robot such as Nao or Darwin-OP. Moreover, the observer does not require any change to the robot hardware as it only uses measurements from the available force-sensing resistors (FSR) inserted under the feet of the humanoid robot and from the robot inertial measurement unit (IMU). The proposed observer was extensively validated on a Nao humanoid robot. In all conducted experiments, the observer successfully estimated the external force within a reasonable margin of error.


Title: CPG-based Controllers can Generate Both Discrete and Rhythmic Movements
Key Words: human-robot interaction  motion control  neural net architecture  neurocontrollers  three-term control  CPG-based controllers  discrete movements  rhythmic movements  bio-inspired robot controller  oscillating neurons  PID controller  handshaking  Task analysis  Neurons  Oscillators  Manipulators  Grippers  Intelligent robots 
Abstract: Complex tasks require the combination of both discrete and rhythmic movements. Though scientists do not yet agree on the neural architecture involved in both types and in the transition from one to the other, the importance of having robot controllers able to behave rhythmically and discretely is universally recoanized. In this paper, a bio-inspired robot controller based on oscillating neurons is proposed to realize both discrete and rhythmic movements and easily transition from one to the other. It is shown that, under certain parameter conditions, the CPG controller behaves like a PID controller. In order to demonstrate the feasibility of controlling both discrete and rhythmic movements, the CPG is applied to the initiation of handshaking, namely, reach towards the human hand and start to shake it. Results show that this architecture is suitable for both discrete and rhythmic movements and can easily transition from one to the other.


Title: A 3D Template Model for Healthy and Impaired Walking
Key Words: biomechanics  elasticity  gait analysis  legged locomotion  motion control  muscle  nonlinear control systems  pendulums  robot dynamics  springs (mechanical)  3D template model  modeling studies  neuromuscular control  impaired unperturbed gaits  human strategies  lateral asymmetries  experimental studies  stance time relations  stroke patients  bipedal SLIP  spring-loaded inverted pendulum  pathologic gaits  modulated compliant hip  VBLA model  velocity based leg adjustment  asymmetric leg  control parameters  similar gait patterns  hip stiffness  rest angles  FMCH models  Legged locomotion  Three-dimensional displays  Mathematical model  Solid modeling  Hip  Biological system modeling  Springs 
Abstract: Several modeling studies, which address neuromuscular control in impaired unperturbed gaits, were performed to predict human strategies to cope with lateral asymmetries in the body. Experimental studies show different step length and stance time relations between limbs in walking of stroke patients. By extension of a bipedal SLIP (spring-loaded inverted pendulum) based model and the corresponding controllers to 3D space, we focus on different features of the pathologic gaits. The introduced model is based on an extension of the FMCH (force modulated compliant hip) and VBLA (velocity based leg adjustment) model to 3D space. With the proposed model, asymmetric leg and control parameters can result in similar gait patterns as observed in experiments. These parameters comprise hip stiffness and rest angles in FMCH models and the tuning parameter of VBLA for foot placement. It is shown that asymmetries in muscle properties (e.g. stiffness) and leg adjustment can play an important role in generating pathologic gaits.


Title: Exploiting Friction in Torque Controlled Humanoid Robots
Key Words: friction  humanoid robots  motion control  robot dynamics  stability  torque control  torque controlled humanoid robots  common architecture  nested loops  joint/motor torques  joint friction phenomena  high level control objectives  joint task space control  humanoid robot iCub  stabilizing property  Friction  Brushless motors  Humanoid robots  Task analysis  Robot sensing systems  Robot kinematics 
Abstract: A common architecture for torque controlled humanoid robots consists in two nested loops. The outer loop generates desired joint/motor torques, and the inner loop stabilizes these desired values. In doing so, the inner loop usually compensates for joint friction phenomena, thus removing their inherent stabilizing property that may be also beneficial for high level control objectives. This paper shows how to exploit friction for joint and task space control of humanoid robots. Experiments are carried out on the humanoid robot iCub.


Title: Structure preserving Multi-Contact Balance Control for Series-Elastic and Visco-Elastic Humanoid Robots
Key Words: actuators  elasticity  humanoid robots  legged locomotion  predictive control  robot dynamics  visco-elastic humanoid robots  actuator control  multicontact balancing  force distribution problem  actuator dynamics  dynamically consistent force distribution  model predictive controller  contact force  actuator constraints  multicontact balance control  series-elastic humanoid robos  structure preservation control concept  locomotion  Force  Actuators  Robot kinematics  Dynamics  Task analysis  Humanoid robots 
Abstract: This paper proposes an integration of multi-body and actuator control for multi-contact balancing for robots with highly elastic joints. Inspired by the structure preserving control concept for series-elastic fixed-base robots, the presented approach aims to minimize the control effort by keeping the system structure intact. Balancing on multiple contacts requires to solve the force distribution problem. In locomotion, contacts change quickly, requiring a swift redistribution of contact forces. This is a challenge for elastic robots as the actuator dynamics and limits prevent instantaneous changes of contact forces. The proposed dynamically consistent force distribution is implemented as a model predictive controller which resolves redundancy while complying with contact force and actuator constraints.


Title: Feedback Control For Cassie With Deep Reinforcement Learning
Key Words: feedback  learning (artificial intelligence)  legged locomotion  Markov processes  motion control  robot dynamics  velocity control  Cassie  deep reinforcement learning  bipedal locomotion skills  local linearization  reduced-order abstractions  tractable solutions  model-based control strategies  torque limits  joint limits  nonlinearities  control computations  DRL  machine learning literature  ad-hoc simulation models  realizable bipedal robots  feedback control problem  robust walking controllers  controller robustness  model-free approach  Legged locomotion  Reinforcement learning  Computational modeling  Aerospace electronics  Feedback control  Trajectory 
Abstract: Bipedal locomotion skills are challenging to develop. Control strategies often use local linearization of the dynamics in conjunction with reduced-order abstractions to yield tractable solutions. In these model-based control strategies, the controller is often not fully aware of many details, including torque limits, joint limits, and other non-linearities that are necessarily excluded from the control computations for simplicity. Deep reinforcement learning (DRL) offers a promising model-free approach for controlling bipedal locomotion which can more fully exploit the dynamics. However, current results in the machine learning literature are often based on ad-hoc simulation models that are not based on corresponding hardware. Thus it remains unclear how well DRL will succeed on realizable bipedal robots. In this paper, we demonstrate the effectiveness of DRL using a realistic model of Cassie, a bipedal robot. By formulating a feedback control problem as finding the optimal policy for a Markov Decision Process, we are able to learn robust walking controllers that imitate a reference motion with DRL. Controllers for different walking speeds are learned by imitating simple time-scaled versions of the original reference motion. Controller robustness is demonstrated through several challenging tests, including sensory delay, walking blindly on irregular terrain and unexpected pushes at the pelvis. We also show we can interpolate between individual policies and that robustness can be improved with an interpolated policy.


Title: Robust and Stretched-Knee Biped Walking Using Joint-Space Motion Control
Key Words: humanoid robots  legged locomotion  motion control  robot kinematics  robust control  IK based motion control  kinematics singularity problem  motion optimization method  human-like walking motion  SIMBICON  inverse kinematics  joint-space motion control  stretched-knee biped walking  walking robustness  simple biped locomotion control  Legged locomotion  Foot  Torque  Optimization  Robustness  Knee 
Abstract: Comparing to IK (Inverse Kinematics) based motion control, joint-space motion control is more advantageous in terms of not being restricted by kinematics singularity problem. In this paper, we start with SIMBICON (Simple Biped Locomotion Control) based controller, a joint-space motion control method, extend it for enhancing walking's robustness and versatility. We propose a motion optimization method considering walking robustness, desired walking velocity and energy efficient minimization for walking motion generation. This method enables us to achieve human-like walking motion, which has stretched-knee posture and robust to large push disturbances. We also apply our proposed method to a life-sized biped robot and validate its effectiveness with push recovery and walking on unknown debris experiments.


Title: Public perception of android robots: Indications from an analysis of YouTube comments
Key Words: control engineering computing  data mining  humanoid robots  human-robot interaction  learning (artificial intelligence)  public administration  social networking (online)  text analysis  end-users  Youtube comments  social perception indication  machine learning  text mining  rendering interactions  textual reactions  video stimuli  technical specification  science fiction valley  public perception  human-robot relationships  robotic society  quantitative content analysis  android robots  YouTube  Videos  Androids  Humanoid robots  Clustering algorithms  Text mining 
Abstract: The public perception of android robots is a field of growing applied relevance. Currently, most androids are confined within controlled environments rendering interactions between potential end-users, and robots challenging. Even more challenging is for researchers to investigate end-users' perception of androids. We exploit pre-existing YouTube comments as artifacts for quantitative content analysis to gain an indication of social perception on androids. We perform a content analysis of 10301 YouTube comments from four different videos, and reflect on the textual reactions to video stimuli of four extremely human-like android robots. We use text mining and machine learning techniques to process and analyze our corpus. Our findings reveal three equally important topics that should be considered for paving the way towards a robotic society: human-robot relationships, technical specifications, and the science fiction valley. Considering people's attitudes, fears and wishes towards androids, researchers can increase citizen awareness, and engagement.


Title: Towards Automatic 3D Shape Instantiation for Deployed Stent Grafts: 2D Multiple-class and Class-imbalance Marker Segmentation with Equally-weighted Focal U-Net
Key Words: blood vessels  cardiovascular system  image registration  image segmentation  medical image processing  mobile robots  path planning  stents  focal loss function  fluoroscopy projection  robot-assisted fenestrated endovascular aortic repair  automatic 3D shape instantiation  focal u-net  multiple class marker segmentation  multiple class marker center determination  robust perspective-S-point method  tensorflow codes  mean intersection over union  weighted u-net  network architecture  graft gap interpolation  stent graft  semiautomatic 3D shape instantiation method  FEVAR  class-imbalance marker segmentation  initial marker segmentation  fluoroscopy projections  Image segmentation  Shape  Three-dimensional displays  Aneurysm  Training  Two dimensional displays  Testing 
Abstract: Robot-assisted Fenestrated Endovascular Aortic Repair (FEVAR) is currently navigated by 2D fluoroscopy which is insufficiently informative. Previously, a semi-automatic 3D shape instantiation method was developed to instantiate the 3D shape of a main, deployed, and fenestrated stent graft from a single fluoroscopy projection in real-time, which could help 3D FEVAR navigation and robotic path planning. This proposed semi-automatic method was based on the Robust Perspective-S-Point (RP5P) method, graft gap interpolation and semiautomatic multiple-class marker center determination. In this paper, an automatic 3D shape instantiation could be achieved by automatic multiple-class marker segmentation and hence automatic multiple-class marker center determination. Firstly, the markers were designed into five different shapes. Then, Equally-weighted Focal U-Net was proposed to segment the fluoroscopy projections of customized markers into five classes and hence to determine the marker centers. The proposed Equally-weighted Focal U-Net utilized U-Net as the network architecture, equally-weighted loss function for initial marker segmentation, and then equally-weighted focal loss function for improving the initial marker segmentation. This proposed network outperformed traditional Weighted U-Net on the class-imbalance segmentation in this paper with reducing one hyperparameter - the weight. An overall mean Intersection over Union (mIoU) of 0.6943 was achieved on 78 testing images, where 81.01 % markers were segmented with a center position error <; 1.6mm. Comparable accuracy of 3D shape instantiation was also achieved and stated. The data, trained models and TensorFlow codes are available on-line.


Title: A Confidence-Based Shared Control Strategy for the Smart Tissue Autonomous Robot (STAR)
Key Words: biological tissues  blood  medical robotics  mobile robots  surgery  confidence-based shared control strategy  STAR  surgery systems  robotic accuracy  surgical procedures  complex surgical environments  surgical scenarios  cutting pattern  robotic electrocautery tool  surgical task  confidence models  confidence-based control allocation function  autonomous robot controller  smart tissue autonomous robot  autonomous robotic assisted surgery  2D pattern cutting  Robots  Trajectory  Task analysis  Surgery  Human factors  Cameras  Blood 
Abstract: Autonomous robotic assisted surgery (RAS) systems aim to reduce human errors and improve patient outcomes leveraging robotic accuracy and repeatability during surgical procedures. However, full automation of RAS in complex surgical environments is still not feasible and collaboration with the surgeon is required for safe and effective use. In this work, we utilize our Smart Tissue Autonomous Robot (STAR) to develop and evaluate a shared control strategy for the collaboration of the robot with a human operator in surgical scenarios. We consider 2D pattern cutting tasks with partial blood occlusion of the cutting pattern using a robotic electrocautery tool. For this surgical task and RAS system, we i) develop a confidence-based shared control strategy, ii) assess the pattern tracking performances of manual and autonomous controls and identify the confidence models for human and robot as well as a confidence-based control allocation function, and iii) experimentally evaluate the accuracy of our proposed shared control strategy. In our experiments on porcine fat samples, by combining the best elements of autonomous robot controller with complementary skills of a human operator, our proposed control strategy improved the cutting accuracy by 6.4%, while reducing the operator work time to 44% compared to a pure manual control.


Title: Magnetic- Visual Sensor Fusion-based Dense 3D Reconstruction and Localization for Endoscopic Capsule Robots
Key Words: biomedical optical imaging  cameras  endoscopes  image fusion  image reconstruction  medical image processing  medical robotics  robot vision  visual sensor fusion-based dense 3D reconstruction  real-time 3D reconstruction  actively controlled capsule endoscopic robots  minimally invasive diagnostic technology  therapeutic technology  gastrointestinal tract  intraoperative map fusion approach  actively controlled endoscopic capsule robot applications  magnetic vision-based localization  nonrigid deformations  frame-to-model map fusion  ex-vivo porcine stomach models  root mean square surface reconstruction errors  endoscopic camera  Magnetic resonance imaging  Robot sensing systems  Magnetic separation  Three-dimensional displays  Cameras  Endoscopes 
Abstract: Reliable and real-time 3D reconstruction and localization functionality is a crucial prerequisite for the navigation of actively controlled capsule endoscopic robots as an emerging, minimally invasive diagnostic and therapeutic technology for use in the gastrointestinal (GI) tract. In this study, we propose a fully dense, non-rigidly deformable, strictly real-time, intraoperative map fusion approach for actively controlled endoscopic capsule robot applications which combines magnetic and vision-based localization, with non-rigid deformations based frame-to-model map fusion. The performance of the proposed method is evaluated using four different ex-vivo porcine stomach models. Across different trajectories of varying speed and complexity, and four different endoscopic cameras, the root mean square surface reconstruction errors vary from 1.58 to 2.17 cm.


Title: Robust Generalized Point Cloud Registration with Expectation Maximization Considering Anisotropic Positional Uncertainties
Key Words: expectation-maximisation algorithm  Gaussian distribution  image registration  matrix algebra  optimisation  anisotropic positional uncertainties  E-step  correspondence probabilities  M-step  transformation matrix  constrained optimization problem  expectation conditional maximization framework  multivariate Gaussian distribution  positional error  generalized point cloud registration problem  computer-assisted surgery  medical robotics  robust generalized point cloud registration  Three-dimensional displays  Hidden Markov models  Covariance matrices  Surgery  Optimization  Mixture models  Linear programming 
Abstract: Alignment of two point clouds is an essential problem in medical robotics and computer-assisted surgery. In this paper, we first formally formulate the generalized point cloud registration problem in a probabilistic manner. Specifically, not only positional but also the orientational information are incorporated into registration. Notably, the positional error is assumed to obey a multivariate Gaussian distribution to accommodate anisotropic cases. Expectation conditional maximization framework is utilized to solve the problem. In E-step, the correspondence probabilities between points in two generalized point clouds are computed. In M -step, the constrained optimization problem with respect to the transformation matrix is re-formulated as an unconstrained one. Extensive experiments are conducted to compare the proposed algorithm with the state-of-the-art registration methods. The experimental results demonstrate the algorithm's robustness to noise and outliers, fast convergence speed.


Title: Vision-Based Surgical Tool Pose Estimation for the da Vinci® Robotic Surgical System
Key Words: Bayes methods  computer vision  endoscopes  medical image processing  medical robotics  particle filtering (numerical methods)  pose estimation  rendering (computer graphics)  robot vision  stereo image processing  surgery  virtual reality  robot endoscopes  defined tool geometry  virtual images  silhouette rendering algorithm  Bayesian state estimation  computer vision techniques  robot kinematics  stereo vision  vision-based Surgical tool pose estimation  surgical robotic system  surgical tool tracking  endoscopic stereo image streams  virtual rendering method  Tools  Solid modeling  Rendering (computer graphics)  Robots  Cameras  Bayes methods  Geometry 
Abstract: This paper presents an approach to surgical tool tracking using stereo vision for the da Vinci® Surgical Robotic System. The proposed method is based on robot kinematics, computer vision techniques and Bayesian state estimation. The proposed method employs a silhouette rendering algorithm to create virtual images of the surgical tool by generating the silhouette of the defined tool geometry under the da Vinci® robot endoscopes. The virtual rendering method provides the tool representation in image form, which makes it possible to measure the distance between the rendered tool and real tool from endoscopic stereo image streams. Particle Filter algorithm employing the virtual rendering method is then used for surgical tool tracking. The tracking performance is evaluated on an actual da Vinci® surgical robotic system and a ROS/Gazebo-based simulation of the da Vinci® system.


Title: A Parallel Robotic Mechanism for the Stabilization and Guidance of an Endoscope Tip in Laser Osteotomy
Key Words: bone  endoscopes  laser applications in medicine  medical robotics  orthopaedics  surgery  parallel robotic mechanism  laser osteotomy  endoscope tip stabilization  robot-assisted minimally invasive laser osteotome  robust platform  sub-millimeter range  endoscope tip motion  Endoscopes  Bones  Laser beam cutting  Rails  Kinematics  End effectors 
Abstract: This paper presents a parallel robotic mechanism for endoscope tip stabilization and guidance for a robot-assisted minimally invasive laser osteotome. The mechanism attaches to the bone of the patient, providing a stable and robust platform for the laser integrated in the endoscope tip which has to be moved precisely in the sub-millimeter range along a preoperatively planned path. This method is only possible because cutting bone with laser instead of using conventional bone drills and saws involves considerably lower interaction forces. The design, kinematics, control, and motion performance of the concept are presented for an upscaled prototype. The obtained deviation of the endoscope tip motion from the reference path lies in the sub-millimeter range. This result allows us to conclude that the concept is more than promising. Furthermore, we expect that the herein presented principle will influence the way osteotomies will be performed in the future.


Title: RoboTracker: Collaborative robotic assistant device with electromechanical patient tracking for spinal surgery
Key Words: biomechanics  bone  medical robotics  neurophysiology  orthopaedics  surgery  RoboTracker  electromechanical patient tracking  spinal surgery  neural damage  spinal surgical procedures  pedicle screw fixation  technological improvements  surgeons  optical tracking navigation  stringent limitation  tracked elements  miniature robot  novel robotic assisted surgery system  surgical instruments  patient motion  electromechanical tracking device  collaborative robotic assistant device  Fasteners  Tracking  Surgery  Robot kinematics  Kinematics  Mathematical model 
Abstract: Due to the risks of muscle, bone and neural damage in spinal surgical procedures that require pedicle screw fixation, technological improvements have appeared to help surgeons perform the procedures with higher accuracy. Systems based on optical tracking navigation impose a stringent limitation in the workflow of surgeons since a clear line of sight has to be kept between the cameras and the tracked elements. Other solutions are based on mounting a miniature robot on the spine of the patient, which is very invasive and entails some risks. For these reasons, a novel robotic assisted surgery system capable to guide surgical instruments with minimal deviations compensating patient motion is being developed. This paper presents the system and the electromechanical tracking device used to sense patient motion.


Title: A Sliding Mode Control Architecture for Human-Manipulator Cooperative Surface Treatment Tasks
Key Words: control engineering computing  deburring  end effectors  force sensors  industrial manipulators  industrial robots  mobile robots  motion control  multi-robot systems  position control  variable structure systems  redundant 7R manipulator  robotic surface treatment  novel collaborative controller  robot motion  robotic tool  conditioning task  robot end-effector  surface treatment tool  nonconventional sliding mode control  task prioritization  control scheme  autonomous physical agent  human operator propioceptive abilities  shared strategy effectively couples  robotic manipulator partner  physical strength  surface treatment tasks  human-manipulator  sliding mode control architecture  Robot sensing systems  Surface treatment  Task analysis  Tools  Surface morphology  Manipulators 
Abstract: This paper presents a control architecture readily suitable for surface treatment tasks such as polishing, grinding, finishing or deburring as carried out by a human operator, with the added benefit of accuracy, recurrence and physical strength as administered by a robotic manipulator partner. The shared strategy effectively couples the human operator propioceptive abilities and fine skills through his interactions with the autonomous physical agent. The novel proposed control scheme is based on task prioritization and a non-conventional sliding mode control, which is considered to benefit from its inherent robustness and low computational cost. The system relies on two force sensors, one located between the last link of the robot and the surface treatment tool, and the other located in some place of the robot end-effector: the former is used to suitably accomplish the conditioning task, while the latter is used by the operator to manually guide the robotic tool. When the operator chooses to cease guiding the tool, the robot motion safely switches back to an automatic reference tracking. The paper presents the theories for the novel collaborative controller, whilst its effectiveness for robotic surface treatment is substantiated by experimental results using a redundant 7R manipulator and a mock-up conditioning tool.


Title: Human Intention Estimation based on Neural Networks for Enhanced Collaboration with Robots
Key Words: damping  force sensors  human-robot interaction  industrial robots  motion control  recurrent neural nets  sensors  stability  trajectory control  recurrent neural networks  RNNs  force sensor  human-robot collaboration  human intention estimation  ABB IRB140 industrial robot  model-based generated data  proactive robot behavior  variable impedance controllers  admittance behavior  stability requirements  Trajectory  Task analysis  Robot sensing systems  Neural networks  Damping  Estimation 
Abstract: In human-robot collaboration, the robot is required to provide assistance to the user by facilitating task execution. However, due to stability requirements, a well-damped admittance behavior of the robot is necessary during interaction, thus inducing fatigue in the operator. While available schemes involve variable impedance controllers to mitigate this effect, here we propose an alternative approach entailing a proactive robot behavior that assists in the cooperative execution of trajectories towards desired goals, by estimating the user intention. To this end, we make use of Recurrent Neural Networks (RNNs) to predict and classify cooperative motions, on the basis of a set of predefined goals in the workspace and model-based generated data of human movements. Manual guidance validation experiments are conducted on a 6 d.o.f. ABB IRB140 industrial robot equipped with a force sensor.


Title: Variable Admittance Control for Human-Robot Collaboration based on Online Neural Network Training
Key Words: backpropagation  feedforward neural nets  human-robot interaction  manipulators  motion control  neurocontrollers  variable admittance control  human-robot collaboration  online neural network training  human-robot cooperation  multilayer feedforward neural network  Cartesian velocity  admittance controller  error backpropagation algorithm  KUKA LWR robot  virtual damping  point-to-point cooperative motion  Admittance  Artificial neural networks  Damping  Trajectory  Robot kinematics  Training  Variable Admittance Control  Neural Networks  Error Backpropagation  Minimum Jerk Trajectory 
Abstract: In this paper, a method for variable admittance control in human-robot cooperation is proposed. A multilayer feedforward neural network is designed using the Cartesian velocity of the robot and the applied force by the operator as its inputs to modify online the virtual damping of the admittance controller. The neural network is trained online using the error backpropagation algorithm based on the error between the velocity of the minimum jerk trajectory model and the measured velocity of the robot. The performance of the proposed controller and the NN generalization ability are evaluated by conducting a point-to-point cooperative motion with multiple subjects using the KUKA LWR robot.


Title: Online Human Muscle Force Estimation for Fatigue Management in Human-Robot Co-Manipulation
Key Words: electromyography  human-robot interaction  learning (artificial intelligence)  medical computing  medical robotics  muscle  arm configurations  human-robot comanipulation  optimisation  online human muscle force estimation  human operator  robot sensory system  task force  specific fatigued muscles  task execution  fatigue management system  muscle fatigue levels  model-based estimation  estimated muscle forces  endpoint interaction forces  online predictions  machine learning technique  human arm  less-fatigued muscles  anticipatory robotic responses  individual muscle group  excessive fatigue levels  selective management  Muscles  Force  Fatigue  Task analysis  Robot sensing systems  Optimization 
Abstract: In this paper, we propose a novel method for selective management of muscle fatigue in human-robot co-manipulation. The proposed framework enables the detection of excessive fatigue levels of an individual muscle group while executing a certain task, and provides anticipatory robotic responses to distribute the effort among less-fatigued muscles of human arm. Our approach uses a machine learning technique to enable online predictions of muscle forces in different arm configurations and endpoint interaction forces. The estimated muscle forces are then used for the model-based estimation of muscle fatigue levels. Through optimisation, the fatigue management system can alter the task execution in a way that specific fatigued muscles are offloaded, while at the same time enables the production of task force using muscles with lower levels of fatigue. The main advantage of the proposed method is that it can operate online, and that all the measurements are performed by the robot sensory system, which can significantly increase the applicability in real-world scenarios. To validate the proposed method, we performed proof-of-concept experiments where the task of the human operator was to use a tool to polish an object that was manipulated by the robot.


Title: Evolutionary Motion Control Optimization in Physical Human-Robot Interaction
Key Words: biomedical ultrasonics  evolutionary computation  force control  human-robot interaction  medical robotics  motion control  optimisation  phantoms  trajectory control  evolutionary motion control optimization  medical freehand ultrasound  trajectory planning  optimal trajectories  human leg phantom  physical human-robot interaction  online tuning  collaborative robot  medical ultrasound motion  parallel force-impedance control  differential evolution  pHRI  mean absolute error  Ultrasonic imaging  Task analysis  Tuning  Legged locomotion  Force  Robot kinematics 
Abstract: Given that the success of an interaction task depends on the capability of the robot system to handle physical contact with its environment, pure motion control is often insufficient. This is especially true in the context of medical freehand ultrasound where the human body is a deformable surface and an unstructured environment, representing both a safety concern and a challenge for trajectory planning and control. The systematic tuning of practical high degree-of-freedom physical human-robot interaction (pHRI) tasks is not trivial and there are many parameters to be tuned. While traditional tuning is generally performed ad hoc and requires knowledge of the robot and environment dynamics, we propose a simple and effective online tuning framework using differential evolution (DE) to optimize the motion parameters for parallel force/impedance control in a pHRI and medical ultrasound motion application. Through real-world experiments with a KUKA LBR iiwa 7 R800 collaborative robot, the DE framework tuned motion control for optimal and safe trajectories along a human leg phantom. The optimization process was able to successfully reduce the mean absolute error of the motion contact force to 0.537 N through the evolution of eight motion control parameters.


Title: Human-Robot Cooperative Object Manipulation with Contact Changes
Key Words: cooperative systems  human-robot interaction  interactive systems  manipulators  mobile robots  path planning  physical interaction system  bi-manual physical cooperation  force interaction cues  interactive search-based planning  online trajectory  motion generation  mixed initiative collaboration strategy  human-robot cooperative object manipulation  human-robot interaction  bi-manual mobile robot  Robot sensing systems  Task analysis  Planning  Robot kinematics  Trajectory  Synchronization 
Abstract: This paper presents a system for cooperatively manipulating large objects between a human and a robot. This physical interaction system is designed to handle, transport, or manipulate large objects of different shapes in cooperation with a human. Unique points are the bi-manual physical cooperation, the sequential characteristic of the cooperation including contact changes, and a novel architecture combining force interaction cues, interactive search-based planning, and online trajectory and motion generation. The resulting system implements a mixed initiative collaboration strategy, deferring to the human when his intentions are unclear, and driving the task once understood. This results in an easy and intuitive human-robot interaction. It is evaluated in simulations and on a bi-manual mobile robot with 32 degrees of freedom.


Title: From Human Physical Interaction To Online Motion Adaptation Using Parameterized Dynamical Systems
Key Words: adaptive control  control engineering computing  human-robot interaction  manipulator dynamics  motion control  path planning  trajectory control  parameterized time-independent dynamical systems  motion flexibility  motion generation  impedance-controlled robots  adaptive motion planning approach  parameterized dynamical systems  online motion adaptation  human physical interaction  Task analysis  Trajectory  Impedance  Service robots  Convergence  Planning 
Abstract: In this work, we present an adaptive motion planning approach for impedance-controlled robots to modify their tasks based on human physical interactions. We use a class of parameterized time-independent dynamical systems for motion generation where the modulation of such parameters allows for motion flexibility. To adapt to human interactions, we update the parameters of our dynamical system in order to reduce the tracking error (i.e., between the desired trajectory generated by the dynamical system and the real trajectory influenced by the human interaction). We provide analytical analysis and several simulations of our method. Finally, we investigate our approach through real world experiments with a 7-DOF KUKA LWR 4+ robot performing tasks such as polishing and pick-and-place.


Title: Unmanned Aerial Auger for Underground Sensor Installation
Key Words: Auger effect  autonomous aerial vehicles  geophysical equipment  geophysical techniques  sensors  soil  underground equipment  digging mechanism  power consumption  unmanned aerial systems  target soil sensors  unmanned aerial auger performance  UAS  underground sensor installation  depth 120.0 mm  Force  Robot sensing systems  Substrates  Fasteners  Monitoring  Soil moisture 
Abstract: Using an Unmanned Aerial Systems (UAS) to autonomously deploy soil sensors enables their installation in otherwise hard to access locations. In this paper, we present a system that integrates a UAS and a digging mechanism which can carry, secure, and install a small sensor into dirt effectively and efficiently. The integrated system includes 1) a low profile, light-weight, inexpensive auger mechanism, 2) a sensor carrying and deploying mechanism with low power consumption, and 3) sensors and software that control and evaluate the auger performance during digging. When tested on a suite of target soils and a target depth of 120mm, the system achieved a success rate of 100% for indoor tests and 92.5% for outdoors, verifying the potential of the approach.


Title: Enhanced Non-Steady Gliding Performance of the MultiMo-Bat through Optimal Airfoil Configuration and Control Strategy
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  design engineering  drag  mobile robots  optimal control  pitch control (position)  robot dynamics  active pitch control strategy  center-of-mass location  morphological intelligence  optimal control strategy  collapsible airfoils  nonsteady-state gliding performance  gliding robots  drag coefficients  aerodynamic complexities  Robots  Automotive components  Aerodynamics  Optimization  Atmospheric modeling  Trajectory  Springs 
Abstract: Many robots make use of gravitational potential energy, generated by another mode, to enhance mobility through gliding locomotion. However, unstructured environments can create situations in which the initial conditions for steady-state gliding cannot be achieved; for example, jumping out of a hole, where the obstacle is very close to the robot. This paper suggests an optimization methodology for finding airfoil configurations and control strategies to maximize the effective non-steady-state gliding ratio for the most challenging initial condition, that of zero velocity. Parameters for the optimization are a location of a robot's center-of-mass in relation to its center-of-pressure and, through the addition of a tail, an active pitch control strategy. The optimal center-of-mass location produces the best passive gliding performance (morphological intelligence), and the optimal control strategy improves the gliding distance. Due to the aerodynamic complexities of modeling the collapsible airfoils, we find the optimal location of the center-of-mass from gliding experiments performed on the robot at different center-of-mass locations and initial pitch angles. An optimal location of the center-of-mass was found to be 40% of the wing chord for our robotic platform; measured from the wing's leading edge. The optimal location has a wide range of initial pitch angles which result in stable, yet non-steady-state, gliding behaviors. The morphological intelligence built into our robotic platform creates two observable dynamic behaviors, that of horizontal velocity gain and sink rate minimization. We then estimate the drag coefficients from the experiments, and conduct dynamic simulations to optimize the pitch control strategy. The design methodology presented here can enhance the non-steady-state gliding performance of a broad range of gliding robots, and the control strategy can further enhance performance on those which utilize an active tail.


Title: Development of Camber-Flat Wing Structure Convert Mechanism for Asymmetric Flapping Micro Air Vehicle
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  design engineering  vehicle dynamics  r asymmetric flapping micro air vehicle  rigidity  camber-flat wing structure convert mechanism  Force  Muscles  Robots  Drag  Force measurement  Insects  Actuators 
Abstract: This study presents principle of the camber-flat wing structure conversion mechanism, which is inspired by a dragonfly, and its applicability to MAV. The camber-flat wing structure convert mechanism makes MAV flight using asymmetric flapping pattern through control of angle of attack without complicate structure. This mechanism was inspired from the dragonfly's feature that the camber structure of the wing increases the rigidity of wing structure and makes dragonfly has asymmetric flapping pattern. Experimental results show that MAV has asymmetric flapping pattern that can more stable flight performance when hovering flight with a camber structure and superior performance when the forward flight with a flat structure. The average lift force in the camber wing structure was 0.02N, the average thrust force was 0.02N and the average lift force was 0.011N in the flat wing structure at 20 Hz flapping frequency.


Title: Robotic Boreblending: The Future of In-Situ Gas Turbine Repair
Key Words: compressors  gas turbines  industrial robots  inspection  maintenance engineering  maintenance  robot flexible joints  kinematic analysis  In-Situ Gas Turbine Repair  robotic boreblending  Tools  Blades  Maintenance engineering  Turbines  Joints  End effectors 
Abstract: Automation of inspection and repair tasks on complex installations is gaining attention from industries with high-value assets such as aerospace, nuclear and marine. This paper reports on a five degrees of freedom robotic system capable of performing accurate and repeatable repair procedures through a narrow inspection port, which minimizes the cost and downtime associated with unscheduled maintenance. Careful study of the target working volume and repair process informed the design of a robotic probe capable of replicating the operation. Kinematic analysis of the robot's flexible, prismatic and rotary joints was used to define accurate machining paths in 3D space, and the results were verified using an optical motion capture system (accuracy of 0.25 mm). After comprehensive verifications of the constitutive elements, the robotic system was successfully demonstrated for repair of a high-pressure compressor aerofoil in a gas turbine. The results not only proves the ability of the system to address such difficult repair scenarios but also highlights a domain of opportunities in developing specialist robotics for repair of high-value assets, which is a subject to growing global demand.


Title: Design of an Autonomous Robot for Mapping, Navigation, and Manipulation in Underground Mines
Key Words: cameras  inertial systems  manipulators  mining  mobile robots  robot vision  sensors  autonomous driving  autonomous robot  manipulation  underground mines  dangerous working environment  harsh environment  robot design  underground objects  manipulating objects  robotic arm  robust four wheeled platform  depth cameras  inertial measurement unit  autonomous navigation  Robot sensing systems  Manipulators  Cameras  Navigation  Mobile robots 
Abstract: Underground mines are a dangerous working environment and, therefore, robots could help putting less humans at risk. Traditional robots, sensors, and software often do not work reliably underground due to the harsh environment. This paper analyzes requirements and presents a robot design capable of navigating autonomously underground and manipulating objects with a robotic arm. The robot's base is a robust four wheeled platform powered by electric motors and able to withstand the harsh environment. It is equipped with color and depth cameras, lighting, laser scanners, an inertial measurement unit, and a robotic arm. We conducted two experiments testing mapping and autonomous navigation. Mapping a 75 meters long route including a loop closure results in a map that qualitatively matches the original map to a good extent. Testing autonomous driving on a previously created map of a second, straight, 150 meters long route was also successful. However, without loop closure, rotation errors cause apparent deviations in the created map. These first experiments showed the robot's operability underground.


Title: Design and Performance Evaluation of an Infotaxis-Based Three-Dimensional Algorithm for Odor Source Localization
Key Words: electronic noses  gases  mobile robots  probability  wind tunnels  gaseous leak source  high wind speeds  environmental conditions  environmental parameters  multiple algorithmic parameters  wind tunnel  probabilistic Infotaxis algorithm  odor source localization  infotaxis-based three-dimensional algorithm  Robots  Entropy  Atmospheric modeling  Mathematical model  Probabilistic logic  Numerical models  Probability 
Abstract: In this paper we tackle the problem of finding the source of a gaseous leak with a robot in a three-dimensional (3-D) physical space. The proposed method extends the operational range of the probabilistic Infotaxis algorithm [1] into 3-D and makes multiple improvements in order to increase its performance in such settings. The method has been tested systematically through high-fidelity simulations and in a wind tunnel emulating realistic conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments. The algorithm shows good performance in various environmental conditions, particularly in high wind speeds and different source release rates.


Title: Cognition-enabled Framework for Mixed Human-Robot Rescue Teams
Key Words: cognition  human-robot interaction  mobile robots  telerobotics  cognition-enabled framework  rescue missions  cognitive capabilities  robot behavior  human-robot rescue teams  human-robot interaction  visibility areas  robotic systems teleoperation  locomotion areas  belief state representations  Cognition  Robot sensing systems  Geographic information systems  Task analysis  Lakes  Bridges 
Abstract: With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.


Title: Pulleys and Force Sensors Influence on Payload Estimation of Cable-Driven Parallel Robots
Key Words: cables (mechanical)  feedforward  force sensors  manipulators  motion control  pulleys  robot kinematics  robust control  torque control  Cable-Driven Parallel robots  suspended Cable-Driven Parallel Robot  heavy objects  heterogeneous objects  payload mass  robust control  pulleys  payload estimation  geometric model  mass estimations  cable tensions  torque controller  real-time mass compensation  CDPR prototype  force sensors influence  pick-and-place operations  Pulleys  Payloads  Mechanical cables  Estimation  Robots  Prototypes  Trajectory 
Abstract: The subject of this paper is about the use of a suspended Cable-Driven Parallel Robot (CDPR) for pick-and-place operations of heavy and heterogeneous objects. The knowledge of the payload mass and its center of mass in realtime is an asset for robust control of the device, which is required to ensure a good stability, especially when the objects have different shapes, sizes and masses. Accordingly, this paper aims at experimentally evaluating the effects of (i) the pulleys modeling and (ii) the use of force sensors for the payload estimation. It turns out that the consideration of the pulleys into the geometric model of the robot improves the mass and center of mass estimations of the payload. A comparison is made between the estimation of cable tensions from force sensors and from motor currents. Finally, a torque controller with a feedforward term for real-time mass compensation is proposed and implemented on a CDPR prototype.


Title: 3D-printed flexure-based finger joints for anthropomorphic hands
Key Words: dexterous manipulators  grippers  hinges  production engineering computing  prosthetics  springs (mechanical)  three-dimensional printing  3D printed flexure-based finger joints  grasping force  load bearing capacity  anthropomorphic hands  nonflexure-based prosthetic hands  presented joints power grasping capability outperform current state flexure-base hands  Angle Three-Flexure Cross Hinge  Fasteners  Force  Topology  Grasping  Stress  Optimization  Load modeling  Compliant joints  flexures  robotic hand  prosthetic hand  anthropomorphic  additive manufacturing 
Abstract: Flexure-based finger joints for prosthetic hands have been studied, but until now they lack stiffness and load bearing capacity. In this paper we present a design which combines large range of motion, stiffness and load bearing capacity, with an overload protection mechanism. Several planar and non-planar hinge topologies are studied to determine load capacity over the range of motion. Optimized topologies are compared, in 30 degrees deflected state, in terms of stresses by deflection and grasping forces. Additionally, support stiffnesses were computed for all hinges in the whole range of motion (45 degrees). The Hole Cross Hinge presented the best performance over the range of motion with a grasping force up to 15 N while deflected 30 degrees. A new concept, the Angle Three-Flexure Cross Hinge, provides outstanding performance for deflections from 17.5 up to 30 degrees with a 20 N maximum grasping force when fully deflected. Experimental verification of the support stiffness over the range of motion shows some additional compliances, but the stiffness trend of the printed hinge is in line with the model. The presented joints power grasping capability outperform current state flexure-base hands and are comparable to commercial non-flexure-based prosthetic hands. In the event of excessive loads, an overload protection mechanism is in place to protect the flexure- hinges.


Title: Body-Mounted Robot for Image-Guided Percutaneous Interventions: Mechanical Design and Preliminary Accuracy Evaluation
Key Words: biomedical MRI  computerised tomography  diagnostic radiography  image registration  manipulators  medical image processing  medical robotics  needles  robot kinematics  surgery  needle-based percutaneous interventions  biopsy seed placement  brachytherapy seed placement  robot mechanism  Magnetic Resonance Imaging  repeatable robot registration  robot kinematics  robot calibration procedure  robotic manipulator  body-mounted robot  image-guided percutaneous interventions  MRI guidance  Computed Tomography  shoulder arthrography  Robot kinematics  Magnetic resonance imaging  Needles  Manipulators  Computed tomography  Calibration 
Abstract: This paper presents a body-mounted, four degree-of-freedom (4-DOF) parallel mechanism robot for image-guided percutaneous interventions. The design of the robot is optimized to be light weight and compact such that it could be mounted to the patient body. It has a modular design that can be adopted for assisting various image-guided, needle-based percutaneous interventions such as arthrography, biopsy and brachytherapy seed placement. The robot mechanism and the control system are designed and manufactured with components compatible with imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT). The current version of the robot presented in this paper is optimized for shoulder arthrography under MRI guidance; a Z-shaped fiducial frame is attached to the robot, providing accurate and repeatable robot registration with the MR scanner coordinate system. Here we present the mechanical design of the manipulator, robot kinematics, robot calibration procedure, and preliminary bench-top accuracy assessment. The bench-top accuracy evaluation of the robotic manipulator shows average translational error of 1.01 mm and 0.96 mm in X and Z axes, respectively, and average rotational error of 3.06 degrees and 2.07 degrees about the X and Z axes, respectively.


Title: HERI II: A Robust and Flexible Robotic Hand based on Modular Finger design and Under Actuation Principles
Key Words: actuators  elasticity  manipulators  position measurement  design effectiveness  resilient manipulation  robust manipulation  Centauro Robot  transmission system  motor current readings  finger phalanxes  contact pressure  absolute position measurements  precise grasping  delicate grasping  sensory system  under-actuated transmission  single actuator  finger module  finger arrangement  highly integrated modular finger units  under-actuated hand  actuation principles  modular finger design  HERI II  Grasping  Tendons  Force  Pulleys  Thumb  Robots 
Abstract: This paper introduces the design of a novel under-actuated hand with highly integrated modular finger units, which can be easily reconfigured in terms of finger arrangement and number to account for the manipulation needs of different applications. Each finger module is powered by a single actuator through an under-actuated transmission and equipped with a sensory system for delicate and precise grasping, which includes absolute position measurements, contact pressure sensing at finger phalanxes and motor current readings. Finally, intrinsic elasticity integrated in the transmission system make the hand robust and adaptive to impacts when interacting with the objects and environment. This highly integrated hand (HERI II) was developed for the Centauro Robot to enable robust and resilient manipulation. A set of experiments demonstrating the hand's grasping performance were carried out and fully verified the design effectiveness of the proposed hand.


Title: Design, Modeling and Control of a Soft Robotic Arm
Key Words: closed loop systems  design engineering  linear quadratic Gaussian control  manipulators  nonlinear control systems  pendulums  pressure control  stability  valves  soft robotic arm  hybrid robotic arm  soft bladders  inflatable bladders  low cost switching valves  pressure control  valve model  system identification  linear quadratic Gaussian controller  closed loop control performance  stabilization  rotational inverted pendulum  Furuta pendulum  Actuators  Valves  Manipulators  Fabrics  Welding  Switches 
Abstract: In this paper we present the design of a hybrid robotic arm using soft, inflatable bladders for actuation. Low cost switching valves are used for pressure control, where the valve model is identified experimentally. A model of the robotic arm is derived based on system identification and used to derive a linear quadratic Gaussian controller. A method to solve limitations of the employed switching valves is proposed and experimentally proven to improve tracking performance. The closed loop control performance of the robotic arm is demonstrated by stabilizing a rotational inverted pendulum known as the Furuta pendulum.


Title: Energy-Efficient Design and Control of a Vibro-Driven Robot
Key Words: control system synthesis  feedback  friction  mobile robots  motion control  nonlinear control systems  pendulums  position control  robot dynamics  springs (mechanical)  stick-slip  trajectory generation profile  VDR systems  nonlinear-motion prototype  physical robot  dynamic contributions  driving pendulum  partial feedback controller  tracking control  noncollocated constraint conditions  travelling distance  passive dynamics  friction-induced stick-slip motions  spring-augmented pendulum  open problems  underactuated nature  locomotion  vibro-driven robotic systems  energy-efficient design  Robots  Trajectory  Force  Dynamics  Friction  Energy efficiency  Acceleration 
Abstract: Vibro-driven robotic (VDR) systems use stick-slip motions for locomotion. Due to the underactuated nature of the system, efficient design and control are still open problems. We present a new energy preserving design based on a spring-augmented pendulum. We indirectly control the friction-induced stick-slip motions by exploiting the passive dynamics in order to achieve an improvement in overall travelling distance and energy efficiency. Both collocated and non-collocated constraint conditions are elaborately analysed and considered to obtain a desired trajectory generation profile. For tracking control, we develop a partial feedback controller for the driving pendulum which counteracts the dynamic contributions from the platform. Comparative simulation studies show the effectiveness and intriguing performance of the proposed approach, while its feasibility is experimentally verified through a physical robot. Our robot is to the best of our knowledge the first nonlinear-motion prototype in literature towards the VDR systems.


Title: Design of Compliant Mechanosensory Composite (CMC) and its Application Toward the Sensible Mesoscale Robotics
Key Words: angular measurement  coils  composite materials  conducting polymers  contact resistance  grippers  intelligent sensors  mobile robots  motion measurement  embedded sensing ability  conductive polymer PEDOT:PSS  CMC process  sensible mesoscale robotics  macroscale robots  compliant mechanosensory composite design  locomotory modulation  electric contact resistance  ECR  bending angle estimation  cyclic bending analysis  sparsely printed serpentine pattern  SMA coil  shape memory alloy coil  embedded sensors  size 0.1 mm to 10.0 mm  Robot sensing systems  Resistance  Fabrication  Contact resistance  Manufacturing processes 
Abstract: Sensed information greatly helps a robot to adjust its motion or modulate the locomotory behavior. While many sensing components have been developed for macroscale robots, such off-the-shelf sensors are hardly integrated with a mesoscale (i.e., 0.1 mm to 10 mm) robot due to the size limitation. In this work, we propose a Compliant Mechanosensory Composite (CMC) to fabricate a small compliant mechanism with embedded sensing ability. As the first demonstration of CMC, we directly print a conductive polymer PEDOT:PSS onto the flexible joint of a compliant mechanism to sense the motion of the flexible joint itself. Owing to the variation of electric contact resistance (ECR) upon bending, the CMC could estimate its bending angle. The performance of the CMC was verified by analyzing the cyclic bending, transient and stationary response. Overall, a sparsely printed serpentine pattern with thicker line exhibited consistent response without a noticeable hysteresis. To demonstrate the applicability of the CMC process, a small gripper actuated by a SMA (shape memory alloy) coil was fabricated, and its motion was successfully measured using the embedded sensors. We expect the proposed CMC will enable a small robot to become sensible at its self motion, external load, and physical contacts in future.


Title: Conductive Knit-covered Pneumatic Artificial Muscle (k-PAM) Actuator
Key Words: durability  fabrics  pneumatic actuators  silver  yarn  stitch methods  semipermanent conductive knit  high repetitive operation environment  nonconductive yarn  external force  actuator body  k-PAM  conductive knit-covered pneumatic artificial muscle  Actuators  Yarn  Bladder  Fabrication  Force  Sensors  Resistance 
Abstract: The paper presents design, fabrication and characteristics of two kinds of conductive Knit-covered Pneumatic Artificial Muscle (it is called as k-PAM in the paper) actuators, in which two different knits are made by braiding silver-coated (conductive) yarn and spandex (non-conductive) yarn with different stitch methods. The k-PAM is able to measure the change in length of the actuator body according to the applied air pressures as well as the strain due to external force. A complete fabrication method is presented to make the actuator work for higher pressure (≥ 300[kPa]). Since the force generated by the actuator is decoupled from the external force, ultimately, it can be directly used to measure not only the length but also the force. Experimental validations are performed describing the characteristics of two different types of k-PAMs. It is expected that the k-PAM can be used directly for robotic applications in higher pressure condition, while the semi-permanent conductive knit provides the actuator with durability in high repetitive operation environment.


Title: Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts
Key Words: coal  floods  inspection  maintenance engineering  mining  mobile robots  navigation  path planning  sensors  shafts  underwater vehicles  flooded shafts  EU project STAMS  autonomous underwater robotic system  periodic monitoring  underwater robot navigation  flooded mine shafts inspection  flooded mine shafts maintenance  sensor information  Robot sensing systems  Shafts  Three-dimensional displays  Sonar  Navigation  Visual odometry 
Abstract: The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.


Title: Mechanical subsystems integration and structural analysis for the autonomous underwater explorer
Key Words: autonomous underwater vehicles  finite element analysis  mechanical strength  mobile robots  robot dynamics  strain gauges  position requirements  finite element method  perception unit  FEM  strain gauge locations  modular mechanical design  autonomous underwater explorer  structural analysis  mechanical subsystems integration  hull endures pressures  deep dives  hull strength  structural strength analysis  orientation requirements  navigation systems  propulsion unit  ballast system  UX-1  Shape  Robots  Electronic ballasts  Manifolds  Propulsion  Finite element analysis  Cameras 
Abstract: The aim of this study is to analyse the modular mechanical design and integration of all three low-level modules in UX-1 (pendulum, ballast system and propulsion unit). The components of the perception and navigation systems have position and orientation requirements that dictate the shape of the hull. A structural strength analysis using Finite Element method (FEM) was made to study the hull strength during deep dives. The results are presented here, which indicates that the hull endures pressures related to deep dives. Also for validation, strain gauge locations were defined.


Title: UX 1 system design - A robotic system for underwater mining exploration
Key Words: cameras  control system synthesis  innovation management  mining  mobile robots  robot vision  sonar  underwater vehicles  UX 1 system design  underwater mining exploration  UX-1 underwater mine exploration robotic system  UNEXMIN project  international innovation action  EU H2020 program  flooded underground mines  UX-1 robot prototype  recovery system  post-processing computational infrastructure  spherical robot  rotating laser line structured light systems  comprehensive mine model  robot design  UV-light  natural gamma-ray detector  multi-spectral camera  electro-conductivity  magnetic field sensors  high resolution imagery  Robot sensing systems  Sonar  Cameras  Payloads  Three-dimensional displays 
Abstract: This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.


Title: Automation in sensing and raw material characterization - a conceptual framework
Key Words: hyperspectral imaging  image fusion  image sensors  infrared spectra  infrared spectroscopy  statistical analysis  raw material characterization  material identification process  technological maturity  data fusion  sensor combinations approach  sensors signals  sensor technologies  real-time mining project concept  red green blue imaging  short wave infrared hyperspectral imaging  sensing automation  sensor signal  sensor data combinations  RTM  RGB imaging  visible near infrared hyperspectral imaging  VNIR  SWIR  Fourier-transform infrared spectroscopy  FTIR  laser induced breakdown spectroscopy  LIBS  multi-variate statistical interpretation  Minerals  Data integration  Automation  Robot sensing systems  Hyperspectral imaging  Raw materials  sensors data  data fusion  automation  material characterization  polymetallic sulphides 
Abstract: The use of sensor technologies for material characterization is rapidly growing and innovative advancement is observed. However, the use of sensor combinations for a raw material characterization in mining is very limited and automation of the material identification process using a combined sensor signal is not defined. Potential sensor technologies for raw material characterization were evaluated based on the applicability and technological maturity. To ensure a rapid implementation of the Real-time mining (RTM) project concept, mature technologies such as Red Green Blue (RGB) imaging, Visible Near Infrared (VNIR) hyperspectral imaging, Short Wave Infrared (SWIR) hyperspectral imaging, Fourier-Transform Infrared Spectroscopy (FTIR), Laser Induced Breakdown Spectroscopy (LIBS) and Raman were selected. Each selected technology was assessed for automation in sensing and applicability (for characterization of the test case materials). Based on the results the sensor data were further considered for data fusion. The proposed sensor combinations approach encompasses three levels of data fusion: low-level, mid-level and high-level. The data of the different sensors are fused together in order to acquire a wide range of mineral properties within each lithotype and an improved classification and predictive models. The preferred level of data fusion and preferred sensor data combinations will be used to develop a multi-variate statistical interpretation rule which relates combination of sensors signals with raw material properties. Thus a tool which integrates the combined sensor signal with materials properties will be developed and used to automate the material characterization process.


Title: The benefits and challenges of robotics in the mineral raw materials sector - an overview
Key Words: industrial robots  mineral processing industry  mining industry  raw materials  mineral raw materials sector  material transport  robotic digging  robotic loading  mining industry  Service robots  Minerals  Productivity  Fuel processing industries  Robot sensing systems  Raw materials 
Abstract: Robotics applications in the raw materials sector are becoming increasingly common due to their many perceived benefits. In mining, the extended use of robotics is especially seen in the exploration and exploitation phases, where mineral resources are discovered, extracted and processed. The use of robotics in the mining industry started in the 60s and today it is seen in the automation of material transport or in robotic digging and loading. Potential benefits include improved productivity, decreased production costs, better operational efficiency, increased safety, reduced waste and, ultimately, more value creation. The increasing amount of robotics used in the raw materials sector is coupled with a series of ethical and legal issues, regulatory challenges and policy requirements that affect both producers and end-users of robotic technologies. The benefits and challenges of robotics applications, often overlooked by the stakeholders, can hinder both their integration in the sector and the further development of mining activities, if not properly addressed.


Title: Design, Modeling and Control of a Spherical Autonomous Underwater Vehicle for Mine Exploration
Key Words: autonomous underwater vehicles  control system synthesis  intelligent control  motion control  oceanographic equipment  position control  three-term control  flooded mine tunnel networks  unique mechanical hardware design  electrical hardware design  high-fidelity dynamic model  underwater experiments  controlled environment  standard motion patterns  Proportional-Integral-Derivative controller  PID controller  advanced control schemes  spherical AUV  tested underwater motions  spherical autonomous underwater vehicle  vehicle prototype  novel spherical autonomous  Prototypes  DC motors  Manifolds  Mathematical model  Robots  Propulsion  Shape 
Abstract: This paper presents the design, implementation and validation of a novel spherical Autonomous Underwater Vehicle (AUV) prototype, developed for inspection and exploration of flooded mine tunnel networks. The unique mechanical, electrical and hardware design is presented, as well as the development of a theoretical 6 degree-of-freedom (DOF) high-fidelity dynamic model of the system. A series of underwater experiments were carried out in a controlled environment to test the standard motion patterns of the AUV with a Proportional-Integral-Derivative (PID) controller. The performance of the PID controller will be used as the baseline for comparison of more advanced control schemes. The experimental results demonstrated that the spherical AUV was able to realize the tested underwater motions with notable performance.


Title: ίVAMOS! Underwater Mining Machine Navigation System
Key Words: autonomous underwater vehicles  Kalman filters  mining  mining equipment  mobile robots  nonlinear filters  satellite navigation  sensor fusion  underwater acoustic communication  underwater mining machine navigation system  data fusion approach  sensor information  extended kalman filter  EKF  ¡VAMOS  multiple antenna GNSS system  inverted ultra-short baseline  surface vessel  underwater mining vehicle  multiple vehicle underwater localization solution  Position measurement  Global navigation satellite system  Receivers  Transponders  Accelerometers  Data mining  Gravity 
Abstract: Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.


Title: Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System
Key Words: control engineering computing  mining  mobile robots  position control  virtual reality  global architecture  real-time grade system  3D virtual reality HMI  realtime mine modeling  ¡VAMOS!  underwater robotic mining system  navigation  mining field trial  PNA system  PNA sensors  Three-dimensional displays  Sensor systems  Solid modeling  Presence network agents  Virtual reality  Real-time systems 
Abstract: This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.


Title: Model-Based Action Exploration for Learning Dynamic Motion Skills
Key Words: Gaussian distribution  learning (artificial intelligence)  mobile robots  motion control  model-based action exploration  dynamic motion skills  deep reinforcement learning  Gaussian distribution  forward dynamics model  motion control tasks  internal lookahead prediction  robotic locomotion  juggling  Computational modeling  Stochastic processes  Robots  Predictive models  Task analysis  Training  Generative adversarial networks 
Abstract: Deep reinforcement learning has achieved great strides in solving challenging motion control tasks. Recently, there has been significant work on methods for exploiting the data gathered during training, but there has been less work on how to best generate the data to learn from. For continuous action domains, the most common method for generating exploratory actions involves sampling from a Gaussian distribution centred around the mean action output by a policy. Although these methods can be quite capable, they do not scale well with the dimensionality of the action space, and can be dangerous to apply on hardware. We consider learning a forward dynamics model to predict the result, (xt+1), of taking a particular action, (u), given a specific observation of the state, (xt). With this model we perform internal lookahead predictions of outcomes and seek actions we believe have a reasonable chance of success. This method alters the exploratory action space, thereby increasing learning speed and enables higher quality solutions to difficult problems, such as robotic locomotion and juggling.


Title: Active Learning based on Data Uncertainty and Model Sensitivity
Key Words: humanoid robots  learning (artificial intelligence)  pendulums  elementary skills  smooth movements  newly acquired knowledge  additional demonstration  nonsmooth transitions  latent space  metric learning  deep generative models  smooth trajectories  abrupt movements  missing information  necessary knowledge  fundamentally different skills  model sensitivity  data uncertainty  active learning  Uncertainty  Jacobian matrices  Manifolds  Data models  Measurement  Robot sensing systems 
Abstract: Robots can rapidly acquire new skills from demonstrations. However, during generalisation of skills or transitioning across fundamentally different skills, it is unclear whether the robot has the necessary knowledge to perform the task. Failing to detect missing information often leads to abrupt movements or to collisions with the environment. Active learning can quantify the uncertainty of performing the task and, in general, locate regions of missing information. We introduce a novel algorithm for active learning and demonstrate its utility for generating smooth trajectories. Our approach is based on deep generative models and metric learning in latent spaces. It relies on the Jacobian of the likelihood to detect non-smooth transitions in the latent space, i.e., transitions that lead to abrupt changes in the movement of the robot. When non-smooth transitions are detected, our algorithm asks for an additional demonstration from that specific region. The newly acquired knowledge modifies the data manifold and allows for learning a latent representation for generating smooth movements. We demonstrate the efficacy of our approach on generalising elementary skills, transitioning across different skills, and implicitly avoiding collisions with the environment. For our experiments, we use a simulated pendulum where we observe its motion from images and a 7-DoF anthropomorphic arm.


Title: Deep Reinforcement Learning for Audio-Visual Gaze Control
Key Words: gaze tracking  human-robot interaction  learning (artificial intelligence)  deep reinforcement  audio-visual gaze control  human-robot interaction  controlled robot motions  visual observations  acoustic observations  robot head  robotic head  reinforcement learning formulation  gaze control problem  audio data  visual data  audio-visual fusion framework  RL  microphone observations  deep architectures  Visualization  Cameras  Robot vision systems  Robot kinematics  Reinforcement learning 
Abstract: We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.


Title: An Ensemble with Shared Representations Based on Convolutional Networks for Continually Learning Facial Expressions
Key Words: convolutional neural nets  emotion recognition  face recognition  feature extraction  human-robot interaction  robot vision  supervised learning  ensemble-based systems  human-robot interactions  unlabelled facial expressions  emotion recognition capability  social robots  continually learning facial expressions  shared representations  ensemble predictions  convolutional branches  low-level feature extractors  convolutional networks  Training  Feature extraction  Robots  Computer architecture  Face recognition  Convolution  Redundancy 
Abstract: Social robots able to continually learn facial expressions could progressively improve their emotion recognition capability towards people interacting with them. Semi-supervised learning through ensemble predictions is an efficient strategy to leverage the high exposure of unlabelled facial expressions during human-robot interactions. Traditional ensemble-based systems, however, are composed of several independent classifiers leading to a high degree of redundancy, and unnecessary allocation of computational resources. In this paper, we proposed an ensemble based on convolutional networks where the early layers are strong low-level feature extractors, and their representations shared with an ensemble of convolutional branches. This results in a significant drop in redundancy of low-level features processing. Training in a semi-supervised setting, we show that our approach is able to continually learn facial expressions through ensemble predictions using unlabelled samples from different data distributions.


Title: Deep Q-Learning for Dry Stacking Irregular Objects
Key Words: learning (artificial intelligence)  manipulators  motion control  neurocontrollers  state-action pairs  Q-network  robot arm  generated stacking plans  physical constraints  geometric constraints  action space  deep neural network  learned Q-function  reinforcement learning algorithm  local geometric considerations  reinforcement learning approach  dry stacking irregular objects  deep Q-learning  Stacking  Buildings  Robots  Planning  Shape  Stability analysis  Reinforcement learning 
Abstract: We propose a reinforcement learning approach for automatically building dry stacked (i.e. no mortar) structures with irregular objects. Stacking irregular objects is a challenging problem since each assembly action can be drawn from a continuous space of poses for an object, and several local geometric and physical considerations strongly affect the stability. To tackle this challenge, we concentrate on a simplified 2D version of the problem. We present a reinforcement learning algorithm based on deep Q-learning, where the learned Q-function, which maps state-action pairs into expected long-term rewards, is represented by a deep neural network. As the action space is continuous the Q-network is trained by sampling a finite number of actions that consider both geometric and physical constraints to approximate the target Q-values, Experiments show that the proposed method outperforms previous heuristics-based planning, leading to super construction with objects containing a significant amount of variations. We validate the generated stacking plans by executing them using a robot arm and manufactured, irregular objects.


Title: Learning Actionable Representations from Visual Observations
Key Words: learning (artificial intelligence)  video coding  learning task-agnostic representations  continuous control tasks  multiple frames  single frame  self-supervised approach  reinforcement learning setting  random actions  continuous control policies  Proximal Policy Optimization  learned embeddings  real-world Pouring dataset  single-frame baseline  learning actionable representations  time-contrastive networks  Task analysis  Robots  Visualization  Reinforcement learning  Aerospace electronics  Solid modeling  Semantics 
Abstract: In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.


Title: Efficient Distributed Torque Computation for Large Scale Robot Skin
Key Words: computational complexity  control engineering computing  mobile robots  real-time systems  sensor fusion  skin  tactile sensors  torque control  skin information  reactive skin torque controller  kinesthetic robot behavior  scale robot skin  efficient distributed torque computation  real-time control loop  skin joint torques  computational delay  control PC  distributed skin joint torque computation  local microcontrollers  skin joint torque computations  real-time loop  complex computations  distributed skin cells  scale skin  appropriate skin joint torque  Skin  Torque  Robot sensing systems  Real-time systems  Robot kinematics 
Abstract: The realization of a kinesthetic robot behavior using robot skin requires a reactive skin torque controller, which fuses skin information and robot information to an appropriate skin joint torque in real-time. This fusion of information in real-time is challenging when deploying large scale skin. In this paper, we present a system which efficiently computes the torque of distributed skin cells locally at the point of contacts, completely removing this complex computations from the real-time loop. We demonstrate the feasibility of realizing the skin joint torque computations on the local micro-controllers of the skin cells. Conducting experiments with a real robot, we compare the accuracy of the distributed skin joint torque computation with the computation on the control PC. We also show that the novel distributed approach completely eliminates the computational delay of computing skin joint torques in the robot's real-time control loop. As a result, this approach removes any limits for the maximum number of skin cells in control.


Title: A Robust and Efficient Dynamic Network Protocol for a large-scale artificial robotic skin
Key Words: protocols  robots  skin  telecommunication network reliability  protocol converges  skin network  artificial robot skin  dynamic network protocol  static network protocol approach  skin cells  artificial robotic skins  large-scale artificial robotic skin  Skin  Routing protocols  Robot sensing systems  Routing  Heuristic algorithms 
Abstract: Artificial robotic skins are continuously in contact with their environment, and therefore highly rely on proper connections in their skin cells' network. With a static network protocol approach, the affected skin area is unusable after a connection failure. Therefore, we developed a dynamic network protocol for large-scale artificial robotic skins, which re-routes the network upon connection failures to keep the whole skin in operation. Furthermore, the protocol balances the load for driving larger skins without packet loss. For verification, we validated the protocol on a large artificial robot skin we have developed and analyzed its performance with a skin network consisting of up to 204 cells. The failure recovery of the protocol converges in at most 50ms. We showed that the balancing method achieves a packet loss reduction of over 30% compared to the previously used protocol.


Title: 3D Shape Perception from Monocular Vision, Touch, and Shape Priors
Key Words: cameras  computational geometry  feature extraction  image colour analysis  image reconstruction  image segmentation  learning (artificial intelligence)  manipulators  neural nets  object detection  object recognition  robot vision  shape recognition  solid modelling  tactile sensors  visual perception  3D object shape  precise local shape information  monocular camera  visual observations  physical world  perceiving accurate 3D object shape  touch  monocular vision  real-world objects  visual prediction  object regions  learned shape priors  large-scale shape repositories  common object shapes  tactile observations  Shape  Three-dimensional displays  Image reconstruction  Surface reconstruction  Robot sensing systems 
Abstract: Perceiving accurate 3D object shape is important for robots to interact with the physical world. Current research along this direction has been primarily relying on visual observations. Vision, however useful, has inherent limitations due to occlusions and the 2D-3D ambiguities, especially for perception with a monocular camera. In contrast, touch gets precise local shape information, though its efficiency for reconstructing the entire shape could be low. In this paper, we propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories. We use vision first, applying neural networks with learned shape priors to predict an object's 3D shape from a single-view color image. We then use tactile sensing to refine the shape; the robot actively touches the object regions where the visual prediction has high uncertainty. Our method efficiently builds the 3D shape of common objects from a color image and a small number of tactile explorations (around 10). Our setup is easy to apply and has potentials to help robots better perform grasping or manipulation tasks on real-world objects.


Title: Exploration and Reconstruction of Unknown Objects using a Novel Normal and Contact Sensor
Key Words: humanoid robots  manipulators  object recognition  pressure sensors  tactile sensors  tactile sensors  contact measurement  surface orientation  surface reconstruction  unknown objects  pressure sensor  contact force  developed sensor prototype  contact detection capability  normal estimation accuracy  contact sensor  surface normals  inertial measurement unit  IMU  mean reconstruction accuracy  Surface reconstruction  Surface treatment  Tactile sensors  Force 
Abstract: Tactile sensing of surface normals is essential for exploration of unknown objects. Many tactile sensors have been developed for contact measurement. However, few of these sensors provide surface orientation, and only up to a limited degree. This paper presents a novel contact and surface orientation sensor concept and its application for surface reconstruction of unknown objects. The sensor is comprised of an Inertial Measurement Unit (IMU) and a pressure sensor to accurately estimate the surface orientation in a wide range, while at the same time measuring contact force. We describe the developed sensor prototype and evaluate its performance regarding contact detection capability and normal estimation accuracy. We use this to reconstruct the surface of unknown objects using the humanoid robot ARMAR-III resulting in a mean reconstruction accuracy of 3.6 mm.


Title: Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides
Key Words: actuators  force sensors  grippers  optical sensors  optical waveguides  remotely operated vehicles  soft robotic hand  optical sensing elements  proprioception  curvature sensing elements  contact force sensors  normal force  sensor design decisions  simulated deep-sea environments  curvature sensors  soft finger actuators  soft curvature  deep-sea grasping  intentionally-lossy optical waveguides  soft robotic grasping applications  subNewton force sensitivity  temperature -10.0 degC to 50.0 degC  Optical waveguides  Optical sensors  Optical device fabrication  Optical losses  Optical refraction  Optical variables control 
Abstract: In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.


Title: Realtime State Estimation with Tactile and Visual Sensing for Inserting a Suction-held Object
Key Words: mobile robots  robot kinematics  robot vision  state estimation  tactile sensors  visual sensing  suction-held object  real-time state estimation system  robotic packaging  tactile sensing  on-line estimation technique  contact geometry  complex contact interactions  iSAM  robot kinematic measurement  planar settings  data-driven method  Robot sensing systems  Visualization  State estimation  Task analysis  Containers 
Abstract: We develop a real-time state estimation system to recover the pose and contact formation of an object relative to its environment. In this paper, we focus on the application of inserting an object picked by a suction cup into a tight space, a key technology for robotic packaging. We propose a framework that fuses tactile and visual sensing. Visual sensing is versatile and non-intrusive, but suffers from occlusions and limited accuracy, especially for tasks involving contact. Tactile sensing is local, but provides accuracy and robustness to occlusions. The proposed algorithm to fuse them is based on iSAM, an on-line estimation technique, which we use to incorporate kinematic measurements from the robot, contact geometry of the object and the container, and visual tracking. In this paper, we generalize previous results in planar settings [1] to a 3D task with more complex contact interactions. A key challenge is that we do not observe contact locations between the suction-held object and the container directly. We propose a data-driven method to infer the contact formation, which is then used in real-time by the state estimator. We demonstrate and evaluate the algorithm in a setup instrumented to provide groundtruth.


Title: Finding safe 3D robot grasps through efficient haptic exploration with unscented Bayesian optimization and collision penalty
Key Words: approximation theory  Bayes methods  collision avoidance  grippers  haptic interfaces  Kalman filters  mobile robots  optimisation  path planning  unscented Bayesian optimization  novel collision penalty  exploration steps  safe 3D robot grasps  efficient haptic exploration  robust grasping  accurate models  known objects  approximate models  familiar objects  partial point clouds  unknown objects  sensing inaccuracies  local exploration  grasp execution  3D haptic exploration strategy  Grasping  Three-dimensional displays  Optimization  Robot sensing systems  Bayes methods 
Abstract: Robust grasping is a major, and still unsolved, problem in robotics. Information about the 3D shape of an object can be obtained either from prior knowledge (e.g., accurate models of known objects or approximate models of familiar objects) or real-time sensing (e.g., partial point clouds of unknown objects) and can be used to identify good potential grasps. However, due to modeling and sensing inaccuracies, local exploration is often needed to refine such grasps and successfully apply them in the real world. The recently proposed unscented Bayesian optimization technique can make such exploration safer by selecting grasps that are robust to uncertainty in the input space (e.g., inaccuracies in the grasp execution). Extending our previous work on 2D optimization, in this paper we propose a 3D haptic exploration strategy that combines unscented Bayesian optimization with a novel collision penalty heuristic to find safe grasps in a very efficient way: while by augmenting the search-space to 3D we are able to find better grasps, the collision penalty heuristic allows us to do so without increasing the number of exploration steps.


Title: Indoor Mapping and Localization for Pedestrians using Opportunistic Sensing with Smartphones
Key Words: Bayes methods  Gaussian processes  indoor radio  mobile computing  mobile robots  optimisation  particle filtering (numerical methods)  path planning  radionavigation  regression analysis  SLAM (robots)  smart phones  wireless LAN  Gaussian Processes Regression  real-time localization  GPR variance map  pseudowall constraints  magnetic fields  globally consistent trajectories  opportunistic magnetic headings  WiFi signal similarity validation  magnetic sequence matching  loop-closure constraints  pedestrian dead-reckoning  motion constraints  GraphSLAM front-end  signal maps  Bayesian filtering-based online localization  GraphSLAM-based offline mapping  ambient indoor environments  low-cost indoor mapping  indoor localization  smartphone  size 2.3 m  size 3.41 m  Wireless fidelity  Trajectory  Smart phones  Simultaneous localization and mapping  Ground penetrating radar  Legged locomotion 
Abstract: Indoor localization for pedestrians has gained increasing popularity among the rich body of literature for the last decade. In this paper, a low-cost indoor mapping and localization solution is proposed using the opportunistic signals from ambient indoor environments with a smartphone. It is composed of GraphSLAM-based offline mapping and Bayesian filtering-based online localization using generated signal maps. The GraphSLAM front-end is constructed by motion constraints from pedestrian dead-reckoning (PDR), loop-closure constraints identified by magnetic sequence matching with WiFi signal similarity validation, and observation constraints from opportunistic magnetic headings after error rejection. Globally consistent trajectories are created by graph optimization, after which signal maps (e.g., WiFi, magnetic fields, lights) are generated by Gaussian Processes Regression (GPR) for later localization. We propose to use the pseudo-wall constraints from the GPR variance map of magnetic fields and the lights measurements as observations for particle filtering. The proposed method is evaluated on several datasets collected from both the in-compass office buildings and outside public areas. Real-time localization is demonstrated on a smartphone in an office building covering 2000 square meters with the 50- and 90-percentile accuracies being 2.30 m and 3.41 m, respectively.


Title: Navigation without localisation: reliable teach and repeat based on the convergence theorem
Key Words: calibration  cameras  mobile robots  navigation  path planning  robot vision  velocity control  mobile robot  taught path  learned velocities  camera information  position error model  mathematical proof  camera calibration  navigation system  mathematical model  explicit localisation  teach-and-repeat navigation scenarios  teach-and-repeat visual navigation  Robot kinematics  Navigation  Cameras  Robot vision systems  Simultaneous localization and mapping  Feature extraction 
Abstract: We present a novel concept for teach-and-repeat visual navigation. The proposed concept is based on a mathematical model, which indicates that in teach-and-repeat navigation scenarios, mobile robots do not need to perform explicit localisation. Rather than that, a mobile robot which repeats a previously taught path can simply “replay” the learned velocities, while using its camera information only to correct its heading relative to the intended path. To support our claim, we establish a position error model of a robot, which traverses a taught path by only correcting its heading. Then, we outline a mathematical proof which shows that this position error does not diverge over time. Based on the insights from the model, we present a simple monocular teach-and-repeat navigation method. The method is computationally efficient, it does not require camera calibration, and it can learn and autonomously traverse arbitrarily-shaped paths. In a series of experiments, we demonstrate that the method can reliably guide mobile robots in realistic indoor and outdoor conditions, and can cope with imperfect odometry, landmark deficiency, illumination variations and naturally-occurring environment changes. Furthermore, we provide the navigation system and the datasets gathered at www.github.com/gestom/stroll_bearnav.


Title: Accurate Mix-Norm-Based Scan Matching
Key Words: expectation-maximisation algorithm  image matching  learning (artificial intelligence)  least squares approximations  mobile robots  optimisation  pose estimation  exponential power distributions  convergence characteristic  mix-norm-based scan matching  robust objective function design  MoEP-based residual error model  EM-like algorithm  likelihood field model  iteratively reweighted least squares phase  LFM  IRLS  on-line parameter learning  MiNoM optimization  mobile robotics  Iterative closest point algorithm  Linear programming  Gaussian distribution  Standards  Convergence  Optimization  Heuristic algorithms 
Abstract: Highly accurate mapping and localization is of prime importance for mobile robotics, and its core lies in efficient scan matching. Previous research are focusing on designing a robust objective function and the residual error distribution is often ignored or simply assumed as unitary or mixture of simple distributions. In this paper, a mixture of exponential power (MoEP) distributions is proposed to approximate the residual error distribution. The objective function induced by MoEP-based residual error modelling ensembles a mix-norm-based scan matching (MiNoM), which enhances the matching accuracy and convergence characteristic. Both the parameters of transformation (rotation and translation) and residual error distribution are estimated efficiently via an EM-like algorithm. The optimization of MiNoM is iteratively achieved via two phases: An on-line parameter learning (OPL) phase to learn residual error distribution for better representation according to the likelihood field model (LFM), and an iteratively reweighted least squares (IRLS) phase to attain transformation for accuracy and efficiency. Extensive experimental results validate that the proposed MiNoM out-performs several state-of-the-art scan matching algorithms in both convergence characteristic and matching accuracy.


Title: StreetMap - Mapping and Localization on Ground Planes using a Downward Facing Camera
Key Words: cameras  feature extraction  image filtering  image texture  mobile robots  robot vision  rectilinear textures  indoor tiling  ground plane texture  globally consistent map  complete working pipeline  absolute localization  indoor tiles  general texture  ground textures  mobile robot  downward facing camera  Cameras  Robot vision systems  Feature extraction  Robot kinematics  Slabs 
Abstract: This paper describes a system to map a ground-plane, and to subsequently use the map for localization of a mobile robot. The robot has a downward-facing camera, and works on a variety of ground textures including general texture like tarmac, man-made designs like carpet, and rectilinear textures like indoor tiles or outdoor slabs. Such textures provide a basis for measuring relative motion (i.e. computer mouse functionality). But the goal here is the more challenging one of absolute localization. The paper describes a complete working pipeline to build a globally consistent map of a given ground-plane and subsequently to localize within this map at real-time. Two algorithms are described. The first is a feature-based approach which is general to any ground plane texture. The second algorithm takes advantage of the extra constraints available for common rectilinear textures like indoor tiling, paving slabs, and laid brickwork. Quantitative and qualitative experimental results are shown for mapping and localization on a variety of ground-planes.


Title: The TUM VI Benchmark for Evaluating Visual-Inertial Odometry
Key Words: augmented reality  calibration  cameras  distance measurement  image capture  image sensors  image sequences  mobile robots  optical tracking  pose estimation  robot vision  SLAM (robots)  synchronisation  visual-inertial odometry  photometric calibration  motion capture system  IMU measurements  pose ground truth  inertial measurements  vision sensors  augmented reality  SLAM methods  visual odometry  IMU sensors  camera images  TUM VI benchmark  frequency 20.0 Hz  frequency 200.0 Hz  frequency 120.0 Hz  Cameras  Calibration  Simultaneous localization and mapping  Benchmark testing  Visual odometry  Time measurement 
Abstract: Visual odometry and SLAM methods have a large variety of applications in domains such as augmented reality or robotics. Complementing vision sensors with inertial measurements tremendously improves tracking accuracy and robustness, and thus has spawned large interest in the development of visual-inertial (VI) odometry approaches. In this paper, we propose the TUM VI benchmark, a novel dataset with a diverse set of sequences in different scenes for evaluating VI odometry. It provides camera images with 1024×1024 resolution at 20 Hz, high dynamic range and photometric calibration. An IMU measures accelerations and angular velocities on 3 axes at 200 Hz, while the cameras and IMU sensors are time-synchronized in hardware. For trajectory evaluation, we also provide accurate pose ground truth from a motion capture system at high frequency (120 Hz) at the start and end of the sequences which we accurately aligned with the camera and IMU measurements. The full dataset with raw and calibrated data is publicly available. We also evaluate state-of-the-art VI odometry approaches on our dataset.


Title: Scale-Robust Localization Using General Object Landmarks
Key Words: distance measurement  feature extraction  learning (artificial intelligence)  mobile robots  object detection  robot vision  SLAM (robots)  deep-learning-based object features  KITTI Odometry benchmark  outdoor images  scale-robust localization  visual localization  robotic mapping applications  object landmarks  SIFT point-features  Visualization  Measurement  Simultaneous localization and mapping  Robustness  Databases  Search problems 
Abstract: Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3× difference in scale between map and query images. We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change. This technique is training-free and class-agnostic, and in principle can be deployed in any environment out-of-the-box. We evaluate the proposed technique on the KITTI Odometry benchmark and on a novel dataset of outdoor images exhibiting changes in visual scale of 7× and greater, which we have released to the public. Our technique consistently outperforms localization using either SIFT features or the proposed object features alone, achieving both greater accuracy and much lower failure rates under large changes in scale.


Title: Invariant smoothing on Lie Groups
Key Words: estimation theory  Kalman filters  Lie groups  linearisation techniques  optimisation  robot vision  SLAM (robots)  smoothing methods  linearizations  invariant Kalman filtering  robot localization  posteriori estimator  nonlinear smoothing methods  group-affine observation systems  Lie groups  invariant smoothing  Smoothing methods  Manifolds  Simultaneous localization and mapping  Kalman filters  Random variables  Estimation  Robot localization 
Abstract: In this paper we propose a (non-linear) smoothing algorithm for group-affine observation systems, a recently introduced class of estimation problems on Lie groups that bear a particular structure. As most non-linear smoothing methods, the proposed algorithm is based on a maximum a posteriori estimator, determined by optimization. But owing to the specific properties of the considered class of problems, the involved linearizations are proved to have a form of independence with respect to the current estimates, leveraged to avoid (partially or sometimes totally) the need to relinearize. The method is validated on a robot localization example, both in simulations and on real experimental data.


Title: Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids
Key Words: biomechanics  bone  data acquisition  humanoid robots  muscle  robot vision  body tissue  joint-muscle model  muscle-route change model  geometric model  tendon-driven musculoskeletal humanoid Kengoro  muscle routes  tendon-driven musculoskeletal humanoids  flexible spine  body complexity  muscle lengths  muscle route changes  internal muscle tension  online self-body image acquisition  multiple degrees of freedom  controllability  neural network  Muscles  Robot sensing systems  Humanoid robots  Solid modeling  Training 
Abstract: Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.


Title: A Combined RGB and Depth Descriptor for SLAM with Humanoids
Key Words: cameras  feature extraction  humanoid robots  image colour analysis  mobile robots  pose estimation  robot vision  SLAM (robots)  feature tracking  codebooks  reproducibility  humanoid robots  visual simultaneous localization  depth descriptor  ORB-SLAM  visual SLAM system  track features  DLab  RGB-D camera  Nao humanoid  binary descriptor  FAB-MAP  place recognition module  Simultaneous localization and mapping  Image color analysis  Cameras  Three-dimensional displays  Humanoid robots  Visualization 
Abstract: In this paper, we present a visual simultaneous localization and mapping (SLAM) system for humanoid robots. We introduce a new binary descriptor called DLab that exploits the combined information of color, depth, and intensity to achieve robustness with respect to uniqueness, reproducibility, and stability. We use DLab within ORB-SLAM, where we replaced the place recognition module with a modification of FAB-MAP that works with newly built codebooks using our binary descriptor. In experiments carried out in simulation and with a real Nao humanoid equipped with an RGB-D camera, we show that DLab has a superior performance in comparison to other descriptors. The application to feature tracking and place recognition reveal that the new descriptor is able to reliably track features even in sequences with seriously blurred images and that it has a higher percentage of correctly identified similar images. As a result, our new visual SLAM system has a lower absolute trajectory error in comparison to ORB-SLAM and is able to accurately track the robot's trajectory.


Title: Neural-Network-Controlled Spring Mass Template for Humanoid Running
Key Words: humanoid robots  interpolation  legged locomotion  neurocontrollers  pendulums  robot dynamics  springs (mechanical)  table lookup  lookup tables  data-driven approach  deep neural network  simulation data  SLIP model  humanoid robot  whole-body model  QP-based inverse dynamics controller  WALK-MAN robot  robust running motions  neural-network-controlled spring mass template  humanoid running  legged robots  model-based approaches  whole-body robot  controlled SLIP-like behaviors  online incompatibility  interpolations  spring-loaded inverted pendulum model  Legged locomotion  Neural networks  Data models  Training  Biological system modeling  Robot kinematics 
Abstract: To generate dynamic motions such as hopping and running on legged robots, model-based approaches are usually used to embed the well studied spring-loaded inverted pendulum (SLIP) model into the whole-body robot. In producing controlled SLIP-like behaviors, existing methods either suffer from online incompatibility or resort to classical interpolations based on lookup tables. Alternatively, this paper presents the application of a data-driven approach which obviates the need for solving the inverse of the running return map online. Specifically, a deep neural network is trained offline with a large amount of simulation data based on the SLIP model to learn its dynamics. The trained network is applied online to generate reference foot placements for the humanoid robot. The references are then mapped to the whole-body model through a QP-based inverse dynamics controller. Simulation experiments on the WALK-MAN robot are conducted to evaluate the effectiveness of the proposed approach in generating bio-inspired and robust running motions.


Title: Quadruped Locomotion Control Based on Two Bipeds Jointly Carrying Model
Key Words: gait analysis  legged locomotion  motion control  robot dynamics  quadruped locomotion control  novel gait planning  control framework  quadruped robot  rear ends  joint torques  support legs  bipedal sub-robots  quadruped body forces  bipedal torso forces  operating modes  virtual forces  support leg torques  gait generators  gait parameters  hind legs  Legged locomotion  Robot kinematics  Torso  Radio frequency  Hip  Mathematical model 
Abstract: A novel gait planning and control framework was developed for quadruped locomotion of a robot. It modeled the quadruped robot as two bipeds carrying the body from the front and rear ends. We first mapped the relationship between the joint torques of support legs and the torso forces of the bipedal sub-robots. Then the equations describing the relationship between the quadruped body forces and the bipedal torso forces under various operating modes of the robot were deduced and solved. Virtual forces were generated on the quadruped body to manipulate its velocity and orientation. Then these virtual forces were distributed to the front and hind sub-robots to generate support leg torques. The state machines and gait generators for the two bipedal sub-robots were designed individually, resulting in the decoupling of the gait parameters in the front legs and hind legs. The effectiveness of the controller was validated through dynamic simulations.


Title: Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
Key Words: feature extraction  inference mechanisms  learning (artificial intelligence)  legged locomotion  motion control  path planning  robot vision  terrain mapping  multilegged robot  crawled terrain  hexapod robot  legged robot  terrain features inference  aerial scan  robot locomotion  incremental learning  geometrical data  visual data  terrain learning  extraterrestrial missions  robot deployment  robot motion planning  cost of transport estimation  terrain descriptors  mechanical properties  Robots  Feature extraction  Image color analysis  Estimation  Unmanned aerial vehicles  Three-dimensional displays  Visualization 
Abstract: The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.


Title: Determining Optimal Gait Parameters for a Statically Stable Walking Human Assistive Quadruped Robot
Key Words: legged locomotion  optimal control  optimisation  robot dynamics  stability  optimal gait parameters  statically stable walking human assistive quadruped robot  optimal statically stable gait  quadruped robot walking  energy efficient gait  energy efficient quadruped gait  cost function  energy term  stability term  quasistatic analysis  human assistive device  optimization  Legged locomotion  Foot  Cost function  Stability analysis  Gravity 
Abstract: In this paper we propose a method to determine an optimal statically stable gait for a quadruped robot walking in the presence of an expected disturbance. There exists a tradeoff between a stable gait and an energy efficient gait. Our goal is to determine an energy efficient quadruped gait that will maintain stability while a human uses the device to stabilize themselves while walking. In order to determine an optimal gait, we present a cost function consisting of an energy term and a stability term. A method of evaluating the cost function using dynamics and quasi-static analysis is demonstrated. The optimization is implemented for a human assistive device currently being designed and the results are verified in simulation.


Title: Designing Concentric Tube Manipulators for Stability Using Topology Optimization
Key Words: bending  finite element analysis  manipulator dynamics  medical robotics  pipes  surgery  torsion  snapping problem  concentric tube robotic system  topology optimization  concentric tube continuum robots  surgical environments  BTSR  tube design  concentric tube manipulators  surgical environment  bending to torsional stiffness ratio  finite element analysis  Electron tubes  Optimization  Topology  Stress  Manipulators  Load modeling 
Abstract: One of the major problems facing the development and road to practical usage of concentric tube continuum robots in surgical environments is that of instability. This issue, also known as the snapping problem, is caused by a tube having a high bending to torsional stiffness ratio (BTSR). Past efforts have shown that by cutting patterns on the tubes, this problem can be avoided. This paper seeks to redesign the topology of the tubes so that BTSR is decreased and the snapping problem is resolved in a particular tube set. The generated designs are then tested through finite element analysis as well as experimental testing to demonstrate the elimination of the snapping problem. Using this novel tube design on a concentric tube robotic system can increase its stable workspace because it allows the usage of greater tube curvatures and/or curve lengths.


Title: Haptic Feedback and Dynamic Active Constraints for Robot-Assisted Endovascular Catheterization
Key Words: blood vessels  catheters  ergonomics  force feedback  haptic interfaces  manipulators  medical robotics  phantoms  surgery  robot-assisted endovascular catheterization  computer assistance  reduced radiation doses  tortuous anatomy  natural bedside manipulation skills  dexterity  clinical usability  robotic platform  ergonomic master-slave system  navigation system  integrated vision-based haptic feedback  natural bedside skills  dynamic motion tracking  catheterization tasks  phantom  mean force  maximum force  force feedback  vision-based dynamic active constraints  ergonomic robotic catheter manipulator  robot-assisted endovascular procedures  CathBot  vessel walls  vascular surgeon  catheter tip  Catheters  Surgery  Navigation  Force feedback  Robot sensing systems 
Abstract: Robotic and computer assistance can bring significant benefits to endovascular procedures in terms of precision and stability, reduced radiation doses, improved comfort and access to difficult and tortuous anatomy. However, the design of current commercially available platforms tends to alter the natural bedside manipulation skills of the operator, so that the manually acquired experience and dexterity are not well utilized. Furthermore, most of these systems lack of haptic feedback, preventing their acceptance and limiting the clinical usability. In this paper a new robotic platform for endovascular catheterization, the CathBot, is presented. It is an ergonomic master-slave system with navigation system and integrated vision-based haptic feedback, designed to maintain the natural bedside skills of the vascular surgeon. Unlike previous work reported in literature, dynamic motion tracking of both the vessel walls the catheter tip is incorporated to create dynamic active constraints. The system was evaluated through a combined quantitative and qualitative user study simulating catheterization tasks on a phantom. Forces exerted on the phantom were measured. The results showed a 70% decrease in mean force and 61% decrease in maximum force when force feedback is provided. This research provides the first integration of vision-based dynamic active constraints within an ergonomic robotic catheter manipulator. The technological advances presented here, demonstrates that vision-based haptic feedback can improve the effectiveness, precision, and safety of robot-assisted endovascular procedures.


Title: Intuitive Gaze-Control of a Robotized Flexible Endoscope
Key Words: endoscopes  manipulators  medical robotics  visual servoing  intuitive gaze-control  robotized flexible endoscope  flexible endoscopy  intuitive platform  ergonomic platform  standard endoscope  gaze control system  eye-tracking  hands-free manipulation  system characteristics  robotized system  manually controlled endoscope  gaze controlled endoscope  lower task load  hands-free gaze control  visual servoing  Endoscopes  Robots  Optical imaging  Task analysis  Gears  Control systems  Cameras 
Abstract: Flexible endoscopy is a routinely performed procedure that has predominantly remained unchanged for decades despite its many challenges. This paper introduces a novel, more intuitive and ergonomic platform that can be used with any flexible endoscope, allowing easier navigation and manipulation. A standard endoscope is robotized and a gaze control system based on eye-tracking is developed and implemented, allowing hands-free manipulation. The system characteristics and step response has been evaluated using visual servoing. Further, the robotized system has been compared with a manually controlled endoscope during a user study. The users (n=11) showed a preference for the gaze controlled endoscope and a lower task load when the task was performed with the gaze control. In addition, gaze control was related to a higher success rate and a lower time to perform the task. The results presented validate the system's technical performance and demonstrate the intuitiveness of hands-free gaze control in flexible endoscopy.


Title: A Soft Robot to Navigate the Lumens of the Body Using Undulatory Locomotion Generated by a Rotating Magnetic Dipole Field
Key Words: blood vessels  magnetic actuators  magnetic fields  magnetic sensors  medical robotics  microrobots  mobile robots  motion control  numerical analysis  path planning  permanent magnets  rotating magnetic dipole field  soft-robotic actuation concept  mesoscale medical robot  natural lumens  blood vessels  embedded permanent magnets  magnetic polarity  rotating dipole magnetic field  traveling-wave undulatory motion  soft-actuation technology  nonuniform dipole fields  undulatory locomotion  uniform dipole fields  diagnostic context  therapeutic context  numerical simulation  Coils  Magnetic resonance imaging  Magnetic separation  Soft robotics  Permanent magnets  Magnetic moments 
Abstract: In this paper, we describe a soft-robotic actuation concept to enable a mesoscale medical robot to navigate the natural lumens of the body, such as blood vessels and intestines. The concept comprises a simple soft robot with two embedded permanent magnets with alternating magnetic polarity, and a rotating (nonuniform) dipole magnetic field that is swept over the robot, resulting in a traveling-wave undulatory motion that propels the robot forward and backward. This soft-actuation technology can be fabricated in a wide range of sizes due to its simplicity, and has the potential to be applied in a variety of diagnostic and therapeutic contexts. We conduct experiments and numerical simulations to verify the movement of the soft robot. Then, we confirm the benefits of using nonuniform dipole fields over using uniform fields, as well as the benefits of alternating the polarity of the magnets embedded in the device.


Title: A Robot System for Automated Wound Filling with Jetted Materials
Key Words: computer vision  control engineering computing  diseases  medical robotics  nozzles  path planning  patient treatment  proteins  skin  surgery  tissue engineering  wounds  robot system  automated wound filling  jetted materials  skin surface wounds  chronic illness  tissue engineering  3D machine vision system  skin wound  3D point set  path planning algorithm  robot manipulator  ink-jet nozzle  biomaterials  cell growth promoters  Wounds  Three-dimensional displays  Robot kinematics  Cameras  Machine vision  Manuals 
Abstract: Skin surface wounds due to burns, surgeries and chronic illness affect millions of people worldwide. Tissue engineering has become an increasingly popular treatment, but it is a highly manual process. Increasing the automation in tissue engineering could increase the rate of treatment for patients and improve outcomes. We present an initial investigation into an automated in-situ treatment. In our proposed method, a 3D machine vision system detects a skin wound to be treated and then determines the 3D point set corresponding to the wound. The 3D point set is then passed to path planning algorithm for a robot manipulator to move an ink-jet nozzle over the wound and fill the cavity with quick-curing/gelling fluids such collagen and other biomaterials and cell growth promoters. This paper details initial results and experimental validation of each of the proposed steps.


Title: State Estimation for MRI-Actuated Cathers via Catadioptric Stereo Camera
Key Words: biomedical MRI  cameras  catheters  image segmentation  medical robotics  particle filtering (numerical methods)  particle filter  catadioptric camera system  tracking algorithm  MRI-actuated cathers  catadioptric stereo camera  MRI-actuated catheter  novel robotic catheter system  MR tracking system  alternative catheter tracking method  Catheters  Cameras  Actuators  Tracking  Atmospheric measurements  Particle measurements  Mirrors 
Abstract: An MRI-actuated catheter is a novel robotic catheter system that utilizes the MR scanner for both remote steering and catheter tracking. In order to develop the mathematical model and the planning algorithm of the catheter in parallel to the MR tracking system, an alternative catheter tracking method is needed. This paper presents a catheter tracking algorithm based on the particle filter and the catadioptric camera system. The motion model of the particle filter is based on the quasi-static kinematics of the catheter. The measurement model calculates the weights of the particles according to the normalized crosscorrelation of the segmented image from camera and a virtual rendering of the catheter. The efficacy of the tracking algorithm is demonstrates via experimental results.


Title: Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots
Key Words: biomedical optical imaging  diseases  endoscopes  image sequences  medical image processing  medical robotics  motion estimation  unsupervised learning  single-view depth estimation network  passive capsule endoscopes  minimally invasive diagnostic technology  realtime odometry  monocular endoscopic capsule robots  multiview pose estimation  endoscopic capsule robots  disease detection  drug delivery  gastrointestinal tract  reprojection minimization  unsupervised odometry  depth learning  biopsy-like operations  ex-vivo porcine stomach datasets  motion estimation  Cameras  Robots  Endoscopes  Reliability  Sensors  Pose estimation 
Abstract: In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.


Title: Bayesian-inferred Flexible Path Generation in Human-Robot Collaborative Networks
Key Words: Bayes methods  computational geometry  human-robot interaction  inference mechanisms  mobile robots  optimisation  path planning  position control  probability  stochastic processes  flexible path human-robot collaborative network  weighted Euclidean distance  potentially optimal tasks  single task  optimal trajectory  task selection  human intent  Bayesian inference  human-robot collaborative networks  Bayesian-inferred flexible path generation  highly impulsive humans  Task analysis  Trajectory  Robot kinematics  Bayes methods  Collaboration  Cost function 
Abstract: This paper presents a novel method for generating the trajectory of a robot assisting a human in servicing a set of tasks embedded in a convex 2-D domain. This method makes use of Bayesian inference to predict human intent in task selection. Rather than following optimal trajectory towards a single task, the robot computes a set of potentially optimal tasks each weighted by the human's posterior probability and superimposes them into a cost function that is designed to minimize the weighted Euclidean distance relative to set. The effect is a flexible path human-robot collaborative network that is shown in simulation to complete all tasks in a given domain in less time than existing methods for a certain class of highly impulsive humans, i.e., humans that tend to randomly switch tasks at times generated by a Poisson counting process. The algorithm is also illustrated through an experimental demonstration.


Title: Head-Mounted Augmented Reality for Explainable Robotic Wheelchair Assistance
Key Words: augmented reality  handicapped aids  human-robot interaction  medical robotics  mobile robots  wheelchairs  robotic wheelchair assistance  visual feedback  wheelchair navigation  head-mounted aid  Microsoft Hololens  mental model  severely disabled individuals  robotic wheelchairs  head-mounted augmented reality  augmented information acquisition  assistive navigation  immersive wheelchair training regime  learning curve  Wheelchairs  Mobile robots  Navigation  Visualization  Collision avoidance  Trajectory 
Abstract: Robotic wheelchairs with built-in assistive features, such as shared control, are an emerging means of providing independent mobility to severely disabled individuals. However, patients often struggle to build a mental model of their wheelchair's behaviour under different environmental conditions. Motivated by the desire to help users bridge this gap in perception, we propose a novel augmented reality system using a Microsoft Hololens as a head-mounted aid for wheelchair navigation. The system displays visual feedback to the wearer as a way of explaining the underlying dynamics of the wheelchair's shared controller and its predicted future states. To investigate the influence of different interface design options, a pilot study was also conducted. We evaluated the acceptance rate and learning curve of an immersive wheelchair training regime, revealing preliminary insights into the potential beneficial and adverse nature of different augmented reality cues for assistive navigation. In particular, we demonstrate that care should be taken in the presentation of information, with effort-reducing cues for augmented information acquisition (for example, a rear-view display) being the most appreciated.


Title: Robot Programming Through Augmented Trajectories in Augmented Reality
Key Words: augmented reality  helmet mounted displays  human-robot interaction  industrial robots  motion control  robot programming  teaching  augmented trajectories  augmented reality  mixed reality head-mounted display  robotic interface  robot programming task  robot motion  AR-robot teaching interface  kinesthetic teaching interface  7-DOF robot arm  Microsoft Hololens  carbon-fiber-reinforcement-polymer vacuum bagging process  AR manufacturing paradigm  Task analysis  Trajectory  Service robots  Visualization  End effectors 
Abstract: This paper presents a future-focused approach for robot programming based on augmented trajectories. Using a mixed reality head-mounted display (Microsoft Hololens) and a 7-DOF robot arm, we designed an augmented reality (AR) robotic interface with four interactive functions to ease the robot programming task: 1) Trajectory specification. 2) Virtual previews of robot motion. 3) Visualization of robot parameters. 4) Online reprogramming during simulation and execution. We validate our AR-robot teaching interface by comparing it with a kinesthetic teaching interface in two different scenarios as part of a pilot study: creation of contact surface path and free space path. Furthermore, we present an industrial case study that illustrates our AR manufacturing paradigm by interacting with a 7-DOF robot arm to reduce wrinkles during the pleating step of the carbon-fiber-reinforcement-polymer vacuum bagging process in a simulated scenario.


Title: The HRC Model Set for Human-Robot Collaboration Research
Key Words: human-robot interaction  HRC model set  human-robot collaboration research  human-robot collaboration experiments  HRC experiments  Robots  Task analysis  Collaboration  Robotic assembly  Complexity theory  Standards 
Abstract: In this paper, we present a model set for designing human-robot collaboration (HRC) experiments. It targets a common scenario in HRC, which is the collaborative assembly of furniture, and it consists of a combination of standard components and custom designs. With this work, we aim at reducing the amount of work required to set up and reproduce HRC experiments, and we provide a unified framework to facilitate the comparison and integration of contributions to the field. The model set is designed to be modular, extendable, and easy to distribute. Importantly, it covers the majority of relevant research in HRC, and it allows tuning of a number of experimental variables that are particularly valuable to the field. Additionally, we provide a set of software libraries for perception, control and interaction, with the goal of encouraging other researchers to proactively contribute to our work.


Title: Band of Brothers and Bolts: Caring About Your Robot Teammate
Key Words: computer games  human-robot interaction  consequential behavioral pattern  empathic response  robot teammate  robot companion  Robots  Atmospheric measurements  Particle measurements  Computer bugs  Time measurement  Bonding 
Abstract: It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.


Title: DNN-based Speech Recognition System dealing with Motor State as Auxiliary Information of DNN for Head Shaking Robot
Key Words: acoustic signal processing  neural nets  robots  signal denoising  speech processing  speech recognition  motor state  head shaking robot  deep neural network  acoustic modeling  speech recognition algorithm  feature mapping model  acoustic model  phoneme recognition  feature enhancement model  speech recognition system  auxiliary information  DNN  background noise suppression  Robots  Speech recognition  Speech enhancement  Noise measurement  Feature extraction  Mel frequency cepstral coefficient 
Abstract: In this paper, a deep neural network (DNN) based integrated background noise suppression and acoustic modeling for speech recognition proposed in which on/off state of the motor for the head shaking robot is employed as the relevant auxiliary information of the DNN input. Since the motor sound being generated when the robot is moving or shaking its head severely degrades the performance of the speech recognition accuracy, we propose to use the motor on/off state as additional information when designing the DNN-based recognition system. Our speech recognition algorithm consists of two parts including the feature mapping model for feature enhancement and the acoustic model for phoneme recognition. As for the feature mapping, the stacked DNN is designed for the precise feature enhancement such that the lower DNN and upper DNN are trained separately and combined after which the motor state is plugged into both the lower DNN and upper DNN in addition to the input noisy speech. Then, the acoustic model is trained upon the feature enhancement model in which the motor state is again used as the augmented feature. The proposed technique to suppress the acoustic and motor noises was evaluated in term of the phoneme error rate (PER) and showed a significant improvement over the conventional system.


Title: The Power of a Hand-shake in Human-Robot Interactions
Key Words: control engineering computing  human-robot interaction  nonhandshake conditions  human-robot interactions  human emotional bond  human willingness  social robot Vizzy  handshake conditions  Task analysis  Navigation  Haptic interfaces  Human-robot interaction  Tactile sensors 
Abstract: In this paper, we study the influence of a handshake in the human emotional bond to a robot. In particular, we evaluate the human willingness to help a robot whether the robot first introduces itself to the human with or without a handshake. In the tested paradigm the robot and the human have to perform a joint task, but at a certain stage, the robot needs help to navigate through an obstacle. Without requesting explicit help from the human, the robot performs some attempts to navigate through the obstacle, suggesting to the human that it requires help. In a study with 45 participants, we measure the human's perceptions of the social robot Vizzy, comparing the handshake vs non-handshake conditions. In addition, we evaluate the influence of a handshake in the pro-social behaviour of helping it and the willingness to help it in the future. The results show that a handshake increases the perception of Warmth, Animacy, Likeability, and the tendency to help the robot more, by removing the obstacle.


Title: Received Signal Strength of Electromagnetic Waves Aided Integrated Inertial Navigation System for Underwater Vehicle
Key Words: inertial navigation  Kalman filters  mobile robots  navigation  position measurement  remotely operated vehicles  sensor fusion  underwater vehicles  wireless sensor networks  Kalman filter  Earth-fixed reference sensors  EM waves attenuation  long-term navigation  basin environment  underwater wireless sensor networks  EM waves sensors  sensor-fusion-based localization scheme  electromagnetic waves sensors  sensor fusion  underwater localization scheme  strong signal attenuation  signal uncertainties  underwater environment  unmanned underwater vehicle  sensory information  integrated inertial navigation system  Manganese  Attenuation  Sensor fusion  Robot sensing systems  Noise measurement  Time measurement 
Abstract: Sensory information from an Earth-fixed reference is necessary to guarantee a high localization accuracy of an unmanned underwater vehicle (UUV). However, the implementation of these sensors in an underwater environment is challenging because of signal uncertainties and strong signal attenuation. In this paper, we propose an underwater localization scheme with a sensor fusion of inertial navigation system (INS) and received signal strength of electromagnetic (EM) waves sensors. In the proposed sensor-fusion-based localization scheme, the UUV predicts its location by using INS based on dead-reckoning and corrects the predicted position by Kalman filter using EM waves sensor information when the UUV receives the signals of EM waves sensors in underwater wireless sensor networks. The proposed scheme enables localization with high accuracy and high sampling rate during a long-term task. The results of an experiment performed in a basin environment shows the feasibility of the proposed scheme. The scheme achieved reliable localization accuracy by comparing the pre-measured ground-truth position and long-term navigation. These results show the feasibility of exploiting EM waves attenuation as Earth-fixed reference sensors.


Title: Multibeam Data Processing for Underwater Mapping
Key Words: image segmentation  oceanographic techniques  sonar  sonar detection  sonar imaging  underwater vehicles  balanced trade-off  underwater mapping literature  underwater mapping literature  local thresholding techniques  subsea structures  multibeam data processing  DIDSON imaging sonar  map accuracy  sonar-based underwater mapping  sonar artifacts  range measurements  occupied regions  free regions  received acoustic echos  sonars output  underwater mapping platforms  primary sensor  multibeam sonars  Sonar measurements  Robot sensing systems  Acoustic beams  Image segmentation  Mathematical model  Acoustics 
Abstract: From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.


Title: Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection
Key Words: autonomous underwater vehicles  cameras  collision avoidance  convolutional neural nets  mobile robots  navigation  object detection  robot vision  supervised learning  proportional controller  vision-based autonomous underwater swimming  computer vision  visual target selection  coral-deprived regions  monocular image data  convolutional neural network  supervised learning  motor controller  collision avoidance  autonomous robot swimming  autonomous coral reef navigation  obstacle-avoidance  forward-facing camera  Navigation  Cameras  Robot vision systems  Task analysis  Visualization  Neural networks 
Abstract: We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.


Title: Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop
Key Words: autonomous underwater vehicles  data acquisition  marine safety  mobile robots  perception  robust continuous system integration  critical deep-sea robot operations  knowledge-enabled simulation  reliability  self-localization  system components  safety  simulation in the loop methodology  SIL methodology  Task analysis  Robot sensing systems  Data models  Benchmark testing  Continuous time systems 
Abstract: Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.


Title: Reliable fusion of black-box estimates of underwater localization
Key Words: estimation theory  Kalman filters  mobile robots  Monte Carlo methods  sensor fusion  underwater vehicles  inertial sensory  Kalman filter  augmented Monte Carlo localization algorithms  geophysical sensory  task context  localization signal  heuristic model  underwater robot localization  un-modeled noise  adaptive fusion policy  redundant parametric estimations  information fusion  robot tracking  black-box estimates  reliable fusion  Estimation  Task analysis  Reliability  Robot sensing systems  Global Positioning System  Computational modeling 
Abstract: The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.


Title: Coverage Optimization with Non-Actuated, Floating Mobile Sensors using Iterative Trajectory Planning in Marine Flow Fields
Key Words: oceanographic equipment  oceanographic techniques  passive nodes  coverage optimization  mobile sensors  iterative trajectory planning  marine flow fields  spatial coverage problem  passive floating sensors  iterative measurement  modeling scheme  initial sample point  survey area  ambient surface currents  computational tool  autonomous marine surveying system  ocean drifters  spatial distribution  ocean flow fields  Trajectory  Sensors  Oceans  Planning  Sea measurements  Computational modeling  Robots 
Abstract: This paper considers a spatial coverage problem in which a network of passive floating sensors is used to collect samples in a body of water. We employ an iterative measurement and modeling scheme to incrementally deploy sensors so as to achieve spatial coverage, despite only controlling the initial sample point. Once deployed, sensors are moved about a survey area by ambient surface currents. We demonstrate our results in simulation on 40 different ocean flow fields and compare against several baselines. This work provides a computational tool for scientists seeking a low-cost, autonomous marine surveying system. Although in this paper, we concentrate on ocean drifters, our approach can be extended to other domains where a spatial distribution of passive nodes in a flow field can be modeled.


Title: A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
Key Words: autonomous underwater vehicles  bridges (structures)  inspection  multi-robot systems  path planning  underwater structures  DSCPP  smooth paths  spiral path  popular boustrophedon-based coverage approach  intervention autonomous underwater vehicle  deformable spiral coverage path planning algorithm  smooth coverage path planning  deformable spiral-based algorithm  Spirals  Cleaning  Path planning  Fatigue  Underwater structures  Manipulators  Poles and towers 
Abstract: Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.


Title: Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs
Key Words: autonomous underwater vehicles  calibration  clocks  Global Positioning System  hydrophones  integer programming  linear programming  mobile robots  sensors  synchronisation  time-of-arrival estimation  underwater sound  underwater acoustic transmitter  real-time calibration algorithms  TOF measurements  temperature variation  mixed integer linear program  AUV  TDOA filtering methods  mean localization errors  acoustic tag state estimation  unsynchronized hydrophones  underwater robotic sensor system  marine animals  time difference of arrival  autonomous underwater vehicle  nonlinear clock skews  time of flight  GPS data  TOF filtering methods  standard deviation  Clocks  Sonar equipment  Acoustics  Temperature measurement  Acoustic measurements  Estimation 
Abstract: This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.


Title: GelSlim: A High-Resolution, Compact, Robust, and Calibrated Tactile-sensing Finger
Key Words: calibration  dexterous manipulators  grippers  robot vision  tactile sensors  calibrated tactile-sensing finger  high-resolution tactile-sensing finger  robot grasping  previous GelSight sensing techniques  Adelson 2009  homogeneous output  previous vision-based tactile sensors  compact integration  optical path  illumination source  geometric design variables  finger thickness  tactile sensing area  grasping tasks  compliant gel  calibration process  homogeneous illumination  tactile images  Tactile sensors  Cameras  Three-dimensional displays  Grasping 
Abstract: This work describes the development of a high-resolution tactile-sensing finger for robot grasping. This finger, inspired by previous GelSight sensing techniques (Johnson and Adelson 2009), features an integration that is slimmer, more robust, and with more homogeneous output than previous vision-based tactile sensors. To achieve a compact integration, we redesign the optical path from illumination source to camera by combining light guides and an arrangement of mirror reflections. We parameterize the optical path with geometric design variables and describe the tradeoffs between the finger thickness, camera depth of field, and size of the tactile sensing area. The sensor sustains the wear from continuous use - and abuse - in grasping tasks by combining tougher materials for the compliant gel, a textured fabric skin, a structurally rigid body, and a calibration process that maintains homogeneous illumination and contrast of the tactile images during use. Finally, we evaluate the sensor's durability along four metrics that track the signal quality during more than 3000 grasping experiments.


Title: Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors
Key Words: end effectors  force measurement  grippers  position control  tactile sensors  object exploration  Google Soli readings  grasping process  stable grasps  single-grasp  model-free object classification  hyper-adaptive hand  tactile sensors  end-effectors  object identification  robotics applications  autonomous object  quality inspection  hyper-adaptive robot hand  model objects  adaptive grasping mechanisms  tactile modules  barometric sensors  Google Soli sensor  everyday objects  random forests classifier  Robot sensing systems  Thumb  Google  Pins 
Abstract: Robots need to use their end-effectors not only to grasp and manipulate objects but also to understand the environment surrounding them. Object identification is of paramount importance in robotics applications, as it facilitates autonomous object handling, sorting, and quality inspection. In this paper, we present a new hyper-adaptive robot hand that is capable of discriminating between different everyday objects, as well as `model' objects with the same external geometry but varying material, density, or volume, with a single grasp. This work leverages all the benefits of simple, adaptive grasping mechanisms (robustness, simplicity, low weight, adaptability), a Random Forests classifier, tactile modules based on barometric sensors, and radar technology offered by the Google Soli sensor. Unlike prior work, the method does not rely on object exploration, object release or re-grasping and works for a wide variety of everyday objects. The feature space used consists of the Google Soli readings, the motor positions and the contact forces measured at different time instances of the grasping process. The whole approach is model-free and the hand is controlled in an open-loop fashion, achieving stable grasps with minimal complexity. The efficiency of the designs, sensors, and methods has been experimentally validated with experimental paradigms involving model and everyday objects.


Title: Encoding Guidelines for a Culturally Competent Robot for Elderly Care
Key Words: geriatrics  handicapped aids  human-robot interaction  man-machine systems  service robots  encoding guidelines  culturally competent robot  elderly care  socially assistive robots  older people  runtime adaptation  assisted person  invaluable enabling technology  culturally competent assistive behaviours  pepper robot  Indian persona  Guidelines  Cultural differences  Robot sensing systems  Motion pictures  Medical services  Encoding 
Abstract: The functionalities and behaviours of socially assistive robots for the care of older people are usually defined by the robot's designers with limited room for runtime adaptation to meet the preferences, expectations and needs of the assisted person. However, adaptation plays a crucial role for the robot's acceptability and ultimately for its effectiveness. Culture, which deeply influences a person's preferences and habits, can be viewed as an invaluable “enabling technology” to achieve such level of adaptation. This paper discusses how guidelines describing culturally competent assistive behaviours can be encoded in a robot to effectively tune its actions, gestures and words. The proposed system is implemented on a Pepper robot and tested with an Indian persona, whose habits and preferences the robot discovers and adapts to at runtime.


Title: Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots
Key Words: ethical aspects  geriatrics  medical robotics  CARESSES robot  ethical thinking  VSD  international multidisciplinary project  culturally competent SAR  ethical concepts  value sensitive design  culturally competent socially assistive robots  Robots  Task analysis  Ethics  Guidelines  Cultural differences  Assistive technology  Medical services 
Abstract: Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.


Title: Developing a New Brand of Culturally-Aware Personal Robots Based on Local Cultural Practices in the Danish Health Care System
Key Words: brain  cultural aspects  health care  human-robot interaction  medical robotics  mobile robots  good starting point  concrete application fields  national culture  concrete applications  local cultural practices  culturally-aware personal robots  human robot interaction  Danish health care system  brain damage  learning processes  Cultural differences  Global communication  Robot sensing systems  Task analysis  Conferences  Programming 
Abstract: In earlier work it has been shown how culture can be used as a parameter influencing human robot interaction in general (e.g. [1]). While this is a good starting point, in our work with concrete application fields we encounter that culture in its usual definition as national culture (e.g. [2]; [3]) is too general a concept to be useful in these concrete applications. Thus, we shifted our focus instead to a concept of local cultural practices, which is derived from situated practices as in Wengers communities of practice [4] and grounded loosely in Sperbers idea of an epidemiology of representations [5], i.e. culture or rather cultural practices as an emergent phenomenon from learning processes in a given group. Developing this new kind of culture-aware robots can then not start from a general definition of culture like Hofstede [2], Schwartz and Sagiv [6], etc. but has to take the actual group of users (and stakeholders) into account. We exemplify this approach with our work in a residency for citizens with acquired brain damage.


Title: Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction
Key Words: emotion recognition  human-robot interaction  learning (artificial intelligence)  multiculture society  incremental learning model  habitual emotional behaviors  social robot  emotional bodily expressions  imitated robot motions  cultural background  culturally competent robots  long term human-robot interaction  Robot kinematics  Neurons  Self-organizing feature maps  Trajectory  Training  Collision avoidance 
Abstract: Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.


Title: Identification of the User's Habits based on Activity Information
Key Words: Fourier series  home automation  service robots  k-means method  Fourier series representation  activity recognition module  habit estimation system  smart house  user habits  activity information  user personality traits  habit representation  Activity recognition  Robot kinematics  TV  Radiofrequency identification  Receivers  Senior citizens 
Abstract: This work proposes a system able to recognize the user habits based on his daily activities in a smart house. The habit estimation system uses the information provided by an activity recognition module, which provides the sequence and the duration of the activities performed by the user. Based on those parameters, the activities are represented as a signal by using Fourier series representation. Several output signals from different users are clustered into groups using the k-means method, where each cluster corresponds to a specific habit from a group of people. The proposed system was tested with dataset from the experiment that took place in an environment similar to a smart house. The users were asked to perform a set of 6 activities in any desired orders. In total, twenty-four subjects took part in the experiments. All activities were successfully recognized by the system and three different habits were found. The proposed system along with its habit representation can be potentially used to trace the relationships between the habits observed and some aspects of the user personality traits.


Title: AIBO Robot Mortuary Rites in the Japanese Cultural Context*
Key Words: biomimetics  robots  AIBO Robot mortuary rites  Japanese cultural context  AlBO Entertainment Robot  Japanese tech-repair company  Buddhist funeral ceremony  A-Fun's maintenance services  AIBO funerals  human-machine relations  robot design  pet-like robots  zoomorphism  Companies  Maintenance engineering  Animals  Robot sensing systems  Medical treatment  Toy manufacturing industry 
Abstract: In 1999 Sony released the AlBO Entertainment Robot, selling more than 150,000 units worldwide until 2006. By 2014, Sony had stopped offering upgrades and maintenance for the product, and owners were faced with the fact their pet-like robots would “die”. Some shrines and temples in Japan hold ningyo kuyo̅ or mass funerals for dolls and other toys. At the suggestion of a small Japanese tech-repair company called A-Fun, one temple began offering a Buddhist funeral ceremony for AIBOs. Approximately 700 AIBOs have so far received a funeral service. This paper surveys A-Fun`s maintenance services for old AIBOs, the AIBO funerals, and Sony's new 2018 AIBO release, in the cross-disciplinary context of human-machine relations in Japan and elsewhere. Drawing on the author's interviews with key actors, it articulates links between philosophy and neuroscience to explain tendencies toward zoomorphism in robot design. Perceiving presence (sonzai kan) and sensibility (kansei) in objects is a culturally contingent phenomenon. Whereas ways of conceiving the partly animate are largely absent from Western philosophy, in the case of AIBO ownership in Japan there is a reverential mindfulness of the technology's inherent contradictions.


Title: Social Robots as a Means of Integration? an Explorative Acceptance Study considering Gender and Non-verbal Behaviour
Key Words: computer aided instruction  educational robots  gender issues  human-robot interaction  culture-specific behaviours  social robot  german female nonverbal behaviour  educational robot  culture-specific manipulations  European states  gender-specific behaviours  Robot sensing systems  Mouth  Cultural differences  Training  Europe 
Abstract: The integration of migrants and refugees is currently a severe challenge for European states. Especially the imparting of culture- and gender-specific behaviours is an important issue. Social robots might be a valuable tool to introduce refugees to culture-specific behaviours of their host country. In this paper, we investigate the general acceptance of a social robot as well as users' perception of a robot presenting stereo-typical Arabic vs. German female non-verbal behaviour to Syrian newcomers to Germany. Our preliminary study revealed a generally positive attitude towards robots and the idea of an educational robot. Culture-specific manipulations were reflected in participants' partial preference for the Arabic version, but not in participants' perceptual ratings.


Title: Do I act familiar? Investigating the Similarity-Attraction Principle on Culture-specific Communicative behaviour for Social Robots
Key Words: behavioural sciences computing  cultural aspects  human-robot interaction  mobile robots  social robots conversation  cultural dichotomy  human-human interactions  culture-specific communicative behaviour  similarity-attraction principle  Cultural differences  Observers  Computational modeling  Global communication  Service robots  Senior citizens 
Abstract: Culture, amongst other individual and social factors, plays a crucial role in human-human interactions. If robots should become a part of our society, they should be able to act in culture-specific manners as well. In this paper, we showcase the implementation of a cultural dichotomy, namely individualism vs. collectivism, in a social robots' conversation. Presenting these conversations to human observers from Germany and Japan, we investigate whether the implemented differences are recognized as such, and whether stereotypical culture-specific behaviours that correspond to the observers' cultural background is preferred. Results suggest that the manipulations in behaviour had the intended effect, but are not reflected in personal preferences.


Title: Dexterous Manipulation Graphs
Key Words: dexterous manipulators  end effectors  graph theory  grippers  Dexterous Manipulation graphs  in-hand manipulation  end-effector  dual arm robot  end pose  parallel grippers  Grippers  End effectors  Planning  Dynamics  Shape 
Abstract: We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.


Title: Instance Segmentation of Visible and Occluded Regions for Finding and Picking Target from a Pile of Objects
Key Words: image motion analysis  image segmentation  learning (artificial intelligence)  object detection  target object  robotic system  human-annotated dataset  human annotations  image synthesis  inter-instance relationship  novel relook architecture  instance occlusion segmentation  occluded masks  Image segmentation  Robots  Feature extraction  Object segmentation  Image generation  Task analysis  Predictive models 
Abstract: We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order. The fundamental idea is to segment instances with both visible and occluded masks, which we call `instance occlusion segmentation'. To achieve this, we extend an existing instance segmentation model with a novel `relook' architecture, in which the model explicitly learns the inter-instance relationship. Also, by using image synthesis, we make the system capable of handling new objects without human annotations. The experimental results show the effectiveness of the relook architecture when compared with a conventional model and of the image synthesis when compared to a human-annotated dataset. We also demonstrate the capability of our system to achieve picking a target in a cluttered environment with a real robot.


Title: Online prediction of threading task failure using Convolutional Neural Networks
Key Words: assembling  convolutional neural nets  fasteners  fault diagnosis  flexible manufacturing systems  force sensors  grippers  industrial robots  pattern classification  production engineering computing  supervised learning  online prediction  fasteners assembly automation  flexible systems  industrial robot  force-torque sensor  pneumatic gripper  supervised machine learning algorithm  threading task execution time  task failure  FDI techniques  convolutional neural network classifier  fault detection and isolation  CNN  Fasteners  Task analysis  Robot sensing systems  Instruction sets  Force  Service robots 
Abstract: Fasteners assembly automation in different industries require flexible systems capable of dealing with faulty situations. Fault detection and isolation (FDI) techniques are used to detect failure and deal with them, avoiding losses on parts, tools or robots. However, FDI usually deals with the faults after or at the moment they occur. Thus, we propose a method that predicts potential failures online, based on the forces and torques signatures captured during the task. We demonstrate the approach experimentally using an industrial robot, equipped with a force-torque sensor and a pneumatic gripper, used to align and thread nuts into bolts. All effort information is fed into a supervised machine learning algorithm, based on a Convolutional Neural Network (CNN) classifier. The network was able to predict and classify the threading task outcomes in 3 groups: mounted, not mounted or jammed. Our approach was able to reduce in 10.9% the threading task execution time when compared to a reference without FDI, but had problem to predict jammed cases. The same experiment was also performed with other two additional learning algorithms, and the results were systematically compared.


Title: Deep Reinforcement Learning for Robotic Assembly of Mixed Deformable and Rigid Objects
Key Words: control engineering computing  feedback  industrial robots  learning (artificial intelligence)  neural nets  position control  robot programming  robotic assembly  torque control  torque measurement  neural network  force torque measurements  passive mechanical compliance  deep reinforcement learning  torque control  robot control algorithms  assembly tasks  feedback control methods  robotic assembly  industrial robot  robot learning  admittance controller  policy learning process  robot arm wrist sensor  deformable hole  rigid peg  Robot sensing systems  Task analysis  Reinforcement learning  Neural networks  Service robots  Robotic assembly 
Abstract: Reinforcement learning for assembly tasks can yield powerful robot control algorithms for applications that are challenging or even impossible for “conventional” feedback control methods. Insertion of a rigid peg into a deformable hole of smaller diameter is such a task. In this contribution we solve this task with Deep Reinforcement Learning. Force-torque measurements from a robot arm wrist sensor are thereby incorporated two-fold; they are integrated into the policy learning process and they are exploited in an admittance controller that is coupled to the neural network. This enables robot learning of contact-rich assembly tasks without explicit joint torque control or passive mechanical compliance. We demonstrate our approach in experiments with an industrial robot.


Title: A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*
Key Words: bending  blood vessels  catheters  finite element analysis  medical image processing  force estimation accuracy  endovascular intervention procedures  multiple catheter  sensor-less catheter contact force estimation approach  vessel wall  embolization  navigation process safety  robotic vascular interventions  sensor-less sensing solution  multiple contact point forces  image feedback  catheter-vessel interaction  real-time image processing algorithms  interaction contact points  image-based deflection measurement  nonlinear finite element beam model  three-point-bending tests  catheter-guidewire-vessel interaction contact forces  catheter-guidewire manipulation  bending modulus property  under-actuated catheter-guidewire  catheter-guidewire-vessel interaction  Catheters  Force  Robot sensing systems  Estimation  Force measurement  Phantoms  Finite element analysis 
Abstract: Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.


Title: Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process
Key Words: aerospace robotics  aircraft control  autonomous aerial vehicles  force control  manipulators  position control  springs (mechanical)  vibration control  emergency switch process  dangerous work situation  industrial leakage accidents  flexible robot  small robot  aerial manipulator system  hexa-rotor UAV  UAV platform  hover flight  impedance control algorithm  force-sensorless contact force control method  one-DOF manipulator  spring-mass-damper system model  Manipulators  Force  Contacts  Attitude control  Force control  Pressing 
Abstract: The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.


Title: Mechatronic fingernail with static and dynamic force sensing
Key Words: force control  force sensors  manipulators  mechatronics  motion control  compact working prototype  multicell tactile fingertip sensor  distal phalange  robotic hand  mechatronic fingernail  static force sensing  dynamic force sensing  sensorized fingernail  mechatronic hands  static interaction forces  dynamic interaction forces  Nails  Robot sensing systems  Force  Force measurement  Delays 
Abstract: Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.


Title: Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM
Key Words: mixed analogue-digital integrated circuits  mobile robots  neural nets  neurophysiology  pose estimation  SLAM (robots)  pose estimation  spiking neural networks  neuromorphic SLAM  biologically inspired neuronal path integration  mobile robot  neuronal map formation architecture  simultaneous localization and mapping  mixed signal analog-digital neuromorphic hardware  ultra low-power neuromorphic hardware  robotic vehicle simulation  on-board plasticity  Neurons  Neuromorphics  Collision avoidance  Simultaneous localization and mapping  Synapses 
Abstract: In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).


Title: Virtual Occupancy Grid Map for Submap-based Pose Graph SLAM and Planning in 3D Environments
Key Words: graph theory  image reconstruction  mobile robots  path planning  pose estimation  robot vision  SLAM (robots)  3D scene reconstructions  virtual occupancy grid map  mobile robots  VOG-map  submap-based pose graph SLAM  underwater SLAM system  path planning  free space information  Simultaneous localization and mapping  Three-dimensional displays  Path planning  Robot kinematics  Casting 
Abstract: In this paper, we propose a mapping approach that constructs a globally deformable virtual occupancy grid map (VOG-map) based on local submaps. Such a representation allows pose graph SLAM systems to correct globally accumulated drift via loop closures while maintaining free space information for the purpose of path planning. We demonstrate use of such a representation for implementing an underwater SLAM system in which the robot actively plans paths to generate accurate 3D scene reconstructions. We evaluate performance on simulated as well as real-world experiments. Our work furthers capabilities of mobile robots actively mapping and exploring unstructured, three dimensional environments.


Title: Decentralized Localization Framework using Heterogeneous Map-matchings
Key Words: decentralised control  mobile robots  road vehicles  sensor fusion  stability  stochastic processes  decentralized localization framework  heterogeneous map-matchings  system stability  localization methods  map matchings  stochastic situational analysis model  heterogeneous map-matching sources  dissimilar sensors  fusion methods  multienvironment sensors  single environmental sensor  autonomous driving applications  robust real-time localization  Roads  Laser radar  Three-dimensional displays  Cameras  Feature extraction  Sensor fusion 
Abstract: Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.


Title: LDSO: Direct Sparse Odometry with Loop Closure
Key Words: feature extraction  graph theory  mobile robots  optimisation  pose estimation  robot vision  SLAM (robots)  intensity gradient  DSO sliding window optimization  Sim(3) relative pose constraints  image pixel  loop closure detection  monocular visual SLAM system  Direct Sparse Odometry  state-of-the-art feature-based systems  pose-graph optimization  modified point selection strategy  relative poses  co-visibility graph  3D geometric error terms  conventional feature-based bag-of-words approach  loop closure candidates  tracking frontend  corner features  LDSO  featureless areas  Optimization  Feature extraction  Microsoft Windows  Simultaneous localization and mapping  Cameras  Bundle adjustment  Robustness 
Abstract: In this paper we present an extension of Direct Sparse Odometry (DSO) [1] to a monocular visual SLAM system with loop closure detection and pose-graph optimization (LDSO). As a direct technique, DSO can utilize any image pixel with sufficient intensity gradient, which makes it robust even in featureless areas. LDSO retains this robustness, while at the same time ensuring repeatability of some of these points by favoring corner features in the tracking frontend. This repeatability allows to reliably detect loop closure candidates with a conventional feature-based bag-of-words (BoW) approach. Loop closure candidates are verified geometrically and Sim(3) relative pose constraints are estimated by jointly minimizing 2D and 3D geometric error terms. These constraints are fused with a co-visibility graph of relative poses extracted from DSO's sliding window optimization. Our evaluation on publicly available datasets demonstrates that the modified point selection strategy retains the tracking accuracy and robustness, and the integrated pose-graph optimization significantly reduces the accumulated rotation-, translation- and scale-drift, resulting in an overall performance comparable to state-of-the-art feature-based systems, even without global bundle adjustment.


Title: Energetic Efficiency of a Compositional Controller on a Monoped With an Articulated Leg and SLIP Dynamics
Key Words: design engineering  energy conservation  legged locomotion  motion control  nonlinear control systems  optimal control  optimisation  pendulums  robot dynamics  springs (mechanical)  trajectory control  energetic efficiency  compositional controller  articulated leg  SLIP dynamics  dynamic legged robot locomotion control  jumping robots  Raibert-style controller  SLIP-Raibert approach  trajectory-optimized controller  robot design  spring loaded inverted pendulum  three-link monoped model  Legged locomotion  Aerospace electronics  Actuators  Dynamics  Optimization  Robot kinematics 
Abstract: Embedding the dynamics of the Spring Loaded Inverted Pendulum (SLIP) and applying a compositional controller around it can simplify dynamic legged robot locomotion control, but what is the energetic cost of this convenience? This paper measures the magnitude of this effect in such a way that the results are applicable to a wide class of jumping robots. A three-link monoped model with revolute joints is used to compare the energetic costs of locomotion using two different control approaches: 1) SLIP-embedding with a Raibert-style controller optimized for energetic efficiency, and 2) a trajectory optimized only for energetic efficiency. By performing this comparison in simulation for a large number of different monopeds randomly sampled from a space of realistic robot designs, it is found that the SLIP-Raibert approach requires, on average, almost twice the energy of the trajectory-optimized controller to traverse a given distance. Furthermore, the increase in energetic cost does not depend much on the particulars of the robot design, as the SLIP-Raibert approach requires at least 50% more energy for approximately 88% of realistic robot designs.


Title: Precision Jumping Limits from Flight-phase Control in Salto-1P
Key Words: approximation theory  attitude control  control system synthesis  gait analysis  legged locomotion  motion control  position control  robot dynamics  velocity control  running velocity  precision results  height increases  foot placement precision degrades  attitude error  attitude control accuracy  error standard deviation  random walk  aggressive changes  precise foot placement  physical platform  offline dynamic model  order Taylor series approximation  untethered monopedal robot  deadbeat foot placement  Salto-1P  flight-phase control  precision jumping limits  Foot  Legged locomotion  Trajectory  Attitude control  Mathematical model  Robot kinematics 
Abstract: We developed a deadbeat foot placement hopping controller for an untethered monopedal robot, Salto-1P. The controller uses a third order Taylor series approximation to an offline dynamic model and performs well on the physical platform. The robot demonstrated precise foot placement even on trajectories with aggressive changes in speed, direction, and height: in a random walk, its error standard deviation was 0.10 m. We establish how foot placement precision is tightly limited by attitude control accuracy, requiring attitude error less than 0.7 degrees for some tasks. We also show how foot placement precision degrades linearly as hopping height increases. These precision results apply to the large class of controllers that prescribe touchdown angle to control running velocity.


Title: Analytically-Guided Design of a Tailed Bipedal Hopping Robot
Key Words: actuators  design engineering  legged locomotion  robot dynamics  robot kinematics  hybrid averaging analysis  conjectured closed form representation  approximate hopping limit cycle  physical control  dynamical design choices affords  tailed bipedal hopping robot  template dynamics  actuator template  spatial hopping gait  Actuators  Legged locomotion  Damping  Kinematics  Limit-cycles  Stability analysis 
Abstract: We present the first fully spatial hopping gait of a 12 DoF tailed biped driven by only 4 actuators. The control of this physical machine is built up from parallel compositions of controllers for progressively higher DoF extensions of a simple 2 DoF, 1 actuator template. These template dynamics are still not themselves integrable, but a new hybrid averaging analysis yields a conjectured closed form representation of the approximate hopping limit cycle as a function of its physical and control parameters. The resulting insight into the role of the machines kinematic and dynamical design choices affords a redesign leading to the newly achieved behavior.


Title: MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot
Key Words: actuators  gait analysis  legged locomotion  motion control  robot dynamics  robust control  control architecture  legged locomotion  abduction-adduction degrees  gait modification  cost of transport  CoT  proprioceptive actuation  leg design  mechanical design  dynamic quadruped robot  robust robot  MIT cheetah 3  Legged locomotion  Actuators  Torque  Force  Knee  Robot sensing systems 
Abstract: This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.


Title: Magneto: A Versatile Multi-Limbed Inspection Robot
Key Words: actuators  design engineering  inspection  legged locomotion  manipulator kinematics  quadruped climbing robot  high dimensional system design  human entry portholes  three degrees of freedom actuated limbs  3-DOF compliant magnetic foot  locomotion  complex 3-D structures  industrial confined spaces  body shape  multilimbed inspection robot  legged climbing robots  confined space openings  manipulation mode mid-climb  limb function  Magneto  compact foot design  Adhesives  Legged locomotion  Magnetic separation  Foot  Inspection  Soft magnetic materials 
Abstract: In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.


Title: Data-Driven Discrete Planning for Targeted Hopping of Compliantly Actuated Robotic Legs
Key Words: actuators  elasticity  legged locomotion  mobile robots  motion control  path planning  robot dynamics  planar hopping leg prototype validate  hopping trials  data-driven manner  serial elastic actuation  planar leg  discrete-time planning problem  simple controller structure  time-continuous trajectories  considerable real-time problems  fast locomotion  motion planning  compliantly actuated robotic legs  targeted hopping  data-driven discrete planning  Legged locomotion  Planning  Springs  Switches  Hardware 
Abstract: Motion planning for fast locomotion of compliantly actuated robotic legs is generally considered to be a challenging issue, posing considerable real-time problems. This is at least the case if time-continuous trajectories need to be generated online. In this paper we take advantage of a simple controller structure, which reduces the motion planning to a discrete-time planning problem, in which only a small set of input parameters need to be determined for each step. We show that for a planar leg with serial elastic actuation, hopping on a ground with stairs of irregular length and height can be planned online, based on a parameter mapping which has been learned in a data-driven manner by performing hopping trials with an adaptive exploration algorithm to evenly sample the parameter space. Experiments on a planar hopping leg prototype validate the approach.


Title: Quadrupedal walking motion and footstep placement through Linear Model Predictive Control
Key Words: convex programming  gait analysis  humanoid robots  legged locomotion  motion control  predictive control  robot dynamics  linear model predictive control framework  quadrupedal walking motion  auxiliary states  bipedal locomotion  hybrid wheeled-legged quadruped  humanoid upper-body  joint optimization problem  nonconvex programming framework  quadrupedal robot  automatic footstep placement  walking gait  CENTAURO robot  control inputs  linear constraints  approximate QP  Legged locomotion  Robot kinematics  Optimization  Stability analysis  Planning 
Abstract: The present work addresses the generation of a walking gait with automatic footstep placement for a quadrupedal robot, within a Linear Model Predictive Control framework. Existing work has shown how this is only possible within a non-convex programming framework, finding a solution of which is well-known to be very hard. We propose a way to formulate the joint optimization problem as an approximate QP with linear constraints, whose global optimum can be quickly found with off-the-shelf solvers. More specifically, this is done by introducing auxiliary states and control inputs, each of which is subject to linear constraints that are inspired from the literature on bipedal locomotion. Finally, we validate our method on the CENTAURO robot, a hybrid wheeled-legged quadruped with a humanoid upper-body.


Title: A Synergetic Voluntary Control for Exoskeleton based on Spinal Cord Mapping of Peripheral Bioelectric Activity
Key Words: bioelectric phenomena  electromyography  gait analysis  injuries  matrix decomposition  medical robotics  neurophysiology  patient rehabilitation  synergetic voluntary control  spinal cord mapping  peripheral bioelectric activity  voluntary motion intention  control method  exoskeleton robot control  voluntary lower limb muscle activities  spinal cord injury  muscle synergy  walking motion  spinal cord map level  reliable cord levels  unreliable spinal cord levels  maximally voluntary locomotion  whole-body muscle activity  intended lower limb muscle activity  spinal cord activity  walking rehabilitation  nonnegative matrix factorization  transformation matrix  hybrid assistive limb  walking experiments  Muscles  Legged locomotion  Spinal cord  Exoskeletons  Robot kinematics  Estimation 
Abstract: Walking rehabilitation must be performed based on voluntary motion intention, and for this purpose, the development of a control method for an exoskeleton robot based on voluntary intention is investigated. This study proposes a method of exoskeleton robot control to estimate the voluntary lower limb muscle activities lost after a spinal cord injury (SCI). This method is based on the spinal cord mapping of the remaining muscle activities and its matching to the one obtained from healthy participants considering the muscle synergy of the whole body during the walking motion. By implementing the matching procedure at the spinal cord map level and incorporating information of reliable and unreliable spinal cord levels based on a diagnosis, the method has the potential to provide a maximally voluntary locomotion for people with SCI. We report an analysis of the synergy of the whole-body muscle activity during walking and its spinal cord mapping using non-negative matrix factorization and the computation of the transformation matrix to estimate the intended lower limb muscle activity from the remaining spinal cord activity. The implementation of the proposed method using the right leg of the hybrid assistive limb and walking experiments with a healthy participant are also reported.


Title: Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton with Hemiplegia Patients
Key Words: adaptive control  dynamic programming  gait analysis  handicapped aids  iterative methods  learning (artificial intelligence)  medical robotics  motion control  multi-agent systems  patient rehabilitation  hemiplegia patient  lower limb exoskeleton  learning-based walking assistance control strategy  paraplegia patients  leader-follower multi-agent system  LF-MAS  reinforcement learning framework  policy iteration adaptive dynamic programming algorithm  PI-ADP algorithm  tracking control  Legged locomotion  Exoskeletons  Reinforcement learning  Control systems  Heuristic algorithms  Multi-agent systems  Cost function  Walking Assistance Strategy  Leader-Follower Multi-Agent System  Reinforcement Learning  Lower Exoskeleton  Hemiplegia 
Abstract: Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.


Title: Similarity of the Impact of Humanoid and In-Person Communications on Frontal Brain Activity of Older People
Key Words: brain  geriatrics  handicapped aids  humanoid robots  human-robot interaction  medical robotics  older people  in-person communication  brain information  frontal brain activity  humanoid robot  video-chat  speaker  brain activation  storytelling experiment  sensory gateway  behavioural responses  human-robot interaction  Brain  Humanoid robots  Time series analysis  Media  Senior citizens  Data acquisition 
Abstract: We report results of the analyses of the effect of communication through a humanoid robot in comparison with in-person, video-chat, and speaker on frontal brain activity of older people during an storytelling experiment. Our results suggest that whereas communicating through a physically embodied medium potentially induces a significantly higher pattern of brain activation with respect to video-chat and speaker, its difference is non-significant in comparison with in-person communication. These results imply that communicating through a humanoid robot induces a pattern of brain activity in older people that is potentially similar to in-person communication. Our findings benefit researchers and practitioners in rehabilitation and elderly care facilities in search of effective means of communication with their patients to increase their involvement in the incremental steps of their treatments. Moreover, they imply the utility of brain information as a promising sensory gateway in characterization of the behavioural responses in human-robot interaction.


Title: A Phase Variable Approach to Volitional Control of Powered Knee-Ankle Prostheses
Key Words: artificial limbs  finite state machines  gait analysis  legged locomotion  medical robotics  motion control  trajectory control  volitional control  powered knee-ankle prostheses  multijoint prosthetic legs  periodic walking  piecewise holonomic phase variable  finite state machine  nominal reference gait trajectory  high-speed walking  backward walking  phase variable approach  volitional leg motions  Legged locomotion  Thigh  Trajectory  Task analysis  Prosthetics  Sensors  Foot 
Abstract: Although there has been recent progress in control of multi-joint prosthetic legs for periodic tasks such as walking, volitional control of these systems for non-periodic maneuvers is still an open problem. In this paper, we develop a new controller that is capable of both periodic walking and common volitional leg motions based on a piecewise holonomic phase variable through a finite state machine. The phase variable is constructed by measuring the thigh angle, and the transitions in the finite state machine are formulated through sensing foot contact together with attributes of a nominal reference gait trajectory. The controller was implemented on a powered knee-ankle prosthesis and tested with a transfemoral amputee subject, who successfully performed a wide range of periodic and non-periodic tasks, including low- and high-speed walking, quick start and stop, backward walking, walking over obstacles, and kicking a soccer ball. The proposed approach is expected to provide better understanding of volitional motions and lead to more reliable control of multi-joint prostheses for a wider range of tasks.


Title: Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform
Key Words: biomechanics  force control  medical robotics  patient rehabilitation  position control  robotic device interacts  pre-clinical validation  upper-limb rehabilitation robotic platform  UHP multifunctional upper-limb rehabilitation robot  rehabilitation therapies  UHP rehabilitation robot  multifunctional device  robotized therapies  advanced position-force control approaches  Rehabilitation robotics  Training  Games  Software  Robot sensing systems  Elbow 
Abstract: Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.


Title: Cable Actuated Dexterous (CADEX) Glove for Effective Rehabilitation of the Hand for Patients with Neurological diseases
Key Words: actuators  biomechanics  bone  dexterous manipulators  diseases  medical disorders  medical robotics  neurophysiology  patient rehabilitation  decoupled opposition-reposition  functional recovery  CADEX glove  consistent motion  actuated cables  exotendons  dexterous motion  carpometacarpal joint  simple thumb motions  compact design  soft robotic devices  wearable robotic devices  hands  larger motor cortical area  recovery motor function  motor cortex  neuroplastic change  neurological disease  effective rehabilitation  cable actuated dexterous glove  Thumb  Force  Routing  Silicon  Tendons  IP networks 
Abstract: Neuroplastic changes in motor cortex is essential for the recovery motor function of patients with neurological diseases. To enlarge neuroplastic change, various movements should be provided to stimulate larger motor cortical area, and because hands occupy the largest area, it is especially important. Many wearable robotic devices have been developed for rehabilitation of the hand, and soft robotic devices in particular have drawn attention for their compact design. However, most soft devices provide simple thumb motions, which flex or extend all joints without assistance of opposition/reposition of the carpometacarpal joint although the importance in producing various grasps. In this study, the design of a cable actuated dexterous (CADEX) glove is proposed. For dexterous motion, the structure and orientation of major finger tendons were replicated with exotendons (actuated cables), and four exotendons were used for the thumb with the path optimized to provide flexion/extension of the thumb and decoupled opposition/reposition of the carpometacarpal with other joints. To provide consistent motion, silicon was used for stable anchoring of exotendons while preventing slippage and reducing deformation. The motion generated by the CADEX glove was experimentally evaluated for a single healthy subject. The result shows that the CADEX glove could flex and extend the finger with various ratios among joints, and the opposition/reposition of carpometacarpal joint of the thumb could be achieved consistently with minimal effect on the other joints. The CADEX glove is expected to help providing various tasks which is expected to enhance the functional recovery of patients with neurological disease.


Title: SMA based wrist exoskeleton for rehabilitation therapy*
Key Words: biomechanics  electroactive polymer actuators  medical robotics  patient rehabilitation  pneumatic actuators  shape memory effects  wearable robots  SMA based wrist exoskeleton  rehabilitation therapy  rehabilitation wearable exoskeleton  wrist joint  flexion-extension  adduction-abduction  Shape Memory Alloy based actuators  SMA actuator technology  rehabilitation robotic devices  Wrist  Actuators  Exoskeletons  Wires  Medical treatment  Robots  Biological system modeling 
Abstract: This paper presents a rehabilitation wearable exoskeleton for wrist joint with two degrees of freedom (DOF), flexion-extension and adduction-abduction (radial and ulnar deviation), actuated with Shape Memory Alloy (SMA) based actuators. Thanks to this type of actuators, the proposed device presents a very light weight and noiseless operation, in comparison with similar devices. The preliminary results obtained over real tests with the wrist exoskeleton are presented. This prototype demonstrates that SMA actuator technology is a viable alternative when investigating possible improvement of rehabilitation robotic devices in terms of weight, size and cost.


Title: Utility Model Re-description within a Motivational System for Cognitive Robotics
Key Words: cognition  intelligent robots  learning (artificial intelligence)  motivational system  cognitive architecture  interaction traces  robotic setup  cognitive robotics  value functions  redescriptive approach  utility model redescription  precise utility models  MotivEn model  robot coordination  Robot sensing systems  Cognitive systems  Robot kinematics  Space exploration  Instruments  Drives 
Abstract: This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.


Title: A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *
Key Words: audio signal processing  audio-visual systems  avatars  humanoid robots  learning (artificial intelligence)  motion control  crossmodal conflict resolution  robot sensorimotor coupling  swift behaviour  robust behaviour  neurorobotic experiment  iCub robot exhibits  complex crossmodal environment  multisensory conflicts  behavioural study  audio-visual cues  visual bias  discrete behavioural response  complex environments  incongruent dynamic audio-visual cues  human-like responses  environmental statistics  stereophonic sound processing  facial features  body motion  deep learning model  animated avatars  Avatars  Visualization  Robot sensing systems  Lips  Task analysis  Spatial resolution 
Abstract: Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.


Title: Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots
Key Words: human-robot interaction  learning (artificial intelligence)  mobile robots  neural nets  object detection  object recognition  service robots  robust object recognition  symbiotic deep learning  mobile service robot  human environments  symbiotic autonomy approach  HHELP  RGB camera  onboard tablet  object detection  deep neural network  domestic environment  YOLOv2 neural network  bootstrap YOLOv2  CMU  Monarch Mbot  ISR-Lisbon  Neural networks  Labeling  Training  Symbiosis  Service robots  Object recognition 
Abstract: Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.


Title: People as Sensors: Imputing Maps from Human Actions
Key Words: collision avoidance  driver information systems  mobile robots  pedestrians  road vehicles  human actions  autonomous vehicles  pedestrian detection  collision avoidance  map estimation  human driving experiments  landmark-based mapping approaches  agents actions  Random variables  Estimation  Automobiles  Computational modeling  Intelligent sensors 
Abstract: Despite growing attention in autonomy, there are still many open problems, including how autonomous vehicles will interact and communicate with other agents, such as human drivers and pedestrians. Unlike most approaches that focus on pedestrian detection and planning for collision avoidance, this paper considers modeling the interaction between human drivers and pedestrians and how it might influence map estimation, as a proxy for detection. We take a mapping inspired approach and incorporate people as sensors into mapping frameworks. By taking advantage of other agents' actions, we demonstrate how we can impute portions of the map that would otherwise be occluded. We evaluate our framework in human driving experiments and on real-world data, using occupancy grids and landmark-based mapping approaches. Our approach significantly improves overall environment awareness and outperforms standard mapping techniques.


Title: How do humans read robotics? The matter of the lexical ambiguity resolution
Key Words: human-robot interaction  robotic actions  lexical ambiguity resolution  Robots  Linguistics  Rhetoric  Semantics  Task analysis  Psychology 
Abstract: The words used to describe robotic performances include a degree of ambiguity that the human brain should solve without difficulty. However, the language used in-and about-robotics seems to escape from the ordinary processing of lexical ambiguity resolution. In this paper, we argue that there is no lack of an adequate language for robotics but that the lexicon at hand is forced by our representations. We investigate the main representational issues of the notions that express robotic actions and dispositions (i.e. behaviors).


Title: Free-View, 3D Gaze-Guided, Assistive Robotic System for Activities of Daily Living
Key Words: assisted living  end effectors  gaze tracking  medical robotics  object recognition  trajectory control  user interfaces  gaze control  assistive robotic system  daily living  free-view gaze interface  object recognition  trajectory planning  quadriplegia patient  end-effector position  Three-dimensional displays  Cameras  Task analysis  Robot kinematics  Object recognition  Planning 
Abstract: Patients suffering from quadriplegia have limited body motion which prevents them from performing daily activities. We have developed an assistive robotic system with an intuitive free-view gaze interface. The user's point of regard is estimated in 3D space while allowing free head movement and is combined with object recognition and trajectory planning. This framework allows the user to interact with objects using fixations. Two operational modes have been implemented to cater for different eventualities. The automatic mode performs a pre-defined task associated with a gaze-selected object, while the manual mode allows gaze control of the robot's end-effector position on the user's frame of reference. User studies reported effortless operation in automatic mode. A manual pick and place task achieved a success rate of 100% on the users' first attempt.


Title: The Future of Legal and Ethical Regulations for Autonomous Robotics
Key Words: consumer electronics  mobile robots  autonomous robotics  autonomous systems  novel autonomy framework  device safety  regulatory frameworks  specific framework those devices  future autonomy regulations  consumer electronics vis-á-vis medical devices  regulatory landscape  autonomous elements  future regulation  Autonomous systems  Robots  Law  Standards  Ethics  Complex systems 
Abstract: “Autonomous robotics” promise significant improvements across a host of different complex systems, which will need to be managed within regulatory frameworks to promote, at a minimum, device safety. Contrary to how they are often portrayed, however, these systems do not necessarily require fundamentally new approaches to engineering or regulatory challenges, i.e., the development of a novel “autonomy framework” applicable to different types of devices. Rather, because autonomous systems generally represent a progressive improvement of existing complex systems, preexisting regulatory scheme offer the best guidance for considering future regulation of autonomous elements. Moreover, the regulatory landscape differs considerably based on the type of device at issue (e.g., consumer electronics vis-á-vis medical devices). This paper argues that users and regulators must consider future autonomy regulations within the specific framework those devices currently inhabit, rather than focusing on a novel set of rules divorced from the preexisting context.


Title: Uncertainty-based Online Mapping and Motion Planning for Marine Robotics Guidance
Key Words: autonomous underwater vehicles  path planning  probability  robot dynamics  vehicle dynamics  uncertainty-based framework  online computation constraints  motion planning  marine robotics guidance  robotic systems  safe path  underwater environments  autonomous vehicles  probabilistic safety  online mapping  Uncertainty  Safety  Planning  Probabilistic logic  Robot sensing systems  Vehicle dynamics 
Abstract: In real-world robotics, motion planning remains to be an open challenge. Not only robotic systems are required to move through unexplored environments, but also their manoeuvrability is constrained by their dynamics and often suffer from uncertainty. One approach to overcome this problem is to incrementally map the surroundings while, simultaneously, planning a safe and feasible path to a desired goal. This is especially critical in underwater environments, where autonomous vehicles must deal with both motion and environment uncertainties. In order to cope with these constraints, this work proposes an uncertainty-based framework for mapping and planning3 feasible motions online with probabilistic safety-guarantees. The proposed approach deals with the motion, probabilistic safety, and online computation constraints by (i) incrementally representing the environment as a collection of local maps, and (ii) iteratively (re)planning kinodynamically-feasible and probabilistically-safe paths to goal. The proposed framework is evaluated on the Sparus II, a nonholonomic torpedo-shaped AUV, by conducting simulated and real-world trials, thus proving the efficacy of the method and its suitability even for systems with limited on-board computational power.


Title: Passive acoustic tracking for behavior mode classification between surface and underwater vehicles
Key Words: autonomous underwater vehicles  hydrophones  mobile robots  acoustic modems  vehicle state  communication line  submerged vehicles  hydrophone arrays  AUV mode estimates  dynamic time  simulation data  simulation-based classifier  bearing tracking data  passive tracking  TTI data  field array data  experiment data  surface vessels  AUV behavior  passive acoustic tracking  behavior mode classification  autonomous underwater vehicles  speed-of-light communication  AUV platforms  surface vehicle behavior  K-nearest-neighbor  Boats  Acoustics  Sea surface  Trajectory  Arrays  Data models  Sonar equipment 
Abstract: Autonomous underwater vehicles (AUVs) pose significant communication challenges: vehicles are submerged for periods of time in which speed-of-light communication is impossible. This is a particular problem on low-cost AUV platforms, on which acoustic modems are not available to get vehicle state or provide re-deploy commands. We investigate one possible method of providing operators with a communication line to these vehicles by using noise underwater to both classify behavior of submerged vehicles and to command them. In this scheme, processing of data from hydrophone arrays provide operators with AUV mode estimates and AUVs with surface vehicle behavior updates. Simulation studies were used to characterize trajectories for simple transect versus loiter behaviors based on the bearing and time to intercept (TTI). A classifier based on K-nearest-neighbor with dynamic time warping as a distance metric was used to classify simulation data. The simulation-based classifier was then applied to classify bearing tracking data from passive tracking of a loitering AUV and bearing and TTI data from passive tracking of a transecting boat based on field array data. Experiment data was classified with 76 % accuracy using bearing-only data, 96% accuracy for TTI -only data and 99 % accuracy for combined classification. The techniques developed here could be used for AUV cuing by surface vessels and monitoring of AUV behavior.


Title: A Rationale-Driven Team Plan Representation for Autonomous Intra-Robot Replanning*
Key Words: mobile robots  multi-robot systems  path planning  rationale-driven team plan representation  autonomous multirobot teams  autonomous intrarobot replanning  team planner  intrarobot replanning algorithm  Robots  Oceans  Task analysis  Prediction algorithms  Planning  Satellites  Global Positioning System 
Abstract: For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.


Title: Stochastic Optimization for Autonomous Vehicles with Limited Control Authority
Key Words: gradient methods  greedy algorithms  mobile robots  optimisation  state-space methods  stochastic processes  SGA  multivehicle information gathering  action space representation  stochastic optimization scheme  perturbed action sequences  state space information function  sequential greedy allocation  autonomous vehicles  stochastic gradient ascent algorithm  vehicle control authority  navy coastal ocean model  NCOM  Gulf of Mexico  GoM  Monte Carlo tree search method  MCTS  Oceans  Optimization  Stochastic processes  Approximation algorithms  Trajectory  Aerospace electronics  Robots 
Abstract: In this work, we present a Stochastic Gradient Ascent (SGA) algorithm for multi-vehicle information gathering that accounts for limitations on a vehicle's control authority caused by external forces. By representing vehicle paths using a novel action space representation, rather than a state space representation, we remove the need to perform feasibility calculations on the vehicle's path. Our algorithm uses a stochastic optimization scheme by sampling perturbed action sequences around the current best known sequence to estimate the gradient of a state space information function with respect to the action sequence. Additionally, we use sequential greedy allocation to plan for multiple vehicles. Results are shown using a Navy Coastal Ocean Model (NCOM) for the Gulf of Mexico (GoM). SGA shows improvement in the amount of information gained over a greedy baseline. Additionally, we compare to Monte Carlo Tree Search (MCTS) Method, which is able to gather competitive amounts of information but is more computationally intensive than our approach.


Title: Proactive Collision Avoidance for ASVs using A Dynamic Reciprocal Velocity Obstacles Method
Key Words: collision avoidance  marine vehicles  mobile robots  velocity control  reciprocal velocity obstacles framework  dynamic obstacles  collision avoidance decisions  international regulations  autonomous surface vessel  future behavior  interactive behavior  collision avoidance method  dynamic reciprocal velocity obstacles method  proactive collision avoidance  COLREGs  ASV behavior  complex dynamic models  RVO framework  predictive approach  Collision avoidance  Decision making  Propulsion  Uncertainty  Sensor systems  Computational modeling 
Abstract: We propose a collision avoidance method that incorporates the interactive behavior of agents and is proactive in dealing with the uncertainty of the future behavior of obstacles. The proposed method considers interactions that will be experienced by an autonomous surface vessel (ASV) in an environment governed by the international regulations for preventing collisions at sea (COLREGs). Our approach aims at encouraging dynamic obstacles to cooperate according to COLREGs. Therefore, we propose a strategy for assessing the cooperative behavior of obstacles, and the result of the assessment is used to adapt collision avoidance decisions within the Reciprocal Velocity Obstacles (RVO) framework. Moreover, we propose a predictive approach to solving known limitations of the RVO framework, and we present computationally feasible extensions that enable the use of complex dynamic models and objectives suitable for ASVs. We demonstrate the performance and potentials of our method through a simulation study, and the results show that the proposed method leads to proactive and more predictable ASV behavior compared with both Velocity Obstacles (VO) and RVO, especially when obstacles cooperate by following COLREGs.


Title: A Multi-Task Priority Framework for Redundant Robots with Multiple Kinematic Chains under Hard Joint and Cartesian Constraints
Key Words: redundant manipulators  multiple kinematic chains  hard joint  reverse priority framework  kinematic control  redundant robots  reverse priority method  robotic systems  bilateral constraints  unilateral constraints  multitask priority framework  joint priorities  Cartesian constraints  Task analysis  Kinematics  Jacobian matrices  Redundancy  End effectors 
Abstract: This paper introduces an extension of the reverse priority framework for the kinematic control of redundant robots. It integrates, in a unified framework, the treatment of multiple tasks, multiple kinematic chains, different joint priorities and hard constraints. The management of multiple tasks is based on the reverse priority method, that has been modified so that it makes possible the assignment of different priorities to each joint in order to accomplish the tasks. This framework is also suitable for robotic systems with multiple kinematic chains, which could share several joints. Moreover, it can deal with bilateral and unilateral constraints, that can be defined either at joint or cartesian space. Hard constraints are considered at each priority level, instead of treating them separately at the highest priority level. The proposed framework has been evaluated in simulation and in real experiments with a redundant underwater vehicle-manipulator system at sea.


Title: Vision-based Target Tracking for a Skid-steer Vehicle using Guided Policy Search with Field-of-view Constraint
Key Words: learning (artificial intelligence)  mobile robots  optimisation  remotely operated vehicles  robot dynamics  robot kinematics  robot vision  search problems  steering systems  target tracking  skid-steer vehicle  guided policy search  skid-type robot  local policy optimization  FOV constraint  vision-based tracking policy  skid-steer mobile robot  field-of-view constraint  vision-based target tracking method  end-to-end policy  pixel image data  deep reinforcement learning  kinematic slip model  Mobile robots  Training  Kinematics  Cameras  Target tracking  Wheels 
Abstract: This paper describes a vision-based target tracking method for a skid-steer vehicle. With the development of deep reinforcement learning, many researchers have tried to generate an end-to-end policy to control the mobile robot from a raw pixel image data. However, the action in most research only concerns high-level decisions such as go straight, turn left and right. High-level decisions alone are not sufficient to precisely control platforms such as a skid-steer vehicle due to the lack of steering mechanism. Thus, unlike existing work, we aim to control the motor command for the wheels directly. To this end, we employ guided policy search (GPS) based on the general kinematic slip model for the skid-type robot. Furthermore, to prohibit the target from getting out of the camera field of view (FOV) in the training phase, we update local policy optimization with a FOV constraint and perform a pre-training to make the initial policy more efficient. Our method allows the skid-type robot to automatically acquire the vision-based tracking policy while local policies satisfy the FOV constraint during the training phase. We evaluate our method through both simulation and experiment with a skid-steer mobile robot. Finally, we test the performance of learned policy with a moving target in a new environment.


Title: On the Kinematics of Wheeled Motion Control of a Hybrid Wheeled-Legged CENTAURO robot
Key Words: legged locomotion  motion control  robot kinematics  stability  wheels  wheeled-legged CENTAURO robot  real-world terrains  mobile platforms  versatile mobility  first-order inverse kinematics scheme  wheeled mobility  legged-wheeled motion kinematics control  wheels camber angles  legged-wheeled system stability  floating base model  legged-wheeled centaur-like robot  Legged locomotion  Wheels  Kinematics  Robot kinematics  Solid modeling 
Abstract: Legged-wheeled robots combine the advantages of efficient wheeled mobility with the adaptability to real-world terrains through the legged locomotion. Due to this hybrid mobility skill, they can excel in many application scenarios where other mobile platforms are not suitable for. However, their versatile mobility increases the number of constraints in their motion control where both the properties of legged and wheeled systems need to be considered. Relevant schemes for legged-wheeled platforms so far have been developed exploiting separate motion control of the wheeled and legged functionalities. This paper discusses the legged-wheeled motion kinematics without constraining the camber angles of the wheels, and it proposes a first-order inverse kinematics scheme that stabilizes the legged-wheeled system in the wheeled motion. Furthermore, the work adopts a floating base model that allows to easily incorporate the legged motion to the scheme. The developed controller is tested in simulation and experiments on a legged-wheeled centaur-like robot - CENTAURO.


Title: Development of Stone Throwing Robot and High Precision Driving Control for Curling
Key Words: artificial intelligence  control engineering computing  control system synthesis  feedforward  mobile robots  motion control  observers  position control  three-term control  velocity control  wheels  AI system  stone throwing robot  curling sports  throwing-curling  artificial intelligence system  precise driving control  STR driving  robust heading angle control  model-based feedforward control  conventional PID controller  anti-slip control  dimensional drive control  curling sport  robot component  developed robot  novel mobile robot  high precision driving Control  Mobile robots  Wheels  Cameras  Artificial intelligence  Ice  Servers 
Abstract: In this paper, a novel mobile robot developed to perform Curling sports is introduced. The developed robot is a Stone Throwing Robot (STR) for Curling that can travel on the ice with wheels and throw a stone as well as make curls of the stone. The STR is developed as a robot component of an Artificial Intelligence(AI) system that can autonomously play the curling sport. The proposed STR can throw a stone at any desired speed and in any desired direction, which are determined by the AI system. To achieve this precise driving of the STR and throwing of the stone, two dimensional drive control is developed for the STR, which consists of 1) anti-slip control for high traction, 2) precise velocity control and 3) high accuracy heading angle control. In addition to the conventional PID controller, model-based feedforward control, Model Following Control (MFC) for the anti-slip control of the wheel on the ice and Yaw Moment Observer (YMO) for the robust heading angle control are applied as key technologies for the STR driving. The design configurations of the STR to achieve the detection of its own location and throwing/curling of the stone is proposed in this paper as well as the detail of the precise driving control.


Title: MAP - A Mobile Agile Printer Robot for on-site Construction
Key Words: construction  legged locomotion  mobile robots  robot kinematics  service robots  three-dimensional printing  wheels  outdoors construction site  3D printing large structures  omnidirectional robot capable  Mobile Agile Printer construction robot  on-site construction  concurrent on-site operations  low 3D printing trajectory deviations  construction robots  mobile platform  high-DoF 3D printing system  MAP  Three-dimensional printing  Wheels  Legged locomotion  Printers 
Abstract: In this paper, we present a Mobile Agile Printer (MAP) construction robot; a highly agile, 4-legged, omnidirectional robot capable of 3D printing large structures. To overcome dynamic challenges when operating within an outdoors construction site, MAP incorporates a high-DoF 3D printing system connected to a mobile platform with novel features designed to enable disturbance rejection and live adaption to the robot's pose. In doing so, we demonstrate the benefits of designing construction robots with a focus on agility, a compact working volume and ability to operate within a potentially unlimited workspace. Performance tests were conducted showing smooth omni-directional motion as a key requirement for maintaining low 3D printing trajectory deviations over a large volume. In doing so, we show that MAP has the ability to construct in new ways more sensitive to its environment, context and concurrent on-site operations.


Title: Slip Modeling and Estimation for a Planetary Exploration Rover: Experimental Results from Mt. Etna
Key Words: aerospace robotics  mobile robots  planetary rovers  position control  wheels  wheel-soil interaction properties  inherent errors  wheel slippage  parameter-based approach  whole-body slip modeling  lightweight rover system  slip parameter calibration  system-specific implementation  experimental results  Mt. Etna  resulting wheel odometry measurements  space exploration scenario  planetary exploration rover  wheeled mobile systems  planetary rovers  planetary exploration missions  Wheels  Jacobian matrices  Trajectory  Current measurement  Extraterrestrial measurements  Soil  Mathematical model 
Abstract: For wheeled mobile systems, the wheel odometry is an important source of information about the current motion of the vehicle. It is used e.g. in the context of pose estimation and self-localization of planetary rovers, which is a crucial part of the success of planetary exploration missions. Depending on the wheel-soil interaction properties, wheel odometry measurements are subject to inherent errors such as wheel slippage. In this paper, a parameter-based approach for whole-body slip modeling and calibration is applied to a four-wheeled lightweight rover system. Details on the method for slip parameter calibration as well as the system-specific implementation are given. Experimental results from a test campaign on Mt. Etna are presented, showing significant improvements of the resulting wheel odometry measurements. The results are validated during a long range drive of approx. 900 m and discussed w. r. t. the advantages but also limitations of the method within a space exploration scenario.


Title: User-specific Gaussian Process Model of Wheelchair Drivers with a Haptic Joystick Interface
Key Words: Gaussian processes  handicapped aids  haptic interfaces  human-robot interaction  interactive devices  man-machine systems  mobile robots  navigation  path planning  user modelling  wheelchairs  Gaussian process  spastic wheelchair user  navigation assistance frequency  achievable user model evaluation frequency  haptic joysticks  probabilistic user-specific driver model  mental navigation plan  particular user  personalised driver model  navigation plans  probabilistic framework  navigation task  inherent uncertainty  heterogeneous driving styles  mobile robot  intuitive control  driving semiautonomous  collaborative human-robot navigation  haptic joystick interface  wheelchair drivers  user-specific Gaussian process model  Wheelchairs  Navigation  Mobile robots  Probabilistic logic  Gaussian processes  Hidden Markov models 
Abstract: In collaborative human-robot navigation such as when driving semi-autonomous robotic wheelchairs, intuitive control of the mobile robot is only possible if the robot understands its user. This becomes especially important as users present varying levels of abilities and heterogeneous driving styles. Furthermore, the robot needs to consider the inherent uncertainty on its navigation task because the user may not be able to communicate his or her plans explicitly. In order to address these requirements, we have adopted a probabilistic framework to recognise navigation plans. A key component in this framework is a personalised driver model, which captures how a particular user transforms his or her mental navigation plan into inputs to the robot. In this work, we evaluate the use of Gaussian Processes to implement and calibrate this probabilistic, user-specific driver model, and this for use with haptic joysticks. Furthermore, special care was taken to obtain fast online evaluation of this user model through sparse approximation and parallel computation on a GPU. This resulted in an achievable user model evaluation frequency of 40 Hz, which is far above the navigation assistance frequency we aimed for, i.e. 5 Hz. We illustrate the validity of the approach by recognising the navigation plans of a spastic wheelchair user.


Title: A minimalist Stair Climbing Robot (SCR) formed as a leg balancing & climbing Mobile Inverted Pendulum (MIP)
Key Words: feedback  legged locomotion  motion control  pendulums  robot kinematics  service robots  stability  wheels  SCR  leg balancing  patent-pending  minimal-complexity Stair Climbing Robot  vehicle design  stairs  leveraging feedback control  foot  MIP drive wheels  reaction wheels  stair-climbing throwbot  mobile inverted pendulum  left-right stability  fore-aft stabilization  chassis-wheel assembly  minimalist stair climbing robot  Wheels  Legged locomotion  Robot kinematics  Gears  Torque 
Abstract: This paper presents a (patent-pending) small, quasi-static, minimal-complexity Stair Climbing Robot (SCR). The vehicle design is given simply by adding a third motor to a (Segway-like) Mobile Inverted Pendulum (MIP), enabling it to maneuver up stairs, leveraging feedback control, by planting it's “foot” onto the ground in front of the next step, lifting the chassis/wheel assembly up it's own “leg”, leaning over onto the top of the next step, self uprighting, and repeating for the following step(s). Fore/aft stabilization during leg balancing is given by using the MIP drive wheels as reaction wheels, while left/right stability is given by the width of the foot itself. The design is small and simple enough to potentially be ruggedized as a stair-climbing throwbot, akin to the Recon Scout (but able to climb up stairs) for reconnaissance in military and homeland security applications.


Title: Tire Force Estimation of Dynamic Wheeled Mobile Robots using Tire-Model Based Constrained Kalman Filtering
Key Words: automobiles  feedback  friction  gears  Kalman filters  mobile robots  robot dynamics  tyres  wheels  wheel encoders  tire-road interaction  estimation algorithm  three-dimensional individual tire forces  dynamic wheeled mobile robots  tire-model based constrained Kalman filtering  tire force real-time estimation  tire force estimation techniques  car-like rearwheel-driven four wheel wheeled mobile robots  onboard navigation sensors  feedback  tire-road friction coefficient  torque inputs  differential gear  CarSim  Tires  Wheels  Force  Estimation  Dynamics  Sensors  Friction 
Abstract: We propose a novel real-time algorithm to estimate the full three-dimensional individual tire forces (i.e., vertical, longitudinal as well as lateral) of a car-like rearwheel-driven four wheel wheeled mobile robots equipped with onboard navigation sensors and wheel encoders. The key enabling idea for this is to utilize the tire model (i.e., the magic formula) in a feedback manner on the framework of the constrained Kalman filtering to render the tire force estimation: 1) more accurate as compared to the typical tire force estimation techniques neglecting the tire-road interaction; and 2) more robust as compared to the results adopting the tire model, yet, only in an open-loop manner. Our proposed algorithm, while performing this full tire force onboard/real-time estimation, also provides the estimation of: 1) tire-road friction coefficient; and 2) torque inputs of the rear left and right wheels, which are connected via differential gear. Simulations with CarSim and outdoor experiments are performed to validate the proposed estimation algorithm.


Title: Online Spatial Sound Perception Using Microphone Array on Mobile Robot*
Key Words: acoustic generators  acoustic signal detection  acoustic signal processing  convolutional neural nets  microphone arrays  mobile robots  probability  probabilistic regions  sound sources  microphone array  autonomous mobile robot  three-dimensional position localization  sound signals detection  online spatial sound perception system  convolutional neural network  CNN  three-dimensional position recognition  sound positions estimation  Mobile robots  Robot sensing systems  Microphone arrays  Estimation  Probabilistic logic 
Abstract: The paper proposes a spatial sound perception system for an autonomous mobile robot. The system performs three-dimensional position localization and recognition as online processing from a robot in motion. For online processing, the sound positions are estimated as probabilistic regions in three dimensional space, because the robot could observe only arrival direction of the sound at a moment. The detected sound signals are recognized using Convolutional Neural Network (CNN), for the adjustment to short input signals. The experimental results show our mobile robot could observe surrounding sound sources online and continuously update its position and sound label.


Title: Extracting the Relationship between the Spatial Distribution and Types of Bird Vocalizations Using Robot Audition System HARK
Key Words: acoustic signal processing  biocommunications  microphone arrays  robots  zoology  HARK robot audition system  song-behavior relationships  HARKBird  wild birds  2D localize vocalizations  vocalizations characteristics  microphone arrays  portable observation system  wild bird vocalizations  ecological functions  spatial distribution  Birds  Microphone arrays  Two dimensional displays  Robots  Real-time systems  Arrays 
Abstract: For a deeper understanding of ecological functions and semantics of wild bird vocalizations (i.e., songs and calls), it is important to clarify the fine-scaled and detailed relationships among their characteristics of vocalizations and their behavioral contexts. However, it takes a lot of time and effort to obtain such data using conventional recordings or by human observation. Bringing out a robot to a field is our approach to solve this problem. We are developing a portable observation system called HARKBird using a robot audition HARK and microphone arrays to understand temporal patterns of vocalizations characteristics and their behavioral contexts. In this paper, we introduce a prototype system to 2D localize vocalizations of wild birds in real-time, and to classify their song types after recording. We show that the system can estimate the position of songs of a target individual and classify their songs with a reasonable quality to discuss their song - behavior relationships.


Title: Failure Detection Using Proprioceptive, Auditory and Visual Modalities
Key Words: computerised monitoring  humanoid robots  manipulators  robot vision  sensor fusion  failure detection  continuous execution monitoring  multimodal failure monitoring  single sensor modality  high level proprioceptive  auditory predicates  visual predicates  humanoid robot  tabletop manipulation scenarios  safety handling  multimodal fusion  Robot sensing systems  Hidden Markov models  Monitoring  Visualization  Task analysis  Grasping 
Abstract: Handling safety is crucial to achieve lifelong autonomy for robots. Unsafe situations might arise during manipulation in unstructured environments due to noises in sensory feedback, improper action parameters, hardware limitations or external factors. In order to assure safety, continuous execution monitoring and failure detection procedures are mandatory. To this end, we present a multimodal failure monitoring and detection system to detect manipulation failures. Rather than relying only on a single sensor modality, we consider integration of different modalities to get better detection performance in different failure cases. In our system, high level proprioceptive, auditory and visual predicates are extracted by processing each modality separately. Then, the extracted predicates are fused. Experiments on a humanoid robot for tabletop manipulation scenarios indicate that the contribution of each modality is different depending on the action in execution and multimodal fusion results in an overall performance increase in detecting failures compared to the performance attained by unimodal processing.


Title: HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System
Key Words: acoustic signal processing  feature extraction  learning (artificial intelligence)  microphone arrays  neural nets  public domain software  robots  zoology  wild birds  portable device  sound sources  real-time requirement  sound source detection  bird song analysis  open source software  bird song classifier  portability  computational time  bird song dataset  classification accuracy  HARK-bird-box  real-time bird song scene analysis system  Birds  Real-time systems  Microphone arrays  Source separation  Feature extraction  Image analysis  bird song scene analysis  robot audition  scene understanding  real-time system 
Abstract: This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.


Title: Multi-timescale Feature-extraction Architecture of Deep Neural Networks for Acoustic Model Training from Raw Speech Signal
Key Words: acoustic signal processing  feature extraction  neural nets  speech recognition  robot audition  normalization-free processing  speech features  multitimescale architecture  speech signals  low-latency speech recognition  utterance-wise mean subtraction  acoustic models  raw speech signal  acoustic model training  deep neural networks  multitimescale feature-extraction architecture  Feature extraction  Acoustics  Artificial neural networks  Splicing  Robots  Filter banks  Training 
Abstract: This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.


Title: Tracking a moving sound source from a multi-rotor drone
Key Words: acoustic signal processing  audio signal processing  autonomous aerial vehicles  cameras  feature extraction  helicopters  humanoid robots  particle filtering (numerical methods)  signal denoising  spatial filters  time-frequency analysis  ground-truth trajectory  noisy estimations  direction of arrival  ego-noise  human speaker  multirotor drone  moving sound source  moving source  short audio segments  time-frequency spatial filter  specific drone  propellers  motors  emergency whistle  Drones  Time-frequency analysis  Direction-of-arrival estimation  Microphone arrays  Loudspeakers  Propellers 
Abstract: We propose a method to track from a multi-rotor drone a moving source, such as a human speaker or an emergency whistle, whose sound is mixed with the strong ego-noise generated by rotating motors and propellers. The proposed method is independent of the specific drone and does not need pre-training nor reference signals. We first employ a time-frequency spatial filter to estimate, on short audio segments, the direction of arrival of the moving source and then we track these noisy estimations with a particle filter. We quantitatively evaluate the results using a ground-truth trajectory of the sound source obtained with an on-board camera and compare the performance of the proposed method with baseline solutions.


Title: Kinematic Morphing Networks for Manipulation Skill Transfer
Key Words: affine transforms  image morphing  iterative methods  manipulators  motion control  neural nets  robot vision  kinematic model  robot motions  robot skill  manipulation skill transfer  kinematic morphing networks  affine transformations  map depth image observations  deep neural network  Kinematics  Three-dimensional displays  Robot sensing systems  Prototypes  Neural networks  Solid modeling 
Abstract: The transfer of a robot skill between different geometric environments is non-trivial since a wide variety of environments exists, sensor observations as well as robot motions are high-dimensional, and the environment might only be partially observed. We consider the problem of extracting a low-dimensional description of the manipulated environment in form of a kinematic model. This allows us to transfer a skill by defining a policy on a prototype model and morphing the observed environment to this prototype. A deep neural network is used to map depth image observations of the environment to morphing parameter, which include transformations and configurations of the prototype model. Using the concatenation property of affine transformations and the ability to convert point clouds to depth images allows to apply the network in an iterative manner. The network is trained on data generated in a simulator and on augmented data that is created with its own predictions. The algorithm is evaluated on different tasks, where it is shown that iterative predictions lead to a higher accuracy than one-step predictions.


Title: Vision-Aided Absolute Trajectory Estimation Using an Unsupervised Deep Network with Online Error Correction
Key Words: accelerometers  calibration  cameras  distance measurement  gyroscopes  inertial navigation  learning (artificial intelligence)  mobile robots  neural nets  pose estimation  robot vision  SLAM (robots)  vision-aided absolute trajectory estimation  unsupervised deep network  online error correction  unsupervised deep neural network approach  RGB-D imagery  inertial measurements  Visual-Inertial-Odometry Learner  inertial measurement unit intrinsic parameters  white noise  extrinsic calibration  camera  IMU measurements  hypothesis trajectories  scaled image projection errors  visual odometry  visual simultaneous localization  KITTI Odometry dataset  competitive odometry performance  visual-inertial odometry  Cameras  Jacobian matrices  Image reconstruction  Trajectory  Simultaneous localization and mapping  Training 
Abstract: Adstract- We present an unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters (corresponding to gyroscope and accelerometer bias or white noise) or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to a spatial grid of pixel coordinates. We evaluate our network against state-of-the-art (SOA) visual-inertial odometry, visual odometry, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset [1] and demonstrate competitive odometry performance.


Title: Distributed Deep Reinforcement Learning based Indoor Visual Navigation
Key Words: indoor environment  indoor navigation  learning (artificial intelligence)  mobile robots  object detection  path planning  robot vision  complicated environment scene  motor control command  navigation task  large-scale indoor complex environment  pre-constructed map  indoor environment  complex spatial perception possible  indoor space  complex navigation path  aforementioned large-scale environment  real environments  distributed deep reinforcement learning based indoor visual navigation  Navigation  Visualization  Task analysis  Training  Reinforcement learning  Robots  Indoor environments  deep reinforcement learning  visual navigation 
Abstract: Recently, as the rise of deep reinforcement learning, it not only can help the robot to convert the complicated environment scene to motor control command directly but also can accomplish the navigation task properly. In this paper, we propose a novel structure, where the objective is to achieve navigation in large-scale indoor complex environment without pre-constructed map. Generally, it requires good understanding of such indoor environment to make complex spatial perception possible, especially when the indoor space consists of many walls and doors which might block the view of robot leading to complex navigation path. By the proposed distributed deep reinforcement learning in different local regions, our method can achieve indoor visual navigation in the aforementioned large-scale environment without extra map information and human instruction. In the experiments, we validate our proposed method by conducting highly promising navigation tasks both in simulation and real environments.


Title: Synthesizing Neural Network Controllers with Probabilistic Model-Based Reinforcement Learning
Key Words: learning (artificial intelligence)  mobile robots  neurocontrollers  underwater vehicles  complex neural network controllers  motor controllers  probabilistic model-based reinforcement learning  robotics systems  sample-based version  Deep-PILeO  model-based algorithm  random numbers  clips gradients  neural network dynamics model  data-efficient synthesis  complex neural network policies  data-efficiency  truncated log-normal noise  Robots  Optimization  Vehicle dynamics  Task analysis  Heuristic algorithms  Neural networks  Stochastic processes 
Abstract: We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.


Title: Composite Reinforcement Learning for Social Robot Navigation
Key Words: human-robot interaction  learning (artificial intelligence)  mobile robots  path planning  service robots  minimum distance path  deep reinforcement learning technique  navigational movement  service robot  social robot navigation  CRL system  human robot interaction  human feedback  composite reinforcement learning framework  high dimension complex problem  Navigation  Reinforcement learning  Legged locomotion  Task analysis  Collision avoidance  Robot kinematics 
Abstract: For a service robot, it is not adequate to let its navigational movement be based only on a single metric, such as minimum distance path. In the environment where the robot and humans are coexisting, the robot should always perform social navigation whenever it is moving. However, to perform social navigation, the robot needs to follow certain “social norms” of the environment. Recently, deep reinforcement learning (DRL) technique is popularly applied to the robotics field; yet, it is rarely used to solve the mentioned social navigation problem, generally deemed as a high dimension complex problem. In this paper, we propose the composite reinforcement learning (CRL) framework under which the robot learns appropriate social navigation with sensor input and reward update based on human feedback. For learning the aspect of human robot interaction (HRI), we provide a method to facilitate the training of DRL in real environment by incorporating prior knowledge to the system. It turns out that our CRL system not only can incrementally learn how to set its velocity and to perform HRI but also keep collecting human feedback to synchronize the reward functions to the current social norms. The experiments show that the proposed CRL system can safely learn how to navigate in the environment and show that our system is able to perform HRI for social navigation.


Title: Target Localization with Drones using Mobile CNNs
Key Words: aerospace robotics  decision theory  learning (artificial intelligence)  Markov processes  search problems  target localization  accurate visual search  effective search strategies  observation models  latest developments  mobile platforms  policy search  point based methods  POMDP framework  single basketball  perception modules  error characteristics  control algorithm  realistic parameters  fast search strategy  longer search time  real data  error rates  false positive rates  false negative rates  visual search strategies  drone platform  robust algorithm  mobile CNN  Drones  Sensors  Search problems  Data collection  Computational modeling  Delays  Visualization 
Abstract: Fast and accurate visual search is an enabler for many applications of drones. Prior works use POMDPs to produce effective search strategies. As the observation models are from heuristics, the robustness of these approaches on the field is unclear. This work builds a testbed that combines latest developments in related areas, including mobile CNNs for inference on mobile platforms and policy search with point based methods, in a POMDP framework. A dataset for a simple but realistic application, search for a single basketball, is collected to train the perception modules, investigate their error characteristics and validate the control algorithm. From simulation using realistic parameters, we found the significant role persistent factors in the environment can play in designing a fast search strategy. Failure to taking these factors into account results in up to 60% longer search time at the same success rate. Our empirical tests using mobile CNN and real data reveals that prior assumptions on error rates as functions of heights are wrong. The errors grows non-linearly, and there is significant between false positive and false negative rates. Our findings shed new lights on what to consider in designing visual search strategies in a drone platform and is one step towards a fast and robust algorithm.


Title: An Adjustable Force Sensitive Sensor with an Electromagnet for a Soft, Distributed, Digital 3-axis Skin Sensor
Key Words: distributed sensors  electromagnets  foams  force measurement  force sensors  magnetic field measurement  magnetic sensors  microcontrollers  microsensors  skin  3-axis force sensor  soft distributed digital 3-axis skin sensor  integrated microcontroller  adjustable force sensitive sensor  magnetic field strength  soft foam  3-axis magnetic sensor  planar electromagnet  Robot sensing systems  Sensitivity  Magnetometers  Magnetic separation  Coils  Force 
Abstract: Typically, the range and sensitivity of force sensors are determined during production. However, to be able to do both delicate and high-force demanding work, adjustable force sensitivity would be beneficial. The current paper proposes such a sensor by implementing a planar electromagnet above a 3-axis magnetic sensor, separated by soft foam. Furthermore, the sensor has digital output with an integrated microcontroller. The magnetic field strength with varying currents is examined in simulation, and the field changes according to displacements are investigated both in simulation and with the actual sensor. A prototype 3-axis force sensor is implemented and the relationship between the magnetic field change and the corresponding applied force is also investigated. It could be shown that the sensitivity of the sensor to displacements, as well as force, can indeed be adjusted.


Title: Object Recognition Through Active Sensing Using a Multi-Fingered Robot Hand with 3D Tactile Sensors
Key Words: control engineering computing  convolutional neural nets  dexterous manipulators  object recognition  recurrent neural nets  tactile sensors  time series  multifingered robot hand  triaxial force vector measurements  3D tactile sensors  distributed force vector measurements  feedforward neural network  recurrent neural network  time-series training  active object sensing  Allegro Hand  uSkin tactile sensors  tactile object recognition  time series data  Force  Force measurement  Object recognition  Tactile sensors 
Abstract: This paper investigates tactile object recognition with relatively densely distributed force vector measurements and evaluates what kind of tactile information is beneficial for object recognition. The uSkin tactile sensors are embedded in an Allegro Hand, and provide 240 triaxial force vector measurements in total in all fingers. Active object sensing is used to gather time-series training and testing data. A simple feedforward, a recurrent, and a convolutional neural network are used for recognizing objects. Evaluations with different number of employed measurements, static vs. time series data and force vector vs. only normal force vector measurements show that the high-dimensional information provided by the sensors is indeed beneficial. An object recognition rate of up to 95% for 20 objects was achieved.


Title: Sensory-motor augmentation of the robot with shared human perception
Key Words: control engineering computing  dexterous manipulators  haptic interfaces  human-robot interaction  manipulators  man-machine systems  mobile robots  robot vision  robots  tactile sensors  operator actions  co-manipulated object  human hand  tiny vibration sensor  low-level robot intelligence  human operator  human-robot collaboration  human-robot cooperation  dexterous manipulation operations  manufacturing production lines  shared human perception  sensory-motor augmentation  Robot sensing systems  Task analysis  Vibrations  Force  Mechanical sensors 
Abstract: Robots have replaced people in many manufacturing production lines but the information they gather from sensors might not be sufficient to autonomously accomplish dexterous manipulation operations. Symbiotic human-robot cooperation appears to be a more realistic near future in industrial scenarios. In this paper we present a configuration of human-robot collaboration in which the robot is sensory-augmented by means of a set of tactile signals coming from the human operator. The incorporation of low-level robot “intelligence” permits the cooperative manipulation of an object while enabling the human operator to stay focused on task itself and carry it out in the most natural way. The effectiveness of this approach is demonstrated in a use case in which a robot helps a human operator to successfully accomplish a writing task. System performance has been evaluated, considering several positions of the tiny vibration sensor in charge of gathering the human perception, by testing it on both the human hand and the co-manipulated object. Results suggest that the sensor provides valuable information for recognizing operator actions when it is placed either on the human hand or on the co-manipulated object. However, the sensor on the finger directly represents the operator's perception, while the output of the sensor attached to the object changes according to the distance between the interaction point and the sensor itself. In addition, in wearing the sensor, neither the object nor the robot need to be instrumented: the operator is free to interact with a large set of objects and collaborate with any existing robot without requiring supplemental equipment.


Title: HTC Vive: Analysis and Accuracy Improvement
Key Words: calibration  object tracking  pose estimation  tracking  virtual reality  estimation repeatability  calibration procedure  open-source tracking algorithm  robotics applications  shelf algorithm  virtual reality applications  inertial measurements  millimeter magnitude  controlled experiments  ground truth  off-the-shelf tracking system  cost-effective  HTC Vive  Robots  Tracking  Photodiodes  Extraterrestrial measurements  Pose estimation  Transforms 
Abstract: HTC Vive has been gaining attention as a cost-effective, off-the-shelf tracking system for collecting ground truth pose data. We assess this system's pose estimation through a series of controlled experiments where we show its precision to be in the millimeter magnitude and accuracy to range from millimeter to meter. We also show that Vive gives greater weight to inertial measurements in order to produce a smooth trajectory for virtual reality applications. Hence, the Vive's off the shelf algorithm is poorly suited for robotics applications such as measuring ground truth poses, where accuracy and repeatability are key. Therefore we introduce a new open-source tracking algorithm and calibration procedure for Vive which address these problems. We also show that our approach improves the pose estimation repeatability and accuracy by up to two orders of magnitude.


Title: Improving indoor robots localisation by fusing different sensors
Key Words: cameras  mobile robots  navigation  path planning  pose estimation  laser LMS-200  omnidirectional camera Mobotix C2S  tour guide robot  external landmarks  indoor mobile robots navigation  odometry  external sensors  indoor robots localisation  Cameras  Measurement by laser beam  Lasers  Robot vision systems 
Abstract: Indoor mobile robots navigation must use external sensors to complement odometry. This paper analyses two different external sensors such as a laser LMS-200 and an omnidirectional camera Mobotix C2S. Experiments with only one of these sensors and with both integrated are carried out on a tour guide robot in order to obtain conclusions about their contribution to robot pose estimation, and how to locate external landmarks in the environment.


Title: Robust Camera Pose Estimation via Consensus on Ray Bundle and Vector Field
Key Words: Bayes methods  expectation-maximisation algorithm  image matching  pose estimation  probability  vectors  robust camera pose estimation  point correspondences  general outlier removal strategy  3D ray bundle consensus  2D vector field consensus  expectation-maximization algorithm  inlier probability  outlier rejection methods  Cameras  Pose estimation  Two dimensional displays  Three-dimensional displays  Robot vision systems  Robustness  Probabilistic logic 
Abstract: Estimating the camera pose requires point correspondences. However, in practice, correspondences are inevitably corrupted by outliers, which affects the pose estimation. We propose a general and accurate outlier removal strategy for robust camera pose estimation. The proposed strategy can detect outliers by leveraging the fact that only inliers comply with two effective consensuses, i.e., 3D ray bundle consensus and 2D vector field consensus. Our strategy has a nested structure. First, the outer module utilizes the 3D ray bundle consensus. We define the likelihood based on the probabilistic mixture model and maximize it by the expectation-maximization (EM) algorithm. The inlier probability of each correspondence and the camera pose are determined alternately. Second, the inner module exploits the 2D vector field consensus to refine the probabilities obtained by the outer module. The refinement based on the Bayesian rule facilitates the convergence of the outer module and improves the accuracy of the entire framework. Our strategy can be integrated into various existing camera pose estimation methods which are originally vulnerable to outliers. Experiments on both synthesized data and real images have shown that our approach outperforms state-of-the-art outlier rejection methods in terms of accuracy and robustness.


Title: Efficient Map Representations for Multi-Dimensional Normal Distributions Transforms
Key Words: mobile robots  Monte Carlo methods  normal distribution  probability  robot vision  stereo image processing  transforms  indoor environments  outdoor environments  driving flying robots  fast approach  accurate approach  indexed kd-trees  free space  occupancy probabilities  map consistency  large-scale environments  mapping efficiency  efficient map representations  3D map representations  static environments  dynamic environments  multidimensional normal distributions transforms  3D normal distributions transform mapping  Three-dimensional displays  Robot sensing systems  Gaussian distribution  Two dimensional displays  Task analysis  Transforms 
Abstract: Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.


Title: Modeling and Control of an Articulated Tail for Maneuvering a Reduced Degree of Freedom Legged Robot
Key Words: actuators  feedback  hardware-in-the loop simulation  legged locomotion  linearisation techniques  motion control  robot dynamics  leg mechanisms  quadruped robot  dynamic tail motions  robotic system design  outer loop controller  articulated tail mechanism  inner loop controller  tail prototype  dynamic modeling control  articulated robotic tail  maneuvering  legged robotic systems  reduced degree of freedom legged robot  hardware-in-the-loop experiments  quadruped platform simulation  feedback linearization maps  Legged locomotion  Robot kinematics  Foot  Dynamics  Task analysis  Manipulators 
Abstract: This paper presents dynamic modeling and control of an articulated robotic tail to maneuver and stabilize a reduced degree-of-freedom (DOF) quadruped robot. Conventional legged robotic systems consist of leg mechanisms that provide simultaneous propulsion, maneuvering and stabilization. However, in nature animals have been observed to utilize their tails to assist the legs in multiple tasks. Similarly, by incorporating an articulated tail onboard a quadruped robot, dynamic tail motions can be used to aid maneuvering. Therefore, tail implementation can potentially lead to simplifications in design and control of the legged robot since the legs will be responsible for only propulsion tasks. In this paper, a robotic system design consisting of an articulated tail and quadruped robot system is presented. Dynamic models are derived to analyze an optimal tail mass and length ratio to enhance inertial adjustment applications and develop an outer loop controller to plan tail trajectories for desired maneuvering applications. Results of analytical optimization are corroborated with measured data from biological animals. To decouple the dynamics of the articulated tail mechanism an inner loop controller using feedback linearization maps the desired behavior to the actuator inputs. This approach is validated using hardware-in-the-loop experiments with tail prototype in conjunction with simulated quadruped platform. Results demonstrate the capabilities of the articulated tail in enabling precise left and right turning (maneuvering).


Title: Modeling and Fuzzy Control of One-legged Somersaulting Robot
Key Words: fuzzy control  legged locomotion  motion control  robot dynamics  robot kinematics  springs (mechanical)  flight phases  hybrid dynamic model  challenging control issue  one-legged hopping robots  springy leg  fuzzy logic control  one-legged somersaulting robot  multilegged ones  hopping motion  SLIP robots  Legged locomotion  Actuators  Mathematical model  Torque  Wheels 
Abstract: Research on legged robots has developed rapidly in the recent decades. One-legged robots, unlike multi-legged ones, have only one type of motion, called hopping. Hopping motion is generally divided into stance and flight phases. Switching between these two phases represents a hybrid dynamic model. Dynamic stabilization of hopping motion is a challenging control issue. Most of one-legged hopping robots studied in the past are able to hop with their one springy leg. In this paper, a novel one-legged robot is introduced and studied with two springs on the two sides. The one-legged somersaulting robot is able to hop with both springy sides. This ability causes lower energy consumption in passing obstacles and a longer step length in comparison with well-known SLIP robots with hopping motion stemming from the fact that it only has one rotary actuator. Fuzzy logic control is applied to achieve a stable limit cycle in the robot's somersaulting motion.


Title: Towards a Passive Adaptive Planar Foot with Ground Orientation and Contact Force Sensing for Legged Robots
Key Words: force sensors  gait analysis  legged locomotion  robot dynamics  soil  stability  ground orientation  drift-free relative foot sole pose  passive adaptive planar foot  ground contact  highly dynamic legged robots  point foot design  legged locomotion  contact force sensor  stability  inertial measurement units  IMUs  quadrupedal robot ANYmal  compressible soils  built-in 6-axis force-torque transducer  Foot  Sensors  Legged locomotion  Force  Force measurement  Microcontrollers 
Abstract: Adapting to the ground enables stable footholds in legged locomotion by exploiting the structure of the terrain. On that account, we present a passive adaptive planar foot with three rotational degrees of freedom that is lightweight and thus suited for highly dynamic legged robots. Its low laying pivot joint provides high stability towards kinking. Information about the relative foot sole pose, and accordingly, the ground orientation is gathered by inertial measurement units (IMUs) placed on the foot sole and the shank. A complementary filter is presented that fuses these orientation estimates with an angular encoder to obtain a drift-free relative foot sole pose. The passive adaptive planar foot has been tested and compared to the classical point foot design on a variety of terrains and shows superior traction performance, especially on compressible soils. Being mounted on the quadrupedal robot ANYmal, the foot provides a reliable contact detection based on the fusion of the built-in 6-axis force/torque transducer and the IMUs. This allows to walk and trot on uneven terrain, loose soils, as well as climbing up a ramp and stairs while keeping the entire foot sole in ground contact all the time.


Title: SLIP-Model-Based Dynamic Motion Transition Between Different Fixed Points in One Stride in a Leg-Wheel Transformable Robot
Key Words: force control  legged locomotion  motion control  nonlinear control systems  pendulums  stable running motion  stable fixed-point trajectories  ordinary SLIP model  passive spring  leg-spring stiffness  fixed-point trajectory  multistride transition  leg-wheel transformable robot  SLIP-model-based dynamic motion transition  motion generation strategy  force control  TurboQuad  Legged locomotion  Springs  Robot kinematics  Mathematical model  Dynamics  DC motors 
Abstract: We report on the development of a motion generation strategy that allows the robot to transit from one stable running motion to another in one stride by actively changing leg stiffness in real time. Stable motion of the robot is generated based on the stable fixed-point trajectories of the spring-loaded inverted pendulum (SLIP) model. While the transition of the ordinary SLIP model with fixed parameters gradually converges if stable, a robot that uses force control to simulate the passive spring of the SLIP can actively modulate leg-spring stiffness. This enables the robot to switch instantly to another fixed-point trajectory of the SLIP model without going through multi-stride transition. The proposed method is implemented on a leg-wheel transformable robot, TurboQuad, and is evaluated experimentally. The results confirm that the robot can successfully transit between different fixed-point trajectories.


Title: Continuous Shape Changing Locomotion of 32-legged Spherical Robot
Key Words: legged locomotion  trajectory control  amoeba movement  Mochibot  trajectory control  deformable robots  omni directional continuous crawling  free form locomotion  32-legged spherical robot  continuous shape changing locomotion  Shape  Legged locomotion  Actuators  Skeleton  Rails 
Abstract: Shape changing robot is an approach towards locomotion on uncertain terrain due to its omni-directional features. However, the current locomotion method for such robots rely on discontinuous rolling. We propose a free form locomotion: an omni directional continuous crawling for deformable robots. This method introduce continuous shifting of contact surface similar to amoeba movement. A Mochibot that has thirty two telescopic legs is developed to verify the proposed locomotion method. Through the experiments, we have confirmed that the robot can track smooth paths: straight, smooth, and hand written curves. We also evaluate errors between desired and measured trajectories of the robot.


Title: End-effector with a Hook and Two Fingers for the Locomotion and Simple Work of a Four-limbed Robot
Key Words: end effectors  legged locomotion  motion control  manipulation tasks  four-limb robot WAREC-1  vertical ladder  fingers  locomotion modes  legged robot  hook shape  grasping working  end-effector  End effectors  Thumb  Grasping  Force  Shape 
Abstract: In this paper, we propose an end-effector for realizing various locomotion modes and simple work of a legged robot. The locomotion modes include climbing a vertical ladder, crawling, and walking. The simple work includes grasping and switching motions required at a disaster site. The developed end-effector has a two-pronged hook shape and two fingers for grasping and working and can be used to perform the locomotion and manipulation tasks described above. The experimental results confirmed that the four-limb robot WAREC-1 (WAseda REsCuer-No. 1) equipped with our proposed end-effector was able to climb a vertical ladder and perform the crawling motion. We also confirmed that the end-effector could grasp and switch five types of objects: a cylinder, cylinder with trigger, T-shaped, disk, and thin plate.


Title: A Framework for Modeling Closed Kinematic Chains with a Focus on Legged Robots
Key Words: legged locomotion  robot kinematics  singularly perturbed systems  legged robots  MATLAB framework  dynamic modeling simulation  legged locomotive mechanisms  fixed-base systems  singular perturbation theory  CKC mechanisms  dynamic monopedal gait  closed kinematic chains  floating-base systems  functional API  Mathematical model  Legged locomotion  Kinematics  Software  Computational modeling  Couplings 
Abstract: This paper presents the foundations of a MATLAB framework for dynamic modeling and simulation of closed kinematic chain (CKC) mechanisms, with a particular focus on implementation with legged locomotive mechanisms. As such, the framework supports both floating-base and fixed-base systems. Through the use of singular perturbation theory, various CKC mechanisms can be modeled so that constraint errors asymptotically converge to zero, thus avoiding the numerical drift that plagues commonly used methods. A functional API and the relevant core commands necessary to construct a model are presented. Two robotic legs incorporating CKC mechanisms are utilized as case studies, and simulations of each leg performing a dynamic monopedal gait are illustrated.


Title: Steering of an Underactuated Legged Robot through Terrain Contact with an Active Tail
Key Words: closed loop systems  drag  gait analysis  legged locomotion  motion control  robot dynamics  robot kinematics  steering systems  underactuated legged robot  terrain contact  rapid point turn  active tail payload  steady-state turning model  differential drive turning gaits  tail impact turning  tail drag  palm-sized legged robot  LoadRoACH  tail contact turning strategies  closed-loop corner steering maneuver  mass 55.0 g  Turning  Legged locomotion  Force  Steady-state  Drag  Aerodynamics 
Abstract: This paper analyzes and implements two novel turning strategies for underactuated legged robots that leverage contact of an active tail against terrain. The first strategy produces a sustained turn with a tail dragging against the ground during forward locomotion. The second strategy produces a rapid point turn by impacting the tail against the ground. LoadRoACH, a 55 g palm-sized legged robot, is developed to carry the active tail payload used in turning experiments. A steady-state turning model predicts the achievable turn speed of the robot on carpet, and open-loop turning experiments characterize the performance of the two tail contact turning strategies. Tail drag turning provides comparable turning maneuverability to differential drive turning gaits on carpet and gravel surfaces. Tail impact turning can produce rapid point turns on carpet, tarp, and gravel, but has a large variability in turn angle and time to recover from the turn. Finally, tail drag and tail impact turning control methods are implemented in an aggressive closed-loop corner steering maneuver.


Title: Unpowered Lower-Body Exoskeleton with Torso Lifting Mechanism for Supporting Sit-to-Stand Transitions
Key Words: biomechanics  bone  injuries  muscle  patient rehabilitation  pulleys  unpowered lower-body exoskeleton  torso lifting mechanism  knee joint  lower torso  spinal cord injury  lower-body impairments  power transfer mechanism  lumbar motion  cable-driven pulley system  human body dynamics  rigid link model  impedance model  passive system  natural motions  upper body  body residual capabilities  external power source  upper-body  passive energy storage  muscle activity  exoskeleton support  passive exoskeleton  STS training  STS posture transitions  sit-to-stand posture transitions  STS transition support  upright locomotion  patient rehabilitation  Exoskeletons  Biological system modeling  Torso  Torque  Robots  Wheelchairs  Dynamics  Passive exoskeleton  human dynamics modeling  physical human-robot interaction  rehabilitation robotics 
Abstract: In this paper, we propose the design of an exoskeleton with support at the knee joint and lower torso for sit-to-stand and stand-to-sit (STS) posture transitions; devised for users with spinal cord injury and other complete lower-body impairments. The STS transitions assistance is achieved through a power transfer mechanism that synchronizes knees and lumbar motion through a cable-driven pulley system. We analyze the human body dynamics in the posture transition with a rigid link model and the interaction interface with the exoskeleton through an impedance model for producing a passive system voluntarily controlled by natural motions of the upper body. Therefore, allowing the potential users to achieve STS transitions with their body residual capabilities without an external power source. Instead, transferring power from their upper-body to lower-body, herewith, controlling a passive energy storage. A prototype was constructed and evaluated with seven healthy subjects observing the proposed motion and muscle activity during the STS transitions. The results show a significant reduction in the muscle activity evaluated, at the erector spinae, gluteus maximus and rectus femoris, with reductions between 30% to 50% at the p <; 0.01 level comparing STS transitions with and without the exoskeleton support. Concluding that the STS transitions support is feasible with the passive exoskeleton envisioned for applications in upright locomotion, STS training, and rehabilitation.


Title: Development of Master-slave Type Lower Limb Motion Teaching System
Key Words: control engineering computing  electromyography  medical robotics  motion control  pneumatic actuators  recurrent neural nets  robot vision  teaching  pneumatic artificial rubber muscle  PARM  assistive force  hip joint motion  master-slave type lower limb motion teaching system  motor skill learning  physical activities  teachers motion  recurrent neural network  electromyogram signals  learners motion  Hip  Education  Visualization  Force  Neural networks  Delays  Belts 
Abstract: Motor skill learning is fundamental in many physical activities of human. In the processes of learning of motor skills, learners often receive visual or physical information about postures from teachers. However, the information about postures usually cannot be transmitted precisely. In this paper, we propose a motion teaching system to transmit teachers' motion to learners directly by using a motion capture and an assist suit. The assist suit, which has a pneumatic artificial rubber muscle (PARM) as an actuator, was designed to move a learner's hip joint with less loss of assistive force and less constraint of motion. Hip joint motion of a teacher can be transmitted to the assist suit by master-slave control. In addition, to compensate the delay of the PARM, posture of the teacher is predicted before the occurence by a recurrent neural network by using electromyogram signals and the past joint angle. We confirmed the system can transmit a teacher's motion to a learner in real time, and with the neural network, the delay of the learner's motion could be suppressed to approximately 0.1s, which is enough to feel visual and physical information synchronous. Therefore, the proposed motion teaching system would have the ability to transmit teachers' motion to learners visually and physically with precision sufficient to facilitate skill transmission.


Title: Design and Experimental Characterisation of a Hydrostatic Transmission for Upper Limb Exoskeletons
Key Words: controllability  force control  friction  hydrostatics  medical robotics  power transmission (mechanical)  torque control  wearable robots  high performance fluid power transmission  leakage-free operation  virtually zero stick-friction  intrinsic backdrivable operation  fluid transmission system  design parameters  upper limb exoskeleton  hydrostatic transmission  remote electrical actuation  hydrostatic air-liquid torque transmission system  rolling membrane cylinders  controllability  Exoskeletons  Torque  Robots  Hydraulic systems  Layout  Pulleys  Actuators 
Abstract: This paper introduces a novel hydrostatic air-liquid torque transmission system for an upper limb exoskeleton. The proposed design is based on remote electrical actuation, with grounded motors, combined with high performance fluid power transmission employed to deliver the power to the joints of the exoskeleton. The fluid transmission is based on rolling membrane cylinders that guarantee leakage-free operation, no backlash, and virtually zero stick-friction. This solution makes it possible to obtain easy controllability, good efficiency, intrinsic backdrivable operation, and reduced mass/inertia of the links of the robot. Additionally, the proposed system can be potentially implemented at relatively low-costs thanks to the employment of standard components and an architecture based on a modular approach. A test bench of the fluid transmission system is developed and a campaign of experiments is conducted to characterize its static/dynamic response for different choice of design parameters. In addition, we present a preliminary complete integrated arrangement of an upper limb exoskeleton equipped with the proposed transmission system. Results confirm the feasibility of the proposed actuation approach for the envisaged application.


Title: Muscle Activation Source Model-based sEMG Signal Decomposition and Recognition of Interface Rotation
Key Words: biomechanics  electromyography  medical signal processing  motion estimation  skin  muscle structures  muscle activation source model-based sEMG signal decomposition  sEMG interface rotation  muscle activation signals  surface electromyography signals  muscle activation extraction  hand motion estimation  rotation recognition  inertial measurement unit  Electrodes  Muscles  Mathematical model  Signal resolution  Electromyography  Conductivity  Motion estimation 
Abstract: Muscle activation signals are measured from the skin surface as surface electromyography (EMG) signals that contain information on human intentions; therefore, they are widely used in various robotics applications owing to their usability. However, selective muscle activation extraction is difficult because of the complexity of muscle structures. This study investigated muscle activation source model-based sEMG signal decomposition that considers the anatomical factors of muscle structures. The main advantage of the proposed model-based signal decomposition is that sEMG interface rotation can be recognized by comparing source parameters identified before and after rotation. To assess the performance of the proposed model-based decomposition method, hand motion estimation and rotation recognition were conducted. Additionally, two-dimensional simultaneous control was conducted with an inertial measurement unit to verify the usability of the proposed model. The results indicate that the proposed model decomposes an sEMG signal based on motion with good performance and demonstrate feasibility of motion estimation independent of sEMG interface rotation.


Title: Design, Control and Preliminary Test of Robotic Ankle Prosthesis
Key Words: actuators  artificial limbs  biomechanics  elasticity  gait analysis  medical control systems  medical robotics  prosthetics  springs (mechanical)  torque  torque control  variable transmission series elastic actuator  commercially available ankle foot prosthesis  robotic ankle prosthesis  preliminary test  variable transmission mechanism  powered plantar flexion  robotic ankle foot prosthesis  ankle joint torque-angle  ankle angle varies  variable transmission ratio  ankle foot joint  Prosthetics  Foot  Legged locomotion  Torque  Springs 
Abstract: Currently, most of commercially available ankle foot prosthesis are passive, which don't exhibit appropriate biomechanics during walking and could not adapt to dynamic property of able-bodied walking. In this paper, we present a novel robotic ankle foot prosthesis with variable transmission series elastic actuator (SEA). Slider crank mechanism is applied to transform linear motion of series elastic actuator to rotary motion of ankle foot joint. And this could contribute to variable transmission ratio while ankle angle varies. Because of variable transmission ratio, ankle joint torque is increasing while ankle angle is flexed from plantar flexion to dorsiflexion, whose feature has similar increase trend with human's ankle joint torque-angle relationship, and exhibits an appropriate characteristic for developing robotic ankle foot prosthesis. Larger torque could be obtained in powered plantar flexion, and this indicates that variable transmission mechanism would help reduce required motor torque compared with traditional mechanism. Energy stored in springs of series elastic actuator contribute a torque to powered plantar flexion. Preliminary experiments with a transtibial amputee and a transferomal amputee have been performed to test the prototype.


Title: A Method for Robot Motor Fatigue Management in Physical Interaction and Human-Robot Collaboration Tasks
Key Words: collision avoidance  fatigue  human-robot interaction  industrial accidents  industrial robots  mobile robots  motion control  robot kinematics  human co-worker  KUKA lightweight robot  human-robot collaboration tasks  software frameworks  robot motor fatigue management  robot kinematic redundancy  collaborative human-robot surface polishing  autonomous surface wiping  Cartesian task production  two-stage reaction process  robot productivity  hardware solutions  accidental collisions  human safety  Robots  Task analysis  Fatigue  Temperature measurement  Torque  Force  Collision avoidance 
Abstract: Collaborative robots are often designed with limited power and force capacity, with the aim to provide affordable solutions and ensure human safety in case of accidental collisions and impacts. If a task requires a power beyond this capacity, or is performed repeatedly over long periods, such limits may be exceeded, which can cause inevitable robot damage and contribute to the lost productivity. In such cases, where hardware solutions and improvements are not applicable, effective software frameworks can prolong robot productivity and lifetime. To this end, in this paper we propose a novel technique for the monitoring and management of robot fatigue in repetitive or high-effort task execution scenarios. The robot fatigue is estimated by the measured temperature of motors in the joints. The proposed fatigue management system is composed of two-stage reaction process that is triggered by different levels of the estimated fatigue. The first stage exploits the kinematic redundancy of robot structure in attempt to minimise the load in the specific joints that under fatigue by reconfiguration in the joint space through the null space of the Cartesian task production. If the first stage is not successful in reducing the fatigue, the second stage is activated that gradually reduces the forces of hybrid controller. At that point, the human co-worker can temporarily take over the task execution until the robot will be recovered from the excessive fatigue. To validate the proposed approach we conducted experiments on KUKA Lightweight Robot performing two interaction tasks: autonomous surface wiping and collaborative human-robot surface polishing.


Title: Adaptive Task Planner for Performing Home Service Tasks in Cooperation with a Human
Key Words: humanoid robots  human-robot interaction  image colour analysis  image sensors  path planning  robot vision  sequence network  episodic memory  user behaviors  task scheduler schedules  executable behavior  alternative behavior sequence  failed behavior problem  wheel-based humanoid robot  adaptive task planner  home service task  temporal sequence  fast forward planner  sequence to sequence network  Task analysis  Robot sensing systems  Robot kinematics  Planning  Generators  Thermal sensors 
Abstract: To perform a home service task through cooperation with a human in a real environment, a robot needs to deal with the environmental changes and accordingly plan appropriate behavior sequence. For this purpose, in this paper, we propose an adaptive task planner which is based on memory and reasoning. A robot perceives user behaviors and objects using an RGB-depth and thermal sensor. The robot stores a temporal sequence of behaviors for performing a task in its episodic memory that is realized by a sequence to sequence network. When the user command is given, the episodic memory is used to retrieve the behavior sequence to carry out the command. On the other hand, when the robot perceives user behaviors, the robot postpones its behavior till his/her behavior is stopped. Once stopped, the episodic memory retrieves the behavior sequence to conduct a task that the user has intended. A task scheduler schedules the behavior sequence from the memory and sends it to an internal simulator. The internal simulator confirms the behavior sequence to be executable and then if executable, it sends the next executable behavior to the execution module. If a behavior fails in the internal simulation test, fast forward planner generates an alternative behavior sequence to resolve the failed behavior problem. The effectiveness and applicability of the proposed planner is demonstrated by a wheel-based humanoid robot.


Title: Design of SUPERball v2, a Compliant Tensegrity Robot for Absorbing Large Impacts
Key Words: actuators  aerospace robotics  cables (mechanical)  design engineering  impact (mechanical)  mobile robots  planetary rovers  torque control  velocity control  SUPERball v2  spherical six-bar tensegrity robot  fully actuated six-bar design  compliant nylon cables  torque-control enabled motor  robust mechanical structure  system design  compliant tensegrity robot  impact velocities  24 actuators  actuation  high-speed landings  six-bar tensegrity robot  Robot kinematics  Springs  Meters  NASA  Mechanical cables  Robot sensing systems 
Abstract: In this paper, we present the system design and initial testing of SUPERball v2, a completely re-designed 2-meter spherical six-bar tensegrity robot designed to survive high-speed landings as well as locomote to desired locations. SUPERball v2 was designed to enable a host of new actuation and experimentation. The prototype features a fully actuated six-bar design (24 actuators), compliant nylon cables (up to 15% stretch), torque-control enabled motors, and a robust mechanical structure capable of surviving impact velocities upwards of 8 m/s.


Title: Slip Avoidance in Dual-Arm Manipulation
Key Words: aerospace robotics  force control  friction  manipulator dynamics  manipulators  mobile robots  motion control  position control  stability  slip avoidance  dual-arm manipulation  multifinger  multiarm grasping  friction contacts  contact slippage  space robotics  stable grasp  static conditions  grasp stability  safe force closure condition  specified motion trajectory  estimated inertial force  required squeeze force  inertial force component  motion-induced disturbance force  slip prevention strategy  dual-arm transportation  dual-arm robot  dynamic squeeze adjustment  robot-load motion  Force  Manipulators  Satellites  Grasping  Collision avoidance  Friction 
Abstract: In multi-finger or multi-arm grasping with friction contacts, maintaining force closure during motion is critical. Violation of this condition would cause contact slippage and possibly loss of grasp. This issue is of particular importance in space robotics, where the loss of grasp could lead to catastrophic consequences. There has been ample literature on stable grasp and force closure under static conditions. This paper investigates multi-arm grasping during motion, where the inertial force from the load could adversely affect grasp stability. Our approach dynamically adjusts the squeeze force and commanded robot/load motion to maintain a safe force closure condition. For a specified motion trajectory, the squeeze force is updated to prevent slippage based on the estimated inertial force. When the required squeeze force is beyond what the manipulators can safely apply, the trajectory will be scaled to reduce the inertial force component. In addition to motion-induced disturbance force, contact between the load and other objects in the environment can also cause slippage. The slip prevention strategy is extended to this case as well. The application scenario is based on the dual-arm transportation and berthing of a load in a micro-gravity environment. For laboratory testing, we use a fixed-base dual-arm robot to grasp, transport, and berth an object on a planar air bearing table. We also extend the transportation tests to a more general spatial setting, and use the dynamic squeeze adjustment to grasp, lift, and transport an object. Experimental results show the proposed method is effective at avoiding contact slippage during motion and when the object is in contact with the environment.


Title: Relative and inertial attitude determination in three-vehicle long formations
Key Words: attitude control  attitude measurement  inertial navigation  mobile robots  multi-robot systems  inertial attitude  three-vehicle long formations  attitude determination problem  three-vehicle formation  independent inertial measurement  attitude relations  relative attitude  inertial candidates  constrained formations  sensor noise  Position measurement  Sensors  Extraterrestrial measurements  Visualization  Estimation  Space vehicles  Navigation 
Abstract: This paper addresses a new attitude determination problem for formations. It considers a three-vehicle formation with relative and inertial measurements from sensors, where Constraints limit the relative measurements, which are not available between two of the vehicles, also known as deputies. The other vehicle is called the chief and does not have any limitation. Furthermore, each of the vehicles has an independent inertial measurement, whose references are known. The goal is to determine all attitude relations, both inertial and relative. The solution for this problem is divided into different stages. First, the relative attitude between the chief and the deputies is assessed, which results in two candidates for each of these relations. Then, each candidate yields a candidate for the inertial attitude of the chief. Next, comparing the four inertial candidates gives the solution for their respective relations and consequently for the relative relations as well. The remaining relations derive directly from those already known. The paper also provides some early insights about degeneracies, possible particular cases of the solution, and the effect of sensor noise. Finally, the solution is validated with a simulation, whose results are similar to attitude determination problems in constrained formations.


Title: Steerable Locomotion Controller for Six-strut Icosahedral Tensegrity Robots
Key Words: accelerometers  mobile robots  motion control  nonlinear dynamical systems  robust control  steerable locomotion controller  nonlinear dynamics  six-strut icosahedral tensegrity robots  step-wise locomotion  SUPERball v2 robot  preexisting step-wise controller  tensegrity structure  locomotion problem  step-wise motion controllers  Robot kinematics  NASA  Trajectory  Face  Robot sensing systems  Navigation 
Abstract: This paper proposes a novel steerable locomotion controller for six-strut tensegrity robots. Tensegrity robots are lightweight and have many promising features such as robustness, shape-shifting capabilities, and deployability, making them good candidates for exploration and scouting of remote areas. Despite these advantages, tensegrity robots are challenging to control due to their large number of degrees of freedom, nonlinear dynamics, and intrinsic compliance. Recently, many step-wise motion controllers have been employed to simplify the locomotion problem, thanks to the discrete nature of the tensegrity structure. In this paper we present a novel locomotion controller which will steer the direction of motion of a six-strut tensegrity robot when used in conjunction with any preexisting step-wise controller. We validated our controller on the SUPERball v2 robot, showing straight and curved trajectories, and an example of navigation around obstacles. Our method is computationally inexpensive, only requires knowledge about the current base triangle (e.g, via accelerometer data), and can be generalized to any six-strut tensegrity robot which can perform step-wise locomotion.


Title: Series Elastic Tether Management for Rappelling Rovers
Key Words: actuators  closed loop systems  design engineering  elasticity  force control  mobile robots  position control  robot kinematics  wheels  series elastic tether management  Axel rappelling rover  intriguing science sites  important science sites  difficult terrains  conventional rovers  extended autonomous rappelling  tether spooling  shock tolerance  first-generation tether management system  double bull-wheel capstan  low-stiffness series elastic actuator  SEA  decouple internal spooling tension  external tether tension  closed-loop tether tension control  rappelling system  constant spooling tension  measured output tension  tension contribution  shock-drop tolerance  Springs  Bandwidth  Sea measurements  Actuators  Electric shock  Robots  Friction 
Abstract: The Axel rappelling rover was designed to enable access to intriguing and important science sites that lie in difficult terrains that are inaccessible to conventional rovers. Extended autonomous rappelling calls for careful control of tether tension, precise management of tether spooling, and some measure of shock tolerance. This paper covers the design and testing of a first-generation tether management system (TMS) for Axel. The system uses a double bull-wheel capstan driven by a low-stiffness series elastic actuator (SEA) to provide tension control and decouple internal spooling tension from external tether tension. A series elastic actuator was chosen for this application to permit closed-loop tether tension control and to provide shock/drop tolerance of the rappelling system both while moving and when the system is inactive with the motors locked. Experiments on the new TMS show that this design performs well in keeping nearly constant spooling tension while rejecting large dynamic disturbances at the output. While the SEA is very effective at maintaining a given tension contribution, the additional effects of friction and the unique mechanical properties of the tether result in substantial errors in the measured output tension. Upcoming field trials will be used to evaluate the effectiveness and sufficiency of this system when integrated in Axel.


Title: Image Based Visual Servoing for Tumbling Objects
Key Words: feature extraction  image reconstruction  mobile robots  pose estimation  robot vision  visual servoing  image based visual servoing  image plane  elliptical track  feature points  image space  feature error  explicit reconstruction  uncooperative tumbling object  robotic system  inertial axis  tumbling motion  Visual servoing  Cameras  Feature extraction  Estimation  Solid modeling  Satellites 
Abstract: Objects in space often exhibit a tumbling motion around the major inertial axis. In this paper, we address the image based visual servoing of a robotic system towards an uncooperative tumbling object. In contrast to previous approaches that require explicit reconstruction of the object and an estimation of its velocity, we propose a novel controller that is able to minimize the feature error directly in image space. This is achieved by observing that the feature points on the tumbling object follow a circular path around the axis of rotation and their projection creates an elliptical track in the image plane. Our controller minimizes the error between this elliptical track and the desired features, such that at the desired pose the features lie on the circumference of the ellipse. The effectiveness of our framework is exhibited by implementing the algorithm in simulation as well on a mobile robot.


Title: Online Path Planning and Compliance Control of Space Robot for Capturing Tumbling Large Object
Key Words: aerospace control  aerospace robotics  compliance control  end effectors  force feedback  image capture  manipulator dynamics  mobile robots  motion control  object recognition  path planning  position control  robot vision  robust control  compliance control  planned trajectory  moving grasping point  end-effector position error  end-effector motion  coordinated control  spacecraft base  robotic arm  online path planning  space robot  coordinated motion control  robust control scheme  end-effector trajectory  tumbling large object capturing  Grasping  End effectors  Robot kinematics  Trajectory 
Abstract: This paper presents the path planning and coordinated control of a space robot with a manipulator for capturing a rotating large object. As the grasping point on a rotating large object is translationally moving fast, an appropriate strategy and coordinated motion control of the spacecraft base and robotic arm must be employed for approaching and tracking such a grasping point. In this paper, we propose a robust control scheme including the online path planning and compliance control for grasping such a target. The path planning is derived in a simple form that allows the desired end-effector trajectory to be easily modified in real-time using the newly updated states without complex numerical calculation. In addition, the compliance control allows the end-effector to track the planned trajectory or the moving grasping point, while using contact force feedback to reduce the end-effector position error from the grasping point when capturing the target. This end-effector motion is implemented by coordinated control on the spacecraft base and robotic arm, which can suitably alter their distribution of motion according to scenes using a weighted pseudoinverse matrix. Experiments are conducted to demonstrate the validity of the proposed path planning and compliance control.


Title: Workspace Aware Online Grasp Planning
Key Words: end effectors  path planning  reachable end-effector configurations  unique end-effector poses  workspace aware online grasp planning  reachable grasps  Planning  Robots  Trajectory  Measurement  Kinematics  Grasping  Databases 
Abstract: This work provides a framework for a workspace aware online grasp planner. This framework greatly improves the performance of standard online grasp planning algorithms by incorporating a notion of reachability into the online grasp planning process. Offline, a database of hundreds of thousands of unique end-effector poses were queried for feasibility. At runtime, our grasp planner uses this database to bias the hand towards reachable end-effector configurations. The bias keeps the grasp planner in accessible regions of the planning scene so that the resulting grasps are tailored to the situation at hand. This results in a higher percentage of reachable grasps, a higher percentage of successful grasp executions, and a reduced planning time. We also present experimental results using simulated and real environments.


Title: Robotic Grasping Using Proximity Sensors for Detecting both Target Object and Support Surface
Key Words: biomechanics  dexterous manipulators  force control  grippers  manipulators  position control  robot vision  tactile sensors  support surface  target object  positioning  posturing  robotic grasping  proximity sensors  adequate relative posture  Grasping  Robot sensing systems  Robot kinematics  Visualization  Optical sensors 
Abstract: The robustness of the positioning and posturing of robot hands relative to target object and support surface is an important issue for autonomous grasping. For example, to perform a grasping action such as picking up thin objects from a table top, the position and posture of the hand must be controlled to keep adequate relative posture and distance to the support surface besides those between the hand and the target object. Because slight errors in the posture and position are enough to cause grasping failure, the positioning and posturing of the hand must be precise enough, specially when the hand is close to the target object and support surface. To improve the robustness of robotic grasping, in this paper we present a method by grasping control based on the relative posture and position between hand and support surface besides those between hand and target object, using proximity sensors. Proximity sensors are newly installed on fingernails besides on the fingertips. As the fingernail sensor, an integration of Time-of-Flight (TOF) sensor and photo-reflector is designed to realize long range detection, as well as with precise and high-speed detection regardless of the reflectance of support surfaces when approaching the support surface. By the sensors, the hand can approach the object and support surface coarsely first, and then can be controlled fast and precisely to realize adequate grasping motion along the support surface but without contact with the support face. The method has been implemented to a manipulator system, and successful grasping experiments have demonstrated the effectiveness of the proposed method.


Title: Model-free and learning-free grasping by Local Contact Moment matching
Key Words: dexterous manipulators  grippers  image matching  learning (artificial intelligence)  path planning  robot vision  local contact moment matching  LoCoMo metric  grasp planners  learning-based approaches  prototype grasp configurations  robust contacts  fingertip contacts  physical parameters  force-closure analysis  object surface patches  zero-moment shift features  learning-free grasping  Grasping  Robots  Measurement  Grippers  Shape  Three-dimensional displays  Training data 
Abstract: This paper addresses the problem of grasping arbitrarily shaped objects, observed as partial point-clouds, without requiring: models of the objects, physics parameters, training data, or other a-priori knowledge. A grasp metric is proposed based on Local Contact Moment (LoCoMo). LoCoMo combines zero-moment shift features, of both hand and object surface patches, to determine local similarity. This metric is then used to search for a set of feasible grasp poses with associated grasp likelihoods. LoCoMo overcomes some limitations of both classical grasp planners and learning-based approaches. Unlike force-closure analysis, LoCoMo does not require knowledge of physical parameters such as friction coefficients, and avoids assumptions about fingertip contacts, instead enabling robust contacts of large areas of hand and object surface. Unlike more recent learning-based approaches, LoCoMo does not require training data, and does not need any prototype grasp configurations to be taught by kinesthetic demonstration. We present results of real-robot experiments grasping 21 different objects, observed by a wrist-mounted depth camera. All objects are grasped successfully when presented to the robot individually. The robot also successfully clears cluttered heaps of objects by sequentially grasping and lifting objects until none remain.


Title: A Framework for Robot Grasp Transferring with Non-rigid Transformation
Key Words: collision avoidance  control engineering computing  dexterous manipulators  grippers  learning (artificial intelligence)  optimisation  path planning  orientation search  collision avoidance  grasp generation  dexterous tasks execution  online planning  grasp planning  robot grasp transferring  task requirements  robot reachability  grasp robustness  nonrigid transformation  human demonstration  analytic approach  Task analysis  Robots  Grasping  Planning  Collision avoidance  Grippers  Databases 
Abstract: Grasp planning is essential for robots to execute dexterous tasks. Solving the optimal grasps for various objects online, however, is challenging due to the heavy computation load during exhaustive sampling, and the difficulties to consider task requirements. This paper proposes a framework to combine analytic approach with learning for efficient grasp generation. The example grasps are taught by human demonstration and mapped to similar objects by a non-rigid transformation. The mapped grasps are evaluated analytically and refined by an orientation search to improve the grasp robustness and robot reachability. The proposed approach is able to plan high-quality grasps, avoid collision, satisfy task requirements, and achieve efficient online planning. The effectiveness of the proposed method is verified by a series of experiments.


Title: Using human studies to analyze capabilities of underactuated and compliant hands in manipulation tasks
Key Words: actuators  manipulators  human studies  underactuated hands  compliant hands  manipulation tasks  human-subjects  manipulation performance  robotic hands  compliance  compliant distal joints  task completion  different poses  superior task performance  fully-actuated techniques  actuation  robotic systems  Task analysis  Grasping  Robots  Spraying  Shape  Potentiometers  Rubber 
Abstract: We present a human-subjects study approach that supports the analysis of the manipulation performance of robotic hands that have the same morphology but different actuation and compliance. Specifically, we use this approach to analyze three different types of hands (one underactuated, one fully actuated, one fully actuated with compliant distal joints) as they are used to perform two manipulation tasks. The first task uses a power grasp (spraying with a spray bottle), the second a precision grasp (tracing a line on a bowl with a pen). We show that compliance in the distal joints significantly improves performance and task completion. We also show that humans choose significantly different poses for the same task when using a fully-actuated versus underactuated hand, which also results in superior task performance. Our results suggest that humans use a combination of under-actuated and fully-actuated techniques, which when used on robotic systems would also improve their performance on manipulation tasks.


Title: Affordance Wayfields for Task and Motion Planning
Key Words: gradient methods  manipulators  path planning  manipulation affordances  affordance wayfields  motion planning  gradient descent  Michigan Progress Fetch mobile manipulator  Planning  Task analysis  End effectors  Trajectory  Cost function 
Abstract: Affordances provide a natural means for a robot to describe its agency as actions it can perform on objects. Further, affordances can enable robots to reason complicated, multi-step tasks that involve proper use of a diversity of objects. This paper proposes the concept of affordance wayfields for representing manipulation affordances as objective functions in configuration space. Affordance wayfields quantify how well a path, or sequence of motions, will accomplish an afforded action on an object. Paths that enact affordances can be located by performing a randomized form of gradient descent over affordance wayfields. Incorporating obstacles, or other constraints into wayfields allows our method to adaptively generate valid motions for executing afforded actions. We demonstrate that affordance wayfields can enable robots, such as the Michigan Progress Fetch mobile manipulator, to solve complex real-world tasks such as assembling a table, or loading and unloading objects from a storage chest.


Title: Tactile Regrasp: Grasp Adjustments via Simulated Tactile Transformations
Key Words: convolutional neural nets  grippers  manipulators  motion control  path planning  robot vision  tactile regrasp  simulated tactile transformations  tactile sensing  regrasp action  local transformations  grasp quality metric  deep convolutional neural network  rigid-body transformations  grasp quality network  grasp actions  tactile measurements  grasp adjustments  regrasp control policy  tactile imprints  robot motions  Grasping  Measurement  Tactile sensors  Grippers 
Abstract: This paper presents a novel regrasp control policy that makes use of tactile sensing to plan local grasp adjustments. Our approach determines regrasp actions by virtually searching for local transformations of tactile measurements that improve the quality of the grasp. First, we construct a tactile-based grasp quality metric using a deep convolutional neural network trained on over 2800 grasps. The quality of each grasp, a continuous value between 0 and 1, is determined experimentally by measuring its resistance to external perturbations. Second, we simulate the tactile imprints associated with robot motions relative to the initial grasp by performing rigid-body transformations of the given tactile measurements. The newly generated tactile imprints are evaluated with the learned grasp quality network and the regrasp action is chosen to maximize the grasp quality. Results show that the grasp quality network can predict the outcome of grasps with an average accuracy of 85% on known objects and 75% on novel objects. The regrasp control policy improves the success rate of grasp actions by an average relative increase of 70% on a test set of 8 objects. We provide a video summarizing our approach at https://youtu.be/gjn7DmfpwDk.


Title: Adaptive Autonomous Grasp Selection via Pairwise Ranking
Key Words: feature selection  manipulators  mobile robots  robot vision  object subsets  grasp selection algorithm  grasp metrics  object features  user-specified grasp preferences  pairwise ranking problem  pointwise ranking formulation  adaptive autonomous grasp selection  object databases  grasping strategies  robot pick-and-place applications  Measurement  Solid modeling  Training data  Three-dimensional displays  Databases  Training  Data models 
Abstract: Autonomous grasp selection for robot pick-and-place applications makes use of either empirical methods leveraging object databases, which generate grasps for specific objects at the initial cost of modeling effort, or analytical methods, which generalize to novel objects but fail on object subsets that require specific grasping strategies not captured by the algorithm. We introduce a grasp selection algorithm that ranks grasp candidates with a set of grasp metrics augmented with object features, creating an approach that adapts its strategies based on user-specified grasp preferences. We formulate grasp selection as a pairwise ranking problem, which significantly reduces data collection compared to traditional grasp ranking methods and generalizes to novel objects. Our approach outperforms a state-of-the-art grasp calculation baseline and a pointwise ranking formulation of the same problem.


Title: Experience-Based Model Selection to Enable Long-Term, Safe Control for Repetitive Tasks Under Changing Conditions
Key Words: Gaussian processes  learning (artificial intelligence)  learning systems  mobile robots  regression analysis  robot dynamics  learning approaches  significant performance improvements  robotic control  realistic scenarios  rapid changes  existing single-mode safe learning controller  increasing number  nonlinear models  robot dynamics  visited operating conditions  new operating condition  distinct operating condition  control loop  physical changes  artificial changes  experience-based model selection  enable long-term  safe control  repetitive tasks  Gaussian process regression  Robots  Vehicle dynamics  Safety  Heuristic algorithms  Data models  Computational modeling  Task analysis 
Abstract: Learning approaches have enabled significant performance improvements in robotic control allowing robots to execute motions that were previously impossible. The majority of the work to date, however, assumes that the parts to be learned are static or slowly changing, which limits their applicability in realistic scenarios with rapid changes in the conditions. This paper presents a method to extend an existing single-mode safe learning controller based on Gaussian Process Regression to learn an increasing number of non-linear models for the robot dynamics. We show that this approach enables a robot to re-use past experiences from a large number of previously visited operating conditions, and to safely adapt when a new and distinct operating condition is encountered. This allows the robot to achieve safety and high performance in a large number of operating conditions that do not have to be specified ahead of time. Our approach runs independently from the controller, imposing no additional computation time on the control loop regardless of the number of previous operating conditions considered. We demonstrate the effectiveness of our approach in experiment on a 900 kg ground robot with both physical and artificial changes to its dynamics. All of our experiments are conducted using vision for localization.


Title: Efficient Model Identification for Tensegrity Locomotion
Key Words: Bayes methods  legged locomotion  optimisation  robot dynamics  Tensegrity locomotion  mechanical models  actuated robot links  dynamical robotic tasks  Bayesian optimization framework  high-dimensional Tensegrity robot  compliant Tensegrity robot  precise locomotion control  model identification  unknown physical parameters  physics engine  Robots  Engines  Optimization  Physics  Predictive models  Dimensionality reduction  Task analysis 
Abstract: This paper aims to identify in a practical manner unknown physical parameters, such as mechanical models of actuated robot links, which are critical in dynamical robotic tasks. Key features include the use of an off-the-shelf physics engine and the Bayesian optimization framework. The task being considered is locomotion with a high-dimensional, compliant Tensegrity robot. A key insight, in this case, is the need to project the space of models into an appropriate lower dimensional space for time efficiency. Comparisons with alternatives indicate that the proposed method can identify the parameters more accurately within the given time budget, which also results in more precise locomotion control.


Title: Robot-driven Trajectory Improvement for Feeding Tasks
Key Words: assisted living  handicapped aids  learning (artificial intelligence)  medical robotics  mobile robots  path planning  search problems  trajectory control  robotic joints  kinesthetic learning  active learning  robot-driven trajectory improvement  assistive robotics  parameterized similar path search algorithm  PSPS  feeding tasks  computer programming  Trajectory  Task analysis  Robot kinematics  Cost function  Training  Manipulators 
Abstract: Kinesthetic learning is a type of learning from demonstration in which the teacher manually moves the robot through the demonstrated trajectory. It shows great promise in the area of assistive robotics since it enables a caretaker who is not an expert in computer programming to communicate a novel task to an assistive robot. However, the trajectory the caretaker demonstrates to solve the task may be a high-cost trajectory for the robot. The demonstrated trajectory could be high-cost because the teacher does not know what trajectories are easy or hard for the robot to perform, which would be due to a limitation of the teacher's knowledge, or because the teacher has difficulty moving all the robotic joints precisely along the desired trajectories, which would be due to a limitation of the teacher's coordination. We propose the Parameterized Similar Path Search (PSPS) algorithm to extend kinesthetic learning so that a robot can improve the learned trajectory over a known cost function. This algorithm is based on active learning from the robot through collaboration between the robot's knowledge of the cost function and the caretaker's knowledge of the constraints of the assigned task.


Title: Accelerating Learning in Constructive Predictive Frameworks with the Successor Representation
Key Words: computer aided instruction  learning (artificial intelligence)  mobile robots  robot programming  unstructured environments  dynamic environments  reinforcement learning  predictive questions  massive network  interconnected GVFs  interdependent GVFs  SR  continual learning  physical robot arm  constructive predictive frameworks  constructive knowledge system  general value functions  successor representation  accelerated learning  Robots  Prediction algorithms  Function approximation  Acceleration  Approximation algorithms  Standards  Adaptation models 
Abstract: We propose using the Successor Representation (SR) to accelerate learning in a constructive knowledge system based on General Value Functions (GVFs). In real-world settings, like robotics for unstructured and dynamic environments, it is impossible to model all meaningful aspects of a system and its environment by hand. Instead, robots must learn and adapt to changes in their environment and task, incrementally constructing models from their own experience. GVFs, taken from the field of reinforcement learning (RL), are a way of modeling the world as predictive questions. One approach to such models proposes a massive network of interconnected and interdependent GVFs, which are incrementally added over time. It is reasonable to expect that new, incrementally added predictions can be learned more swiftly if the learning process leverages knowledge gained from past experience. The SR provides a means of capturing regularities that can be reused across multiple GVFs by separating the dynamics of the world from the prediction targets. As a primary contribution of this work, we show that using the SR can improve sample efficiency and learning speed of GVFs in a continual learning setting where new predictions are incrementally added and learned over time. We analyze our approach in a grid-world and then demonstrate its potential on data from a physical robot arm.


Title: Reinforcement Learning with Symbolic Input-Output Models
Key Words: autoregressive processes  learning systems  optimal control  regression analysis  state-space methods  reinforcement learning  symbolic input-output models  dynamic prediction model  RL algorithms  nonlinear autoregressive with exogenous input  symbolic regression  parsimonious models  symbolic input-output process model  state-space models  Robots  Springs  Data models  Computational modeling  Optimal control  Reinforcement learning  Process control  Model learning  symbolic regression  reinforcement learning  optimal control 
Abstract: It is well known that reinforcement learning (RL) can benefit from the use of a dynamic prediction model which is learned on data samples collected online from the process to be controlled. Most RL algorithms are formulated in the state-space domain and use state-space models. However, learning state-space models is difficult, mainly because in the vast majority of problems the full state cannot be measured on the system or reconstructed from the measurements. To circumvent this limitation, we propose to use input-output models of the NARX (nonlinear autoregressive with exogenous input) type. Symbolic regression is employed to construct parsimonious models and the corresponding value functions. Thanks to this approach, we can learn accurate models and compute optimal policies even from small amounts of training data. We demonstrate the approach on two simulated examples, a hopping robot and a 1-DOF robot arm, and on a real inverted pendulum system. Results show that our proposed method can reliably determine a good control policy based on a symbolic input-output process model and value function.


Title: A Framework for Teaching Impedance Behaviours by Combining Human and Robot ‘Best Practice’
Key Words: control engineering education  educational robots  learning (artificial intelligence)  manipulators  mobile robots  motion control  muscle  robot dynamics  robot programming  human robot best practice  physical robot  teaching impedance  impedance modulation  human demonstrations  human stiffness  damping  muscle level  task demands  robotic systems  task critical component  robot-specific controller  variable impedance profile  Impedance  Task analysis  Damping  Modulation  Robot kinematics  Covariance matrices 
Abstract: This paper presents a programming by demonstration framework for teaching impedance modulation using human demonstrations. Physiologically, human stiffness and damping are coupled at the muscle level, restricting the ability to modulate impedance according to task demands. Robotic systems often do not have this restriction (stiffness and damping can be varied independently), but the challenge is to devise an appropriate variable impedance profile for a given task. In this paper, the task critical component is first learned for imitation and a robot-specific controller is then blended into the control using the null space. In doing so, the control cheme takes advantage of both human and robot `best practice'. Experimental results on a physical robot suggest an order of magnitude better mean performance, with lower variance, can be achieved using the blended scheme.


Title: Automated Tuning of Nonlinear Model Predictive Controller by Reinforcement Learning
Key Words: autonomous aerial vehicles  control engineering computing  iterative methods  learning (artificial intelligence)  nonlinear control systems  predictive control  trajectory control  nonlinear MPC  trajectory tracking control  aerial robots  NMPC weights  automated tuning  nonlinear model predictive controller  reinforcement learning  nontrivial weight tuning process  generic user-independent framework  trial-and-error method  iterative Gazebo simulations  standard desktop computer  Tuning  Rotors  Computational modeling  Optimization  Aerodynamics  Iron  Reinforcement learning 
Abstract: One of the major challenges of model predictive control (MPC) for robotic applications is the non-trivial weight tuning process while crafting the objective function. This process is often executed using the trial-and-error method by the user. Consequently, the optimality of the weights and the time required for the process become highly dependent on the skill set and experience of the user. In this study, we present a generic and user-independent framework which automates the tuning process by reinforcement learning. The proposed method shows competency in tuning a nonlinear MPC (NMPC) which is employed for trajectory tracking control of aerial robots. It explores the desirable weights within less than an hour in iterative Gazebo simulations running on a standard desktop computer. The real world experiments illustrate that the NMPC weights explored by the proposed method result in a satisfactory trajectory tracking performance.


Title: Soft-obstacle Avoidance for Redundant Manipulators with Recurrent Neural Network
Key Words: biological tissues  collision avoidance  medical robotics  motion control  optimisation  recurrent neural nets  redundant manipulators  surgery  telerobotics  surgical trauma  safety motion constraints  soft-obstacle avoidance problem  redundant manipulators  recurrent neural network  human beings  teleoperated robots  robotic autonomy  soft tissues  surgical safety  robotic surgery  optimization problem  minimally invasive surgeries  Raven-II surgical robot  RNNs  Surgery  Manipulators  Task analysis  Collision avoidance  Recurrent neural networks  Optimization  Soft Obstacle Avoidance  Autonomous Robotic Surgery  Robot Arm  Recurrent Neural Network 
Abstract: Compressing soft-obstacles secondary to a controlled motion task is common for human beings. While these tasks are nearly trivial for teleoperated robots, they remain a challenging problem in robotic autonomy. Addressing the problem is significant. For example, in Minimally Invasive Surgeries (MISs), safely compressing soft tissues ensures the surgical safety and decreases tissue removal, thus dramatically decreases surgical trauma and operating room time, and leads to improved surgical outcomes. In this work, we define the problem of soft-obstacle avoidance and project the safety motion constraints into the task space and the velocity space. We illustrate the significance of addressing this problem in the robotic surgery scenario. We present a Recurrent Neural Networks (RNNs) based solution, which formulates the problem as an inequality constrained optimization problem and solves it in its dual space. The application of the proposed method was demonstrated in the Raven II surgical robot. Experimental results demonstrated that the proposed method is effective in addressing the soft-obstacle avoidance problem.


Title: GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation
Key Words: learning (artificial intelligence)  mobile robots  neural nets  stereo image processing  traversable places  traversable spaces  traversability estimation approaches  GONet  semisupervised deep learning approach  fisheye images  generative adversarial networks  GANs  stereo fisheye cameras  time 24.0 hour  Cameras  Estimation  Robot vision systems  Generators  Training  Gallium nitride 
Abstract: We present semi-supervised deep learning approaches for traversability estimation from fisheye images. Our method, GONet, and the proposed extensions leverage Generative Adversarial Networks (GANs) to effectively predict whether the area seen in the input image(s) is safe for a robot to traverse. These methods are trained with many positive images of traversable places, but just a small set of negative images depicting blocked and unsafe areas. This makes the proposed methods practical. Positive examples can be collected easily by simply operating a robot through traversable spaces, while obtaining negative examples is time consuming, costly, and potentially dangerous. Through extensive experiments and several demonstrations, we show that the proposed traversability estimation approaches are robust and can generalize to unseen scenarios. Further, we demonstrate that our methods are memory efficient and fast, allowing for real-time operation on a mobile robot with single or stereo fisheye cameras. As part of our contributions, we open-source two new datasets for traversability estimation. These datasets are composed of approximately 24h of videos from more than 25 indoor environments. Our methods outperform baseline approaches for traversability estimation on these new datasets.


Title: Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  path planning  safe operation  deep reinforcement learning  complex interactions  environment increases  dynamic agents  particular behavior rules  arbitrary number  motion planning  decision-making agents  collision avoidance algorithms  Collision avoidance  Robots  Training  Decision making  Heuristic algorithms  Sensors  Navigation 
Abstract: Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.


Title: Real-Time Workload Classification during Driving using HyperNetworks
Key Words: cognition  medical signal processing  pattern classification  recurrent neural nets  signal classification  traffic engineering computing  m-HyperLSTM  mixture hyper long short term memory networks  cognitive demands  data variability  robotics  physiological signals  behavioral signals  human cognitive states  eye-gaze pattern dataset  HyperNetworks  real-time cognitive workload classification  sensor artefacts  Adaptation models  Data models  Physiology  Task analysis  Real-time systems  Robot sensing systems 
Abstract: Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks (m-HyperLSTM), a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9% precision and 87.8% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.


Title: Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing
Key Words: Gaussian processes  learning (artificial intelligence)  neural nets  state estimation  robot state estimation  planar pushing  ball bouncing  analytical rigid-body simulator  model uncertainty  symbolic simulators  stochastic neural networks  generalizable physical simulator  universal uncertainty estimates  analytical learned simulators  Gaussian processes  object trajectories  Analytical models  Predictive models  Physics  Data models  Uncertainty  Engines  Neural networks 
Abstract: An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.


Title: Learning to Pour using Deep Deterministic Policy Gradients
Key Words: learning (artificial intelligence)  robots  domestic environments  industrial environments  pre-defined heights  liquid dynamics  PR2 robot  learned policy  fundamental skill  deep deterministic policy gradients  liquid simulator  Liquids  Training  Task analysis  Reinforcement learning  Service robots  Trajectory 
Abstract: Pouring is a fundamental skill for robots in both domestic and industrial environments. Ideally, a robot should be able to pour with high accuracy to specific, pre-defined heights and without spilling. However, due to the complex dynamics of liquids, it is difficult to learn how to pour to achieve these goals. In this paper we present an approach to learn a policy for pouring using Deep Deterministic Policy Gradients (DDPG). We remove the need for collecting training experiences on a real robot, by using a state-of-the-art liquid simulator, which allows for learning the liquid dynamics. We show through our experiments, performed with a PR2 robot, that it is possible to successfully transfer the learned policy to a real robot and even apply it to different liquids.


Title: Learning Sample-Efficient Target Reaching for Mobile Robots
Key Words: gradient methods  learning (artificial intelligence)  mobile robots  path planning  self-supervised policy gradient algorithm  unsupervised auxiliary tasks  sparse range-finder measurements  convolutional networks  network architecture  sparse reward problem  robots uncertainty  unsupervised tasks  mobile robots  planning problem  sample-efficient target reaching learning  Task analysis  Robot sensing systems  Planning  Encoding  Uncertainty  Training 
Abstract: In this paper, we propose a novel architecture and a self-supervised policy gradient algorithm, which employs unsupervised auxiliary tasks to enable a mobile robot to learn how to navigate to a given goal. The dependency on the global information is eliminated by providing only sparse range-finder measurements to the robot. The partially observable planning problem is addressed by splitting it into a hierarchical process. We use convolutional networks to plan locally, and a differentiable memory to provide information about past time steps in the trajectory. These modules, combined in our network architecture, produce globally consistent plans. The sparse reward problem is mitigated by our modified policy gradient algorithm. We model the robots uncertainty with unsupervised tasks to force exploration. The novel architecture we propose with the modified version of the policy gradient algorithm allows our robot to reach the goal in a sample efficient manner, which is orders of magnitude faster than the current state of the art policy gradient algorithm. Simulation and experimental results are provided to validate the proposed approach.


Title: Generative Modeling of Multimodal Multi-Human Behavior
Key Words: approximation theory  behavioural sciences computing  bin packing  human-robot interaction  learning (artificial intelligence)  mobile robots  multi-agent systems  statistical distributions  deep learning approximations  probabilistic graphical models  candidate future agent behavior  crowded environments  human-driven vehicles  human-robot collaborative bin packing  multimodal probability distribution  multihuman interactions  basketball player trajectories  multimodal multihuman behavior  self-driving cars  warehouse  autoencoders  response dynamics  robotic applications  proxy  Trajectory  Predictive models  Analytical models  Deep learning  Ground penetrating radar  Data models  Robots 
Abstract: This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.


Title: Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs
Key Words: convolutional neural nets  image fusion  learning (artificial intelligence)  convolutional network  part affordances  object affordances  affordance detection network  physical properties  geometrical structures  two-stream fully convolutional network  potential affordances  multimodal encoding  geometrical properties  abstract rich photometrical properties  depth images  powerful discriminative features  decoding stream  encoding streams  RGB-D data  Feature extraction  Encoding  Task analysis  Robots  Streaming media  Decoding  Fuses  Affordance detection network (ADNet)  fully convolutional network (FCN) 
Abstract: For a robot to manipulate an object, it has to understand the functions and the actions that can be subjected to the object. This set of information is known as affordance of the object. Affordances are generally defined by the geometrical structures and physical properties of the objects. In this paper, we present an affordance detection network (ADNet) for detecting object affordances using multimodal input i.e., RGB-D data. The method is based on the state-of-the-art fully convolutional network with two encoding streams and one decoding stream. In the presented formulation, the network learns powerful discriminative features independently from the RGB and depth images, which enables it to abstract rich photometrical and geometrical properties of the objects. The multimodal encoding is combined at multiple stages of the network using the late-fusion strategy and used is for predicting the potential affordances of the objects.


Title: Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments
Key Words: learning (artificial intelligence)  legged locomotion  path planning  robot vision  wheels  navigation skills  navigation behaviors  action policies training  height-map image observations  motor commands  dynamic environments  mobile robot navigation  complex environments  deep reinforcement learning  wheel-legged robots  Training  Task analysis  Navigation  Mobile robots  Trajectory  Robot sensing systems 
Abstract: Mobile robot navigation in complex and dynamic environments is a challenging but important problem. Reinforcement learning approaches fail to solve these tasks efficiently due to reward sparsities, temporal complexities and high-dimensionality of sensorimotor spaces which are inherent in such problems. We present a novel approach to train action policies to acquire navigation skills for wheel-legged robots using deep reinforcement learning. The policy maps height-map image observations to motor commands to navigate to a target position while avoiding obstacles. We propose to acquire the multifaceted navigation skill by learning and exploiting a number of manageable navigation behaviors. We also introduce a domain randomization technique to improve the versatility of the training samples. We demonstrate experimentally a significant improvement in terms of data-efficiency, success rate, robustness against irrelevant sensory data, and also the quality of the maneuver skills.


Title: Learning and Generalization of Dynamic Movement Primitives by Hierarchical Deep Reinforcement Learning from Demonstration
Key Words: grippers  learning (artificial intelligence)  nonlinear differential equations  meta-controller  learning generalization  dynamic movement primitives  hierarchical deep reinforcement learning  nonlinear differential equation  observed movement  hierarchical strategy  hierarchical deep RL  DMP framework  6-degree-of-freedom arm  deterministic actor-critic algorithm  robotic skill learning  Task analysis  Robots  Reinforcement learning  Mathematical model  Differential equations  Dynamics  Deep learning 
Abstract: This paper presents an approach to learn and generalize robotic skills from a demonstration using deep reinforcement learning (deep RL). Dynamic Movement Primitives (DMPs) formulate a nonlinear differential equation and produce the observed movement from a demonstration. However, it is hard to generate new behaviors from using DMPs. Thus, we apply DMPs framework into deep RL as an initial setting for learning the robotic skills. First, we build a network to represent this differential equation, and learn and generalize the movements by optimizing the shape of DMPs with respect to the rewards up to the end of each sequence of movement primitives. In order to do this, we consider a deterministic actor-critic algorithm for deep RL and we also apply a hierarchical strategy. This drastically reduces the search space for a robot by decomposing the task, which allows to solve the sparse reward problem from a complex task. In order to integrate DMPs with hierarchical deep RL, the differential equation is considered as temporal abstraction of option. The overall structure is mainly composed of two controllers: meta-controller and sub-controller. The meta-controller learns a policy over intrinsic goals and a sub-controller learns a policy over actions to accomplish the given goals. We demonstrate our approach on a 6 degree-of-freedom (DOF) arm with a I-DOF gripper and evaluate our approach through a pick-and-place task.


Title: Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network
Key Words: convolutional neural nets  learning (artificial intelligence)  object detection  robot vision  statistical analysis  support vector machines  patched convolutional neural network  semantic-aware patch-level convolutional neural network  statistical features  multiclass support vector machine  deep learning framework  robotic applications  vision systems  shadow detection methods  Image color analysis  Image edge detection  Support vector machines  Robots  Image segmentation  Training  Time complexity 
Abstract: In recent years, various shadow detection methods from a single image have been proposed and used in vision systems; however, most of them are not appropriate for the robotic applications due to the expensive time complexity. This paper introduces a fast shadow detection method using a deep learning framework, with a time cost that is appropriate for robotic applications. In our solution, we first obtain a shadow prior map with the help of multi-class support vector machine using statistical features. Then, we use a semantic-aware patch-level Convolutional Neural Network that efficiently trains on shadow examples by combining the original image and the shadow prior map. Experiments on benchmark datasets demonstrate the proposed method significantly decreases the time complexity of shadow detection, by one or two orders of magnitude compared with state-of-the-art methods, without losing accuracy.


Title: Robust Decentralized Context-Aware Sensor Fault Detection with In-Place Self-Calibration
Key Words: Bayes methods  calibration  fault diagnosis  hidden Markov models  sensors  statistical analysis  complex context information  decentralized RANSAC  Bayesian networks  uncalibrated sensor  hidden Markov models  robust decentralized context-aware sensor fault detection methods  industrial plants  in-place sensor self-recalibration capability  consensus-based modeling step  statistical analysis  network topology  complex dynamic systems  Robot sensing systems  Hidden Markov models  Computational modeling  Monitoring  Temperature measurement  Bayes methods  Analytical models 
Abstract: There is a high demand in advanced fault detection methods suitable for sensor networks monitoring complex dynamic systems such as industrial plants or large infrastructure units. This paper proposes a robust and efficient decentralized sensor fault detection method with in-place sensor self-recalibration capability that extracts and uses complex context information referred to the full monitored process. The method includes three main components, all decentralized and sharing the same statistical framework: 1) a consensus-based modeling step based on decentralized RANSAC; 2) a statistical analysis based on Bayesian networks and Hidden Markov Models in which each sensor identifies inconsistencies with the consensus model and determines if it is correctly calibrated, uncalibrated or faulty and; 3) a final step in which each uncalibrated sensor self-recalibrates using the consensus model. The proposed method is efficient in the use of computational and communicational resources, it is scalable and robust against outliers, transmission errors, sensor failures and network topology changes. It has been extensively validated in an experimental industrial setting.


Title: Heterogeneous Sensor-Robot Team Positioning and Mixed Strategy Scheduling
Key Words: game theory  multi-robot systems  scheduling  sensor placement  simulated annealing  heterogeneous sensor-robot team positioning  mixed strategy scheduling  effector robots  anticipated arrival traffic  adversarial game  sensor positions  anticipated potential arrival paths  uniform power schedule  adaptive simulated annealing  Robot sensing systems  Schedules  Robot kinematics  Games  Linear programming 
Abstract: We are faced with the problem of optimally placing a heterogeneous team of sensors and effector robots in an area while taking into account the environment, anticipated arrival traffic, and desired power consumption of the team. We stage the problems of anticipating arrival traffic and determining a proper power schedule as an adversarial game, incorporating our analysis of the game in the objective function which evaluates sensor positions. We obtain the set of sensor positions which performs best at the desired power consumption, evaluating the mixed strategy of sensor activity that best counters the anticipated potential arrival paths. To determine an approximate global optima for a large number of heterogeneous nodes, we employ Adaptive Simulated Annealing (ASA) to ensure our algorithm is flexible over a varied range of scenarios. We compare the proposed algorithm to a gradient-based greedy placement algorithm with a uniform power schedule within simulation.


Title: Robotic Subsurface Pipeline Mapping with a Ground-penetrating Radar and a Camera
Key Words: buried object detection  geophysical image processing  geophysical techniques  ground penetrating radar  image reconstruction  maximum likelihood estimation  pipelines  radar detection  radar imaging  robot vision  pipeline groups  hyperbola response  GPR sensing process  Ground Penetrating Radar scans  subsurface pipeline mapping method  robotic subsurface pipeline mapping  subsurface pipes  representative pipeline configurations  maximum likelihood estimation  J-Linkage method  hyperbolas  GPR scans  mapping outputs  visual simultaneous localization  nonperpendicular angles  general scanning  size 4.69 cm  Ground penetrating radar  Pipelines  Cameras  Three-dimensional displays  Trajectory  Robot sensing systems 
Abstract: We propose a novel subsurface pipeline mapping method by fusing Ground Penetrating Radar (GPR) scans and camera images. To facilitate the simultaneous detection of multiple pipelines, we model the GPR sensing process and prove hyperbola response for general scanning with non-perpendicular angles. Furthermore, we fuse visual simultaneous localization and mapping outputs, encoder readings with GPR scans to classify hyperbolas into different pipeline groups. We extensively apply the J-Linkage method and maximum likelihood estimation to improve algorithm robustness and accuracy. As the result, we optimally estimate the radii and locations of all pipelines. We have implemented our method and tested it in physical experiments with representative pipeline configurations. The results show that our method successfully reconstructs all subsurface pipes. Moreover, the average localization error is 4.69cm.


Title: UAV Based Wireless Charging of Sensor Networks Without Prior Knowledge
Key Words: autonomous aerial vehicles  wireless sensor networks  Power Transfer Efficiency Compensation  efficiency drops  real-world power transfer scenarios  knowledge algorithm  maximum power transfer efficiency  constant maximum efficiency CPTEC  UAV based Wireless Charging  Unmanned Aerial Vehicles  Wireless Rechargeable Sensor Networks  charging efficiency  wireless transmitter  charged node  sensor nodes  power information  limits scalability  wireless receiver  power level increase  power level increase  Robot sensing systems  Unmanned aerial vehicles  Wireless sensor networks  Wireless communication  Receivers  Wireless power transfer 
Abstract: Unmanned Aerial Vehicles (UAVs) can charge Wireless Rechargeable Sensor Networks (WRSNs) in remote or hard to access locations. However, the charging efficiency is heavily affected by the distance between the wireless transmitter and receiver. This efficiency impacts the possible power level increase of each charged node. Most charging algorithms require full knowledge of sensor nodes' power levels to identify the nodes to charge. Collecting this power information adds overhead to the network and limits scalability. We propose and implement Charging with Power Transfer Efficiency Compensation (CPTEC), an algorithm that charges a WRSN without the need for a priori knowledge of the nodes' power levels. We show that CPTEC compensates for efficiency drops, due to landing alignments, making it practical for real-world power transfer scenarios. Our results show that CPTEC is able to perform with a median at ≈ 72% of the optimal performance of a full knowledge algorithm that assumes maximum power transfer efficiency, while other work drops to ≈ 22%. Under constant maximum efficiency CPTEC performs ≈ 90% of the optimal full knowledge case.


Title: Mobile Robot Localization Considering Class of Sensor Observations
Key Words: collision avoidance  mobile robots  localization robustness  environment dynamics  robots  sensor observations  mapped obstacles  observation model  unmapped obstacles  real-world mobile robot navigation competition  mobile robot localization  Robot sensing systems  Mathematical model  Robustness  Hidden Markov models  Mobile robots  Collision avoidance 
Abstract: Localization robustness against environment dynamics is significant for robots to achieve autonomous navigation in unmodified environments. A basic method of improving the robustness of a robot is considering the sensor observations obtained from mapped obstacles and using them for localizing the robot's pose. This study proposes an observation model that considers the class of sensor observations, where “class” categorizes the sensor observations as those obtained from mapped and unmapped obstacles. In the proposed approach, the robot's pose and the class are estimated simultaneously. As a result, the robot's pose can be localized using the sensor observations obtained only from mapped obstacles. First, we evaluated the performance of the proposed approach using simulations. Further, we tested the proposed approach in a real-world mobile robot navigation competition, called “Tsukuba Challenge,” held in Japan. The robustness and effectiveness of the proposed approach against environment dynamics were verified from the experimental results.


Title: Robust Odometry using Sensor Consensus Analysis
Key Words: calibration  distance measurement  Kalman filters  measurement uncertainty  nonlinear filters  sensors  statistical testing  odometry system  measurement pre-processing stage  sensor consensus analysis  German Intercity-Express highspeed trains  wheel slip  autonomous systems  rail industry  extended Kalman filter  automatic train protection systems  incorrect velocity estimation  robust odometry systems  wheel encoder miscalibration  wheel slippage  wheel encoder calibration  SCA  statistical z-testing  measurement uncertainty  Wheels  Robot sensing systems  Acceleration  Measurement uncertainty  Global Positioning System  Extraterrestrial measurements  Length measurement 
Abstract: Odometry forms an important component of many manned and autonomous systems. In the rail industry in particular, having precise and robust odometry is crucial for the correct operation of the Automatic Train Protection systems that ensure the safety of high-speed trains in operation around the world. Two problems commonly encountered in such odometry systems are miscalibration of the wheel encoders and slippage of the wheels under acceleration and braking, resulting in incorrect velocity estimates. This paper introduces an odometry system that addresses these problems. It comprises of an Extended Kalman Filter that tracks the calibration of the wheel encoders as state variables, and a measurement pre-processing stage called Sensor Consensus Analysis (SCA) that scales the uncertainty of a measurement based on how consistent it is with the measurements from the other sensors. SCA uses the statistical z-test to determine when an individual measurement is inconsistent with the other measurements, and scales the uncertainty until the z-test passes. This system is demonstrated on data from German Intercity-Express highspeed trains and it is shown to successfully deal with errors due to miscalibration and wheel slip.


Title: Human-in-the-loop Augmented Mapping
Key Words: inertial systems  mobile robots  operating systems (computers)  optical radar  path planning  robot programming  user interfaces  2D map building  user interface  human map augmentation  LIDAR  Gmapping ROS package  Unity software  online editing capabilities  user-friendly system  traditional offline post processing  real-time human augmented mapping system  human-in-the-loop  mapping errors  Two dimensional displays  Laser radar  Simultaneous localization and mapping  Three-dimensional displays  Corporate acquisitions 
Abstract: In this paper we develop a real-time human augmented mapping system. This approach replaces the traditional offline post processing of maps by a user-friendly system allowing for online editing capabilities. A wide number of applications that acquire accurate mapping of the environment could benefit from such a solution. The proposed framework consists of two main parts: 2D map building using LIDAR, encoders, and IMU; and a user interface for human map augmentation. The first part is built over Gmapping ROS package, while the second is developed in Unity software. Realworld experiments validated the ability of our system to correct for sensor noise and various mapping errors, thus increasing the accuracy of the obtained maps without additional computational costs.


Title: A B-Spline Mapping Framework for Long-Term Autonomous Operations
Key Words: image representation  image sensors  mobile robots  navigation  path planning  robot vision  SLAM (robots)  splines (mathematics)  landmark-based maps  robotics community  high frequency sensor  B-spline curves  B-spline maps  mapping algorithm  2D B-spline mapping framework  outdoor long-term autonomous operations  simultaneous localization and mapping  SLAM algorithm  software-in-the-loop simulations  Splines (mathematics)  Simultaneous localization and mapping  Three-dimensional displays  Robot kinematics  Two dimensional displays 
Abstract: This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.


Title: Building Dense Reflectance Maps of Indoor Environments Using an RGB-D Camera
Key Words: brightness  cameras  image colour analysis  image reconstruction  lighting conditions  light emitters  high dynamic range radiosity estimation  reflectance estimate  diffuse reflectance  specific lighting condition  colored models  extensive progress  RGB-D cameras  dense surface geometry  robotic applications  indoor environments  building dense reflectance maps  Cameras  Lighting  Image reconstruction  Robots  Geometry  Indoor environments  Surface treatment 
Abstract: The ability to build models of the environment is an essential prerequisite for many robotic applications. In recent years, mapping of dense surface geometry using RGB-D cameras has seen extensive progress. Many approaches build colored models, typically directly using the intensity values provided by the camera. Unfortunately, these intensities are inherently affected by illumination. Therefore, the resulting maps only represent the environment for one specific lighting condition. To overcome this limitation, we propose to build reflectance maps that are invariant against changes in lighting. Our approach estimates the diffuse reflectance of a surface by recovering its radiosity and the corresponding irradiance. As imperfections in this process can significantly degrade the reflectance estimate, we remove outliers in the high dynamic range radiosity estimation and propose a method to refine the reflectance estimate. Our system implements the whole pipeline for offline reconstruction of dense reflectance maps including the segmentation of light emitters in the scene. We demonstrate the applicability of our approach in real-world experiments under varying lighting conditions.


Title: 3D Underground Mapping with a Mobile Robot and a GPR Antenna
Key Words: feature extraction  ground penetrating radar  image matching  image segmentation  mobile robots  radar imaging  underground robotic applications  image processing techniques  subsurface 3D map  Ground Penetrating Radar  construction services  automatic subsurface mapping  GPR antenna  mobile robot  underground mapping  Ground penetrating radar  Three-dimensional displays  Feature extraction  Mobile antennas  Mobile robots  Antenna measurements 
Abstract: Automatic subsurface mapping is essential in the construction services, as it is anticipated to become the main operational environment of the future robots to be realized in the respective domain. Towards this direction, the paper at hand, introduces for the first time herein, an integrated framework for subsurface mapping by exploiting a surface operating mobile robot with a Ground Penetrating Radar (GPR). The mobile robot tows the GPR antenna, which is mounted on a specifically designed trailer, and is utilized as the mean to cover the surface area, while at the same time the antenna scans the subsurface by emitting electromagnetic pulses. The gathered data are processed for the construction of a subsurface 3D map. Specifically, image processing techniques, that involve background segmentation, HOG [1] feature extraction, hypothesis verification and matching are applied on the 2D radargram (B-Scan) for the detection of the salient points that correspond to buried utilities. By employing the pulse propagation velocity into the subsurface and the soil utilities, the salient points are expressed in world coordinates and used for the composition of the 3D subsurface map. Our method has been evaluated on a real test site, accompanied by ground-truth annotation data of experts and revealed remarkable performance, exhibiting not only the feasibility of underground mapping but also the capacity to obtain exploitable results for underground robotic applications.


Title: Adaptive Baseline Monocular Dense Mapping with Inter-Frame Depth Propagation
Key Words: image matching  image reconstruction  image sequences  stereo image processing  monocular dense mapping methods  frame-to-frame propagated depth filter  wide-baseline observations  sequential input images  adaptive baseline matching cost computation  sequential depth estimation  multibaseline observations  separate multiview stereo problems  image sequence  inter-frame depth propagation  adaptive baseline monocular dense mapping  Estimation  Cameras  Probabilistic logic  Adaptive systems  Image sequences  Real-time systems  Robot vision systems 
Abstract: State-of-the-art monocular dense mapping methods usually divide the image sequence into several separate multi-view stereo problems thus have limited utilization of the information in multi-baseline observations and sequential depth estimations. In this paper, two core contributions are proposed to improve the mapping performance by exploiting the information. The first is an adaptive baseline matching cost computation that uses the sequential input images to provide each pixel with wide-baseline observations. The second is a frame-to-frame propagated depth filter which integrates the sequential depth estimation of the same physical point in a robust probabilistic manner. Two contributions are integrated into a monocular dense mapping system that generates the depth maps in real-time for both pinhole and fisheye cameras. Our system is fully parallelized and can run at more than 25 fps on a Nvidia Jetson TX2. We compare our work with state-of-the-art methods on the public dataset. Onboard UAV mapping and handhold experiments are also used to demonstrate the performance of our method. For the benefit of the community, we make the implementation open source.


Title: Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles
Key Words: cameras  computer vision  image reconstruction  image resolution  image texture  mesh generation  mobile robots  optical radar  robot vision  scan matching techniques  end-to-end real time framework  real time incremental foveal texture mapping  real time incremental foveal texture mapping  precise localization  detailed map  urban environment  high resolution graphics grade  texture mapping error  texture error  output map  computation time  ray-filtering  sparse input LIDAR scan  high resolution 3D  camera image information  pose-refinement procedure  color texture  coherent 3D surface  computer games  background map  planning algorithms  virtual test bed  autonomous vehicles  navigation  Three-dimensional displays  Laser radar  Cameras  Real-time systems  Image color analysis  Global Positioning System 
Abstract: We propose an end-to-end real time framework to generate high resolution graphics grade textured 3D map of urban environment. The generated detailed map finds its application in the precise localization and navigation of autonomous vehicles. It can also serve as a virtual test bed for various vision and planning algorithms as well as a background map in the computer games. In this paper, we focus on two important issues: (i) incrementally generating a map with coherent 3D surface, in real time and (ii) preserving the quality of color texture. To handle the above issues, firstly, we perform a pose-refinement procedure which leverages camera image information, Delaunay triangulation and existing scan matching techniques to produce high resolution 3D map from the sparse input LIDAR scan. This 3D map is then texturized and accumulated by using a novel technique of ray-filtering which handles occlusion and inconsistencies in pose-refinement. Further, inspired by human fovea, we introduce foveal-processing which significantly reduces the computation time and also assists ray-filtering to maintain consistency in color texture and coherency in 3D surface of the output map. Moreover, we also introduce texture error (TE) and mean texture mapping error (MTME), which provides quantitative measure of texturing and overall quality of the textured maps.


Title: Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
Key Words: collision avoidance  human-robot interaction  mobile robots  optical radar  path planning  probability  directional grid maps  occupancy map  mobile robot  robotic arm  static environments  dynamic objects  safer navigation  human-robot interaction  directional statistics  robotic mapping  model circular data  angular motion  probability measure-field  angular variations  indoor environments  outdoor environments  dynamic environments  grid maps  multimodal angular uncertainty  Vehicle dynamics  Robot sensing systems  Data models  Uncertainty  Navigation 
Abstract: Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.


Title: The Effect of Swing Leg Retraction on Biped Walking Stability is Influenced by the Walking Speed and Step-Length
Key Words: gait analysis  legged locomotion  mechanical stability  mechanical variables control  walking speed  swing leg retraction  human-preferred walking patterns  human walking speeds/step-lengths  simple biped model  SLR effects  human walking patterns  biped walking stability  Legged locomotion  Mathematical model  Analytical models  Stability criteria  Foot  Biped robots  Swing leg retraction  Human walking 
Abstract: Swing Leg Retraction (SLR) is observed in human walking and running. Previous studies have concluded that SLR improves the stability and robustness of biped walking. But this conclusion was based on analysis of robot models that can only walk at a very small range of step-lengths and slow or fixed speeds. By contrast, humans can walk with a large range of speeds and step-lengths. Moreover, human walking patterns have a special feature that has not been considered in the previous studies on SLR effects: At a given walking speed, v, humans prefer a step-length, s, which satisfies the power law, s-vβ. Therefore, previous studies on SLR can't tell us whether their conclusion will still hold in the full range of human walking patterns (i.e., various walking speeds and step-lengths). This is the question we want to answer in this paper. In this study, using a simple biped model, we studied how the SLR affects the walking stability in the full range of human walking speeds/step-lengths. Preliminary analysis of both models suggests the same conclusion: (1) SLR improves the stability more evidently in human-preferred walking patterns than in other walking patterns. (2) In walking patterns that are very unlike human-preferred ones, the SLR improves the stability very little, or even deteriorates it drastically. Therefore, the new finding of our study is that how the SLR affects the biped walking stability depends on the walking speed and step-length. SLR does not always improve the stability of biped walking.


Title: An Analytical Study on Trotting at Constant Velocity and Height
Key Words: legged locomotion  motion control  robot dynamics  body height  quadrupedal trotting gaits  single-legged model  point mass  actuated rotational joints  robot mass  actuator properties  robot body feasible trajectories  forward velocity  leg properties  Legged locomotion  Actuators  Trajectory  Knee  Torque  Task analysis 
Abstract: Quadrupedal trotting gaits of constant forward velocity and body height are studied. A method is developed, which is structured upon analytical expressions derived from the dynamics of a reduced single-legged model comprised of a point mass, and two actuated rotational joints. The inputs of the method include the robot mass, the leg and actuator properties, and the desired forward velocity, yielding all robot body feasible trajectories and their energy footprints. Thus, the method predicts the maximum forward velocity of a trotting quadruped; it also suggests energetically optimal combinations of body height and step length for a given forward velocity.


Title: Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick
Key Words: biomechanics  bone  humanoid robots  kinematics  mobile robots  motion control  muscle  swimming style  musculoskeletal humanoid robot  Triton  flexible spine  erector spinae muscles  stiffness adjustment system  lumbar joints  musculoskeletal body  multijoint coordination  pneumatic muscles  lightweight properties  inherently waterproof properties  human swimming  musculoskeletal swimming robot  joint angle  thrust force  biomechanical research  underwater dolphin kick  Muscles  Dolphins  Force  Legged locomotion  Sports 
Abstract: The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.


Title: Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)
Key Words: humanoid robots  hydraulic control equipment  hydraulic systems  legged locomotion  magnetorheology  robust control  vibration control  wheels  magnetorheological fluid-based damper  hydraulic wheel-legged robot  terrain environments  direct-drive wheels  hydraulic system  environmental adaptability  mobile abilities  innovative design  robustness  humanoid structural design  multimodal locomotion  wheel-legged hybrid robot  WLR  Conferences  Intelligent robots 
Abstract: Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.


Title: Sensor-Based Reactive Execution of Symbolic Rearrangement Plans by a Legged Mobile Manipulator
Key Words: collision avoidance  feedback  legged locomotion  manipulators  mobile robots  motion control  path planning  torque control  motion planner  reactive layer  reference output  deliberative layer  unanticipated obstacles  gait layer  abstract unicycle commands  reactive module  appropriately coordinated joint level torque feedback loops  empirical demonstration  sensor-based reactive execution  symbolic rearrangement plans  legged mobile manipulator  physical rearrangement  wheeled stools  moderately cluttered indoor environment  quadrupedal robot  layer hierarchical architecture  offline symbolic task  Task analysis  Grippers  Robot sensing systems  Robot kinematics  Mobile robots  Manipulators 
Abstract: We demonstrate the physical rearrangement of wheeled stools in a moderately cluttered indoor environment by a quadrupedal robot that autonomously achieves a user's desired configuration. The robot's behaviors are planned and executed by a three layer hierarchical architecture consisting of: an offline symbolic task and motion planner; a reactive layer that tracks the reference output of the deliberative layer and avoids unanticipated obstacles sensed online; and a gait layer that realizes the abstract unicycle commands from the reactive module through appropriately coordinated joint level torque feedback loops. This work also extends prior formal results about the reactive layer to a broad class of nonconvex obstacles. Our design is verified both by formal proofs as well as empirical demonstration of various assembly tasks.


Title: An Assist-as-Needed Velocity Field Control Scheme for Rehabilitation Robots
Key Words: control system synthesis  feedback  medical robotics  neural nets  patient rehabilitation  stability  velocity control  rehabilitation robots  neural network term  dead-zone function  feedback control term  bounded control command  AAN scheme  controller design  assist-as-needed velocity field control scheme  proportional-like feedback term  forgetting factor  lower-limb exoskeleton  NN component  system stability  Artificial neural networks  Timing  Aerospace electronics  Rehabilitation robotics  Stability analysis  Exoskeletons  Rehabilitation robots  assist-as-need control  neural network  exoskeleton 
Abstract: This paper addresses the problem of assist-as-needed (AAN) control for rehabilitation robots. To achieve a motion which is not explicitly a function of time, the velocity field control is considered in this paper. The proposed new controller consists of a proportional-like feedback term and a neural network (NN) term, where the later is exploited to compensate for the dynamic uncertainties of the system. The AAN property is facilitated by means of a dead-zone function in the feedback control term and a forgetting factor in the adaptation law of NN component. The designed controller guarantees the stability of the system with a bounded control command. The performance of the proposed AAN scheme is validated through the simulation and experiment conducted on a lower-limb exoskeleton.


Title: The KIT Prosthetic Hand: Design and Control
Key Words: actuators  biomechanics  cameras  colour displays  dexterous manipulators  embedded systems  mechatronics  medical robotics  prosthetics  three-dimensional printing  mechatronics  kinematic parameters  RGB camera  colour display  innovative control  sensor integration  hand closing time  percentile male hand  underactuated TUAT/Karlsruhe mechanism  hand mechanics  embedded control system  underactuated mechanism  five-finger 3D printed hand prosthesis  KIT prosthetic hand  Embedded systems  Grasping  Tendons  Robot sensing systems  Thumb  Prosthetic hand 
Abstract: The development and control of prosthetic hands is an active research area and recently progress in mechatronics, sensor integration and innovative control has been made. However, integration of different components into a prosthetic hand remains challenging due to space constraints, the requirements regarding holistic integration and the need for a user interface. In this paper, we present the KIT prosthetic hand, a novel five-finger 3D printed hand prosthesis, with its underactuated mechanism, sensors and embedded control system. The hand mechanics is based on the underactuated TUAT/Karlsruhe mechanism with two motors actuating 10 degrees of freedom. The mechanism has been realized in 3D printing technologies to facilitate a personalization of the prosthetic hand in terms of size and kinematic parameters. The prosthesis has been designed as a 50th percentile male hand. It integrates an advanced embedded system as well as an RGB camera in the base of the palm and a colour display in the back of the hand. Experiments indicate a finger tip force of 7.48 N to 11.82 N, a hook grasp force of 120 N and a hand closing time of ~ 1.3 s.


Title: Robot Controllers Compatible with Human Beam Balancing Behavior
Key Words: angular momentum  biocontrol  biomechanics  legged locomotion  mechanoception  motion control  pendulums  stability  human beam balancing behavior  challenging motor skill  upright balance  stability  humans  narrow beam  lower-body angular momentum  interlimb coordination  balance controller  robotics literature  robot controllers  balancing controllers  Robot kinematics  Foot  Task analysis  Legged locomotion  Correlation  Exoskeletons 
Abstract: Standing on a beam is a challenging motor skill that requires the regulation of upright balance and stability. In this paper, we analyzed the behavior of humans balancing on a narrow beam without footwear. The results revealed high anti-correlation between lumped upper- and lower-body angular momentum. Despite differences in gross measures of balance, interlimb coordination was consistent between the novice and expert subjects, suggesting that both performances could be described with the same balance controller. By simulating a double inverted pendulum model utilizing different balancing controllers described in the robotics literature, we identified that the whole behavior observed from humans standing on a beam was best replicated with controllers that predominantly utilized hip actuation.


Title: Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study
Key Words: biomechanics  medical robotics  motion control  robot dynamics  robot kinematics  shock absorbers  viscoelasticity  wearable robots  lower-extremity wearable link mechanism  exoskeleton robot  shock absorbing exoskeleton  human skeletal system  human-exoskeleton coupled system  vertical mobility system  dynamic models  kinematic models  multielement viscoelastic model  Exoskeletons  Electric shock  Muscles  Joints  Bones  Force  Injuries 
Abstract: The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.


Title: Prediction of Manipulation Action Classes Using Semantic Spatial Reasoning
Key Words: hidden Markov models  human-robot interaction  image sequences  manipulators  spatial reasoning  video signal processing  trajectory-based HMM method  simple robot demonstration  dynamic spatial relations  static relations  temporal sequence  Enriched Semantic Event Chain framework  video sequences  predictive action recognition  human-robot interaction  Semantic spatial reasoning  manipulation action classes  Robots  Three-dimensional displays  Predictive models  Semantics  Human-robot interaction  Prediction algorithms  Image segmentation 
Abstract: Human-robot interaction strongly benefits from fast, predictive action recognition. For us this is relatively easy but difficult for a robot. To address this problem, here we present a novel prediction algorithm for manipulation action classes in video sequences. Manipulations are first represented using the Enriched Semantic Event Chain (ESEC) framework. This creates a temporal sequence of static and dynamic spatial relations between the objects that take part in the manipulation by which an action can be quickly recognized. We measured performance on 32 ideal as well as real manipulations and compared our method also against a state of the art trajectory-based HMM method for action recognition. We observe that manipulations can be correctly predicted after only (on average) 45% of action's total time and that we are almost twice as fast as the HMM-based method. Finally, we demonstrate the advantage of this framework in a simple robot demonstration comparing two different approaches.


Title: Human Motion Prediction Under Social Grouping Constraints
Key Words: Markov processes  mobile robots  motion control  multi-robot systems  planning (artificial intelligence)  probability  random processes  human motion prediction  social grouping constraints  long-term prediction  social relations  social norms  surrounding agents  MDP planning problem  social forces  social grouping information  prediction process  soft formation constraints  mobile robots  Force  Task analysis  Trajectory  Predictive models  Computational modeling  Tracking  Planning 
Abstract: Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.


Title: Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans
Key Words: human-robot interaction  Kalman filters  mobile robots  multi-robot systems  path planning  risk analysis  trajectory control  risk-based human-aware multirobot coordination  dynamic environments  human-populated environments  Kalman filter  position estimation  MRTA problem  human trajectory prediction  multirobot task allocation problem  human-aware navigation  risk-based bids  risk-based human-aware planning  human-agnostic planning  prediction error  Robot kinematics  Task analysis  Navigation  Planning  Uncertainty  Estimation 
Abstract: In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.


Title: Effects of Integrated Intent Recognition and Communication on Human-Robot Collaboration
Key Words: human-robot interaction  image motion analysis  mobile robots  human-robot interaction  human partners hand motion intent  communication system  bi-directional intent system  predictable motion  legible motion  motion planner system  intent recognition system  collaborative physical task  intentional motion  human-robot collaboration  integrated intent recognition  Collaboration  Task analysis  Trajectory  Motion segmentation  Containers  Manipulators 
Abstract: Human-robot interaction research to date has investigated intent recognition and communication separately. In this paper, we explore the effects of integrating both the robot's ability to generate intentional motion and predict the human's motion in a collaborative physical task. We implemented an intent recognition system to recognize the human partner's hand motion intent and a motion planner system to enable the robot to communicate its intent by using legible and predictable motion. We tested this bi-directional intent system in a 2-way within-subjects user study. Results suggest that an integrated intent recognition and communication system may facilitate more collaborative behavior among team members.


Title: After You: Doorway Negotiation for Human-Robot and Robot-Robot Interaction
Key Words: human-robot interaction  path planning  doorway negotiation  robot-robot interaction  autonomous robot behavior  aggressive interaction  navigation deadlocks  assertive robot  common navigation sensors  naive human participants  human users  robot-robot experiments  human-robot interaction study  Navigation  Collision avoidance  Robot sensing systems  System recovery  Autonomous robots  Safety 
Abstract: We propose and test an autonomous robot behavior for socially-compliant navigation of doorways with both human and robot interlocutors. Building on previous work for “aggressive” interaction between robots to resolve navigation deadlocks in corridors, we demonstrate an “assertive” robot that negotiates right-of-way when faced with a human or other robot. The negotiation is implemented using only motion and common navigation sensors, without explicit message-passing. Our goal is for the correct agent to take priority, as decided both by time-efficiency and as judged subjectively by naive human participants. Our contribution is a practical method for doorway negotiation, and a study of human users' responses to a robot that appears to participate in existing social customs surrounding doors. Our method is evaluated with robot-robot experiments and a human-robot interaction study with nonexpert users.


Title: The Power of Color: A Study on the Effective Use of Colored Light in Human-Robot Interaction
Key Words: human computer interaction  human-robot interaction  mobile robots  service robots  mobile robot  color preference  appropriate colors  cheap feedback mechanism  complex interaction techniques  human-robot interaction  colored light  Color  Videos  Animation  Mobile robots  Task analysis  Human-robot interaction 
Abstract: In times of more and more complex interaction techniques, we point out the powerfulness of colored light as a simple and cheap feedback mechanism. Since it is visible over a distance and does not interfere with other modalities, it is especially interesting for mobile robots. In an online survey, we asked 56 participants to choose the most appropriate colors for scenarios that were presented in the form of videos. In these scenarios a mobile robot accomplished tasks, in some with success, in others it failed because the task is not feasible, in others it stopped because it waited for help. We analyze in what way the color preferences differ between these three categories. The results show a connection between colors and meanings and that it depends on the participants' technical affinity, experience with robots and gender how clear the color preference is for a certain category. Finally, we found out that the participants' favorite color is not related to color preferences.


Title: Neuroscientifically-Grounded Research for Improved Human-Robot Interaction
Key Words: cognition  electroencephalography  humanoid robots  human-robot interaction  man-machine systems  neurophysiology  psychology  objective neuroscientific methods  experimental psychology research  well-controlled experimental designs  improved human-robot interaction  experimentation tapping  robot design  human social cognition  humanoid robot  robotics community  enhanced event-related potentials  faster response times  gaze-cueing research  documented results  iCub robot  HRI protocol  gaze cueing  joint attention  attentional cueing  human-robot interaction research  Cognition  Psychology  Humanoid robots  Protocols  Electroencephalography  Robot sensing systems 
Abstract: The present study highlights the benefits of using well-controlled experimental designs, grounded in experimental psychology research and objective neuroscientific methods, for generating progress in human-robot interaction (HRI) research. More specifically, we aimed at implementing a well-studied paradigm of attentional cueing through gaze (the so-called “joint attention” or “gaze cueing”) in an HRI protocol involving the iCub robot. Similarly to documented results in gaze-cueing research, we found faster response times and enhanced event-related potentials of the EEG signal for discrimination of cued, relative to uncued, targets. These results are informative for the robotics community by showing that a humanoid robot with mechanistic eyes and human-like characteristics of the face is in fact capable of engaging a human in joint attention to a similar extent as another human would do. More generally, we propose that the methodology of combining neuroscience methods with an HRI protocol, contributes to understanding mechanisms of human social cognition in interactions with robots and to improving robot design, thanks to systematic and well-controlled experimentation tapping onto specific cognitive mechanisms of the human, such as joint attention.


Title: Robust LIDAR Localization for Autonomous Driving in Rain
Key Words: feature extraction  mobile robots  optical radar  particle filtering (numerical methods)  stereo image processing  traffic engineering computing  3D LIDAR scans  histogram filter  particle filter  posterior distributions  vehicle poses  complex urban environments  fair weather  rainy weather  robust LIDAR localization  autonomous driving  map-based localization method  rainy conditions  ground reflectivity features  vertical features extraction  Feature extraction  Three-dimensional displays  Laser radar  Histograms  Rain  Measurement by laser beam  Two dimensional displays 
Abstract: This paper introduces a map-based localization method aiming to increase robustness in rainy conditions. This method utilizes two types of features: ground reflectivity features and vertical features extracted from 3D LIDAR scans and builds vehicle pose belief with two filters: a histogram filter and a particle filter. The posterior distributions from the two filters are integrated to estimate vehicle poses. This method exploits advantages of both features and filters, compensating respective weakness to deal with complex urban environments. Testing was performed in the fair and rainy weather. Road test results prove robustness and reliability of the proposed method.


Title: Move Base Flex A Highly Flexible Navigation Framework for Mobile Robots
Key Words: mobile robots  motion control  navigation  path planning  MBF  path planning  motion control  robot tasks  complex navigation tasks  Move Base Flex  highly flexible navigation framework  modular navigation  map-independent navigation  open-source navigation  Navigation  Robots  Computer architecture  Task analysis  Flexible printed circuits  Servers  Planning 
Abstract: We present Move Base Flex (MBF), a highly flexible, modular, map-independent, open-source navigation framework for use in ROS. MBF provides modular actions for executing plugins for path planning, motion control, and recovery. These actions define interfaces for external executives to allow highly flexible navigation strategies, which can be intertwined with other robot tasks. MBF has been successfully deployed in a professional setting at customer facilities to control robots in highly dynamic environments. We compare MBF with the well-known move_base and present the architecture as well as different deployment approaches, including how MBF can be used with different executives to perform complex navigation tasks interleaved with other robot operations.


Title: Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
Key Words: collision avoidance  emergency management  mobile robots  motion control  multi-robot systems  trajectory control  safe navigation  safe motion controls  emergency trajectory candidates  just-in-time emergency trajectories  autonomous navigation  vehicle operation  safe system state  MHTP  moving horizon trajectory planner  safety requirements  vehicle's local control system  differential-drive mobile agent  nonstatic environment  robot  Trajectory  Safety  Navigation  Robots  Vehicle dynamics  Planning  Collision avoidance 
Abstract: Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.


Title: PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
Key Words: feature extraction  mobile robots  optical radar  path planning  local views  sliding window fashion  matching current  old features  map representation  local maps  off-road environments  single localization failure  distinctive features  coined PoseMap  dynamic environments  robotic systems  long-term localization  multienvironment 3D LiDAR localization  frequency 8.0 Hz  time 18.0 month  Simultaneous localization and mapping  Three-dimensional displays  Laser radar  Optimization  Feature extraction 
Abstract: Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.


Title: Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction
Key Words: collision avoidance  human computer interaction  mobile robots  navigation  pedestrians  road vehicles  vehicles  personal mobility vehicle autonomous navigation  pedestrian flow  data driven approach  parameter extraction  safe navigation  moving obstacles  public pedestrian paths  robotic PMV  human-driven smooth navigation  PMV-Human interaction  Navigation  Legged locomotion  Trajectory  Three-dimensional displays  Wheelchairs  Bicycles 
Abstract: In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.


Title: Identifying Driver Behaviors Using Trajectory Features for Vehicle Navigation
Key Words: automobiles  behavioural sciences computing  driver information systems  feature extraction  Internet  mobile robots  vehicle trajectories  autonomous vehicles  car trajectories  data-driven mapping  vehicle navigation simulation system  driver behavior identification  Web-based user study  Trajectory  Navigation  Automobiles  Feature extraction  Measurement  Acceleration 
Abstract: We present a novel approach to automatically identify driver behaviors from vehicle trajectories and use them for safe navigation of autonomous vehicles. We propose a novel set of features that can be easily extracted from car trajectories. We derive a data-driven mapping between these features and six driver behaviors using an elaborate web-based user study. We also compute a summarized score indicating a level of awareness that is needed while driving next to other vehicles. We also incorporate our algorithm into a vehicle navigation simulation system and demonstrate its benefits in terms of safer realtime navigation, while driving next to aggressive or dangerous drivers.


Title: Autonomous Acquisition of Behavior Trees for Robot Control
Key Words: computer games  feedback  intelligent robots  learning (artificial intelligence)  mobile robots  optimisation  trees (mathematics)  robot control  learned control policy  RL control policies  optimal behavior permutation  intelligent agents  autonomous acquisition  computer game industry  intelligent robots  reinforcement learning  decanonicalization algorithm  canonical behavior tree  combinatorial search  Task analysis  Computer architecture  Reinforcement learning  Robot control  Games  Industries 
Abstract: Behavior trees (BT) are a popular control architecture in the computer game industry, and have been more recently applied in robotics. One open question is how can intelligent agents/robots autonomously acquire their behavior trees for task level control? In contrast with existing approaches that either refine an initially given BT, or directly build the BT based on human feedback/demonstration, we leverage reinforcement learning (RL) that allows robots to autonomously learn control policies by repeated task interaction, but often expressed in a language more difficult to interpret than BTs. The learned control policy is then converted to a behavior tree via our proposed decanonicalization algorithm. The feasibility of this idea is based on a proposed notion of canonical behavior trees (CBT). In particular, we show (1) CBTs are sufficiently expressive to capture RL control policies, and (2) that RL can be independent of an optimal behavior permutation, despite the BT convention of left-to-right priority, thus obviating the need for a combinatorial search. Two evaluation domains help illustrate our approach.


Title: Learning-Based Modular Task-Oriented Grasp Stability Assessment
Key Words: learning (artificial intelligence)  manipulators  stability  tactile sensors  modular task-oriented stability assessment  stability prediction  relevant modular tasks  unnecessary grasp adaptations  manipulation actions  trained model  individual stability demands  specific task  underlying model  learning-based approach  object uncertainties  sensory data  robotic manipulation tasks  modular task-oriented grasp stability assessment  manipulation task  unnecessary grasp force adaptations  Task analysis  Stability analysis  Force  Tactile sensors  Feature extraction  Friction  Adaptation models 
Abstract: Assessing grasp stability is essential to prevent the failure of robotic manipulation tasks due to sensory data and object uncertainties. Learning-based approaches are widely deployed to infer the success of a grasp. Typically, the underlying model used to estimate the grasp stability is trained for a specific task, such as lifting, hand-over, or pouring. Since every task has individual stability demands, it is important to adapt the trained model to new manipulation actions. If the same trained model is directly applied to a new task, unnecessary grasp adaptations might be triggered, or in the worst case, the manipulation might fail. To address this issue, we divide the manipulation task used for training into seven sub-tasks, defined as modular tasks. We deploy a learning-based approach and assess the stability for each modular task separately. We further propose analytical features to reduce the dimensionality and the redundancy of the tactile sensor readings. A main task can thereby be represented as a sequence of relevant modular tasks. The stability prediction of the main task is computed based on the inferred success labels of the modular tasks. Our experimental evaluation shows that the proposed feature set lowers the prediction error up to 5.69% compared to other sets used in state-of-the-art methods. Robotic experiments demonstrate that our modular task-oriented stability assessment avoids unnecessary grasp force adaptations and regrasps for various manipulation tasks.


Title: Interactive Robotic Manipulation of Elastic Objects
Key Words: collision avoidance  elastic deformation  finite element analysis  force control  manipulators  robot kinematics  sensitivity analysis  simulation  interactive simulation-based control methodology  interactive robotic manipulation  finite element method  sensitivity analysis  mathematical model  robots configuration  collision avoidance  elastic deformation objects  quasistatic assumption  Robots  Computational modeling  Shape  Collision avoidance  Mathematical model  Strain  Finite element analysis 
Abstract: In this paper, we address the challenge of robotic manipulation of elastically deforming objects. To this end, we model elastic objects using the Finite Element Method. Through a quasi-static assumption, we leverage sensitivity analysis to mathematically model how changes in the robot's configuration affect the deformed shape of the object being manipulated. This enables an interactive, simulation-based control methodology, wherein user-specified deformations for the elastic objects are automatically mapped to joint angle commands. The optimization formulation we introduce is general, operates directly within a robot's workspace and can readily incorporate joint limits as well as collision avoidance between the links. We validate our control methodology on a YuMi® IRB 14000, which we use to manipulate a variety of elastic objects.


Title: Domain Randomization and Generative Models for Robotic Grasping
Key Words: grippers  learning (artificial intelligence)  neural nets  planning (artificial intelligence)  probability  domain randomization  generative models  deep learning-based robotic grasping  significant progress thanks  algorithmic improvements  increased data availability  state-of-the-art models  unique object instances  result generalization  novel data generation pipeline  deep neural network  successful grasps  autoregressive grasp planning model  probability distribution  possible grasps  sample grasps  test time  model architecture  unseen realistic objects  random objects  real-world grasp  random simulated objects  Grasping  Training  Data models  Computational modeling  Robot sensing systems  Neural networks 
Abstract: Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.


Title: Intrinsically Motivated Self-Supervised Deep Sensorimotor Learning for Grasping
Key Words: closed loop systems  learning (artificial intelligence)  manipulators  neural nets  high-dimensional state spaces  object recognition  video games  machine translation  deep neural networks  training datasets  deep learning  robot systems  closed-loop control states  motivated self-supervised deep sensorimotor learning  intrinsic motivators  Robot sensing systems  Entropy  Training  Uncertainty  Deep learning  Biological neural networks 
Abstract: Deep learning has been successful in a variety of applications that have high-dimensional state spaces such as object recognition, video games, and machine translation. Deep neural networks can automatically learn important features from high-dimensional state given large training datasets. However, the success of deep learning in robot systems in the realworld is limited due to the cost of obtaining these large datasets. To overcome this problem, we propose an information-theoretic, intrinsically motivated, self-labeling mechanism using closed-loop control states. Taking this approach biases exploration to informative interactions-as such, a robot requires much less training to achieve reliable performance. In this paper, we explore the impact such an approach has on learning how to grasp objects. We evaluate different intrinsic motivators present in the literature applied appropriately in our framework and discuss the benefits and drawbacks of each.


Title: Manipulation Planning Under Changing External Forces
Key Words: grippers  path planning  position control  stability  bimanual regrasp planning  bimanual robot  external forces  manipulation planning algorithm  forceful operations  subsequent grasps  single gripper  stability  Planning  Grippers  Manifolds  Manipulators  Task analysis  Robot kinematics 
Abstract: We present a manipulation planning algorithm for a robot to keep an object stable under changing external forces. We particularly focus on the case where a human may be applying forceful operations, e.g. cutting or drilling, on an object that the robot is holding. The planner produces an efficient plan by intelligently deciding when the robot should change its grasp on the object as the human applies the forces. The planner also tries to choose subsequent grasps such that they will minimize the number of regrasps that will be required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the problem of bimanual regrasp planning, where the object is not placed on a support surface, but instead it is held by a single gripper until the second gripper moves to a new position on the object. This requires the planner to also reason about the stability of the object under gravity. We provide an implementation on a bimanual robot and present experiments to show the performance of our planner.


Title: Jacquard: A Large Scale Dataset for Robotic Grasp Detection
Key Words: belief networks  CAD  computer vision  grippers  image classification  image representation  learning (artificial intelligence)  object recognition  robot vision  solid modelling  robotic grasp detection  grasping skill  real-life applications  state-of-the-art robotic  deep neural networks  robotics  scale synthetic dataset  ground truth  Jacquard grasping dataset  CAD models dataset  successful grasping positions  grasp attempts  grasping robot trials  generalization skills  Jacquard dataset  grasping position detections  human labeled dataset  CNN  RGB-D images  ShapeNet  Solid modeling  Grippers  Robot kinematics  Grasping  Data models  Neural networks 
Abstract: Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset.


Title: Planning Hand-Arm Grasping Motions with Human-Like Appearance
Key Words: humanoid robots  manipulator kinematics  motion control  path planning  planning hand-arm grasping motions  hand-arm robotic systems  grasping actions  coordinated movements  robotic arm  anthropomorphic mechanical hand  human movements  human hand synergies  planning phase  motion planning  state-of-the-art planning algorithm  human-like appearance  search space  sampling-based planner  Planning  Grasping  Robot kinematics  Trajectory  Complexity theory  Manipulators 
Abstract: This paper addresses the problem of obtaining human-like motions on hand-arm robotic systems performing grasping actions. The focus is set on the coordinated movements of the robotic arm and the anthropomorphic mechanical hand, with which the arm is equipped. For this, human movements performing different grasps are captured and mapped to the robot in order to compute the human hand synergies. These synergies are used to both obtain human-like movements and to reduce the complexity of the planning phase by reducing the dimension of the search space. In addition, the paper proposes a sampling-based planner, which guides the motion planning following the synergies and considering different types of grasps. The introduced approach is tested in an application example and thoroughly compared with a state-of-the-art planning algorithm, obtaining better results.


Title: Robust Exploration with Multiple Hypothesis Data Association
Key Words: image fusion  mobile robots  robot vision  SLAM (robots)  target tracking  tree searching  joint compatibility branch  simultaneous localization and mapping  map accuracy  diverse hypotheses  multiple hypothesis tracking  robust back-ends  catastrophic failure  single false positive assignment  rich features  autonomous exploration  SLAM  ambiguous data association problem  multiple hypothesis data association  robust exploration  Simultaneous localization and mapping  Trajectory  Noise measurement  State estimation  Optimization  Measurement uncertainty 
Abstract: We study the ambiguous data association problem confronting simultaneous localization and mapping (SLAM), specifically for the autonomous exploration of environments lacking rich features. In such environments, a single false positive assignment might lead to catastrophic failure, which even robust back-ends may be unable to resolve. Inspired by multiple hypothesis tracking, we present a novel approach to effectively manage multiple hypotheses (MH) of data association inherited from traditional joint compatibility branch and bound (JCBB), which entails the generation, ordering and elimination of hypotheses. We analyze the performance of MHJCBB in two particular situations, one applying it to SLAM over a predefined trajectory and the other showing its applicability in exploring unknown environments. Statistical results demonstrate that MHJCBB's maintenance of diverse hypotheses under ambiguous conditions significantly improves map accuracy.


Title: Reactive Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps
Key Words: cameras  collision avoidance  Gaussian processes  geometry  helicopters  mobile robots  probability  trajectory control  collision avoidance  discrete map  GMM local mapping algorithm  gaussian mixture model maps  robots  CPU  quadrotor navigation  depth camera processing  time-parameterized trajectory  geometric properties  probabilistic approach  cluttered environments  Trajectory  Collision avoidance  Robot sensing systems  Real-time systems  Current measurement  Gaussian mixture model 
Abstract: In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.


Title: Integrating Human-Provided Information into Belief State Representation Using Dynamic Factorization
Key Words: mobile robots  path planning  probability  3D continuous cooking task  2D discrete gridworld task  open-domain planning problems  complex partially observed tasks  efficient planning  static factoring  possible objects  open domains  appropriate factoring  efficient belief state representation  raw sensory information  internal knowledge  sensory observations  probabilistic relational constraints  declarative information  partially observed environments  dynamic factorization  Planning  Robot sensing systems  Task analysis  Markov processes  Intelligent robots  Probabilistic logic 
Abstract: In partially observed environments, it can be useful for a human to provide the robot with declarative information that represents probabilistic relational constraints on properties of objects in the world, augmenting the robot's sensory observations. For instance, a robot tasked with a search-and-rescue mission may be informed by the human that two victims are probably in the same room. An important question arises: how should we represent the robot's internal knowledge so that this information is correctly processed and combined with raw sensory information? In this paper, we provide an efficient belief state representation that dynamically selects an appropriate factoring, combining aspects of the belief when they are correlated through information and separating them when they are not. This strategy works in open domains, in which the set of possible objects is not known in advance, and provides significant improvements in inference time over a static factoring, leading to more efficient planning for complex partially observed tasks. We validate our approach experimentally in two open-domain planning problems: a 2D discrete gridworld task and a 3D continuous cooking task. A supplementary video can be found at http://tinyurl.com/chitnis-iros-18.


Title: Simultaneous Task Allocation and Planning Under Uncertainty
Key Words: control engineering computing  formal verification  iterative methods  Markov processes  mobile robots  multi-robot systems  operating systems (computers)  path planning  resource allocation  robot programming  temporal logic  simultaneous task allocation  uncertain environments  individual robot behaviour  linear temporal logic  multirobot policies  simultaneous task planning  Markov decision processes  formal verification  multirobot operating systems  Task analysis  Planning  Robot kinematics  Resource management  Uncertainty  Probabilistic logic 
Abstract: We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.


Title: Strategic-Tactical Planning for Autonomous Underwater Vehicles over Long Horizons
Key Words: autonomous underwater vehicles  control engineering computing  mobile robots  planning (artificial intelligence)  robot dynamics  vehicle dynamics  strategic-tactical planning  autonomous underwater vehicles  long horizons  persistent autonomy  AI Planners  long-term autonomous behaviour  abstraction planning techniques  two-level hierarchical structure  hierarchical decompositions  Task analysis  Planning  Manifolds  Batteries  Inspection  Robots  Valves 
Abstract: In challenging environments where human intervention is expensive, robust and persistent autonomy is a key requirement. AI Planners can efficiently construct plans to achieve this long-term autonomous behaviour. However, in plans which are expected to last over days, or even weeks, the size of the state-space becomes too large for current planners to solve as a single problem. These problems are well-suited to decomposition and abstraction planning techniques. We present a novel approach in the context of persistent autonomy in autonomous underwater vehicles, in which tasks are complex and diverse and plans cannot be precomputed. Our approach performs a decomposition into a two-level hierarchical structure, which dynamically constructs planning problems at the upper level of the hierarchy using solution plans from the lower level. Solution plans are then executed and monitored simultaneously at both levels. We evaluate the approach, showing that compared to strictly top-down hierarchical decompositions, our approach leads to more robust solution plans of higher quality.


Title: Grid-Based Motion Planning Using Advanced Motions for Hexapod Robots
Key Words: graph theory  legged locomotion  motion control  path planning  grid-based motion planning  advanced motions  hexapod robots  motion planning framework  chimney walking  robot motion  hierarchical planning framework  custom-designed Corin hexapod  environment surfaces  Legged locomotion  Planning  Trajectory  Collision avoidance  Robot motion 
Abstract: This paper presents the motion planning framework for a hexapod, based on advanced motions, for accessing challenging spaces, namely narrow pathways and large holes, both of which are surrounded by walls. The advanced motions, wall and chimney walking, utilise environment surfaces that are perpendicular to the ground plane to support the robot motion. Such techniques have not yet been studied in the literature. The hierarchical planning framework proposed here is an extension to existing approaches which have only considered ground walking where foothold contacts are confined to the ground plane. During the pre-processing phase of the 2.5D grid map, the motion primitives employed are assessed for each cell and stacked to the graph if valid. The A* algorithm is then used to find a path to the goal position. Following that, the path is post-processed to smoothen the motions and generate a continuous path. Footholds are then selected along the path. The framework has been evaluated in simulation on the custom-designed Corin hexapod. The resulting path enables access to areas that are previously thought to be inaccessible and reduces the travelling distance compared to previous studies.


Title: Learning from Demonstration for Hydraulic Manipulators
Key Words: control system synthesis  end effectors  force control  force sensors  friction  hydraulic systems  learning (artificial intelligence)  manipulator dynamics  manipulators  motion control  position control  stability  telerobotics  fragile force-torque sensor  heavy-duty hydraulic manipulators  teleoperated human demonstrations  novel VDC-based impedance control method  sliding motion  learning method  manipulator actuators  contact force  hydraulic slave manipulator  slave manipulators  teleoperation system  stability-guaranteed controller  virtual decomposition control  advanced subsystem-dynamic-based control design framework  human demonstration  reasonable method  force-reflected bilateral teleoperation  extremely powerful hydraulic manipulator  teleoperated demonstration  in-contact tasks  Hydraulic systems  Force  Task analysis  Manipulator dynamics  Impedance  Control design 
Abstract: This paper presents, for the first time, a method for learning in-contact tasks from a teleoperated demonstration with a hydraulic manipulator. Due to the use of extremely powerful hydraulic manipulator, a force-reflected bilateral teleoperation is the most reasonable method of giving a human demonstration. An advanced subsystem-dynamic-based control design framework, virtual decomposition control (VDC), is used to design a stability-guaranteed controller for the teleoperation system, while taking into account the full nonlinear dynamics of the master and slave manipulators. The use of fragile force/torque sensor at the tip of the hydraulic slave manipulator is avoided by estimating the contact forces from the manipulator actuators' chamber pressures. In the proposed learning method, it is observed that a surface-sliding tool has a friction-dependent range of directions (between the actual direction of motion and the contact force) from which the manipulator can apply force to produce the sliding motion. By this intuition, an intersection of these ranges can be taken over a motion to robustly find a desired direction for the motion from one or more demonstrations. The compliant axes required to reproduce the motion can be found by assuming that all motions outside the desired direction is caused by the environment, signalling the need for compliance. Finally, the learning method is incorporated to a novel VDC-based impedance control method to learn compliant behaviour from teleoperated human demonstrations. Experiments with 2-DOF hydraulic manipulator with a 475kg payload demonstrate the suitability and effectiveness of the proposed method to perform learning from demonstration (LfD) with heavy-duty hydraulic manipulators.


Title: Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment
Key Words: backpropagation  collision avoidance  error compensation  fusion reactor design  fusion reactor instrumentation  high energy physics instrumentation computing  manipulator kinematics  neural nets  physical instrumentation control  plasma toroidal confinement  Tokamak devices  nuclear fusion environment  Experimental Advanced Superconducting Tokamak  noncircular cross-section  real-time detection  plasma discharges  EAMA system design  vacuum-available design scheme  error prediction  EAST articulated maintenance arm  repair operations  internal components  high temperature environments  flexible robot arms  error compensation  flexible multijoint manipulator  EAST ultrahigh vacuum condition  inverse kinematics  obstacle avoidance strategy  back-propagation neural network  integrated control strategy  temperature 80.0 degC to 120.0 degC  Manipulators  Kinematics  Predictive models  Load modeling  Error compensation  Strain 
Abstract: Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10-5Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.


Title: Progress and Prospects of EAST Remote Maintenance System
Key Words: automatic optical inspection  edge detection  fusion reactor instrumentation  grippers  inspection  maintenance engineering  nuclear power stations  object detection  plasma toroidal confinement  power system control  robot vision  service robots  Tokamak devices  light maintenance capability  tokamak condition  EAST remote maintenance system  grasping tasks  EAMA robot  EAST articulated maintenance arm  EAMA control system  EAST tokamak  CIVIS  CFETR in-vessel inspection system  Maintenance engineering  Inspection  Solid modeling  Manipulators  Robot sensing systems 
Abstract: Fast inspection and light maintenance capability is already a clear demand to control the tokamak condition and improve the efficiency of the experimental campaigns. EAST remote maintenance system has been developed to implement inspection and grasping tasks during plasma. The paper presents design description of EAMA (EAST articulated maintenance arm) robot, the gripper and the CASK. The field commissioning was performed both in mockup and EAST tokamak to demonstrate the availability and functionalities of EAMA system. To be able to realize fully routine operation on EAST, improvement of EAMA control system was proposed with integration developed algorithm, such as the robot flexible model modeling, vision servo, motion planning, etc. Finally, thoughts for CFETR In-Vessel Inspection System (CIVIS) are given.


Title: Pose Estimation for Mobile Robots to Maximise Data Quality of Fixed-Focus Laser Diagnostics in Hazardous Environments
Key Words: collision avoidance  laser beam effects  mobile robots  pose estimation  sensor placement  service robots  spectroscopy  pose estimation  mobile robots  data quality  fixed-focus laser diagnostic  hazardous environments  nuclear environments  decommissioning  LIBS  scientific instrument  optical emission  arbitrary diagnostic mounting  obstacle avoidance  diagnostic mounting  sensor placement  high intensity pulsed laser  laser induced breakdown spectroscopy  Robot kinematics  Robot sensing systems  Data integrity  Lasers  Instruments  Plasmas 
Abstract: Characterisation of nuclear environments is critical for long term operation and decommissioning. Laser Induced Breakdown Spectroscopy (LIBS) is an example of a scientific instrument that could be deployed to aid in characterisation of unknown environments. LIBS consists of a high intensity pulsed laser being focussed down onto a target to create a plasma, and optical emission from the plasma is then used to determine elemental composition of unknown materials. For robots deployed with these instruments in extreme environments, mission time can be limited by hazards present such as radiation. Once deployed a robot must be able to collect the best data possible whilst maximising operational runtime. We present a data quality based probabilistic approach to robot pose estimation to maximise data quality, by considering optimum sensor placement whilst avoiding harmful environmental features such as radiation for a fixed-focus laser diagnostic such as LIBS. This approach is able to determine optimum robot poses for arbitrary targets in 3D for arbitrary diagnostic mounting with respect to the robot. The approach is able to avoid obstacles and avoid occlusion of the target by said obstacles. This can be used as part of autonomous investigation and characterisation performed by mobile robots in hazardous environments.


Title: A Variational Feature Encoding Method of 3D Object for Probabilistic Semantic SLAM
Key Words: Bayes methods  belief networks  feature extraction  maximum likelihood estimation  object recognition  probability  robot vision  SLAM (robots)  object recognition methods  true generative model  semantic simultaneous localization and mapping  maximum likelihood estimation  shape retrieval  Bayesian inference  Bayesian networks  approximated distributions  variational auto-encoder  complex distributions  observation likelihood  tractable distributions  3D object shapes  view-independent loop closure  object shape  range sensor  mobile robot  complex probability distribution  probabilistic observation model  high-level semantic features  complex 3D objects  probabilistic semantic SLAM  variational feature encoding method  Shape  Simultaneous localization and mapping  Three-dimensional displays  Semantics  Solid modeling  Bayes methods  Probabilistic logic 
Abstract: This paper presents a feature encoding method of complex 3D objects for high-level semantic features. Recent approaches to object recognition methods become important for semantic simultaneous localization and mapping (SLAM). However, there is a lack of consideration of the probabilistic observation model for 3D objects, as the shape of a 3D object basically follows a complex probability distribution. Furthermore, since the mobile robot equipped with a range sensor observes only a single view, much information of the object shape is discarded. These limitations are the major obstacles to semantic SLAM and view-independent loop closure using 3D object shapes as features. In order to enable the numerical analysis for the Bayesian inference, we approximate the true observation model of 3D objects to tractable distributions. Since the observation likelihood can be obtained from the generative model, we formulate the true generative model for 3D object with the Bayesian networks. To capture these complex distributions, we apply a variational auto-encoder. To analyze the approximated distributions and encoded features, we perform classification with maximum likelihood estimation and shape retrieval.


Title: End to End Vehicle Lateral Control Using a Single Fisheye Camera
Key Words: automobiles  cameras  collision avoidance  convolutional neural nets  mobile robots  robot vision  steering systems  label augmentation  short range fisheye camera  open road driving  single fisheye camera  convolutional neural networks  steering angle  autonomous cars  end-to-end control evaluation  end-to-end vehicle lateral control  urban road  sharp turns  obstacle avoidance  data augmentation  Automobiles  Cameras  Roads  Training  Neural networks  Testing 
Abstract: Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.


Title: A Novel OCR-RCNN for Elevator Button Recognition
Key Words: learning (artificial intelligence)  neurocontrollers  optical character recognition  path planning  recurrent neural nets  robot vision  service robots  autonomous elevator operation  inter-floor navigation problem  elevator button recognition  severe class imbalance problem  optical character recognition network  Faster RCNN architecture  elevator panels  OCR-RCNN architecture  service robots  image conditions  Elevators  Optical character recognition software  Proposals  Task analysis  Feature extraction  Training  Pipelines 
Abstract: Autonomous elevator operation is considered an intelligent solution in handling the inter-floor navigation problem of service robots. As one of the most fundamental steps, elevator button recognition starts to receive more and more attention. However, due to the challenging image conditions and severe class imbalance problem, the performance of existing results is unsatisfying. In this paper, we propose to combine an optical character recognition (OCR) network and the Faster RCNN architecture into a single neural network, called OCR-RCNN to facilitate an end-to-end training and elevator button recognition procedure. To verify our method, we collect a large dataset of elevator panels and carry out extensive comparative experiments. The experiment results show that our method can greatly outperform the traditional recognition pipelines, yielding an accurate and robust performance on recognizing untrained elevator buttons.


Title: Cost Functions for Robot Motion Style
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  neurocontrollers  task constraints  nominal task cost  task types  task instances  robot motion style  nuanced costs  featurized costs  nominal motion  cost type  raw trajectory input  neural network parameterization operating  hand-designed features  weighted linear combination  cost functions  trajectory optimization process  Task analysis  Robots  Cost function  Neural networks  Trajectory optimization 
Abstract: We focus on autonomously generating robot motion for day to day physical tasks that is expressive of a certain style or emotion. Because we seek generalization across task instances and task types, we propose to capture style via cost functions that the robot can use to augment its nominal task cost and task constraints in a trajectory optimization process. We compare two approaches to representing such cost functions: a weighted linear combination of hand-designed features, and a neural network parameterization operating on raw trajectory input. For each cost type, we learn weights for each style from user feedback. We contrast these approaches to a nominal motion across different tasks and for different styles in a user study, and find that they both perform on par with each other, and significantly outperform the baseline. Each approach has its advantages: featurized costs require learning fewer parameters and can perform better on some styles, but neural network representations do not require expert knowledge to design features and could even learn more complex, nuanced costs than an expert can easily design.


Title: Imitation Learning for Object Manipulation Based on Position/Force Information Using Bilateral Control
Key Words: control engineering computing  force control  learning (artificial intelligence)  manipulators  neural nets  position control  bilateral control  imitation learning method  position information  precise object manipulation  neural networks  robots  position-force information  Force  Torque  Predictive models  Manipulators  Angular velocity  Control systems 
Abstract: This study proposes an imitation learning method based on force and position information. Force information is required for precise object manipulation but is difficult to obtain because the acting and reaction forces cannot be separated. To separate the forces, we proposed to introduce bilateral control, in which the acting and reaction forces are divided using two robots. In the proposed method, two models of neural networks learn a task; to draw a line along a ruler. We verify the possibility that force information is essential to imitate the human skill of object manipulation.


Title: Learning Implicit Sampling Distributions for Motion Planning
Key Words: learning (artificial intelligence)  manipulators  mobile robots  path planning  sampling methods  search problems  implicit sampling distributions  motion planning  sampling-based motion planners  state space  sampling distribution  hand selected heuristics  policy-search based method  sampling-based planners  7DOF robot arm  Planning  Task analysis  Probability distribution  Manipulators  Space exploration  Collision avoidance 
Abstract: Sampling-based motion planners have experienced much success due to their ability to efficiently and evenly explore the state space. However, for many tasks, it may be more efficient to not uniformly explore the state space, especially when there is prior information about its structure. Previous methods have attempted to modify the sampling distribution using hand selected heuristics that can work well for specific environments but not universally. In this paper, a policy-search based method is presented as an adaptive way to learn implicit sampling distributions for different environments. It utilizes information from past searches in similar environments to generate better distributions in novel environments, thus reducing overall computational cost. Our method can be incorporated with a variety of sampling-based planners to improve performance. Our approach is validated on a number of tasks, including a 7DOF robot arm, showing marked improvement in number of collision checks as well as number of nodes expanded compared with baseline methods.


Title: Online Temporal Calibration for Monocular Visual-Inertial Systems
Key Words: calibration  cameras  inertial systems  motion estimation  optimisation  robot vision  sensor fusion  SLAM (robots)  monocular visual-inertial systems  accurate state estimation  intelligent applications  robot navigation  autonomous driving  virtual reality  augmented reality  visual fusion  inertial fusion  sensor fusion  visual measurements  inertial measurements  IMU states  SLAM system  feature-based optimization frameworks  Cameras  Sensors  Delays  Calibration  Visualization  Clocks  Three-dimensional displays 
Abstract: Accurate state estimation is a fundamental module for various intelligent applications, such as robot navigation, autonomous driving, virtual and augmented reality. Visual and inertial fusion is a popular technology for 6-DOF state estimation in recent years. Time instants at which different sensors' measurements are recorded are of crucial importance to the system's robustness and accuracy. In practice, timestamps of each sensor typically suffer from triggering and transmission delays, leading to temporal misalignment (time offsets) among different sensors. Such temporal offset dramatically influences the performance of sensor fusion. To this end, we propose an online approach for calibrating temporal offset between visual and inertial measurements. Our approach achieves temporal offset calibration by jointly optimizing time offset, camera and IMU states, as well as feature locations in a SLAM system. Furthermore, the approach is a general model, which can be easily employed in several feature-based optimization frameworks. Simulation and experimental results demonstrate the high accuracy of our calibration approach even compared with other state-of-art offline tools. The VIO comparison against other methods proves that the online temporal calibration significantly benefits visual-inertial systems. The source code of temporal calibration is integrated into our public project, VINS-Mono1.


Title: Modular Sensor Fusion for Semantic Segmentation
Key Words: image segmentation  learning (artificial intelligence)  sensor fusion  statistical analysis  training sets  single modality segmentation results  statistical models  competitive performance  statistical fusion approaches  aligned multisensor training data  specific architecture  semantic segmentation approaches  current multisensor deep learning  real-world operations  perceptual range  robotic systems  fundamental process  modular sensor fusion  Semantics  Image segmentation  Robot sensing systems  Training  Fuses  Computer architecture 
Abstract: Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.


Title: Robust Sensor Fusion with Self-Tuning Mixture Models
Key Words: adaptive control  control system synthesis  expectation-maximisation algorithm  Gaussian processes  least squares approximations  mixture models  nonlinear control systems  optimisation  robots  robust control  self-adjusting systems  sensor fusion  state estimation  robust sensor fusion  self-tuning mixture models  nonlinear state estimation  robotics  robust cost functions  nonGaussian error models  environmental changes  ageing  error distribution  state estimation process  Gaussian mixture  sensor model  standard state estimation  implicit expectation-maximization approach  distribution parameters  self-tuning algorithm  least-squares optimization framework  parameter tuning  Estimation  Robot sensing systems  Optimization  Tuning  Biological system modeling  Heuristic algorithms  Standards 
Abstract: A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.


Title: Trifo-VIO: Robust and Efficient Stereo Visual Inertial Odometry Using Points and Lines
Key Words: computer graphics  distance measurement  filtering theory  graph theory  image matching  Kalman filters  mobile robots  nonlinear filters  pose estimation  robot vision  SLAM (robots)  stereo image processing  efficient stereo Visual Inertial Odometry  stereo VIO system  line features  system robustness  point features  low-texture environment  lightweight filtering-based loop closing technique  global bundle adjustment  graph optimization  current sliding window  Trifo Ironsides dataset  visual-inertial dataset  high-quality synchronized stereo camera  Cameras  Optimization  Visualization  Feature extraction  Image edge detection  Three-dimensional displays  Robot sensing systems 
Abstract: In this paper, we present the Trifo Visual Inertial Odometry (Trifo-VIO), a tightly-coupled filtering-based stereo VIO system using both points and lines. Line features help improve system robustness in challenging scenarios when point features cannot be reliably detected or tracked, e.g. low-texture environment or lighting change. In addition, we propose a novel lightweight filtering-based loop closing technique to reduce accumulated drift without global bundle adjustment or pose graph optimization. We formulate loop closure as EKF updates to optimally relocate the current sliding window maintained by the filter to past keyframes. We also present the Trifo Ironsides dataset, a new visual-inertial dataset, featuring high-quality synchronized stereo camera and IMU data from the Ironsides sensor [3] with various motion types and textures and millimeter-accuracy groundtruth. To validate the performance of the proposed system, we conduct extensive comparison with state-of-the-art approaches (OKVIS, VINS-MONO and S-MSCKF) using both the public EuRoC dataset and the Trifo Ironsides dataset.


Title: Scale Correct Monocular Visual Odometry Using a LiDAR Altimeter
Key Words: distance measurement  image sequences  mobile robots  optical radar  robot vision  SLAM (robots)  stereo image processing  stereo visual SLAM  monocular vision  inherent scale ambiguity  LiDAR altimeter  scale correct monocular visual odometry  RGB-D methods  scale drift  keyframe basis  scale constraint  mapping algorithm  keyframe based tracking  Visual Odometry method  laser altimeter  range data  exploration vehicles  power requirements  computational load  metrological accuracy  RGB-D sensors  3D LiDARs  metric references  sensory sources  Cameras  Laser radar  Measurement  Three-dimensional displays  Visual odometry  Visualization  Sensors 
Abstract: The inherent scale ambiguity in monocular vision is a well known issue that forces the integration of other sensory sources to obtain metric references. However, 2D or 3D LiDARs and RGB-D sensors, while guaranteeing metrological accuracy, impose a non negligible burden both in terms of computational load and power requirements limiting the feasibility of being implemented on small exploration vehicles. This paper presents a scale aware monocular Visual Odometry framework that fuses range data from a laser altimeter in order to recover and maintain a correct metric scale. The proposed Visual Odometry method consists of a keyframe based tracking and mapping algorithm using optical flow where range data serves as a scale constraint on a keyframe to keyframe basis. An optimization backend based on iSAM2 is employed in order to refine the trajectory and map estimates eliminating the scale drift without the need of performing loop closures. We demonstrate that our algorithm can obtain very similar performances to state of the art stereo visual SLAM and RGB-D methods.


Title: Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates
Key Words: convergence  mobile robots  multi-robot systems  composition strategy  mobile robots  multirobot systems  efficient solution  low-level tasks  high-level missions  single behavior  requisite expressiveness  provably correct composition  terminal configuration  valid initial configuration  nominal control inputs  control barrier certificates  finite-time convergence control barrier functions  information-exchange network  Convergence  Robot kinematics  Task analysis  Multi-robot systems  Mobile robots  Robot sensing systems 
Abstract: In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.


Title: Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization
Key Words: learning (artificial intelligence)  mobile robots  multi-robot systems  oceanographic equipment  optimisation  underwater equipment  unsupervised learning  distributed spatiotemporal topic models  real seabed imagery  multirobot underwater terrain characterization  local robot topic distributions  local topic model  multirobot distributed learning  marine robots  multirobot teams  multiple robots  single-robot topic models  learned models  unsupervised models  raw data  latent structure  Bayesian topic models  unsupervised learning techniques  multirobot terrain characterization  Adaptation models  Robot sensing systems  Spatiotemporal phenomena  Data models  Visualization  Mathematical model 
Abstract: Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.


Title: On the Use of Energy Tanks for Multi-Robot Interconnection
Key Words: mobile robots  multi-robot systems  robust control  energy tank  multirobot systems passive interconnections  robustly stable cooperative behavior  passivity constraint  novel generalized interconnection  passive systems  coupled system  Couplings  Damping  Robots  Multi-robot systems  Robust stability  Buildings  Nonlinear dynamical systems 
Abstract: In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.


Title: A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications
Key Words: database management systems  multi-robot systems  multirobot applications  robots  log files  querying features  scaling capabilities  modern databases  multirobot systems  robotic use cases  benchmarking scenarios  networked multirobot architectures  extensible workbench  benchmarking databases  Databases  Robot sensing systems  Benchmark testing  Containers  Systems architecture 
Abstract: Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.


Title: Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks
Key Words: mobile robots  multi-robot systems  self-assembly  robots measure  frame-work  infinitesimally shape-similar frameworks  shape-similarity matrix  differential-drive robots  formation control strategies  multirobot team  infinitesimal shape-similarity  Robot sensing systems  Transmission line matrix methods  Self-assembly  Shape  Trajectory  Multi-Robot Systems 
Abstract: Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.


Title: Optimal Redeployment of Multirobot Teams for Communication Maintenance
Key Words: approximation theory  computational complexity  human-robot interaction  integer programming  linear programming  mobile robots  multi-robot systems  optimal redeployment  multirobot teams  communication maintenance  mobile robots  communication relays  computational complexity  Integer Linear Programming formulation  approximation hardness  Maintenance engineering  Relays  Task analysis  Complexity theory  Linear programming  Mobile robots 
Abstract: In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.


Title: Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
Key Words: aerospace robotics  dynamic programming  integer programming  linear programming  mobile robots  multi-robot systems  path planning  visibility-based monitoring  heterogeneous robot team  terrain path  aerial robots  route planning  dynamic programming approach  integer linear programming solution  ground robots  Unmanned aerial vehicles  Robot sensing systems  Educational robots  Monitoring  Dynamic programming  Integrated circuits 
Abstract: We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.


Title: Algorithms for Task Allocation in Homogeneous Swarm of Robots
Key Words: control system synthesis  decentralised control  feedback  Markov processes  mobile robots  multi-robot systems  task allocation  homogeneous swarm  homogeneous robots  Markov chain  agent converges  local-decentralized controllers  controller design  local-feedback  Task analysis  Markov processes  Robot kinematics  Kernel  Probabilistic logic  Q measurement 
Abstract: In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.


Title: Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform
Key Words: humanoid robots  legged locomotion  manipulators  robot dynamics  autonomous legged personal helper robot  enhanced dynamics  multimodal legged robotic platform  versatile 3D ZMP trajectory optimization algorithm  stable locomotion  multimodal robotic platform  2D zero moment point trajectory optimization  manipulation  light weight robotic system  Legged locomotion  Foot  Trajectory  Heuristic algorithms  Task analysis 
Abstract: This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.


Title: Hybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs
Key Words: distance measurement  graph theory  inertial navigation  legged locomotion  motion estimation  optimisation  sensor fusion  state estimation  factor graphs  robotic state estimation  sensor fusion framework  legged robots  visual encoder  inertial encoder  visual-inertial odometry  visual-inertial navigation systems  cassie-series robot  nonlinear optimization  motion capture system  preintegration theory  Kinematics  Legged locomotion  Optimization  Cameras  Robot vision systems 
Abstract: The factor graph framework is a convenient modeling technique for robotic state estimation where states are represented as nodes, and measurements are modeled as factors. When designing a sensor fusion framework for legged robots, one often has access to visual, inertial, joint encoder, and contact sensors. While visual-inertial odometry has been studied extensively in this framework, the addition of a preintegrated contact factor for legged robots has been only recently proposed. This allowed for integration of encoder and contact measurements into existing factor graphs, however, new nodes had to be added to the graph every time contact was made or broken. In this work, to cope with the problem of switching contact frames, we propose a hybrid contact preintegration theory that allows contact information to be integrated through an arbitrary number of contact switches. The proposed hybrid modeling approach reduces the number of required variables in the nonlinear optimization problem by only requiring new states to be added alongside camera or selected keyframes. This method is evaluated using real experimental data collected from a Cassie-series robot where the trajectory of the robot produced by a motion capture system is used as a proxy for ground truth. The evaluation shows that inclusion of the proposed preintegrated hybrid contact factor alongside visual-inertial navigation systems improves estimation accuracy as well as robustness to vision failure, while its generalization makes it more accessible for legged platforms.


Title: Stable, Autonomous, Unknown Terrain Locomotion for Quadrupeds Based on Visual Feedback and Mixed-Integer Convex Optimization
Key Words: convex programming  integer programming  legged locomotion  motion control  path planning  quadratic programming  robot vision  visual feedback  mixed-integer convex optimization  complete motion planning approach  quadruped locomotion  convex polygons  potentially feasible foothold regions  feasible destination planner  extracted polygons  footstep planner  mass trajectory planner  path planner  stable terrain locomotion  autonomous terrain locomotion  unknown terrain locomotion  quadrupeds  feasible goal position  ALPHRED  Optimization  Trajectory  Legged locomotion  Planning  Three-dimensional displays 
Abstract: This paper presents a complete motion planning approach for quadruped locomotion across an unknown terrain using a framework based on mixed-integer convex optimization and visual feedback. Vision data is used to find convex polygons in the surrounding environment, which acts as potentially feasible foothold regions. Then, a goal position is initially provided, which the best feasible destination planner uses to solve for an actual feasible goal position based on the extracted polygons. Next, a footstep planner uses the feasible goal position to plan a fixed number of footsteps, which may or may not result in the robot reaching the position. The center of mass (COM) trajectory planner using quadratic programming is extended to solve for a trajectory in 3D space while maintaining convexity, which reduces the computation time, allowing the robot to plan and execute motions online. The suggested method is implemented as a policy rather than a path planner, but its performance as a path planner is also shown. The approach is verified on both simulation and on a physical robot, ALPHRED, walking on various unknown terrains.


Title: Leg Design to Enable Dynamic Running and Climbing on BOBCAT
Key Words: legged locomotion  manipulator dynamics  robot kinematics  design tool  leg configuration  multimodal platform BOBCAT  leg design  design process  leg morphology  manipulator community  dynamic workspace  template dynamics  dynamic climbing  dynamic running  Legged locomotion  Dynamics  Couplings  Force  Kinematics  Foot 
Abstract: The design process for leg morphology has taken much of its inspiration from the manipulator community, including the concept of maximizing the workspace of a design. In this paper, we define the concept of Effective Dynamic Workspace, which examines the subset of the overall workspace capable of achieving the desired template dynamics. With this new design tool, the leg configuration of a new multi-modal platform BOBCAT is examined and refined. With the refined design, BOBCAT is able to achieve speeds of 2m/s while running and 0.17m/s while climbing a vertical wall.


Title: Learning Hardware Dynamics Model from Experiments for Locomotion Optimization
Key Words: control engineering computing  learning (artificial intelligence)  legged locomotion  motion control  optimisation  pendulums  robot dynamics  locomotion optimization  hardware compatibility  hardware-compatible motion plan  linear inverted pendulum  ZMP  hardware dynamics model learning  zero moment point  LIP  center of mass  quadruped  Hardware  Optimization  Dynamics  Legged locomotion  Data models  Solid modeling 
Abstract: The hardware compatibility of legged locomotion is often illustrated by Zero Moment Point (ZMP) that has been extensively studied for decades. One of the most popular models for computing the ZMP is the linear inverted pendulum (LIP) model that expresses ZMP as a linear function of the center of mass(COM) and its acceleration. In the real world, however, it may not accurately predict the true ZMP of hardware due to various reasons such as unmodeled dynamics and differences between simulation model and hardware. In this paper, we aim to improve the theoretical ZMP model by learning the real hardware dynamics from experimental data. We first optimize the motion plan using the theoretical ZMP model and collect COP data by executing the motion on a force plate. We then train a new ZMP model that maps the motion plan variable to the actual ZMP and use the learned model for finding a new hardware-compatible motion plan. Through various locomotion tasks of a quadruped, we demonstrate that motions planned for the learned ZMP model are compatible on hardware when those for the theoretical ZMP model are not. Furthermore, experiments using ZMP models with different complexities reveal that overly complex models may suffer from over-fitting even though they can potentially represent more complex, unmodeled dynamics.


Title: Iterative Learning of Energy-Efficient Dynamic Walking Gaits
Key Words: iterative methods  learning systems  legged locomotion  motion control  robot dynamics  energy-efficient dynamic walking gaits  dynamic walking robots  lifelike locomotion  efficient gaits  Iterative Learning Control  control signal  periodic reference  terminal ILC  dynamic walking robot gaits  final foot placement  energy efficiency  phase-indexed TILC  energy-efficient walking motion  time-indexed TILC  Legged locomotion  Computational modeling  Data models  Foot  Planning  Convergence 
Abstract: Dynamic walking robots have the potential for efficient and lifelike locomotion, but computing efficient gaits and tracking them is difficult in the presence of under-modeling. Iterative Learning Control (ILC) is a method to learn the control signal to track a periodic reference over several attempts, augmenting a model with online data. Terminal ILC (TILC), a variant of ILC, allows other performance objectives to be addressed at the cost of ignoring parts of the reference. However, dynamic walking robot gaits are not necessarily periodic in time. In this paper, we adapt TILC to jointly optimize final foot placement and energy efficiency on dynamic walking robots by indexing by a phase variable instead of time, yielding “phase-indexed TILC” (θ - TILC). When implemented on a five-link walker in simulation, θ- TILC learns a more energy-efficient walking motion compared to traditional time-indexed TILC.


Title: Bipedal Hopping: Reduced-Order Model Embedding via Optimization-Based Control
Key Words: control system synthesis  feedback  legged locomotion  Lyapunov methods  nonlinear control systems  quadratic programming  robot dynamics  robot kinematics  springs (mechanical)  stability  bipedal hopping  reduced-order model embedding  optimization-based control  spring-mass model  spring stiffness  damping  trajectory optimization  control Lyapunov function  CLF-QP  nonlinear feedback control law  dynamic jumping behaviors  bipedal robots  3D bipedal robot Cassie  quadratic program  Legged locomotion  Springs  Robot kinematics  Kinematics  Hip  Jacobian matrices 
Abstract: This paper presents the design and validation of controlling hopping on the 3D bipedal robot Cassie. A spring-mass model is identified from the kinematics and compliance of the robot. The spring stiffness and damping are encapsulated by the leg length, thus actuating the leg length can create and control hopping behaviors. Trajectory optimization via direct collocation is performed on the spring-mass model to plan jumping and landing motions. The leg length trajectories are utilized as desired outputs to synthesize a control Lyapunov function based quadratic program (CLF-QP). Centroidal angular momentum, taking as an addition output in the CLF-QP, is also stabilized in the jumping phase to prevent whole body rotation in the underactuated flight phase. The solution to the CLF-QP is a nonlinear feedback control law that achieves dynamic jumping behaviors on bipedal robots with compliance. The framework presented in this paper is verified experimentally on the bipedal robot Cassie.


Title: An Actuator Design Criterion to Maximize Physical Balance Recovery
Key Words: actuators  control system synthesis  gears  legged locomotion  mechanical stability  motion control  optimisation  pendulums  robot dynamics  wheels  legged robot  hip joint  balance recovery motion  actuator design  physical balance recovery  electric motor  gear reduction  wheel pendulum  robot design  Actuators  Torque  Robot kinematics  Friction  Electrical resistance measurement  Legged locomotion 
Abstract: This paper first presents a formula to predict the largest balance disturbance from which a legged robot can recover without taking a step. It then presents an actuator design criterion derived from this formula that maximizes the robot's ability to recover. In this study, it is assumed that the robot is using a single major joint (e.g, a hip joint) to perform its balance recovery movement, and that the actuator consists of an electric motor and reduction gear. It is also assumed that the robot's support polygon is sufficiently small that it can be approximated as a point, and that the balance recovery motion is essentially planar, so that a 2-D analysis remains valid in 3-D. Finally, it is assumed that, for the purpose of studying balance recovery motion, the robot can be approximated by a reaction wheel pendulum. The theory has been tested experimentally on a robot designed to be good at balancing, and was found to agree closely with experimental results.


Title: Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors
Key Words: biomedical optical imaging  blood vessels  brain  collision avoidance  Doppler measurement  image motion analysis  laser applications in medicine  medical image processing  medical robotics  needles  pose estimation  steering systems  surgery  percutaneous procedures  hemorrhage  vessel motion  tissue bulk motion  Doppler signals  multiple forward looking sensors  preoperative imaging modalities  vessel pose estimation  needle steering systems  robotic assisted needle insertion process  vessel detection  biologically inspired steerable needle  laser Doppler flowmetry  life threatening complications  percutaneous interventions  needle steering surgery  obstacle avoidance  Needles  Probes  Phantoms  Sensors  Doppler effect  Gold  Grey matter 
Abstract: During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.


Title: Trajectory Optimization of Robot-Assisted Endovascular Catheterization with Reinforcement Learning
Key Words: blood vessels  cardiovascular system  catheters  diagnostic radiography  learning (artificial intelligence)  manipulator dynamics  medical image processing  medical robotics  mobile robots  path planning  patient treatment  surgery  telerobotics  catheter manipulation  learning-based robotic catheterization platform  dynamic movement primitives  catheterization tasks  customized robotic manipulator  robotic trajectories  catheter tip  hands-on robotic navigation platforms  trajectory optimization  robot-assisted endovascular catheterization  flow simulations  X-ray radiation reduction  path integral RL  path integral reinforcement learning  Robots  Catheters  Task analysis  Catheterization  Surgery  Trajectory  Navigation 
Abstract: Emerging robot-assisted endovascular intervention has the potential to reduce X-ray radiations to the operator while enhancing the stability and dexterity of catheter manipulation. Supervised and shared autonomy of endovascular procedures could add further improvements in reduced fatigue and cognitive workloads of the operator, higher success rates of cannulation and improved surgical outcomes. However, robotic path planning for endovascular procedure is challenging due to complex and non-linear flow dynamics inside the vasculature. This paper presents a learning-based robotic catheterization platform addressing those challenges, this approach incorporates path integral reinforcement learning (RL) framework based on dynamic movement primitives (DMP) to enhance catheterization tasks by a customized robotic manipulator. The robotic trajectories were optimized through RL in order to avoid unwanted contacts between the catheter tip and the vessel wall. The proposed methods can adapt to different flow simulations, vascular models, and catheterization tasks. The quality of the catheterization was evaluated with performance metrics. The results show significant refinement of catheter paths by the proposed approach, resulting in shorter overall lengths and fewer contact forces, which can potentially reduce risks in endothelial wall damages, embolization, and stroke. The results support the development of robotic path planning for endovascular procedures as well as designing intelligent, hands-on robotic navigation platforms.


Title: ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery
Key Words: biomedical optical imaging  cameras  endoscopes  image sensors  Kalman filters  medical image processing  medical robotics  orthopaedics  SLAM (robots)  surgery  image feedback  ArthroSLAM  Simultaneous Localisation and Mapping system  SLAM system  external camera  robotic arm  minimally invasive arthroscopic surgery  minimally invasive orthopedic surgery  robotic orthopedic surgical assistant  knee section  human cadaver knee joint  Extended Kalman Filter framework  arthroscope holder  intraarticular space  Cameras  Robot vision systems  Visualization  Reliability 
Abstract: Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.


Title: I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration
Key Words: gaze tracking  human-robot interaction  mobile robots  robot vision  robot autonomy  attention model  user attention  handheld robot collaboration  handheld tool  task knowledge  tool-mounted gaze tracking system  video game setup  cooperative handheld robot  Task analysis  Robot kinematics  Tools  Tracking  Gaze tracking  Estimation 
Abstract: This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users.


Title: Recursive Bayesian Human Intent Recognition in Shared-Control Robotics
Key Words: Bayes methods  control engineering computing  human-robot interaction  inference mechanisms  mobile robots  telerobotics  recursive Bayesian human intent recognition  shared-control robotics  human-robot collaboration  mathematical formulation  assistive teleoperation  recursive Bayesian filtering approach models  nonverbal observations  contextual observations  goal-directed actions  human inference  robot motion  autonomy intent inference performance  shared-control operation  probabilistic reasoning  human intent recognition  human agents behavior  probabilistic fusion  Robots  Bayes methods  Task analysis  Hidden Markov models  Uncertainty  Mathematical model  Probabilistic logic 
Abstract: Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.


Title: A Novel Shared Position Control Method for Robot Navigation Via Low Throughput Human-Machine Interfaces
Key Words: mobile robots  motion control  path planning  position control  user interfaces  wheelchairs  shared position control method  inference parallelization  low throughput human-machine interfaces  robot navigation  robotic wheelchair  circular massless holonomic robot  robot motion  single switch interface  brain-computer interface  Navigation  Wheelchairs  Mobile robots  Position control  Linear systems  Throughput 
Abstract: In this paper, we analyze systems with low throughput human-machine interfaces (such as a brain-computer interface, single switch interface) from the controls perspective. We develop some principles for performance improvement in such systems based on the parallelization of inference and robot motion. The proposed principles are used to design a novel shared position control to navigate a circular massless holonomic robot in a known environment. The system is implemented in simulation and integrated with a real robotic wheelchair. Robot experiments demonstrated the viability of the proposed navigation method in various modes of operation.


Title: Robot Identification and Localization with Pointing Gestures
Key Words: distance measurement  gesture recognition  mobile robots  multi-robot systems  pose estimation  robot vision  SLAM (robots)  mobile robot  multirobot scenarios  robot identification and localization  gesture pointing  robot odometry frame  inertial measurement unit  IMU  Robot sensing systems  Robot kinematics  Solid modeling  Manipulators  Drones  Three-dimensional displays 
Abstract: We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.


Title: Establishing Appropriate Trust via Critical States
Key Words: learning (artificial intelligence)  neural nets  robots  trusted computing  appropriate trust  critical states  learned neural network policies  end-users  mental model  robot learning  Autonomous automobiles  Cognitive science  Task analysis  Automobiles  Reinforcement learning  Entropy 
Abstract: In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.


Title: Interaction System Based on an Avatar Projected on a Pyramidal Display
Key Words: avatars  computer animation  control engineering computing  emotion recognition  face recognition  human computer interaction  human-robot interaction  middleware  mobile robots  operating systems (computers)  telerobotics  pyramidal structure  expression generator subsystem  avatar animations  avatar teleoperation  emotion displaying ability  interaction system  pyramidal display  social robot behavioral architecture  back projection subsystem  three-dimensional avatar  robotic operating system  three dimensional virtual head  3D avatar  facial action coding system  ROS middleware  user interface  avatars gestural ability  Avatars  Animation  Robots  Solid modeling  Face  Shape  Bones 
Abstract: In this paper an interaction system based on a three dimensional virtual head projected onto a pyramidal display is proposed. The proposed system makes use of a social robot behavioral architecture already developed in our lab, which allows us to interchange developments between our robotic realizations and the 3D avatar. The overall system is divided into two parts: back projection subsystem and expression generator subsystem. The back projection subsystem projects a three-dimensional avatar onto a pyramidal structure in order to achieve a sensation of depth and realism. The expression generator subsystem carries out the avatar animations using shape keys and bones, following the Facial Action Coding System (FACS). The system consists in several nodes that are integrated in ROS middleware (Robotic Operating System), and includes a user interface that makes the avatar teleoperation easier (the package is avaible in github public respository). In order to evaluate the expressiveness of the system, two sets of experiments have been performed: one to analyze the avatar's gestural ability, that is, its capability to perform expressions that can be identified by an observer, and a second experiment to measure the emotion displaying ability in terms of valence and arousal.


Title: Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions
Key Words: cameras  computer vision  image motion analysis  image segmentation  image sensors  image sequences  motion estimation  object detection  object tracking  stereo image processing  dynamic scene  multimotion visual odometry pipeline  MVO  dynamic objects  motion capture system  simultaneous estimation  third-party motions  computer vision  previous work  moving camera  largely static environment  segment  tracking-by-detection  motion constraints  planar motion  SE motion  scene flow  unconstrained motions  camera motions  object tracking  stereo/RGB-D camera  multimodal visual odometry pipeline  Cameras  Motion segmentation  Tracking  Dynamics  Trajectory  Estimation  Image segmentation 
Abstract: Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.


Title: Underwater Surveying via Bearing Only Cooperative Localization
Key Words: mobile robots  path planning  remotely operated vehicles  underwater vehicles  bearing only cooperative localization  aerial ground vehicles  underwater domain  robotic applications  cave mapping  marine archeology surveying  fresh water  South Carolina  visibility conditions  depth sensors  magnetic sensors  inertial sensors  Florida  Barbados  Cameras  Springs  Robot kinematics  Lakes  Robot sensing systems 
Abstract: Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.


Title: Ego-Motion Estimate Corruption Due to Violations of the Range Flow Constraint
Key Words: distance measurement  image sensors  image sequences  mobile robots  motion estimation  robot vision  range sensors  visual odometry techniques  dense geometry-based visual odometry methods  range flow constraint equation  temporal derivatives  spatial derivatives  range images  ego-motion estimation  range data  Mathematical model  Cameras  Optical imaging  Visual odometry  Optical sensors  Adaptive optics  Optical variables control 
Abstract: Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.


Title: Semi-Supervised SLAM: Leveraging Low-Cost Sensors on Underground Autonomous Vehicles for Position Tracking
Key Words: cameras  learning (artificial intelligence)  mining  mining industry  mobile robots  object tracking  robot vision  SLAM (robots)  ORB-SLAM2  ground map locations  deep learning  position tracking  operational underground mining vehicles  single camera localization  map creation  mine environment  mining companies  underground environment  SemiSupervised SLAM  underground autonomous vehicles  low-cost sensors  Simultaneous localization and mapping  Cameras  Measurement  Grounding  Visual odometry  Lighting 
Abstract: This work presents Semi-Supervised SLAM - a method for developing a map suitable for coarse localization within an underground environment with minimal human intervention, with system characteristics driven by real-world requirements of major mining companies. This work leverages existing information common within a mining environment - namely a surveyed mine map - which is used to sparsely ground map locations within the mine environment, increasing map accuracy and allowing localization within a global frame. Map creation utilizes a low cost camera sensor and minimal user information to produce a map which can be used for single camera localization within a mining environment. We evaluate the localization capabilities of the proposed approach in depth by performing data collection on operational underground mining vehicles within an active underground mine and by simulating occlusions common to the environment such as dust and water. The proposed system is capable of producing maps which have an average localization error 2.5 times smaller than the next best performing method ORB-SLAM2, comparable localization performance to a state-of-the-art deep learning approach (which is not a feasible solution due to both compute and training requirements) and is robust to simulated environmental obscurants.


Title: An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication
Key Words: cooperative communication  inspection  mobile robots  protocols  automatic tracked robot chain system  gas pipeline inspection  wireless relay communication  wireless signal attenuation  relay communication node  wireless application layer communication protocol  relay transmission efficiency  RSSI-based coordinated movement  Robot sensing systems  Robot kinematics  Pipelines  Relays  Wireless communication  Wireless sensor networks 
Abstract: Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.


Title: Estimating Achievable Range of Ground Robots Operating on Single Battery Discharge for Operational Efficacy Amelioration
Key Words: mobile robots  estimation error  single battery discharge  operational efficacy  mobile robots  active pursuit  law enforcement  plausible traversal velocity  energy utilization  consumers  ancillary robotic functions  Robot sensing systems  Batteries  Mobile robots  Energy consumption  Discharges (electric) 
Abstract: Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.


Title: Interaction-Aware Probabilistic Behavior Prediction in Urban Environments
Key Words: Bayes methods  belief networks  control engineering computing  driver information systems  inference mechanisms  Markov processes  mobile robots  Monte Carlo methods  probability  road vehicles  traffic engineering computing  combinatorial scene developments  road layouts  future scenes  probabilistic forward simulation  sequential Monte Carlo inference  single agents  context-dependent motion models  complete scene  dynamic Bayesian network  probabilistic prediction framework  mutual interaction  traffic rules  road-geometry  route intentions  traffic participants  urban scenarios  complex scenarios  autonomous driving  urban environments  interaction-aware probabilistic behavior prediction  interaction-unaware physics  real-world scenarios  Trajectory  Estimation  Vehicles  Probabilistic logic  Hidden Markov models  Predictive models  Bayes methods 
Abstract: Planning for autonomous driving in complex, urban scenarios requires accurate prediction of the trajectories of surrounding traffic participants. Their future behavior depends on their route intentions, the road-geometry, traffic rules and mutual interaction, resulting in interdependencies between their trajectories. We present a probabilistic prediction framework based on a dynamic Bayesian network, which represents the state of the complete scene including all agents and respects the aforementioned dependencies. We propose Markovian, context-dependent motion models to define the interaction-aware behavior of drivers. At first, the state of the dynamic Bayesian network is estimated over time by tracking the single agents via sequential Monte Carlo inference. Secondly, we perform a probabilistic forward simulation of the network's estimated belief state to generate the different combinatorial scene developments. This provides the corresponding trajectories for the set of possible, future scenes. Our framework can handle various road layouts and number of traffic participants. We evaluate the approach in online simulations and real-world scenarios. It is shown that our interaction-aware prediction outperforms interaction-unaware physics- and map-based approaches.


Title: FEM-Based Deformation Control for Dexterous Manipulation of 3D Soft Objects
Key Words: control engineering computing  dexterous manipulators  elasticity  finite element analysis  force sensors  mobile robots  robot vision  solid modelling  finite element method  Lagrange multipliers  elasticity parameters  3D soft objects  dexterous manipulation  FEM-based deformation control  soft cylindrical object  manipulation task  underactuated anthropomorphic hand  force sensor  contact points  in-hand manipulation  anthropomorphic device  Strain  Finite element analysis  Robots  Deformable models  Three-dimensional displays  Biological system modeling  Estimation 
Abstract: In this paper, a method for dexterous manipulation of 3D soft objects for real-time deformation control is presented, relying on Finite Element modelling. The goal is to generate proper forces on the fingertips of an anthropomorphic device during in-hand manipulation to produce desired displacements of selected control points on the object. The desired motions of the fingers are computed in real-time as an inverse solution of a Finite Element Method (FEM), the forces applied by the fingertips at the contact points being modelled by Lagrange multipliers. The elasticity parameters of the model are preliminarly estimated using a vision system and a force sensor. Experimental results are shown with an underactuated anthropomorphic hand that performs a manipulation task on a soft cylindrical object.


Title: An Adaptive Robotic Gripper with L-Shape Fingers for Peg-in-Hole Tasks
Key Words: force sensors  grippers  mobile robots  adaptive robotic gripper  L-shape finger  peg-in-hole process  force sensor  IREX  international robotic exhibition 2017  Grippers  Task analysis  Uncertainty  Manufacturing processes  Robot sensing systems  Planning 
Abstract: This paper develops an adaptive gripper for peg-in-hole tasks. Conventional grippers require complicated compliant mechanisms or complicated control strategy and force sensing to successfully insert pegs into holes. Different from them, this paper proposes a simple gripper with an L-shape finger as a low-cost peg-in-hole solution. The basic idea is to divide a peg-in-hole process into a preparation phase and an execution phase, and eliminate uncertainty step-by-step by pushing using the L-shape finger in the preparation phase. The robustness of the gripper for peg-in-hole tasks is examined by repeated executions for different pegs in the International Robotic Exhibition 2017 (IREX) in Tokyo. The experimental section presents details of the executions, and qualitatively shows the high performance of the proposed gripper.


Title: Interleaving Hierarchical Task Planning and Motion Constraint Testing for Dual-Arm Manipulation
Key Words: control engineering computing  geometry  inference mechanisms  manipulators  path planning  planning (artificial intelligence)  dual-arm manipulation  symbolic planning  reasoning capabilities  robotic manipulators  geometric constraint verification  Barrett WAM robots  geometric puzzle  hierarchical task network planner  hierarchical task planning  motion constraint testing  motion planning  Task analysis  Planning  Uncertainty  Shape  Manipulators  Cameras 
Abstract: In recent years the topic of combining motion and symbolic planning to perform complex tasks in the field of robotics has received a lot of attention. The underlying idea is to have access at once to the reasoning capabilities of a task planner and to the ability of the motion planner to verify that the plan is feasible from a physical and geometrical point of view. The present work describes a framework to perform manipulation tasks that require the use of two robotic manipulators. To do so we employ a Hierarchical Task Network (HTN) planner interleaved with geometric constraint verification. In this framework we also consider observation actions and handle noisy perceptions from a probabilistic perspective. These ideas are put into practice by means of an experimental set-up in which two Barrett WAM robots have to cooperatively solve a geometric puzzle. Our findings provide further evidence that considering explicitly physical constraints during task planning, rather than deferring their validation to the moment of execution, is advantageous in terms of execution time and breadth of situations that can be handled.


Title: Sequence Pattern Extraction by Segmenting Time Series Data Using GP-HSMM with Hierarchical Dirichlet Process
Key Words: Bayes methods  feature extraction  Gaussian processes  hidden Markov models  image motion analysis  image sampling  image segmentation  learning (artificial intelligence)  nonparametric statistics  time series  continuous time-series data  semiMarkov model  Gaussian processes  nonparametric models  unit motion patterns  complicated continuous motion  nonparametric Bayesian model  hierarchical Dirichlet process  hierarchical Dirichlet processes-Gaussian process  HDP-GP-HSMM  motion-capture data  sequence pattern extraction  time series data  continuous information  unit motions  unsupervised segmentation  Hidden Markov models  Motion segmentation  Gaussian processes  Bayes methods  Data models  Trajectory  Kernel 
Abstract: Humans recognize perceived continuous information by dividing it into significant segments such as words and unit motions. We believe that such unsupervised segmentation is also an important ability that robots need to learn topics such as language and motions. Hence, in this paper, we propose a method for dividing continuous time-series data into segments in an unsupervised manner. To this end, we proposed a method based on a hidden semi-Markov model with Gaussian process (GP-HSMM). If Gaussian processes, which are nonparametric models, are used, unit motion patterns can be extracted from complicated continuous motion. However, this approach requires the number of classes of segments in the time-series data in advance. To overcome this problem, in this paper, we extend GP-HSMM to a nonparametric Bayesian model by introducing a hierarchical Dirichlet process (HDP) and propose the hierarchical Dirichlet processes-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). In the nonparametric Bayesian model, an infinite number of classes is assumed and it becomes difficult to estimate the parameters naively. Instead, the parameters of the proposed HDP-GP-HSMM are estimated by applying slice sampling. In the experiments, we use various synthetic and motion-capture data to show that our proposed model can estimate a more correct number of classes and achieve more accurate segmentation than baseline methods.


Title: Persistent Anytime Learning of Objects from Unseen Classes
Key Words: image classification  random forests  random forest classifier  semantic mapping  object classification  standard offline methods  incremental approach  robotic applications  data samples  Training  Vegetation  Robots  Semantics  Standards  Training data  Uncertainty  Learning and Adaptive Systems  Object Detection  Segmentation and Categorization  Online Learning 
Abstract: We present a fast and very effective method for object classification that is particularly suited for robotic applications such as grasping and semantic mapping. Our approach is based on a Random Forest classifier that can be trained incrementally. This has the major benefit that semantic information from new data samples can be incorporated without retraining the entire model. Even if new samples from a previously unseen class are presented, our method is able to perform efficient updates and learn a sustainable representation for this new class. Further features of our method include a very fast and memory-efficient implementation, as well as the ability to interrupt the learning process at any time without a significant performance degradation. Experiments on benchmark data for robotic applications show the clear benefits of our incremental approach and its competitiveness with standard offline methods in terms of classification accuracy.


Title: Adaptive Robot Body Learning and Estimation Through Predictive Coding
Key Words: actuators  adaptive control  Bayes methods  Gaussian processes  humanoid robots  human-robot interaction  learning (artificial intelligence)  manipulator kinematics  mobile robots  regression analysis  sensor fusion  nonlinear actuators  noisy sensory information  computational perceptual model  predictive processing  arbitrary sensors  Gaussian additive noise  Gaussian process regression  robot body configuration belief  sensory prediction errors  multisensory robotic arm  additive errors  adaptive robot body learning  predictive coding  predictive functions  sensorimotor integration  human-robot interaction  sensor modalities contributions  sensory visuo-tactile perturbations  Robot sensing systems  Visualization  Estimation  Computational modeling  Adaptation models  Bio-inspired perception  body-schema  predictive processing  embodied artificial intelligence  learning and adaptive systems  humanoid robotics 
Abstract: The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.


Title: Online Learning of Body Orientation Control on a Humanoid Robot Using Finite Element Goal Babbling
Key Words: control engineering computing  finite element analysis  humanoid robots  learning (artificial intelligence)  optimisation  position control  robust control  finite element goal babbling  utility function maximization  Nao humanoid robot  robust control  online learning method  FEGB  body orientation control  time 20.0 min to 30.0 min  Task analysis  Aerospace electronics  Finite element analysis  Space exploration  Humanoid robots  Robot sensing systems 
Abstract: How can high dimensional robots learn general sets of skills from experience in the real world? Many previous approaches focus on maximizing a single utility function and require large datasets of experience to do this, something that is not possible to collect outside of simulation as every data point is expensive both in time and in a potential wear down of the robot. This paper addresses this question using a newly developed framework called Finite Element Goal Babbling (FEGB). FEGB is an online learning method that aims at providing general control over some measurable feature, in contrast to optimizing it to some given utility function. It generalizes standard goal babbling by breaking down the full learning problem into local sub-problems, and combining it with a planner that learns how to navigate between these subproblems. We test FEGB using a real humanoid robot Nao, and find that it could quickly learn to robustly control its body orientation. After only 20-30 minutes of training, the robot could freely move into any body orientation between lying on either side and on its back. Rapid learning of body orientation control in high dimensional real robots is largely an unexplored field of robotics, and although many challenges remain, FEGB shows a feasible approach to the problem.


Title: Cost Adaptation for Robust Decentralized Swarm Behaviour
Key Words: computer games  control engineering computing  decentralised control  learning (artificial intelligence)  multi-agent systems  multi-robot systems  optimisation  robot dynamics  cost adaptation  decentralized receding horizon control  multiagent settings  meta-learning process  mesh-networked swarm agents  adaptation mechanism  safer task completion  Unity3D game engine  D-RHC  robust decentralized swarm behaviour  Task analysis  Delays  Decision making  Cost function  Mesh networks  Control systems 
Abstract: Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multiagent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process - cost adaptation - which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.


Title: Active Model Learning and Diverse Action Sampling for Task and Motion Planning
Key Words: Gaussian processes  learning (artificial intelligence)  mobile robots  path planning  sampling methods  complex domains  flexible generative planning  state-of-the-art methods  active learning  Gaussian process methods  operator effectiveness  adaptive sampling methods  diverse elements  robot configurations  object poses  newly learned models  long horizon problems  active model learning  action sampling  motion planning  sensorimotor primitives  complex long-horizon problems  continuous-space robot task  Planning  Task analysis  Level set  Robot sensing systems  Gaussian processes  Training 
Abstract: The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world. In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world? We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.


Title: Improving Reinforcement Learning Pre-Training with Variational Dropout
Key Words: control engineering computing  Gaussian processes  legged locomotion  supervised learning  reinforcement learning pre-training  control policies  robotic agents  bipedal locomotion  data points  Gaussian dropout networks  variational inference  policy parameters  standard supervised learning  optimal policies  variational dropout  regularization term  RL algorithm  high-dimensional continuous control problems  Task analysis  Training  Reinforcement learning  Training data  Cloning  Supervised learning  Robots 
Abstract: Reinforcement learning has been very successful at learning control policies for robotic agents in order to perform various tasks, such as driving around a track, navigating a maze, and bipedal locomotion. One significant drawback of reinforcement learning methods is that they require a large number of data points in order to learn good policies, a trait known as poor data efficiency or poor sample efficiency. One approach for improving sample efficiency is supervised pre-training of policies to directly clone the behavior of an expert, but this suffers from poor generalization far from the training data. We propose to improve this by using Gaussian dropout networks with a regularization term based on variational inference in the pre-training step. We show that this initializes policy parameters to significantly better values than standard supervised learning or random initialization, thus greatly reducing sample complexity compared with state-of-the-art methods, and enabling an RL algorithm to learn optimal policies for high-dimensional continuous control problems in a practical time frame.


Title: A Framework for Dexterous Manipulation
Key Words: dexterous manipulators  humanoid robots  learning (artificial intelligence)  manipulator dynamics  motion control  dexterous manipulation  humanoid robot Robonaut-2  anthropomorphic Robonaut-2 hand  manipulation tasks  hand fan  IROS2018 fan robotic challenge  phase I modality A competition  Robots  Task analysis  Neurons  Brain modeling  Fans  Computational modeling  Grasping 
Abstract: In this work, we introduce a framework for performing dexterous manipulations on the humanoid robot Robonaut-2. This framework memorizes how actions change perceptions and can learn a sequence of actions based on demonstrations. With the anthropomorphic Robonaut-2 hand and arm, a variety of manipulation tasks such as grasping novel objects, rotating a drill for grasping, and tightening a bolt with a ratchet can be accomplished. This framework was also used to compete in the IROS2018 Fan Robotic Challenge that requires manipulating a hand fan and was a winner of the phase I modality A competition.


Title: An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge
Key Words: dexterous manipulators  grippers  motion control  tactile sensors  vibrations  extrinsic dexterity approach  IROS 2018 fan robotic challenge  Spanish folding fan  dexterous manipulation  robotic systems  external dexterity  high DoF grippers  3D-printed adaptation  multimodal tactile sensor  Fans  Grippers  Robot kinematics  Service robots  Task analysis  End effectors 
Abstract: The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.


Title: Development of Low-Inertia High-Stiffness Manipulator LIMS2 for High-Speed Manipulation of Foldable Objects
Key Words: actuators  control engineering computing  dexterous manipulators  elastic constants  fans  grippers  manipulator dynamics  manipulator kinematics  motion control  operating systems (computers)  protocols  low-inertia high-stiffness manipulator  high-speed manipulation  foldable objects  dual-arm robot system  LIMS2-AMBIDEX  IROS2018 Robotic Challenge  seven-degrees-of-freedom  foldable fan  Fan Robotic Challenge Phase  high-speed communication protocol  tension-amplification mechanisms  gripper  robot operating system  Xenomai  real-time development framework  EtherCAT  software framework  mass 2.63 kg  Wrist  Fans  Robots  Elbow  Shoulder  Grippers  Actuators 
Abstract: In this paper, a dual-arm robot system for high-speed manipulations, which is named LIMS2-AMBIDEX and is developed to compete in the IROS2018 Robotic Challenge, is presented. It has two seven-degrees-of-freedom (DO F) lightweight arms, a three-DOF head, and a one-DOF gripper to manipulate foldable objects. Because all the heavy actuators are placed at the shoulder, it has remarkably low mass beyond the shoulder (2.63 kg), which guarantees an inherent safety at high speeds. Utilizing tension-amplification mechanisms, the high stiffness and strength are achieved, and thus it has the control performance comparable to conventional industrial manipulators. A unique three-DOF wrist mechanism, whose motions directly represent the quaternion values of the joint orientation, can manipulate objects without singular points in the entire range of motion. In order to utilize the object's inertia during rapid manipulation, the gripper was specially designed: it has a one-DOF finger to grasp the upper rib of the foldable fan and two supporting forks to grasp the bottom rib stably. For real-time performance and increased scalability, a software framework was developed based on Robot Operating System (ROS). The real-time capability is achieved by using the real-time development framework Xenomai and the high-speed communication protocol EtherCAT. As most of the algorithms are implemented in the distributed nodes using ROS, it is convenient to expand, improve, and replace the algorithms. Consequentially, the entire motion of the Fan Robotic Challenge Phase I Modality B required 1.05 s, which is substantially faster than a similar manipulation by most humans.


Title: Flamen − 7 DOF Robotic Arm to Manipulate a Spanish Fan
Key Words: control engineering computing  fans  manipulators  mobile robots  motion control  position control  7-DOF robotic arm  Flamen  Flamenco dancers  manipulation  traditional fan  Spanish fan  Fans  Manipulators  Robot kinematics  Actuators  Grasping  Cameras  Actuation  Automation  Background subtraction  Contour Detection  Coordinate extraction  Filtering  Mapping  Masking  Robotic Arm  Spanish Fan 
Abstract: A Spanish fan is a hand held traditional fan which is used as an accessory and also by Flamenco dancers. The manipulation of the fan is quite difficult as it involves dynamic motion which includes opening, flapping and closing the fan along a pivotal point. The key points include the motion to be quick and the fan to be opened to the maximum degree possible without human intervention. A robotic arm with 7 Degrees of Freedom (DOF) is used to manipulate the autonomous motion. The fan placed on the table is localized and detected using a camera by background subtraction, masking and filtering; post which the contour of the fan is detected. The pixels obtained is then transformed into real life coordinates. The Dynamixel motors then traverses to the coordinates of the fan's position to grasp, open, flap, close and put the fan down.


Title: IROS 2018 Fan Challenge - Team DLR Augsburg
Key Words: human-robot interaction  service robots  hot summer  blistering sun  Madrid  scorching heat  simple gesture  robotic assistant  relaxing shade  team DLR Augsburg  IROS 2018 fan challenge  tinto de verano  Fans  Grippers  Robot kinematics  End effectors  Cameras  Servomotors 
Abstract: It's a hot summer in 2021 and the blistering sun is shining upon Madrid. You are enjoying some tinto de verano on your terraza. Sizzling in the scorching heat, you are trying to relax. With a simple gesture you call your robotic assistant to help you cool down a little bit. Without further ado, your robot provides some relaxing shade holding a parasol for you, picks up a fan autonomously and starts waving it and the gentle breeze brings you some light relief.


Title: A Universal Controller for Unmanned Aerial Vehicles
Key Words: aerodynamics  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  helicopters  mobile robots  UAVs  agile fixed-wing aircraft  control logic  unmanned aerial vehicles  tilt-rotor  vehicle flight envelope  single physics-based controller  multicopters  autonomous flight  quadrotor  Force  Aircraft  Quaternions  Attitude control  Actuators 
Abstract: Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.


Title: Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System
Key Words: aerospace robotics  decentralised control  helicopters  Lyapunov methods  materials handling  mobile robots  motion control  multi-robot systems  optical tracking  stability  energetic passivity property  drone on-board IMUs  Lyapunov analysis  optical tracking systems  three-drone payload transport system  motion stability  cable-suspended payload  multiple conventional quadcopters  cabled-based multidrone load transport system  decentralized motion control  Payloads  Drones  Force  Stability analysis  Trajectory 
Abstract: A provably stable decentralized control scheme is proposed to allow multiple conventional quadcopters carry a cable-suspended payload. The method exploits a fundamental energetic passivity property of the combined drones, cables, and payload system to stably move the payload from its origin to destination. This is achieved without making any assumption about the status of the cables tension during the flight, and any measurement from the payload. The controller is decentralized in the sense that inter-drone communication of feedback measurements is not required. Motion stability is demonstrated via a Lyapunov analysis. The proposed controller is successfully implemented on a three-drone payload transport system in an indoor environment, using measurement from an optical tracking systems and the drones on-board IMUs.


Title: SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors
Key Words: aircraft control  autonomous aerial vehicles  human-robot interaction  microrobots  multi-robot systems  path planning  tactile sensors  trajectory control  impedance controlled swarm  nanoquadrotors  novel interaction strategy  human-swarm communication  human operator guides  quadrotors  impedance control  human hand velocity  formation shape  Crazyflie 2.0 quadrotor platform  control algorithm  tactile patterns  controllability  complex life-like formation  tactile sensation  drone formation  human-swarm interaction  swarm navigation  Impedance  Drones  Robots  Mathematical model  Shape  Force  Safety 
Abstract: We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.


Title: Real-Time Light Field Processing for Autonomous Robotics
Key Words: calibration  cameras  image sensors  mobile robots  optical radar  robot vision  telerobotics  autonomous robotics systems  LIDAR sensors  time light field processing  simple linear arrays  high frequency vibrations  light fields  autonomous cars  light field imaging system  field-of-view  software framework  Cameras  Robot vision systems  Vibrations  Calibration  Three-dimensional displays 
Abstract: Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.


Title: Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels
Key Words: image sensors  lenses  photodetectors  robot vision  stereo image processing  visual perception  WAF lens  wide angle fovea lens  high-definition imager  autonomous robot  vehicle supersensing vision system  robotic vision  field of view  FOV  high-resolution photosensitive imaging chip  stereo vision system  optical performance  aspherical surface  projection testing  Lenses  Prototypes  Spatial resolution  Cameras  Robots  Optical imaging 
Abstract: This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.


Title: Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning
Key Words: convolutional neural nets  end effectors  learning (artificial intelligence)  motion control  neurocontrollers  learning synergies  self-supervised deep reinforcement learning  cluttered objects  pushing movements  model-free deep reinforcement learning  fully convolutional networks  end-effector orientations  Q-learning framework  pushing motions  grasping success rates  picking efficiencies  skilled robotic manipulation  grasping  prehensile action  pixel-wise sampling  Grasping  Training  Three-dimensional displays  Reinforcement learning  Planning  Manipulators 
Abstract: Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/


Title: Towards Material Classification of Scenes Using Active Thermography
Key Words: image classification  infrared imaging  learning (artificial intelligence)  temperature measurement  multimaterial scene  varying distances  multiclass classification  heating intensity  material classification  variable distances  relatively large surface areas  modern machine learning methods  data-driven approach  signal variations  thermal camera  heat lamp  size 20.0 cm  size 40.0 cm  size 30.0 cm  time 4.0 s  time 5.0 s  time 1.0 s  Heating systems  Cameras  Heat transfer  Robot sensing systems  Surface treatment 
Abstract: By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.


Title: Vision-Based State Estimation and Trajectory Tracking Control of Car-Like Mobile Robots with Wheel Skidding and Slipping
Key Words: automobiles  control system synthesis  estimation theory  Lyapunov methods  mobile robots  motion control  robot vision  stability  state estimation  trajectory control  wheels  car-like mobile robots  wheel slipping  Lyapunov method  system stability  visual estimation algorithm  vision-based approach  wheel skidding  trajectory tracking control  vision-based state estimation  Mobile robots  Wheels  Perturbation methods  Visualization  Estimation  Trajectory tracking 
Abstract: Most existing trajectory tracking controllers are based on non-skidding and non-slipping assumptions, also assume that full states are accessible, which is unrealistic for real-world applications due to tire-road interaction. This paper presents a novel vision-based approach to achieve high performance tracking control of a Car-Like Mobile Robot (CLMR) with wheel skidding and slippage. A visual estimation algorithm is proposed to provide reliable position, velocity, skidding and slipping information to close the control loop. The stability of the proposed system can be guaranteed by Lyapunov method since the position tracking error and the estimation error converge to zero simultaneously. Simulation is made to validate the effectiveness of the developed controller in the presence of skidding and slipping with online visual estimator.


Title: Recruitment Near Worksites Facilitates Robustness of Foraging E-Puck Swarms to Global Positioning Noise
Key Words: collision avoidance  mobile robots  position control  worksites facilitates robustness  foraging e-puck swarms  global positioning noise  collective foraging  robot global positioning data  broadcast messages  e-puck robots  semivirtual environment  VICON positioning system  robot positioning data  pseudorandom environments  important physical aspects  inherent noise  robot infra-red sensors  robot controllers  Robot kinematics  Robot sensing systems  Servers  Task analysis  Recruitment 
Abstract: We compare the ability of two different robot controllers for collective foraging to cope with noise in robot global positioning data and show how recruitment, in the form of broadcast messages near worksites, can make swarms more robust. Swarms of five e-puck robots are used in a semi-virtual environment, facilitated by the VICON positioning system. This setup allows us to control the amount of noise in the robot positioning data and to generate pseudo-random environments, while retaining important physical aspects of the experiment. The effect of inherent noise in the robot infra-red sensors, used for obstacle avoidance, is noted and the importance of modelling such noise in agent-based simulations is highlighted.


Title: Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis
Key Words: mobile robots  multi-robot systems  self-adjusting systems  self-assembly  trees (mathematics)  complex patterns  programmable systems  similar complexity  role model  natural plants  environmental conditions  dynamic environments  patterned formation  vascular tissue  aggregated robots  dynamic environment  robot swarm experiments  Legged locomotion  Robot sensing systems  Collision avoidance  Self-assembly  Shape  Resource management 
Abstract: Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.


Title: $\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms
Key Words: aggregation  fuzzy control  fuzzy set theory  image colour analysis  mobile robots  multi-robot systems  pheromone diffusion  BEECLUST algorithm  pheromone-based communication  pheromone-based aggregation method  ΦClust  artificial pheromone  BEECLUST method  pheromone evaporation  robotic swarms  Robot sensing systems  Biological system modeling  Aggregates  Swarm robotics  Temperature sensors  Swarm Robotics  Aggregation  Pheromone  Bio-inspired 
Abstract: In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.


Title: Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms
Key Words: collision avoidance  decentralised control  mobile robots  multi-robot systems  robots  trees (mathematics)  physics-based simulations  logical tree  robot network  spatially distributed targets  robot swarm  large-scale robot  decentralized connectivity-preserving deployment  real-robot experiments  tree root  connectivity constraints  physical network  logical tree topology  Robot kinematics  Topology  Heuristic algorithms  Network topology  Switches  Task analysis 
Abstract: We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.


Title: A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems
Key Words: collision avoidance  logistics  mobile robots  multi-agent systems  multi-robot systems  control scheme  collaborative transportation  bar-like shaped loads  robot-teams  collaborative object transportation task  precision farming setting  distributed swarm aggregation algorithm  bar shaped multiagent systems  state space  aggregate state  collision avoidance  angular consensus  segment-to-segment distance definition  control law  autonomous tractors  Bars  Multi-agent systems  Robot kinematics  Collision avoidance  Aggregates  Load modeling 
Abstract: In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.


Title: Resilient Active Information Gathering with Mobile Robots
Key Words: mobile robots  multi-robot systems  information acquisition tasks  failure-prone  resilient design problems  submodular approximation algorithms  active robots  mobile robots  resilient active information gathering  multirobot target tracking  active information gathering scenario  denial-of-service attacks  system-wide resiliency  minimal communication  Robot sensing systems  Target tracking  Mobile robots  Robot kinematics  Task analysis 
Abstract: Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.


Title: Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams
Key Words: decision making  multi-robot systems  probability  rescue robots  robust control  state estimation  computationally-efficient manner  feasible baseline approaches  context-dependent policies  robot rescue decision-making  multirobot teams  scalable policy synthesis framework  parallelizable policy synthesis framework  time-varying  stochastic mission conditions  physics-based simulations  probability minimization  state estimation  Robots  Task analysis  Computational modeling  State estimation  Probabilistic logic  Switches  Navigation 
Abstract: We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.


Title: Development of Rimless Wheel with Controlled Wobbling Mass
Key Words: gait analysis  legged locomotion  numerical analysis  robot dynamics  wheels  controlled wobbling mass  rimless wheel  level-ground walking  propulsive effects  physical parameters  control parameters  numerical simulation  robots  Legged locomotion  Wheels  Trajectory  Torso  Mathematical model 
Abstract: This paper presents a novel method for generating level-ground walking for a rimless wheel with a controlled wobbling mass. Our rimless wheel achieves level-ground walking by simply controlling the wobbling mass attached to the wheel. We mathematically demonstrate that the controlled wobbling mass generates propulsive effects for the rimless wheel. The walking speed of the rimless wheel can be changed by varying the amplitude of the wobbling mass: thus slow walking to high-speed walking can be realized for the wheel. Moreover, we have developed a robot based on a rimless wheel to show effectiveness of our proposed methods. We then analyze the walking properties with respect to the physical parameters and control parameters of our robot through numerical simulation.


Title: Maneuverability in Dynamic Vertical Climbing
Key Words: legged locomotion  robot dynamics  distinct dynamic gait identification  dynamic climbing platform  prescribed body roll  reduced order pendular dynamic climbing model  dynamic vertical climbing  dynamic maneuverability  dynamic downward climbing  Legged locomotion  Dynamics  Foot  Mathematical model  Force  Trajectory 
Abstract: In this paper, we examine the reduced order pendular dynamic climbing model with the addition of attachment windows based on prescribed body roll. With this model and on the new dynamic climbing platform, TAILS, we demonstrate dynamic downward climbing as well as identify distinct dynamic gaits within downward climbing. This, combined with the application of an asymmetric configuration of the rear legs enables strafing motions and thus dynamic maneuverability on walls in the vertical domain.


Title: Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution
Key Words: actuators  closed loop systems  design engineering  force control  gears  industrial robots  legged locomotion  manipulator kinematics  motion control  torque control  wearable robots  force control  PPE loads  extra robotic legs system  hazardous material emergency  gear reductions  XRL system  power systems  closed-loop kinematic chain  actuator loads  personal protective equipment  robotic human augmentation system  torque redistribution  Legged locomotion  Payloads  Kinematics  Force  Torque  Actuators  Human Augmentation  Supernumerary Robotic Limbs  Exoskeletons  Mechanism Design  Industrial Robotics 
Abstract: We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.


Title: Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis
Key Words: end effectors  friction  legged locomotion  climbing region  feasibility region analysis  multilimbed climbing robots  slide failure mode  over-torque failure mode  pure friction end effectors  walls  hexapod robot  robot deformation  climbing failure  robots  stiffness matrices  statically indeterminate forces  static indeterminacy modeling  multilimbed robot vertical two wall climbing  Strain  Mathematical model  Friction  Force  Robot kinematics  Manipulators 
Abstract: This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.


Title: Fast Walking with Rhythmic Sway of Torso in a 2D Passive Ankle Walker
Key Words: gait analysis  legged locomotion  2D passive ankle walker  biped robots  rhythmic sway  torso-swaying optimization  optimal trajectories  fast walking speed  un-actuated ankles  Legged locomotion  Torso  Trajectory  Optimization  Mathematical model  Foot  Biped robots  legged locomotion 
Abstract: There is a category of biped robots that are equipped with passive or un-actuated ankles, which we call Passive-Ankle Walkers (PAWs). Lack of actuation at ankles is a disadvantage in the fast walking of PAWs. We started this study with an intuitive hypothesis that rhythmic sway of torso may enable faster walking in PAWs. To test this hypothesis, firstly, we optimized the rhythmic sway of torso of a simulated PAW model for fast walking speed, and analyzed the robustness of the optimal trajectories. Then we implemented the optimal trajectories on a real robot. Both the simulation analysis and the experimental results indicated that optimized torso-swaying can greatly increase the walking speed by 40%. By analyzing the walking patterns of the simulated model and the real robot, we identified the reason for the faster walking with swaying-torso: The rhythmic sway of torso enables the robot to walk with a relatively large step-length while still keeninu a hizh sten-frenuencv.


Title: Torque Controlled Biped Model Through a Bio-Inspired Controller Using Adaptive Learning
Key Words: biomimetics  legged locomotion  motion control  oscillators  robot dynamics  torque control  flat terrain  impedance control  adaptive frequency oscillator  biomimetic controller  torque adjustment  walking behavior  joint stiffness  adaptable stiffness  bipedal robots  motion control  biomimetic solutions  slopes  holes  obstacles  unstructured terrains  human beings  harmonious locomotion  efficient locomotion  biped robots  adaptive learning  bio-inspired controller  torque controlled biped model  Legged locomotion  Oscillators  Biological system modeling  Adaptation models  Torque  Robot kinematics  Biped  Central Pattern Generator  Hopf  AFO  torque  stiffness 
Abstract: Biped robots have not achieved the efficient and harmonious locomotion of the human beings, capable of walking and running on unstructured terrains, with obstacles, holes and slopes. With this in mind, researchers started the development of biomimetic solutions to control the locomotion of biped models. This work presents a new solution of motion control of bipedal robots with adaptable stiffness, by exploring effects of joint stiffness in modulating walking behavior. Further, torque adjustment is achieved through a biomimetic controller that mimics and adjusts the natural dynamics of the robot to the environment. Specifically, the torque adjustment is made using AFOs (adaptive frequency oscillator) to generate the correct equilibrium positions that will be applied to the impedance control that computes the torque of each joint. Results show that the biped model is capable of walking in several types of terrain, including flat terrain, ramps, stairs and flat terrain with obstacles.


Title: High-Speed Stealth Walking of Underactuated Biped Utilizing Effects of Upper-Body Control and Semicircular Feet
Key Words: gait analysis  legged locomotion  motion control  robot dynamics  high-speed stealth walking  upper-body control  semicircular feet  stable legged locomotion  underactuated robotic walkers  double-limb support phase  gait properties  typical stealth walking gaits  upper body motion  underactuated biped  Legged locomotion  Foot  Mathematical model  Trajectory  Numerical models  Stability analysis  Analytical models 
Abstract: Stealth walking is a way of walking carefully and noiselessly, and is an approach to stable legged locomotion of underactuated robotic walkers on irregular terrains. This paper proposes a method for generating a high-speed stealth walking gait without including double-limb support phase, and discusses the effect of upper-body control and semicircular feet on the gait properties. First, we introduce a model of a 3-link planar underactuated biped with an upper body and semicircular feet, and derive the approximate target initial state of the upper body by using the linearized equation of motion. Second, we conduct numerical simulations of the nonlinear model to observe the typical stealth walking gaits, and analyze the changing tendency of the upper body motion with respect to the foot radius. Furthermore, we discuss the advantage of semicircular feet through parametric studies of the gait efficiencies.


Title: A Comparison of Assistive Methods for Suturing in MIRS
Key Words: dexterous manipulators  medical robotics  surgery  telerobotics  human-in-the-Ioop  vision-free  telemanipulation paradigm  surgeons control  minimally invasive robotic surgery  robotic systems  laparoscopic interventions  assistive methods  da Vinci Research Kit robot  robot behaviour  MIRS  cognitive load  dexterity  surgical site  Robots  Needles  Surgery  Force  Trajectory  Force measurement  Task analysis 
Abstract: In Minimally Invasive Robotic Surgery (MIRS) a robot is interposed between the surgeon and the surgical site to increase the precision, dexterity, and to reduce surgeon's effort and cognitive load with respect to the standard laparoscopic interventions. However, the modern robotic systems for MIRS are still based on the traditional telemanipulation paradigm, e.g. the robot behaviour is fully under surgeon's control, and no autonomy or assistance is implemented. In this work, supervised and shared controllers have been developed in a vision-free, human-in-the-Ioop, control framework to help surgeon during a surgical suturing procedure. Experiments conducted on the da Vinci Research Kit robot proves the effectiveness of the method indicating also the guidelines for improving results.


Title: External Force/Torque Estimation on a Dexterous Parallel Robotic Surgical Instrument Wrist
Key Words: actuators  dexterous manipulators  force control  force sensors  linear motors  manipulator dynamics  manipulator kinematics  medical robotics  motion control  observers  position control  surgery  torque control  sensorless force estimation algorithm  rigid link parallel wrist mechanism  reaction force observers  back-drivable rigid-link wrist mechanism  force sensors  robotic surgical wrist mechanism  estimation method  dexterous parallel robotic surgical instrument wrist  RMS force-torque estimation error values  external force-torque estimation  Wrist  Force  Robot sensing systems  Estimation  Jacobian matrices  Kinematics 
Abstract: This paper describes a novel sensorless force estimation algorithm for the rigid link parallel wrist mechanism of a robotic surgical instrument. The method utilizes novel reaction force observers (RFOB) in joint space, which are modified disturbance observers (DOB) combined with Neural Networks (NN) for inverse dynamics calculations, to estimate external forces acting on the motors. External force/torque estimation in Cartesian space is achieved by the use of the robot Jacobian. The proposed algorithm is applicable to any back-drivable rigid-link wrist mechanism without the need for force sensors. In this paper, the method is implemented on a novel 3 degree-of-freedom (DOF) parallel robotic surgical wrist mechanism that is designed for high dexterity (±90 degrees pitch-yaw rotations, thrust motion) and force/torque estimation. The wrist is actuated extracorporally with 3 rigid push-pull rods and 3 linear motors. With a rigid transmission and high back-drivability, external force/torque estimation can be achieved from the motor position readings utilizing the proposed method. Several experiments were performed on the manufactured prototype of the instrument and results validate the efficacy of the wrist and estimation method with RMS force/torque estimation error values of 0.0024 Nm in pitch axis, 0.0043 Nm in yaw axis and 0.1866 N in thrust axis.


Title: Hand-Impedance Measurement During Laparoscopic Training Coupled with Robotic Manipulators
Key Words: end effectors  force sensors  medical robotics  position control  surgery  end-effector position information  impedance measurement  human hand-impedance  laparoscopic training program  physically interactive robotic manipulators  robotic assistants  needle  variable admittance controlled robots  step vice velocity disturbances  force sensor  minimally invasive surgery training box  Robots  Force  Laparoscopes  Training  Admittance  Frequency measurement  Stability analysis 
Abstract: This paper presents measurements of human hand-impedance during a laparoscopic training program with physically interactive robotic manipulators. The knowledge of how the hand-impedance changes due to training might be useful to inform better training programs and to introduce co-manipulated robotic assistants for effective trainings. Ten novice subjects participated in a three weeks training program for a suturing activity in laparoscopy. The subjects have been instructed to set the needle, enter the skin, and tie knots by using laparoscopic tools within a Minimally Invasive Surgery training box. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle. Based on the interaction force and end-effector position information, impedances of the left and right hands were computed in four different directions. The computed results were compared with respect to the participants skill progression.


Title: Comparison of 3D Surgical Tool Segmentation Procedures with Robot Kinematics Prior
Key Words: biological tissues  biomedical MRI  computerised tomography  image reconstruction  image registration  image segmentation  medical image processing  medical robotics  robot kinematics  surgery  robot-assisted laparoscopic surgery  surgical guidance  local 3D reconstruction  tool-tissue interaction region  3D reconstructed model  Raven II surgical robot system  3D surgical tool segmentation procedure  robot kinematics  vision-based force estimation  medical image registration  preoperative data  patient anatomy  surgical task space  Tools  Three-dimensional displays  Cameras  Image segmentation  Robot vision systems  Force  Image reconstruction 
Abstract: 3D reconstruction and surgical tool segmentation are necessary for several advanced tasks in robot-assisted laparoscopic surgery. These tasks include vision-based force estimation, surgical guidance, and medical image registration where pre-operative data (CT or MRI scan image slices) are overlaid on patient anatomy in real-time during surgery [1] to name a few. In this work, two main strategies were considered: (1) initialize with surgical tool segmentation from 2D images, then proceed to local 3D reconstruction near the tool-tissue interaction region by projecting the segmented result into 3D space, and (2) initialize with 3D reconstruction of the entire surgical task space, followed by surgical tool segmentation from within the 3D reconstructed model. Both methods were implemented on the Raven II surgical robot system, and accuracy and time complexity for both methods were comparatively analyzed while considering various task parameters. Finally, based on the results of this work, guidelines for selecting reconstruction and segmentation strategies and procedure for particular situations are outlined in Section V.


Title: Preference-Based Assistance Prediction for Human-Robot Collaboration Tasks
Key Words: control engineering computing  hidden Markov models  human-robot interaction  learning (artificial intelligence)  human-robot collaboration tasks  learning supportive behavior preferences  human-level prediction  personalized supportive behavior model  observed human workers  hidden Markov model  training data  human peer  physical tasks  human worker  robots  preference-based assistance prediction  Task analysis  Hidden Markov models  Service robots  Collaboration  Legged locomotion  Data models 
Abstract: Human-Robot Collaboration (HRC) aims to develop robots that provide assistance to human workers while performing physical tasks. Such assistance comes in the form of supportive behaviors that are different from the actions part of the task, and that are meant to help a human worker more effectively accomplish the task. Learning how to provide useful behaviors that are tailored to a human peer represents a difficult challenge. This is due to the need of large amounts of training data in the form of real world observations that include information about such preferences. This data needs to encode not only the structure and progression of the task, but also the different workers' preferences with respect to when and what assistance the robot should provide. Our work separates the challenge of learning a model of the task (which requires a large amount of training data) from that of learning supportive behavior preferences for the interaction (which has obvious restrictions for the number of user-provided demonstrations to which we have access). We first learn a hidden Markov model (HMM) from a training set consisting of observed human workers performing the considered task in simulation. We then use this model to predict, while observing the human peer, what supportive behaviors a robot should offer throughout the task. Building upon the hidden state representation, our system is able to learn the supportive behaviors based on as few as five user-annotated demonstrations, learning a personalized supportive behavior model. We evaluate our system on a user study with 14 participants, and show results on par with human-level prediction for the task.


Title: Collaborative Planning for Mixed-Autonomy Lane Merging
Key Words: control engineering computing  decision making  driver information systems  game theory  mobile robots  multi-agent systems  path planning  road traffic  road vehicles  collaborative planning  social activity  mixed-autonomy traffic  Human-driven Vehicle  HV  Autonomous Vehicle drive  AV  planning framework  two-lane highway  double lane merging  collaborative decision making  mixed-autonomy lane merging  Automobiles  Planning  Merging  Collaboration  Robots  Autonomous vehicles 
Abstract: Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.


Title: Adaptive Modality Selection Algorithm in Robot-Assisted Cognitive Training
Key Words: cognition  human-robot interaction  learning (artificial intelligence)  medical robotics  patient rehabilitation  robot programming  service robots  robotic system  robot-assisted cognitive training  socially assistive robots  therapy  Alzheimer's disease  mild cognitive impairment  dementia  adaptive modality selection algorithm  interaction modalities  AMS algorithm  Shape  Training  Service robots  Manipulators  Task analysis  Market research 
Abstract: Interaction of socially assistive robots with users is based on social cues coming from different interaction modalities, such as speech or gestures. However, using all modalities at all times may be inefficient as it can overload the user with redundant information and increase the task completion time. Additionally, users may favor certain modalities over the other as a result of their disability or personal preference. In this paper, we propose an Adaptive Modality Selection (AMS) algorithm that chooses modalities depending on the state of the user and the environment, as well as user preferences. The variables that describe the environment and the user state are defined as resources, and we posit that modalities are successful if certain resources possess specific values during their use. Besides the resources, the proposed algorithm takes into account user preferences which it learns while interacting with users. We tested our algorithm in simulations, and we implemented it on a robotic system that provides cognitive training, specifically Sequential memory exercises. Experimental results show that it is possible to use only a subset of available modalities without compromising the interaction. Moreover, we see a trend for users to perform better when interacting with a system with implemented AMS algorithm.


Title: Continuous Shared Control for Robotic Arm Reaching Driven by a Hybrid Gaze-Brain Machine Interface
Key Words: brain-computer interfaces  continuous systems  electroencephalography  end effectors  handicapped aids  human-robot interaction  medical control systems  medical robotics  motion control  shared control paradigm  human-robot interface  robot autonomy  gaze-BMI control  hybrid gaze-BMI  robotic arm end-effector  continuous shared control  hybrid gaze-brain machine interface  brain-machine interface  assistive robot  motor impaired people  motion intention strength  obstacle avoidance  Robot kinematics  End effectors  Task analysis  Electroencephalography  Robot sensing systems 
Abstract: The brain-machine interface (BMI) has been reported to offer the potential for controlling the assistive robot for the motor impaired people, using the non-invasively obtained electroencephalogram (EEG) signals. However, the EEG based BMI may not be sufficient and stable to drive the robot moving freely in its 2D or 3D workspace. The robot autonomy may provide assistance for the BMI users with the shared control paradigm. Nevertheless, users suffers from several limitations of the current shared control paradigms applied on BMI, e.g., loss of sense of control, high mental workload due to unintuitive control with the human-robot interface and fixed level of assistance. To overcome these drawbacks, we propose a new control paradigm for the robotic arm reaching task where the robot autonomy is dynamically blended with the gaze-BMI control from a user. In this paradigm, the hybrid gaze-BMI constitutes an intuitive and effective input to continuously control the robotic arm end-effector moving freely in its 2D workspace, with an adjustable speed proportional to the motion intention strength. Furthermore, the adjustable level of assistance by our paradigm allows the system to balance the user's capabilities and feelings of control while compensating for the reaching task's difficulty. The proposed paradigm is verified in the task where a healthy subject utilizes the hybrid gaze-BMI to control the robotic arm end-effector reaching for a target object while avoiding the obstacle in the path. The experimental results demonstrate that the movements with our shared control paradigm are safer, more efficient and less difficult than those without shared control.


Title: The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity
Key Words: human-robot interaction  multi-robot systems  navigation  path planning  simulated robot-human interaction scenarios  entitative robots  strong emotional reactions  socially invisible robot navigation  robot entitativity  data-driven algorithm  navigational algorithms  trajectory computation  multirobot systems  Trajectory  Navigation  Psychology  Computational modeling  Surveillance  Robot kinematics 
Abstract: We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.


Title: Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace
Key Words: control engineering computing  human-robot interaction  planning (artificial intelligence)  virtual reality  mixed-reality technologies  human-robot interaction  HoloLens  human-in-the-loop operation  projection-aware task planning capabilities  Robots  Task analysis  Planning  Virtual reality  Observers  Vocabulary  Natural languages 
Abstract: Recent advances in mixed-reality technologies have renewed interest in alternative modes of communication for human-robot interaction. However, most of the work in this direction has been confined to tasks such as teleoperation, simulation or explication of individual actions of a robot. In this paper, we will discuss how the capability to project intentions affect the task planning capabilities of a robot. Specifically, we will start with a discussion on how projection actions can be used to reveal information regarding the future intentions of the robot at the time of task execution. We will then pose a new planning paradigm - projection-aware planning - whereby a robot can trade off its plan cost with its ability to reveal its intentions using its projection actions. We will demonstrate each of these scenarios with the help of a joint human-robot activity using the HoloLens.


Title: KnowRobSIM — Game Engine-Enabled Knowledge Processing Towards Cognition-Enabled Robot Control
Key Words: cognitive systems  computer games  control engineering computing  data structures  decision making  inference mechanisms  knowledge representation  manipulators  motion control  rendering (computer graphics)  action simulation  physics engine  AI knowledge representation  decision making capabilities  robotic agents  motion parameterization  symbolic reasoning methods  modern game engine technology  game engine-enabled knowledge processing  cognition-enabled robot control  KnowRobSIM  reasoning methods  manipulation tasks  data structures  world scene rendering  object manipulation  Cognition  Games  Engines  Robots  Force  Data structures 
Abstract: AI knowledge representation and reasoning methods consider actions to be blackboxes that abstract away from how they are executed. This abstract view does not suffice for the decision making capabilities required by robotic agents that are to accomplish manipulation tasks. Such robots have to reason about how to pour without spilling, where to grasp a pot, how to open different containers, and so on. To enable such reasoning it is necessary to consider how objects are perceived, how motions can be executed and parameterized, and how motion parameterization affects the physical effects of actions. To this end, we propose to complement and extend symbolic reasoning methods with KnowRobSIM, an additional reasoning infrastructure based on modern game engine technology, including the subsymbolic world modeling through data structures, action simulation based on physics engine, and world scene rendering. We demonstrate how KnowRobSIM can perform powerful reasoning, prediction, and learning tasks that are required for informed decision making in object manipulation.


Title: Probabilistic Collision Threat Assessment for Autonomous Driving at Road Intersections Inclusive of Vehicles in Violation of Traffic Rules
Key Words: belief networks  collision avoidance  decision making  mobile robots  probability  road safety  road traffic  road vehicles  traffic rules violation  vehicles road intersections inclusive  Bayesian networks  time window filtering  decision-making  in-vehicle testing  nonviolation vehicles  closed urban test road  violation vehicles  autonomous vehicle  probabilistic collision threat assessment algorithm  autonomous driving  Roads  Reliability  Principal component analysis  Probabilistic logic  Prediction algorithms  Autonomous vehicles 
Abstract: In this paper, we propose a probabilistic collision threat assessment algorithm for autonomous driving at road intersections that assesses a given traffic situation at an intersection reliably and robustly for an autonomous vehicle to cross the intersection safely, even in the face of violation vehicles (that is, vehicles in violation of traffic rules at the intersection). To this end, the proposed algorithm employs a detailed digital map to predict future paths of observed vehicles and then utilizes the predicted future paths to identify potential threats (vehicles) and potential collision areas, regardless of whether observed vehicles are obeying traffic rules at the intersection. Next, by means of Bayesian networks and time window filtering under an independent and distributed reasoning structure, it assesses the potential threats regarding the possibility of collision reliably and robustly, even under uncertain and incomplete noise data. Then, it has been tested and evaluated through in-vehicle testing on a closed urban test road under traffic conditions inclusive of non-violation and violation vehicles. In-vehicle testing results show that the performance of the proposed algorithm is sufficiently reliable to be used in decision-making for autonomous driving at intersections in terms of reliability and robustness, even in the face of violation vehicles.


Title: Search-Based Optimal Motion Planning for Automated Driving
Key Words: mobile robots  optimisation  path planning  road vehicles  search problems  trajectory control  automated driving  fast motion planning  robust motion planning  real-time computation  urban conditions  convenient geometrical representation  search space  driving constraints  classical path planning approach  exact cost-to-go map  optimal motion trajectory  time horizons  fast driving conditions  slow driving conditions  search-based optimal motion planning  Planning  Vehicle dynamics  Trajectory  Dynamics  Roads  Search problems  Automation  motion planning  automated driving  lane change  multi-lane driving  traffic lights  A* search  MPC 
Abstract: This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.


Title: Transferable Pedestrian Motion Prediction Models at Intersections
Key Words: automobiles  feature selection  learning (artificial intelligence)  mobile robots  pedestrians  road safety  statistical analysis  trajectory control  autonomous cars  transfer learning algorithms  pedestrian trajectories  transferable pedestrian motion prediction algorithm  trajectory planning  inverse reinforcement learning  feature selection  IRL  augmented seminonnegative sparse coding  ASNSC  Trajectory  Hidden Markov models  Semantics  Predictive models  Prediction algorithms  Feature extraction  Reinforcement learning 
Abstract: One desirable capability of autonomous cars is to accurately predict the pedestrian motion near intersections for safe and efficient trajectory planning. We are interested in developing transfer learning algorithms that can be trained on the pedestrian trajectories collected at one intersection and yet still provide accurate predictions of the trajectories at another, previously unseen intersection. We first discussed the feature selection for transferable pedestrian motion models in general. Following this discussion, we developed one transferable pedestrian motion prediction algorithm based on Inverse Reinforcement Learning (IRL) that infers pedestrian intentions and predicts future trajectories based on observed trajectory. We evaluated our algorithm at three intersections. We used the accuracy of augmented semi-nonnegative sparse coding (ASNSC), trained and tested at the same intersection as a baseline. The result shows that the proposed algorithm improves the baseline accuracy by a statistically significant percentage in both non-transfer task and transfer task.


Title: Model-Free Grasp Planning for Configurable Vacuum Grippers
Key Words: data acquisition  dexterous manipulators  grippers  path planning  robot vision  model-free grasp planning  adequate sensor-based surface acquisition  two-step 3D data acquisition approach  action execution  iterative grasp planning  visual detection  arbitrary suction cups  contact surfaces  formalized aspects  arbitrary positions  robustly grasp unknown objects  grasp planner  robot arm  visual sensor  dynamically configurable vacuum gripper  robot system  optimal grasp configurations  configurable vacuum gripper system  Grippers  Three-dimensional displays  Planning  Grasping  Robot sensing systems  Force 
Abstract: A concept consisting of a new configurable vacuum gripper system and a corresponding method for determining optimal grasp configurations solely based on 3D vision is introduced. The robot system consists of a dynamically configurable vacuum gripper, a visual sensor, and a robot arm that are used in combination with a new grasp planner to robustly grasp unknown objects in arbitrary positions. For this purpose, formalized aspects of selecting contact surfaces for arbitrary suction cups are described; the concept involves visual detection of the objects, segmentation, iterative grasp planning, and action execution. The approach allows for a fast and efficient, yet precise execution of grasps. The core idea is a two-step 3D data acquisition approach and grasp point computation that takes advantage of the fact that the suction cups of the gripper can all be aligned axis-parallel. Therefore, an adequate sensor-based surface acquisition is done from a single viewpoint with respect to the gripper. Results of realworld experiments show that the proposed concept is suitable for a wide range of different and unknown objects in our setup.


Title: Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints
Key Words: actuators  biomechanics  dexterous manipulators  shear modulus  springs (mechanical)  grasping  fingered hand  machined spring  variable stiffness  human hands  gripping force  robot hands  thumb CM joint  MP joints  fingers  variable rigidity mechanism  joint mechanism  Springs  Joints  Thumb  Muscles  Actuators  Force  Wires 
Abstract: Human hands can not only grasp objects of various shape and size and manipulate them in hands but also exert such a large gripping force that they can support the body in the situations such as dangling a bar and climbing a ladder. On the other hand, it is difficult for most robot hands to manage both. Therefore in this paper we developed the hand which can grasp various objects and exert large gripping force. To develop such hand, we focused on the thumb CM joint with wide range of motion and the MP joints of four fingers with the DOF of abduction and adduction. Based on the hand with large gripping force and flexibility using machined spring, we applied above mentioned joint mechanism to the hand. The thumb CM joint has wide range of motion because of the combination of three machined springs and MP joints of four fingers have variable rigidity mechanism instead of driving each joint independently in order to move joint in limited space and by limited actuators. Using the developed hand, we achieved the grasping of various objects, supporting a large load and several motions with an arm.


Title: The Co-Gripper: A Wireless Cooperative Gripper for Safe Human Robot Interaction
Key Words: grippers  human-robot interaction  robust control  safe human robot interaction  intuitive control  industrial service applications  robotic device  manipulation tasks  modular underactuated structure  robotic arms  wearable wireless control interface  human operator  gripper performance  human-robot cooperation tasks  co-gripper  Grippers  Collaboration  Robot kinematics  Manipulators  Service robots  Wireless communication 
Abstract: In this paper, we introduce a set of guidelines for the design of grippers suitable for a safe human robot/interaction in cooperative tasks. Modularity, adaptability, robustness, intuitive control, limited weight are some of the key elements that could allow to effectively spread these devices in industrial and service applications. Following such guidelines, we present the prototype of the Co-Gripper: a robotic device for cooperative manipulation tasks with humans. The gripper is composed of two pairs of fingers, actuated with two motors, that can be controlled in a coordinated way or independently. Each finger has a modular underactuated structure, composed of three phalanges connected by passive joints. The gripper is wireless, so it can be easily connected both to the robotic arms and on passive structures. We designed a wearable wireless control interface composed of a ring and a bracelet allowing a simple and intuitive activation of the gripper without limiting human operator's manipulation capabilities. We performed a set of tests to quantify gripper performance and to exploit its potentialities in human-robot cooperation tasks.


Title: The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm
Key Words: assembling  design engineering  dexterous manipulators  grippers  industrial manipulators  manipulator kinematics  bimanual manipulation  electromechanical devices  classic dual arm manipulation  classic industrial robotic arms kinematics  general purpose grasping  KIT swiss knife gripper  disassembly tasks  robotic gripper design  dexterous in-hand manipulation  Grippers  Tools  Task analysis  Grasping  Manipulators  Service robots 
Abstract: This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.


Title: Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots
Key Words: collision avoidance  learning (artificial intelligence)  legged locomotion  microrobots  mobile robots  neural nets  robot dynamics  underactuated legged systems  hand-engineered controllers  dynamic maneuvers  complex terrains  real-world legged millirobot  learned neural network models  predictive model  expressive capacity neural network models  high-capacity neural network models  effective learning  dynamic legged millirobot  image-conditioned dynamics models  underactuated legged millirobots  low manufacturing costs  complex environments  highly dynamic systems  Vehicle dynamics  Legged locomotion  Neural networks  Adaptation models  Predictive models  Robot sensing systems 
Abstract: Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.


Title: Online Adaptation of Robot Pushing Control to Object Properties
Key Words: learning (artificial intelligence)  manipulators  mobile robots  path planning  unknown objects  data-driven approach  local inverse models  robot-object interaction  push manipulation  object behaviour  maximum a posteriori estimation  pushing objects  holonomic mobile robot base  diverse object set  learned inverse models  object properties  online adaptation  robot pushing control  robotic scenarios  real-world environments  MAP  Inverse problems  Adaptation models  Robot kinematics  Friction  Feedforward systems  Task analysis 
Abstract: Pushing is a common task in robotic scenarios. In real-world environments, robots need to manipulate various unknown objects without previous experience. We propose a data-driven approach for learning local inverse models of robot-object interaction for push manipulation. The robot makes observations of the object behaviour on the fly and adapts its movement direction. The proposed model is probabilistic, and we update it using maximum a posteriori (MAP) estimation. We test our method by pushing objects with a holonomic mobile robot base. Validation of results over a diverse object set demonstrates a high degree of robustness and a high success rate in pushing objects towards a fixed target and along a path compared to previous methods. Moreover, based on learned inverse models, the robot can learn object properties and distinguish between different object behaviours when they are pushed from different sides.


Title: Composable Learning with Sparse Kernel Representations
Key Words: collision avoidance  Hilbert spaces  learning (artificial intelligence)  mobile robots  sparse matrices  stochastic processes  obstacle-avoidance policies  Reproducing kernel Hilbert space  NAF  2D environment  sparse kernel representations  normalized advantage function  state-action function  nonparametric controllers  reinforcement learning algorithm  composable learning  Kernel  Stochastic processes  Hilbert space  Data models  Training  Complexity theory  Robots 
Abstract: We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.


Title: Compensating for Context by Learning Local Models of Perception Performance
Key Words: distance measurement  mobile robots  probability  robot vision  stereo image processing  perception performance  perception system performance  environmental geometry  probabilistic performance  monocular odometry systems  stereo visual odometry systems  system failures  ground robot  Context modeling  Visual odometry  Data models  Training data  Predictive models  Prediction algorithms 
Abstract: Perception system performance can vary dramatically with contextual factors such as environmental geometry, appearance, and other phenomena. In this work we present a theoretical framework for understanding the role of context in perception and discuss three approaches for predicting probabilistic performance from observations by efficiently learning local performance models. We compare these approaches with experiments on the monocular and stereo visual odometry systems for a ground robot, and show that they can effectively predict system failures in a wide variety of environments.


Title: Setting up a Reinforcement Learning Task with a Real-World Robot
Key Words: learning (artificial intelligence)  manipulators  multi-robot systems  hard-to-engineer adaptive solutions  complex tasks  diverse robotic tasks  reinforcement learning research  learning task  real-world robot  effective learning  learning performance  task setup  UR5 robotic arm  Task analysis  Robot sensing systems  Instruction sets  Delays  Reinforcement learning  Robot kinematics 
Abstract: Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.


Title: CINet: A Learning Based Approach to Incremental Context Modeling in Robots
Key Words: learning (artificial intelligence)  recurrent neural nets  robots  incremental context modeling  robots  rule-based approach  recurrent neural network  CINet  learning based approach  scene reasoning tasks  Context modeling  Training  Robots  Computational modeling  Resource management  Recurrent neural networks  Testing 
Abstract: There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we pose the task of when to increment as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks.


Title: Learning Generalizable Robot Skills from Demonstrations in Cluttered Environments
Key Words: collision avoidance  dexterous manipulators  intelligent robots  learning (artificial intelligence)  trajectory control  learning from demonstration  LfD approach  reaching skills  placing skills  7-DOF JACO2 manipulator  clutter-free environments  human demonstrations  cluttered environments  generalizable robot skills  salient human behavior  recent inference-based technique  incremental skill learning approach  importance weighted batch  Trajectory  Robots  Clamps  Covariance matrices  Collision avoidance  Stochastic processes  Clutter 
Abstract: Learning from Demonstration (LfD) is a popular approach to endowing robots with skills without having to program them by hand. Typically, LfD relies on human demonstrations in clutter-free environments. This prevents the demonstrations from being affected by irrelevant objects, whose influence can obfuscate the true intention of the human or the constraints of the desired skill. However, it is unrealistic to assume that the robot's environment can always be restructured to remove clutter when capturing human demonstrations. To contend with this problem, we develop an importance weighted batch and incremental skill learning approach, building on a recent inference-based technique for skill representation and reproduction. Our approach reduces unwanted environmental influences on the learned skill, while still capturing the salient human behavior. We provide both batch and incremental versions of our approach and validate our algorithms on a 7-DOF JACO2 manipulator with reaching and placing skills.


Title: Interacting with a “Transparent” Upper-Limb Exoskeleton: A Human Motor Control Approach
Key Words: biomechanics  human-robot interaction  medical robotics  motion control  neurophysiology  optimal control  patient rehabilitation  robot dynamics  robot kinematics  transparent upper-limb exoskeleton  human motor control approach  human-exoskeleton interaction  exoskeleton device  motor adaptation  human motor control research  as-transparent-as-possible contact/interaction forces  motor control laws  human movement  optimal control simulations  motor control features  Exoskeletons  Motor drives  Robots  Torque  Task analysis  Perturbation methods  Kinematics 
Abstract: Establishing a symbiotic relationship between a human and a exoskeleton is the end goal in many applications in order to provide benefits to the user. However, the literature focusing on the human side of human-exoskeleton interaction has remained less exhaustive than the literature focusing on the design (hardware/software) of the exoskeleton device itself. It is, though, essential to understand how a human adapts his motor control when interacting with an exoskeleton. Motor adaptation is an implicit process carried out by the central nervous system when the body encounters a perturbation, a paradigm that has been extensively studied in the field of human motor control research. When wearing an exoskeleton, even “as-transparent-as-possible”, contact/interaction forces may impact well-known motor control laws in a way that may be detrimental to the user, and even compromise usability in real applications. The present paper investigates how interaction with a backdrivable upper-limb exoskeleton (ABLE) set in “transparent” mode of control affects the kinematics/dynamics of human movement in a simple task. We find that important motor control features are preserved when moving with ABLE but an overall movement slowness occurs, likely as a response to increased inertia according to optimal control simulations. Such a human motor control approach illustrates one possible way to assess the degree of symbiosis between human and exoskeleton, i.e. by grounding on well-known findings in motor control research.


Title: Wearable Pediatric Gait Exoskeleton - A Feasibility Study
Key Words: gait analysis  medical robotics  muscle  orthotics  paediatrics  patient rehabilitation  metabolic degeneration  SMA patient rehabilitation  sit-to-stand movements  degrees-of-freedom  flexion-extension  adduction-abduction  muscle strength  wearable exoskeleton  gait assistance  feasibility test  ATLAS exoskeleton  Spinal Muscular Atrophy patients  wearable pediatric gait exoskeleton  Exoskeletons  Pediatrics  Diseases  Force  Torque  Hip  Biomimetics 
Abstract: This study reports the initial testing of a gait exoskeleton for Spinal Muscular Atrophy (SMA) patients having variable muscle strength with no balance or ambulation capabilities. To improve the quality of life of such patients, a pediatric gait exoskeleton was developed. The ATLAS exoskeleton has 8 active degrees of freedom (DOF): 2 at the hip (adduction/abduction and flexion/extension), 1 at the knee and ankle joint for flexion and extension. A feasibility test was performed to gauge the initial response of the patients. This study demonstrates that the exoskeleton was able to provide gait assistance and sit-to-stand movements effectively to the subjects. This kind of wearable exoskeleton will play a key role in the rehabilitation of SMA patients and delay further metabolic degeneration in the future.


Title: Verification of a Robotic Ankle Exoskeleton Control Scheme for Gait Assistance in Individuals with Cerebral Palsy
Key Words: gait analysis  handicapped aids  medical robotics  muscle  orthopaedics  orthotics  paediatrics  patient rehabilitation  wearable robots  robotic ankle exoskeleton control scheme  gait assistance  cerebral palsy  walking ability  pediatric health  pediatric physical disability  pathological gait patterns  CP  ankle-foot-orthoses  clinically relevant improvement  gait mechanics  orthopedic surgery  muscle injections  physical therapy  wearable exoskeletons  gait rehabilitation  initial clinical verification  instrumented gait analysis  positive ankle power  powered plantar-flexion assistance  reduced muscle function  powered assistance magnitude  powered assistance timing  net metabolic rate  locomotion  Exoskeletons  Legged locomotion  Torque  DC motors  Atmospheric measurements  Particle measurements  Muscles 
Abstract: Walking ability is critically important for pediatric health, well-being, and independence. Children with cerebral palsy (CP), the most prevalent cause of pediatric physical disability, often present pathological gait patterns that negatively impact walking capacity. Reduced function of the muscles surrounding the ankle joint in those with CP also greatly increases the energy cost of transport leading to reduce mobility. Ankle-foot-orthoses show limited effectiveness for clinically relevant improvement in gait mechanics, while orthopedic surgery, muscle injections and physical therapy are unable to completely restore gait function. While wearable exoskeletons hold promise for gait rehabilitation, appropriately controlling the timing and magnitude of powered assistance across individuals and conditions remains a considerable challenge. This work seeks to address this challenge through the design and initial clinical verification of a simple ankle exoskeleton control scheme designed to reduce the metabolic cost of transport during walking in an individual with CP. Preliminary experimental results from instrumented gait analysis following 5 training visits demonstrated a 45% increase in positive ankle power and a 16% reduction in net metabolic rate during walking with the exoskeleton providing powered plantar-flexion assistance compared to walking without the exoskeleton. Future work will expand this investigation to a larger cohort of individuals with CP and across additional modes of locomotion.


Title: Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training
Key Words: computer games  control engineering computing  haptic interfaces  medical computing  medical robotics  patient rehabilitation  user experience  virtual reality  game experience  Haptic Kitchen game  haptic guidance  haptic interaction  haptic performance balancing algorithm  spouse-controlled haptic support  patients post-stroke  robot-supported multiplayer rehabilitation  haptically linked patient-spouse training  robot-aided rehabilitation  multiplayer games  Air Hockey game  Games  Haptic interfaces  Training  Robots  Damping  Trajectory  Sports 
Abstract: Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.


Title: A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model
Key Words: actuators  biocontrol  biomechanics  bone  gait analysis  legged locomotion  medical robotics  mobile robots  muscle  springs (mechanical)  underlying biological mechanisms  wearable robot  wearable robotic device  human locomotion mechanics  wearable robotics  soft-exosuit enables multiscale analysis  bipedal animal model  biological system interface  Kinematics  Springs  Tendons  Robots  Birds  Fixtures 
Abstract: Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.


Title: Through-the-Lens Drone Filming
Key Words: autonomous aerial vehicles  cameras  feature extraction  Global Positioning System  image motion analysis  image sensors  mobile robots  pose estimation  robot vision  video signal processing  image composition  monocular 3D human pose estimation  drone control system  drone filming system  wearable GPS-based sensors  wearable infrared-based sensors  through-the-lens drone filming  aerial filming  camera control  drone hardware  human actions  drone camera system  through-the-lens camera planning  flight control  through-the-lens drone  wearable-sensor-based solutions  drone platform  outdoor environments  human movement  remote controller  action scenes  Cameras  Drones  Three-dimensional displays  Sensors  Pose estimation  Solid modeling  Two dimensional displays 
Abstract: Aerial filming in action scenes using a drone is difficult for inexperienced flyers because manipulating a remote controller and meeting the desired image composition are two independent, while concurrent, tasks. Existing systems attempt to utilize wearable GPS-based or infrared-based sensors to track the human movement and to assist in capturing footage. However, these sensors work only in either indoor (infrared-based) or outdoor environments (GPS-based), but not both. In this paper, we introduce a novel drone filming system which integrates monocular 3D human pose estimation and localization into a drone platform to remove the constraints imposed by wearable-sensor-based solutions. Meanwhile, given the estimated position, we propose a novel drone control system, called “through-the-lens drone filming”, to allow a cameraman to conveniently control the drone by manipulating a 3D model in the preview, which closes the gap between the flight control and the viewpoint design. Our system includes two key enabling techniques: 1) subject localization based on visual-inertial fusion, and 2) through-the-lens camera planning. This is the first drone camera system which allows users to capture human actions by manipulating the camera in a virtual environment. From the drone hardware, we integrate a gimbal camera and two GPUs into the limited space of a drone and demonstrate the feasibility of running the entire system onboard with insignificant delays, which are sufficient for filming in our real-time application. Experimental results, in both simulation and real-world scenarios, demonstrate that our techniques can greatly ease camera control and capture better videos.


Title: Towards Aerial Recovery of Parachute-Deployed Payloads
Key Words: aerospace robotics  aircraft control  mobile robots  position control  parachute-deployed payloads  sensor payloads  atmospheric profiling applications  inaccessible regions  multirotor unmanned aerial system  parachute-payload system  long-term payload transportation systems  aerial recovery  Payloads  Target tracking  Cameras  Robot sensing systems  Vehicle dynamics  Aerodynamics 
Abstract: Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.


Title: Airborne Docking for Multi-Rotor Aerial Manipulations
Key Words: autonomous aerial vehicles  mobile robots  multirotor aerial robots  transport multirotor UAV  winch mechanism  onboard locolization  mobile manipulation system  airborne docking method  IMU data  multirotor aerial manipulations  Winches  Bars  Cameras  Robot vision systems  DC motors  Propellers 
Abstract: We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.


Title: Optimal Time Allocation for Quadrotor Trajectory Generation
Key Words: autonomous aerial vehicles  convex programming  helicopters  mobile robots  optimal control  polynomials  robot dynamics  trajectory control  optimal time allocation  quadrotor flights  quadrotor trajectory generation problem  spatial trajectory  time optimization  polynomial trajectories  quadrotor platform  kinodynamic limits  autonomous flights  open-source ROS-package  temporal trajectory  convex program  mapping function  Trajectory  Resource management  Safety  Optimization  Acceleration  Time-domain analysis  Shape 
Abstract: In this paper, we present a framework to do optimal time allocation for quadrotor trajectory generation. Using this method, we can generate minimum-time piecewise polynomial trajectories for quadrotor flights. We decouple the quadrotor trajectory generation problem into two folds. Firstly we generate a smooth and safe curve which is parameterized by a virtual variable. This curve named spatial trajectory is independent of time and has fixed spatial properties. Then a mapping function which decides how the quadrotor moves along the spatial trajectory respecting kinodynamic limits is found by minimizing total trajectory time. The mapping function maps the virtual variable to time is named temporal trajectory. We formulate the minimum-time temporal trajectory generation problem as a convex program which can be efficiently solved. We show that the proposed method can corporate with various types of previous trajectory generation method to obtain the optimal time allocation. The proposed method is integrated into a customized light-weight quadrotor platform and is validated by presenting autonomous flights in indoor and outdoor environments. We release our code for time optimization as an open-source ros-package.


Title: Aerial Radio-Based Telemetry for Tracking Wildlife
Key Words: autonomous aerial vehicles  directive antennas  mobile radio  mobile robots  radio tracking  telemetry  aerial radio-based telemetry  measurement locations  radio collar  low-cost directional antenna  USB receiver  wedges  online strategy  measurement noise  autonomous aerial robot  wildlife tracking  localization uncertainty  Antenna measurements  Animals  Measurement uncertainty  Uncertainty  Time measurement  Sensors  Robots 
Abstract: This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.


Title: Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
Key Words: aerospace control  aerospace robotics  aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  path planning  robot dynamics  stability  multilinked model  near-hover condition  motion sequence  improved dynamics derivation  flight control method  flight stability  small opening  flight motion  transformable multilinked aerial robot  multilinked robot  transformable aerial robot  under-actuated multirotors  aggressive maneuvering  necessary condition  crucial problems  unknown obstacle  multirotor  robot body  Unmanned aerial vehicles  Rotors  Collision avoidance  Path planning  Stability analysis  Robot sensing systems 
Abstract: In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).


Title: LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain
Key Words: embedded systems  feature extraction  image segmentation  optical radar  optimisation  pose estimation  robot vision  SLAM (robots)  SLAM framework  edge features  feature extraction  point cloud segmentation  lightweight and ground-optimized lidar odometry  real-time six degree-of-freedom pose estimation  low-power embedded system  ground plane  two-step Levenberg-Marquardt optimization method  optimization steps  ground vehicles  LeGO-LOAM  Feature extraction  Three-dimensional displays  Laser radar  Image segmentation  Pose estimation  Real-time systems  Iterative closest point algorithm 
Abstract: We propose a lightweight and ground-optimized lidar odometry and mapping method, LeGO-LOAM, for realtime six degree-of-freedom pose estimation with ground vehicles. LeGO-LOAM is lightweight, as it can achieve realtime pose estimation on a low-power embedded system. LeGO-LOAM is ground-optimized, as it leverages the presence of a ground plane in its segmentation and optimization steps. We first apply point cloud segmentation to filter out noise, and feature extraction to obtain distinctive planar and edge features. A two-step Levenberg-Marquardt optimization method then uses the planar and edge features to solve different components of the six degree-of-freedom transformation across consecutive scans. We compare the performance of LeGO-LOAM with a state-of-the-art method, LOAM, using datasets gathered from variable-terrain environments with ground vehicles, and show that LeGO-LOAM achieves similar or better accuracy with reduced computational expense. We also integrate LeGO-LOAM into a SLAM framework to eliminate the pose estimation error caused by drift, which is tested using the KITTI dataset.


Title: Learning a Local Feature Descriptor for 3D LiDAR Scans
Key Words: convolutional neural nets  feature extraction  image matching  image representation  learning (artificial intelligence)  robot vision  SLAM (robots)  learned feature descriptor  3D local descriptors  local feature descriptor  3D LiDAR scans  robust data association  scan alignment algorithms  handcrafted feature descriptors  metric learning network  local surface patches  convolutional neural network  ground-truth correspondences  SLAM system  CNN  Siamese network  Three-dimensional displays  Measurement  Laser radar  Feature extraction  Streaming media  Task analysis  Gray-scale 
Abstract: Robust data association is necessary for virtually every SLAM system and finding corresponding points is typically a preprocessing step for scan alignment algorithms. Traditionally, handcrafted feature descriptors were used for these problems but recently learned descriptors have been shown to perform more robustly. In this work, we propose a local feature descriptor for 3D LiDAR scans. The descriptor is learned using a Convolutional Neural Network (CNN). Our proposed architecture consists of a Siamese network for learning a feature descriptor and a metric learning network for matching the descriptors. We also present a method for estimating local surface patches and obtaining ground-truth correspondences. In extensive experiments, we compare our learned feature descriptor with existing 3D local descriptors and report highly competitive results for multiple experiments in terms of matching accuracy and computation time.


Title: Hallucinating Robots: Inferring Obstacle Distances from Partial Laser Measurements
Key Words: collision avoidance  distance measurement  learning (artificial intelligence)  mobile robots  neural nets  optical scanners  hallucinating robots  obstacle distances  partial laser measurements  mobile robots  2D laser scanners  glass panels  richer sensor readings  RGBD sensors  raw 2D laser data  raw 2D laser distances  partial 2D laser readings  Lasers  Two dimensional displays  Measurement by laser beam  Robot sensing systems  Neural networks 
Abstract: Many mobile robots rely on 2D laser scanners for localization, mapping, and navigation. However, those sensors are unable to correctly provide distance to obstacles such as glass panels and tables whose actual occupancy is invisible at the height the sensor is measuring. In this work, instead of estimating the distance to obstacles from richer sensor readings such as 3D lasers or RGBD sensors, we present a method to estimate the distance directly from raw 2D laser data. To learn a mapping from raw 2D laser distances to obstacle distances we frame the problem as a learning task and train a neural network formed as an autoencoder. A novel configuration of network hyperparameters is proposed for the task at hand and is quantitatively validated on a test set. Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the trained network can successfully infer obstacle distances from partial 2D laser readings.


Title: Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder
Key Words: image sensors  object detection  optical radar  optical scanners  scan homogeneity  3D sensor homogeneity  spherical formulation  HDL-32 sensors  building full-3D lidars  robotics research  constant pitch angles  rolling DOF  RMBLs  complex 3D scan measurement distributions  spherical FOV  high-resolution scans  rotating multibeam lidars  degree-of-freedom  vertical resolution  high data rates  accessible 3D sensors  MBL  multibeam lidar scanners  multibeam Velodyne range-finder  Three-dimensional displays  Laser radar  Indexes  Kinematics  Robot sensing systems 
Abstract: Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.


Title: Laser Map Aided Visual Inertial Localization in Changing Environment
Key Words: cameras  geometry  optical radar  optimisation  robot vision  SLAM (robots)  map optimization  changing environment  bi-directional tasks  LiDAR-built map  online visual inertial odometry system  laser map aided visual inertial localization  geometry information  crossmodal data association  multisession laser  Visualization  Lasers  Bundle adjustment  Laser radar  Robots  Cameras 
Abstract: Long-term visual localization in outdoor environment is a challenging problem, especially faced with the cross-seasonal, bi-directional tasks and changing environment. In this paper we propose a novel visual inertial localization framework that localizes against the LiDAR-built map. Based on the geometry information of the laser map, a hybrid bundle adjustment framework is proposed, which estimates the poses of the cameras with respect to the prior laser map as well as optimizes the state variables of the online visual inertial odometry system simultaneously. For more accurate crossmodal data association, the laser map is optimized using multisession laser and visual data to extract the salient and stable subset for visual localization. To validate the efficiency of the proposed method, we collect data in south part of our campus in different seasons, along the same and opposite-direction route. In all sessions of localization data, our proposed method gives satisfactory results, and shows the superiority of the hybrid bundle adjustment and map optimization1.


Title: Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map
Key Words: feature extraction  optical radar  robot vision  SLAM (robots)  stereo image processing  simultaneous localization and mapping  scan context performance  Light Detection and Ranging scans  visual scenes  two-phase search algorithm  3D LiDAR scans  loop-detection invariant  nonhistogram-based global descriptor  global localization  diverse sensors  dense 3D maps  structural information  diverse feature detectors  3D point cloud map  place recognition  Three-dimensional displays  Sensors  Laser radar  Histograms  Shape  Visualization  Encoding 
Abstract: Compared to diverse feature detectors and descriptors used for visual scenes, describing a place using structural information is relatively less reported. Recent advances in simultaneous localization and mapping (SLAM) provides dense 3D maps of the environment and the localization is proposed by diverse sensors. Toward the global localization based on the structural information, we propose Scan Context, a non-histogram-based global descriptor from 3D Light Detection and Ranging (LiDAR) scans. Unlike previously reported methods, the proposed approach directly records a 3D structure of a visible space from a sensor and does not rely on a histogram or on prior training. In addition, this approach proposes the use of a similarity score to calculate the distance between two scan contexts and also a two-phase search algorithm to efficiently detect a loop. Scan context and its search algorithm make loop-detection invariant to LiDAR viewpoint changes so that loops can be detected in places such as reverse revisit and corner. Scan context performance has been evaluated via various benchmark datasets of 3D LiDAR scans, and the proposed method shows a sufficiently improved performance.


Title: Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping
Key Words: mobile robots  multi-robot systems  optimisation  path planning  probability  decentralised mission monitoring  spatiotemporal optimal stopping  multirobot variant  mission monitoring problem  multiple tracker robots  single target robot  multirobot systems  task performance  marine robotics missions  single-robot paths  probabilistic representation  decentralised scheme  useful analytical properties  planned trajectories  probabilistic motion  observation models  mission monitoring systems  Monitoring  Trajectory  Target tracking  Robot kinematics  Probabilistic logic  Predictive models 
Abstract: We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.


Title: Uncertain Local Leader Selection in Distributed Formations
Key Words: collision avoidance  control engineering computing  mobile robots  multi-robot systems  virtual local leader  accurate local leader  formation accuracy  individual robot  sensory uncertainty  distributed setting  optimal multirobot formation control  uncertain environment  desired formation  specific formation  desired destination  single robot  local leaders  specific predefined angle  hierarchical form  Leader-Follower  distributed formations  uncertain local leader selection  visible robots  Robot sensing systems  Reliability  Shape  Uncertainty  Task analysis 
Abstract: Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.


Title: Electing an Approximate Center in a Huge Modular Robot with the k-BFS SumSweep Algorithm
Key Words: approximation theory  distributed control  embedded systems  large-scale systems  mobile robots  multi-robot systems  tree searching  asynchronous distributed embedded systems  distributed system coordination  approximation algorithm  memory per node  neighboring modules  lattice structure  resource-constrained identical modules  distributed modular robotic ensembles  huge modular robot  large-scale systems  hardware modular robots  approximate-center node  k-BFS SumSweep algorithm  Approximation algorithms  Robot kinematics  Voting  Heuristic algorithms  Probabilistic logic  Embedded systems  Distributed algorithm  Modular robots  Center election 
Abstract: Among the diversity of the existing modular robotic systems, we consider in this paper the subset of distributed modular robotic ensembles composed of resource-constrained identical modules that are organized in a lattice structure and which can only communicate with neighboring modules. These modular robotic ensembles form asynchronous distributed embedded systems. In many algorithms dedicated to distributed system coordination, a specific role has to be played by a leader, i.e., a single node in the system. This leader can be elected using various criteria. A possible strategy is to elect a center node, i.e., a node that has the minimum distance to all the other nodes. Indeed, this node is ideally located to communicate with all the others and this leads to better performance in many algorithms. The contribution of this paper is to propose the k-BFS SumSweep algorithm designed to elect an approximate-center node. We evaluated our algorithm both on hardware modular robots and in a simulator for large ensembles of robots. Experimental results show that k-BFS SumSweep is often the most accurate approximation algorithm (with an average relative accuracy between 90% to 100%) while using the fewest messages in large-scale systems, requiring only a modest amount of memory per node, and converging in a reasonable length of time.


Title: A New Characterization of Mobility for Distance-Bearing Formations of Unicycle Robots
Key Words: mobile robots  multi-agent systems  multi-robot systems  position control  trajectory control  multiagent systems  classification task  conventional centered wheel  distance-bearing formations  unicycle robots  distance-bearing constraints  macro-robot  regular convex polygon  trajectory-tracking control problem  Mobile robots  Wheels  Robot kinematics  Kinematics  Vehicle dynamics  Axles 
Abstract: In this paper, we present a new characterization of mobility for formations of unicycle robots defined by distance-bearing constraints. In fact, by introducing a simple reduction procedure which associates a prescribed formation with a “macro-robot”, we extend the classification by type proposed by Campion et al., to multi-agent systems. To simplify the classification task, which only leverages the nonslip condition for a conventional centered wheel, we assume that the robots are disposed at the vertices of a regular convex polygon. We demonstrate the practical utility of the notion of macro-robot in a trajectory-tracking control problem for a formation of unicycles.


Title: Modeling and Control of Multiple Aerial-Ground Manipulator System (MAGMaS) with Load Flexibility
Key Words: aerospace robotics  manipulators  mobile robots  multi-robot systems  vibration control  MAGMaS  load flexibility  heterogeneous system  aerial robot  rigid load manipulation  load weight holding  long-slender object manipulation  multiple aerial-ground manipulator system  flexible load-tip pose tracking  vibration suppression controllability  Unmanned aerial vehicles  Manipulators  Load modeling  Vibrations  Mathematical model  Shape 
Abstract: The MAGMaS (Multiple Aerial-Ground Manipulator System) was proposed in [1] as a heterogeneous system composed of multiple ground (mobile) manipulators and aerial robots to collaboratively manipulate a long/large-sized object and demonstrated therein for rigid load manipulation. Here, we extend this result of [1] to the case of load manipulation with flexibility, which is crucial for long/slender object manipulation, yet, not considered in [1]. We first provide a rigorous modeling of the load flexibility and its effects on the MAGMaS dynamics. We then propose a novel collaborative control framework for flexible load-tip pose tracking, where the ground manipulator provides slower nominal pose tracking with overall load weight holding, whereas the aerial robot allows for faster vibration suppression with some load weight sharing. We also discuss the issue of controllability stemming from that the aerial robot provides less number of actuation than the modes of the load flexibility; and elucidate some peculiar conditions for this vibration suppression controllability. Simulations are also performed to demonstrate the effectiveness of the proposed theory.


Title: Determining Effective Swarm Sizes for Multi-Job Type Missions
Key Words: multi-agent systems  multi-robot systems  optimisation  particle swarm optimisation  queueing theory  sensitivity analysis  vehicle routing  sensitivity analysis  M/M/k/k queuing model  swarm search and service mission  SSS mission  swarm sizes  DVR  dynamic vehicle routing  multijob type missions  multiagent framework  balancing vehicle allocation  human operators  Robot sensing systems  Routing  Time factors  Planning  Task analysis 
Abstract: Swarm search and service (SSS) missions require large swarms to simultaneously search an area while servicing jobs as they are encountered. Jobs must be immediately serviced and can be one of several different job types - each requiring a different service time and number of vehicles to complete its service successfully. After jobs are serviced, vehicles are returned to the swarm and become available for reallocation. As part of SSS mission planning, human operators must determine the number of vehicles needed to achieve this balance. The complexities associated with balancing vehicle allocation to multiple as yet unknown tasks with returning vehicles makes this extremely difficult for humans. Previous work assumes that all system jobs are known ahead of time or that vehicles move independently of each other in a multi-agent framework. We present a dynamic vehicle routing (DVR) framework whose policies optimally allocate vehicles as jobs arrive. By incorporating time constraints into the DVR framework, an M/M/k/k queuing model can be used to evaluate overall steady state system performance for a given swarm size. Using these estimates, operators can rapidly compare system performance across different configurations, leading to more effective choices for swarm size. A sensitivity analysis is performed and its results are compared with the model, illustrating the appropriateness of our method to problems of plausible scale and complexity.


Title: Multi-Robot Virtual Structure Switching and Formation Changing Strategy in an Unknown Occluded Environment
Key Words: collision avoidance  hierarchical systems  multi-robot systems  stability  switching systems (control)  trees (mathematics)  multirobot virtual structure switching  formation changing strategy  region-based shape controller  swarm-robotic framework  traditional obstacle-avoidance problem  virtual structure methodology  triangular formation  shrinking phenomena  variable structure  two-layer hierarchical control strategy  inter-agent formation  spanning-tree-assisted-shape-matching algorithm  stability analysis  Shape  Robots  Switches  Convergence  Simulation  Stability analysis 
Abstract: This paper presents a switching strategy of a region-based shape controller for a swarm-robotic framework to overcome the traditional obstacle-avoidance problem in the virtual structure methodology. In this control approach, initially, the robots move as a group inside a circular region which we conceive to be the initial virtual structure, while preserving a specific pattern, say a triangular formation, among them. In order to avoid static/dynamic obstacles, while approaching towards the target without any prior knowledge about the environment, the virtual-circle is allowed to shrink up to a certain limit. The shrinking phenomena of the virtual circle will depend upon the number of agents within the circle and the distance between two the nearest obstacles sensed by the agents through which the swarm should be able to pass. If the situation demands, the structure may assume the shape of an ellipse of equivalent area continually throughout the path described by the swarm encapsulated within the variable structure. To achieve this, two-layer hierarchical control strategy has been proposed. Moreover, if the shape of the virtual structure changes, the formation of the swarm inside the region may also change. To make the inter-agent formation flexible inside the newly formed virtual structure, a spanning-tree-assisted-shape-matching algorithm has been employed for accommodating all the agents inside the virtual region which helps in the formation change in the agents as well. Finally, simulation results and stability analysis of the controllers are provided to demonstrate our proposed technique.


Title: Distributed Sensing Subject to Temporal Logic Constraints
Key Words: entropy  formal specification  greedy algorithms  multi-agent systems  optimisation  temporal logic  distributed sensing subject  temporal logic constraints  temporal logic specifications  local objective functions  motion plans  objective function  information entropy  unassigned agents  satisfaction guarantees  optimality loss  local greedy minimization  TL constraints  specification complexity  TL specification  product automaton based approach  Robot sensing systems  Linear programming  Task analysis  Planning  Automata 
Abstract: This paper considers the combination of temporal logic (TL) specifications and local objective functions to create online, multiagent, motion plans. These plans are guaranteed to satisfy a persistent mission TL specification and locally optimize an objective function (e.g. in this paper, a cost based on information entropy). The presented approach decouples the two tasks by assigning sub-teams of agents to fulfill the TL specification, while unassigned agents optimize the objective function locally. This paper also presents a novel decoupling of the classic product automaton based approach while maintaining satisfaction guarantees. We also qualitatively show that optimality loss in the local greedy minimization due to the TL constraints can be approximated based on specification complexity. This approach is evaluated with a set of simulations and an experiment of 6 robots with real sensors.


Title: A New Robot Fly Design That is Easier to Fabricate and Capable of Flight and Ground Locomotion
Key Words: aerodynamics  aerospace components  aerospace robotics  feedback  microrobots  mobile robots  stability  new robot fly design  insect-sized  potential advantages  larger robots  greater deployment numbers  previous iterations  locomotion capabilities  additionally land  long legs  wing-driven ground locomotion  flapping wings  landing  extremely confined spaces  simplifying fabrication  feedback-stabilized flights  Actuators  Legged locomotion  Fabrication  Laminates  Laser beam cutting  Solid lasers 
Abstract: Efforts to engineer insect-sized (~100 mg) robots are motivated by their potential advantages relative to larger robots, such as greater deployment numbers at the same cost. Previous iterations have demonstrated controlled flight, but were limited in terms of locomotion capabilities outside of flight. They also consisted of many parts, making them difficult to fabricate. Here we present a re-design that lowers the center of mass, allowing the robot to additionally land without the need for long legs. Furthermore, we show that the new design allows for wing-driven ground locomotion. This is achieved by varying the speed of downstroke relative to the upstroke of the flapping wings, which also allows for steering. By landing and subsequently moving along the ground, the robot can negotiate extremely confined spaces and underneath obstacles, as well as navigate to precise locations for sensing operations. The new design also drastically reduces the number of parts, simplifying fabrication. We describe the new design in detail and present results demonstrating these capabilities, as well as feedback-stabilized flights.


Title: Milligram-Scale Micro Aerial Vehicle Design for Low-Voltage Operation
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  electromagnetic actuators  microrobots  milligram-scale microaerial vehicle design  low-voltage operation  wing-span  wing aerial vehicle  electromagnetic actuator  low-voltage input  actuation  single resonant mechanism  small-linear-displacement amplifying stages  ±45° wing strokes  ±45° wing plane  energy efficient electromagnetic design  electromagnetic works  mass 70.0 mg  size 3.0 cm  mass 60.0 mg  voltage 5.5 V  frequency 98.0 Hz  power 250.0 mW  mass 100.0 mg  Magnetic resonance  Actuators  Springs  Magnetic separation  Loss measurement  Mathematical model  Laser beams 
Abstract: We present a 70mg, 3cm wing-span, flapping wing aerial vehicle capable of generating up to 60mg of lift using an electromagnetic actuator with low-voltage input (≈5.5V). Its design is novel, with the actuation and transmission integrated into a single resonant mechanism, thus not requiring any small-linear-displacement amplifying stages seen in other works. It can produce ±45° wing strokes and ±45° wing plane rotations at 98Hz operation mimicking relevant insects at this size scale. With required input power of only 250mW, it is, to the best of our knowledge, the most energy efficient electromagnetic design at the sub-100mg scale reported to date, and an order of magnitude more efficient than all other electromagnetic works.


Title: Repeatability and Reproducibility Analysis of a Multistable Module Devoted to Digital Microrobotics
Key Words: digital control  mechanical stability  micromanipulators  micromechanical devices  microrobots  robot dynamics  mechanical stability  complex control strategies  bistable modules  mechanism size  repeatability analysis  multistable module  DiMiBot robots  digital microrobotics  complex systems  multistable prototype  multiple modules  reproducibility analysis  miniaturized structure  discrete stable positions  Clamps  Actuators  Prototypes  Task analysis  Switches  Silicon  Micromechanical devices 
Abstract: The digital microrobot, called DiMiBot, opened a new paradigm in the design of microrobots by using mechanical stability instead of complex control strategies. Current DiMiBot robots are based on the use of bistable modules to reach discrete stable positions. However, the number of stable positions depends on the number of bistable modules. As a consequence, the mechanism size increases rapidly and its miniaturization becomes complex and non-intuitive. To tackle this issue, a new multistable module has been developed to reach several stable positions within a miniaturized structure. In this paper, we focus on the reapitability and the reproducibility analysis of the developed multistable module in terms of displacement. This study is mandatory to demonstrate the effectiveness of the module as it is expected to be an elementary component of the next generation of DiMiBot. To this end, a series of experimental measurements are conducted on individual and multiple modules. The results analysis show a good agreement between the theoretical and the experimental displacements. In other words, the multistable prototype is able to reach 13 stable positions linearly in one dimensional direction with a step of about 10 μm. These capabilities open a promising perspectives and applications of this module to achieve microrobotics tasks. For example, it can be integrated in complex systems devoted to advanced tasks or accurate positioning in MEMS devices.


Title: Depth Estimation of Optically Transparent Microrobots Using Convolutional and Recurrent Neural Networks
Key Words: closed loop systems  convolutional neural nets  learning (artificial intelligence)  microrobots  neurocontrollers  pose estimation  position control  recurrent neural nets  regression analysis  robot vision  three-dimensional printing  optically transparent microrobots  closed-loop control techniques  depth estimation method  supervised learning  depth regression model  3D-printed microrobots  recurrent neural networks  convolutional neural networks  optical tweezers setup  three-dimensional position estimation  long short-term memory cell  Three-dimensional displays  Estimation  Solid modeling  Optical imaging  Lighting  Data models  Microscopy 
Abstract: Estimating the three-dimensional (3D) position of microrobots is necessary in order to develop closed-loop control techniques and to improve the user's 3D perception in the micro-scale. This paper describes a depth estimation method based on supervised learning for optically transparent microrobots of known geometry. The proposed methodology uses Convolutional Neural Networks (CNNs) combined with a Recurrent Network, in particular a Long Short-Term Memory (LSTM) cell for depth regression. The proposed depth regression model is independent of the 3D orientation of the microrobot and is robust to varying illumination levels while it uses learned data-specific features. The model is trained and validated using microscope images and ground truth data generated from 3D-printed microrobots imaged in an Optical Tweezers (OT) setup. The validation results demonstrate that the proposed trained model can reconstruct the depth of the microrobot independently of its 3D orientation with submicron accuracy for the test set.


Title: On Designing 2D Discrete Workspacesto Sort or Classify Polyominoes
Key Words: materials handling  robotic assembly  polyominoes sorting  2D discrete workspace design  dynamic sensorless classifiers  orthoconvex polyominoes  grid-based workspace  Sorting  Shape  Robot sensing systems  Two dimensional displays  Machine vision  Cams  Dynamics 
Abstract: This paper studies the general problem of physically sorting polyominoes according to shape using a 2D, rigid, grid-based workspace. The workspace is designed for sensorless operation, using a fixed set of open-loop force-field inputs that move a polyomino from an inlet port to an outlet port that corresponds to the polyomino's shape, and reset the workspace to classify the next polyomino. This paper proves that static workspaces can classify all orthoconvex polyominoes of width w and height h, and provides a motion sequence and required size of workspace as a function of wand h. By allowing moving polyomino cams that assist in the sorting, we can design dynamic works paces that can sort all polyomi-noes that are “completely filled” using a constant number of force-field inputs. Hardware experiments using magnetic and gravity-based actuation demonstrate these static and dynamic sensorless classifiers at the millimeter scale.


Title: Miniature Robot Finger Using a Micro Linear Ultrasonic Motor and a Closed-Loop Linkage
Key Words: closed loop systems  controllability  dexterous manipulators  end effectors  force control  linear motors  microactuators  microrobots  ultrasonic motors  miniature robot finger  microrobot hands  microlinear ultrasonic motor prototype  closed-loop six-bar-linkage mechanism  microfabrication  Acoustics  Stators  Robots  Couplings  Actuators  Electrodes  Vibrations 
Abstract: To prioritize miniaturization, the actuators of micro robot hands are placed far from the end effectors, but such mechanisms restrict controllability and dexterity. We propose a miniature robot finger driven by a new micro linear ultrasonic motor as a key component for micro robot hands. It enables dexterous and multiple motions for micro hands used in limited spaces. In this paper, we build a new micro linear ultrasonic motor involving a cuboid stator with a side length of approximately 2 mm, making it one of the smallest linear motors. The micro linear ultrasonic motor prototype shows an output torque of approximately 7.75 mN at low voltage operation, which is sufficient force to handle tiny objects. The miniature finger, a closed-loop six-bar-linkage mechanism, is built by micro fabrication and connected to the motor prototype. The first demonstration of the miniature finger is shown under a high-speed camera with a high power lens.


Title: Force/Velocity Manipulability Analysis for 3D Continuum Robots
Key Words: dexterous manipulators  mobile robots  path planning  continuum robots  continuum manipulators  effective manipulation  rigid robots  manipulability indices  unified force-velocity manipulability  concentric-tube robot  manipulability measurement  force-velocity manipulability analysis  Robot kinematics  Indexes  Force  Manipulators  Jacobian matrices  Ellipsoids 
Abstract: The enhanced dexterity and manipulability offered by continuum manipulators makes them the robots of choice for complex procedures inside the human body. However, without tailored analytical tools to evaluate their manipulability, many capabilities of continuum robots such as safe and effective manipulation will remain largely inaccessible. This paper presents a quantifiable measure for analysing force/velocity manipulability of continuum robots. We expand classical measures of manipulability for rigid robots to introduce three types of manipulability indices to continuum robots, namely, velocity, compliance, and unified force-velocity manipulability. We provide a specific case study using the proposed method to analyse the force/velocity manipulability for a concentric-tube robot. We investigate the application of the manipulability measures to compare performance of continuum robots in terms of compliance and force-velocity manipulability. The proposed manipulability measures enable future research on design and optimal path planning for continuum robots.


Title: Analysis of Dynamic Response of an MRI-Guided Magnetically-Actuated Steerable Catheter System
Key Words: biomedical MRI  catheters  closed loop systems  control nonlinearities  dynamic response  frequency response  linearisation techniques  magnetic actuators  medical image processing  medical robotics  open loop systems  robot vision  MRI-guided magnetically-actuated steerable catheter system  free-space open-loop dynamic response analysis  magnetically-actuated steerable intra-vascular catheter system  current carrying microcoils  magnetic torques  system nonlinearity  pendulum model  approximate input-output linearization  black-box system identification approach  frequency response analysis  camera system  free-space trajectories  robotic catheter  MRI guidance  magnetic resonance imaging scanner  free-space closed-loop control  Nyquist frequency  Catheters  Coils  Magnetic resonance imaging  Torque  Robots  Chirp  Trajectory 
Abstract: This paper presents a free-space open-loop dynamic response analysis for an MRI -guided magnetically-actuated steerable intra-vascular catheter system. The catheter tip is embedded with a set of current carrying micro-coils. The catheter is directly actuated via the magnetic torques generated on these coils by the magnetic field of the magnetic resonance imaging (MRI)scanner. The relationship between the input current commands and catheter tip deflection angle presents an inherent nonlinearity in the proposed catheter system. The system nonlinearity is analyzed by utilizing a pendulum model. The pendulum model is used to describe the system nonlinearity and to perform an approximate input-output linearization. Then, a black-box system identification approach is performed for frequency response analysis of the linearized dynamics. The optimal estimated model is reduced by observing the modes and considering the Nyquist frequency of the camera system that is used to track the catheter motion. The reduced model is experimentally validated with 3D open-loop Cartesian free-space trajectories. This study paves the way for effective and accurate free-space closed-loop control of the robotic catheter with real-time feedback from MRI guidance in subsequent research.


Title: Development and validation of MRI compatible pediatric surgical robot with modular tooling for bone biopsy
Key Words: biomedical MRI  bone  medical robotics  paediatrics  phantoms  surgery  tumours  PSR-BBT  cortical bone phantoms  cancellous bone phantoms  MRI testing  T1-FFE  T2-FFE  MR-guided robotic surgery  modular Tooling  magnetic resonance imaging  MR-compatible tools  surgical accuracy  Pediatric Surgery Robot platform  modular tool interface  Bone Biopsy Tooling  modified titanium bone biopsy needle  joint Cartesian level control  MRI compatible pediatric surgical robot  lesion  tumor  5-DOF robot  Philips Achieva 3.0T MRI bore  surgical preplanning  control interface  Cartesian level control  axial force  signal-to-noise ratio variation  geometric distortion  magnetic flux density 3 T  Biopsy  Bones  Magnetic resonance imaging  Robots  Surgery  Signal to noise ratio  Tools 
Abstract: In clinical practice, magnetic resonance imaging (MRI) is used to locate a lesion/tumor for bone biopsy in children. However, there is a lack of MR-compatible tools that can be used simultaneously during imaging and biopsy while maintaining surgical accuracy and safety. The Pediatric Surgery Robot (PSR) platform is a 5-DOF robot with a modular tool interface. For the case of bone biopsy, a Bone Biopsy Tooling (BBT) is attached. It is designed to fit within a Philips Achieva 3.0T MRI bore and carry a modified titanium bone biopsy needle. A surgical pre-planning and control interface has been developed for joint and Cartesian level control. The PSR-BBT has demonstrated 1.65 +/- 1.77 mm accuracy in Cartesian control in free space. The PSR-BBT can generate 12.46 +/- 0.32 N of axial force while drilling at a speed of 30 rpm, which is sufficient for cortical and cancellous bone phantoms. Under MRI testing (T1-FFE, T1-SE, T2-FFE and T2-TSE scans), the system demonstrated less than 33% signal-to-noise ratio variation while drilling and a 0.46% geometric distortion while powered on without significantly impacting MRI guidance in situ. These results show that the PSR-BBT can allow the user to simultaneously image and perform the biopsy and presents the PSR as a viable platform for MR-guided robotic surgery.


Title: Trigonometric Ratio-Based Remote Center of Motion Mechanism for Bone Drilling
Key Words: actuators  bone  medical robotics  motion control  orthopaedics  robot vision  surgery  bone drilling robotic systems  drill alignment  RCM mechanism  remote center of motion mechanism  surgical procedures  linear actuators  gearless arc-guide  vision-guided navigation system  orientation guidance  trigonometric ratio  Bones  Robots  Surgery  Actuators  Force  Computed tomography  Task analysis  Remote center of motion mechanism  surgical robotics  vision-guided navigation  bone drilling 
Abstract: The remote center of motion (RCM) mechanism is a prominent candidate to aid bone drilling. The surgeon can simply place a drill with the RCM mechanism near the entry point to provide drill alignment with the target. Using this assistive mechanism for bone drilling improves drilling accuracy and reduces the complexity of bone drilling robotic systems. However, because most RCM mechanisms have been developed for laparoscopic surgery or needle insertion into soft tissue, they lack rigidity and are unsuitable for bone drilling. One of the most difficult and important surgical procedures in bone drilling is maintaining as well as guiding the orientation of the drill with respect to the target. This paper proposes an improved RCM mechanism in which a pair of linear actuators and a gearless arc-guide are employed to achieve high rigidity and resolution, which enable bone drilling. A vision-guided navigation system is also integrated into the proposed system to automatically guide the orientation. To verify that the proposed RCM mechanism has sufficient rigidity and targeting accuracy, a series of experiments was performed. The results obtained confirm that the proposed mechanism can maintain its tilting angle under up to 50 N, with a targeting error of approximately 0.28mm.


Title: Rolling-Joint Design Optimization for Tendon Driven Snake-Like Surgical Robots
Key Words: manipulators  medical robotics  surgery  tendon driven snake-like surgical robots  intra-luminal procedures  flexibility  serial rolling-joints  base architecture  joint angle range  tendons  rolling-joint design optimization  optimized joints  Tendons  Tools  Navigation  Robot sensing systems  Mathematical model  Three-dimensional displays 
Abstract: The use of snake-like robots for surgery is a popular choice for intra-luminal procedures. In practice, the requirements for strength, flexibility and accuracy are difficult to be satisfied simultaneously. This paper presents a computational approach for optimizing the design of a snake-like robot using serial rolling-joints and tendons as the base architecture. The method optimizes the design in terms of joint angle range and tendon placement to prevent the tendons and joints from colliding during bending motion. The resulting optimized joints were manufactured using 3D printing. The robot was characterized in terms of workspace, dexterity, precision and manipulation forces. The results show a repeatability as low as 0.9mm and manipulation forces of up to 5.6N.


Title: Enhancing the Command-Following Bandwidth for Transparent Bilateral Teleoperation
Key Words: mobile robots  motion control  telerobotics  command-following bandwidth  transparent bilateral teleoperation  slave robot motion controller  high motion controller gain  human user  successive stiffness increment approach  SSI approach  bilateral teleoperation controller  Pressing  Force  Bandwidth  Haptic interfaces  Trajectory  Manipulators 
Abstract: Enhancing transparency of a teleoperation system by increasing the command-following bandwidth has not received lots of attention so far. This is considered a challenging task since in a teleoperation system the command-following bandwidth of the slave robot motion controller cannot be increased with a conventional motion controller as the desired trajectory is instantaneously commanded by the human user and thus, cannot be considered to be given in a pre-computed, smooth second order derivative form. We propose a method to increase the command-following bandwidth by extending the previously introduced Successive Stiffness Increment (SSI) approach to bilateral teleoperation. The approach allows realizing a very high motion controller gain, which cannot be realized with a conventional bilateral teleoperation controller as confirmed by experimental results.


Title: Transparency-Optimal Passivity Layer Design for Time-Domain Control of Multi-DoF Haptic-Enabled Teleoperation
Key Words: haptic interfaces  optimisation  telerobotics  time-domain scheme  optimization problem  optimization-based passivity control algorithm  virtual teleoperated environment  real-time implementation  optimal transparency  energy-bounding control  haptic-enabled bilateral teleoperation systems  multiDoF  time-domain control  transparency-optimal passivity layer design  Force  Task analysis  Computer architecture  Robots  Indexes  Time-domain analysis  Haptic interfaces 
Abstract: This paper presents a novel optimization-based passivity control algorithm for haptic-enabled bilateral teleoperation systems involving multiple degrees of freedom. In particular, in the context of energy-bounding control, the contribution focuses on the implementation of a passivity layer for an existing time-domain scheme, ensuring optimal transparency of the interaction along subsets of the environment space which are preponderant for the given task, while preserving the energy bounds required for passivity. The involved optimization problem is convex and amenable to real-time implementation. The effectiveness of the proposed design is validated via an experiment performed on a virtual teleoperated environment.


Title: Development and Evaluation of an Intuitive Flexible Interface for Teleoperating Soft Growing Robots
Key Words: bending  mobile robots  path planning  service robots  telerobotics  user interfaces  intuitive flexible interface  teleoperating soft growing robots  robotic systems design  tip-extending  navigation  disaster scenarios  intuitive human control  intuitively map human bending  shape information  command mappings  developed interface  commercially available interfaces  virtual task scenarios  shape mapping  vine robot rolls  Shape  Robot sensing systems  Robot kinematics  Three-dimensional displays  Kinematics  Current measurement 
Abstract: Mobility by growth is a new paradigm in robotic systems design and their applications in the real world. Soft, tip-extending, or “growing”, robots have potential applications including inspection and navigation in disaster scenarios. However, due to their growing capability, such robots create unique challenges for intuitive human control. In this paper, a new flexible interface is proposed to intuitively map human bending commands into movements of the growing robot while providing shape information of the robot in order to improve situational awareness. Several command mappings are proposed, and a subjective study was conducted to assess the intuitiveness of the developed interface and mappings compared with other commercially available interfaces. The interfaces were evaluated using four metrics in two virtual task scenarios. The proposed interface with shape mapping performed better than the other interfaces, especially when the vine robot rolls over unintentionally during complex tasks.


Title: Comparison of Multimodal Heading and Pointing Gestures for Co-Located Mixed Reality Human-Robot Interaction
Key Words: control engineering computing  helmet mounted displays  human-robot interaction  intelligent robots  mobile robots  multi-robot systems  service robots  user interfaces  virtual reality  multimodal heading  pointing gestures  human operator  co-located robots  head-mounted-display  HRI situations  enormous potential  MR human-robot collaboration system  industrial robot arm  multimodal HRI techniques  heading-based interaction techniques  multirobot system  current robot programming  human-robot interaction scenarios  virtual information  pick-and-place scenarios  potential robot actions  co-located mixed reality human-robot interaction  Microsoft HoloLens  Virtual reality  Service robots  Task analysis  Collaboration  Visualization  Manipulators 
Abstract: Mixed reality (MR)opens up new vistas for human-robot interaction (HRI)scenarios in which a human operator can control and collaborate with co-located robots. For instance, when using a see-through head-mounted-display (HMD)such as the Microsoft HoloLens, the operator can see the real robots and additional virtual information can be superimposed over the real-world view to improve security, acceptability and predictability in HRI situations. In particular, previewing potential robot actions in-situ before they are executed has enormous potential to reduce the risks of damaging the system or injuring the human operator. In this paper, we introduce the concept and implementation of such an MR human-robot collaboration system in which a human can intuitively and naturally control a co-located industrial robot arm for pick-and-place tasks. In addition, we compared two different, multimodal HRI techniques to select the pick location on a target object using (i)head orientation (aka heading)or (ii)pointing, both in combination with speech. The results show that heading-based interaction techniques are more precise, require less time and are perceived as less physically, temporally and mentally demanding for MR-based pick-and-place scenarios. We confirmed these results in an additional usability study in a delivery-service task with a multi-robot system. The developed MR interface shows a preview of the current robot programming to the operator, e. g., pick selection or trajectory. The findings provide important implications for the design of future MR setups.


Title: Humanoid Teleoperation Using Task-Relevant Haptic Feedback
Key Words: compliance control  feedback  haptic interfaces  humanoid robots  stability  telerobotics  torque control  operating tools  space station  key technology  robotic teleoperation  task-relevant haptic feedback  humanoid robot TORO  torque-controlled humanoid robot  null-space autonomous controller  robot stability  haptic cues  humanoid teleoperation  task-relevant haptic interface  disaster scenarios  Humanoid robots  Task analysis  End effectors  Haptic interfaces  Robot sensing systems  Aerospace electronics 
Abstract: Robotic teleoperation is a key technology for a wide variety of fields. Teleoperating a humanoid in particular is essential as it allows the user to act remotely on an interface designed especially for humans, e.g., in a space station, or operating tools and machinery in disaster scenarios. This paper presents a `task-relevant' haptic interface for humanoid teleoperation, which bridges the gap between the task at hand and the balance of the robot. The operator is given command over the humanoid's hands and is informed through haptic cues about the impact of her/his potential actions on the robot' stability. Moreover, a null-space autonomous controller acts in the operator's null-space to provide her/him with a wider workspace and help in the successful execution of the task. The architecture is designed to top an existing compliance controller for a torque-controlled humanoid robot. Experiments on the humanoid robot TORO are reported to demonstrate the feasibility and effectiveness of the approach.


Title: ROS Reality: A Virtual Reality Framework Using Consumer-Grade Hardware for ROS-Enabled Robots
Key Words: control engineering computing  dexterous manipulators  Internet  operating systems (computers)  telerobotics  virtual reality  direct kinesthetic handling  robot operating system  ROS reality  virtual reality systems  virtual reality framework  VR teleoperation package  robotic frameworks  consumer-grade VR systems  consumer-grade hardware  robotic teleoperation tasks  Baxter robot  Unity-compatible VR headset  ROS-enabled robot  Robots  Task analysis  Solid modeling  Virtual reality  Hardware  Two dimensional displays  Engines 
Abstract: Virtual reality (VR)systems let users intuitively interact with 3D environments and have been used extensively for robotic teleoperation tasks. While more immersive than their 2D counterparts, early VR systems were expensive and required specialized hardware. Fortunately, there has been a recent proliferation of consumer-grade VR systems at affordable price points. These systems are inexpensive, relatively portable, and can be integrated into existing robotic frameworks. Our group has designed a VR teleoperation package for the Robot Operating System (ROS), ROS Reality, that can be easily integrated into such frameworks. ROS Reality is an open-source, over-the-Internet teleoperation interface between any ROS-enabled robot and any Unity-compatible VR headset. We completed a pilot study to test the efficacy of our system, with expert human users controlling a Baxter robot via ROS Reality to complete 24 dexterous manipulation tasks, compared to the same users controlling the robot via direct kinesthetic handling. This study provides insight into the feasibility of robotic teleoperation tasks in VR with current consumer-grade resources and exposes issues that need to be addressed in these VR systems. In addition, this paper presents a description of ROS Reality, its components, and architecture. We hope this system will be adopted by other research groups to allow for easy integration of VR teleoperated robots into future experiments.


Title: User Evaluation of a Haptic-Enabled Shared-Control Approach for Robotic Telemanipulation
Key Words: haptic interfaces  manipulators  telerobotics  grounded haptic interface  remaining null-space directions  human operator  slave manipulator degrees  effective approaches  nuclear sites  estimated cost  currently employed systems  handling radioactive waste  nuclear decommissioning sites  robotic telemanipulators  robotic telemanipulation  user evaluation  remote telemanipulation tasks  currently-available teleoperation systems  shared-control approach  6-DOF teleoperation approach  shared-control architecture  robotic system  haptic cues  Task analysis  Manipulators  Grippers  Force  Grasping 
Abstract: Robotic telemanipulators are already widely used in nuclear decommissioning sites for handling radioactive waste. However, currently employed systems are still extremely primitive, making the handling of these materials prohibitively slow and ineffective. As the estimated cost for the decommissioning and clean-up of nuclear sites keeps rising, it is clear that one would need faster and more effective approaches. Towards this goal, in this paper we present the user evaluation of a recently proposed haptic-enabled shared-control architecture for telemanipulation. An autonomous algorithm regulates a subset of the slave manipulator degrees of freedom (DoF) in order to help the human operator in grasping an object of interest. The human operator can then steer the manipulator along the remaining null-space directions with respect to the main task by acting on a grounded haptic interface. The haptic cues provided to the operator are designed in order to inform about the feasibility of the user's commands with respect to possible constraints of the robotic system. In this paper we compared this shared-control architecture against a classical 6-DOF teleoperation approach in a real scenario by running experiments with 10 subjects. The results clearly show that the proposed shared-control approach is a viable and effective solution for improving currently-available teleoperation systems in remote telemanipulation tasks.


Title: Towards an Automatic Spasticity Assessment by Means of Collaborative Robots
Key Words: biomechanics  brain  medical disorders  medical robotics  muscle  neurophysiology  patient rehabilitation  shear modulus  viscoelasticity  exaggerated stretch reflexes  upper motor neuron syndrome  collaborative robots  noninvasive biomechanical modelling  automatic spasticity assessment  muscle control disorder  muscle tone  upper limb joints  patient rehabilitation  7-DOF Rosen kinematics  nonlinear state  Hills force-velocity relation  rigidity  viscoelasticity  extensibility  thixotropy  passive movement response  Collaboration  Biological system modeling  Muscles  Brain modeling  Biomechanics  Intelligent robots  Collaborative robotics  Movement capture  Rehabilitation  Spasticity  Upper limb modelling 
Abstract: Summary form only given. Robotics can play a significant role in the rehabilitation of patients with spasticity by improving their early diagnosis and reducing the costs associated with care. Spasticity is a muscle control disorder characterized by an increase in muscle tone with exaggerated stretch reflexes, as one component of the upper motor neuron syndrome. Furthermore, spasticity is present in other pathologies, such as cerebral palsy, spina bifida, brain stroke among others. This video shows the ongoing research on developing a platform for the modelling and the assessment of spasticity using collaborative robots as clinical tool. Our aim is to develop methods for non-invasive biomechanical modelling of upper limbs joints using 7-DOF Rosen Kinematics [1], mixed with a non-linear state of Hills force-velocity relation [2], improved by introducing new parameters such as rigidity, viscoelasticity, extensibility and thixotropy. After a learning phase performed by the therapist, the robot replicates the trajectories required to perform the assessment. The video also describes the detailed analysis of passive movement response (force/torque and position/velocity)of the limb. These parameters will be used to determine the degree of spasticity of patients in a fast and objective manner, while simultaneously developing new clinical scales, such as a modified version of Ashworth [3].


Title: Research on Carved Turns of a Skiing Humanoid Robot on a Real-World Slope
Key Words: humanoid robots  learning (artificial intelligence)  mobile robots  motion control  sport  South Korea  deep learning method  motion pattern  IMU sensor  skiing humanoid Robot  realworld slope  carved turn  skiing robot DIANA  Alpine slalom skiing competition  PyeongChang 2018 Winter Olympic Games  robot sports events  Humanoid robots  Sports  Robot sensing systems  Moon  Service robots  Intelligent robots 
Abstract: Humans play sports to improve their athletic ability. The robot, especially humanoid robot, is also able to improve its athletic performances, such as reaction speed and balancing, through robot sports. Therefore, robots have been developed through performing various robot sports events such as robot soccer, robot marathon, robot fight and so on. In this reason, The Ski Robot Challenge was held in South Korea in commemoration of the PyeongChang 2018 Winter Olympic Games. The event was an Alpine slalom skiing competition in the almost same rules to human's but on a relatively short course (80m). To participate in this ski tournament, the skiing robot DIANA has been developed. In this video, the skiing robot technologies were introduced. At first, she must be able to recognize the flags. The deep learning method was used to recognize them. Secondly, she had a motion pattern to perform the carving turn, the most difficult and fastest skiing technique. In order to improve the stability, she compensated her motion to follow reference COP, based on the measured F/T sensor data. In addition, IMU sensor was used to remove instantaneous disturbance. Using these methods, the humanoid robot, DIANA, that can perform the carved turn on a realworld slope was successfully developed.


Title: Waiter Robot Application: Balance Control for Transporting Objects
Key Words: force control  humanoid robots  manipulators  motion control  nonlinear control systems  pendulums  position control  robot vision  stability  waiter robot application  dynamic balance control  simplified mathematical model  robot arm  manipulation control system  nongrasping tasks  ZMP criterion  humanoid robot TEO  zero moment point stability criterion  force-torque sensors  computer vision  center of mass  CoM  Humanoid robots  Stability criteria  Sensors  Mathematical model  Control systems  Balance  Manipulation  Force-Torque  Vision  Humanoid 
Abstract: Dynamic balance control for humanoid robots encounters difficulties such as stability, speed, and smoothness. In most of the previous studies, joints act as controller of the Center of Mass (CoM)supported using a simplified mathematical model. Then, the stability of the motion is guaranteed using the Zero Moment Point (ZMP)stability criterion. In this video, a humanoid robot [1] will carry a tray secured to the wrist and the objects to be transported will be placed on the tray. This condition implies that the object is not grasped and therefore, the robot arm will be the only point of support of the object through the tray. Thus, the manipulation control system must be able to detect the stability of the object and act according to the different perturbations applied to it. A 3D balance control system for non-grasping tasks is presented and it is based on the ZMP criterion and 3D inverted pendulum equations. The perception system required is based on the use of Force-Torque sensors [2], computer vision [3], and their integration. The effectiveness of the proposed approach is being investigated with the humanoid robot TEO.


Title: Visual-Inertial Teach and Repeat Powered by Google Tango
Key Words: automatic optical inspection  autonomous aerial vehicles  collision avoidance  control engineering computing  Global Positioning System  mobile robots  pose estimation  robot vision  trajectory control  human operator  visual inspection task  autonomous aerial vehicle  Google Tango visual-inertial mapping framework  pose estimates  GPS-denied environments  inspection points  feature-based localization map  industrial facilities  multicopters  visual-inertial teach  hedge maze  Robots  Inspection  Task analysis  Collision avoidance  Google  Autonomous systems  Visualization 
Abstract: Many industrial facilities require periodic visual inspections. Often the points of interest are out of reach or in potentially hazardous environment. Multi-copters are ideal platforms to automate this expensive and tedious task. This video presents a system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a tablet. The system employs the Google Tango visual-inertial mapping framework as the only source of pose estimates, thus enabling operation in GPS-denied environments. In a first step the operator records the desired inspection path using the tablet. Inspection points are automatically inserted if the operator pauses, holding a viewpoint. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the way points defined by the operator. Furthermore, the system is able to track the global pose of other robots or the operator, localized in the same map, and follow them in real-time, while avoiding collision. This was demonstrated in the second part of the video, where the robot is following the operator in real-time through a hedge maze.


Title: Distributed Reconfigurable Formation Generator for Mini Aerial Vehicles
Key Words: aircraft control  distributed algorithms  mobile robots  multi-robot systems  tracking  trajectory control  multirobot systems  geometric parameters  distributed algorithm  tracking controller  robots position  distributed trajectory generator  mini aerial vehicles  distributed reconfigurable formation generator  Generators  Intelligent robots  Trajectory  Multi-robot systems  Distributed algorithms 
Abstract: This video presents a distributed trajectory generator for formation control of multi-robot systems. The desired formation is defined by its geometric parameters but the position of each robot in the formation is not predefined a priori. The contribution is the design of a distributed algorithm to compute the robots' positions with respect to a given target while maintaining a particular formation which can be reconfigured on-line. A tracking controller ensures the convergence of the robots to their desired positions.


Title: Autonomous Underwater Vehicle Navigation in Structured Environment
Key Words: autonomous underwater vehicles  cameras  geophysical image processing  image sensors  marine navigation  oceanographic techniques  position measurement  sensor fusion  sonar  AUV navigation system  autonomous underwater vehicle navigation system  signal uncertainties  signal distortion  cameras  position estimation  image sonar aided integrated navigation system  active vision markers  inherent drift of dead-reckoning velocities  jacket structure  artificial landmarks  sensor-fusion-based localization scheme  integrated navigation system  Sonar navigation  Oceans  Sonar  Autonomous robots  Industries  Intelligent robots  Autonomous underwater vehicles 
Abstract: With the increase in developments in underwater infrastructure, the demand for development of autonomous vehicle navigation system in structured environment is also increased. However, the localization in a structured environment is a challenging problem due to signal uncertainties and distortions. In order to overcome these problems, we propose the camera and sonar aided integrated navigation system. In the proposed sensor-fusion-based localization scheme, the AUV estimates its own position continuously using artificial landmarks. The artificial landmarks for image sonar is deployed along the path to guide the AUV to the structure. The active vision markers are installed on the jacket structure, and they function as both landmarks and waypoints. This approach prevents the inherent drift of dead-reckoning velocities and collision with structures. The proposed approach was verified through a real sea experiment. The AUV conducted the full autonomous navigation from the dock to the jacket structure, and then returned to the dock without collision or significant localization error. These results show the feasibility of full autonomous navigation in a structured environment.


Title: Cooperative UAVs as a Tool for Aerial Inspection of Large Scale Aging Infrastructure
Key Words: autonomous aerial vehicles  collision avoidance  image reconstruction  inspection  Kalman filters  mobile robots  robot vision  wind turbines  UAVs  Aerial inspection  aerial tool  autonomous cooperative coverage  multiple Unmanned Aerial Vehicles  onboard computer  sensory system  autonomous navigation  localization system  Ultra Wideband  aerial team  realistic wind turbine inspection experiments  dense 3D reconstruction  inspected structures  state Kalman filter  3D infrastructure  large scale aging infrastructure  Inspection  Three-dimensional displays  Tools  Intelligent robots  Aging  Unmanned aerial vehicles  Robot sensing systems 
Abstract: This work presents an aerial tool towards the autonomous cooperative coverage and inspection of a large scale 3D infrastructure using multiple Unmanned Aerial Vehicles (UAVs). In the presented approach the UAVs are relying only on their onboard computer and sensory system, deployed for inspection of the 3D structure. In this application each agent covers a different part of the scene autonomously, while avoiding collisions. The autonomous navigation of each platform on the designed path is enabled by the localization system that fuses Ultra Wideband with inertial measurements through an Error- State Kalman Filter. The visual information collected from the aerial team is collaboratively processed to create the 3D model. The performance of the overall setup has been experimentally evaluated in realistic wind turbine inspection experiments, providing dense 3D reconstruction of the inspected structures.


Title: Hear the Egg - Demonstrating Robotic Interactive Auditory Perception
Key Words: audio signal processing  hearing  humanoid robots  image classification  interactive video  mobile robots  robot vision  video retrieval  neuro inspired companion  plastic capsules  classic TV game show  material classification task  NICO  humanoid robot  interactive auditory perception approach  egg-demonstrating robotic interactive auditory perception  capsules content  Humanoid robots  Mel frequency cepstral coefficient  Intelligent robots  Plastics  Recurrent neural networks  Gold 
Abstract: We present an illustrative example of an interactive auditory perception approach performed by a humanoid robot called NICO, the Neuro Inspired COmpanion [1]. The video demonstrates a material classification task in the style of a classic TV game show. NICO and another candidate are supposed to determine the content of small plastic capsules that are visually indistinguishable. Shaking the capsules produces audio signals that range from rattling stones, over tinkling coins to swooshing sand. NICO can perceive and analyze these sounds to determine the material of the capsules content.


Title: Computing Cross-Sections of the Workspace of Suspended Cable-Driven Parallel Robot with Sagging Cables Having Tension Limitations
Key Words: cables (mechanical)  robot kinematics  suspended cable-driven parallel robot  sagging cables  horizontal cross-sections  tension limitations  CDPR  kinematics equations  inverse kinematics  Kinematics  Parallel robots  Mathematical model  Legged locomotion  Mechanical cables  Robot kinematics 
Abstract: Although workspace is essential for the design and control of cable-driven parallel robots (CDPR) very few works have been devoted to this topic when sagging cables are considered, most probably because of the complexity of the cable model. In this paper we consider suspended CDPR with sagging cables that can support only a limited tension. We propose an algorithm to compute the border of horizontal cross-sections of the workspace for a given altitude and orientation of the platform. We show that singularities of the kinematics equations have to be taken into account for a proper determination of the border and that the workspace can be separated in several components according to the branch of the inverse kinematics on which the robot is evolving. We also compare the workspace obtained for ideal and sagging cables.


Title: A Singularity-Robust LQR Controller for Parallel Robots
Key Words: control system synthesis  linear quadratic control  mobile robots  nonlinear control systems  optimal control  robust control  torque control  singularity-robust LQR controller  five-bar parallel robot  optimal control law  expensive inverse dynamics computations  reliable controller  singularity-crossing trajectories  motion range  singularity-free regions  forward singularities  parallel robots  Trajectory  Parallel robots  Robot kinematics  Regulators  Task analysis 
Abstract: Parallel robots exhibit the so-called forward singularities, which complicate substantially the planning and control of their motions. Often, such complications are circumvented by restricting the motions to singularity-free regions of the workspace. However, this comes at the expense of reducing the motion range of the robot substantially. It is for this reason that, recently, efforts are underway to control singularity-crossing trajectories. This paper proposes a reliable controller to stabilize such kind of trajectories. The controller is based on the classical theory of linear quadratic regulators, which we adapt appropriately to the case of parallel robots. As opposed to traditional computed-torque methods, the obtained controller does not rely on expensive inverse dynamics computations. Instead, it uses an optimal control law that is easy to evaluate, and does not generate instabilities at forward singularities. The performance of the controller is exemplified on a five-bar parallel robot accomplishing two tasks that require the traversal of singularities.


Title: An Active Stabilizer for Cable-Driven Parallel Robot Vibration Damping
Key Words: actuators  cables (mechanical)  closed loop systems  damping  manipulator kinematics  position control  vibration control  vibrations  parasitic vibrations  CDPR mobile platform  vibration damping  actuated rotating arms  control strategy  planar 3-DOF CDPR  three-arm stabilizer  cable-driven parallel robots  active stabilizer  position control  cable-driven parallel robot vibration  closed-loop system  Vibrations  Damping  Actuators  Stability analysis  Symmetric matrices  Torque  Jacobian matrices 
Abstract: Cable-Driven Parallel Robots (CDPRs) can execute fast motions across a large workspace. However, these performances are reached at the cost of a relatively low stiffness which often yields parasitic vibrations at the CDPR mobile platform. In this paper, vibration damping of CDPRs is addressed by means of an original active stabilizer consisting of actuated rotating arms installed on-board the CDPR mobile platform. A control strategy for the whole system, which consists of the CDPR and the stabilizer, and with one purpose for each-position control for the platform and vibration damping for the stabilizer-is designed. The system being controlled at two different time scales, the singular perturbation theory can be used to prove the stability of the corresponding closed-loop system. The efficiency of the proposed device and control strategy is tested in simulations in the case of a planar 3-DOF CDPR equipped with a three-arm stabilizer.


Title: Design and Fabrication of a Bipedal Robot Using Serial-Parallel Hybrid Leg Mechanism
Key Words: design engineering  legged locomotion  machine bearings  motion control  robot dynamics  velocity control  serial-parallel hybrid leg mechanism  forward walking motion  developed robot  feet workspace  pelvis structure  structural rigidity  bearings  carbon fiber tubes  agile bipedal locomotion  light structural inertia  parallel mechanism  serial mechanism  bipedal robot  performance evaluation  Legged locomotion  Foot  Hip  Servomotors  Humanoid robots  Knee 
Abstract: In this paper, we present the design and performance evaluation of a bipedal robot that utilizes the Hybrid Leg mechanism. It is a leg mechanism that achieves 6 DOF with a combined structure of serial and parallel mechanism. It is designed to have a light structural inertia and large workspace for agile bipedal locomotion. A new version of Hybrid Leg is fabricated with carbon fiber tubes and bearings to improve its structural rigidity and accuracy while supporting its weight. A pair of Hybrid Legs is assembled together for bipedal locomotion. In the assembly, we adopt a pelvis structure with an yaw angle offset to enlarge the feet workspace, inspired by the toe-out angle of the human feet. The workspace and range of velocity are presented in simulation and verified with hardware experiments. We also demonstrate a simple forward walking motion with the developed robot.


Title: Configuration Space Metrics
Key Words: manipulator kinematics  path planning  configuration space metrics  robot manipulators  task constraint  Euclidean distance metric  robot behavior  3DOF arm  Jaco 7DOF arm  Task analysis  Euclidean distance  Manifolds  End effectors  Elbow 
Abstract: When robot manipulators decide how to reach for an object, hand it over, or obey some task constraint, they implicitly assume a Euclidean distance metric in their configuration space. Their notion of what makes a configuration closer or further is dictated by this assumption. But different distance metrics will lead to different solutions. What is efficient under a Euclidean metric might not necessarily look the most efficient or natural to a person observing the robot. In this paper, we analyze the effect of the metric on robot behavior, examining both Euclidean, as well as non-Euclidean metrics - metrics that make certain joints cheaper, or that correlate different joints. Our user data suggests that tasks on a 3DOF arm and the Jaco 7DOF arm can typically be grouped into ones where a Euclidean metric works well, and tasks where that is no longer the case: there, surprisingly, penalizing elbow motion (and sometimes correlating the shoulder and wrist) leads to solutions that are more aligned with what users prefer.


Title: Fused Angles and the Deficiencies of Euler Angles
Key Words: gait analysis  legged locomotion  robot dynamics  fused angles  Euler angles representation  balance-related scenarios  parameter sensitivities  walking bipedal robots  three-dimensional Euclidean space  Quaternions  Task analysis  Legged locomotion  Rotation measurement  Intelligent robots  Sensitivity 
Abstract: Just like the well-established Euler angles representation, fused angles are a convenient parameterisation for rotations in three-dimensional Euclidean space. They were developed in the context of balancing bodies, most specifically walking bipedal robots, but have since found wider application due to their useful properties. A comparative analysis between fused angles and Euler angles is presented in this paper, delineating the specific differences between the two representations that make fused angles more suitable for representing orientations in balance-related scenarios. Aspects of comparison include the locations of the singularities, the associated parameter sensitivities, the level of mutual independence of the parameters, and the axisymmetry of the parameters.


Title: Geometric Optimization of a Large Scale CDPR Operating on a Building Facade
Key Words: buildings (structures)  cables (mechanical)  construction industry  design engineering  mobile robots  optimisation  geometric design procedure  geometric optimization  building facade  large-scale construction applications  wrench-feasibility constraints  cable-driven parallel robot  cable tension  Geometry  Optimization  Indexes  Buildings  Robots  Trajectory  Payloads 
Abstract: This paper deals with the optimization of the geometry of a Cable-Driven Parallel Robot (CDPR) dedicated to large-scale construction applications. Since the maximum cable tension is a critical parameter in the design of the CDPR components, the geometry of the CDPR is optimized by minimizing the lowest maximum cable tension that ensures the validity of wrench-feasibility constraints. The geometric design procedure used in this paper consists of two phases, the CDPR cable connections is selected in the first phase followed by a second phase where the geometric parameters are optimized. The result of this procedure is an original fully-constrained CDPR geometry.


Title: Learning the Forward and Inverse Kinematics of a 6-DOF Concentric Tube Continuum Robot in SE(3)
Key Words: actuators  approximation theory  neural nets  position control  robot kinematics  forward kinematics  concentric tube continuum robot  high computational load  nonlinear modeling effort  data-driven approach  physics-based model  robot prototype  inverse kinematics approximation  artificial neural network  ReLU  rectified linear unit  rotation actuator error  trigonometric function  mechanics modeling  position control  Electron tubes  Robots  Kinematics  Neural networks  Quaternions  Computational modeling  Load modeling 
Abstract: Recent physics-based models of concentric tube continuum robots are able to describe pose of the tip, given the preformed translation and rotation in joint space of the robot. However, such model-based approaches are associated with high computational load and highly non-linear modeling effort. A data-driven approach for computationally fast estimation of the kinematics without requiring the knowledge and the uncertainties in the physics-based model would be an asset. This paper introduces an approach to solve the forward kinematics as well as the inverse kinematics of concentric tube continuum robots with 6-DOF in three dimensional space SE(3). Two artificial neural networks with ReLU (rectified linear unit) activation functions are designed in order to approximate the respective kinematics. Measured data from a robot prototype are used in order to train, validate, and test the proposed approach. We introduce a representation of the rotatory joints by trigonometric functions that improves the accuracy of the approximation. The results with experimental measurements show higher accuracy for the forward kinematics compared to the state of the art mechanics modeling. The tip error is less then 2.3 mm w.r.t. position (1 % of total robot length) and 1.1° w.r.t. orientation. The single artificial neural network for the inverse kinematics approximation achieves a translation and rotation actuator error of 4.0 mm and 8.3 0, respectively.


Title: Learning Forward and Inverse Kinematics Maps Efficiently
Key Words: actuators  control engineering computing  elasticity  learning (artificial intelligence)  manipulator kinematics  nonparametric statistics  learning forward kinematics maps  exploratory learning approaches  action-outcome sampling  omnielastic manipulators  rigid manipulators  inverse kinematics mappings  nonparametric models  elastic discretely-actuated robots  rigid discretely-actuated robots  tailored parametric models  data-efficiency  Manipulators  Kinematics  Solid modeling  Elasticity  Analytical models  Strain 
Abstract: When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.


Title: A Fail-Safe Semi-Centralized Impedance Controller: Validation on a Parallel Kinematics Ankle
Key Words: humanoid robots  legged locomotion  robot kinematics  torque control  fail-safe semicentralized impedance controller  parallel kinematics ankle  COMAN+  dual four-bar mechanism  fully centralized impedance control implementation  torque reference inputs  local joint torque controllers  safer robot response  Impedance  Torque  Kinematics  Actuators  Damping  Humanoid robots 
Abstract: This paper proposes the implementation of an impedance controller on the ankle level of COMAN+, a robot with parallel kinematics ankles actuated by a dual four-bar mechanism. The main contribution of the work is a realization of said control scheme that grants a less abrupt and safer robot response in case of system failures, that would cause the local joint torque controllers to lose their torque reference inputs. In particular, we propose a semi-centralized impedance control implementation which eliminates the instability of the pure joint torque control schemes used in the classical fully centralized methods when torque reference interruptions occur. Finally, we present experimental results, proving the effectiveness of our method and demonstrating how it ensures a safer behaviour compared to a fully centralized impedance control implementation when the communication to the ankle joints is interrupted. This paper is a follow-up work of [1], which presented and analyzed the parallel kinematics ankles.


Title: Probabilistic Kinematic State Estimation for Motion Planning of Planetary Rovers
Key Words: aerospace robotics  Mars  mobile robots  path planning  planetary rovers  robot kinematics  state estimation  statistical distributions  light-weight analytic solution  rocky terrain  typical numeric approaches  onboard computation  single collision  unstructured terrain  robot motion planning  kinematics-based collision detection  planetary rovers  probabilistic kinematic state estimation  deterministic state bounds  distribution models  probabilistic safety guarantees  worst-case evaluation  deterministic bounds  probability distributions  frequent false positive detection  conservative safety check approach  worst-case values  constraint violation  terrain height  articulated suspension systems  Mars 2020 rover mission  Approximate Clearance Evaluation  Wheels  Kinematics  Planning  Space vehicles  Uncertainty  Numerical models  Probabilistic logic 
Abstract: Kinematics-based collision detection is important for robot motion planning in unstructured terrain. Especially, planetary rovers require such capability as a single collision may lead to the termination of a mission. For onboard computation, typical numeric approaches are unsuitable as they are computationally expensive and unstable on rocky terrain; instead, a light-weight analytic solution (ACE: Approximate Clearance Evaluation) is planning to be used for the Mars 2020 rover mission. ACE computes the state bounds of articulated suspension systems from terrain height bounds, and assess the safety by checking the constraint violation of states with the worst-case values. ACE's conservative safety check approach can sometimes lead to over-pessimism: feasible states are often reported as infeasible, thus resulting in frequent false positive detection. In this paper, we introduce a computationally efficient probabilistic variant of ACE (called p-ACE) which estimates the probability distributions of states in real time. The advantage of having probability distributions over states, instead of deterministic bounds, is to provide more flexible and less pessimistic worst-case evaluation with probabilistic safety guarantees. Empirically derived distribution models are used to compute the total probability of constraint satisfaction, which is then used for path assessment. Through experiments with a high-fidelity simulator, we empirically show that p-ACE relaxes the deterministic state bounds without losing safety guarantees.


Title: Constrained Control of Robotic Manipulators Using the Explicit Reference Governor
Key Words: actuators  collision avoidance  end effectors  manipulators  position control  robot arm  ERG  Explicit Reference Governor  nonconvex constraints  constrained control  2DOF planar robotic manipulator  end-effector position  actuator saturations  static obstacles  joint ranges  Manipulator dynamics  Safety  End effectors  Actuators  Navigation 
Abstract: Robotic manipulators that are intended to interact with humans in their operating region are systems that need formal safety guarantees. Current solutions cannot handle both input and state constraints, have difficulties handling nonconvex constraints, or are computationally too expensive. To tackle these drawbacks, we analyzed a constrained control strategy, the Explicit Reference Governor (ERG), which can address both input and state constraints, and does not require any online optimization, thus making it computationally inexpensive. This paper presents the theory of the ERG for a general robotic manipulator and shows simulations for a specific 2DOF planar robotic manipulator. The proposed control scheme is able to steer the robot arm to the desired end-effector position, or an admissible approximation, in the presence of limited joint ranges, actuator saturations, and static obstacles. As a result, the ERG is a promising tool for the control of robotic manipulators subject to constraints.


Title: Iterative Learning Vector Field for FES-Supported Cyclic Upper Limb Movements in Combination with Robotic Weight Compensation
Key Words: bioelectric phenomena  biomechanics  iterative methods  learning (artificial intelligence)  medical computing  medical robotics  muscle  neuromuscular stimulation  neurophysiology  patient rehabilitation  physiological models  control system  spinal cord injured patients  functional electrical stimulation  iterative learning control approaches  prespecified reference trajectory  self-selected cadence  smooth stimulation intensity profiles  complex neuromusculoskeletal model  initial RMS error  steady state RMS error  adaptive FES support  purely volitional movements  breaststroke motions  control algorithm  artificially activated muscles  learning algorithm  joint angle space  stimulation intensities  ILVF  transversal plane  cable tension forces  arm weight  breaststroke swimming exercises  repetitive arm movements  cable-driven robotic system  anterior deltoid  posterior deltoid  triceps  biceps  feedback-controlled FES  robotic weight compensation  FES-supported cyclic upper limb movements  iterative learning vector field  Iron  Muscles  Trajectory  Manipulators  Torque  Aerospace electronics 
Abstract: Robotics and Functional Electrical Stimulation (FES) are well-established technologies for the rehabilitation of stroke and spinal cord injured (SCI) patients. We propose a hybrid solution that combines feedback-controlled FES of biceps and triceps as well as posterior and anterior deltoid with a cable-driven robotic system to support repetitive arm movements, like “breaststroke swimming” exercises. The robotic system partially compensates the arm weight by controlling the cable tension forces, and the FES promotes motion in the transversal plane. To adjust the FES support to the needs of the individual patients we use an iterative learning vector field (ILVF) which encodes the stimulation intensities that are applied to guide the patient along a pre-specified reference trajectory in the joint angle space. In contrast to previous iterative learning control approaches, the ILVF allows the patient to perform the motion at self-selected cadence. The proposed learning algorithm explicitly takes the dynamics of the artificially activated muscles into account and assures smooth stimulation intensity profiles. The control algorithm is tested in simulations using a complex neuro-musculoskeletal model. For “breaststroke” motions, the initial RMS error of purely volitional movements is reduced from 38° to 10° within 21 cycles by the adaptive FES support. After 50 iterations of the ILVF, the algorithm converges to a steady state RMS error of 4°. Changes in the patient's muscle activity and cadence were well tolerated by the control system and did not cause a noticable increase in the steady state RMS error.


Title: Online Self-Supervised Long-Range Scene Segmentation for MAVs
Key Words: autonomous aerial vehicles  image segmentation  learning (artificial intelligence)  microrobots  mobile robots  object detection  robot vision  vision-based autonomous MAV flight  self-supervised online learning  adaptive scene segmentation  data-driven methods  manually annotated training data  geometry-based methods  sensor capabilities  robust scene understanding  complex dynamic environments  autonomous flights  lightweight MicroAerial Vehicles  MAVs  online self-supervised long-range scene segmentation  Image segmentation  Training  Robot sensing systems  Visualization  Real-time systems  Convolution 
Abstract: Recently, there have been numerous advances in the development of payload and power constrained lightweight Micro Aerial Vehicles (MAVs). As these robots aspire for highspeed autonomous flights in complex dynamic environments, robust scene understanding at long-range becomes critical. The problem is heavily characterized by either the limitations imposed by sensor capabilities for geometry-based methods, or the need for large-amounts of manually annotated training data required by data-driven methods. This motivates the need to build systems that have the capability to alleviate these problems by exploiting the complimentary strengths of both geometry and data-driven methods. In this paper, we take a step in this direction and propose a generic framework for adaptive scene segmentation using self-supervised online learning. We present this in the context of vision-based autonomous MAV flight, and demonstrate the efficacy of our proposed system through extensive experiments on benchmark datasets and realworld field tests.


Title: PAMPC: Perception-Aware Model Predictive Control for Quadrotors
Key Words: autonomous aerial vehicles  helicopters  mobile robots  nonlinear programming  path planning  predictive control  robot vision  PAMPC  lighting conditions  visual-inertial odometry pipeline  low-power ARM computer  nonlinear optimization problem  action objective  numerical optimization  perception-aware model predictive control framework  model-based optimization framework  perception objective  quadrotor  motion planning  Cameras  Trajectory  Optimization  Robot vision systems  Predictive control  Planning 
Abstract: We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.


Title: History-Aware Autonomous Exploration in Confined Environments Using MAVs
Key Words: attitude control  autonomous aerial vehicles  mobile robots  path planning  sampling-based exploration algorithms  3D exploration planner  field-of-view depth sensor  configuration space  high sampling efficiency  computational constrained real world MAV  history-aware autonomous exploration  confined environments  inspection tasks  high-dimensional path planning problem  microaerial vehicle  search and rescue missions  next-best views  robot orientation  Planning  Robot sensing systems  Three-dimensional displays  Trajectory  History  Optimization 
Abstract: Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 × faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 × faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.


Title: Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation
Key Words: autonomous aerial vehicles  collision avoidance  convolutional neural nets  feature extraction  indoor navigation  learning (artificial intelligence)  learning systems  mobile robots  motion control  neurocontrollers  regression analysis  robot vision  sensor fusion  velocity control  indoor flights  unmanned aerial vehicles  civilian applications  indoor-flight dataset  agent distance-to-collision prediction  drone safe deployment  on-board monocular camera  external sensors  spatio-temporal feature extraction  static appearance information  motion information  robot distance estimation  linear velocity  navigation policy learning  real-distance labels  raw visual input  regression CNN  real-time obstacle avoidance  indoor robot navigation  autonomous navigation methods  UAV  self-supervised CNN-based approach  navigation policy  Robots  Navigation  Sensors  Drones  Cameras  Task analysis  Trajectory 
Abstract: Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.


Title: Hands and Faces, Fast: Mono-Camera User Detection Robust Enough to Directly Control a UAV in Flight
Key Words: autonomous aerial vehicles  cameras  control engineering computing  convolutional neural nets  face recognition  feature extraction  gesture recognition  human-robot interaction  image colour analysis  image segmentation  object detection  robust control  video signal processing  YOLOv2 deep convolutional neural network  hand-and-face detector  gestural human-UAV interface  robust control  hand-labelled videos  face-engagement  robust sensor front-end  gray-scale images  robust real-time system  mono-camera user detection  human-robot interaction  human-UAV interaction experiments  Detectors  Feature extraction  Proposals  Training  Object detection  Face detection  Cameras 
Abstract: We present a robust real-time system for simultaneous detection of hands and faces in RGB and gray-scale images, and a novel dataset used for training. Our goal is to provide a robust sensor front-end suitable for real-time human-robot interaction using face-engagement and gestures. Using hand-labelled videos obtained from real human-UAV interaction experiments, we re-trained the YOLOv2 Deep Convolutional Neural Network to detect only hands and faces. This model was then used to automatically label several much larger third-party datasets. After manual correction of these results, we modified and re-trained the model on all this labelled data. We obtain qualitatively good detection results at 60Hz on a commodity GPU: our simultaneous hand-and-face detector gives state of the art accuracy and speed in a hand detection benchmark and competitive results in a face detection benchmark. To demonstrate its effectiveness for human-robot interaction we describe its use as the input to a simple but practical gestural human-UAV interface for entertainment or industrial applications. All software, training and test data are freely available.


Title: Vision Based Forward Sensitive Reactive Control for a Quadrotor VTOL
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  helicopters  image sequences  mobile robots  robot vision  dense high-speed optical flow  real-time motion cues  obstacle avoidance  smooth trajectory  image flow representation  forest environment  forward sensitive reactive control  quadrotor VTOL  aerial robotic vehicles  3D full reconstruction  fully image based control criteria  Optical sensors  Optical imaging  Adaptive optics  Velocity measurement  Robot sensing systems  Cameras 
Abstract: Deployment of aerial robotic vehicles for real world tasks such as home deliveries, close range aerial inspection, etc., require robotic vehicles to fly through complex and cluttered 3D environments such as forests, shrubbery or into balconies, garages, or sheds. Dense high-speed optical flow can provide real-time motion cues for obstacle avoidance that does not require 3D full reconstruction of the environment. However, classical reactive control does not `look ahead' and tends to bounce off obstacles rather than generating a smooth trajectory that anticipates and avoids upcoming obstacles. In this paper, we consider deriving a fully image based control criteria that forward predicts a cylinder of free space into the image flow representation of the environment and steers the vehicle by manoeuvering this cylinder through the upcoming environment. The length and radius of the cylinder provide a guarantee that the vehicle can indeed fly through the space identified and the fact that it is predicted forward into the environment leads to smooth anticipation of upcoming obstacles. Results are obtained for a quadrotor flying autonomously through a forest environment.


Title: Angle-Encoded Swarm Optimization for UAV Formation Path Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  particle swarm optimisation  angle-encoded particle swarm optimization  3DR solo drones  mission planner  Internet-of- Things  UAV formation path planning  triangular formation maintenance  swarm convergence  multiple-objective optimisation algorithm  unmanned aerial vehicles  feasible path planning technique  Trajectory  Collision avoidance  Unmanned aerial vehicles  Task analysis  Cost function  Shape  Quadcopter  θ-PSO  path planning  loT  triangular formation  collision avoidance 
Abstract: This paper presents a novel and feasible path planning technique for a group of unmanned aerial vehicles (DAVs) conducting surface inspection of infrastructure. The ultimate goal is to minimise the travel distance of DAVs while simultaneously avoid obstacles, and maintain altitude constraints as well as the shape of the UAV formation. A multiple-objective optimisation algorithm, called the Angle-encoded Particle Swarm Optimization (θ- PSO) algorithm, is proposed to accelerate the swarm convergence with angular velocity and position being used for the location of particles. The whole formation is modelled as a virtual rigid body and controlled to maintain a desired geometric shape among the paths created while the centroid of the group follows a pre-determined trajectory. Based on the testbed of 3DR Solo drones equipped with a proprietary Mission Planner, and the Internet-of- Things (loT) for multi-directional transmission and reception of data between the DAV s, extensive experiments have been conducted for triangular formation maintenance along a monorail bridge. The results obtained confirm the feasibility and effectiveness of the proposed approach.


Title: An Integrated Localization-Navigation Scheme for Distance-Based Docking of UAVs
Key Words: adaptive estimation  autonomous aerial vehicles  convergence  image sequences  invariance  mobile robots  navigation  path planning  position control  single landmark  unmanned aerial vehicles  GPS-less environment  optical flow sensors  ultra-wideband ranging sensors  discrete-time LaSalle invariance principle  UAV  distance-based docking problem  integrated localization-navigation scheme  asymptotic docking  delicate control scheme  relative position  nonlinear adaptive estimation scheme  bounded velocity  discrete-time integrators  navigation tasks  relative localization  integrated estimation-control scheme  arbitrarily unknown position  Navigation  Convergence  Distance measurement  Adaptive estimation  Estimation  Task analysis  Optical sensors 
Abstract: In this paper we study the distance-based docking problem of unmanned aerial vehicles (UAVs) by using a single landmark placed at an arbitrarily unknown position. To solve the problem, we propose an integrated estimation-control scheme to simultaneously achieve the relative localization and navigation tasks for discrete-time integrators under bounded velocity: a nonlinear adaptive estimation scheme to estimate the relative position to the landmark, and a delicate control scheme to ensure both the convergence of the estimation and the asymptotic docking at the given landmark. A rigorous proof of convergence is provided by invoking the discrete-time LaSalle's invariance principle, and we also validate our theoretical findings on quadcopters equipped with ultra-wideband ranging sensors and optical flow sensors in a GPS-less environment.


Title: Classification of Hanging Garments Using Learned Features Extracted from 3D Point Clouds
Key Words: clothing  computer graphics  control engineering computing  convolutional neural nets  feature extraction  image classification  manipulators  neurocontrollers  robot vision  service robots  support vector machines  3D objects  feature vector extraction  t-shirts  hanging garments classification  3D point clouds  SVM  generalized convolution operation  single global feature vector  convolutional neural network  depth maps  robotic arm  hanging state  robotic manipulation  garment category  Clothing  Three-dimensional displays  Feature extraction  Robot sensing systems  Convolution  Image reconstruction 
Abstract: The presented work deals with classification of garment categories including pants, shorts, shirts, T-shirts and towels. The knowledge of the garment category is crucial for its robotic manipulation. Our work focuses particularly on garments being held in a hanging state by a robotic arm. The input of our method is a set of depth maps taken from different viewpoints around the garment. The depths are fused into a single 3D point cloud. The cloud is fed into a convolutional neural network that transforms it into a single global feature vector. The network utilizes a generalized convolution operation defined over the local neighborhood of a point. It can deal with permutations of the input points. It was trained on a large dataset of common 3D objects. The extracted feature vector is classified with SVM trained on smaller datasets of garments. The proposed method was evaluated on publicly available data and compared to the original methods, achieving competitive performance and better generalization capability.


Title: Coverage Control for Multi-Robot Teams with Heterogeneous Sensing Capabilities Using Limited Communications*
Key Words: distributed control  mobile robots  multi-robot systems  multirobot teams  heterogeneous sensing capabilities  coverage algorithm  multirobot systems  qualitatively different sensing modalities  required sensing modalities  particular sensory capability  distributed control algorithm  robotic platform  Robot sensing systems  Robot kinematics  Monitoring  Temperature sensors  Density functional theory 
Abstract: This paper presents a coverage algorithm for multi-robot systems where the robots are equipped with qualitatively different sensing modalities. Unlike previous approaches to the problem of coverage for teams with heterogeneous sensing capabilities, in this paper the robots have access to information about their neighbors' specific sensor modalities. This knowledge affords the ability of ensuring that no robot is tasked with covering features in a region without the required sensing modalities. With this information, a robot can determine which of its neighbors it should coordinate with to cover the environmental features in a region while ignoring robots that are not equipped with that particular sensory capability. We derive a distributed control algorithm that allows the robots to move in a direction of descent relative to a novel locational cost, in order to minimize it. The performance of the algorithm is evaluated on a real robotic platform.


Title: An Adaptive Robot for Building In-Plane Programmable Structures
Key Words: actuators  control system synthesis  elasticity  mechatronics  mesh generation  nonlinear control systems  optimal control  position control  robot kinematics  supports  autonomous cells  unstructured triangular meshes  arbitrary planar shapes  self-reconfigurable system  programmable matter  kinematic model  cellular robot  positioning errors  simplified mechanical model  adaptive robot  single elements  triangular cells  linear actuators  triangular shapes  in-plane programmable structures  Actuators  Robots  Couplings  Kinematics  Shape  Latches  Computational modeling 
Abstract: A new approach for cellular robots is presented. The single elements of the robot are triangular cells, which can change their shape by means of linear actuators at each edge. The novelty concerns the connection of autonomous cells at their edges rather than at the vertices. In this way, unstructured triangular meshes can be formed. The robot can self-reconfigure and thus can reproduce almost arbitrary planar shapes. In a similar way, the system has been realized with tetrahedrons in a simplified way within a previous work. The self-reconfigurable system shall serve as a basis for programmable matter. The present paper includes the mechatronic design, its components and the kinematic model of the cellular robot. In order to reduce positioning errors, a model is developed, which considers compliance and clearance in the links and joints. Based on a simplified mechanical model using elastic trusses, the positioning errors can be predicted. The parameters of these models are identified from simple motion sequences. Furthermore, the nonlinearity of actuators is identified and corrected. In this way, the desired triangular shapes can be prescribed without measuring the position of the cells.


Title: Circle Formation with Computation-Free Robots Shows Emergent Behavioural Structure
Key Words: finite state machines  mobile robots  multi-robot systems  spatiotemporal phenomena  computation-free robots  emergent behavioural structure  finite state machine  minimal robots  nonholonomic robots  self-healing circle formations  frontal binary sensor  grid-search method  computation-free behaviour  spatio-temporal dynamics  Robot sensing systems  Mobile robots  Robot kinematics  Apertures  Standards  Computational modeling 
Abstract: In this paper, we demonstrate how behavioural structure, such as a finite state machine, can emerge in minimal robots without computation nor memory capabilities. As a case study we observe the ability of a group of non-holonomic robots to form robust, self-healing circle formations in a decentralized manner using only a limited frontal binary sensor. We present a grid-search method to find suitable parameters that promote the formation of a stable circle. We then examine how the parameters of the controllers affect the appearance of the behaviour, and provide theoretical proof for its emergence and self-healing properties. We validate the proposed model through a set of experiments with ten mobile real robots. Our results with real robots match the simulated experiments and provide insights on how a simple, computation-free behaviour can generate complex spatio-temporal dynamics.


Title: Sampling of Pareto-Optimal Trajectories Using Progressive Objective Evaluation in Multi-Objective Motion Planning
Key Words: Bayes methods  Markov processes  Monte Carlo methods  Pareto optimisation  path planning  implicit uniform distribution  Pareto-frontier  progressive objective evaluation  objective functions  Pareto-optimal trajectories  multiobjective motion planning  multiobjective motion-planning problems  sampling trajectories  Pareto-optimal set  Markov chain Monte Carlo method  Trajectory  Markov processes  Planning  Monte Carlo methods  Sociology  Optimization 
Abstract: In this paper, we introduce a Markov chain Monte Carlo (MCMC)method to solve multi-objective motion-planning problems. We formulate the problem of finding Pareto-optimal trajectories as a problem of sampling trajectories from a Pareto-optimal set. We define an implicit uniform distribution over the Pareto-frontier using a dominance function and then sample in the space of trajectories. The nature of MCMC guarantees the convergence to the Pareto-frontier, while the uniform distribution ensures the diversity of the trajectories. We also propose progressive objective evaluation to increase efficiency in problems with expensive-to-evaluate objective functions. This enables determination of dominance relationship between trajectories before they are entirely evaluated. We finally analyze the effectiveness of the framework and its applications in robotics.


Title: Should We Compete or Should We Cooperate? Applying Game Theory to Task Allocation in Drone Swarms
Key Words: game theory  preferred task allocations  competitive algorithm  game theoretical algorithms  described scenario  relevant question  partial information  disaster area  drone swarms  task allocation  game theory  Task analysis  Robots  Resource management  Games  Drones  Nash equilibrium  Genetic algorithms 
Abstract: Let's imagine a swarm of drones that has to visit some locations and build a map in a disaster area. Let's assume the drones only can communicate to their neighbors and manage partial information of the mission. A relevant question in this scenario is “Should the robots compete or should they cooperate?”. This work analyzes the described scenario to answer this question. Two game theoretical algorithms have been developed: one competitive and another cooperative. The competitive algorithm poses games among each drone and its neighbors and searches the Nash Equilibrium. The cooperative one defines electoral systems that allow the drones to vote their preferred task allocations for their neighbors. Both algorithms are extensively tested in multiple scenarios with different features. After the experiments the question can be answered “The robots should cooperate!”.


Title: Magnetic Navigation of a Rotating Colloidal Swarm Using Ultrasound Images
Key Words: biomedical ultrasonics  image enhancement  magnetic particles  medical image processing  medical robotics  microrobots  nanomedicine  nanoparticles  magnetic navigation  rotating colloidal swarm  ultrasound images  paramagnetic nanoparticle-based swarm  simple rotating magnetic fields  microrobotic swarm  enhanced ultrasound imaging  imaging contrast  microrobot imaging  nanoparticle  solid surface  Magnetic resonance imaging  Ultrasonic imaging  Nanoparticles  Magnetic recording  Magnetic moments  Navigation 
Abstract: Microrobots are considered as promising tools for biomedical applications. However, the imaging of them becomes challenges in order to be further applied on in vivo environments. Here we report the magnetic navigation of a paramagnetic nanoparticle-based swarm using ultrasound images. The swarm can be generated using simple rotating magnetic fields, resulting in a region containing particles with a high area density. Ultrasound images of the swarm shows a periodic changing of imaging contrast. The reason for such dynamic contrast has been analyzed and experimental results are presented. Moreover, this swarm exhibits enhanced ultrasound imaging in comparison to that formed by individual nanoparticles with a low area density, and the relationship between imaging contrast and area density is testified. Furthermore, the microrobotic swarm can be navigated near a solid surface at different velocities, and the imaging contrast show negligible changes. This method allows us to localize and navigate a microrobotic swarm with enhanced ultrasound imaging indicating a promising approach for imaging of microrobots.


Title: Human Motion Classification Based on Multi-Modal Sensor Data for Lower Limb Exoskeletons
Key Words: biomechanics  force sensors  gait analysis  hidden Markov models  image motion analysis  learning (artificial intelligence)  medical robotics  patient rehabilitation  pattern classification  wearable computers  human motion classification  multimodal sensor data  lower limb exoskeletons  intuitive exoskeleton control  improved user acceptance  wearability comfort  exoskeleton control system  online classification  lower-limb exoskeleton  defined motion patterns  recent sensor measurements  sliding window approach  training data  passive exoskeleton  3D-force sensors  3 inertial measurement units  correct classification  generalization performance  hidden Markov models  Exoskeletons  Hidden Markov models  Robot sensing systems  Legged locomotion  Force  Force sensors  Thigh 
Abstract: Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.


Title: A Novel Joint Torque Estimation Method and Sensory System for Assistive Lower Limb Exoskeletons
Key Words: biomechanics  gait analysis  legged locomotion  medical robotics  motion control  patient rehabilitation  torque  torque control  novel joint torque estimation method  sensory System  assistive lower limb exoskeletons  hip  reference signals  life scenarios  noncyclic locomotion activity  unexpected terrain  unpredicted interactions  upper body  mass location  sensorized shoe sensing system  inverse static analysis  lower limbs  leg joint  body posture sensors  sensorized shoes  interaction loads  irregular terrains  natural feet postures  knee torques  iT-Knee Bipedal System  assistive task  Sensors  Foot  Torque  Task analysis  Exoskeletons  Legged locomotion  Knee 
Abstract: This work presents a novel method for estimating online the torques at the ankle, knee and hip of a user with the goal of generating reference signals for torque controlled lower limb exoskeletons. In particular, this approach attempts to address difficulties arising in real life scenarios when noncyclic locomotion activity, unexpected terrain or unpredicted interactions with the surroundings occur. An advantage of the proposed method is that it does not require any information on the user's upper body (i.e. pose, weight and center of mass location)or on any interaction of the user's upper body with the environment (i.e. payload handling or pushing and pulling task). By monitoring the interaction of the user's feet with the ground through a novel sensorized shoe sensing system, the method applies an inverse static analysis on the user's lower limbs to estimate in real time the torque at each leg joint. The system is fully wearable, ergonomic and portable and uses a reduced number of body posture sensors. The design of the sensorized shoes permits plantar flexion, while measuring the toe and heel orientation and the interaction loads. This allows walking on irregular terrains and natural feet postures in different tasks. Trials were performed to validate the proposed approach under different tasks and terrains. Finally, the knee torques estimated online by the proposed strategy were used as reference signals to drive the iT-Knee Bipedal System in an assistive task.


Title: Robotic Hand-Free-Stick for Walking Balance Assistance
Key Words: gait analysis  handicapped aids  humanoid robots  legged locomotion  pressure measurement  servomotors  stick motion  walking tests  HFS  ZMP area  walking balance assistance  robotic hand-free-stick  wearable robotic stick  walking assistance  nonserious dysfunction  Zero moment point  hands free conditions  body balance ability  boots type prototype  lightweight robotic stick  slider-link mechanism  stick angle  hand-free-stick  Legged locomotion  Hafnium  Foot  Prototypes  Senior citizens  Weight measurement 
Abstract: This paper proposes a wearable robotic stick for walking assistance, called “Hand-Free-Stick” (HFS), for people with non-serious dysfunction in their gait. The basic idea of the proposed HFS is to enlarge ZMP (Zero moment point) area of a user under hands free conditions and to augment his/her body balance ability in walking. A boots type prototype of the HFS is developed with a lightweight robotic stick using a servomotor, in which the slider-link mechanism works to regulate the stick angle and length at the same time. The stick motion is controlled by a single-board computer based on the distribution of foot/feet pressures measured by the sensor system using eight load cells attached at the sole of boots. A set of walking tests with/without the prototype of HFS is carried out for four healthy subjects and demonstrates the effectiveness of the proposed HFS to expand the ZMP area leading to walking balance assistance.


Title: Soft Fabric Actuator for Robotic Applications
Key Words: electroactive polymer actuators  fabrics  microactuators  polymer fibres  polymers  wearable robots  weaving  coiled soft actuators  STCA multiple fabrication method  continuous fabrication method  actuation test  soft fabric actuator  actuation strain  robotic applications  twisted and coiled soft actuators  Spandex TCA  Nylon TCA  human arm size mannequin  angle control  Actuators  Fabrics  Fabrication  Strain  Weaving  Yarn  Connectors 
Abstract: This paper presents a fabric actuator consisting of ordinary polymer fibers, conductive fibers, and twisted and coiled soft actuators (TCAs). Previous studies have developed a Spandex TCA (STCA) that is driven at a lower temperature than the conventional Nylon TCA and exhibits greater actuation strain. However, no method to drive STCAs via electrical joule-heating has been developed yet. The fabric actuator presented in this paper offers a solution to this problem by employing an STCA multiple fabrication method, a continuous fabrication method, bundling technology, and weaving technology. Two types of samples (cylindrical and planar) are fabricated and their performances are evaluated experimentally. From the actuation test according to the loads, the maximum contraction strain of 34.3% is measured. The repeatability is also verified through 200 cycles of actuation. Using a linearized model, the dynamic performance of the fabric actuator is predicted and compared with experimental results. An actual human arm size mannequin is driven by applying the fabric actuator, and angle control can be achieved with an encoder mounted on the joint. In addition, fabric actuator is weaved to sweater showing the possibility of wearable assistive robot.


Title: Child-Sized Passive Exoskeleton for Supporting Voluntary Sitting and Standing Motions
Key Words: biomechanics  handicapped aids  medical robotics  motion control  patient rehabilitation  position control  springs (mechanical)  wearable robots  child-sized passive exoskeleton  voluntary sitting-standing posture transition  lower limb impairment  gas springs  voluntary upper body motion  posture transition model  minimum jerk criterion  toilet usage  toilet seat  voluntary posture transition  voluntary sitting motion  voluntary standing motion  exoskeleton design  center of gravity transition  seating position  locomotion capability  children self-reliant social activities  Exoskeletons  Knee  Wheelchairs  Pediatrics  Mathematical model  Trajectory  Springs 
Abstract: This paper describes a novel passive exoskeleton for voluntary sitting-standing posture transition for children with lower limb impairment. The design of the exoskeleton is based on the utilization of the center of gravity transition through the user's upper body motion. The passive exoskeleton powered by gas springs allows the user to realize a natural-like posture transition by the user's voluntary upper body motion. We designed the posture transition model such that the user can realize the posture transition in a natural manner based on a minimum jerk criterion. The proposed design aims to permit toilet usage without transferring seating positions between the exoskeleton and toilet seat. Furthermore, the developed mechanism can be integrated with a regular wheelchair, which would allow users to have locomotion capability. We believe that the design can improve children's self-reliant social activities by supporting their voluntary posture transition and toilet use. In this paper, we describe the detailed design process of the exoskeleton and preliminary experiments to investigate its effectiveness through evaluation with a healthy participant.


Title: Hands-Free Assistive Manipulator Using Augmented Reality and Tongue Drive System
Key Words: assisted living  augmented reality  handicapped aids  human-robot interaction  manipulators  mobile robots  robot vision  user interfaces  augmented reality glasses  robot autonomy  tongue drive system  egocentric perspective  visual feedback  Cartesian control  robotic assistant  cognitive burden  physical disabilities  hands-free collaborative manipulation  human-in-the-loop system  hands-free assistive manipulator  robotic arm  Manipulators  Task analysis  Visualization  Tongue  Three-dimensional displays  Machine vision 
Abstract: A human-in-the-loop system is proposed to enable hands-free collaborative manipulation for people with physical disabilities. Studies show that the cognitive burden of interfacing with a robotic assistant decreases with increased robot autonomy. Incorporating modern advances in perception with augmented reality, this paper describes a framework for obtaining high-level intents from the user to specify manipulation tasks for execution. Augmented reality glasses provide an egocentric perspective to the robot. The glasses also provide visual feedback to users on a virtual menu showing a summary of robot affordances. The system processes the vision input to interpret the users environment. A Tongue Drive System serves as the input modality for triggering task execution by the robotic arm. Several manipulation experiments are performed with comparison to Cartesian control. The outcomes are also compared to reported state-of-the-art approaches. The results demonstrate competitive performance with minimal user input requirements.


Title: Supervised Autonomous Locomotion and Manipulation for Disaster Response with a Centaur-Like Robot
Key Words: disasters  legged locomotion  manipulators  motion control  rescue robots  telerobotics  autonomous locomotion  mobile manipulation tasks  SAR  flexible locomotion  terrains  anthropomorphic upper body  complex tasks  direct teleoperation approaches  supervised autonomy approaches  disaster response scenarios  centaur-like robot Centauro  hybrid legged-wheeled base  operator assistance functionalities  search and rescue  Task analysis  Three-dimensional displays  Legged locomotion  Cameras  Robot vision systems 
Abstract: Mobile manipulation tasks are one of the key challenges in the field of search and rescue (SAR) robotics requiring robots with flexible locomotion and manipulation abilities. Since the tasks are mostly unknown in advance, the robot has to adapt to a wide variety of terrains and workspaces during a mission. The centaur-like robot Centauro has a hybrid legged-wheeled base and an anthropomorphic upper body to carry out complex tasks in environments too dangerous for humans. Due to its high number of degrees of freedom, controlling the robot with direct teleoperation approaches is challenging and exhausting. Supervised autonomy approaches are promising to increase quality and speed of control while keeping the flexibility to solve unknown tasks. We developed a set of operator assistance functionalities with different levels of autonomy to control the robot for challenging locomotion and manipulation tasks. The integrated system was evaluated in disaster response scenarios and showed promising performance.


Title: Design of a Lightweight, Ergonomic Manipulator for Enabling Expressive Gesturing in Telepresence Robots
Key Words: end effectors  ergonomics  gesture recognition  human-robot interaction  telerobotics  anthropomorphic end effector  telepresence experience  expressive gesturing  tangible interactions  face-to-face interactions  remote users  local users  remote communication  telepresence robots  telepresence interactions  ergonomic manipulator  lightweight manipulator  engaging communication  expressive communication  physical actions  subconscious quality  primary social behaviors  physical referencing  expressive gestures  Manipulators  Shoulder  Telepresence  Elbow  Kinematics  Torque 
Abstract: Recent research on telepresence robots demonstrates that while they enable new heights of remote communication, there still exists challenges for both local and remote users in creating a connectedness one only encounters in face-to-face interactions. A large part of communication is beyond hearing and vision. Tangible interactions, expressive gestures, and physical referencing represent three of the primary social behaviors missing in the current telepresence experience. There is an inherent, subconscious quality to these physical actions that has been shown to allow more expressive and engaging communication. In this project we present the design, fabrication, and initial performance validation of a lightweight, ergonomic manipulator with a heavy, anthropomorphic end effector that enables gesturing capabilities for telepresence interactions.


Title: Implementation of Augmented Teleoperation System Based on Robot Operating System (ROS)
Key Words: augmented reality  dexterous manipulators  haptic interfaces  human computer interaction  telerobotics  augmented teleoperation System  robot operating system  rugged robots  resource sharing  system integration  telerobotic system  operator interface  virtual fixture generation  current technology basis  human operator  complex robotic systems  telerobotic operation  enhanced teleoperator interface incorporating multimodal  current telerobotics technology  complex manipulation  dexterous manipulation  severe task requirements  unstructured nuclear environment  remote systems  ROS  Three-dimensional displays  Robot sensing systems  Telerobotics  Haptic interfaces  Fixtures 
Abstract: Deployment of robotics and remote systems for tasks in unstructured nuclear environment has been impeded by the severe task requirements such as high radiation and dexterous and complex manipulation of heavy materials, which cannot be addressed by the current telerobotics technology. To address such practical challenges, this paper presents an enhanced teleoperator interface incorporating multi-modal augmented reality, and new method of telerobotic operation based on perceptual overlay - `virtual fixtures'. Rather than trying to devise complex robotic systems, innovation is directed to enhancement of teleoperator interface so as to draw more performance and intuition from the human operator. Particular enhancements were made over the current technology basis in 3D sensing and reconstruction, virtual fixture generation, and operator interface. The telerobotic system was developed using ROS (Robot Operating System) to streamline system integration and resource sharing. The presented innovation is expected to allow deployment of simple and rugged robots to perform dexterous manipulation of heavy objects.


Title: Tracking-Based Depth Estimation of Metallic Pieces for Robotic Guidance
Key Words: force feedback  human computer interaction  human-robot interaction  manipulators  mobile robots  object recognition  robot vision  telerobotics  velocity control  human-robot interface  tracking experiments  metallic parts  vision-based control system  robotic arm  monochromatic objects  metallic connectors  metallic plates  featureless objects  teleoperation loop  tracking system  object recognition  higher-level applications  safer system  interaction modalities  force feedback  bilateral teleoperation  low level interaction methods  multimodal interactions  robotic operator  harsh environments  safe robotic interventions  robotic guidance  metallic pieces  depth estimation  Cameras  Estimation  Robot vision systems  Correlation  Object recognition  Target tracking 
Abstract: In order to perform safe robotic interventions in harsh environments it is necessary to help the robotic operator with a Human-Robot Interface that provides multimodal interactions, from low level interaction methods to bilateral teleoperation with force feedback. These interaction modalities, though, rely purely on the operator's skills. With the objective of providing a safer system, higher-level applications can be integrated in the interface in order to provide some help to the operator, without relying uniquely on his/her capacities. This paper presents a novel object recognition and tracking system which runs in real-time on the robot while the operator is operating it. The tracking system enters in the teleoperation loop and helps the operator to achieve the requested goals. The system is optimized to track featureless objects such as metallic plates, metallic connectors and monochromatic objects. Moreover, the algorithm provides improvements with respect to previous tracking experiments, including depth estimation in order to better interact with the velocity control of the robotic arm when approaching the target, as well as high reliability with partial occlusions. This vision-based control system is used in real interventions in hazardous environments, in order to track and manipulate metallic parts of scientific and engineering machines, giving a performance success over 95%, and reaching the 100% under the remote human supervision.


Title: Managing Off-Nominal Events in Shared Teleoperation with Learned Task Compliance
Key Words: control engineering computing  learning (artificial intelligence)  manipulator dynamics  mobile robots  telerobotics  off-nominal events  shared teleoperation  learned task compliance  teleoperation assistance  remote manufacturing  off-nominal situations  attenuate assistance  hole-cleaning task  imitation learning policies  Haptic interfaces  Task analysis  Robots  Collaboration  Trajectory  Tools  Force 
Abstract: This article studies imitation learning policies that encode task compliance to provide teleoperation assistance for remote manufacturing. The central challenge is how to handle off-nominal situations, such as out-of-sequence work or unplanned obstacles, since the assistance has not been trained to handle such scenarios. In such cases, there is potential for the assistance to degrade-rather than improve-operator performance. This work proposes a method that exploits the learned task compliance to classify persistent human actions as off-nominal, and attenuate assistance in these regions. Applied to a hole-cleaning task with n = 11 subjects, the proposed method shows up to 17% reduction in task completion time and up to 68% reduction in forces in off-nominal situations as compared to assistance without the method. Additionally, the method retains the performance improvements of assistance in nominal operating regimes.


Title: Inferring Semantic State Transitions During Telerobotic Manipulation
Key Words: control engineering computing  human-robot interaction  inference mechanisms  manipulators  mobile robots  service robots  telerobotics  telerobotic manipulation  autonomous operations  service robots  robot teleoperation  automated planning  higher abstraction level  semantic reasoning  abstract state  operational modes  simulation based geometric tracking  semantic state transitions inference  state inference entities  Semantics  Planning  Computational modeling  Physics  Robot sensing systems  Task analysis 
Abstract: Human teleoperation of robots and autonomous operations go hand in hand in today's service robots. While robot teleoperation is typically performed on low to medium levels of abstraction, automated planning has to take place on a higher abstraction level, i.e. by means of semantic reasoning. Accordingly, an abstract state of the world has to be maintained in order to enable an operator to switch seamlessly between both operational modes. We propose a novel approach that combines simulation based geometric tracking and semantic state inference by means of so called State Inference Entities to overcome this issue. We also demonstrate how Evolutionary Strategies can be employed to refine simulation parameters. All experiments are demonstrated in real-world experiments conducted with the humanoid robot Rollin' Justin.


Title: Smoother Position-Drift Compensation for Time Domain Passivity Approach Based Teleoperation
Key Words: compensation  delays  force feedback  motion control  position control  robust control  synchronisation  telerobotics  robust methods  bilateral teleoperation  position drift  slave devices  position synchronization  position-drift problem  TDPA-based teleoperation  force feedback  high impulse-like force signals  teleoperation task  energy-based TDPA  compensator  regular-amplitude forces  time domain passivity approach  position tracking  position-drift compensation  master devices  robust stability  time 500.0 ms  Force  Task analysis  Delays  Communication channels  Time-domain analysis  Delay effects  Admittance 
Abstract: Despite being one of the most robust methods in bilateral teleoperation, Time Domain Passivity Approach (TDPA)presents the drawback of accumulating position drift between master and slave devices. The lack of position synchronization poses an obstacle to the performance of teleoperation and may prevent the successful accomplishment of such tasks. Several techniques have been developed in order to solve the position-drift problem in TDPA-based teleoperation. However, they either present poor transparency by over-conservatively constraining force feedback or add high impulse-like force signals that can be harmful to the hardware and to the human operator. We propose a new approach to compensate position drift in TDPA-based teleoperation in a smoother way, which keeps the forces within the normal range of the teleoperation task while preserving the level of transparency and the robust stability of energy-based TDPA. We also add a way of tuning the compensator to behave in accordance with the task being performed, whether it requires faster or smoother compensation. The feasibility and performance of the method were experimentally validated. Good position tracking and regular-amplitude forces are demonstrated with up to 500 ms round-trip constant and variable delays for hard-wall contacts.


Title: An Ungrounded Master Device for Tele-Microassembly
Key Words: grippers  haptic interfaces  manipulator kinematics  microassembling  micromanipulators  position control  robotic assembly  telerobotics  velocity control  ungrounded master device  tele-microassembly  intuitive remote handling interface  portable instrumented tweezers  spatial motion  slave kinematics  slave robot  hand-held assembly tool  joystick-like interfaces  microgripper  haptic feedback  position variables  speed variables  Tracking  Haptic interfaces  Robot sensing systems  Force  Tools 
Abstract: Micro-assembly is a challenging issue for automation due to particularities of micro-world physics and limitations on sensors. Consequently, most applications are human-operated often with basic joystick-like interfaces. Beside being nonintuitive, these solutions do not provide their users with a meaningful insight into the microworld. This paper proposes a novel intuitive remote handling interface, using a classical hand-held assembly tool as a paradigm. The master device is a portable instrumented tweezers with one active degree of freedom. Its spatial motion, tracked by optical means, controls the slave kinematics while its pinch commands the slave robot's microgripper and provides haptic feedback. Different coupling strategies using position or speed variables are demonstrated.


Title: “Hammer: Robot Programming Interface for Common People”
Key Words: Android (operating system)  augmented reality  control engineering computing  industrial robots  production engineering computing  robot programming  user interfaces  visual programming  Hammer  robot programming interface  tablet-based end-user interface  industrial robot programming  Hephestos European project  Android application  Android OS  visual programming concept  online programming  reprogramming  robot control  manual-guidance interface  augmented-reality-based-monitoring system  scratch programming language  sensors systems  Service robots  Robot programming  Task analysis  Robot sensing systems  Intelligent robots  Industrial Robots  Human-Centered Robotics  Intelligent and Flexible Manufacturing 
Abstract: This video shows the main features of Hammer, a tablet-based end-user interface for industrial robot programming, in a real environment: a robotic cell created for the Hephestos European project. Hammer is an Android application that makes easier to program tasks for industrial robots like polishing, milling or grinding. It is based on the Scratch programming language, but specifically design and created for Android OS. It is a visual programming concept that allows non-skilled operators to create programs. The application allows to monitor the tasks while it is being executed by overlapping real time information through augmented reality. The application includes a teach pendant screen that can be customized according to the operator needs at every moment. The application is designed for online programming and reprogramming; easy use of learn-by-demonstration methods; easy connection with the robot control and sensors systems; and safety-system integration. It aims to be intuitive, easy to use, and simple. The application has four main parts: customized teach pendant, robot programming IDE and simulator, manual-guidance interface and augmented-reality-based-monitoring system.


Title: The Art of Manipulation: Learning to Manipulate Blindly
Key Words: human-robot interaction  learning (artificial intelligence)  manipulators  path planning  peg-in-hole problem  manipulation learning  human performance  robot manipulation  high-level manipulation planning  autonomous skill learning  inter-class generalization  insertion skills  human-level performance  manipulation strategies  basic motor control  Task analysis  Motor drives  Planning  Intelligent robots  Art  Bridges 
Abstract: Performing skillfull manipulation is a very challenging task for robots. So far, even experts could barely program them to e.g. perform the well known peg-in-hole problem in the real world. Autonomously acquiring such skills, let alone generalizing them to new tasks, is still a major challenge. Typically, manipulation learning is approached with the help of large computation power, very long learning times, or possibly both. However, the performance achieved up to now is still far from human performance. We show the results of our new paradigm to robot manipulation. It bridges and unifies basic motor control, simple and complex manipulation strategies and high-level manipulation planning. The robots show autonomous skill learning, intra-class and inter-class generalization of insertion skills at human-level performance.


Title: Toward the Next Generation of Robotic Waiters
Key Words: compensation  feedforward  manipulators  service robots  sloshing phenomena  orientation compensation  robotic waiters  feed-forward control  robot arm  feed-forward controller  motion capture system  robot manipulator  Glass  Manipulators  Intelligent robots  Next generation networking  Steel  Tracking 
Abstract: The gap between human waiters and state-of-the-art robot systems that try to serve something to drink is often embarrassing, with the former able to manipulate glasses and trays or glasses on trays with incredible dexterity and the latter that move at incredible slowness. In this video, we want to show that robots can do it better by moving a bottle or a tankard full of beer that are simply placed on a flat steel plate connected the flange of a robot manipulator. The robot tracks the trajectory defined by a human operator that moves its hand in the 3D space, with a motion capture system that acquires in real time the position. A feed-forward controller, placed between the user and the robot and based on the combination of a smoother and proper orientation compensation, counteracts the lateral accelerations and suppress sloshing phenomena of the liquids. Eventually a camera mounted on the robot arm provides a visual feedback to the operator with monitoring purposes. The challenge for the operator was to drop the carried object. will the feed-forward control be robust enough to avoid this event, even at high speed? Watch the video and find out!


Title: Human-Robot-Cooperation Real Time Robot Path Planning for Dynamic HRC-Applications
Key Words: collision avoidance  human-robot interaction  mobile robots  optimisation  path planning  collision optimization  real time robot path planning  dynamic obstacles  motion planning framework  pre-programmed robot paths  dynamic HRC-applications  human-robot-cooperation  unstructured environment  robot velocity  movement paths  free robot trajectories  framework plans  human-robot shared workspace  human obstacles  Robots  Collision avoidance  Real-time systems  Machine tools  Dynamics  Safety  Trajectory 
Abstract: Human-Robot shared workspace is a dynamic and unstructured environment. In such environment, pre-programmed robot paths might cause collisions or production disruptions. In order to solve this problem, motion planning framework has been proposed that adapts the robot's movement (path and speed)according to the human movement or any other dynamic obstacles in real time. Firstly, it defines the safety distance between robot and human or other obstacles. During run-time the 3D-Smart-Sensors capture the current position of human and other dynamic/static obstacles in human-robot shared workspace. The proposed framework plans and optimizes collision free robot trajectories with consideration for safety distance, path length and executing time. Once a new optimal trajectory is found, the framework controls the robot to adjust its movement paths. Moreover, the proposed framework can adjust the robot velocity based on the 3D-Zone Model of human-robot shared workspace. Therefore, the robot can reach its goal quickly and safely in a dynamic and unstructured environment.


Title: High Power Hand with Retention Mechanism
Key Words: biomechanics  dexterous manipulators  disasters  motion control  plates (structures)  power system control  retention mechanism  electrical power supply  electrical power saving  high power hand  multifingered robot hand  power manipulation  dexterous motion  Robots  Thumb  Power supplies  Force  Mechanical engineering  Conferences 
Abstract: When a disaster occurs, high output power should be available for rescue operation even if the electric supply is insufficient at site. This video presents a novel multi-fingered robot hand for extreme environments without a sufficient electric supply. The robot hand has four fingers with 16 joints and 12 degrees of freedom. The finger has a retention mechanism using no electrical power supply and a fingertip force of 150 [N]. Holding without power supply shows that our robot hand can lift a heavy barbell and keep its posture without using electrical power. The high fingertip force shows that steel cans can be crushed by the robot hand. In addition, dexterous motion of our robot hand shows that each finger allows flexion/extension and adduction/abduction. High-power manipulation shows that the robot hand can grasp and manipulate a hammer drill for making a hole in a concrete plate. The robot hand has a high potential for performing various tasks by obtaining high power output and electrical power saving.


Title: On-Chip Virtual Vortex Gear and Its Application
Key Words: flow visualisation  microchannel flow  pattern formation  valves  vortices  VVG  controllable valve  microfluidic system  flow speed  flow energy  chemical injection  sheath flow  3D flow patterns  On-Chip Virtual Vortex Gear  Reynolds number  parallel streamlines  circular chamber  target chamber  spontaneous diffusing  Gears  Valves  Chemicals  Mechanical engineering  Microfluidics  Conferences  Intelligent robots 
Abstract: This video presents a microfluidic phenomenon called “Virtual Vortex Gear (VVG)” and an application of it. The video contains 4 parts and is described as follows: The 1st part shows an application of VVG as a controllable valve in a micro fluidic system and the on and off of the valve are controlled by different flow speeds. The valve is turned on when the flow speed is high enough, and vice versa. The 2nd part shows the generation of VVG and its mechanism. When the flow speed, which is proportional to Reynolds Number, is gradually increased, the flow pattern evolves in the order as (1)parallel streamlines, (2)one vortex, (3)two vortices and eventually (4)three vortices including the last vortex inside the circular chamber. The evolution indicates the transmission of flow energy from the main stream to the inside of the chamber when the flow speed is over a certain range. In addition, every two adjacent vortices rotate in opposite directions which is just like a set of gears, and that is why we named it “VVG”. In the 3rd part, an application of VVG for chemical injection is demonstrated. A colored liquid is represented for the chemical and is surrounded by different sheath flow for the control of injection locations. It is found that only the fluid in a particular pinpoint can be injected into the target chamber. Furthermore, the complex but stable 3D flow patterns are visualized from the video. The last part of the video shows that different amount of chemical injection can be performed in different chambers along the same main stream and the distribution of the color is gradually become uniform by spontaneous diffusing.


Title: Deformation Capture via Self-Sensing Capacitive Arrays (Video)
Key Words: capacitance  capacitance measurement  capacitive sensors  computerised instrumentation  data acquisition  deformation  mesh generation  neural nets  deformation capture  soft self-sensing capacitive arrays  dense surface deformations  electrode patterns  single silicone compound  electrode strip patterns  local capacitors  local capacitance measurements change  fabrication technique  modern fablabs  resulting sensors  area changes  underlying motion  deep neural network  sensor geometry  local area measurements  motion capture system  runtime vertex positions  state-of-the-art elastic surface energy  prototype sensor  deforming skeletal  Robot sensing systems  Strain  Electrodes  Fabrication  Intelligent robots  Compounds  Capacitors 
Abstract: In this video we present soft self-sensing capacitive arrays and demonstrate their use in capturing dense surface deformations without requiring line of sight. The capacitive arrays are made of two electrode patterns embedded into a single silicone compound. The overlaps of the electrode strip patterns form local capacitors. As the sensor is stretched the local capacitance measurements change. We introduce a fabrication technique that allows to produce such sensors while only requiring hardware readily available in modern fablabs. The resulting sensors are able to densely capture area changes as they deform. Since they do not directly measure bend, a prior is required to fully reconstruct the underlying motion. We propose a deep neural network regressing the sensor geometry from the local area measurements. A motion capture system is used for training data acquisition. At runtime vertex positions are predicted and used as positional constraints to deform a mesh using a state-of-the-art elastic surface energy. The flexibility and accuracy of the introduced sensors is demonstrated in a series of controlled experiments and by fabricating a prototype sensor and applying it to capture deforming skeletal and non-skeletal objects.


Title: Excuse Me, May I Say Something? A Robot Facilitating Q&A for Lectures
Key Words: computer aided instruction  humanoid robots  human-robot interaction  Internet  neural nets  young students  CommU  desktop social robot  online messaging system  robot facilitating Q&a  Hiroshi Ishiguro  Logic gates  Intelligent robots  Monitoring  Neural networks 
Abstract: Hiroshi Ishiguro gave a lecture to a group of young students. We employed CommU, the desktop social robot, to manage the questions and answers for the talk. We encouraged the students to ask questions anytime. Half of the classroom was told to ask questions by raising their hand while the other half was shown an online messaging system developed for CommU, which allows the audience to post questions, which the robot would directly say. We had a gatekeeper to monitor for invalid sentences. In the middle of the presentation we asked the students to shift roles. The robot used a neural network based estimator of interruptibility to find the best time to speak. We did not expect too many questions, but the audience really embraced using the robot. They posted 44 questions to the presenter through CommU. On the other hand they asked 8 direct questions by raising their hands and standing up. Students thought that they gained more information from the lecturer using the robot than using the conventional method. In this instance we didnt stop the students from asking too many questions, but in a real-world application the gatekeeper will have to play an important role.


Title: Towards Autonomous Auto Calibration of Unregistered RGB-D Setups: The Benefit of Plane Priors
Key Words: calibration  cameras  image colour analysis  image reconstruction  optimisation  spatial variables measurement  autonomous autocalibration  color sensor  depth sensor  camera system  structure from motion reconstructions  SfM reconstructions  optimization  robust calibration algorithm  robot perception  unregistered RGB-D setups  Calibration  Cameras  Sensors  Robots  Image color analysis  Image reconstruction  Three-dimensional displays 
Abstract: In the last few years novel color and depth (RGB-D) sensors have greatly pushed robot perception. To enable a precise pixel-wise fusion of color and depth information good calibration is needed. The calibration determines the intrinsic parameters, the extrinsic parameters, and corrects for depth errors. While classic calibration approaches involve a dedicated calibration target and a trained expert, the autonomous calibration of such camera systems for robots operating in unknown environments is still an open problem. It demands for robust methods that do not need an expert to set up or tune the algorithm. Hence, we present a robust calibration algorithm that utilizes structure from motion (SfM) reconstructions as a calibration target and incorporates plane priors in the optimization to improve the convergence behavior and improve the calibration robustness. We evaluate our method against the state of the art performing over 300 experiments on ten different datasets, and show a significant improvement of the calibration accuracy.


Title: Adaptive Sensor Bias Estimation in Nine Degree of Freedom Inertial Measurement Units: Theory and Preliminary Evaluation
Key Words: angular measurement  attitude measurement  calibration  gyroscopes  inertial systems  magnetic field measurement  magnetic sensors  magnetometers  adaptive sensor bias estimation  three-axis magnetometers  three-axis accelerometers  three-axis angular rate sensors  high-end angular rate sensors  ring-laser gyros  MEMS gyros  compensation  attitude estimation  attitude and heading reference systems  nine degree of freedom inertial measurement units  sensor bias calibration methods  adaptive sensor bias observer  magnetic-north AHRS heading  DOF inertial measurement units  true-North heading AHRS estimation  Earth-rate estimation  9-DOF IMU measurements  Robot sensing systems  Magnetometers  Instruments  Accelerometers  Observers  Gyroscopes 
Abstract: Nine degrees of freedom (DOF) inertial measurement units (IMUs) comprised of three-axis magnetometers, three-axis accelerometers, and three-axis angular rate sensors are commonly used in attitude and heading reference systems (AHRSs). Two classes of AHRSs exist: systems that estimate true-North heading and systems that estimate magnetic-North heading. True-North heading AHRSs require high-end angular rate sensors which are sensitive enough to dynamically estimate Earth-rate (typically fiber-optic and ring-laser gyros), while magnetic-North AHRSs employ gyros that are not sensitive enough to dynamically estimate Earth-rate (i.e. all MEMS gyros). Thus, magnetic-North AHRSs employ magnetometers for estimating heading. This paper will focus on this class of magnetic-North AHRSs. These systems fuse IMU measurements to generate estimates of the instrument's roll, pitch, and magnetic heading. However, their accuracy is limited by sensor measurement bias that is unknown a priori. Hence, accurate sensor bias estimation and compensation is essential for true attitude estimation. This paper reports a novel adaptive sensor bias observer for sensor measurement biases in 9-DOF IMUs. The algorithm requires smaller angular movements of the instrument than other reported sensor bias calibration methods, does not require a priori knowledge of local fields like the local magnetic field or the local gravity vector, and does not require knowledge of the attitude of the instrument. Stability proofs, preliminary simulations, and a full-scale vehicle experimental evaluation are reported.


Title: Automatic Extrinsic Calibration of a Camera and a 3D LiDAR Using Line and Plane Correspondences
Key Words: calibration  cameras  measurement errors  optical radar  optical sensors  checkerboard  3D light detection and ranging sensor  3D line correspondences  3D plane correspondences  measurement errors  plane-only algorithms  LiDAR measurement  LiDAR intrinsic scale factor  calibration process  laser points  parallel planar targets  automatic extrinsic calibration  Cameras  Laser radar  Calibration  Three-dimensional displays  Lasers  Robot vision systems  Approximation algorithms 
Abstract: In this paper, we address the problem of extrinsic calibration of a camera and a 3D Light Detection and Ranging (LiDAR) sensor using a checkerboard. Unlike previous works which require at least three checkerboard poses, our algorithm reduces the minimal number of poses to one by combining 3D line and plane correspondences. Besides, we prove that parallel planar targets with parallel boundaries provide the same constraints in our algorithm. This allows us to place the checkerboard close to the LiDAR so that the laser points better approximate the target boundary without loss of generality. Moreover, we present an algorithm to estimate the similarity transformation between the LiDAR and the camera for the applications where only the correspondences between laser points and pixels are concerned. Using a similarity transformation can simplify the calibration process since the physical size of the checkerboard is not needed. Meanwhile, estimating the scale can yield a more accurate result due to the inevitable measurement errors of the checkerboard size and the LiDAR intrinsic scale factor that transforms the LiDAR measurement to the metric measurement. Our algorithm is validated through simulations and experiments. Compared to the plane-only algorithms, our algorithm can obtain more accurate result by fewer number of poses. This is beneficial to the large-scale commercial application.


Title: SCALAR - Simultaneous Calibration of 2D Laser and Robot's Kinematic Parameters Using Three Planar Constraints
Key Words: calibration  industrial robots  laser ranging  position control  robot kinematics  calibration approaches  calibration parameters  geometric planar constraints  2D Laser Range Finder  6-DoF robot  calibration method  laser tracker  expensive external measurement system  calibrations  robot accuracy  industrial robots  kinematic parameters  simultaneous calibration  SCALAR  robot system  Robot kinematics  Calibration  Cameras  Measurement by laser beam  Kinematics  Robot vision systems 
Abstract: Industrial robots are increasingly used in various applications where the robot accuracy becomes very important, hence calibrations of the robot's kinematic parameters and the measurement system's extrinsic parameters are required. However, the existing calibration approaches are either too cumbersome or require another expensive external measurement system such as laser tracker or measurement spinarm. In this paper, we propose SCALAR, a calibration method to simultaneously improve the kinematic parameters of a 6-DoF robot and the extrinsic parameters of a 2D Laser Range Finder (LRF) that is attached to the robot. Three flat planes are placed around the robot, and for each plane the robot moves to several poses such that the LRF's ray intersect the respective plane. Geometric planar constraints are then used to optimize the calibration parameters using Levenberg-Marquardt nonlinear optimization algorithm. We demonstrate through simulations that SCALAR can reduce the average position and orientation errors of the robot system from 14.6 mm and 4.05° to 0.09 mm and 0.02°.


Title: Automated Tool Coordinate Calibration System of an Industrial Robot
Key Words: artificial intelligence  calibration  cameras  computer vision  error compensation  industrial manipulators  industrial robots  machine tools  neural nets  position control  production engineering computing  robot vision  tool calibration  automated tool  freight handling  tool replacement  collision accident  routine maintenance  tool coordinates  current industrial practices  artificial intelligence method  manual method  system independent method  automatic calibration  hand camera  tool position data  coordinate system conversion  calibration system functions  current robot  6-degree-0f-freedom industrial robot  optimal deep neural network method error compensation  Tools  Robot kinematics  Cameras  Calibration  Service robots  Robot vision systems  Calibration  Tool Coordinate  CamShift  MeanShift  DNN 
Abstract: Due to the widespread use of industrial robots in market, its application has extended to welding, painting, and freight handling. And tool coordinate calibration is regularly modified after tool replacement due to collision accident or routine maintenance. After tool replacement, operators often rebuild tool coordinates. This is the traditional mode of operation in the current industrial practices. However, smart factory will make artificial intelligence method replace manual method. This paper presents a system independent method for automatic calibration of the tool coordinate system which is faster, simpler, cheaper and more effective than the manual method. The proposed method required images to be captured using two “eye to hand” cameras and one “eye in hand” camera. Tool position data is then acquired through CamShift and MeanShift algorithm for image trajectory tracking along with coordinate system conversion, several methods like PCA, LDA can deal with the vision data. Optimal Deep Neural Network (DNN) method error compensation of a robot allows the tool to automatically run with the calibration system functions. We have developed a 6 degrees of freedom(DoF) industrial robot for this experiment. Nine different kinds of DNN models are built and finally with suitable tool coordinate error compensation for the current robot, tool calibration can be achieved adaptively and efficiently.


Title: Robust Optimization-Based Calculation of Invariant Trajectory Representations for Point and Rigid-body Motion
Key Words: image motion analysis  image recognition  image reconstruction  image representation  optimisation  smoothing methods  standard smoothing methods  measurement noise  motion trajectories  robust optimization-based calculation  invariant trajectory representations  motion experiments  motion recognition  context-independent motion models  rigid-body motion  Trajectory  Sensitivity  Smoothing methods  Context modeling  Fasteners  Noise measurement  Programming 
Abstract: Invariant representations of demonstrated motion trajectories provide context-independent motion models that can be used in motion recognition and generalization applications such as robot programming by demonstration. In practice, the use of invariant representations is still limited because their numerical calculation from a demonstrated trajectory is complicated by sensitivity to measurement noise and singularities, yielding inaccurate invariant functions that do not correspond well with the original trajectory. This paper improves the calculation of invariant representations for point and rigid-body motions by reformulating their calculation as an optimization problem that minimizes the error between the trajectory reconstructed from the invariant representation and the measured trajectory. Robustness against noise and singularities is ensured through the addition of regularization terms on the invariants. Simulations and real motion experiments show that the accuracy of the calculated invariant representations greatly improves with respect to standard smoothing methods. These results encourage future developments of motion recognition and generalization applications based on invariant trajectory representations.


Title: Reducing the Computational Complexity of Mass-Matrix Calculation for High DOF Robots
Key Words: computational complexity  manipulator dynamics  matrix algebra  position control  high DOF robots  geometric dynamics algorithm for high number of robot joints  GDAHJ  JSIM  joint space inertia matrix  dynamics computations  degrees of freedom  mass-matrix calculation  computational complexity  Acceleration  Mathematical model  Heuristic algorithms  Robot kinematics  Dynamics  Computational complexity  mass-matrix  dynamics  Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ)  high DOF robots 
Abstract: Increasingly, robots have more degrees of freedom (DOF), imposing a need for calculating more complex dynamics. As a result, better efficiency in carrying out dynamics computations is becoming more important. In this study, an efficient method for computing the joint space inertia matrix (JSIM) for high DOF serially linked robots is addressed. We call this method the Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ). GDAHJ is non-symbolic, preserve simple formulation, and it is convenient for numerical implementation. This is achieved by simplifying the way to recursively derive the mass-matrix exploiting the unique property of each column of the JSIM and minimizing the number of operations with O(n2) complexity. Results compare favorably with existing methods, achieving better performance over state-of-the-art by Featherstone when applied for robots with more than 13 DOF.


Title: Position-Based Time-Integrator for Frictional Articulated Body Dynamics
Key Words: friction  graphics processing units  Newton method  optimisation  robot dynamics  Newton-Euler-based simulator  Newton-type optimization scheme  friction forces  position variables  frictional dynamics  frictional articulated body dynamics  position-based time-integrator  Mathematical model  Friction  Dynamics  Heuristic algorithms  Optimization  Linear programming  Robots 
Abstract: We present a new time-integrator for modeling the frictional dynamics of articulated bodies. Our formulation represents the configuration of the articulated body using position variables and then uses those variables to model the friction forces between the articulated body and the environment. Our approach corresponds to a Newton-type optimization scheme that is guaranteed to converge so that it is stable with large timestep sizes. We evaluate the accuracy and stability of our time-integrator by comparing it with a conventional formulations based on the Newton-Euler equation and demonstrate the benefits on standard controller-optimization applications. We achieve 3-5 times speedup over a Newton-Euler-based simulator on a CPU. Our approach can be easily parallelized on a GPU and results in additional 4-15 times performance improvement.


Title: Actuator and Friction Dynamics Formulation in Control of PKMs: From Design to Real-Time Experiments
Key Words: actuators  control system synthesis  feedforward  friction  manipulator dynamics  motion control  position control  real-time experiments  dynamic formulation  parallel manipulators  actuator  friction dynamics  model-based controller  computed feedforward  formulated dynamics  control performance  high-speed motions  feedforward part  computational efforts  PKM  four-degree-of-freedom parallel robot  unfavourable nonlinearity abundant extensively  Friction  Actuators  Dynamics  Manipulator dynamics  Computational modeling  Torque 
Abstract: This paper deals with a new dynamic formulation of parallel manipulators incorporating the actuator and friction dynamics to be utilized in control. A model-based controller, PD with computed feedforward, is implemented for a parallel robot taking into consideration the formulated dynamics. The motivation behind this contribution is to enhance the control performance by compensating the unfavourable nonlinearities abundant extensively in PKMs. Those nonlinearities may increase considerably when operating at high-speed motions. The proposed feedforward part relies on the reference trajectories instead of the measured ones improving the control performance and the computational efforts. To validate our contribution, real-time experiments are conducted on a four degree-of-freedom parallel robot named VELOCE in different operating conditions.


Title: Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair
Key Words: aerodynamics  aircraft maintenance  end effectors  industrial robots  inspection  mechatronics  suspensions (mechanical components)  slender dual-structure continuum robot  In-Situ Aeroengine Repair  in-situ aeroengine maintenance works  end-effector  aeroengine combustion chamber  configuration-cable kinematics  Maintenance engineering  Kinematics  Inspection  Shape  End effectors  Task analysis 
Abstract: In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.


Title: Reasoning Systems for Semantic Navigation in Mobile Robots
Key Words: control engineering computing  inference mechanisms  mobile robots  navigation  ontologies (artificial intelligence)  path planning  semantic navigation paradigm  mobile robot  environmental semantic concepts  ontological model  KnowRob  relational database  reasoning system  semantic representation  semantic navigation system  Navigation  Ontologies  Semantics  Cognition  Mobile robots  Relational databases 
Abstract: Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.


Title: Hybrid Approach for Human Activity Recognition by Ubiquitous Robots
Key Words: image recognition  learning (artificial intelligence)  mobile robots  ontologies (artificial intelligence)  ubiquitous computing  human activity recognition  ubiquitous robots  context-aware intelligent services  humans  professional living activities  daily living activities  consistent description  correct description  human context  Ontologies  Activity recognition  Machine learning  Dairy products  Robot sensing systems 
Abstract: One of the main objectives of ubiquitous robots is to proactively provide context-aware intelligent services to assist humans in their professional or daily living activities. One of the main challenges is how to automatically obtain a consistent and correct description of human context such as location, activities, emotions, etc. In this paper, a new hybrid approach for reasoning on the context is proposed. This approach focuses on human activity recognition and consists of machine-learning algorithms, an expressive ontology representation, and a reasoning system. The latter allows detecting the inconsistencies that may appear during the machine learning phase. The proposed approach can also correct automatically these inconsistencies by considering the context of the ongoing activity. The obtained results on the Opportunity dataset demonstrate the feasibility of the proposed method to enhance the performance of human activity recognition.


Title: Approaches for Action Sequence Representation in Robotics: A Review
Key Words: reviews  robots  robotics  action sequences representation  robots  action sequence representation  complex robotic tasks  robot task  Task analysis  Planning  Calculus  Strips  Service robots  Proposals 
Abstract: Robust representation of actions and its sequences for complex robotic tasks would transform robot's understanding to execute robotic tasks efficiently. The challenge is to understand action sequences for highly unstructured environments and to represent and construct action and action sequences. In this manuscript, we present a review of literature dealing with representation of action and action sequences for robot task planning and execution. The methodological review was conducted using Google Scholar and IEEE Xplore, searching the specific keywords. This manuscript gives an overview of current approaches for representing action sequences in robotics. We propose a classification of different methodologies used for action sequences representation and describe the most important aspects of the reviewed publications. This review allows the reader to understand several options that do exist in the research community, to represent and deploy such action representations in real robots.


Title: Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots
Key Words: control engineering computing  human-robot interaction  industrial manipulators  manipulator kinematics  ontologies (artificial intelligence)  production engineering computing  robot programming  ontology-based knowledge representation  dual-arm robotic system  industrial applications  end-user programming  robot arms  intuitive programming  task transfer  kinematics  robot-agnostic skills  industrial robots skill reusability  Robot kinematics  Synchronization  Service robots  Ontologies  Manipulators  Task analysis 
Abstract: We assume that an intuitive means for the specification, re-use, modification and transfer of synchronized motions-both regarding the two arms of a dual-arm robotic system, as well as regarding the coordination of a user and a robot-is key in interactive and collaborative settings as they are currently targeted for industrial applications. We show, how our knowledge based approach to end-user programming of synchronized motions and other generalizable, robot-agnostic skills can support such specification of coordinated actions between two robot arms and explain how that could be extended to include coordination with a human user. We describe the underlying ontologies and possibilities to populate those with an interface for intuitive programming, and show the generality of our approach through a task transfer between different kinematics (different robots), where the user is supported through underlying reasoning about the fulfillment of certain parameters or constraints for the involved skills.


Title: Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).
Key Words: control engineering computing  ontologies (artificial intelligence)  robots  ontology  robotic skills  structural part  base configuration  abstract structure  modular robotic platform  skill-oriented designer  conceptual robotic structures  Robot sensing systems  Ontologies  Legged locomotion  Semantics  Taxonomy  Morphology 
Abstract: This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.


Title: Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.
Key Words: disasters  emergency management  emergency services  multi-agent systems  rescue robots  wireless sensor networks  search and rescue missions  wireless sensor networks  robots  mobile node  heterogeneous agents  multiagent team  natural disasters  human disasters  emergency response  information gathering  wireless sensor network  canine agent  Dogs  Wireless sensor networks  Receivers  Mobile nodes  Transmitters  Databases 
Abstract: Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.


Title: PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python
Key Words: aerospace robotics  cameras  computer aided instruction  control engineering education  educational courses  mobile robots  Python  remotely operated vehicles  robot programming  robot vision  state estimation  three-term control  high-level planning  PiDrone  autonomous educational drone  Python  compelling robotics course  low-cost aerial educational platform  associated college-level introductory robotics course  autonomous aircraft  downward facing RGB camera  distance sensor  onboard Raspberry Pi  accessible platform  inexpensive platform  SSH capable computer  base station  programming platform  robotics operating system framework  ROS framework  PID control  state estimation  Drones  Educational robots  Robot sensing systems  Python  Service robots  Hardware 
Abstract: A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.


Title: State Estimate Recovery for Autonomous Quadcopters
Key Words: acceleration measurement  aerodynamics  autonomous aerial vehicles  channel bank filters  helicopters  Kalman filters  nonlinear filters  robot dynamics  state estimation  state estimate recovery  autonomous quadcopters  aerodynamic force model  extended Kalman filters  linear acceleration measurements  complete recovery logic  quadcopter platform  IMU  Aerodynamics  Gravity  Mathematical model  Accelerometers  Propellers  Data models  Position measurement 
Abstract: A method for recovery from the complete loss of the state estimate is presented for autonomous quadcopters. Given an aerodynamic force model, the only measurements used to reinitialize the state estimate by means of a bank of extended Kalman filters are the angular rate and linear acceleration measurements of an IMU. The method is integrated within a complete recovery logic on a quadcopter platform and experimentally evaluated.


Title: A Revisited Approach to Lateral Acceleration Modeling for Quadrotor UAVs State Estimation
Key Words: aerodynamics  autonomous aerial vehicles  blades  drag  helicopters  Kalman filters  mobile robots  nonlinear filters  robot dynamics  state estimation  lateral acceleration modeling  quadrotor UAVs state estimation  rotors angular speeds  quadrotor drag  lateral accelerations  flight test data  attitude state estimator  EKF-based estimator  velocity state estimator  vehicle aerodynamics modeling  blade element theory  Rotors  Blades  Acceleration  Optical sensors  Data models  Atmospheric modeling  Aerodynamics 
Abstract: Quadrotor state estimation generally relies on the vehicle aerodynamics modeling to achieve improved performance. In this paper the effects of the rotors angular speeds on the quadrotor drag, and therefore on the lateral accelerations, are investigated. While these effects are usually disregarded, we analyze their modeling starting from the Blade Element Theory and flight test data. Two lateral acceleration formulations are proposed. They are adopted within a velocity and attitude state estimator and validated in real-world flights. The EKF-based estimator fuses measurements from low-cost sensors present in the majority of quadrotors (IMU, magnetometer, ultrasonic sensor, optical flow) with the accelerations of the vehicle predicted from the revisited models. Experimental results show the benefits of adopting these innovative models in the estimator when compared with the existing modeling approach.


Title: Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles
Key Words: aerospace robotics  collision avoidance  inspection  optical sensors  power overhead lines  sensor placement  collision avoidance  optical sensors  sensor placement  fixed energy infrastructure  aerial inspection  multirotor platform  assisted control technology  aerial vehicles  semiautonomous power infrastructure inspection  proximity inspection tasks  assisted control approach  Inspection  Wires  Measurement  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles  Task analysis 
Abstract: This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.


Title: DREGON: Dataset and Methods for UAV-Embedded Sound Source Localization
Key Words: acoustic noise  acoustic signal processing  aerospace computing  audio signal processing  autonomous aerial vehicles  control engineering computing  microphone arrays  broad-band source localization  microphone array  noisy in-flight audio recordings  3D position  rotor rotational speed  loud noise conditions  extreme noise levels  accurate motion capture system  target sound source  UAV-embedded sound source localization  DREGON  Microphone arrays  Propellers  Drones  Robots  White noise 
Abstract: This paper introduces DREGON, a novel publicly-available dataset that aims at pushing research in sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). The dataset contains both clean and noisy in-flight audio recordings continuously annotated with the 3D position of the target sound source using an accurate motion capture system. In addition, various signals of interests are available such as the rotational speed of individual rotors and inertial measurements at all time. Besides introducing the dataset, this paper sheds light on the specific properties, challenges and opportunities brought by the emerging task of UAV-embedded sound source localization. Several baseline methods are evaluated and compared on the dataset, with real-time applicability in mind. Very promising results are obtained for the localization of a broad-band source in loud noise conditions, while speech localization remains a challenge under extreme noise levels.


Title: Joint 3D Proposal Generation and Object Detection from View Aggregation
Key Words: image classification  image colour analysis  image fusion  mobile robots  neural nets  object detection  optical radar  radar detection  regression analysis  road vehicle radar  robot vision  high resolution feature maps  reliable 3D object proposals  multiple object classes  category classification  second stage detection network  AVOD  KITTI 3D object detection  autonomous vehicles  3D bounding box regression  multimodal feature fusion  RPN  region proposal network  RGB images  LIDAR point clouds  neural network architecture  autonomous driving scenarios  Aggregate View Object Detection network  joint 3D proposal generation  Three-dimensional displays  Feature extraction  Proposals  Computer architecture  Agriculture  Object detection  Two dimensional displays 
Abstract: We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.


Title: TSSD: Temporal Single-Shot Detector Based on Attention and LSTM
Key Words: feature extraction  object detection  robot vision  video signal processing  convolutional long short-term memory  creative temporal analysis unit  multiscale feature maps  high-level ConvLSTM unit  pyramidal feature hierarchy  attention mechanism  real-time online approaches  video detection task  robotic vision  rich temporal information  temporal object detection  temporal single-shot detector  developed TSSD  attention-aware features  scale suppression  background suppression  ConvLSTM-based attention  attention-based ConvLSTM  Feature extraction  Detectors  Robots  Task analysis  Visualization  Lenses  Proposals 
Abstract: Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.


Title: Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors
Key Words: computer vision  image segmentation  image sensors  Kalman filters  object detection  pattern clustering  target tracking  event-based sensors  computer vision applications  robust tracking  object detection  segmentation  real-time clustering technique  event-based vision sensors  mean-shift clustering method  asynchronous events  multitarget tracking application  clustering accuracy  frame-based method  Sensors  Shape  Real-time systems  Kalman filters  Target tracking  Robots 
Abstract: Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.


Title: Speeding-Up Object Detection Training for Robotics with FALKON
Key Words: computer vision  data mining  feature extraction  learning (artificial intelligence)  object detection  robots  sampling methods  stochastic processes  end-to-end learning  deep feature extractor  bootstrapping approach  object detection training  deep learning methods  robotic applications  back-propagation  region proposal network  hard negatives mining  FALKON algorithm  kernel-based method  stochastic subsampling  computer vision dataset  Training  Feature extraction  Pipelines  Object detection  Robots  Task analysis  Proposals 
Abstract: Latest deep learning methods for object detection provide remarkable performance, but have limits when used in robotic applications. One of the most relevant issues is the long training time, which is due to the large size and imbalance of the associated training sets, characterized by few positive and a large number of negative examples (i.e. background). Proposed approaches are based on end-to-end learning by back-propagation [22] or kernel methods trained with Hard Negatives Mining on top of deep features [8]. These solutions are effective, but prohibitively slow for on-line applications. In this paper we propose a novel pipeline for object detection that overcomes this problem and provides comparable performance, with a 60x training speedup. Our pipeline combines (i) the Region Proposal Network and the deep feature extractor from [22] to efficiently select candidate RoIs and encode them into powerful representations, with (ii) the FALKON [23] algorithm, a novel kernel-based method that allows fast training on large scale problems (millions of points). We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach. We assess the effectiveness of the approach on a standard Computer Vision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a real robotic scenario with the iCubWorld Transformations [18] dataset.


Title: Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels
Key Words: image annotation  image segmentation  learning (artificial intelligence)  image modalities  sparse labeling data  human interaction reduction  environment monitoring data  sparse annotation augmentation  dense ground-truth  label augmentation  adaptive superpixel segmentation propagation  dense semantic segmentation models  pixel level labeling  life applicability  common deep learning models  deep learning approaches  image pixel  multilevel superpixels  effective learning  Image segmentation  Semantics  Labeling  Training  Biological system modeling  Monitoring  Deep learning 
Abstract: Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.


Title: Real-Time Segmentation with Appearance, Motion and Geometry
Key Words: autonomous aerial vehicles  cameras  distance measurement  Global Positioning System  image motion analysis  image segmentation  mobile robots  motion estimation  object detection  remotely operated vehicles  robot vision  domain knowledge  planar scenes  high altitude unmanned aerial vehicles  homography compensated flow  urban scenes  autonomous driving  depth estimates  segmentation accuracy  geometric priors  UAV imagery  baseline network  sparse depth  motion segmentation solution  assisted systems  traffic monitoring  unmanned aerial vehicles imagery  two-stream convolutional network  geometric cues  computational efficiency trade-offs  real-time segmentation  GPS-IMU sensory data  KITTI-MoSeg  Motion segmentation  Computer vision  Real-time systems  Convolutional codes  Autonomous vehicles  Unmanned aerial vehicles  Image segmentation 
Abstract: Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at1.


Title: Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation
Key Words: cameras  collision avoidance  control engineering computing  convolutional neural nets  edge detection  image segmentation  mobile robots  remotely operated vehicles  robot vision  stereo image processing  water edge  stereo extensions  joint stereo-view semantic segmentation  unmanned surface vehicles  scene semantic segmentation problem  single-view model  consistent class labels assignment  monocular CNN  class-label posterior map  stereo-based obstacle detection  Semantics  Image segmentation  Cameras  Image edge detection  Sea surface  Graphical models  Three-dimensional displays 
Abstract: We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.


Title: Efficient Absolute Orientation Revisited
Key Words: attitude measurement  computer vision  matrix decomposition  optimisation  singular value decomposition  fast optimal attitude matrix algorithm  optimal linear attitude estimator method  3D point sets  OLAE method  computer vision  similarity transformation  absolute orientation estimation  attitude estimation techniques  FOAM-based solution  singular-value matrix decompositions  absolute orientation algorithm  robotics  Quaternions  Estimation  Symmetric matrices  Eigenvalues and eigenfunctions  Matrix decomposition  Covariance matrices  Computer vision 
Abstract: Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.


Title: Active Structure-from-Motion for 3d Straight Lines
Key Words: mobile robots  observability  robot vision  visual servoing  Active Structure-from-Motion  planning  Image-Based Visual Servoing  control scheme  straight lines  control law  control effort  3D straight lines  convergence rate  3D parameter estimation  Three-dimensional displays  Cameras  Convergence  Eigenvalues and eigenfunctions  Robots  Observers 
Abstract: A reliable estimation of 3D parameters is a must for several applications like planning and control, in which is included Image-Based Visual Servoing. This control scheme depends directly on 3D parameters, e.g. depth of points, and/or depth and direction of 3D straight lines. Recently, a framework for Active Structure-from-Motion was proposed, addressing the former feature type. However, straight lines were not addressed. These are 1D objects, which allow for more robust detection, and tracking. In this work, the problem of Active Structure-from-Motion for 3D straight lines is addressed. An explicit representation of these features is presented, and a change of variables is proposed. The latter allows the dynamics of the line to respect the conditions for observability of the framework. A control law is used with the purpose of keeping the control effort reasonable, while achieving a desired convergence rate. The approach is validated first in simulation for a single line, and second using a real robot setup. The latter set of experiments are conducted first for a single line, and then for three lines.


Title: Stereo Camera Localization in 3D LiDAR Maps
Key Words: cameras  Global Positioning System  image matching  image reconstruction  mobile robots  optical radar  pose estimation  robot vision  SLAM (robots)  stereo image processing  stereo disparity map  average localization error  stereo camera localization  Global Positioning System  3D LiDAR maps  simultaneous localization and mapping techniques  SLAM techniques  3D light detection and ranging sensors  visual positioning algorithm  GPS signal  visual tracking  six degree of freedom  DOF  camera pose estimation  KITTI dataset  Cameras  Three-dimensional displays  Laser radar  Simultaneous localization and mapping  Visualization  Global Positioning System 
Abstract: As simultaneous localization and mapping (SLAM) techniques have flourished with the advent of 3D Light Detection and Ranging (LiDAR) sensors, accurate 3D maps are readily available. Many researchers turn their attention to localization in a previously acquired 3D map. In this paper, we propose a novel and lightweight camera-only visual positioning algorithm that involves localization within prior 3D LiDAR maps. We aim to achieve the consumer level global positioning system (GPS) accuracy using vision within the urban environment, where GPS signal is unreliable. Via exploiting a stereo camera, depth from the stereo disparity map is matched with 3D LiDAR maps. A full six degree of freedom (DOF) camera pose is estimated via minimizing depth residual. Powered by visual tracking that provides a good initial guess for the localization, the proposed depth residual is successfully applied for camera pose estimation. Our method runs online, as the average localization error is comparable to ones resulting from state-of-the-art approaches. We validate the proposed method as a stand-alone localizer using KITTI dataset and as a module in the SLAM framework using our own dataset.


Title: Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics
Key Words: cameras  energy harvesting  feature extraction  Haar transforms  image classification  image colour analysis  image texture  mobile robots  neural nets  robot vision  solar power  terrain mapping  wavelet transforms  outdoor mobile robots  feature extraction  visual-spectrum images  on-board camera  Haar wavelet transform  color information  textural information  ANN  high dynamic range imagery  energy consumption  traversability criteria  energy harvesting capabilities  vision-based artificial neural network  sequential methodology  solar irradiance map  terrain classes  solar-powered mobile robots  real-time terrain classification  solar irradiance mapping  vision-based terrain classification  Image color analysis  Feature extraction  Neural networks  Training  Image segmentation  Wavelet transforms  Sensors  Field Robotics  Image Processing  Solar Mapping  Terrain Classification  Solar Robotics 
Abstract: This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.


Title: Towards Real-Time Unsupervised Monocular Depth Estimation on CPU
Key Words: embedded systems  estimation theory  feature extraction  image reconstruction  image sensors  learning (artificial intelligence)  microprocessor chips  mobile robots  object detection  robot vision  stereo image processing  robotic navigation  autonomous navigation  deep learning  low-power constraints  embedded system  single input image  image reconstruction problem  KITTI image  depth map  CPU  unsupervised monocular depth estimation  features extraction  time 1.7 s  frequency 8.0 Hz  frequency 40.0 Hz  Estimation  Feature extraction  Computer architecture  Training  Decoding  Image resolution  Real-time systems 
Abstract: Unsupervised depth estimation from a single image is a very attractive technique with several implications in robotic, autonomous navigation, augmented reality and so on. This topic represents a very challenging task and the advent of deep learning enabled to tackle this problem with excellent results. However, these architectures are extremely deep and complex. Thus, real-time performance can be achieved only by leveraging power-hungry GPUs that do not allow to infer depth maps in application fields characterized by low-power constraints. To tackle this issue, in this paper we propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image. Similarly to state-of-the-art, we train our network in an unsupervised manner casting depth estimation as an image reconstruction problem. Extensive experimental results on the KITTI dataset show that compared to the top performing approach our network has similar accuracy but a much lower complexity (about 6% of parameters) enabling to infer a depth map for a KITTI image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard CPU. Moreover, by trading accuracy for efficiency, our network allows to infer maps at about 2 Hz and 40 Hz respectively, still being more accurate than most state-of-the-art slower methods. To the best of our knowledge, it is the first method enabling such performance on CPUs paving the way for effective deployment of unsupervised monocular depth estimation even on embedded systems.


Title: A Plug-In Feed-Forward Control for Sloshing Suppression in Robotic Teleoperation Tasks
Key Words: compensation  containers  end effectors  feedforward  industrial robots  manipulator dynamics  mobile robots  motion control  sloshing  telerobotics  trajectory control  position-orientation trajectory  dynamic filter design  sloshing dynamics suppression  lateral accelerations  active compensation  liquid oscillations  filtering technique  design philosophy  robot end-effector  liquid container  liquid handling robotic systems  robotic teleoperation tasks  feed-forward control  motion capture system  harmonic smoother  Liquids  Containers  Robots  Acceleration  Trajectory  Mathematical model  Vibrations 
Abstract: In this paper, the problem of suppressing sloshing dynamics in liquid handling robotic systems has been faced by designing a dynamic filter that starting from the desired motion of the liquid container calculates the complete position/orientation trajectory for the robot end-effector. Specifically, a design philosophy mixing a filtering technique that suppresses the frequency contributions of the reference motion that may cause liquid oscillations and an active compensation of lateral accelerations by a proper container re-orientation has been adopted. In principle, the latter contribution requires the knowledge of acceleration of the reference trajectory, but because of the use of an harmonic smoother that performs a shaping of the original motion, it is possible to obtain the value of the acceleration in runtime. In this way, the proposed methods can be applied also to reference motions that are not known in advance, e.g. commands directly provided by a human operator. This possibility has been demonstrated by means of a number of experimental tests in which the user teleoperates the robot carrying the container with the liquid by simply moving in the free space its hand, whose 3D position is detected by a motion capture system.


Title: Elastic Structure Preserving Impedance (ESπ)Control for Compliantly Actuated Robots
Key Words: closed loop systems  damping  end effectors  Lyapunov methods  manipulator dynamics  stability  compliantly actuated robots  possibly nonlinear spring characteristics  damping range  end-effector interaction behavior  external loads approach  classical Cartesian impedance control  closed-loop dynamics  elastic structure preserving impedance control  stability analysis  Lyapunov function  Robot kinematics  Impedance  Springs  Damping  Dynamics  Actuators 
Abstract: We present a new approach for Cartesian impedance control of compliantly actuated robots with possibly nonlinear spring characteristics. It reveals a remarkable stiffness and damping range in the experimental evaluation. The most interesting contribution, is the way the desired closed-loop dynamics is designed. Our control concept allows to add a desired stiffness and damping directly on the end-effector, while leaving the system structure intact. The intrinsic inertial and elastic properties of the system are preserved. This is achieved by introducing new motor coordinates that reflect the desired spring and damper terms. Theoretically, by means of additional motor inertia shaping it is possible to make the end-effector interaction behavior with respect to external loads approach, arbitrarily close, the interaction behavior that is achievable by classical Cartesian impedance control on rigid robots. The physically motivated design approach allows for an intuitive understanding of the resulting closed-loop dynamics. We perform a passivity and stability analysis on the basis of al physically motivated storage and Lyapunov function.


Title: An Efficient and Time-Optimal Trajectory Generation Approach for Waypoints Under Kinematic Constraints and Error Bounds
Key Words: manipulator kinematics  nonlinear programming  path planning  time optimal control  trajectory control  motion planners  optimization scale  trajectory results  seven-segment acceleration profile  nonlinear constraint optimization problem  robot manipulator  error bounds  kinematic constraints  time-optimal trajectory generation approach  Trajectory  Splines (mathematics)  Optimization  Manipulators  Acceleration  Kinematics 
Abstract: This paper presents an approach to generate the time-optimal trajectory for a robot manipulator under certain kinematic constraints such as joint position, velocity, acceleration, and jerk limits. This problem of generating a trajectory that takes the minimum time to pass through specified waypoints is formulated as a nonlinear constraint optimization problem. Unlike prior approaches that model the motion of consecutive waypoints as a Cubic Spline, we model this motion with a seven-segment acceleration profile, as this trajectory results in a shorter overall motion time while staying within the bounds of the robot manipulator's constraints. The optimization bottleneck lies in the complexity that increases exponentially with the number of waypoints. To make the optimization scale well with the number of waypoints, we propose an approach that has linear complexity. This approach first divides all waypoints to consecutive batches, each with an overlap of two waypoints. The overlapping waypoints then act as a bridge to concatenate the optimization results of two consecutive batches. The whole trajectory is effectively optimized by successively optimizing every batch. We conduct experiments on practical scenarios and trajectories generated by motion planners to evaluate the effectiveness of our proposed approach over existing state-of-the-art approaches.


Title: Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments
Key Words: collision avoidance  convergence  humanoid robots  mobile robots  Newton method  trajectory control  problem encoding  warm-starting trajectory optimization  motion planner  local minima  motion planning  near-optimal warm-start initializations  global convergence  quasiNewton solvers  probabilistic inference solvers  NASA Valkyrie robot  Task analysis  Collision avoidance  Planning  Robots  Trajectory optimization 
Abstract: Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.


Title: A Self-Tuning Impedance Controller for Autonomous Robotic Manipulation
Key Words: control system synthesis  feedback  manipulators  mobile robots  path planning  robot programming  robot vision  appropriate restoring forces  unstructured environments  complex interactions  autonomous robotic manipulation  self-tuning impedance controller  debris removal task  selective Cartesian axes  impedance parameters  autonomous tuning  robot state machine  interaction values  interaction expectancy value  novel self-regulating impedance controller  task-dependent regulation  task conditions  robot programmers  damping  stiffness  quasistatic performance  impedance control techniques  imposed displacements  Impedance  Task analysis  Robot sensing systems  Three-dimensional displays  Grasping  Damping 
Abstract: Complex interactions with unstructured environments require the application of appropriate restoring forces in response to the imposed displacements. Impedance control techniques provide effective solutions to achieve this, however, their quasi-static performance is highly dependent on the choice of parameters, i.e. stiffness and damping. In most cases, such parameters are previously selected by robot programmers to achieve a desired response, which limits the adaptation capability of robots to varying task conditions. To improve the generality of interaction planning through task-dependent regulation of the parameters, this paper introduces a novel self-regulating impedance controller. The regulation of the parameters is achieved based on the robot's local sensory data, and on an interaction expectancy value. This value combines the interaction values from the robot state machine and visual feedback, to authorize the autonomous tuning of the impedance parameters in selective Cartesian axes. The effectiveness of the proposed method is validated experimentally in a debris removal task.


Title: Development of MR Clutch for a Prospective 5 DOF Robot* This work was supported in part by Canada Foundation for Innovation (CFI) and Natural Sciences and Engineering Research Council (NSERC) of Canada under grant No.25031 and RGPIN-346166.
Key Words: clutches  design engineering  Hall effect transducers  intelligent sensors  machine control  magnetorheology  torque control  intrinsic torque control  mechanical design  prospective 5 DOF robot  MR clutch  magneto-rheological clutch  prospective 5 degrees of freedom robot  embedded Hall sensors  Torque  Magnetic sensors  Stators  Rotors  Robots  Wires 
Abstract: This paper presents an improved design approach for the construction of a Magneto-Rheological (MR) clutch intended to be used in a prospective 5 degrees of freedom robot. The MR clutch features embedded Hall sensors for intrinsic torque control. After a brief description of the MR clutch principles, the details of the mechanical design are discussed. Simulation and preliminary experimental results demonstrate the main characteristics and advantages of the proposed MR clutch.


Title: Embedded and controllable shape morphing with twisted-and-coiled actuators*
Key Words: actuators  muscle  prosthetics  robot designs  adaptive morphology  soft materials  steady-state shape  embedded shape morphing  controllable shape morphing  twisted-and-coiled actuators  thermoplastic material  variable stiffness  mechanical design  artificial muscle  Shape  Programmable logic arrays  Actuators  Strain  Force  Mathematical model  Robots 
Abstract: Shape morphing, meaning a structure can first morph and then lock into another shape, can be applied to robot designs to endow robots with adaptive morphology for increased functionality and adaptivity. In this paper, we introduce a novel shape morphing scheme enabled by a new artificial muscle: twisted and coiled actuators (TCAs). This new actuator is purely soft, low cost, and electrically driven. Embedding a TCA and a thermoplastic material with variable stiffness into soft materials, we create a miniature shape-morphing link. We also establish a general model to predict the steady-state shape of the link given an input power applied to the TCA. Experiments are conducted to characterize parameters and verify the proposed model. Finally, we demonstrate this shape-morphing link can serve as a link in a mechanism to change the trajectory of its foot or endpoint. We envision that such a new shape-morphing scheme can enable robots to leverage the same mechanical design for different functions.


Title: Soft Robotic Burrowing Device with Tip-Extension and Granular Fluidization
Key Words: fluidisation  granular materials  mobile robots  sand  underground equipment  granular fluidization  soft robotic burrowing device  mobile robots  interaction forces  pressure-driven thin film body  tip-extension  pressurized fluid  Electron tubes  Force  Robots  Strips  Fluidization  Pneumatic systems  Fabrics 
Abstract: Mobile robots of all shapes and sizes move through the air, water, and over ground. However, few robots can move through the ground. Not only are the forces resisting movement much greater than in air or water, but the interaction forces are more complicated. Here we propose a soft robotic device that burrows through dry sand while requiring an order of magnitude less force than a similarly sized intruding body. The device leverages the principles of both tip-extension and granular fluidization. Like roots, the device extends from its tip; the principle of tip-extension eliminates skin drag on the sides of the body, because the body is stationary with respect to the medium. We implement this with an everting, pressure-driven thin film body. The second principle, granular fluidization, enables a granular medium to adopt a dynamic fluid-like state when pressurized fluid is passed through it, reducing the forces acting on an object moving through it. We realize granular fluidization with a flow of air through the core of the body that mixes with the medium at the tip. The proposed device could lead to applications such as search and rescue in mudslides or shallow subterranean exploration. Further, because it creates a physical conduit with its body, electrical lines, fluids, or even tools could be passed through this channel.


Title: Liquid Metal-Microelectronics Integration for a Sensorized Soft Robot Skin
Key Words: actuators  elastomers  flexible electronics  gallium alloys  grippers  indium alloys  integrated circuits  liquid metals  microsensors  robots  sensors  shape memory effects  skin  tactile sensors  temperature sensors  robot arm  sensorized soft gripper  shape-memory actuated soft gripper  microelectronic skin  individual sensors  mechanical loading  room temperature liquid metal alloy  eutectic gallium indium  temperature sensing  solid-state electronics  stretchable skin  elastomeric skin  integrated circuits  microelectronic sensors  natural mechanics  signal processing  power regulation  sensorized soft robot skin  liquid metal-microelectronics integration  temperature 293 K to 298 K  Grippers  Robot sensing systems  Temperature sensors  Skin  Liquids  Metals 
Abstract: Progress in soft robotics depends on the integration of electronics for sensing, power regulation, and signal processing. Commercially available microelectronics satisfy these functions and are small enough to preserve the natural mechanics of the host system. Here, we present a method for incorporating microelectronic sensors and integrated circuits (ICs) into the elastomeric skin of a soft robot. The thin stretchable skin contains various solid-state electronics for orientation, pressure, proximity, and temperature sensing, and a microprocessor. The components are connected by thin-film copper traces wetted with eutectic gallium indium (EGaIn), a room temperature liquid metal alloy that allows the circuit to maintain conductivity as it deforms under mechanical loading. In this paper, we characterize the function of the individual sensors in air and water, discuss the integration of the microelectronic skin with a shape-memory actuated soft gripper, and demonstrate the sensorized soft gripper in conjunction with a 4 degree-of-freedom (DOF) robot arm.


Title: Development of a Hybrid Gripper with Soft Material and Rigid Structures
Key Words: bending  finite element analysis  grippers  manipulators  motion control  pneumatic actuators  hybrid gripper  robotic manipulators  conventional robotic grippers  rigid components  gripping motion  soft grippers  bending motion  fingertip force  morphological structure  soft pneumatic actuators  underactuated mechanism  finite element methods  FEM  SPAs  three-fingered gripper  soft components  Grippers  Force  Shape  Strain  Robots  Actuators  Mathematical model 
Abstract: For decades, various robotic grippers have been developed due to its necessity for the robotic manipulators. In case of the conventional robotic grippers with rigid components, an underactuated mechanism was required to satisfy gripping motion. Recently, soft grippers have been studied actively, which have realize bending motion with a simple morphological structure itself and inherent compliance to the environment. In this field of study, it has been rarely investigated to improve the fingertip force and actuation speed with specified design parameters. Thus, in this study, a hybrid gripper, which consists of both soft and rigid components, was suggested based on the key design principles: 1) the ratio of rigid parts against the soft chamber, 2) the cross-sectional shape of the chamber. The suggested principles were verified using the finite element methods (FEMs). As a result, the improved performance of the hybrid gripper was verified in terms of the fingertip force and the actuation speed, compared with the performance of the previously developed soft pneumatic actuators (SPAs). As an application, the three-fingered gripper was manufactured and tested by grasping different types of objects.


Title: Design for Control of a Soft Bidirectional Bending Actuator
Key Words: bending  capacitive sensors  closed loop systems  finite element analysis  pneumatic actuators  strain sensors  sensor effectiveness  design evaluation process  simple control strategies  closed-loop control  soft bidirectional bending actuator  SCAPAs  controllable design  antagonistic actuators  embedded capacitive strain sensors  sensor-controlled antagonistic pneumatic actuators  soft robotic actuators  manufacturing processes  finite element analysis  state reconstruction  single conductive fabric sheet  Actuators  Capacitive sensors  Fabrics  Strain  Robot sensing systems  Sensor systems  soft material robotics  hydraulic/pneumatic actuators  sensor-based control 
Abstract: In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.


Title: Sliding-Layer Laminates: A Robotic Material Enabling Robust and Adaptable Undulatory Locomotion
Key Words: elasticity  hydrodynamics  marine control  mobile robots  motion control  sliding-layer laminates  robotic material enabling robust  adaptable undulatory locomotion  continuum robots  undulatory actuation  body materials  flexible movement  resistive forces  surrounding fluid  solid environments  robot designs  passive propulsive elements  wings  laminate design paradigm  f1exible-yet-stiff robotic materials  SLLs  design principles  morphable materials  swimming robot  passive tail  water swimming  steady swimming  robot tail  locomotion modes  confined swimming  confined environments  high stiffness  stiff tail designs  soft tail designs  complex underwater environments  robot locomotor  flexible-yet-stiff materials  Laminates  Structural beams  Springs  Jamming  Service robots  Laser beams 
Abstract: Continuum robots that move through undulatory actuation must be composed of body materials that can enable flexible movement yet also provide resistive forces to the surrounding fluid, granular, or solid environments. This need for “f1exible-yet-stiff” materials is notably important in robot designs that use passive propulsive elements such as tails and wings. Here we explore a laminate design paradigm for “f1exible-yet-stiff” robotic materials through sliding layer laminates (SLLs). We present design principles motivated by theory and experiment and illustrate a taxonomy of SLL enabled morphable materials capable of up to 7 fold change in stiffness. Lastly, we demonstrate the applicability of SLLs to undulatory continuum robots: a swimming robot with a passive tail. We target two desired robot locomotor behaviors: fast open water swimming, and steady swimming through narrow channels emulating underwater caverns and pipes. We demonstrate how tuning the stiffness of the robot tail maximizes thrust generation in these two locomotion modes. Soft tails are optimal in confined swimming because they generate short amplitude high wavenumber oscillations, while stiff tails in confined environments either collide with the walls or do not generate sufficient thrust. However, stiff tails are far better in unconfined environments which enable large stroke amplitudes requiring high stiffness. Through this demonstration we show that stiff or soft tail designs alone are incapable of effective locomotion in complex underwater environments challenge.


Title: Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor
Key Words: bending  dexterous manipulators  feedback  medical robotics  pipelines  pneumatic control equipment  pneumatic systems  position control  sensors  tactile sensors  vibrations  flexible material  flexible angle estimation sensor  flexible sensor  pneumatically driven flexible finger  Robot sensing systems  Optical sensors  Cameras  Optical fiber amplifiers  Voltage measurement  Three-dimensional displays  Printers 
Abstract: A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.


Title: Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).
Key Words: compliant mechanisms  continuum mechanics  finite element analysis  manipulator dynamics  shear modulus  large deformation continuum surfaces  soft continuum robotic arms  3D integrated surface-arm model  lumped-mass methodology  soft robotics  Mathematical model  Robots  Load modeling  Deformable models  Strain  Actuators  Springs 
Abstract: Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.


Title: Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling
Key Words: control engineering computing  industrial robots  motion control  robot programming  trees (mathematics)  programming complexity  industrial robots  complex motions  self-contained primitive blocks  semantic skill  concurrent motion primitives  modeling skills  motion generators  behavior trees  task level programming  Task analysis  Generators  Robot kinematics  Force  Planning  Grippers  industrial robots  skills  reactive system  behavior tress  motio generators  assembly 
Abstract: Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.


Title: Enhanced Explosive Motion for Torque Controlled Actuators Through Field Weakening Control
Key Words: actuators  machine control  motor drives  permanent magnet motors  robots  synchronous motors  torque control  surface permanent magnet synchronous machine motor drives  operating modes  constraints  system dynamics  reference torque  robotics applications  motor torque reference  motor drives  field weakening control  torque controlled actuators  enhanced explosive motion  peak velocity  Torque  Robots  Permanent magnet motors  Actuators  Synchronous motors  AC motors  Voltage control 
Abstract: This work presents a method to increase the peak output speed of surface permanent magnet synchronous machine (SPMSM) motor drives with application in robotics using field weakening control. Contrary to most existing works, the strategy is stateless and operates using only a motor torque reference as input, making it suitable for robotics applications in which reference torque and speed are continuously and rapidly changing. Based on the system dynamics and constraints, we obtain four different operating modes. The strategy is extensively validated using three different experiments, which show an increase in peak velocity of up to 33%. The results demonstrate that the proposed strategy is effective in extending the dynamic performance and explosive motion capabilities of robots.


Title: Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators
Key Words: active disturbance rejection control  end effectors  feedforward  H∞ control  hydraulic actuators  loading equipment  mining  mobile robots  PD control  vehicle dynamics  wheels  active disturbance rejection control  skid-steer loader  H∞ control  PD control  ADRC  inertial sensors  hydraulic arm dynamics  wheels  end-effector  front-end loaders  robotic mining mobile manipulators  material spillage  hydraulic actuators  autonomous machines  feedforward action  proportional-derivative control  Manipulator dynamics  Force  Dynamics  Mathematical model  Hydraulic actuators  Wheels 
Abstract: Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H∞ control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat® 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.


Title: Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints
Key Words: force control  friction  humanoid robots  legged locomotion  mechanical contact  quadratic programming  robot dynamics  robust control  centroidal momentum dynamics  computationally-robust whole-body controller  quadratic program  passive-ankle bipedal robot  dynamic locomotion behaviors  smooth contact transitions  friction cone constraints  task accelerations  computational robustness  floating base dynamics  internal force constraints  contact reaction forces  operational task priorities  algorithmic computations  prioritized whole-body controllers  humanoid robots  multiobjective control  contact constraints  Task analysis  Null space  Dynamics  Acceleration  Robots  Force  Torque 
Abstract: In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.


Title: Continuously Shaping Projections and Operational Space Tasks
Key Words: least squares approximations  robots  projection operators  multiobjective robot control  dynamic task priority rearrangement  projection shaping  damped least squares  idempotent projectors  shaping operators  stack-of-tasks prioritization scheme  single task dimensions continuous priority rearrangement  Task analysis  Aerospace electronics  Jacobian matrices  Robots  Interference  Torque  Nickel 
Abstract: Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.


Title: Dual-Arm Relative Tasks Performance Using Sparse Kinematic Control
Key Words: manipulator kinematics  mobile robots  robotic assembly  dual-arm relative tasks performance  standard controllers  hierarchical sparse QP architecture  coordinated task  sparse kinematic control strategy  autonomous assembly units  dual-arm robots  production lines  Task analysis  Kinematics  Robot kinematics  Jacobian matrices  Manipulators  Aerospace electronics 
Abstract: To make production lines more flexible, dual-arm robots are good candidates to be deployed in autonomous assembly units. In this paper, we propose a sparse kinematic control strategy, that minimizes the number of joints actuated for a coordinated task between two arms. The control strategy is based on a hierarchical sparse QP architecture. We present experimental results that highlight the capability of this architecture to produce sparser motions (for an assembly task) than those obtained with standard controllers.


Title: Jet-HR1: Stepping Posture Optimization for Bipedal Robot Over Large Ditch Based on a Ducted-fan Propulsion System*
Key Words: aerospace propulsion  ducts  fans  gait analysis  humanoid robots  legged locomotion  optimisation  ducted-fan propulsion system  prototype robot  stepping posture optimization  bipedal robot  two-dimensional gaits  Jet-HRl  jet humanoid robot  Legged locomotion  Foot  Fans  Propulsion  Gravity  Humanoid robots 
Abstract: This paper reports the latest progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over a broad ditch with a height difference between the two sides. This work focuses on the methods of calculating the boundary and optimizing stepping posture to use less thrust and keep the robot balanced while stepping over the ditch. With the proposed methods and new two-dimensional gaits, the prototype robot, named Jet-HRl (Jet Humanoid Robot ver.l) was able to completely step over a broad ditch with 450mm in width (up to 97% of the robot's leg's length), and a height difference of 100mm between two sides.


Title: User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization
Key Words: assisted living  gait analysis  geriatrics  human-robot interaction  intelligent robots  laser ranging  medical robotics  multi-robot systems  stability  state estimation  on-line gait characterization  robotic MAD  IMM-PDA-PF  intelligent robotic mobility assistive device  human-robot formation controller  gait cycle  pathological gait parametrization  human gait phases  on-line estimation  single laser-range-finder  user-adaptive human-robot system  pathological gait characterization  augmented human state estimation  intelligent robotic walker  user-adaptive human-robot formation control  Legged locomotion  Pathology  State estimation  Robot sensing systems  Robot kinematics  Real-time systems 
Abstract: In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.


Title: Passivity Based Iterative Learning of Admittance-Coupled Dynamic Movement Primitives for Interaction with Changing Environments
Key Words: adaptive control  feedback  iterative learning control  learning systems  manipulator dynamics  motion control  path planning  admittance-coupled dynamic movement primitives  compact task representations  sensor-based goal adaptations  adaptive motion capabilities  learning process  environmental changes  contact wrench feedback dynamics  iterative learning approach  system passivity analysis  Kuka LWR robot  nonrigid contact  passivity based iterative learning  reference power tracking  Robots  Impedance  Trajectory  Force feedback  Dynamics  Task analysis  Admittance 
Abstract: Encoding desired motions into dynamic movement primitives (DMPs) is a common way for generating compact task representations that are able to handle sensor-based goal adaptations. At the same time, a robot should not only express adaptive motion capabilities at planning level, but use also contact wrench feedback in the adaptation and learning process of the DMP. Despite first approaches exist in this direction, no fully integrated approach has been proposed so far. In this paper, we introduce a new class of admittance-coupled DMPs that addresses environmental changes by including contact wrench feedback dynamics into the DMP formalism. Moreover, a novel iterative learning approach is devised that is based on monitoring the overall system passivity analysis in terms of reference power tracking. Simulations and experimental results with the Kuka LWR robot maintaining a non-rigid contact with the environment (wiping a surface) are shown for supporting the validity of our approach.


Title: Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints
Key Words: learning (artificial intelligence)  robots  concept constrained learning from demonstration  robust robot learning  constrained learning  LfD process  conceptually-grounded constraints  robust skill learning  CC-LfD  conceptual constraints  skill repair  Trajectory  Maintenance engineering  Task analysis  Training  Service robots  Planning 
Abstract: Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by leveraging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.


Title: Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives
Key Words: augmented reality  iterative methods  learning (artificial intelligence)  mobile robots  motion control  regression analysis  robot dynamics  robot programming  telerobotics  human motor dynamics  kernel-based regression approach  inverse human-dynamics response  human-in-the-loop demonstrator  kernel-based human-dynamics inversion  precision robot motion-primitives  human demonstrator  robot controller  multiple iterations  assisted teleoperation  augmented reality display  Task analysis  Robots  Trajectory  Gaussian processes  Biological system modeling  Kernel  Estimation 
Abstract: Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.


Title: Associative Skill Memory Models
Key Words: force feedback  Gaussian processes  grippers  haptic interfaces  hidden Markov models  humanoid robots  mobile robots  neurophysiology  regression analysis  perturbed movements  torque trajectories  Parametric Hidden Markov Models  force feedback model  associative skill memory models  ASMs  stereotypical movements  stereotypical sensory events  dynamic movement primitives  noisy perception  stored sensory trajectories  haptic measurements  tactile measurements  perturbed movement deviates  stored single sensory trajectory instances  sensory event models  Hidden Markov models  Robot sensing systems  Trajectory  Task analysis  Force feedback  Force 
Abstract: Associative Skill Memories (ASMs) were formulated to encode stereotypical movements along with their stereotypical sensory events to increase the robustness of underlying dynamic movement primitives (DMPs) against noisy perception and perturbations. In ASMs, the stored sensory trajectories, such as the haptic and tactile measurements, are used to compute how much a perturbed movement deviates from the desired one, and to correct the movement if possible. In our work, we extend ASMs: rather than using stored single sensory trajectory instances, our system generates sensory event models and exploits those models to correct the perturbed movements during executions with the aim of generalizing to novel configurations. In particular, measured force and the torque trajectories are modelled using Parametric Hidden Markov Models, and then reproduced by Gaussian Mixture Regression. With Baxter robot, we demonstrate that our proposed force feedback model can be used to correct a trajectory while pushing an object with a mass never experienced before, and which otherwise slips away from the gripper because of noise. In the end, we discuss how far this skill can be generalized using the force model and possible future improvements.


Title: Towards Intelligent Arbitration of Diverse Active Learning Queries
Key Words: decision theory  learning (artificial intelligence)  multi-agent systems  query processing  diverse active learning queries  optimal queries  learning agent  active learner  decision-theoretic arbitration strategies  decision-theoretic strategy  intelligent arbitration  rule-based arbitration strategies  passive learning  Task analysis  Training  Grounding  Robots  Feature extraction  Hafnium  Uncertainty 
Abstract: Active learning literature has explored the selection of optimal queries by a learning agent with respect to given criteria, but prior work in classification has focused only on obtaining labels for queried samples. In contrast, proficient learners, like humans, integrate multiple forms of information during learning. This work seeks to enable an active learner to reason about multiple query types concurrently, aimed at soliciting both instance and feature information from the teacher, and to autonomously arbitrate between queries of different types. We contribute the design of rule-based and decision-theoretic arbitration strategies and evaluate all against baselines of more traditional passive and active learning. Our findings show that all arbitration strategies lead to more efficient learning, compared to the baselines. Moreover, given a dynamically changing environment and constrained questioning budget (typical in human settings), the decision-theoretic strategy statistically outperforms all other methods since it reasons about both what query to make and when to make a query, in order to most effectively utilize its questioning budget.


Title: Segmenting and Sequencing of Compliant Motions
Key Words: end effectors  expectation-maximisation algorithm  force sensors  hidden Markov models  human-robot interaction  motion control  probability  nonhomogeneous hidden Markov model  expectation-maximization algorithm  cartesian impedance controller parameter  KUKA LWR4+ arm  parameter estimation  HMM model  hidden phase transition probabilities  segmented phase  compliant motions  Hidden Markov models  Task analysis  Motion segmentation  Adaptation models  Computational modeling  Impedance 
Abstract: This paper proposes an approach for segmenting a task consisting of compliant motions into phases, learning a primitive for each segmented phase of the task, and reproducing the task by sequencing primitives online based on the learned model. As compliant motions can “probe” the environment, using the interaction between the robot and the environment to detect phase transitions can make the transitions less prone to positional errors. This intuition leads us to model a task with a non-homogeneous Hidden Markov Model (HMM), wherein hidden phase transition probabilities depend on the interaction with the environment (wrench measured by an F/T sensor). Expectation-maximization algorithm is employed in estimating the parameters of the HMM model. During reproduction, the phase changes of a task are detected online using the forward algorithm, with the parameters learned from demonstrations. Cartesian impedance controller parameters are learned from the demonstrations to reproduce each phase of the task. The proposed approach is studied with a KUKA LWR4+ arm in two setups. Experiments show that the method can successfully segment and reproduce a task consisting of compliant motions with one or more demonstrations, even when demonstrations do not have the same starting position and external forces occur from different directions. Finally, we demonstrate that the method can also handle rotational motions.


Title: An Uncertainty-Aware Minimal Intervention Control Strategy Learned from Demonstrations
Key Words: learning (artificial intelligence)  motion control  robots  robots  human environments  active compliance  minimal intervention control principle  task demonstrations  proper gain estimation  unpredictable robot motions  robot compliant  data-efficient strategy  torque-controlled robot  uncertainty-aware minimal intervention control strategy  Robots  Uncertainty  Hidden Markov models  Task analysis  Impedance  Probabilistic logic  Covariance matrices 
Abstract: Motivated by the desire to have robots physically present in human environments, in recent years we have witnessed an emergence of different approaches for learning active compliance. Some of the most compelling solutions exploit a minimal intervention control principle, correcting deviations from a goal only when necessary, and among those who follow this concept, several probabilistic techniques have stood out from the rest. However, these approaches are prone to requiring several task demonstrations for proper gain estimation and to generating unpredictable robot motions in the face of uncertainty. Here we present a Programming by Demonstration approach for uncertainty-aware impedance regulation, aimed at making the robot compliant - and safe to interact with - when the uncertainty about its predicted actions is high. Moreover, we propose a data-efficient strategy, based on the energy observed during demonstrations, to achieve minimal intervention control, when the uncertainty is low. The approach is validated in an experimental scenario, where a human collaboratively moves an object with a 7-DoF torque-controlled robot.


Title: Generative Low-Shot Network Expansion
Key Words: learning (artificial intelligence)  neural nets  pattern classification  conventional deep learning classifiers  pre-trained deep network  base network  low-shot training scenarios  compact generative model  generative low-shot network expansion  hard distillation method  memory footprint  Training  Training data  Data models  Memory management  Task analysis  Robots  Feature extraction 
Abstract: Conventional deep learning classifiers are static in the sense that they are trained on a predefined set of classes and learning to classify a novel class typically requires re-training. In this work, we address the problem of Low-Shot network-expansion learning. We introduce a learning framework which enables expanding a pre-trained (base) deep network to classify novel classes when the number of examples for the novel classes is particularly small. We present a simple yet powerful hard distillation method where the base network is augmented with additional weights to classify the novel classes, while keeping the weights of the base network unchanged. We show that since only a small number of weights needs to be trained, the hard distillation excels in low-shot training scenarios. Furthermore, hard distillation avoids detriment to classification performance on the base classes. Finally, we show that low-shot network expansion can be done with a very small memory footprint by using a compact generative model of the base classes training data with only a negligible degradation relative to learning with the full training set.


Title: Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving
Key Words: control engineering computing  decision trees  fasteners  industrial robots  pattern classification  production engineering computing  robotic assembly  sensors  support vector machines  technical challenges  affordable intelligent screwdriving system  online stage  result classification  state transition graph  labeled screwdriving dataset  multiple sensor signals  classification algorithms  sensor reduction  accurate result classifiers  linear discriminant analysis  feature subset selection  optimal feature subset  corresponding sensor signals  stage classifier  optimal sensor subset  sensor selection  stage & result classifications  automated miniature screwdriving  consumer electronics industry every year  screwdriving process  challenging tasks  robotic threaded fastening systems  system cost  Robot sensing systems  Fasteners  Joining processes  Fault detection  Torque  Reliability 
Abstract: Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.


Title: Evaluating Methods for End-User Creation of Robot Task Plans
Key Words: manipulators  multi-robot systems  path planning  end-user creation  perception-driven task plans  collaborative robots  generalizable robot task plans  behavior tree-based CoSTAR system  pick-and-place assembly tasks  SmartMove  Task analysis  Planning  User interfaces  Service robots  Grippers  Collaboration 
Abstract: How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.


Title: A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching
Key Words: force control  grippers  motion control  robust control  trajectory control  vacuum pumps  robust pinching  Amazon Robotics Challenge 2017  suction air  vacuum pump  pad characteristics  gripper system  trajectory planning  trajectory control  suction force  passive linear motion mechanism  Conferences  Intelligent robots 
Abstract: Suction is an effective method for picking various objects because it makes trajectory planning and control easy. However, suction has not been used due to misalignment and leakage of suction air when handling a variety of shapes. We therefore develop a hand to handle these characteristics. First, we model the vacuum pump and pad characteristics to allow evaluation of momentum and suction force in the case of leakage. Utilizing this, we select a configuration suitable for the items in the Amazon Robotics Challenge 2017. In addition, we design a mechanism for switching from suction to pinching for grasping items that cannot be sucked. Moreover, robust pinching is made possible by equipping the fingertips with a passive linear motion mechanism. In the Amazon Robotics Challenge 2017, it was shown possible to stably grasp items with irregularities and items with large moments. Furthermore, items that cannot be grasped by suction can also be grasped robustly by switching to the pinching mechanism.


Title: Mass Manufacturing of Self-Actuating Robots: Integrating Sensors and Actuators Using Flexible Electronics
Key Words: actuators  bending  flexible electronics  microcontrollers  piezoelectric actuators  printed circuits  shape memory effects  air-pouch actuators  maximum bend angle  supporting electronics  flexible printed circuit  self-sensing robots  mass manufacturing  self-actuating robots  integrating sensors  nonstandard manufacturing techniques  electrical systems  mechanical systems  novel manufacturing technique  flexible electronics factory  standard industrial machines  air pouches  shape memory alloy  polyamide-based flexible circuit  Actuators  Robot sensing systems  Manufacturing  Shape memory alloys  Shape 
Abstract: Currently, the manufacturing of self-actuating and self-sensing robots requires non-standard manufacturing techniques and assembly steps to integrate electrical and mechanical systems. In this work, we developed a novel manufacturing technique, where such robots can be produced at a flexible electronics factory. We developed the technique using standard industrial machines, processes, and materials. Using a lamination process, we were able to integrate air pouches or shape memory alloy (SMA) inside a polyamide-based flexible circuit to produce bending actuators. The bend angle of the actuators is sensed with a chain of inertial measurement units integrated on the actuator. Air-pouch actuators can produce a force of a 2.24N, and a maximum bend angle of 74 degrees. To demonstrate, we manufactured a five-legged robot with the developed actuators and bend sensors, with all the supporting electronics (e.g., microcontrollers, radio) directly integrated into the flexible printed circuit. Such robots are flat and lightweight (15 grams) and thus conveniently compact for transportation and storage. We believe that our technique can allow inexpensive and fast prototyping and deployment of self-actuating and self-sensing robots.


Title: Achieving Flexible Assembly Using Autonomous Robotic Systems
Key Words: mobile robots  recycling  robotic assembly  single shot pre-fabrication methods  assembling  dis-assembly processes  agile development  resource usage  build process  robotic platform  assembly method  cost function  alternative fabrication methods  flexible assembly  autonomous robotic systems  prefabrication  speed advantages  autonomous flexible reassembly  simple Lego bricks  Robots  Grippers  Fabrication  Morphology  Robotic assembly  Optimization  Force 
Abstract: Prefabrication of structures is currently used in a limited capacity, due to the lack of flexibility, despite the potential cost and speed advantages. Autonomous flexible reassembly enables structures to be developed which can be continuously and iteratively dis-assembled and re-assembled providing far more flexibility in comparison to single shot pre-fabrication methods. Dis-assembly of structures should be considered when assembling, due to the asymmetry of assembly and dis-assembly processes, to ensure structures can be recycled and re-assembled. This allows for agile development, significantly reducing the time and resource usage during the build process. In this work, a framework for flexible re-assembly is developed and a robotic platform is developed to implement and test this framework with simple Lego bricks. The tradeoffs in terms of time, resource use and probability of success of this new assembly method can be understood by using a cost function to compare to alternative fabrication methods.


Title: Human Pose Estimation in Presence of Occlusion Using Depth Camera Sensors, in Human-Robot Coexistence Scenarios
Key Words: cameras  human-robot interaction  image filtering  image sensors  mobile robots  particle filtering (numerical methods)  pose estimation  robot vision  human-robot coexistence scenario  collaborative robotics  industrial scenario  vision sensors  cognitive software layers  human intentions  human pose estimation algorithms  partial occlusion  dual arm robot  depth camera sensors  particle filter techniques  Pose estimation  Kinematics  Service robots  Mathematical model  Collaboration  Robot sensing systems 
Abstract: Collaborative robotics over the last few years has gained increasing interest in the industrial scenario. Co-bots can be equipped with vision sensors and cognitive software layers, allowing the robot to figure out human intentions. To make this level of perception possible, human pose estimation algorithms are required. Several techniques have been already proposed to tackle this problem, which however present some weaknesses in particular when occlusions occur. This work proposes an algorithm for human pose estimation in the situations of partial occlusion, based on particle filter techniques. We have proved its validity in a realistic human-robot coexistence scenario, where a human and a dual arm robot have to perform tasks in a shared workspace.


Title: Feasibility of the UR5 Industrial Robot for Robotic Rehabilitation of the Upper Limbs After Stroke
Key Words: human-robot interaction  industrial robots  injuries  medical robotics  motion control  neurophysiology  patient rehabilitation  patient treatment  human-robot collaboration  upper limbs  robot-assisted therapy  rehabilitation treatment  robotic rehabilitation devices  high-effort one-to-one interactions  physical rehabilitation  stroke patients  UR5 collaborative industrial robot  therapeutic treatment  rehabilitation exercises  high-intensity movements  neurological injuries  Service robots  Robot sensing systems  Training  Task analysis  Safety  Collision avoidance 
Abstract: Robot-assisted therapy is an emerging form of rehabilitation treatment for motor recovery of the upper limbs after neurological injuries such as stroke or spinal cord injury. Robotic rehabilitation devices have the potential to reduce the physical strain put on therapists due to the high-effort one-to-one interactions between the therapist and patient involving repetitive high-intensity movements to restore arm and hand functions. Numerous custom robotic devices have been developed in recent years to aid in physical rehabilitation of stroke patients, but most commercially available systems are high-cost devices because of low production volumes and high development costs. In this paper, we analyse the safety and functionality of the UR5 collaborative industrial robot from universal Robots equipped with an external force/torque sensor in a real-time control system for typical rehabilitation exercises. The aim of the paper is to show that a new class of general-purpose industrial robots designed for human-robot collaboration may prove a viable alternative to custom designs. Experiments show that robotic rehabilitation of the upper limbs using a standard industrial robot manipulator UR5 may be feasible. Results have the potential to make robotic rehabilitation more available as a high-quality therapeutic treatment for more patients.


Title: Safety-Related Tasks Within the Set-Based Task-Priority Inverse Kinematics Framework
Key Words: collision avoidance  manipulator kinematics  mobile robots  motion control  equality-based task  task-priority inverse kinematics algorithm  set-based task-priority inverse kinematics framework  Jaco2 manipulator  RGB-D sensor  obstacle detection  obstacle avoidance tasks  joint-limits  set-based tasks  operational space  robotic arm  motion control  safety-related tasks  Task analysis  Manipulators  Robot sensing systems  Kinematics  Collision avoidance  Safety 
Abstract: In this paper we present a framework that allows the motion control of a robotic arm automatically handling different kinds of safety-related tasks. The developed controller is based on a Task-Priority Inverse Kinematics algorithm that allows the manipulator's motion while respecting constraints defined either in the joint or in the operational space in the form of equality-based or set-based tasks. This gives the possibility to define, among the others, tasks as joint-limits, obstacle avoidance or limiting the workspace in the operational space. Additionally, an algorithm for the real-time computation of the minimum distance between the manipulator and other objects in the environment using depth measurements has been implemented, effectively allowing obstacle avoidance tasks. Experiments with a Jaco2 manipulator, operating in an environment where an RGB-D sensor is used for the obstacles detection, show the effectiveness of the developed system.


Title: Model-Based Engineering, Safety Analysis and Risk Assessment for Personal Care Robots
Key Words: control engineering computing  fault trees  humanoid robots  risk management  safety  safety-critical software  service robots  specification languages  Unified Modeling Language  model-based engineering  risk assessment  personal care robots  couple model-based system engineering  robotic system life-cycle  Papyrus UML modeler  Safety Architect  failure mode  effects analysis  fault tree analysis  safety artefacts  modeling environment  humanoid personal care robot  safety analysis  Safety  Unified modeling language  Tools  Analytical models  Risk management  Humanoid robots 
Abstract: In this paper, we propose a method and associate platform to couple model-based system engineering and safety analysis at the early phases of robotic system (RS) life-cycle. The method is compatible with IEC12100 and ISO13482. The platform is based on Papyrus UML modeler and supports RobotML, a domain specific language for RSs, as well as tools for safety analysis and risk assessment, Sophia and Safety Architect. It includes an ability (a) to model architecture of RSs; (b) to automatically run safety analysis (e.g. failure mode and effects analysis, fault tree analysis, etc.); (c) to save and reuse safety artefacts; (d) to represent safety analysis results in the modeling environment. We illustrate the proposed method by considering a humanoid personal care robot from SoftBank Robotics developed in the scope of the ROMEO2 project.


Title: Computation of Safe Path Velocity for Collaborative Robots
Key Words: collision avoidance  human-robot interaction  industrial robots  ISO standards  manufacturing systems  motion control  occupational safety  velocity control  safe path velocity  collaborative robot  safety requirements  collaborative method  safe collisions  point-wise maximal path velocity  post impact safety  ISO/TS 15066  power and force limiting  industrial manufacturing  Robots  Collision avoidance  Force  Safety  Collaboration  Effective mass  Limiting 
Abstract: This paper presents a method for numerically computing the highest path velocity that a collaborative robot can attain, while complying with safety requirements. The safety requirements are obtained from ISO/TS 15066 that describes a collaborative method called power and force limiting, which specifies safe collisions between humans and robots. In particular, we assume that a path is given and compute the point-wise maximal path velocity that ensures a safe impact, i.e., the paper provides no considerations on the post impact safety.


Title: Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy
Key Words: learning (artificial intelligence)  object detection  remotely operated vehicles  indoor environments  Udacity dataset  image conditioned energy based generative adversarial network  on-line monitoring framework  assured autonomy  Adversarial Learning-Based On-Line Anomaly Monitoring  autonomous ground vehicle  sensor data  action condition video prediction framework  anomalous actuator commands  proper actuator commands  generative adversarial network  SFAM  system-focused anomaly detection  CFAM  controller-focused anomaly detection  sensor inputs  unmanned ground vehicle  learning-based control systems  Generators  Convolution  Actuators  Monitoring  Anomaly detection  Robot sensing systems  Computer architecture 
Abstract: The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.


Title: Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems
Key Words: control engineering computing  direction-of-arrival estimation  multi-robot systems  networked control systems  security of data  statistical analysis  networked multirobot systems  parametric statistical tool  wireless network  DoA-aided attack detection scheme  multirobot testbed  distributed direction of arrival estimation-aided cyberattack detection  Direction-of-arrival estimation  Robot sensing systems  Multi-robot systems  Antenna measurements  Robot kinematics 
Abstract: This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.


Title: Evaluating Robotic Devices of Non-Wearable Transferring Aids Using Whole-Body Robotic Simulator of the Elderly
Key Words: assisted living  geriatrics  handicapped aids  medical robotics  patient care  service robots  quantitative physical evaluation  whole-body robotic system  assistive robotic devices  physical assistance  nursing care  elderly person  whole-body robotic simulator  nonwearable transferring aids  Safety  Legged locomotion  Receivers  Senior citizens  Medical services 
Abstract: This paper describes the development of a whole-body robotic simulator of an elderly person for evaluating robotics devices for nursing care. To improve the quality of life of the elderly persons, physical assistance such as transfer, movement, and bathroom assistance is important. It is also important to reduce the workload of caregivers in an aging society. In recent years, assistive robotic devices for nursing care have been developed and commercialized for such purposes. However, such devices have not become popular in the care facilities yet. One of the reasons is that it is still difficult to evaluate the effects of the devices on the care receivers and caregivers. In particular, it is necessary to quantitatively evaluate the effect of the devices on the human body from the viewpoint of safety and comfort. We have developed a whole-body robotic system to simulate the pose and motion of the elderly persons. The purpose of this system is to realize quantitative physical evaluation of robotics devices for nursing care of the human body. The experimental results of the preliminary evaluation of assistive robotic devices are also presented.


Title: Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery
Key Words: cellular transport  collision avoidance  fluorescence  goods distribution  microrobots  mobile robots  nanoparticles  particle swarm optimisation  path planning  position control  quantum dots  tracking  trajectory control  Mag-Spore  fluorescence microscopy  fluorescence imaging  observer-based trajectory tracking controller  multifunctional magnetic Spores  microrobotic cargo delivery possesses  complex environmental conditions  obstructed optical feedback  automated control approach  microrobotic cargo carrier  multifunctional magnetic spore  Magnetic resonance imaging  Automation  Magnetic multilayers  Carbon  Stem cells  Optimization 
Abstract: Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.


Title: Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface
Key Words: microrobots  mobile robots  microchannels  pairwise interactions  local interactions  collective behaviors  mobile microrobot collectives  multiple spinning microrafts  air-water interface  object manipulation  spinning mobile microrobots  size 100.0 mum  Conferences  Intelligent robots 
Abstract: We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.


Title: Fabrication and Locomotion of Flexible Nanoswimmers
Key Words: hinges  magnetic fields  microrobots  mobile robots  motion control  numerical analysis  1-link swimmer  semisoft tail  nanoscale swimmers  sophisticated locomotion mechanisms  hinges  soft joints  small-scale robots  flexible nanoswimmers  magnetic fields  oscillating magnetic field frequency  undulatory locomotion  2-link swimmer  soft hinge  rigid magnetic head  Nickel  Magnetic fields  Gold  Resonant frequency  Magnetosphere  Fabrication  Fasteners 
Abstract: Small-scale robots with soft joints and hinges have recently attracted interest because these components allow for more sophisticated locomotion mechanisms. Here, we investigate two different types of nanoscale swimmers as depicted in Figure 1. One consists of a rigid magnetic head linked to a semi-soft tail (1-link swimmer). Another consists of a rigid magnetic head and tail connected by a soft hinge (2-link swimmer). Both swimmers exhibit undulatory locomotion under an applied oscillating magnetic field. The speeds of the swimmers are assessed as a function of the oscillating magnetic field frequency and the sweeping angle. We find that a resonance-like frequency increases as the length decreases, and, in general, the speed increases as the sweeping angle increases. Last, we show that 2-link swimmers can also swim in a corkscrew-like pattern under rotating magnetic fields.


Title: Gait Learning for Soft Microrobots Controlled by Light Fields
Key Words: Bayes methods  control engineering computing  control system synthesis  Gaussian processes  learning (artificial intelligence)  medical robotics  microrobots  optimisation  self-adaptive microrobotic systems  light-controlled soft microrobots  probabilistic learning control  gait learning  light fields  analytical control design  gait optimization  locomotion models  data-driven approaches  Bayesian optimization  Gaussian processes  BO  GPs  Robots  Cost function  Kernel  Strain  Laser beams  Tuning 
Abstract: Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.


Title: A Novel Monocular-Based Navigation Approach for UAV Autonomous Transmission-Line Inspection
Key Words: autonomous aerial vehicles  control engineering computing  image registration  inspection  mobile robots  neural nets  object detection  path planning  poles and towers  power overhead lines  robot vision  UAV autonomous navigation approach  pan-tilt monocular-based navigation scheme  neural network  homography matrix  distance variation  point set registration model  tower detection  overhead transmission lines  UAV autonomous transmission-line inspection  Poles and towers  Inspection  Navigation  Power transmission lines  Kernel  Cameras  Safety 
Abstract: This paper proposes a unique and robust UAV autonomous navigation approach along one side of overhead transmission lines for inspection. To this end, we establish a perspective model and develop a novel Pan/Tilt monocular-based navigation scheme. Simultaneously, the following three key issues are addressed. First, to locate the effective landmark - transmission tower timely and reliably, we customize a neural network for tower detection and combine it with a fast and smooth tracking. Second, to provide UAV with a robust and precise heading, we detect the transmission lines and compute and optimize their vanishing point. Third, to keep a safe distance from transmission lines, we optimize a homography matrix to restore the parallel nature of transmission lines and perceive the distance variation by a point set registration model. Finally, by the designed UAV platform, we test the whole system in a real-world transmission-line inspection scenario under different weather condition and achieve an encouraging result. Our approach provides great flexibility for refined inspection and effectively improves inspection safety.


Title: Ceiling Effects for Surface Locomotion of Small Rotorcraft
Key Words: aerodynamics  aerospace robotics  helicopters  mobile robots  propellers  small rotorcraft  ceiling effects  surface locomotion  energy saving strategy  flying robots  spinning propeller  classical momentum theory  blade element method  bimodal aerial locomotion  Propellers  Robots  Blades  Rotors  Aerodynamics  Spinning  Mathematical model 
Abstract: Motivated by the potential of bimodal aerial and surface locomotion as an energy saving strategy for small flying robots, we investigate the effects of a flat overhang surface in the vicinity of a spinning propeller. We employ the classical momentum theory and the blade element method to describe the “ceiling effects” in regards to the generated thrust, power, and rotational speed of the propeller in terms of a normalized distance between the ceiling and the propeller. Validating experiments were performed on a benchtop setup, and the results are in agreement with the proposed models. The presence of a ceiling was found to reduce the power consumption by more than a factor of three for the same thrust force. Overall, our findings show promise, paving the way for the use of perching maneuvers by small rotorcraft to extend their missions.


Title: Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
Key Words: autonomous aerial vehicles  biomimetics  control system synthesis  helicopters  manipulators  mobile robots  path planning  robot vision  sensors  AGRASP  multirotor aerial vehicles  robotics perception  vision-based path planning  highly-constrained sensor  autonomous grasping robotic aerial system for perching  biomimetically-inspired manipulation  perch structures  innovative manipulator design  active grasp  passive grip  quadrotor autonomously detection  onboard sensing  onboard processing  Manipulators  Tendons  Robot sensing systems  Bars  Grasping  Three-dimensional displays 
Abstract: This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.


Title: Recovery Control for Quadrotor UAV Colliding with a Pole
Key Words: autonomous aerial vehicles  cameras  collision avoidance  helicopters  mobile robots  robot dynamics  robot vision  telerobotics  inertial onboard sensing  propeller-protected quadrotor UAV  collision recovery control solutions  poles  operator error  wind gusts  onboard cameras  microUAVs  air quality measurement  civil infrastructure inspection  police surveillance  disaster response  postcollision dynamics  onboard vision failure  Force  Collision avoidance  Mathematical model  Geometry  Drones  Aerodynamics  Propellers 
Abstract: Small quadrotor UAVs are projected to fly increasingly in urban environments for a wide variety of applications such as disaster response, police surveillance, civil infrastructure inspection, and air quality measurement. Micro UAVs can detect and avoid obstacles using onboard cameras; nevertheless, disturbances such as wind gusts, operator error, or failure of onboard vision can still result in dangerous collisions with objects. In the urban setting, the most predominant obstacles are walls and poles. With the aim of developing collision recovery control solutions for quadrotor UAVs, this paper investigates the collision dynamics between a propeller-protected quadrotor UAV and a vertical pole. Simulations provide insight into a quadrotor's post-collision dynamics and experimental trials demonstrate the feasibility of autonomously recovering to stable flight using only inertial onboard sensing in real-time.


Title: Incremental Learning-Based Adaptive Object Recognition for Mobile Robots
Key Words: control engineering computing  human-robot interaction  learning (artificial intelligence)  mobile robots  object recognition  robot vision  incremental learning-based adaptive object recognition  autonomous navigation  general object interaction  human-robot teaming  robot assists  localization system  deep learning  robotic perception  mobile robotic tasks  Three-dimensional displays  Object recognition  Image segmentation  Mobile robots  Training  Semantics 
Abstract: 3D visual understanding of the surrounding environment is vital for successful mobile robotic tasks such as autonomous navigation or general object interaction. However, current systems have limited perceptual capabilities in the sense that they are not very well adaptable to unknown environments. Human operators, on the other hand, are experts in adapting to previously unknown information. Hence, human-robot teaming in which the human helps the robot to adapt to new environments and the robot assists in automated object recognition to efficiently feed the control environment of the operator is advantageous. In this work, we propose an object recognition and localization system for mobile robots, based on deep learning, and we study the adaptation of the resulting robotic perception to a new environment. We propose two methods to teach the robot a new object category: using prior knowledge and using limited operator input. We conducted several experiments to show the feasibility of proposed methods.


Title: Object Detection and Pose Estimation Based on Convolutional Neural Networks Trained with Synthetic Data
Key Words: convolutional neural nets  image resolution  image texture  object detection  object recognition  pose estimation  rendering (computer graphics)  robot vision  solid modelling  instance-based object detection  fine pose estimation  robotic tasks  CNN-based approaches  general object recognition tasks  fully-annotated training images  neural models  interest-point-based approaches  category-based coarse pose estimation  fine-resolution instance-based 3D pose estimation  convolutional neural networks  Solid modeling  Three-dimensional displays  Task analysis  Pose estimation  Training  Data models  Training data 
Abstract: Instance-based object detection and fine pose estimation is an active research problem in computer vision. While the traditional interest-point-based approaches for pose estimation are precise, their applicability in robotic tasks relies on controlled environments and rigid objects with detailed textures. CNN-based approaches, on the other hand, have shown impressive results in uncontrolled environments for more general object recognition tasks like category-based coarse pose estimation, but the need of large datasets of fully-annotated training images makes them unfavourable for tasks like instance-based pose estimation. We present a novel approach that combines the robustness of CNNs with a fine-resolution instance-based 3D pose estimation, where the model is trained with fully-annotated synthetic training data, generated automatically from the 3D models of the objects. We propose an experimental setup in which we can carefully examine how the model trained with synthetic data performs on real images of the objects. Results show that the proposed model can be trained only with synthetic renderings of the objects' 3D models and still be successfully applied on images of the real objects, with precision suitable for robotic tasks like object grasping. Based on the results, we present more general insights about training neural models with synthetic images for application on real-world images.


Title: Towards Event-Driven Object Detection with Off-the-Shelf Deep Learning
Key Words: cameras  computer vision  data compression  data visualisation  humanoid robots  image colour analysis  image sensors  learning (artificial intelligence)  object detection  robot vision  data compression  visual algorithms  event-driven object detection  iCub robotic platform  mature frame-based algorithms  bootstraps event-based dataset annotation  temporal integration  visual events  off-the-shelf deep-learning  compressed event-camera data  recognition algorithms  visual technologies  dense arrays  moving objects  contrast changes  pixel data  dynamic range  computer vision  Cameras  Robot vision systems  Visualization  Training  Object detection 
Abstract: Event cameras are an emerging technology in computer vision, offering extremely low latency and bandwidth, as well as a high temporal resolution and dynamic range. Inherent data compression is achieved as pixel data is only produced by contrast changes at the edges of moving objects. However, current trends in state-of-the-art visual algorithms rely on deep-learning with networks designed to process colour and intensity information contained in dense arrays, but are notoriously computationally heavy. While the combination of these visual technologies could lead to fast, efficient, and accurate detection and recognition algorithms, it is uncertain whether the compressed event-camera data actually contain the required information for these techniques to discriminate between objects and a cluttered background. This paper presents a pilot study in which off-the-shelf deep-learning is applied to visual events for object detection on the iCub robotic platform, and analyses the impact of temporal integration of the event data. We also present a novel pipeline that bootstraps event-based dataset annotation from mature frame-based algorithms, in order to more quickly generate the required datasets.


Title: Material Recognition Using a Capacitive Proximity Sensor with Flexible Spatial Resolution
Key Words: capacitive sensors  dielectric materials  mobile robots  neural nets  tactile sensors  conductive dielectric materials  artificial neural network  data frames  electrode combinations  flexible spatial resolution  capacitive proximity sensor  nonconductive dielectric materials  data sets  material recognition  exciter frequency  capacitive tactile  Electrodes  Robot sensing systems  Permittivity  Spatial resolution  Permittivity measurement  Shape 
Abstract: In this paper we present an approach for material recognition using capacitive tactile and proximity sensors. By variating the spatial resolution and the exciter frequency during the measurement in mutual capacitive mode, information about the dielectrical properties of different objects was captured and provided as data frames. For material recognition an artificial neural network was set up and fed with various data sets of different electrode combinations and exciter frequencies. The influence of the electrode combinations and shapes on the recognition accuracy was investigated. It is shown that seven objects of conductive and non-conductive dielectric materials have been ranged with an overall accuracy of about 71%-94%.


Title: Interactive Training of Object Detection Without ImageNet
Key Words: human computer interaction  interactive systems  object detection  robot vision  service robots  ImageNet  robotic tasks  service robots operating  robot perception  interactive training process  zero hand labeling  object detection  Robots  Training  Labeling  Object detection  Task analysis  Image segmentation  Cameras 
Abstract: For many robotic tasks, particularly those of service robots operating in human environments, the scope of object detection needs is greater than the available data. Either public datasets do not contain the entire set of objects needed for the task, and/or it is a commercial application that cannot use public datasets for training. Instead of hiring people to hand-label more data to support the integration of new objects into robot perception, we propose an interactive training process requiring zero hand labeling. With as little as 4 minutes of interaction with the robot per object, we demonstrate 99% precision and 57% recall in stationary object detection tasks.


Title: Action Selection for Interactive Object Segmentation in Clutter
Key Words: image colour analysis  image motion analysis  image segmentation  RGB-D data  higher quality segmentation  probabilistic segmentation approach  segmentation uncertainty  probabilistic segmentation framework  scene motion  object existence  object models  nonprehensile actions  static object segmentation  scene representation  indoor human environments  complex surroundings  interactive object segmentation  Motion segmentation  Tracking  Probabilistic logic  Object segmentation  Octrees  Manipulators 
Abstract: Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter.


Title: Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation
Key Words: control engineering computing  image reconstruction  image segmentation  industrial manipulators  man-machine systems  mobile robots  object recognition  real-time systems  robot vision  telerobotics  virtual reality  model segmentation  autonomous mobile robot systems  human-machine interfaces  virtual reality-technologies  mixed reality-technologies  multimodal teleoperation  real-time remote control  noise-reduced visualization  object recognition  operator-supporting teleoperation  real-time feedback  industrial articulated robotic arm  real-time environment reconstruction  VR-based teleoperation  known object segmentation  point-cloud visualization  long distance UDP/IP communication  Cameras  Calibration  Solid modeling  Robot vision systems  Task analysis 
Abstract: Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.


Title: DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance
Key Words: collision avoidance  graph theory  image segmentation  image sensors  mobile robots  motion control  neural nets  robot vision  stereo image processing  multiple disparity images  C-space expansion  disparity space representation  generic obstacles  wire pixels  confidence map  semantic segmentation paradigm  convolutional neural network  monocular wire detection  generic obstacle avoidance  robust autonomous aerial vehicles  depth estimation  DROAN - disparity-space representation  Wires  Robot sensing systems  Three-dimensional displays  Cameras  Trajectory  Uncertainty 
Abstract: Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.


Title: Robocentric Visual-Inertial Odometry
Key Words: distance measurement  inertial navigation  Kalman filters  mobile robots  Monte Carlo methods  motion estimation  nonlinear filters  position measurement  SLAM (robots)  robocentric EKF-based VINS  standard world-centric frameworks  R-VIO  real-world experiments  state-of-the-art VINS  robocentric visual-inertial odometry  visual-inertial navigation systems  consistent localization  challenging environments  monocular vision  moving local frame  standard world-centric VINS  global gravity vector  multistate constraint Kalman filter framework  visual-inertial odometry algorithm  global pose  high-accuracy relative motion  robocentric formulation  Robot sensing systems  Three-dimensional displays  Computational efficiency  Navigation  Standards  Gravity  Quaternions 
Abstract: In this paper, we propose a novel robocentric formulation of visual-inertial navigation systems (VINS)within a multi-state constraint Kalman filter (MSCKF)framework and develop an efficient, lightweight, robocentric visual-inertial odometry (R-VIO)algorithm for consistent localization in challenging environments using only monocular vision. The key idea of the proposed approach is to deliberately reformulate the 3D VINS with respect to a moving local frame (i.e., robocentric), rather than a fixed global frame of reference as in the standard world-centric VINS, and instead utilize high-accuracy relative motion estimates for global pose update. As an immediate advantage of using this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align its orientation with the global gravity vector. More importantly, we analytically show that the proposed robocentric EKF-based VINS does not undergo the observability mismatch issue as in the standard world-centric frameworks which was identified as the main cause of inconsistency of estimation. The proposed R-VIO is extensively tested through both Monte Carlo simulations and real-world experiments using different sensor platforms in different environments and shown to achieve competitive performance with the state-of-the-art VINS algorithms in terms of consistency, accuracy and efficiency.


Title: Appearance-Based Along-Route Localization for Planetary Missions
Key Words: image matching  image registration  image sequences  mobile robots  object recognition  planetary rovers  robot vision  SLAM (robots)  image preprocessing steps  recognition framework SeqSLAM  appearance-based along-route localization algorithm  planetary missions  direct sequence-based approach  Moon-analogue mission  planetary rover  image similarity metrics wrt  translational viewpoint differences  rotational viewpoint differences  route traversal conditions  matching locations  flexible mechanism  frame matches  homing mechanism  autonomous navigation  real-time localization  individual frames  image sequences  robust place recognition  Navigation  Lighting  Cameras  Moon  Simultaneous localization and mapping  Visualization  mobile robotics  field robotics  place-recognition  autonomous route navigation 
Abstract: We propose an appearance-based along-route localization algorithm that relies on robust place recognition by matching image sequences instead of individual frames. Our approach extends state of the art place recognition framework SeqSLAM in several aspects to realize real-time localization along routes for autonomous navigation. First, our method is online in that we only rely on the recently observed image frames. Second, we provide a homing mechanism based on rotations computed from frame matches. And third, we use a more flexible mechanism to search for matching locations, not restricting the search to straight lines in the cost matrix as in SeqSLAM, but allowing for a wide variety of route traversal conditions such as varying velocities or rotational and translational viewpoint differences. We investigate different image preprocessing steps as well as image similarity metrics wrt. their influence on illumination and viewpoint invariance for a more robust place recognition. On a new challenging dataset, recorded in real world experiments with a planetary rover, in the course of a Moon-analogue mission on Sicily's Mount Etna, we show the feasibility of our direct, sequence-based approach to along-route localization.


Title: A Monocular Indoor Localiser Based on an Extended Kalman Filter and Edge Images from a Convolutional Neural Network
Key Words: cameras  convolutional neural nets  edge detection  image fusion  Kalman filters  mobile robots  nonlinear filters  pose estimation  robot vision  SLAM (robots)  camera location estimation  extended Kalman filter  6 DOF pose estimation  visual simultaneous localisation-and-mapping algorithms  prebuilt map  ground plane edge image extraction  motion model  unsigned distance function  indoor environment  monocular images  monocular indoor localiser  EKF framework  CNN  convolutional neural network  Image edge detection  Cameras  Robot vision systems  Feature extraction  Convolution  Image segmentation 
Abstract: The main contribution of this paper is an extended Kalman filter (EKF)based algorithm for estimating the 6 DOF pose of a camera using monocular images of an indoor environment. In contrast to popular visual simultaneous localisation and mapping algorithms, the technique proposed relies on a pre-built map represented as an unsigned distance function of the ground plane edges. Images from the camera are processed using a Convolutional Neural Network (CNN)to extract a ground plane edge image. Pixels that belong to these edges are used in the observation equation of the EKF to estimate the camera location. Use of the CNN makes it possible to extract ground plane edges under significant changes to scene illumination. The EKF framework lends itself to use of a suitable motion model, fusing information from any other sensors such as wheel encoders or inertial measurement units, if available, and rejecting spurious observations. A series of experiments are presented to demonstrate the effectiveness of the proposed technique.


Title: Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges
Key Words: autonomous aerial vehicles  constraint handling  control engineering computing  distance measurement  iterative methods  least squares approximations  mobile robots  pose estimation  robot vision  tree searching  pose uncertainty domains  interval constraint propagation techniques  simulated two-robots configurations  unmanned aerial vehicles  bounded error measurements  distances measurements  ground station  camera images  UAV  cooperative localization  branch and bound algorithm  nonlinear iterative weighted least squares  Cameras  Robot kinematics  Robot vision systems  Position measurement  Base stations 
Abstract: An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.


Title: Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality
Key Words: augmented reality  calibration  cameras  human-robot interaction  image registration  image sensors  inspection  mobile robots  robot vision  SLAM (robots)  stereo image processing  mixed-reality headsets  headset orientation  structure inspection  marker-free self-localization  onboard depth sensor  simple point cloud registration  camera image  inspection information  joint point cloud and image-based localization  JPIL  human-robot interaction  time 20.0 min  Three-dimensional displays  Headphones  Inspection  Cameras  Virtual reality  Solid modeling  Robot sensing systems 
Abstract: This paper introduces a method of structure inspection using mixed-reality headsets to reduce the human effort in reporting accurate inspection information such as fault locations in 3D coordinates. Prior to every inspection, the headset needs to be localized. While external pose estimation and fiducial marker based localization would require setup, maintenance, and manual calibration; marker-free self-localization can be achieved using the onboard depth sensor and camera. However, due to limited depth sensor range of portable mixed-reality headsets like Microsoft HoloLens, localization based on simple point cloud registration (sPCR) would require extensive mapping of the environment. Also, localization based on camera image would face same issues as stereo ambiguities and hence depends on viewpoint. We thus introduce a novel approach to Joint Point Cloud and Image-based Localization (JPIL) for mixed-reality headsets that uses visual cues and headset orientation to register small, partially overlapped point clouds and save significant manual labor and time in environment mapping. Our empirical results compared to sPCR show average 10 fold reduction of required overlap surface area that could potentially save on average 20 minutes per inspection. JPIL is not only restricted to inspection tasks but also can be essential in enabling intuitive human-robot interaction for spatial mapping and scene understanding in conjunction with other agents like autonomous robotic systems that are increasingly being deployed in outdoor environments for applications like structural inspection.


Title: Probabilistic Dense Reconstruction from a Moving Camera
Key Words: cameras  image colour analysis  image reconstruction  image sequences  probability  SLAM (robots)  stereo image processing  TUM RGB-D SLAM  ICL-NUIM dataset  spatial correlations  visual scale changes  insufficient parallaxes  motion stereo  spatial stereo  single monocular camera  online dense reconstruction  probabilistic approach  moving camera  probabilistic dense reconstruction  outdoor experiments  dense 3D models  inlier probability expectations  depth estimates  probabilistic scheme  monocular depth estimation  temporal correlations  Image reconstruction  Cameras  Estimation  Visualization  Robot vision systems  Probabilistic logic  Simultaneous localization and mapping 
Abstract: This paper presents a probabilistic approach for online dense reconstruction using a single monocular camera moving through the environment. Compared to spatial stereo, depth estimation from motion stereo is challenging due to insufficient parallaxes, visual scale changes, pose errors, etc. We utilize both the spatial and temporal correlations of consecutive depth estimates to increase the robustness and accuracy of monocular depth estimation. An online, recursive, probabilistic scheme to compute depth estimates, with corresponding covariances and inlier probability expectations, is proposed in this work. We integrate the obtained depth hypotheses into dense 3D models in an uncertainty-aware way. We show the effectiveness and efficiency of our proposed approach by comparing it with state-of-the-art methods in the TUM RGB-D SLAM & ICL-NUIM dataset. Online indoor and outdoor experiments are also presented for performance demonstration.


Title: Summarizing Large Scale 3D Mesh
Key Words: mesh generation  mobile robots  robot vision  SLAM (robots)  stereo image processing  vision-based summarizing process  HD 3D maps  large-scale 3D map  semantic information  geometric information  photometric information  autonomous navigation  semantic mapping  3D sensor devices  Three-dimensional displays  Navigation  Entropy  Semantics  Visualization  Optimization  Robots 
Abstract: Recent progress in 3D sensor devices and in semantic mapping allows to build very rich HD 3D maps very useful for autonomous navigation and localization. However, these maps are particularly huge and require important memory capabilities as well computational resources. In this paper, we propose a new method for summarizing a 3D map (Mesh)as a set of compact spheres in order to facilitate its use by systems with limited resources (smartphones, robots, UAVs,...). This vision-based summarizing process is applied in a fully automatic way using jointly photometric, geometric and semantic information of the studied environment. The main contribution of this research is to provide a very compact map that maximizes the significance of its content while maintaining the full visibility of the environment. Experimental results in summarizing large-scale 3D map demonstrate the feasibility of our approach and evaluate the performance of the algorithm.


Title: A Robust Control Method for the Elbow of the Humanoid Robot TEO Based on a Fractional Order Controller
Key Words: humanoid robots  manipulators  PD control  robust control  robust control method  humanoid robot TEO  fractional order controller  elbow joint  fractional order PD controller  robust performance  humanoid right arm  Gain  Humanoid robots  Tuning  Robustness  Elbow 
Abstract: This paper presents a novel method for the control of the elbow joint of the humanoid robot TEO, based on a fractional order PD controller. Due to the graphical nature of the proposed method, a few basic operations are enough to tune the controller, offering very competitive results compared to classic methods. The experiments show a robust performance of the system to mass changes at the tip of the humanoid right arm.


Title: FPGA-Based Velocity Estimation for Control of Robots with Low-Resolution Encoders
Key Words: closed loop systems  field programmable gate arrays  position control  robot dynamics  velocity control  Cartesian impedance control  FPGA-based velocity estimation  low-resolution encoders  robot control algorithms  robot joint velocities  encoder edges  low velocities  low resolution encoders  measurement delay  closed-loop control  joint position control  frequent velocity updates  common encoder imperfections  Velocity measurement  Estimation  Delays  Silicon  Acceleration  Robots 
Abstract: Robot control algorithms often rely on measurements of robot joint velocities, which can be estimated by measuring the time between encoder edges. When encoder edges occur infrequently, such as at low velocities and/or with low resolution encoders, this measurement delay may affect the stability of closed-loop control. This is evident in both the joint position control and Cartesian impedance control of the da Vinci Research Kit (dVRK), which contains several low-resolution encoders. We present a hardware-based method that gives more frequent velocity updates and is not affected by common encoder imperfections such as non-uniform duty cycles and quadrature phase error. The proposed method measures the time between consecutive edges of the same type but, unlike prior methods, is implemented for the rising and falling edges of both channels. Additionally, it estimates acceleration to enable software compensation of the measurement delay. The method is shown to improve Cartesian impedance control of the dVRK.


Title: Underwater Modeling, Experiments and Control Strategies of FroBot
Key Words: legged locomotion  mobile robots  motion control  optimal control  propulsion  robot dynamics  underwater vehicles  two-degree-of-freedom robotic swing-legs  2DOF  Frobot model  Frobot underwater  caudal fins  Morison equation  control applications  CPGs control strategy  optimal control strategy  dynamic model  dual swing-legs propulsion mechanism  Legged locomotion  Mathematical model  Dynamics  Propulsion  Force  Acceleration 
Abstract: FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.


Title: Feedback Linearizing Controller for a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
Key Words: closed loop systems  compensation  flexible manipulators  friction  linearisation techniques  position control  springs (mechanical)  state feedback  vibration control  single link flexible arm  passive gravity compensation mechanism  flexible link robotics  input state feedback linearization controller  gravity compensation system  springs  double loop control scheme  motor position control  flexible link arm tip positioning  joint friction  vibration cancellation  Gravity  Springs  Torque  DC motors  Actuators  Manipulators 
Abstract: Despite the benefits that the spring based gravity compensation mechanism has brought to the field of rigid robotic manipulators, there have been no substantial efforts toward transferring these developments to the field of flexible link robotics. In this paper, we present an input state feedback linearization controller for the tip positioning of a flexible link arm with a gravity compensation system based on springs. The controller is implemented into a double loop control scheme, in which the inner loop addresses the motor position control in presence of joint friction, and the outer loop deals with vibration cancellation and the tracking of fourth-order trajectories for the tip position of the flexible arm. Taking into considerations the interacting forces between the flexible link and the gravity compensation mechanism, and also the characteristics of the control law, we propose a sensory system to measure all the relevant signals. The proposed controller is tested on an experimental prototype built in our laboratory.


Title: System Identification and Closed-Loop Control of a Hydraulically Amplified Self-Healing Electrostatic (HASEL) Actuator
Key Words: closed loop systems  hydraulic actuators  PI control  robots  shock absorbers  springs (mechanical)  vibration control  HASEL actuator  Proportional-Integral controller  closed-loop control  Hydraulically Amplified Self-healing Electrostatic actuator  system identification method  closed-loop controller  soft robotic actuators  high-speed videography based motion tracking  mass-spring-damper model  Actuators  Strain  Sensors  Data acquisition  Capacitance  Electrodes  Dielectric liquids 
Abstract: This paper describes a system identification method and the development of a closed-loop controller for a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator. Our efforts focus on developing a reliable and consistent way to identify system models for these soft robotic actuators using high-speed videography based motion tracking. Utilizing a mass-spring-damper model we are able to accurately capture the behavior of a HASEL actuator. We use the resulting plant model to design a Proportional-Integral controller that demonstrates improved closed-loop tracking and steady-state error performance.


Title: Towards a Soft Fingertip with Integrated Sensing and Actuation
Key Words: biomechanics  dexterous manipulators  elasticity  force control  haptic interfaces  manipulator dynamics  pneumatic actuators  tactile sensors  tactile data  SOFTcell  pneumatic actuation  optical sensing  novel controllable stiffness tactile device  soft robotics  high-dimensional nonlinear soft systems  complex coupling  shape changes  tactile sensing  environmental geometry  low intrinsic stiffness  unstructured environments  safe interaction  soft material robots  integrated sensing  soft fingertip  Cameras  Tactile sensors  Optical sensors  Strain 
Abstract: Soft material robots are attractive for safe interaction with humans and unstructured environments due to their compliance and low intrinsic stiffness and mass. These properties enable new capabilities such as the ability to conform to environmental geometry for tactile sensing and to undergo large shape changes for actuation. Due to the complex coupling between sensing and actuation in high-dimensional nonlinear soft systems, prior work in soft robotics has primarily focused on either sensing or actuation. This paper presents SOFTcell, a novel controllable stiffness tactile device that incorporates both optical sensing and pneumatic actuation. We report details on the device's design and implementation and analyze results from characterization experiments on sensitivity and performance, which show that SOFTcell can controllably increase its effective modulus from 4.4kPa to 46.1kPa. Additionally, we demonstrate the utility of SOFTcell for grasping in a reactive control task in which tactile data is used to detect fingertip shear as a grasped object slips, and cell pressurization is used to prevent the slip without the need to adjust fingertip position.


Title: Learning Oscillator-Based Gait Controller for String-Form Soft Robots Using Parameter-Exploring Policy Gradients
Key Words: gradient methods  learning (artificial intelligence)  legged locomotion  mobile robots  actor-critic  oscillators  harness global entrainment  appropriate mechanosensor feedback  reinforcement learning technique  parameter-exploring policy gradients  string-form soft robots  oscillator-based gait controller  soft-bodied robots  appropriate learning method  episode based parameter updates  exploration noise  physical model  PEPG  simulation models  Robot sensing systems  Oscillators  Reinforcement learning  Force  Actuators  Springs 
Abstract: This paper presents a methodology to design mechanosensor feedback to oscillator-based controller for worm-like soft-bodied robots. A reinforcement learning technique, i.e., PEPG, is employed to embed appropriate mechanosensor feedback to harness global entrainment among the controller, the body dynamics, and the environment without explicitly designing the interaction between the oscillators. Another reinforcement learning, actor-critic, was applied to train the controller for the simulation models to analyze the effectiveness of PEPG in the system. Furthermore, the gait controller was trained under different body dynamics, i.e., the physical model of a caterpillar and an earthworm. We found that PEPG is suitable for the system probably because it does not add exploration noise to actions and it conducts episode based parameter updates. The simulation results show the proposed method can acquire distinct behavior, i.e., caterpillars' crawling, inching and earthworms' crawling, under different body dynamics. The outcome implies, that by utilizing appropriate learning method, desired functionality can be achieved in soft-bodied robots without explicitly designing their behavior.


Title: A Partially Filled Jamming Gripper for Underwater Recovery of Objects Resting on Soft Surfaces
Key Words: compliance control  end effectors  grippers  seawater  sediments  underwater vehicles  partially filled jamming gripper  soft surfaces  partially filled membrane  submerged objects  soft substrates  jamming grippers  particle jamming  end effector membrane  internal membrane pressure  deep sea shipwrecks  downward force  maximum lifting force  gripper membrane  soft sediment  irregular objects  grasping  fresh water tank experiment  seawater  compliant foam  fine loose sediment  waterlogged timbers  compliance control  underwater object recovery  Grippers  Jamming  Force  Manifolds  Solids  Substrates  Sediments  soft robotics  universal jamming grippers  marine archeology 
Abstract: In this paper we demonstrate a universal jamming gripper with a partially filled membrane that can pick up submerged objects resting on soft substrates. Jamming grippers take advantage of the phenomenon of particle jamming to control the compliance of an end effector membrane. Changes in internal membrane pressure are used to transition the membrane between hard and soft states. The effort was motivated by the need for tools to sample artifacts on deep sea shipwrecks, which are often found resting on waterlogged timbers, or partially buried in fine, loose sediment. Limiting downward force protects the target, and reduces the likelihood that it will be pushed down in to the substrate, which could lead to a failed grasp. In benchtop tests, the downward force, and the ratio of maximum lifting force to downward force, are shown to be strongly dependent on the initial volume of particles and fluid in the gripper membrane. The gripper achieves lifting forces 6.7 times the downward force on targets with high aspect ratios. Experiments in a fresh water tank demonstrate the ability to grasp objects resting on soft sediment, and compliant foam. Finally, experiments at sea demonstrate that the end effector functions at depths of more than 1000m seawater, successfully grasping a range of irregular objects.


Title: CLASH: Compliant Low Cost Antagonistic Servo Hands
Key Words: actuators  dexterous manipulators  grippers  actuators  grippers  hand-in-hand grasping  variable stiffness actuation  underactuated fingers  differential coupling mechanism  DLR Awiwi hand  lightweight hands  antagonistic modular hands  rapid prototyping  CLASH hands  compliant low cost antagonistic servo hands  Tendons  Thumb  Force  Servomotors  Grasping  Couplings  Kinematics 
Abstract: This paper presents the first two members of the new generation of CLASH hands, which exploit low cost actuation and rapid prototyping to create antagonistic modular and lightweight hands and grippers. The hands approach the robustness of the DLR Awiwi hand with a much lower complexity and cost. To reduce the number of required actuators, a differential coupling mechanism for underactuated fingers was developed, along with a new mechanism that uses variable stiffness actuation in order to increase the workspace of underactuated fingers. The hands provide a research platform for both hand-in-hand and robotic grasping. Design aspects are discussed, and an initial experimental validation verifies the hands' performance.


Title: FBG-Based Control of a Continuum Manipulator Interacting with Obstacles*
Key Words: bone  Bragg gratings  dexterous manipulators  feedback  fibre optic sensors  medical robotics  patient treatment  FBG feedback  FBG-based control  continuum dexterous manipulators  constraint environments  shape sensing methods  optimization-based control algorithm  FBG tip position feedback  feedback control algorithm  CDM interaction  CDM collisions  soft obstacles  hard obstacles  CDM tip  fiber Bragg grating shape sensing unit  CDM shape  bone degradation  osteolysis less-invasive treatment  hard lesions  soft lesions  jacobian information  Shape  Manipulators  Jacobian matrices  Robot sensing systems  Strain  Real-time systems 
Abstract: Tracking and controlling the shape of continuum dexterous manipulators (CDM) in constraint environments is a challenging task. The imposed constraints and interaction with unknown obstacles may conform the CDM's shape and therefore demands for shape sensing methods which do not rely on direct line of sight. To address these issues, we integrate a novel Fiber Bragg Grating (FBG) shape sensing unit into a CDM, reconstruct the shape in real-time, and develop an optimization-based control algorithm using FBG tip position feedback. The CDM is designed for less-invasive treatment of osteolysis (bone degradation). To evaluate the performance of the feedback control algorithm when the CDM interacts with obstacles, we perform a set of experiments similar to the real scenario of the CDM interaction with soft and hard lesions during the treatment of osteolysis. In addition, we propose methods for identification of the CDM collisions with soft or hard obstacles using the jacobian information. Results demonstrate successful control of the CDM tip based on the FBG feedback and indicate repeatability and robustness of the proposed method when interacting with unknown obstacles.


Title: Modeling and Trajectory Tracking Control of a New Parallel Flexible Link Robot
Key Words: control system synthesis  elastic deformation  end effectors  finite element analysis  flexible manipulators  geometry  manipulator dynamics  tracking  trajectory control  arbitrary geometries  modal truncation  Component Mode Synthesis  underactuated robot  flexible model  trajectory tracking control  kinematic loop  elastic deformations  linear finite element models  parallel flexible link robot  compliant lightweight robot  end-effector  Robots  Strain  Finite element analysis  Trajectory tracking  Kinematics  Mathematical model  Shape 
Abstract: A completely new compliant lightweight robot is presented with a kinematic loop and a highly flexible link. It is explained how to model such parallel robots accurately but still computationally efficient. The elastic deformations are described with the floating frame of reference approach. For the flexible components this allows to use linear finite element models, which can represent arbitrary geometries. These models are further reduced by modal truncation and a Component Mode Synthesis minimizing the number of elastic degrees of freedom, which is necessary for real-time control purposes. The obtained model of the underactuated robot is non-minimum phase for the end-effector as output. Thus, for the applied trajectory tracking controller which is based on servo constraints, the concept of stable inversion is used. The performance is compared to a relocated minimum phase output. Corresponding simulations are validated by first experimental results showing the need for and high accuracy of the flexible model and the trajectory tracking control.


Title: Deep Sequential Models for Sampling-Based Planning
Key Words: collision avoidance  computational geometry  learning (artificial intelligence)  mobile robots  multi-agent systems  path planning  sampling methods  deep sequential models  sequence model  sampling-based planner  efficient plans  planner state  neural-network-based models  fewer rejected samples  multiagent environments  graphical models  Hidden Markov models  Computational modeling  Planning  Adaptation models  Space exploration  Uncertainty  Sensors 
Abstract: We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.


Title: A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning
Key Words: mobile robots  path planning  sampling methods  topology  homotopic similarity  homotopy equivalence  naive application  local planning  sampling-based motion planning  topologically distinct portions  topologically distinct paths  robotic motion planning  homotopy classes  topology-based path similarity metric  path deformation roadmaps  multiple homotopically distinct paths  Measurement  Planning  Strain  Algorithms  Merging  Manipulators 
Abstract: Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.


Title: RG-Trees: Trajectory-Free Feedback Motion Planning Using Sparse Random Reference Governor Trees
Key Words: collision avoidance  feedback  mobile robots  motion control  robust control  sampling methods  trajectory control  trees (mathematics)  trajectory-free feedback motion planning  high dimensional configuration spaces  complex environments  open-loop trajectories  feedback control policies  dynamic robot  planned path  spatial constraints  statistical sampling techniques  control methods  feedback control theory perspective  constraint enforcement  feedback motion planner  trajectory-free novel feedback motion planning algorithm  random trees  tree part  collision-free region  connected simple polygonal regions  reference governor part  tree structure  RG-trees  sparse random reference governor  sampling based methods  Robots  Heuristic algorithms  Planning  Collision avoidance  Dynamics  Aerospace electronics  Navigation 
Abstract: Sampling based methods resulted in feasible and effective motion planning algorithms for high dimensional configuration spaces and complex environments. A vast majority of such algorithms as well as their application rely on generating a set of open-loop trajectories first, which are then tracked by feedback control policies. However, controlling a dynamic robot to follow the planned path, while respecting the spatial constraints originating from the obstacles is still a challenging problem. There are some studies which combine statistical sampling techniques and feedback control methods which address this challenge using different approaches. From the feedback control theory perspective, Reference Governors proved to be a useful framework for constraint enforcement. Very recently, Arslan and Koditschek (2017) introduced a feedback motion planner that utilizes Reference Governors that provably solves the motion planning problem in simplified spherical worlds. In this context, here we propose a “trajectory-free” novel feedback motion planning algorithm which combines the two ideas: random trees and reference governors. Random tree part of the algorithm generates a collision-free region as a set of connected simple polygonal regions. Then, reference governor part navigates the dynamic robot from one region to the adjacent region in the tree structure, ensuring it stays inside the current region and asymptotically reaches to the connected region. Eventually, our algorithm robustly routes the robot from the start location to the goal location without collision. We demonstrate the validity and feasibility of the algorithm on simulation studies.


Title: Real-Time Motion Planning in Changing Environments Using Topology-Based Encoding of Past Knowledge
Key Words: collision avoidance  encoding  graph theory  mobile robots  reachability analysis  topology  approximate Reeb graph  BKPIECE algorithms  topology-based encoding  trajectory planning  complex environments  DRM-connect algorithm  dynamic reachability maps  lazy collision checking  fallback strategy  RRT-connect algorithm  sparser roadmaps  motion planning  changing environments  Task analysis  Trajectory  Planning  Heuristic algorithms  Robots  Topology  Maintenance engineering 
Abstract: Trajectory planning and replanning in complex environments often reuses very little information from the previous solutions. This is particularly evident when the motion is repeated multiple times with only a limited amount of variation between each run. To address this issue, we propose the DRM-connect algorithm, a combination of dynamic reachability maps (DRM) with lazy collision checking and a fallback strategy based on the RRT-connect algorithm which is used to repair the roadmap through further exploration. This fallback allows us to use much sparser roadmaps. Furthermore, we investigate using an approximate Reeb graph to capture the topology-persistent features of the past solutions of the problem utilising this sparsity. We evaluate DRM-connect with a Reeb graph on reaching tasks, and we compare it to state-of-the-art methods. We show that the proposed method outperforms both RRT-connect and BKPIECE algorithms in the number of collision checks required and we show that our method has the potential to scale to systems with higher number degrees of freedom.


Title: Distributionally Robust Sampling-Based Motion Planning Under Uncertainty
Key Words: collision avoidance  feedback  Gaussian distribution  mobile robots  path planning  robot dynamics  sampling methods  stochastic processes  obstacle avoidance  unpredictable obstacle motion  uncertain obstacle location  kinodynamic motion planning  distributionally robust RRT  DR-RRT  Gaussian distributions  distributionally robust sampling  distributionally robust incremental sampling  Uncertainty  Planning  Trajectory  Robots  Feedback control  Probabilistic logic  Stochastic processes 
Abstract: We propose a distributionally robust incremental sampling-based method for kinodynamic motion planning under uncertainty, which we call distributionally robust RRT (DR-RRT). In contrast to many approaches that assume Gaussian distributions for uncertain parameters, here we consider moment-based ambiguity sets of distributions with given mean and covariance. Chance constraints for obstacle avoidance and internal state bounds are then enforced under the worst-case distribution in the ambiguity set, which gives a coherent assessment of constraint violation risks. The method generates risk-bounded trajectories and feedback control laws for robots operating in dynamic, cluttered, and uncertain environments, explicitly incorporating localization error, stochastic process disturbances, unpredictable obstacle motion, and uncertain obstacle location. We show that the algorithm is probabilistically complete under mild assumptions. Numerical experiments illustrate the effectiveness of the algorithm.


Title: Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs
Key Words: collision avoidance  end effectors  trees (mathematics)  path planning problems  C-space planners  configuration space  robot end-effector  collision-free paths  workspace information  global planner  task-space RRTs  workspace decomposition  hierarchical path planner  Task analysis  Path planning  End effectors  Partitioning algorithms  Collision avoidance 
Abstract: This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.


Title: Kinodynamic Comfort Trajectory Planning for Car-Like Robots
Key Words: automobiles  collision avoidance  concave programming  force control  mobile robots  object detection  trajectory control  translational force  direct collocation method  smooth trajectory  kinodynamic comfort trajectory planning  car-like robots  personal autonomous mobility  comfortability  kinodynamic comfort path planning method  nonconvex objective function  bidirectional obstacle detection  obstacle avoidance  smooth trajectory generation  Robots  Acceleration  Planning  Trajectory optimization  System dynamics  Linear programming 
Abstract: As personal autonomous mobility is getting to be more widely adopted, it is more important to consider comfortability of stuffs and persons carried by such mobility. In this work, we define the comfort of a trajectory as forces, specifically, translational force, received to objects carried by a robot while following the trajectory by measuring impulse. To maximize such a comfort, we propose a novel, kinodynamic comfort path planning method based on our definition of comfort. Our work is based on direct collocation method for handling our nonconvex objective function. We also introduce Bidirectional Obstacle Detection(BOD)that identifies the distances along the perpendicular directions to the trajectory. This is mainly designed for avoiding obstacles while minimizing forces causing discomfort. Our experimental results show that our method can compute trajectories whose comfort measures can be up to 18 times higher than those computed by prior related objectives, e.g., squared velocity used for generating smooth trajectory.


Title: Expert-Guided Kinodynamic RRT Path Planner for Non-Holonomic Robots
Key Words: mobile robots  path planning  robot dynamics  nonholonomic robots  EGK-RRT  expert-guided kinodynamic RRT path planner  expert-guided kinodynamic RRT algorithm  deterministic control sequences  Robots  Navigation  Heuristic algorithms  Aerospace electronics  Path planning  Planning  Mathematical model 
Abstract: In this paper, an Expert-Guided Kinodynamic RRT algorithm (EGK-RRT) is presented. It aims to consider how a human pilot would navigate a kinodynamic robot. One of the characteristics of this algorithm is the fact that, unlike the original RRT for kinodynamic systems, it generates deterministic control sequences which can be reproduced as long as the sequence of references (sampled states) are known. Here, the performance of the proposed algorithm is tested against the basic RRT, showing that the EGK-RRT greatly improves in terms of execution speed. In addition to this, the influence of using a visibility check and an inertia estimation in order to select the nearest neighbor is also analyzed, demonstrating that a combination of both factors leads to a better overall performance, both in execution speed and in quality of the generated path.


Title: Robot Imitation Through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments
Key Words: evolutionary computation  humanoid robots  human-robot interaction  optimisation  robot vision  trajectory control  optimization problem  continuous goal-directed actions  robot joint trajectories  online evolved trajectories  force features  iron actions  TEO full-sized humanoid robot  motor execution  CGDA execution  online evolutionary strategies  evolutionary algorithms  robot imitation framework  Trajectory  Robot sensing systems  Feature extraction  Force  Planning  Paints 
Abstract: Continuous Goal-Directed Actions (CGDA)is a robot imitation framework that encodes actions as the changes they produce on the environment. While it presents numerous advantages with respect to other robot imitation frameworks in terms of generalization and portability, final robot joint trajectories for the execution of actions are not necessarily encoded within the model. This is studied as an optimization problem, and the solution is computed through evolutionary algorithms in simulated environments. Evolutionary algorithms require a large number of evaluations, which had made the use of these algorithms in real world applications very challenging. This paper presents online evolutionary strategies, as a change of paradigm within CGDA execution. Online evolutionary strategies shift and merge motor execution into the planning loop. A concrete online evolutionary strategy, Online Evolved Trajectories (OET), is presented. OET drastically reduces computational times between motor executions, and enables working in real world dynamic environments and/or with human collaboration. Its performance has been measured against Full Trajectory Evolution (FTE)and Incrementally Evolved Trajectories (IET), obtaining the best overall results. Experimental evaluations are performed on the TEO full-sized humanoid robot with “paint” and “iron” actions that together involve vision, kinesthetic and force features.


Title: Probabilistic Learning of Torque Controllers from Kinematic and Force Constraints
Key Words: control engineering computing  force control  Gaussian distribution  learning (artificial intelligence)  manipulators  motion control  position control  torque control  kinematic constraints  task representation  task space  Gaussian distributions  7- DoF torque-controlled manipulators  joint space  torque control commands  operational configuration space  force constraints  probabilistic learning  Task analysis  Torque  Aerospace electronics  Probabilistic logic  Force  End effectors 
Abstract: When learning skills from demonstrations, one is often required to think in advance about the appropriate task representation (usually in either operational or configuration space). We here propose a probabilistic approach for simultaneously learning and synthesizing torque control commands which take into account task space, joint space and force constraints. We treat the problem by considering different torque controllers acting on the robot, whose relevance is learned probabilistically from demonstrations. This information is used to combine the controllers by exploiting the properties of Gaussian distributions, generating new torque commands that satisfy the important features of the task. We validate the approach in two experimental scenarios using 7- DoF torque-controlled manipulators, with tasks that require the consideration of different controllers to be properly executed.


Title: Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration
Key Words: control engineering computing  decision making  learning (artificial intelligence)  mobile robots  motion control  path planning  road vehicles  vehicle dynamics  human-vehicle interaction simulation framework  driving motions  vehicle maneuver motion primitives  driving decision-making  vehicle design  human demonstration  vehicle dynamics  motion control  motion primitive library  longitudinal vehicle control  motion reproduction  dynamic motion primitives  imitation learning methods  fixed-base driving simulation  vehicle maneuver motion planning  Vehicles  Computational modeling  Task analysis  Motion segmentation  Vehicle dynamics  Hidden Markov models  Dynamics 
Abstract: High-fidelity computational human models provide a safe and cost-efficient method for studying driver experience in vehicle maneuvers and for validation of vehicle design. Compared to passive human models, active human models capable of reproducing the decision-making, as well as vehicle maneuver motion planning and control, will be able to support realistic simulation of human-vehicle interaction. In this paper, we propose an integrated human-vehicle interaction simulation framework which learns vehicle maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions. Specifically, we recruited six experienced drivers and recorded their vehicle maneuver motions on a fixed-base driving simulation testbed. We further segmented and classified the collected data based on their similarity in joint coordination. Using a combination of imitation learning methods, we extracted the regularity and variability of vehicle maneuver motions across subjects, and learned the dynamic motion primitives to be used for motion reproduction in simulation. We present an implementation of the framework on lower-extremity joint coordination in pedal activation for longitudinal vehicle control. Our research efforts lead to a motion primitive library which enables planning natural driver motions, and will be integrated with the driving decision-making, motion control, and vehicle dynamics in the proposed framework for simulating human-vehicle interaction.


Title: Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization
Key Words: human-robot interaction  inference mechanisms  learning (artificial intelligence)  mobile robots  teaching  user interfaces  teaching strategies  end-user programming  learning task  human teachers  fetch mobile manipulator  warehouses  robotic shelf organization  online user study  goal inference approach  system implementation  grocery store shelf images  Task analysis  Programming  Manipulators  Shape  Packaging  Education 
Abstract: Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.


Title: Incremental Skill Learning of Stable Dynamical Systems
Key Words: control engineering computing  Gaussian processes  learning (artificial intelligence)  mobile robots  motion control  regression analysis  robot programming  stability  trajectory control  control input  Gaussian process regression  incremental skill learning  online adaptation  assistive robotic applications  motion trajectories  dynamical systems  skill acquisition  autonomous DS  stability properties  Robots  Trajectory  Task analysis  Training  Training data  Gaussian processes  Dynamics 
Abstract: Efficient skill acquisition, representation, and online adaptation to different scenarios has become of fundamental importance for assistive robotic applications. In the past decade, dynamical systems (DS) have arisen as a flexible and robust tool to represent learned skills and to generate motion trajectories. This work presents a novel approach to incrementally modify the dynamics of a generic autonomous DS when new demonstrations of a task are provided. A control input is learned from demonstrations to modify the trajectory of the system while preserving the stability properties of the reshaped DS. Learning is performed incrementally through Gaussian process regression, increasing the robot's knowledge of the skill every time a new demonstration is provided. The effectiveness of the proposed approach is demonstrated with experiments on a publicly available dataset of complex motions.


Title: Deeply Informed Neural Sampling for Robot Motion Planning
Key Words: collision avoidance  computational complexity  feedforward neural nets  geometry  learning (artificial intelligence)  mobile robots  sampling methods  obstacle geometry  computational complexity  configuration space  optimal path solution  hand-crafted heuristics  high-dimensional spaces  neural network-based adaptive sampler  raw point cloud data  workspace encoding  collision-free optimal paths  point-mass robot  6-link robotic manipulator  dropout-based stochastic deep feedforward neural network  DeepSMPs neural architecture  deep sampling-based motion planner  robot motion planning  deeply informed neural sampling  contractive autoencoder  rigid-body  Planning  Robots  Encoding  Three-dimensional displays  Convergence  Switched mode power supplies  Transforms 
Abstract: Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.


Title: Inverse Learning of Robot Behavior for Collaborative Planning
Key Words: behavioural sciences computing  decision making  learning (artificial intelligence)  mobile robots  multi-robot systems  optimisation  planning (artificial intelligence)  robots decision making  TurtleBots  Phantom X arms  line robots behavior  collaborative planning problem  colored-ball sorting task  unripe fruit  ripe fruit  IRL  inverse reinforcement learning  Task analysis  Planning  Robot kinematics  Sorting  Teamwork 
Abstract: Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.


Title: Multi-Cable Rolling Locomotion with Spherical Tensegrities Using Model Predictive Control and Deep Learning
Key Words: actuators  cables (mechanical)  differential equations  feedback  learning (artificial intelligence)  open loop systems  predictive control  robust control  trajectory control  generated optimal MPC trajectories  supervised deep learning  contextual policy  benchmark single-cable policy performance  resulting multicable state-action trajectories  dynamic rolling  multicable actuation trajectories  Class-1 tensegrity systems  structured dynamics  spherical tensegrity topology  robust control policies  model-based approach  model predictive control  spherical tensegrities  multicable rolling locomotion  end-to-end feedback policy  Mathematical model  Predictive control  Topology  Robot kinematics  Dynamics  Optimization 
Abstract: This work presents a model-based approach for creating robust control policies for rolling locomotion with a spherical tensegrity topology. Utilizing the structured dynamics of Class-1 tensegrity systems, we turn to model predictive control (MPC) to generate optimal multi-cable actuation trajectories for dynamic rolling. Although the resulting multi-cable state-action trajectories successfully outperform the benchmark single-cable policy performance in speed, computational constraints prevent MPC from being applied in real-time. To address this, we demonstrate that a contextual policy trained using supervised deep learning on the generated optimal MPC trajectories can be used as an end-to-end feedback policy for real-time directed rolling locomotion.


Title: Integrating Path Planning and Pivoting
Key Words: end effectors  path planning  manipulator  pivoting strategy  Baxter robot  path planning  motion planning  in-hand manipulation  end-effector  Grippers  Task analysis  Friction  End effectors  Trajectory 
Abstract: In this work we propose a method for integrating motion planning and in-hand manipulation. Commonly addressed as a separate step from the final execution, in-hand manipulation allows the robot to reorient an object within the end-effector for the successful outcome of the goal task. A joint achievement of repositioning the object and moving the manipulator towards its desired final pose saves time in the execution and introduces more flexibility in the system. We address this problem using a pivoting strategy (i.e. in-hand rotation)for repositioning the object and we integrate this strategy with a path planner for the execution of a complex task. This method is applied on a Baxter robot and its efficacy is shown by experimental results.


Title: Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System
Key Words: dexterous manipulators  manipulator dynamics  robot vision  continuous high-speed operation  one-face turn motion  high-speed multifingered hand  high-speed vision system  Rubiks cube handling  robotic hand regrasping function  time 1.0 s  time 10.0 s  Gravity  Face  Robot sensing systems  Turning  Trajectory  Orbits 
Abstract: The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.


Title: Contingent Contact-Based Motion Planning
Key Words: manipulators  mobile robots  path planning  robust control  POMDP-based planners  contingent contact-based motion planning  contact sensing capability  manipulation planner  conformant planners  high-dimensional configuration spaces  Robot sensing systems  Uncertainty  Planning  Partitioning algorithms  Vegetation 
Abstract: A robot with contact sensing capability can reduce uncertainty relative to the environment by deliberately moving into contact and matching the resulting contact measurement to different possible states in the world. We present a manipulation planner that finds and sequences these actions by reasoning explicitly about the uncertainty over the robot's state. The planner incrementally constructs a policy that covers all possible contact states during a manipulation and finds contingencies for each of them. In contrast to conformant planners (without contingencies), the planned contingent policies are more robust. We demonstrate this in simulated and real-world manipulation experiments. In contrast to POMDP-based planners, we show that our planner can be directly applied to high-dimensional configuration spaces.


Title: A Cable-Driven Redundant Spatial Manipulator with Improved Stiffness and Load Capacity
Key Words: control system synthesis  dexterous manipulators  end effectors  flexible manipulators  Jacobian matrices  manipulator kinematics  motion control  path planning  redundant manipulators  cable transmission mechanisms  load capacity experiments  relatively high stiffness  cable-driven redundant spatial manipulator  flexible manipulability  revolute rigid manipulators  mechanism design  manipulator dexterity  end-effector accuracy  active-passive-linkage segments  active-passive segment  manipulator kinematic equations  motion planning  Jacobian matrix  Denavit-Hartenberg method  D-H method  CRSM  Couplings  Kinematics  Springs  Task analysis  End effectors  Cable-driven  Redundant manipulator  Stiffness  Load capacity  Kinematic 
Abstract: With a light and slender body, a cable-driven redundant spatial manipulator (CRSM) has flexible manipulability and high maneuverability in confined environment. However, compared with revolute rigid manipulators, such type of manipulators generally has low stiffness and weak load capacity. In this paper, we propose a new mechanism design to improve the stiffness and load capacity without sacrificing the manipulator dexterity and the end-effector accuracy. The manipulator is composed of 3 active-passive-linkage segments and 1 active tool end-effector. Each active-passive segment has 2 degrees of freedom (DOFs) driven by three evenly distributed cables. Pretension mechanism and linkage cables are designed to keep strict equal angles of adjacent joints. A separable control box, which contains all the motors and cable transmission mechanisms is also designed with a quick release-and-lock mechanism. Therefore, the robotic arm can be easily removed and installed. Based on the equal angle characteristic, kinematic equations of manipulator are established with Denavit-Hartenberg (D-H) method and the Jacobian matrix is also simplified. Further analysis of the workspace supplies the guidance for the task design and motion planning. Finally, a prototype system is developed to perform the stiffness and load capacity experiments. Experimental results show that the developed CRSM has relatively high stiffness and load capacity.


Title: Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*
Key Words: legged locomotion  manipulators  mobile robots  motion control  path planning  position control  system states  system trajectory  nonprehensile  manipulation strategies  multilimb robot  control strategy  point contacts  contact velocity constraint  force constraint  system forces  system dynamic models  Robot kinematics  Force  Acceleration  Humanoid robots  Legged locomotion  Friction 
Abstract: This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.


Title: Assisted Telemanipulation: A Stack-Of-Tasks Approach to Remote Manipulator Control
Key Words: collision avoidance  dexterous manipulators  force control  grippers  haptic interfaces  humanoid robots  human-robot interaction  mobile robots  motion control  telerobotics  assisted telemanipulation  stack-of-tasks approach  remote manipulator control  assisted teleoperation  robot arm  hierarchical nature  SoT framework  operator commands  assistive tasks  joint limit  obstacle avoidance  automatic gripper alignment  teleoperation problem  assistive control  manual control  real-time stack-of-tasks whole-body motion control framework  teleoperated pick-and-place tasks  telemanipulation system  Task analysis  Grippers  Robot kinematics  Manipulators  Acceleration  Collision avoidance 
Abstract: This article presents an approach for assisted teleoperation of a robot arm, formulated within a real-time stack-of-tasks (SoT)whole-body motion control framework. The approach leverages the hierarchical nature of the SoT framework to integrate operator commands with assistive tasks, such as joint limit and obstacle avoidance or automatic gripper alignment. Thereby some aspects of the teleoperation problem are delegated to the controller and carried out autonomously. The key contributions of this work are two-fold: the first is a method for unobtrusive integration of autonomy in a telemanip-ulation system; and the second is a user study evaluation of the proposed system in the context of teleoperated pick-and-place tasks. The proposed approach of assistive control was found to result in higher grasp success rates and shorter trajectories than achieved through manual control, without incurring additional cognitive load to the operator.


Title: Adaptive Admittance Control in Task-Priority Framework for Contact Force Control in Autonomous Underwater Floating Manipulation* This work is part of a project titled “Force/position control system to enable compliant manipulation from a floating I-AUV”, which received funding from the European Union's Horizon 2020 research and innovation programme, under the Marie Sklodowska-Curie grant agreement no. 750063.
Key Words: autonomous underwater vehicles  cooperative systems  end effectors  force control  manipulator dynamics  manipulator kinematics  manipulators  mobile robots  position control  task-priority kinematic control algorithm  custom force control strategy  impedance control  TP algorithm  inequality tasks  singular configurations  force control part  impedance concept  exerted force  stable contact  control architecture  adaptive admittance control  task-priority framework  contact force control  underwater vehicle-manipulator system  end-effector configuration  floating-base manipulation  Force control  Task analysis  Force  Impedance  Robots  Heuristic algorithms  Inspection 
Abstract: This paper presents a control architecture for an underwater vehicle-manipulator system (UVMS) to enable simultaneous tracking of end-effector configuration and contact force during floating-base manipulation. The main feature of the architecture is its combination of a task-priority (TP) kinematic control algorithm with a custom force control strategy, based on impedance (admittance) control. The TP algorithm used in the work includes recent treatment of equality and inequality tasks as well as original concepts to handle operation in singular configurations of the system. In the force control part the impedance concept is extended to allow for direct control over the value of exerted force and torque. Additional feed-forward signal is used to ensure stable contact. The performance of the control architecture is demonstrated by experiments in a test tank, with GIRONA500 I-AUV performing pipe inspection.


Title: Optimizing Sensor Placement: A Mixture Model Framework Using Stable Poses and Sparsely Precomputed Pose Uncertainty Predictions
Key Words: image sensors  mobile robots  optimisation  pose estimation  probability  robot vision  sensor placement  computer vision system  mixture model framework  sensor placement optimization  robotics tasks  pose estimation  probability distribution  primesense carmine  Robot sensing systems  Uncertainty  Computational modeling  Task analysis  Optimization  Measurement 
Abstract: In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.


Title: Robust 6D Object Pose Estimation in Cluttered Scenes Using Semantic Segmentation and Pose Regression Networks
Key Words: clutter  data acquisition  image segmentation  object detection  pose estimation  regression analysis  robot vision  pose regression networks  cluttered scenes  cropped object-centered  object poses  cluttered bin-picking scenes  semantic segmentation  synthetic data generation procedure  fast data acquisition method  estimation methods  real-world bin-picking settings  object pose estimation  Pose estimation  Semantics  Three-dimensional displays  Training  Image segmentation  Solid modeling  Robots 
Abstract: Object pose estimation is a crucial prerequisite for robots to perform autonomous manipulation in clutter. Real-world bin-picking settings such as warehouses present additional challenges, e.g., new objects are added constantly. Most of the existing object pose estimation methods assume that 3D models of the objects is available beforehand. We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure. This work builds on previous work on semantic segmentation of cluttered bin-picking scenes to isolate individual objects in clutter. An additional network is trained on synthetic scenes to estimate object poses from a cropped object-centered encoding extracted from the segmentation results. The proposed method is evaluated on a synthetic validation dataset and cluttered realworld scenes.


Title: Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks
Key Words: calibration  humanoid robots  learning (artificial intelligence)  manipulators  motion control  neural nets  robot vision  stereo image processing  robotic manipulation tasks  physical iCub robot  joint measurements  systematic error  accurate joint estimates  visuomotor predictor  image-to-image translation approach  physical robot  sensing error  unavoidable sources  underlying head configuration  stereo image pair  visuomotor deep neural network predictor  hand-eye coordination task  iCub humanoid  complex robots  accurate hand-eye coordination  visuomotor learning  Robot kinematics  Head  Task analysis  Robot sensing systems  Visualization  Manipulators 
Abstract: Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.


Title: Proprioception-Based Grasping for Unknown Objects Using a Series-Elastic-Actuated Gripper
Key Words: actuators  dexterous manipulators  elasticity  force control  grippers  mechanoception  MIMO systems  motion control  series-elastic-actuated gripper  stable fingertip grasps  proprioceptive gripper  proprioception-based grasping  multi-input-multi-output control  MIMO control  sensors  Robot sensing systems  Grippers  Grasping  Pulleys  Springs  Sea measurements 
Abstract: Grasping unknown objects has been an active research topic for decades. Approaches range from using various sensors (e.g. vision, tactile) to gain information about the object, to building passively compliant hands that react appropriately to contacts. In this paper, we focus on grasping unknown objects using proprioception (the combination of joint position and torque sensing). Our hypothesis is that proprioception alone can be the basis for versatile performance, including multiple types of grasps for objects with multiple shapes and sizes, and transitions between grasps. Using a series-elastic-actuated gripper, we propose a method for performing stable fingertip grasps for unknown objects with unknown contacts, formulated as multi-input-multi-output (MIMO) control. We also show that the proprioceptive gripper can perform enveloping grasps, as well as the transition from fingertip grasps to enveloping grasps.


Title: Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter
Key Words: Bayes methods  Kalman filters  manipulators  particle filtering (numerical methods)  quadratic programming  state estimation  RBPF  contact states  Kalman filters  constrained Rao-Blackwellized Particle Filter  robotic sensors  robotic manipulation task  multibody dynamic system  Bayesian filtering methods  state estimation  quadratic programming problem  Robot sensing systems  Mathematical model  Kalman filters  State estimation  Dynamics 
Abstract: Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.


Title: A Gripper for Object Search and Grasp Through Proximity Sensing
Key Words: calibration  grippers  manipulators  mobile robots  motion control  robot vision  object grasp  object search  calibration method  proximity sensors  sensor reaction  robot motions  proximity sensing  sensor information  primitive motions  gripper  Robot sensing systems  Rubber  Grippers  Calibration  Search problems 
Abstract: Robots need to adapt themselves to various surroundings in order to achieve robust object search and grasp in unknown environments. For this adaptation, robot motions should be implemented as combination of primitive motions which are based on sensor reaction. Among various sensing methods, non contact sensing is required as a means of preventing operation failures such as pushing objects. Especially, proximity sensors have been proved effective in avoiding occlusion problems. In this paper, we first develop a gripper on which proximity sensors are mounted all around, and then calculate distance between the gripper and objects using proposed calibration method. This enables robots to recognize detailed shapes of objects surrounding the gripper. We also propose primitive motions for object search and grasp, and describe the contents of each motion. The motions are based on sensor information obtained from the gripper. We verify the effectiveness of our system through an experiment in which a real robot performs complex tasks by combination of the primitive motions.


Title: Exploring Vestibulo-Ocular Adaptation in a Closed-Loop Neuro-Robotic Experiment Using STDP. A Simulation Study
Key Words: brain models  closed loop systems  control engineering computing  humanoid robots  neural nets  neural system  Neuro-robotic Platform  NRP  vestibulo ocular cerebellar adaptatIon  STDP mechanisms  cerebellar molecular layer  r-VOR adaptation  spiking cerebellar model  r-VOR task  perception-action closed-loop  vestibulo-ocular reflex  humanoid robot  iCub robot  cerebellar properties  Robot sensing systems  Neurons  Adaptation models  Transfer functions  Task analysis  Optical fiber networks 
Abstract: Studying and understanding the computational primitives of our neural system requires for a diverse and complementary set of techniques. In this work, we use the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar adaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms located at the cerebellar molecular layer and the vestibular nuclei respectively. This simulation study adopts an experimental setup (rotatory VOR)widely used by neuroscientists to better understand the contribution of certain specific cerebellar properties (i.e. distributed STDP, neural properties, coding cerebellar topology, etc.)to r-VOR adaptation. The work proposes and describes an embodiment solution for which we endow a simulated humanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and we face the humanoid to an r-VOR task. The results validate the adaptive capabilities of the spiking cerebellar model (with STDP)in a perception-action closed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.


Title: Neurorobotic Approach to Study Huntington Disease Based on a Mouse Neuromusculoskeletal Model
Key Words: biomechanics  cognition  diseases  genetics  medical robotics  muscle  neurophysiology  altered genetic code  macroscopic neuro-musculoskeletal model  neurorobotic approach  mouse neuromusculoskeletal model  biological system  neurorobotics view  early onset symptoms  neurodegenerative disease  genetically engineered Huntington disease model mice  progressive impaired motor functions  crystalized motion profile  normal mice  abnormal mice  whole-body level motor coordination  long-term objective  human mind  cognitive functions  soft neurorobotic suit  HD model mice  molecular mechanisms  macroscopic neuromusculoskeletal model  Mice  Diseases  Joints  Robots  Kinematics  Bones  Biological system modeling 
Abstract: Motor functions of the biological system has been forged through 4 billion years evolution. From a neurorobotics view, it is important not only to know how well it works, but also how it fails. To quantitatively describe early onset symptoms of a neurodegenerative disease, we analyzed phenotypes of genetically engineered Huntington disease (HD) model mice, which reveal progressive impaired motor functions. We devised a simple yet sensitive paradigm called the crystalized motion profile (CMP), by which we successfully detected subtle difference between normal and abnormal mice in terms of whole-body level motor coordination. Our long-term objective is to remodel human mind and body to regain impaired motor and cognitive functions with ageing. To do so, we are developing a soft neurorobotic suit that provides integrated cognitive and physical interventions to users. Our analysis on the HD model mice is important as the first step to bridge between molecular mechanisms (altered genetic code) and the macroscopic neuro-musculoskeletal model. With this, we can extrapolate from knowledge of non-human mammals to human to derive the remodeling.


Title: Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks
Key Words: aerospace robotics  force control  manipulator kinematics  mobile robots  motion control  rotors  whole body locomotion  tactile perception  finite state automaton  aerial robot peg-in-hole insertion tasks  impedance based force control  dual arm multidegree of freedom manipulator  kinematic constraints  dual arm manipulator  multirotor base  multistage strategy  impedance control  peg-in-hole approach  multirotor platform  canonical peg-in-hole manipulation task  Force  Impedance  Task analysis  Manipulator dynamics  Rotors  Kinematics 
Abstract: This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.


Title: Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations
Key Words: actuators  autonomous aerial vehicles  feedback  industrial manipulators  inspection  manipulator dynamics  manipulator kinematics  mobile robots  motion control  pendulums  position control  torque control  inspection operations  multirotor blades  environmental obstacles  inspection tasks  long reach aerial manipulator  hexarotor platform  compliant joint arm  one-meter-length link  passive pendulum configuration  force/torque estimation-control  joint deflection  visual inspection  wearable exoskeleton interface  aerial manipulator kinematics  aerial manipulator dynamics  Manipulator dynamics  Inspection  Robot sensing systems  Visualization  Exoskeletons  Cameras 
Abstract: The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.


Title: Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles
Key Words: autonomous aerial vehicles  collision avoidance  feedback  mobile robots  multi-robot systems  predictive control  state feedback  trajectory control  prediction horizon  decentralized collision avoidance system  fast nonlinear feedback  virtual UAV  translational dynamics  nonlinear state feedback  linear model predictive controller  optimal trajectory tracking  unmanned aerial vehicles  model predictive trajectory tracking  priority-based collision resolution strategy  tracking mechanism  in-advance collision-free planning  linear MPC  Trajectory  Collision avoidance  Unmanned aerial vehicles  Robot kinematics  Planning  Robot sensing systems 
Abstract: We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.


Title: Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  pressure control  pressure sensors  state estimation  wind tunnels  pressure sensors  NASA Langley Research Center  distributed algorithm  wind tunnel  commercial air transportation  self-aware autonomous aerial vehicles  lattice-based subcomponents  14-foot wingspan  skin panels  flexible aerostructure  aerodynamic state estimation  modular distributed pressure sensing skin  autonomous systems  adaptable self-state estimation  robust self-state estimation  autonomous aerial transportation  pressure distribution  Robot sensing systems  Pressure sensors  Skin  Aerodynamics  NASA 
Abstract: Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.


Title: Light-Weight Object Detection and Decision Making via Approximate Computing in Resource-Constrained Mobile Robots
Key Words: decision making  Markov processes  mobile robots  object detection  path planning  robot vision  light-weight object detection  approximate computing  resource-constrained mobile robots  autonomous flights  indoor environments  point clouds  computer vision algorithms  mobile autonomous platforms  video data  decision making  geometric maps  Markov decision process framework  Object detection  Proposals  Roads  Support vector machines  Computer vision  Cameras 
Abstract: Most of the current solutions for autonomous flights in indoor environments rely on purely geometric maps (e.g., point clouds). There has been, however, a growing interest in supplementing such maps with semantic information (e.g., object detections) using computer vision algorithms. Unfortunately, there is a disconnect between the relatively heavy computational requirements of these computer vision solutions, and the limited computation capacity available on mobile autonomous platforms. In this paper, we propose to bridge this gap with a novel Markov Decision Process framework that adapts the parameters of the vision algorithms to the incoming video data rather than fixing them a priori. As a concrete example, we test our framework on a object detection and tracking task, showing significant benefits in terms of energy consumption without considerable loss in accuracy, using a combination of publicly available and novel datasets.


Title: The RobotriX: An Extremely Photorealistic and Very-Large-Scale Indoor Dataset of Sequences with Robot Trajectories and Interactions
Key Words: control engineering computing  image colour analysis  image resolution  learning (artificial intelligence)  rendering (computer graphics)  robot vision  trajectory control  virtual reality  RobotriX  extremely photorealistic indoor dataset  very-large-scale indoor dataset  robot trajectories  deep learning techniques  robotic vision problems  hyperrealistic indoor scenes  robot agents  Unreal Engine  virtual reality headset  robotic hands  ground truth labels  3D robotic vision tasks  large-scale data-driven techniques  UnrealCV  full HD resolution  RGB-D  2D robotic vision tasks  Robots  Three-dimensional displays  Trajectory  Deep learning  Image resolution  Rendering (computer graphics)  Layout 
Abstract: Enter the RobotriX, an extremely photorealistic indoor dataset designed to enable the application of deep learning techniques to a wide variety of robotic vision problems. The RobotriX consists of hyperrealistic indoor scenes which are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline using UnrealCV to generate raw data and ground truth labels. By taking this approach, we were able to generate a dataset of 38 semantic classes across 512 sequences totaling 8M stills recorded at +60 frames per second with full HD resolution. For each frame, RGB-D and 3D information is provided with full annotations in both spaces. Thanks to the high quality and quantity of both raw information and annotations, the RobotriX will serve as a new milestone for investigating 2D and 3D robotic vision tasks with large-scale data-driven techniques.


Title: Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information
Key Words: learning (artificial intelligence)  mobile robots  object recognition  object category learning  learning recognition  evaluation approaches  recognition approaches  multicontext scenarios  recognition methods  unconstrained human environments  autonomous robots  object categories  human-centric environment  explicit context information  open-ended object recognition  context change  Robots  Visualization  Protocols  Histograms  Context modeling  Three-dimensional displays  Training 
Abstract: To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.


Title: Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization
Key Words: cameras  computer vision  feature extraction  image colour analysis  image segmentation  image texture  learning (artificial intelligence)  optimisation  pose estimation  regression analysis  virtual reality  RGB-D  computer vision applications  self-driving cars  virtual reality  recent random forests  pixel comparison features  3D world locations  2D image locations  point features  geometric information  motion blur  line segments  uncertainty driven regression forests  Cameras  Forestry  Image segmentation  Three-dimensional displays  Robot vision systems  Training  Two dimensional displays 
Abstract: Camera relocalization plays a vital role in many robotics and computer vision applications, such as self-driving cars and virtual reality. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these point features are only sampled randomly in images, without considering geometric information such as lines, leading to large errors with the existence of poorly textured areas or in motion blur. Line segments are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.


Title: Hybrid Bayesian Eigenobjects: Combining Linear Subspace and Deep Network Methods for 3D Robot Vision
Key Words: Bayes methods  eigenvalues and eigenfunctions  image representation  neural nets  regression analysis  robot vision  stereo image processing  linear subspace methods  deep convolutional prediction  nonlinear object representations  Hybrid Bayesian Eigenobjects  deep network methods  3D robot vision  HBEO  3D geometry  Three-dimensional displays  Robots  Bayes methods  Pose estimation  Databases  Principal component analysis  Task analysis 
Abstract: We introduce Hybrid Bayesian Eigenobjects (HBEOs), a novel representation for 3D objects designed to allow a robot to jointly estimate the pose, class, and full 3D geometry of a novel object observed from a single viewpoint in a single practical framework. By combining both linear subspace methods and deep convolutional prediction, HBEOs efficiently learn nonlinear object representations without directly regressing into high-dimensional space. HBEOs also remove the onerous and generally impractical necessity of input data voxelization prior to inference. We experimentally evaluate the suitability of HBEOs to the challenging task of joint pose, class, and shape inference on novel objects and show that, compared to preceding work, HBEOs offer dramatically improved performance in all three tasks along with several orders of magnitude faster runtime performance.


Title: Submap-Based Pose-Graph Visual SLAM: A Robust Visual Exploration and Localization System* The work in this paper is supported by the National Natural Science Foundation of China (61603103, 61673125), the Natural Science Foundation of Guangdong of China (2016A030310293), and the Major Scientific and Technological Special Project of Guangdong of China (2016B090910003).
Key Words: graph theory  mean square error methods  pose estimation  robot vision  SLAM (robots)  VSLAM algorithms  robust visual exploration  visual simultaneous localization and mapping  submap-based pose-graph visual SLAM  robust exploration  visual front-end  submap-based VSLAM system  Image edge detection  Optimization  Robustness  Visualization  Merging  Robots  Tracking  Monocular VSLAM  Submap-based Backend  Robustness 
Abstract: For VSLAM (Visual Simultaneous Localization and Mapping), localization is a challenging task, especially for some challenging situations: textureless frames, motion blur, etc. To build a robust exploration and localization system in a given space, a submap-based VSLAM system is proposed in this paper. Our system uses a submap back-end and a visual front-end. The main advantage of our system is its robustness with respect to tracking failure, a common problem in current VSLAM algorithms. The robustness of our system is compared with the state-of-the-art in terms of average tracking percentage. The precision of our system is also evaluated in terms of ATE (absolute trajectory error) RMSE (root mean square error) comparing the state-of-the-art. The ability of our system in solving the “kidnapped” problem is demonstrated. Our system can improve the robustness of visual localization in challenging situations.


Title: Active Object Perceiver: Recognition-Guided Policy Learning for Object Searching on Mobile Robots
Key Words: indoor navigation  learning (artificial intelligence)  mobile robots  neural nets  object recognition  robot vision  AI2-THOR dataset  action prediction mechanism  deep reinforcement learning  visual navigation  indoor environment  mobile robots  recognition-guided policy learning  active object perceiver  object searching task  physical robot  object recognition module  deep neural network  Robots  Task analysis  Object recognition  Navigation  Search problems  Visualization  Neural networks 
Abstract: We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR)and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.


Title: Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow
Key Words: distance measurement  Gaussian processes  image reconstruction  learning (artificial intelligence)  mobile robots  motion estimation  neural nets  pose estimation  robot vision  SLAM (robots)  stereo image processing  learning monocular visual odometry  monocular SLAM  simultaneous localization  neural network  dual-stream L-VO network  6DOF relative pose  bivariate Gaussian modeling  KITTI odometry  visual SLAM system  dense 2D flow  fully deep learning approach  dense 3D flow  dense 3D mapping  Three-dimensional displays  Simultaneous localization and mapping  Visual odometry  Two dimensional displays  Deep learning  Cameras  Training 
Abstract: This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 % for average translational error and 0.0143°/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.


Title: Key-Frame Strategy During Fast Image-Scale Changes and Zero Motion in VIO Without Persistent Features
Key Words: computational complexity  distance measurement  feature extraction  image sequences  inertial navigation  Kalman filters  motion estimation  robot vision  video signal processing  common special motion  feature displacement  fast motion  zero motion phases  frame selection approach  motion scenarios  motion case identification  subsequent case-specific heuristics  state vectoraltogether  persistent features  VIO algorithm  motion spectrum  fast scale change  frame strategy  fast image-scale changes  regular motion  special treatment  bad data  corrupted data  clean data  visual-inertial odometry frameworks  Computational complexity  Cameras  Computed tomography  Feature extraction  Kalman filters  Quaternions  Covariance matrices 
Abstract: Many of today's Visual-Inertial Odometry (VIO) frameworks work well under regular motion but have issues and need special treatment under special motion. Here, special does not imply bad or corrupted data but stands for increased difficulty to treat clean data. Common special motion for VIO are large feature displacement due to fast motion close to a scene and zero motion phases not providing sufficient baseline. In this paper we present a feature and frame selection approach which seamlessly handles all motion scenarios without the need of (error prone) motion case identification and subsequent case-specific heuristics. We further show that this approach allows to eliminate features in the state vector (persistent features)altogether while still being able to inherently handle zero motion phases. This reduces computational complexity while maintaining the ability to hover in place. We integrate our frame selection approach into our own VIO algorithm and compare its performance against three state-of-the-art algorithms with real data on a real platform. While our approach shows slightly higher global drift it is the only algorithm that can reliably estimate the pose over a large motion spectrum from fast scale change down to zero motion.


Title: Unit Quaternion-Based Parameterization for Point Features in Visual Navigation
Key Words: covariance matrices  geometry  image representation  recursive estimation  SLAM (robots)  point features  visual navigation  Cartesian 3D representation  homogeneous points  error state  unit-quaternion error covariance  initial feature observations  initial error-states  unit quaternion-based representation  unit quaternion-based parameterization  initial infinite depth uncertainty  Quaternions  Cameras  Simultaneous localization and mapping  Visualization  Navigation  Convergence  Three-dimensional displays 
Abstract: In this paper, we propose to use unit quaternions to represent point features in visual navigation. Contrary to the Cartesian 3D representation, the unit quaternion can well represent features at both large and small distances from the camera without suffering from convergence problems. Contrary to inverse-depth, homogeneous points, or anchored homogeneous points, the unit quaternion has error state of minimum dimension of three. In contrast to prior representations, the proposed method does not need to approximate an initial infinite depth uncertainty. In fact, the unit-quaternion error covariance can be initialized from the initial feature observations without prior information, and the initial error-states are not only bounded, but the bound is identical for all scene geometries. To the best of our knowledge, this is the first time bearing-only recursive estimation (in covariance form) of point features has been possible without using measurements to initialize error covariance. The proposed unit quaternion-based representation is validated on numerical examples.


Title: A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control
Key Words: closed loop systems  computational complexity  iterative methods  linear quadratic control  nonlinear control systems  predictive control  iterative algorithms  unconstrained nonlinear optimal control  iLQR algorithm  closed-loop forward integration  linear complexity  multiple shooting algorithms  nonlinear model predictive control applications  computational complexity  high-dimensional underactuated robot  iterative Gauss-Newton shooting methods  Optimal control  Trajectory  Heuristic algorithms  Prediction algorithms  Robots  System dynamics  Convergence  Numerical Optimal Control  Trajectory Optimization  Multiple Shooting  Quadrupedal Robots  Nonlinear Model Predictive Control  Differential Dynamic Programming 
Abstract: This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.


Title: Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks
Key Words: iterative methods  learning (artificial intelligence)  minimax techniques  mobile robots  neurocontrollers  nonlinear control systems  model mismatch  model uncertainties  high-risk scenarios  robustness capacity  minimax iterative dynamic game  robust policies  carefully designed deep neural network policy  policy robustness  adversarial disturbances  ocally robust optimal multistage policy  nonlinear robot control tasks  multistage decision policies  high-dimensional state spaces  complex control tasks  meta-learning-deep policies  Robustness  Heuristic algorithms  Trajectory  Games  Task analysis  Uncertainty  Approximation algorithms 
Abstract: Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.


Title: Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction
Key Words: biomechanics  control engineering computing  elastic constants  haptic interfaces  human-robot interaction  manipulator dynamics  vibrations  human intention based stiffness estimation  HRI device  frequency analysis  input response simulation  vibration magnitude  virtual wall collision  control distribution ratios  physical collaboration operations  human-robot interaction device  weighted hybrid admittance-impedance control  Impedance  Admittance  Force  Manipulators  Stability analysis  Mathematical model 
Abstract: In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.


Title: Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring
Key Words: end effectors  fault diagnosis  fault tolerant control  force control  industrial manipulators  robotic assembly  trajectory control  multimodal environment dynamics  interactive robots  environmental uncertainty  contact force  subtask completion  task monitoring approach  complex assembly tasks  discrete environment dynamic modes  semistructured environments  interactive tasks  impedance control  admittance controlled robots  force/position measurements  admittance controlled robot  gear assembly task  fault detection  force trajectories  position trajectories  end-effector physical compliance  Dynamics  Task analysis  Force  Robot sensing systems  Admittance  Estimation 
Abstract: Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.


Title: Estimating an Articulated Tool's Kinematics via Visuo-Tactile Based Robotic Interactive Manipulation
Key Words: dexterous manipulators  feedback  haptic interfaces  manipulator kinematics  mobile robots  motion control  robot vision  sensor fusion  tactile sensors  visuo-tactile based robotic interactive manipulation  autonomous robots  single passive observation  articulated toy  dual arm robotic setup  tactile finger  visuo-tactile servoing controller  flipping task  tactile feedback  compact control loop  kinematic parameters  vision feedback  articulated tools kinematics  data fusion method  fingertips motion trajectory  Tools  Robot kinematics  Kinematics  Task analysis  End effectors  Robot sensing systems 
Abstract: The usage of articulated tools for autonomous robots is still a challenging task. One of the difficulties is to automatically estimate the tool's kinematics model. This model cannot be obtained from a single passive observation, because some information, such as a rotation axis (hinge), can only be detected when the tool is being used. Inspired by a baby using its hands while playing with an articulated toy, we employ a dual arm robotic setup and propose an interactive manipulation strategy based on visual-tactile servoing to estimate the tool's kinematics model. In our proposed method, one hand is holding the tool's handle stably, and the other arm equipped with tactile finger flips the movable part of the articulated tool. An innovative visuo-tactile servoing controller is introduced to implement the flipping task by integrating the vision and tactile feedback in a compact control loop. In order to deal with the temporary invisibility of the movable part in camera, a data fusion method which integrates the visual measurement of the movable part and the fingertip's motion trajectory is used to optimally estimate the orientation of the tool's movable part. The important tool's kinematic parameters are estimated by geometric calculations while the movable part is flipped by the finger. We evaluate our method by flipping a pivoting cleaning head (flap) of a wiper and estimating the wiper's kinematic parameters. We demonstrate that the flap of the wiper is flipped robustly, even the flap is shortly invisible. The orientation of the flap is tracked well compared to the ground truth data. The kinematic parameters of the wiper are estimated correctly.


Title: Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels
Key Words: automobiles  collision avoidance  control system synthesis  feedback  mobile robots  motion control  robust control  input constraints  control input signals  admissible funnels  planning process  constrained motion  car-like robots  VFO control strategy  parallelized planning  car-like kinematics  mobile robotics  intelligent vehicles  feedback control algorithms  motion execution  VFO control law  state constraints  motion planning algorithms  robot actuation  open loop control signals  parallelized deterministic sampling-based algorithm  vector field orientation  steering dynamics  modeling uncertainties  Robots  Planning  Kinematics  Electron tubes  Vehicle dynamics  Uncertainty  Feedback control 
Abstract: Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.


Title: ASPiC: An Acting System Based on Skill Petri Net Composition
Key Words: path planning  Petri nets  robots  ASPiC  acting system  skill Petri net composition  high-level action  executable commands  autonomous robots  formal model  robot skills  control-flow Petri net model  autonomous surface vehicle  area protection mission  Petri nets  Robots  Analytical models  Adaptation models  Tools  Planning  Inductors 
Abstract: Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.


Title: Static Kinematics for an Antagonistically Actuated Robot Based on a Beam-Mechanics-Based Model
Key Words: manipulator kinematics  pneumatic actuators  static kinematics  beam-mechanics-based model  soft robotic structures  industrial revolution  soft robotics  traditional robots  rigid links  joints  soft robots  stiffness mechanism embodies  pneumatic air actuation  variable stiffness values  soft stiffness controllable robot  mathematical model  stiffness levels  soft robotic manipulator  interaction forces  analytical model  robotic actuation system  actuated robot  Manipulators  Tendons  Force  Soft robotics  Mathematical model  Service robots 
Abstract: Soft robotic structures might play a major role in the 4th industrial revolution. Researchers have successfully demonstrated advantages of soft robotics over traditional robots made of rigid links and joints in several application areas including manufacturing, healthcare and surgical interventions. However, soft robots have limited ability to exert higher forces when it comes to interaction with the environment, hence, change their stiffness on demand over a wide range. One stiffness mechanism embodies tendon-driven and pneumatic air actuation in an antagonistic way achieving variable stiffness values. In this paper, we apply a beam-mechanics-based model to this type of soft stiffness controllable robot. This mathematical model takes into account the various stiffness levels of the soft robotic manipulator as well as interaction forces with the environment at the tip of the manipulator. The analytical model is implemented into a robotic actuation system made of motorised linear rails with load cells (obtaining applied forces to the tendons) and a pressure regulator. Here, we present and analyse the performance and limitations of our model.


Title: A Novel Soft Elbow Exosuit to Supplement Bicep Lifting Capacity
Key Words: bending  biomechanics  electromyography  medical robotics  pneumatic actuators  torque  measurable assistance  bicep lifting capacity  supplemental lifting assistance  muscle activity  bicep muscle  repetitive lifting  pneumatically pressurized soft actuators  high force-to-weight ratio  analytical model  bending behavior  consecutive actuators  theoretical model  elbow joint torque value  surface electromyography sensors  active assistance  soft elbow exosuit  nylon fabrics  motion capture system  concentric contractions  isometric contractions  pressure 300.0 kPa  SN  Actuators  Elbow  Torque  Shape  Force  Injuries  Muscles 
Abstract: This paper investigates the design of a soft elbow exosuit capable of providing supplemental lifting assistance by reducing muscle activity of the bicep muscle. The aim is to improve the efficiency and endurance of workers who are tasked with repetitive lifting. The design consists of an array of pneumatically pressurized soft actuators, which are encased in nylon fabric that allows for a high force-to-weight ratio of 211.SN/g. An analytical model governing the bending behavior of two consecutive actuators and torque generated by the exosuit is developed, with test results showing less than 10% error from the theoretical model. An elbow joint torque value of 27.6N.m is achieved at 300kPa, which is comparable to the 30N.m maximum set by OSHA requirements in the USA. Further testing with a healthy participant is performed using surface electromyography (sEMG) sensors and a motion capture system to assess the capabilities of the exosuit to provide active assistance to the bicep during isometric and concentric contractions. Measurable assistance to lifting is observed with minimal obstruction to the user's range of motion for all experiments.


Title: Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration
Key Words: grippers  intelligent robots  learning (artificial intelligence)  mobile robots  pose estimation  robot vision  solid modelling  complex processing tasks  current robot learning policies  consistent learning policy  skilled operators  robotic automation  variable outcomes  tedious nature  laborious nature  human operators  food industries  ocean space  huge demand  mechanical structures  complex geometrical 3D shapes  high biological variation  deformable food raw materials  compliant food raw materials  robotic handling  complex 3D shapes  compliant food objects  inconsistent demonstrations  LfD learning policy  effective robot handling  gripper finger configuration  RGB-D images  food compliant objects  robotic grasping  robust learning policy  Grasping  Visualization  Service robots  Task analysis  Robot sensing systems  Three-dimensional displays  Compliant food objects  Learning from Demonstration  Robotic handling  Multifingered gripper 
Abstract: The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.


Title: Acoustic Sensing for Soft Pneumatic Actuators
Key Words: microphones  pneumatic actuators  sensors  microphone-based sensor solution  PneuFlex actuator  soft pneumatic actuators  acoustic sensing  contacted material  sensing method  sound signature  contact locations  contact force  Robot sensing systems  Microphones  Pneumatic actuators  Force 
Abstract: We propose a novel sensing method for soft pneumatic actuators. The method uses a single microphone, embedded into the actuator's air chamber. Contact with the environment induces sound (vibration) in the actuator. The materials and the shape of the actuator reflect, refract, and attenuate the sound as it propagates inside the actuator. This produces a unique sound signature for different types of events, enabling the sensing of contact locations, contact force, and the type of contacted material. Sensing is insensitive to the inflation state of the actuator and to background noise. We demonstrate the robustness and versatility of the microphone-based sensor solution in experiments with a PneuFlex actuator. The proposed sensorization avoids the fundamental challenges of sensorizing soft pneumatic actuators, because the placement of a microphone does not negatively affect the compliance of the actuator and because a single microphone suffices for sensorization of the entire actuator, eliminating the need for an application-specific sensor layout.


Title: Flexible Fabric Actuator Realizing 3D Movements Like Human Body Surface for Wearable Devices
Key Words: biomechanics  medical robotics  motion control  muscle  pneumatic actuators  wearable computers  wearable devices  continuous control system  human body surface  rubber swath  fabric actuator  3D movements  motions  McKibben artificial muscles  Muscles  Actuators  Fabrics  Rubber  Weaving  Regulators 
Abstract: A new flexible fabric actuator realizing three dimensional movements for wearable devices is proposed in this paper. Such actuators must be lightweight and highly flexible, producing movements with high degree of freedom to assist/follow human natural motions. Improving the structure and control system of a fabric actuator from the previous research, the flexible fabric actuator with continuous control is developed. This paper presents new configuration of thin artificial muscles on a flexible rubber swath, a continuous control system to control the fabric actuator smoothly, and control methods to realize six basic movements of human body (forward and backward bends, left and right bends, left and right twists)with less number of muscles. The experiment results indicate the possibility that the proposed fabric actuator woven thin McKibben artificial muscles is a viable technology for use in wearable devices.


Title: A Novel All-in-One Manufacturing Process for a Soft Sensor System and its Application to a Soft Sensing Glove
Key Words: biomechanics  data gloves  gallium alloys  manufacturing processes  sensors  virtual reality  wearable computers  manufacturing process  soft sensor system  soft sensing glove  attractive application  wearable devices  soft sensors  rigid sensing units  wearable sensor systems  assembly process  bulky electrode part  novel fabrication process  Fabrication  Robot sensing systems  Electrodes  Sensor systems  Writing  Wiring 
Abstract: A sensing glove is an attractive application of wearable devices. Soft sensors are emerging to replace rigid sensing units, especially for wearable sensor systems, due to its inherent softness, flexibility, and stretchability. However, the fabrication process for the soft sensors is usually complex, time-consuming, labor-intensive, and has low production rate. To integrate a sensor system, an assembly process is essential, which may make the system bulky. Moreover, a solution for the electrode parts has rarely been suggested, although a bulky electrode part may obstruct the user's movement and degrade performance of the sensor. Thus, in this study, a novel fabrication process is suggested based on direct ink writing (DIW) of eutectic gallium-indium (EGaIn), which forms all the items in the sensor system from the sensing units, wiring, and the electrode part. A sensing glove for 2D finger motions was fabricated, and its performance was verified in terms of linearity, dynamic response, and accuracy. The sensing glove can be used as an easily-wearable and an intuitive interface to the virtual reality environment.


Title: On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints
Key Words: humanoid robots  interpolation  path planning  polynomials  position control  splines (mathematics)  spline trajectories  time curves  quaternion coefficients  unitariness condition  quaternion representation  on-line update mechanism  anthropomorphic robot upper-body  real-time compatibility  constrained angular velocity  orientation planning algorithms  task space trajectory generation  robotics applications  continuous acceleration profiles  realtime implementation  Quaternions  Interpolation  Acceleration  Robots  Splines (mathematics)  Trajectory  Planning 
Abstract: This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.


Title: Coverage Path Planning with Adaptive Viewpoint Sampling to Construct 3D Models of Complex Structures for the Purpose of Inspection
Key Words: autonomous aerial vehicles  image sampling  mobile robots  path planning  robot vision  search problems  adaptive search space coverage path planner  unmanned aerial vehicle  coverage path planning  adaptive sampling  onboard sensors  reference model  accurate 3D models  complex structure  adaptive viewpoint sampling  Sensors  Adaptation models  Path planning  Solid modeling  Entropy  Clustering algorithms  Octrees 
Abstract: In this paper, we introduce a coverage path planning algorithm with adaptive viewpoint sampling to construct accurate 3D models of complex large structures using Unmanned Aerial Vehicle (UAV). The developed algorithm, Adaptive Search Space Coverage Path Planner (ASSCPP), utilizes an existing 3D reference model of the complex structure and the onboard sensors' noise models to generate paths that are evaluated based on the traveling distance and the quality of the model. The algorithm generates a set of viewpoints by performing adaptive sampling that directs the search towards areas with low accuracy and low coverage. The algorithm predicts the coverage percentage obtained by following the generated coverage path using the reference model. A set of experiments were conducted in real and simulated environments with structures of different complexities to test the validity of the proposed algorithm.


Title: Solving Markov Decision Processes with Reachability Characterization from Mean First Passage Times
Key Words: decision making  decision theory  iterative methods  Markov processes  reachability analysis  robots  Markov decision processes  reachability characterization  reachability landscape  MFPT-VI  MFPT-PI  mean first passage time based value iteration  mean first passage time based policy iteration  robotic decision-making  numerical evaluation  Convergence  Markov processes  Mathematical model  Approximation algorithms  Planning  Linear systems  Standards 
Abstract: A new mechanism for efficiently solving the Markov decision processes (MDPs) is proposed in this paper. We introduce the notion of reachability landscape where we use the Mean First Passage Time (MFPT) as a means to characterize the reachability of every state in the state space. We show that such reachability characterization very well assesses the importance of states and thus provides a natural basis for effectively prioritizing states and approximating policies. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based Policy Iteration (MFPT-PI) - that have been modified from the state-of-the-art solution methods. To validate our design, we have performed numerical evaluations in robotic decision-making scenarios, by comparing the proposed new methods with corresponding classic baseline mechanisms. The evaluation results showed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art solutions in terms of both practical runtime and number of iterations. Aside from the advantage of fast convergence, this new solution method is intuitively easy to understand and practically simple to implement.


Title: Hybrid Bio-Inspired Architecture for Walking Robots Through Central Pattern Generators Using Open Source FPGAs
Key Words: control engineering computing  data acquisition  field programmable gate arrays  gait analysis  legged locomotion  microprocessor chips  public domain software  hybrid bio-inspired architecture  central pattern generators  robotic control approach  animal nervous system control  CNS-PNS  high level control  low level control  open source tools  binomial brain-peripheral nervous system  open source FPGA  digital circuits  microprocessors  Field programmable gate arrays  Level control  Legged locomotion  Microprocessors  Robot sensing systems 
Abstract: In this paper we present a new robotic control approach inspired in the animal nervous system control. The system implements the binomial Brain-Peripheral Nervous System (CNS-PNS) combining the use of microprocessors as the high level control, or brain, and FPGAs as the low level control, or nervous system. Thanks to the new open source tools for FPGAs, we are able to apply them in the field of robotics in new ways that were impossible before. In this paper, we will demonstrate that our approach is not only able to control the movements of robots using digital circuits built inside an FPGA, but is also capable of generating, synthesizing and uploading them inside the FPGA in real time and on demand.


Title: Towards an Autonomous Robotic Dragonfly: At-Scale Lift Experiments Modeling Dragonfly Forewings
Key Words: aerodynamics  aerospace components  aerospace robotics  bending  carbon fibres  design engineering  mobile robots  piezoelectric actuators  polymer films  robot kinematics  sensors  hindwing pair  Sympetrum san-guineum  flapping kinematics  carbon-fiber support structure  polyester film  polymide-film joints  piezoelectric bending-beam actuator  lift sensor  Sympetrum sanguineum  autonomous robotic dragonfly  artificial dragonfly forewings  Insects  Aerodynamics  Actuators  Resonant frequency  Frequency measurement  Carbon  Power supplies 
Abstract: We report on lift experiments conducted at scale for an artificial platform mimicking the dragonfly species: Sympetrum sanguineum. The platform, as well as the lift sensor, was custom designed and built. The flapping mechanism consisted of a piezoelectric bending-beam actuator, transmission using carbon-fiber elements and polymide-film joints, and wings constructed of polyester film with carbon-fiber support structure. The flapping kinematics of the Sympetrum san-guineum was replicated as closely as possible although only a pair of forewings were used in these experiments. The lift generated, when accounting for the addition of a pair of hindwings, is sufficient to allow for the hovering of a real-life dragonfly. The results, the first at-scale fully transient measurements of artificial dragonfly forewings, show that the lift curves quantitatively as well as qualitatively validate existing 2D and 3D computer simulations of dragonfly forewings.


Title: Ultrasonic and Electrostatic Self-Cleaning Microstructured Adhesives for Robotic Grippers
Key Words: adhesion  adhesives  cleaning  dust  electrostatics  glass  grippers  industrial robots  mobile robots  ultrasonic cleaning  perching robots  electrostatic cleaning  electrostatic repulsion  climbing robots  ultrasonic cleaning  noncontact cleaning method  robotic gripper  contaminated directional gecko-like adhesive  Cleaning  Electrostatics  Surface contamination  Grippers  Electrodes  Substrates  Rough surfaces 
Abstract: This paper introduces electrostatic and ultrasonic techniques to clean dust and other contaminants from the surface of a gecko-like, microstrutured adhesive. The result is a non-destructive, non-contact cleaning method that will afford robotic grippers, climbing robots, and perching robots the ability to operate in real-world environments. Experimental results show that the cleaning efficiency for three different sizes of glass beads, 53-75 μm, 75-90 μm, and 90-106 μm, ranges between 75-99% when using a combination of electrostatic and ultrasonic cleaning. This is a far higher efficiency than when using electrostatic repulsion alone. Experiments also demonstrate an approximately 33% recovery in shear stress on a flat glass for a contaminated directional gecko-like adhesive after contact with a dusty table when electrostatic/ultrasonic cleaning was used. Finally, by applying this method on a robotic gripper, we observed an 18% recovery in normal adhesion on a flat glass substrate.


Title: Evolving a Sensory-Motor Interconnection for Dynamic Quadruped Robot Locomotion Behavior
Key Words: legged locomotion  optimisation  robot dynamics  trees (mathematics)  dynamic quadruped robot locomotion  sensory-motor coordination model  sensory neurons  neural oscillator  bacterial programming  sensory-motor interconnection structure  tree structure optimization  gene transfer process  bacterial mutation  Neurons  Legged locomotion  Robot sensing systems  Microorganisms  Robot kinematics  Optimization 
Abstract: In this paper, we present a novel biologically inspired evolving neural oscillator for quadruped robot locomotion to minimize constraints during the locomotion process. The proposed sensory-motor coordination model is formed by the interconnection between motor and sensory neurons. The model utilizes Bacterial Programming to reconstruct the number of joints and neurons in each joint based on environmental conditions. Bacterial Programming is inspired by the evolutionary process of bacteria that includes bacterial mutation and gene transfer process. In this system, either the number of joints, the number of neurons, or the interconnection structure are changing dynamically depending on the sensory information from sensors equipped on the robot. The proposed model is simulated in computer for realizing the optimization process and the optimized structure is then applied to a real quadruped robot for locomotion process. The optimizing process is based on tree structure optimization to simplify the sensory-motor interconnection structure. The proposed model was validated by series of real robot experiments in different environmental conditions.


Title: Learning-based Path Tracking Control of a Flapping-wing Micro Air Vehicle
Key Words: aerodynamics  aerospace simulation  autonomous aerial vehicles  learning (artificial intelligence)  mobile robots  neurocontrollers  predictive control  vehicle dynamics  autonomous flight  neural network  MPC  Reynolds number  model predictive control  model-based control strategy  FWMAV  flapping-wing microair vehicle  path tracking control  Batteries  Training  Neural networks  Dynamics  Data models  Trajectory  Vehicle dynamics 
Abstract: Flapping-wing micro air vehicles (FWMAVs) become promising research platforms due to their advantages such as various maneuverability, and concealment. However, unsteady flow at low Reynolds number around the wings makes their dynamics time-varying and highly non-linear. It makes autonomous flight of FWMAV as a big challenge. In this paper, we suggest a model-based control strategy for FWMAV using learning architecture. For this task, we construct a ground station for logging flight data and control inputs, and train dynamics with a neural network. Then, we apply model predictive control (MPC) to the trained model. We validate our method by hardware experiments.


Title: Improving the Parallel Execution of Behavior Trees
Key Words: computer games  control system synthesis  finite state machines  mobile robots  trees (mathematics)  control architectures  concurrent programming  CBTs  autonomous agents  computer game  robotics industry  finite state machines  parallel execution  concurrent BTs  parallel operator  behavior trees  Task analysis  Robots  Synchronization  Games  Programming  Monitoring  Concurrent computing 
Abstract: Behavior Trees (BTs) have become a popular framework for designing controllers of autonomous agents in the computer game and in the robotics industry. One of the key advantages of BTs lies in their modularity, where independent modules can be composed to create more complex ones. In the classical formulation of BTs, modules can be composed using one of the three operators: Sequence, Fallback, and Parallel. The Parallel operator is rarely used despite its strong potential against other control architectures such as Finite State Machines. This is due to the fact that concurrent actions may lead to unexpected problems similar to the ones experienced in concurrent programming. In this paper, we outline how to tackle the aforementioned problem by introducing Concurrent BTs (CBTs) as a generalization of BTs in which we include the notions of progress and resource usage. We show how CBTs allow safe concurrent executions of actions and we analyze the approach from a mathematical standpoint. To illustrate the use of CBTs, we provide a set of use cases in realistic robotics scenarios.


Title: Guess What I Attend: Interface-Free Object Selection Using Brain Signals
Key Words: human-robot interaction  learning (artificial intelligence)  mobile robots  object detection  signal detection  user training  event-related potentials  interface-free object selection  brain signals  brain activity  user goals  intuitive communication  human-robot cooperation scenarios  natural brain responses  target object detection  object selection  information geometry  Electroencephalography  Covariance matrices  Task analysis  Information geometry  Switches  Mobile robots 
Abstract: Interpreting the brain activity to identify user goals or to ground a robot's hypotheses about them is a promising direction for non-intrusive and intuitive communication. Such a capability can be of particular relevance in the context of human-robot cooperation scenarios. This paper proposes a novel approach to utilize the natural brain responses to highlighted objects in the scene for object selection. By this, it circumvents the need for additional interfaces or user training. Our approach uses methods from information geometry to classify the target/non-target response of these event-related potentials. Online experiments carried out with a real robot demonstrate an accurate detection of target objects solely based on the user's attention.


Title: Mobile Continuum Robot with Unlimited Extensible Sections
Key Words: bending  buckling  DC motors  force control  gears  mobile robots  motion control  pulleys  typical continuum robots  restricted section length  locomotion  mobile continuum robot design  virtually unlimited extensible sections  driving unit  gear  long flexible tube  traveling distance  multiple driving units  DC motors  crawling locomotion performance  3D printer  helical groove  tendon-driven robots  Electron tubes  DC motors  Gears  Trajectory  Springs  End effectors 
Abstract: Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.


Title: Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World
Key Words: control engineering computing  convolutional neural nets  humanoid robots  learning (artificial intelligence)  manipulators  robot vision  selective dual-arm grasping  pruning grasping points  robot experience  robot grasping  dual-arm robots  humanoid robots  dual-arm manipulation  single-arm limitation  multistage learning method  self-supervised approach  convolutional neural networks  CNN  semantic segmentation  automatic annotation  Grasping  Semantics  Image segmentation  Manipulators  Task analysis  Learning systems 
Abstract: Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.


Title: Bimanual Assembly of Two Parts with Relative Motion Generation and Task Related Optimization
Key Words: collision avoidance  end effectors  motion control  optimisation  robotic assembly  end-effector frame  stack-of- tasks hierarchical solver  collision avoidance  optimization  relative motion generation  bimanual assembly  YuMi bimanual robot  task priority strategy  Task analysis  Collision avoidance  End effectors  Ellipsoids  Robot kinematics 
Abstract: Bimanual assembly of two parts require that a relative target pose is reached prior to the joining operation. Rather than utilizing one arm as a fixture for holding one of the parts while the other performs the assembly, motion generation in the relative end-effector frame is proposed that involves both arms. The proposed approach considers bimanual motion in a dynamic and uncertain environment addressing avoidance of collision with obstacles as well as the robot itself and the environment. Moreover, configurations that optimize the motion and force capabilities for the sucessful and efficient completion of the task are taken into account. A task priority strategy is adopted achieving online performance. Experimental results on the YuMi bimanual robot using the Stack-Of- Tasks hierarchical solver validate the performance of the proposed approach in a folding assembly task.


Title: Dual-Arm Coordinated Motion Planning and Compliance Control for Capturing Moving Objects with Large Momentum
Key Words: compliance control  force control  Jacobian matrices  manipulators  motion control  optimal control  path planning  trajectory control  dual-arm coordinated motion planning  dual-arm robot  operational force control  dual-arm capturing motion  object tracking  compliance control  null-space projected relative Jacobian  collocation trajectory optimization  Planning  Force  Robot kinematics  Jacobian matrices  Trajectory  Tracking 
Abstract: Capturing a moving object with large momentum by a dual-arm robot is especially challenging because of the requirement of dual-arm coordinated motion planning for tracking the moving object, and the operational force control for contact and momentum transfer. In this paper, we present a dual-arm coordinated motion planning and compliance control method with a unique null-space projected relative Jacobian and relative operational force between the two arms. The proposed method is able to plan dual-arm capturing motion and control the capturing force without disturbing the tracking motion. We have also adopted a direct collocation trajectory optimization method to generate optimal trajectory to decrease the object's momentum with minimum effort. Simulation and experiment of dual-arm robots picking up a moving box on a mobile platform are carried out to verify the proposed method.


Title: A Model Predictive Control Approach for Vision-Based Object Grasping via Mobile Manipulator
Key Words: collision avoidance  dexterous manipulators  end effectors  grippers  image colour analysis  image sensors  mobile robots  motion control  nonlinear control systems  path planning  predictive control  robot vision  reach-to-grasp motion  optimal grasping regions  vision-based object grasping  motion control architecture  mobile manipulator system  partial point cloud  onboard RGB-D sensor system  KUKA Youbot  static obstacles  reach-to-grasp scenarios  model predictive control approach  nonlinear model predictive control scheme  Grasping  Three-dimensional displays  Manipulators  Grippers  Robot sensing systems  Predictive control 
Abstract: This paper presents the design of a vision-based object grasping and motion control architecture for a mobile manipulator system. The optimal grasping areas of the object are estimated using the partial point cloud acquired from an onboard RGB-D sensor system. The reach-to-grasp motion of the mobile manipulator is handled via a Nonlinear Model Predictive Control scheme. The controller is formulated accordingly in order to allow the system to operate in a constrained workspace with static obstacles. The goal of the proposed scheme is to guide the robot's end-effector towards the optimal grasping regions with guaranteed input and state constraints such as occlusion and obstacle avoidance, workspace boundaries and field of view constraints. The performance of the proposed strategy is experimentally verified using an 8 Degrees of Freedom KUKA Youbot in different reach-to-grasp scenarios.


Title: A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
Key Words: Bayes methods  image fusion  image sensors  Kalman filters  mobile robots  nonlinear filters  object detection  probability  remotely operated vehicles  robot vision  mobile robot  multistage Bayesian approaches  multistage localization approach  global coordinate frame  multistage target observation approach  target engagement  multiple sensors  Bayesian framework  simultaneous robot localization  sensors on-board  target detection  associated detection probability  extended Kalman filter  unmanned ground vehicle  Robot kinematics  Robot sensing systems  Bayes methods  Mobile robots  Uncertainty 
Abstract: This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.


Title: Coupling Mobile Base and End-Effector Motion in Task Space
Key Words: approximation theory  collision avoidance  end effectors  manipulator dynamics  manipulator kinematics  mobile robots  couple robot base  kinematic constraints  mobile manipulators  model-based dynamic systems  in-depth knowledge  motion planning  task space  end-effector motion  coupling mobile base  kinematically feasible trajectories  robots kinematic design  arbitrary dynamical systems  End effectors  Trajectory  Task analysis  Grippers  Dynamics  Planning 
Abstract: Dynamic systems are a practical alternative to motion planning in executing robot actions. They are of particular interest in Learning from Demonstration, as here we aim to carry out actions in a certain fashion, without a model or in-depth knowledge about the world, which might be difficult to achieve with a planner. Using model-based dynamic systems in task space enables robots to flexibly reproduce demonstrated actions. Nevertheless, when dealing with mobile manipulators, we face the challenge of including the kinematic constraints of the robot in the action models. In this paper we propose to couple robot base and end-effector motions generated by arbitrary dynamical systems modulating the base velocity, while respecting the robots kinematic design. To this end we learn an approximation of the inverse reachability in closed form. In real-world robot experiments we demonstrate that we are able to maintain kinematically feasible trajectories in the presence of obstacles and in configurations differing profoundly from the training scene.


Title: Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot
Key Words: collision avoidance  hospitals  manipulator dynamics  medical robotics  mobile robots  predictive control  probability  PAM robot  probabilistic method  2-wheel walker  autonomous learning  fall prevention  maneuvers mobility aids  patient assistant mobile robot  dynamic model learning  collision-free manipulation  4-legged walker  hybrid MPC-based manipulation planning algorithm  one-wheel point-mass model  hybrid control system  motion interactions  minimal force  approximate dynamic model  Legged locomotion  Dynamics  Planning  Manipulator dynamics  Grippers 
Abstract: One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.


Title: Capacitive Proximity Sensor Skin for Contactless Material Detection
Key Words: capacitance measurement  capacitive sensors  distance measurement  electric impedance measurement  frequency measurement  signal processing  time-of-flight sensors  capacitance based sensor system  characteristic impedance spectrum measurement  absolute distance based capacitance measurement capabilities  ToF sensors  human-machine-interaction  signal processing  frequency based capacitance measurement capabilities  distance sensing methods  capacitive proximity sensing skins  contactless material detection  Robot sensing systems  Impedance  Frequency measurement  Electrodes  Current measurement  Impedance measurement 
Abstract: In this paper, we present a method for contactless material detection with capacitive proximity sensing skins. Our new approach extends the current state-of-the-art proximity and distance sensing methods and measures the characteristic impedance spectrum of an object to obtain material properties. By this, we gain further material information besides of the near field information in a contactless and non-destructive way. The measurement method requires sensors that provide absolute distance and frequency based capacitance measurement capabilities and can be applied to similar systems. The sensor system described in this paper measures proximity with a capacitance based sensor and absolute distance based on time-of-flight (ToF)sensors. Attached on a robot, we gain information about the robot's near field environment. The information is important not only for human- machine- interaction, but also for grasping and manipulation. We focus on signal processing and evaluate our method with measurements of numerous different materials and present a solution to differentiate between them.


Title: Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality
Key Words: convolutional neural nets  grippers  learning (artificial intelligence)  mobile robots  pose estimation  virtual reality  teaching  gripper  domain randomization approach  depth imaging  3D occupancy grid  robot imitation learning  deep 3D convolutional neural network  virtual robot  grasp real fish  virtual reality  human supervisor  Robots  Task analysis  Three-dimensional displays  Grippers  Grasping  Cameras  Virtual reality 
Abstract: We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.


Title: Efficient Pose Estimation from Single RGB-D Image via Hough Forest with Auto-Context
Key Words: feature extraction  image classification  image colour analysis  learning (artificial intelligence)  object detection  pose estimation  probability  regression analysis  6D pose  public datasets  high efficient learning approach  robotic grasps  cascaded Hough forests  pose distribution  classification framework  joint regression  Hough space  object class probability  random forest  cluttered environment  textured texture-less  auto-context  single RGB-D image  efficient pose estimation  Training  Forestry  Vegetation  Three-dimensional displays  Reservoirs  Pose estimation  Covariance matrices 
Abstract: We propose a high efficient learning approach to estimating 6D (Degree of Freedom) pose of the textured or texture-less objects for grasping purposes in a cluttered environment where the objects might be partially occluded. The method comprises three main steps. Given a single RGB-D image, we first deploy appropriate features and the random forest to deduce the object class probability and cast votes for the 6D pose in Hough space by joint regression and classification framework, adopting reservoir sampling and summarizing the pose distribution by clustering. Next, we integrate the auto-context into cascaded Hough forests to improve the efficiency of learning. Extensive experiments on various public datasets and robotic grasps indicate that our method presents some improvements over the state-of-art and reveals the capability for estimating poses in practical applications efficiently.


Title: Plenoptic Monte Carlo Object Localization for Robot Grasping Under Layered Translucency
Key Words: approximation theory  cameras  Gaussian distribution  image colour analysis  manipulators  Monte Carlo methods  robot vision  stained glass panels  object poses  Monte Carlo object localization algorithm  localizing objects  manipulating objects  translucent materials  Lytro first generation light field camera  robot grasping  layered translucency  human environments  robot perception  open challenges  transparent objects  drinking glasses  refractive media  partial occlusions  Michigan progress fetch robot  plenoptic Monte Carlo object localization  depth likelihood volume  PMCL  Three-dimensional displays  Cameras  Glass  Monte Carlo methods  Pose estimation  Robot sensing systems 
Abstract: In order to fully function in human environments, robot perception needs to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL)as a method for localizing object poses in the presence of translucency using plenoptic (light-field)observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.


Title: Pose Estimation for Objects with Rotational Symmetry
Key Words: CAD  inference mechanisms  learning (artificial intelligence)  neural nets  pose estimation  solid modelling  neural network  test time  symmetry-labeled objects  unlabeled CAD models  pose estimation  widely explored problem  poses  training time  3D CAD models  rotational symmetry  Solid modeling  Three-dimensional displays  Pose estimation  Training  Shape  Neural networks  Computational modeling 
Abstract: Pose estimation is a widely explored problem, enabling many robotic tasks such as grasping and manipulation. In this paper, we tackle the problem of pose estimation for objects that exhibit rotational symmetry, which are common in man-made and industrial environments. In particular, our aim is to infer poses for objects not seen at training time, but for which their 3D CAD models are available at test time. Previous work has tackled this problem by learning to compare captured views of real objects with the rendered views of their 3D CAD models, by embedding them in a joint latent space using neural networks. We show that sidestepping the issue of symmetry in this scenario during training leads to poor performance at test time. We propose a model that reasons about rotational symmetry during training by having access to only a small set of symmetry-labeled objects, whereby exploiting a large collection of unlabeled CAD models. We demonstrate that our approach significantly outperforms a naively trained neural network on a new pose dataset containing images of tools and hardware.


Title: Fully Convolutional Grasp Detection Network with Oriented Anchor Box
Key Words: feature extraction  feedforward neural nets  grippers  human-robot interaction  image classification  image colour analysis  image matching  inference mechanisms  learning (artificial intelligence)  object detection  object recognition  regression analysis  robot vision  parallel-plate robotic gripper  RGB images  oriented anchor box mechanism  matching strategy  end-to-end fully convolutional neural network  feature extractor  deep convolutional neural network  multigrasp predictor regresses  predefined oriented rectangles  anchor boxes  standard Cornell Grasp Dataset  image-wise split  object-wise split  latest state-of-the-art approach  grasping poses  convolutional grasp detection network  Feature extraction  Robots  Computational modeling  Grippers  Solid modeling  Computer architecture  Predictive models 
Abstract: In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.


Title: A Probabilistic Approach to Benchmarking and Performance Evaluation of Robot Systems
Key Words: path planning  probability  robots  performance degradation  probabilistic approach  performance evaluation  robot system  human-robot interaction  task planning  robotics  benchmarking evaluation  performance assessment problem  Task analysis  Robots  Benchmark testing  Reliability  Measurement  Approximation algorithms  Probabilistic logic 
Abstract: Problem benchmarks are used in experimental science as a reference against which results of experiments using distinct approaches to solve the problem are compared and evaluated in relative terms. In Robotics, just formulating a general performance assessment problem is difficult per se, as robot systems are composed of very diverse subsystems (e.g., localisation, human-robot interaction, task planning, motion planning). This paper introduces a probabilistic approach to benchmarking and evaluating performance of robot systems, which uses probability theory as the common language to quantify the performance of distinct functionalities of a robot system and their impact on the performance of a task carried out by that system. The approach can be used to analyse the performance of a task plan from the performances if its composing functionalities, or to (re)plan when a performance degradation in functionality is predicted to cause performance degradation of the task plan beyond acceptable limits.


Title: Improving Repeatability of Experiments by Automatic Evaluation of SLAM Algorithms
Key Words: robot vision  SLAM (robots)  SLAM algorithms  robotics  repeatability  Simultaneous Localization And Mapping  Simultaneous localization and mapping  Buildings  Measurement  Data models  Lasers 
Abstract: The development of good experimental methodologies for robotics takes often inspiration from general principles of experimental practice. Repeatability prescribes that experiments should involve several trials in order to guarantee that results are not achieved by chance, but are systematic, and statistically significant trends can be identified. In this paper, we propose an approach to improve the repeatability of experiments performed in robotics. In particular, we focus on the domain of SLAM (Simultaneous Localization And Mapping) and we introduce a system that exploits simulations to generate a large number of test data on which SLAM algorithms are automatically evaluated in order to obtain consistent results, according to the principle of repeatability.


Title: A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry
Key Words: distance measurement  mobile robots  path planning  pose estimation  robot vision  quantitative trajectory evaluation  trajectory alignment  specific sensing modality  error metrics  absolute trajectory error  relative error  visual odometry  Trajectory  Cameras  Noise measurement  Tutorials  Sensors  Visualization 
Abstract: In this tutorial, we provide principled methods to quantitatively evaluate the quality of an estimated trajectory from visual(-inertial) odometry (VO/VIO), which is the foundation of benchmarking the accuracy of different algorithms. First, we show how to determine the transformation type to use in trajectory alignment based on the specific sensing modality (i.e., monocular, stereo and visual-inertial). Second, we describe commonly used error metrics (i.e., the absolute trajectory error and the relative error) and their strengths and weaknesses. To make the methodology presented for VO/VIO applicable to other setups, we also generalize our formulation to any given sensing modality. To facilitate the reproducibility of related research, we publicly release our implementation of the methods described in this tutorial.


Title: Long-Duration Autonomy for Small Rotorcraft UAS Including Recharging
Key Words: autonomous aerial vehicles  helicopters  mobile robots  surveillance  autonomous small rotorcraft  autonomous operation  UAS  recharging station  vision-based precision landing  human operators  mission execution  emergency response  unmanned aerial vehicle surveillance  Global Positioning System  Batteries  Magnetometers  Sensors  Monitoring  Three-dimensional displays  State estimation 
Abstract: Many unmanned aerial vehicle surveillance and monitoring applications require observations at precise locations over long periods of time, ideally days or weeks at a time (e.g. ecosystem monitoring), which has been impractical due to limited endurance and the requirement of humans in the loop for operation. To overcome these limitations, we propose a fully autonomous small rotorcraft UAS that is capable of performing repeated sorties for long-term observation missions without any human intervention. We address two key technologies that are critical for such a system: full platform autonomy including emergency response to enable mission execution independently from human operators, and the ability of vision-based precision landing on a recharging station for automated energy replenishment. Experimental results of up to 11 hours of fully autonomous operation in indoor and outdoor environments illustrate the capability of our system.


Title: Real-Time Feature Depth Estimation for Image-Based Visual ServOing
Key Words: cameras  feature selection  nonlinear control systems  observability  observers  reduced order systems  robot vision  stability  visual servoing  nonlinear reduced-order observer structure  global asymptotic convergence property  restrictive observability condition  depth observer  camera calibration error  image-based visual servoing schemes  interaction matrix  real-time feature depth estimation  Observers  Cameras  Convergence  Visual servoing  Acceleration 
Abstract: Without the 3-D geometry of the target and robust to camera calibration error, image-based visual servoing schemes have gained a lot of attention. However, the depth of the selected feature, which is involved in the interaction matrix relating the time variation of the feature to the velocity twist of the camera, must be estimated correctly to guarantee the stability of the controller. To this end, this paper proposes a new nonlinear reduced-order observer structure to recover the feature depth in real time. Compared with the existing works, the proposed observer has a global asymptotic convergence property and fast convergence rate, and the convergence rate can be easily adjusted only using a single gain parameter. In addition, the proposed observer has a less restrictive observability condition and stronger robustness to noisy measurements. Extensive comparative numerical simulations are carried out to validate the effectiveness of the proposed depth observer.


Title: Fast Convergence for Object Detection by Learning how to Combine Error Functions
Key Words: image segmentation  learning (artificial intelligence)  mobile robots  multi-robot systems  neural nets  object detection  union metric  estimated pickup rate  convergence time  optimally weighted Euclidean distance loss  object detection network  robotic pickup operation  approximate measure  detecting objects  fully convolutional segmentation network  RoboCup@Work challenge environment  on-line trained auxiliary network  dependent loss metrics  Converge-fast-auxnet  object detection neural networks  convergence speed  error functions  fast convergence  Object detection  Training  Convergence  Task analysis  Mathematical model  Euclidean distance 
Abstract: In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.


Title: Towards Real-Time Physical Human-Robot Interaction Using Skeleton Information and Hand Gestures
Key Words: cameras  feature extraction  feedforward neural nets  gesture recognition  human-robot interaction  robot vision  l physical human-robot interaction  dynamic gestures  human-robot interaction scenarios  intelligent human intention detection  hand gesture recognition  hand images  3D skeletal joint coordinates  state-of-the-art 2D skeleton extraction library  time-of-flight depth camera  meaningful gesture  reliable 3D skeleton extraction  human operator  skeleton information  towards real-time physical human-robot interaction  Robot sensing systems  Skeleton  Robot kinematics  Gesture recognition  Human-robot interaction  Three-dimensional displays 
Abstract: For successful physical human-robot interaction, the capability of a robot to understand its environment is imperative. More importantly, the robot should extract from the human operator as much information as possible. A reliable 3D skeleton extraction is essential for a robot to predict the intentions of the operator while s/he moves toward the robot or performs a meaningful gesture. For this purpose, we have integrated a time-of-flight depth camera with a state-of-the-art 2D skeleton extraction library namely Openpose, to obtain 3D skeletal joint coordinates reliably. We have also developed a robust and rotation invariant (in the coronal plane)hand gesture detector using a convolutional neural network. At run time (after having been trained)the detector does not require any pre-processing of the hand images. A complete pipeline for skeleton extraction and hand gesture recognition is developed and employed for real-time physical human-robot interaction, demonstrating the promising capability of the designed framework. This work establishes a firm basis and will be extended for the development of intelligent human intention detection in physical human-robot interaction scenarios, to efficiently recognize a variety of static as well as dynamic gestures.


Title: Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding
Key Words: computer vision  edge detection  feature extraction  image recognition  image representation  image segmentation  stereo image processing  robotic welding  weld seams  point cloud  welding paths  Harris 3D  unorganized point clouds  edge detection method  local neighborhood  adaptive density  corner detector  clusters curvature vectors  RGB-D semantic segmentation  3D washer models  recall scores  automatic weld seam detection  Three-dimensional displays  Image edge detection  Welding  Feature extraction  Corner detection  Clustering algorithms  Detectors 
Abstract: In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds. Our edge detection method evaluates symmetry in a local neighborhood and uses an adaptive density based threshold to differentiate 3D edge points. We extend this algorithm to propose a novel corner detector that clusters curvature vectors and uses their geometrical statistics to classify a point as corner. We perform rigorous evaluation of the algorithms on RGB-D semantic segmentation and 3D washer models from the ShapeNet dataset and report higher precision and recall scores. Finally, we also demonstrate how our edge and corner detectors can be used as a novel approach towards automatic weld seam detection for robotic welding. We propose to generate weld seams directly from a point cloud as opposed to using 3D models for offline planning of welding paths. For this application, we show a comparison between Harris 3D and our proposed approach on a panel workpiece.


Title: Fast Trajectory Planning for Automated Vehicles Using Gradient-Based Nonlinear Model Predictive Control
Key Words: gradient methods  mobile robots  nonlinear control systems  optimisation  path planning  predictive control  road vehicles  automated vehicles  motion trajectory planning  dynamically changing environment  nonlinear system dynamics  automated driving  nonlinear system model  optimization algorithms  gradient-based nonlinear model predictive control  standard PC  Mathematical model  Planning  Vehicle dynamics  Trajectory  Optimization  Task analysis  Heuristic algorithms 
Abstract: Motion trajectory planning is one crucial aspect for automated vehicles, as it governs the own future behavior in a dynamically changing environment. A good utilization of a vehicle's characteristics requires the consideration of the nonlinear system dynamics within the optimization problem to be solved. In particular, real-time feasibility is essential for automated driving, in order to account for the fast changing surrounding, e.g. for moving objects. The key contributions of this paper are the presentation of a fast optimization algorithm for trajectory planning including the nonlinear system model. Further, a new concurrent operation scheme for two optimization algorithms is derived and investigated. The proposed algorithm operates in the submillisecond range on a standard PC. As an exemplary scenario, the task of driving along a challenging reference course is demonstrated.


Title: Humanoid Navigation Planning in Large Unstructured Environments Using Traversability - Based Segmentation
Key Words: collision avoidance  humanoid robots  image segmentation  learning (artificial intelligence)  legged locomotion  motion control  planning (artificial intelligence)  robot kinematics  humanoid navigation planning  unstructured environments  disaster response efforts  navigation planners  considering palm contacts  impractical planning times  library-based method  easy-to-traverse part  discrete planners  easily-traversable segments  discrete-search planner  motion plans  standard discrete planning  navigation planning problems  traversability -based segmentation  Planning  Motion segmentation  Torso  Navigation  Humanoid robots  Foot 
Abstract: Humanoids' abilities to navigate stairs and uneven terrain make them well-suited for disaster response efforts. However, humanoid navigation in such environments is currently limited by the capabilities of navigation planners. Such planners typically consider only footstep locations, but planning with palm contacts may be necessary to cross a gap, avoid an obstacle, or maintain balance. However, considering palm contacts greatly increases the branching factor of the search, leading to impractical planning times for large environments. In previous work we explored using library-based methods to address difficult navigation planning problems requiring palm contacts, but such methods are not efficient when navigating an easy-to-traverse part of the environment. To maximize planning efficiency, we would like to use discrete planners when an area is easy to traverse and switch to the library-based method only when traversal becomes difficult. Thus, in this paper we present a method that 1) Plans a guiding torso path which accounts for the difficulty of traversing the environment as predicted by learned regressors; and 2) Decomposes the guiding path into a set of segments, each of which is assigned a motion mode (i.e. a set of feet and hands to use) and a planning method. Easily-traversable segments are assigned a discrete-search planner, while other segments are assigned a library-based method that fits existing motion plans to the environment near the given segment. Our results suggest that this segmentation approach greatly outperforms standard discrete planning and that using the library-based method for more difficult segments gives a benefit over using discrete planning.


Title: Guaranteed Coverage with a Blind Unreliable Robot
Key Words: graph theory  mobile robots  path planning  guaranteed coverage  blind unreliable robot  coverage planning  simple mobile robot  heuristic algorithm  specially-constructed graph  Robot sensing systems  Robot kinematics  Planning  Navigation  Computational modeling 
Abstract: We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach.


Title: Single Leg Dynamic Motion Planning with Mixed-Integer Convex Optimization
Key Words: actuators  approximation theory  convex programming  integer programming  Jacobian matrices  legged locomotion  path planning  quadratic programming  robot dynamics  trigonometrical terms  Jacobian matrix  optimization problem  mixed-integer quadratically-constrained program  convex outer approximation  torque ellipsoid  semidefinite program  bilinear terms  McCormick envelope convex relaxation  actuator torque  leg dynamic motion planning  MIQCP  SDP  mixed-integer convex programming  Torque  Dynamics  Planning  Legged locomotion  Ellipsoids  Trajectory 
Abstract: This paper proposes a mixed-integer convex programming formulation for dynamic motion planning. Many dynamic constraints such as the actuator torque constraint are nonlinear and non-convex due to the trigonometrical terms from the Jacobian matrix. This often causes the optimization problem to converge to local optima or even infeasible set. In this paper, we convexify the torque constraint by formulating a mixed-integer quadratically-constrained program (MIQCP). More specifically, the workspace is discretized into a union of disjoint polytopes and torque constraint is enforced upon a convex outer approximation of the torque ellipsoid, obtained by solving a semidefinite program (SDP). Bilinear terms are approximated by McCormick envelope convex relaxation. The proposed MIQCP framework could be solved efficiently to global optimum and the generated trajectories could exploit the rich features of the rough terrain without any initial guess from the designer. The demonstrated experiment results prove that this approach is currently capable of planning consecutive jumps that navigates a single-legged robot through challenging terrains.


Title: Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty
Key Words: mobile robots  path planning  flow-aware tralatory planning  motion pattern uncertainty  flow-aware trajectory  dynamic environments  flow model uncertainty  flow-aware planning  statistical model  map flow patterns  biasing functions  RRT* planning algorithm  CLiFF-map model  flow-compliant trajectories  flow motion patterns  Trajectory  Robots  Planning  Cost function  Uncertainty  Vehicle dynamics  Aerospace electronics 
Abstract: In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.


Title: Efficient and Asymptotically Optimal Kinodynamic Motion Planning via Dominance-Informed Regions
Key Words: mobile robots  optimal control  path planning  robot dynamics  sampling methods  search problems  trees (mathematics)  dominance-informed regions  high quality path  search-based methods  sampling-based methods  DIRT  dominance-informed region tree  spatial exploration  robot dynamics  collision checking  informed search principles  asymptotically optimal kinodynamic motion planner  physics-based simulation  successful successor state  Task analysis  Trajectory  Planning  Aerospace electronics  Robots  Dynamics  Cost function 
Abstract: Motion planners have been recently developed that provide path quality guarantees for robots with dynamics. This work aims to improve upon their efficiency, while maintaining their properties. Inspired by informed search principles, one objective is to use heuristics. Nevertheless, comprehensive and fast spatial exploration of the state space is still important in robotics. For this reason, this work introduces Dominance-Informed Regions (DIR), which express both whether parts of the space are unexplored and whether they lies along a high quality path. Furthermore, to speed up the generation of a successful successor state, which involves collision checking or physics-based simulation, a proposed strategy generates the most promising successor in an informed way, while maintaing properties. Overall, this paper introduces a new informed and asymptotically optimal kinodynamic motion planner, the Dominance-Informed Region Tree (DIRT). The method balances exploration-exploitation tradeoffs without many explicit parameters. It is shown to outperform sampling-based and search-based methods for robots to significant dynamics.


Title: High-Speed and Intelligent Pre-Grasp Motion by a Robotic Hand Equipped with Hierarchical Proximity Sensors
Key Words: manipulators  motion measurement  optical sensors  photodetectors  shape measurement  size measurement  high-speed intelligent pre-grasp motion  hierarchical optical proximity sensor  robotic hand manipulation  shape recognition  size recognition  photodetectors  high-speed feedback control  robot fingertips  vision sensors  time 1.0 s  Robot sensing systems  Phototransistors  Grasping  Photoconductivity  Task analysis 
Abstract: Quickness, preciseness and robustness are required in manipulation tasks of robotic hands for automation of manufacturing sites. Previous researches have found that sensing from fingertips equipped with proximity sensors is available for the requirements, because it complements blind areas of vision sensors. In this paper, we develop a novel optical proximity sensor for robot fingertips which provides two levels of proximity information with different purposes, sampling rates, information quantity and quality. The lower-level information from the sensor is for high-speed feedback control of a robotic hand, and the higher-level information is for recognizing the shape and size of an object. A prototype of the sensor with 5 × 5 matrix of photo detectors is presented, and its availability is shown through basic characteristic tests. A motion experiment using a robotic hand equipped with the prototype sensors is also conducted. The result confirms that the robotic hand can adjust the position and orientation of the fingertips to various objects and then correct the grasping form according to the object size within 1s.


Title: Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control
Key Words: convex programming  legged locomotion  predictive control  robot dynamics  torque control  torque-controlled quadruped robot  convex model-predictive control  MIT cheetah 3  dynamic locomotion  ground reaction force planning problems  convex optimization  robot dynamics  Robot kinematics  Legged locomotion  Dynamics  Predictive control  Convex functions  Predictive models 
Abstract: This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.


Title: Optimal Input Waveform for an Indirectly Controlled Limit Cycle Walker
Key Words: control system synthesis  gait analysis  legged locomotion  limit cycles  numerical analysis  optimal control  oscillators  robot dynamics  torque  wheels  control mechanisms  limit cycle walker  forcing energy reduction  gait interval  Arnold tongues  optimal control design  numerical analysis  phase response curve  phase oscillators  rimless wheels  active wobbling mass  joint torques  underactuated locomotion robot  optimal input waveform  optimal forcing waveform  Wheels  Perturbation methods  Limit-cycles  Legged locomotion  Trajectory  Mathematical model 
Abstract: Precisely manipulating the center of mass (CoM) of the underactuated locomotion robot can't be easily achieved by common control mechanisms which apply only joint torques. A novel and indirect method has been recently introduced using an active wobbling mass attached to limit cycle walkers. The next important issue is to design an optimal control input to reduce the forcing energy. In this paper, we use combined rimless wheels as a simplified example to apply our method, which is based on the theory of phase oscillators. First, we introduce the typical modeling and control of this underactuated robot. Second, we obtain the phase response curve by numerically applying perturbations at different phases of the walker's gait interval and calculating the deviations from the unperturbed. Third, we analytically derive an optimal forcing waveform for the wobbling mass to entrain the combined rimless wheel based on the phase response curve. As an ecological extension, an ideal forcing waveform for m: 1 entrainment was further generated. Finally, the proposed method was evaluated by locking range of the Arnold tongues. The results show that the optimal forcing waveform we derived achieves the best performance for 1:1 entrainment among all the candidates. One of the strongest advantages of our method is the easiness of its implementation, prompting its applicability to a wide variety of locomotion systems.


Title: A Comparative Study on Sigma-Point Kalman Filters for Trajectory Estimation of Hybrid Aerial-Aquatic Vehicles
Key Words: autonomous aerial vehicles  autonomous underwater vehicles  Kalman filters  Monte Carlo methods  nonlinear filters  robot dynamics  state estimation  detailed dynamic model simulation  nonlinear algorithm  derivative-free nonlinear Kalman Filters  Cubature Kalman Filter  CKF  nonlinear probabilistic estimators  average execution time  Monte Carlo simulations  in-production HUAUV prototype  state augmentation  sensor data filtering  trajectory estimation  high dimensional state spaces  comparative study  sigma-point Kalman  aerial-aquatic vehicles  nonlinear state estimation methods  transformed unscented Kalman filter  root-mean square error  hybrid unmanned aerial underwater vehicles  HUAUV  Kalman filters  Trajectory tracking  State estimation  Vehicle dynamics  Robot sensing systems 
Abstract: In this paper, a study on nonlinear state estimation methods for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) is presented. Based on a detailed dynamic model simulation, we analyse and elect the best nonlinear algorithm among those presented in the state-of-the-art literature addressing local derivative-free nonlinear Kalman Filters (KFs): the Unscented Kalman Filter (UKF), the Cubature Kalman Filter (CKF) and the Transformed Unscented Kalman Filter (TUKF). Here, these three nonlinear probabilistic estimators were compared in terms of the Root Mean Square Error (RMSE) and the average execution time over Monte Carlo simulations. We simulated real-world conditions for our in-production HUAUV prototype using Inertial Measurement Unit (IMU) data and state augmentation for sensor data filtering and trajectory estimation. We have concluded that the CKF proved to be the most interesting KF to low-cost on-board applications for high dimensional state spaces.


Title: Robust Humanoid Control Using a QP Solver with Integral Gains
Key Words: humanoid robots  Lyapunov methods  quadratic programming  robot dynamics  robust control  torque control  low-frequency bounded disturbances  Lyapunov-stable torque control  dynamical model  dynamic constraints  QP solver  kinetic joint friction  robust humanoid control  torque controlled humanoid robots  multiobjective weighted tasks  optimal dynamically-feasible reference  exponential convergence  joint torque feedback  nonmodelled torque bias  quadratic programming  HRP-5P robot  Torque  Humanoid robots  Convergence  Acceleration  Torque control  Task analysis  Robust control  Torque control  Passivity  Quadratic programming  Humanoid robots 
Abstract: We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.


Title: Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence
Key Words: intelligent sensors  nearest neighbour methods  recurrent neural nets  skin  tactile sensors  recurrent neural network  Preisach model  multiple contact locations  k-nearest neighbors algorithm  artificial neural network  machine learning techniques  soft robotics applications  soft artificial skin sensors  artificial intelligence  soft tactile sensors  Sensors  Force  Hysteresis  Microchannels  Estimation  Wires  Real-time systems 
Abstract: Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.


Title: A Biomimetic Soft Robot for Inspecting Pipeline with Significant Diameter Variation
Key Words: biomimetics  diseases  industrial robots  inspection  pipelines  central pattern generator-based control system  pipeline inspection robots  earthworm-like soft robot  CPG-based control system  pipeline navigation  gastrointestinal tract inspection  tubular environment  biomimetic soft robot  Pipelines  Inspection  Actuators  Soft robotics  Mobile robots  Valves 
Abstract: Navigation through tubular environment is fundamental in tasks such as pipeline inspection, gastrointestinal tract inspection, etc. Conventional pipeline inspection robots are mostly made by rigid materials and could not well adapt to the large size variation of the environment. Soft robots provide an additional solution for inspection of pipelines, especially with significant size variation. In this work, we present a soft robot for pipeline inspection, which consists of an earthworm-like soft robot and a Central Pattern Generator (CPG)-based control system. An analytical model is developed to predict the maximum pipe diameter that the robot could adapt to. For the current prototype, the robot could adapt to size change of three times. Experimental results show that this robot could navigate through pipelines with sharp turnings and with large diameter change.


Title: Continuum Manipulator with Redundant Backbones and Constrained Bending Curvature for Continuously Variable Stiffness
Key Words: bending  design engineering  elasticity  medical robotics  redundant manipulators  continuously constrained bending curvature  hyper-redundant articulated vertebrate structure  slender manipulators  surgical robots  snake-like manipulators  continuously variable stiffness  redundant backbones  redundantly arranged elastic backbones  simple continuum manipulator design  Manipulators  Electron tubes  Kinematics  Friction  Tendons  Strips  Lead 
Abstract: Snake-like manipulators can navigate and perform manipulation in confined spaces. Their recent implementations in surgical robots attracted a lot of attentions. These slender manipulators usually possess either a hyper-redundant articulated vertebrate structure or a continuum one. Primary design considerations usually converge to a balance between proper workspace and acceptable stiffness. Efforts have hence been constantly made to achieve higher or adjustable stiffness for a manipulator to widen its applications. This paper presents a simple continuum manipulator design with variable stiffness based on redundantly arranged elastic backbones and continuously constrained bending curvature. The design concepts, kinematics, a preliminary formulation for stiffness adjustment, system construction and experimental characterizations are elaborated. The results showed that the manipulator's stiffness can be increased up to 4.71 times of the value without the curvature constraining rod, indicating the efficacy of the proposed idea.


Title: A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots
Key Words: cantilevers  electroactive polymer actuators  manipulator kinematics  polymers  millicontinuum soft robots  active flexible polymer actuator  multisegment robot  3D arrangement  robot capability  three-segment CSR  two-segment CSR  single segment robot  multiphysics model  millimeter-size Continuum Soft Robot  multisegment electro-active polymer  Strain  Nonhomogeneous media  Soft robotics  Fabrication  Deformable models  Microactuators 
Abstract: This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.


Title: A Compact Wheeled Robot that Can Jump while Rolling
Key Words: buckling  elasticity  mobile robots  robot dynamics  strips  wheels  elastic strip  snap-through buckling  jumping angle  jumping mechanism  wheels  robot jumping  animals jump  rolling  compact wheeled robot  Mobile robots  Strips  Blades  Wheels  Force  Steel 
Abstract: In this paper, we study a compact wheeled robot that can jump while rolling. Some robots are capable of jumping or rolling, but as far as we know, those robots are not focused on jumping while rolling. We know that animals jump while running to escape from predators. Robots can move quickly by jumping while rolling. We consider a model of a robot jumping while rolling and evaluate the proposed robot. The proposed robot has two wheels and a jumping mechanism based on snap-through buckling of an elastic strip. The proposed robot can jump about 5.9 cm high and 22 cm wide on average while maintaining a traveling speed of about 1.2 m/s. The proposed robot can change the jumping angle without greatly decreasing the impulse for the moving speed.


Title: Soft LEGO: Bottom-Up Design Platform for Soft Robotics
Key Words: assembling  bending  design engineering  finite element analysis  grippers  mobile robots  pneumatic actuators  rapid prototyping (industrial)  Taguchi methods  three-dimensional printing  soft LEGO bricks  soft robotics  pneumatically inflatable soft brick  assembled soft bricks  bottom-up design platform  flexible bending brick  air channel brick  Taguchi method  finite-element analysis  multimaterial 3-dimensional printer  Soft robotics  Hoses  Actuators  Pins  Toy manufacturing industry  Joining processes 
Abstract: This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.


Title: Soft Snake Robots: Investigating the Effects of Gait Parameters on Locomotion in Complex Terrains
Key Words: mobile robots  motion control  gait-curvature combination  half-activation gait  soft robot  soft-bodied robots  locomotion strategies  compliant materials  complex terrains  gait parameters  soft snake robot  Actuators  Soft robotics  Snake robots  Navigation  Friction  Solenoids 
Abstract: Compliant materials used to create soft robots can better replicate biological structures than typical rigid materials. We can look to nature for developing locomotion strategies for these soft-bodied robots. In this work, snakes were used as inspiration to create an inextensible, soft robot which was used as a platform to test gaits in terrain composed of granular media ranging from fine sand to stone. Snakes vary the speed and amplitude of the traveling wave used in lateral undulation to navigate different environments. We used these gait parameters to develop and test a set of custom gaits that varied the phase offset of the sequence of waves as well as using the best performing gait to test how the amplitude of the wave effects locomotion over the selected terrains. These tests provide preliminary evidence that altering these parameters effects the robot's ability to traverse different terrains. The developed robot is also tested in environments specific to applications for snake robots to show how a soft snake robot can be potentially more effective in these environment. The highest performing gait-curvature combination was the half-activation gait (where the back actuator was activated half as long as the front)with a 135° swept angle. It reached a velocity of 2.2 mm/s or 0.011 body-lengths/s on paper, which was the best performing terrain.


Title: Inverse Error Function Trajectories for Image Reconstruction*This material is based upon work supported by the National Science Foundation under Grant No. 1662029
Key Words: cameras  error analysis  Gaussian processes  image motion analysis  image restoration  mobile robots  optical transfer function  inverse error function trajectories  image reconstruction  mobile robots  visual stimuli  camera trajectories  camera motion  motion blur effects  image quality  Gaussian blur kernel  image capturing  linear error  polynomial error  time analysis  point-spread function  Trajectory  Cameras  Image reconstruction  Robot vision systems  Optical imaging  Optical sensors 
Abstract: Capturing clear images while a camera is moving fast, is integral to the development of mobile robots that can respond quickly and effectively to visual stimuli. This paper proposes to generate camera trajectories, with position and time constraints, that result in higher reconstructed image quality. The degradation in of an image captured during motion is known as motion blur. Three main methods exist for mitigating the effects of motion blur: (i) controlling optical parameters, (ii) controlling camera motion, and (iii) image reconstruction. Given control of a camera's motion, trajectories can be generated that result in an expected blur kernel or point-spread function. This work compares the motion blur effects and reconstructed image quality of three trajectories: (i) linear, (ii) polynomial, and (iii) inverse error. Where inverse error trajectories result in Gaussian blur kernels. Residence time analysis provides a basis for characterizing the motion blur effects of the trajectories.


Title: Faster Collision Checks for Car-Like Robot Motion Planning
Key Words: collision avoidance  geometry  mobile robots  motion control  rear disc  faster collision checks  system knowledge  nonholonomic motion  motion planning  frontal disc  car-like robot motion planning  predictive algorithm  Collision avoidance  Trajectory  Shape  Planning  Robot kinematics  Tuning 
Abstract: In this paper, we describe how collision checking for car-like robots can be sped up utilizing system knowledge. Their non-holonomic motion, while being a challenge for motion planning, is utilized here to place discs which are used as an approximation of the robot's shape in a predictive manner. For ease of comparison, we assume the robot to be rectangular, i. e., we use bounding boxes. Our algorithm is compared to a widely-used baseline and shows similar performance in terms of under- and oversampling while being approximately 20-40 % faster. Another feature of the algorithm is its predictive nature: with the frontal disc, we already check for collisions that would occur with the rear disc in the next sample, assuming near-constant curvature. While this might be conservative in some cases where large steering rates are necessary, in our evaluation even tight corridors could be navigated without negative effects.


Title: C-MPDM: Continuously-Parameterized Risk-Aware MPDM by Quickly Discovering Contextual Policies
Key Words: decision making  gradient methods  operations research  optimisation  continuously-parameterized risk-aware MPDM  on-line forward roll-out process  computational cost  continuous-valued parameters  iterative gradient-based algorithm  multipolicy decision making systems  social environment  promising policy parameters  contextual policies  Robots  Cost function  Real-time systems  Trajectory  Decision making  Backpropagation 
Abstract: Risk-aware Multi-Policy Decision Making (MPDM)is a powerful framework for reliable navigation in a dynamic social environment where rather than evaluating individual trajectories, a “library” of policies (reactive controllers)is evaluated by anticipating potentially dangerous future outcomes using an on-line forward roll-out process. There is a core tension in Multi-Policy Decision Making (MPDM)systems - it is desirable to add more policies to the system for flexibility in finding good policies, however, this increases computational cost. As a result, MPDM was limited to small (perhaps 5-10)discrete policies - a significant performance bottleneck. In this paper, we radically enhance the expressivity of MPDM by allowing policies to have continuous-valued parameters, while simultaneously satisfying real-time constraints by quickly discovering promising policy parameters through a novel iterative gradient-based algorithm. Our evaluation includes results from extensive simulation and real-world experiments in semi-crowded environments.


Title: Skating with a Force Controlled Quadrupedal Robot
Key Words: end effectors  force control  legged locomotion  locomotives  motion control  robot dynamics  torque control  wheels  motion planner  legged robot  gliding motions  Virtual Model Controller  optimal contact force distribution  torque-controllable robot ANY mal  passive wheels  ice skates  flat terrain  inclined terrain  skating motions  force controlled quadrupedal robot  wheeled systems  flat environments  locomotion domains  end-effectors  motion controller  Legged locomotion  Force  Torso  Wheels  Robot kinematics 
Abstract: Traditional legged robots are capable of traversing challenging terrain, but lack of energy efficiency when compared to wheeled systems operating on flat environments. The combination of both locomotion domains overcomes the trade-off between mobility and efficiency. Therefore, this paper presents a novel motion planner and controller which together enable a legged robot equipped with skates to perform skating maneuvers. These are achieved by an appropriate combination of planned reaction forces and gliding motions. Our novel motion controller formulates a Virtual Model Controller and an optimal contact force distribution which takes into account the nonholonomic constraints introduced by the skates. This approach has been tested on the torque-controllable robot ANY mal equipped with passive wheels and ice skates as end-effectors. We conducted experiments on flat and inclined terrain, whereby we show that skating motions reduces the cost of transport by up to 80 % with respect to traditional walking gaits.


Title: A Comparative Analysis of Contact Models in Trajectory Optimization for Manipulation*
Key Words: manipulators  optimisation  manipulation  contact-implicit trajectory optimization  variable smooth contact model  optimization process  Task analysis  Robots  Force  Trajectory optimization  Computational modeling  Dynamics 
Abstract: In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We consider three different approaches: (1)a contact model that is based on complementarity constraints, (2)a smooth contact model, and our proposed method (3) a variable smooth contact model. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time. In each case, the optimization process is initialized by setting all torque variables to zero, namely, without a meaningful initial guess. For simulations, we consider a pushing task with varying complexity for a 7 degrees-of-freedom robot arm. Our results demonstrate that the optimization based on the proposed variable smooth contact model provides a good trade-off between the physical fidelity and quality of motions at the cost of increased computation time.


Title: Combining Method of Alternating Projections and Augmented Lagrangian for Task Constrained Trajectory Optimization
Key Words: collision avoidance  convex programming  optimisation  path planning  robot dynamics  similar nature trajectory  off-the-shelf nonlinear solver  similar task constraint residuals  SciPy alternative  alternating projections  Augmented Lagrangian  task constrained trajectory optimization  task space constraints  joint configurations  implicitly defined manifold  task constrained motion planning  optimization problem  nonlinear equality constraints  nonlinear optimization techniques  custom optimizer  task constraints  efficient convex optimization  feasible solution  common robotic benchmark problems  cyclic motion  joint space  Task analysis  Planning  Trajectory optimization  Cost function  Kinematics 
Abstract: Motion planning for manipulators under task space constraints is difficult as it constrains the joint configurations to always lie on an implicitly defined manifold. It is possible to view task constrained motion planning as an optimization problem with non-linear equality constraints, which can be solved by general non-linear optimization techniques. In this paper, we present a novel custom optimizer which exploits the underlying structure present in many task constraints. At the core of our approach are some simple reformulations, which when coupled with the method of alternating projection, leads to an efficient convex optimization based routine for computing a feasible solution to the task constraints. We subsequently build on this result and use the concept of Augmented Lagrangian to guide the feasible solutions towards those that also minimize the user defined cost function. We show that the proposed optimizer is fully distributive and thus, can be easily parallelized. We validate our formulation on some common robotic benchmark problems. In particular, we show that the proposed optimizer achieves cyclic motion in the joint space corresponding to a similar nature trajectory in the task space. Furthermore, as a baseline, we compare the proposed optimizer with an off-the-shelf non-linear solver provide in open source package SciPy. We show that for similar task constraint residuals and smoothness cost, it can be upto more than three times faster than the SciPy alternative.


Title: A Software Framework for Planning Under Partial Observability
Key Words: application program interfaces  decision theory  Markov processes  mobile robots  path planning  planning (artificial intelligence)  software tools  robotics tasks  software tools  software toolkit  POMDP solvers  robot motion planning  partial observability problems  software framework  reliable robot operation  partially observable Markov decision process  abstract solver API  online POMDP planning toolkit  OPPT  Planning  Robot sensing systems  Computational modeling  Observability  Computer architecture  Standards 
Abstract: Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.


Title: Adaptive Path Following of Snake Robot on Ground with Unknown and Varied Friction Coefficients
Key Words: adaptive control  control nonlinearities  control system synthesis  friction  mobile robots  motion control  parameter estimation  varied friction coefficients  underactuated bio-inspired snake robots  adaptive controller  8-link snake robot  adaptive path following  backstepping technique  parameter estimation  control design input  LaSalle-Yoshizawa theorem  Snake robots  Friction  Tuning  Backstepping  Adaptation models  Stability analysis 
Abstract: This paper investigates the straight path following problem for a class of underactuated bio-inspired snake robots on ground with unknown and varied friction coefficients. Existing works usually design control input requiring the exact values of these friction coefficients, which however rely on the specific operating terrain and may not always be known a priori. By virtue of backstepping technique, we present a novel adaptive controller that can compensate for unknown and varied friction coefficients in real-time. Moreover, it is proved via LaSalle-Yoshizawa theorem that the path following errors converge to zero asymptotically and all the parameter estimates are bounded. Simulations and experiments on an 8-link snake robot are carried out to illustrate the effectiveness of the proposed controller.


Title: Analytical Model of Thermal Soaring: Towards Energy Efficient Path Planning for Flying Robots
Key Words: aerospace robotics  biomimetics  continuous systems  discrete systems  mobile robots  path planning  simple hybrid control strategy  flying robot  energy efficient flying  thermal soaring behavior  energy efficient locomotion types  flying animals  energy efficient path planning  Mathematical model  Birds  Thermal loading  Analytical models  Robots  Aerodynamics  Thermal variables control  Bio-inspired model  Thermal soaring  Path planning  Flying locomotion  Hybrid controller 
Abstract: Developing analytical models of efficient locomotion in biology is one of the most interesting goals in bio- inspired robotics. This paper presents a mathematical framework in order to model one of the most energy efficient locomotion types in flying animals; i.e., thermal soaring. Unlike the legged locomotion, in flying, modeling the environmental effects on animals' behaviors is very important. In doing so, we develop our model by assuming thermals as bubbles of rising air. According to pieces of real evidence, this kind of modeling is more compatible with the nature of thermal soaring. Moreover, we present a simple hybrid control strategy for obtaining the optimal path in order to maximize benefit from the updraft of air-flow. By using this control strategy, the flying robot can plan a path for traveling between thermals without flapping; i.e., energy efficient flying. So as to investigate the compatibility of presented model and controller with reality, we set their parameters based on the biological evidences. As a result, in simulations, it is observed that the generated flying behavior is comparable with the thermal soaring behavior of real birds. This observation provides a confirmation for generality and applicability of the presented approach.


Title: Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).
Key Words: microactuators  microrobots  mobile robots  muscle  robot dynamics  stimulation frequency  atmospheric-operable walking robot  maximum walking speed  bio actuated walker  biological microbio-actuator  grants-in-aid  output force  stimulation voltage  muscle-tissue of earthworm  Japan society  atmospheric-operable 3d printed walking bio-robot  control property  Legged locomotion  Force  Muscles  Actuators  Strain measurement  Force measurement 
Abstract: Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.


Title: PiRat: An Autonomous Framework for Studying Social Behaviour in Rats and Robots
Key Words: mobile robots  position control  social stimulus  rat-robot studies  social behaviour  rat-robot interaction studies  novel rat-sized robot  PiRat  robotic behavior  robot rat  reproducible behaviour  closed-loop rat-robot framework  autonomous framework  Rats  Robot sensing systems  Brushless DC motors 
Abstract: The use of robots, as a social stimulus, provides several advantages over using another animal. In particular, for rat-robot studies, robots can produce social behaviour that is reproducible across trials. In the current work, we outline a framework for rat-robot interaction studies, that consists of a novel rat-sized robot (PiRat), models of robotic behavior, and a position tracking system for both robot and rat. We present the design of the framework, including constraints on autonomy, latency, and control. We pilot tested our framework by individually running the robot rat with eight different rats, first through a habituation stage, and then with PiRat performing two different types of behaviour - avoiding and frequently approaching. We evaluate the performance of the framework on latency and autonomy, and on the ability to influence the behaviour of individual rats. We find that the framework performs well on its constraints, engages some of the rats (according to the number of meetings), and features a control scheme that produces reproducible behaviour in rats. These features represent a first demonstration of a closed-loop rat-robot framework.


Title: Tarzan: Design, Prototyping, and Testing of a Wire-Borne Brachiating Robot
Key Words: legged locomotion  motion control  swing-up maneuver  distributed electronics packages  brachiating robot design  prototype robot  remote sensing packages  payload mounting point  minimal power consumption  locking hand design  ladder brachiation modes  parallel wires  elevated wire networks  wire-borne brachiating robot  ladder locomotion modes  Wires  Grippers  Wrist  Thumb  Robot sensing systems 
Abstract: A novel brachiating robot design is presented for the purpose of traversing elevated wire networks. The robot is capable of moving along a single wire and between parallel wires, thereby enabling traversal of a two-dimensional space. Several novel features distinguish this design compared to previous brachiating robots. These include the ability to transition to and from both “rope” and “ladder” brachiation modes through an integrated wrist, a locking hand design for minimal power consumption, and distributed electronics packages that communicate wirelessly. A payload mounting point is installed, offering space for a variety of remote sensing packages. Experimental results using a prototype robot demonstrate that the system can reliably brachiate along a single wire, and can also reliably perform a swing-up maneuver after failed swing attempts or when transitioning between the rope and ladder locomotion modes. Energy expenditure for a single swing is quantified using experimental data. Overall, the proposed robot design is shown to provide a promising platform for traversal of wire networks in two dimensions.


Title: Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots
Key Words: accelerometers  gait analysis  legged locomotion  motion control  position control  terrain mapping  interrupt mode  hexapod walking robot  inertial measurements  multilegged walking robots  proprioceptive terrain sensing  terrain irregularities  inertial data  online foot strike detection  foot strike event detector  data processing  accelerometers  terrain traversal  Legged locomotion  Robot sensing systems  Accelerometers  Servomotors  Reliability 
Abstract: Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.


Title: TacWhiskers: Biomimetic Optical Tactile Whiskered Robots
Key Words: biomimetics  mobile robots  tactile sensors  optical cutaneous tactile sensor  static Tac Whisker array  immotile tactile vibrissae  dynamic Tac Whisker array  dynamic sensor output  Tac Whiskers  biomimetic optical tactile whiskered robots  vibrissal tactile sensor  3D-printed optical cutaneous tactile sensor  TacTip  active object localization task  Pins  Rodents  Tendons  Dynamics  Tactile sensors 
Abstract: Here we propose and investigate a novel vibrissal tactile sensor - the Tac Whisker array - based on modifying a 3D-printed optical cutaneous (fingertip) tactile sensor - the TacTip. Two versions are considered: a static Tac Whisker array analogous to immotile tactile vibrissae (e.g. rodent microvib-rissae) and a dynamic Tac Whisker array analogous to motile tactile vibrissae (e.g. rodent macrovibrissae). Performance is assessed on an active object localization task. The whisking motion of the dynamic Tac Whisker leads to millimetre-scale location perception, whereas perception with the static Tac Whisker array is relatively poor when making dabbing contacts. The dynamic sensor output is dominated by a self-generated motion signal, which can be compensated by comparing to a reference signal. Overall, the Tac Whisker arrays give a new class of tactile whiskered robots that benefit from being relatively inexpensive and customizable. Furthermore, the biomimetic basis for the Tac Whiskers fits well with building an embodied model of the rodent sensory system for investigating animal perception.


Title: Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot
Key Words: image classification  image colour analysis  learning (artificial intelligence)  mobile robots  object detection  object tracking  optical radar  probability  radar tracking  robot vision  service robots  stereo image processing  online transfer learning  3D LiDAR-based human detection  mobile robot  service robots  multisensor tracking system  2D LiDAR  human trajectory  3D LiDAR-based human classification  trajectory probability  RGB-D camera  Three-dimensional displays  Laser radar  Detectors  Robot sensing systems  Cameras 
Abstract: Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.


Title: An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory
Key Words: mobile robots  path planning  robot agent  local-rule-aware home assistive tasks  semantic map  long-term episodic memory  home environments  global society  probabilistic object localization map  Fetch robots  semantic common knowledge  PR2 robot  robotic system  time 41.0 d  Task analysis  Probabilistic logic  Semantics  Planning  Robot sensing systems  Solid modeling  Service Robots  Learning and Adaptive Systems  Big Data in Robotics and Automation 
Abstract: To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.


Title: Dynamic Dumbbell - Novel Muscle Training Robot with Programmable Exercise Load
Key Words: actuators  elasticity  force control  gears  medical robotics  muscle  patient rehabilitation  high performance force control algorithm  rotary series elastic actuator  planetary-geared elastic actuator  mechanical engineering  muscle training robot  exercise load model  advanced muscular exercise  Dynamic Dumbbell  programmable exercise load  Dynamic dumbbell  Dynamics  Muscles  Torque  Robots  Force  Load modeling  Gears 
Abstract: In this paper, Dynamic Dumbbell, a novel robotic device for advanced muscular exercise of upper limb is presented. The type of exercise load is classified and designed in terms of mechanical engineering to be implemented in Dynamic Dumbbell. The exercise load model, which is named as programmable exercise load, is realized by Dynamic Dumbbell. To generate the programmable exercise load, two of compact Planetary-geared Elastic Actuator, which is a rotary Series Elastic Actuator (SEA), are utilized in Dynamic Dumbbell. The SEAs are controlled using high performance force control algorithm. Experimental results verifies the effectiveness of the proposed Dynamic Dumbbell and programmable exercise load.


Title: Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People
Key Words: human-robot interaction  image recognition  mobile robots  navigation  path planning  robot vision  sensors  path-planning  sensor characteristics  autonomous navigation  sensor data  human recognition reliability  human-robot interaction  multiple people  initiate interaction  multimodal potential field  Robot sensing systems  Reliability  Task analysis  Character recognition  Robot kinematics  Cameras 
Abstract: In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.


Title: Estimating Door Shape and Manipulation Model for Daily Assistive Robots Based on the Integration of Visual and Touch Information
Key Words: collision avoidance  learning (artificial intelligence)  manipulators  mobile robots  motion control  robot vision  service robots  visual touch information  door manipulation  door candidates  target door  appropriate shape  single click  single user instruction  unknown door  daily assistive robots  manipulation model  door shape  Shape  Robot kinematics  Trajectory  Visualization  Robot vision systems 
Abstract: We propose a method for a robot to manipulate an unknown door based on a single user instruction. The primary contributions of this paper are (i) to reduce the user instruction to a single click and (ii) to develop an efficient method to estimate an appropriate shape and manipulation model for a target door by integrating visual and touch information obtained by a robot. The proposed method first detects door candidates using a 3-D camera and then estimates the manipulation model of each candidate based on prior learning results. During door manipulation, the system integrates visual and touch information to estimate the shape and manipulation model to generate an appropriate motion. We evaluated the proposed method experimentally, and the results prove that the proposed method is effective.


Title: Designing for Robust Movement in a Child-Friendly Robot
Key Words: design  humanoid robots  human-robot interaction  manipulator dynamics  mobile robots  motion control  safety  torque-limited stepper motors  robotic agents  social interaction  mechanical features  child-friendly robot  social robot  mechanical design  torso-mounted  back-drivable  Safety  Manipulators  Actuators  Prototypes  Torque  Three-dimensional displays 
Abstract: Motion is a critical aspect of communication, required to create natural interactions between humans and robots. Robots for the classroom pose several constraints on motion, which make them challenging to design, including maintaining the safety of the child and the robot, responding in a timely fashion, and creating motions that are expressive and not scary. In this paper we present the mechanical design of a social robot and demonstrate that it is capable of safe motion within the proximity of children through analysis and empirical testing of the arms. The robot has a novel mechanical design for its two arms, which include torso-mounted, back-drivable, torque-limited stepper motors. The results suggest that our design succeeds at increasing safety levels while enabling the use of socially acceptable speeds of motion during the interaction. This study implies that the design of robotic agents for social interaction with children should consider the design of mechanical features that enable safe contact between the human and the robot while not limiting the robot to slow motions that would impair the timing of the interaction.


Title: Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test
Key Words: home computing  manipulators  mobile robots  motion control  multi-robot systems  wheels  international competition  aging population  intelligent sensing  household work  actual home environment  HSR users  technical knowledge  standard platform  international robot competitions  HSR's development background  omnidirectional mobile base  domestic mobile manipulator  human support robot  whole body motion control system  field test  quality of life  intelligent software  World Robot Summit  dual-wheel caster-drive mechanism  RoboCup@Home  HSR's operational movement  Robot kinematics  Manipulators  Task analysis  Sensors  Software  Hardware 
Abstract: There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.


Title: Robot Artist Performs Cartoon Style Facial Portrait Painting
Key Words: art  face recognition  image colour analysis  painting  rendering (computer graphics)  facial features  hand-painted strokes  painting strategy  basic colors  eye-in-hand system  cartoon facial components  face detection  human portrait photos  cartoon style transformation stage  colorful painting  stages-cartoon style transformation  robot cartoonist  human cartoonist  visual feedback system  cartoon stylization painting  robot artist  cartoon style facial portrait painting  face portrait  Painting  Image color analysis  Face  Shape  Facial features  Image segmentation  Cartoon face  robot painting 
Abstract: This paper presents a face portrait with cartoon stylization painting and associated algorithms with the visual feedback system to paint like a human cartoonist. The robot cartoonist creates the artwork in two stages-cartoon style transformation and robot artist for colorful painting. In the cartoon style transformation stage, it transfers human portrait photos to cartoon style by face detection and alignment, which can effectively decompose the face into individual components then replace by cartoon facial components. In the second stage, the robot uses an eye-in-hand system to obtain five basic colors (cyan, magenta, yellow, white and black) to automatically mix a variety of colors automatically. For painting strategy, we start with the outline of the face, which we use non-photorealistic rendering (NPR) to generate hand-painted strokes. After that, the robot artist will implement painting the facial features. We also demonstrate the success of this proposed research.


Title: Robust Plant Phenotyping via Model-Based Optimization
Key Words: agriculture  biology computing  botany  crops  genetic algorithms  genetics  industrial plants  probability  solid modelling  robust plant phenotyping  observable plant traits  labour intensive error prone  automated manner  noninvasive manner  plant breeding methods  nonideal sensing conditions  high throughput plant phenotyping  state-of-the-art 3D phenotyping algorithms  hand-tuned parameters  novel model-based optimization approach  estimating plant physical traits  plant units  plant models  probability distribution approach  phenotyping objective  plant structure  work furthers field-based robotic phenotyping capabilities  plant biologists  crop yields  Three-dimensional displays  Imaging  Optimization  Robot sensing systems  Green products  Image reconstruction  Solid modeling 
Abstract: Plant phenotyping is the measurement of observable plant traits. Current methods for phenotyping in the field are labour intensive and error prone. High throughput plant phenotyping in an automated and noninvasive manner is crucial to accelerating plant breeding methods. Occlusions and non-ideal sensing conditions is a major problem for high throughput plant phenotyping with most state-of-the-art 3D phenotyping algorithms relying heavily on heuristics or hand-tuned parameters. To address this problem, we present a novel model-based optimization approach for estimating plant physical traits from plant units called phytomers. The proposed approach involves sampling parameterized 3D plant models from an underlying probability distribution. It then optimizes, making the mass of this probability distribution approach true parameters of the model. Reformulating the phenotyping objective as a search in the space of plant models lets us reason about the plant structure in a holistic manner without having to rely on hand-tuned parameters. This makes our approach robust to noise and occlusions as frequently encountered in real world environments. We evaluate our approach for plant units taken across simulated, greenhouse and field environments. This work furthers field-based robotic phenotyping capabilities paving the way for plant biologists to study the coupled effect of genetics and environment on improving crop yields.


Title: Design of an Autonomous Precision Pollination Robot
Key Words: greenhouses  mobile robots  motion control  path planning  precision robotic pollination systems  natural pollinators  uniformity  human population  ongoing development  autonomous robot  BrambleBee  ecology  visual perception  robust autonomous pollination system  autonomous precision pollination robot  Cameras  End effectors  Agriculture  Robot vision systems  Three-dimensional displays 
Abstract: Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named “BrambleBee”, which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.


Title: Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture
Key Words: agricultural safety  agriculture  environmental factors  hazardous materials  mobile robots  off-road vehicles  soil  spraying  ultra wideband technology  UWB  Ultra Wide Band technology  soil compaction  safety aspects  chemical products  human activities  environmental impact  autonomous robots  hazardous products  agricultural application  off-road mobile robots  production levels  human health  human operators  smart spraying  radio beacons  Mobile robots  Robot kinematics  Robot sensing systems  Spraying  Agriculture 
Abstract: Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.


Title: Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.
Key Words: neural nets  object detection  optical radar  pedestrians  road safety  high visibility clothing  neural networksresearch  detection methods  lidar range data  lidar intensity data  lidar sensor  pedestrian detection  strong cue  retro-reflective strips  contract UOAX1414  business innovation  new zealand ministry  3D lidar sensors  industrial environments  pedestrian safety  Laser radar  Safety  Sensors  Neural networks  Three-dimensional displays  Clothing  Strips 
Abstract: The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.


Title: UNDERWORLDS: Cascading Situation Assessment for Robots
Key Words: manipulators  mobile robots  spatio-temporal situation assessment  novel lightweight framework  cascading situation assessment  temporal granularities  cascading representations  temporal events  real-time distributed data structures  UNDERWORLDS  Robots  Three-dimensional displays  Solid modeling  Computer architecture  Tools  Software  Task analysis 
Abstract: We introduce UNDERWORLDS, a novel lightweight framework for cascading spatio-temporal situation assessment in robotics. UNDERWORLDS allows programmers to represent the robot's environment as real-time distributed data structures, containing both scene graphs (for representation of 3D geometries) and timelines (for representation of temporal events). UNDERWORLDS supports cascading representations: the environment is viewed as a set of worlds that can each have different spatial and temporal granularities, and may inherit from each other. UNDERWORLDS also provides a set of high-level client libraries and tools to introspect and manipulate the environment models. This article presents the design and architecture of this open-source tool, and explores some applications, along with examples of use.


Title: OpenSeqSLAM2.0: An Open Source Toolbox for Visual Place Recognition Under Changing Conditions
Key Words: image recognition  mobile robots  navigation  object recognition  public domain software  robot vision  SLAM (robots)  open source toolbox  changing conditions  traversed route  inclement conditions  navigating robots  robotic systems  environmental conditions  fully open-source toolbox  open access  source code  visual place recognition problem  open source platform  OpenSeqSLAM2.0  Visualization  Robots  Tools  Open source software  Search methods  Trajectory  Heuristic algorithms 
Abstract: Visually recognising a traversed route - regardless of whether seen during the day or night, in clear or inclement conditions, or in summer or winter - is an important capability for navigating robots. Since SeqSLAM was introduced in 2012, a large body of work has followed exploring how robotic systems can use the algorithm to meet the challenges posed by navigation in changing environmental conditions. The following paper describes OpenSeqSLAM2.0, a fully open-source toolbox for visual place recognition under changing conditions. Beyond the benefits of open access to the source code, OpenSeqSLAM2.0 provides a number of tools to facilitate exploration of the visual place recognition problem and interactive parameter tuning. Using the new open source platform, it is shown for the first time how comprehensive parameter characterisations provide new insights into many of the system components previously presented in ad hoc ways and provide users with a guide to what system component options should be used under what circumstances and why.


Title: HERO: Accelerating Autonomous Robotic Tasks with FPGA
Key Words: convolutional neural nets  field programmable gate arrays  mobile robots  path planning  SLAM (robots)  motion planning tasks  HERO platform  CNN inference  autonomous robotic tasks  Heterogeneous Extensible Robot Open platform  OpenCL programming  SLAM  convolutional neural network inference  FPGA acceleration  heterogeneous computing  simultaneous localization and mapping  VGG-16  ResNet-50  Field programmable gate arrays  Kernel  Acceleration  Simultaneous localization and mapping  Task analysis  Planning 
Abstract: The Heterogeneous Extensible Robot Open (HERO) platform is designed for autonomous robotic research. While bringing in the flexible computational capacities by CPU and FPGA, it addresses the challenges of heterogeneous computing by embracing OpenCL programming. We propose heterogeneous computing approaches for three fundamental robotic tasks: simultaneous localization and mapping (SLAM), motion planning and convolutional neural network (CNN) inference. With FPGA acceleration, the SLAM and motion planning tasks are performed 2-4 times faster on the HERO platform against fine-tuned software implementation. For CNN inference, it can process 20-30 images per second with the network of VGG-16 or ResNet-50. We expect the open platform and the developing experiences shared in this paper can facilitate future robotic research, especially for those compute intensive tasks of perception, movement and manipulation.


Title: Procedurally Provisioned Access Control for Robotic Systems
Key Words: authorisation  Internet of Things  middleware  public domain software  robot programming  robotic systems  industrial IoT  domestic IoT  development lifecycle  ROS2  secure real world robotic deployments  procedural provisioning access control policies  secure DDS  middleware infrastructures  next generation open source robotic software stack  Service robots  Access control  Middleware  Tools  Cryptography 
Abstract: Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.


Title: XBotCloud: A Scalable Cloud Computing Infrastructure for XBot Powered Robots
Key Words: cloud computing  control engineering computing  software agents  Web services  computational resources  robotic platforms  Amazon Web Services Cloud Security  XBotCloud  cross-robot flexibility  XBotCloud performances  robot local control unit  Real-Time modules  moderate execution time constraints  cloud services  cloud server  XBotCore Real-Time cross-robot software component  hard Real-Time execution/communication performance  soft Time execution/communication performance  XBot framework  cloud robotics concept  mobile robots  untethered robots  on-board computational resources  scalable cloud computing infrastructure  Cloud computing  Robot sensing systems  Software as a service  Task analysis  Servers 
Abstract: Limitations with the on-board computational resources installed on untethered robots such as humanoids and mobile robots in general affects significantly the performance and capabilities of these machines. An approach to address this issue is to make use of the cloud robotics concept and take advantage of the extensive computational resources of the cloud. XBotCloud is a recently developed component of the XBot framework. It tackles the above challenges by introducing the tools and mechanisms to enable users and robots to exploit the computational resources of the cloud allowing the execution of services with low, soft or hard Real-Time execution/communication performance. The latter is ensured thanks to the functionality provided by the XBotCore Real-Time cross-robot software component of the XBot framework. XBotCloud addresses also one of the main challenges related with cloud robotics: security. To avoid remote attacks it takes advantage of the Amazon Web Services (AWS)Cloud Security and it uses an internal VPN Network to handle the connectivity between the robot and the cloud server. The full implementation of the framework is presented and its functionality is demonstrated in realistic tasks involving pipelines that mix the execution of cloud services with moderate execution time constraints and Real-Time modules running on the robot local control unit. XBotCloud performances and cross-robot flexibility are experimentally validated on two different robotic platforms, the WALK-MAN humanoid and the CENTAURO upper body/full-body.


Title: Learning to Touch Objects Through Stage-Wise Deep Reinforcement Learning
Key Words: end effectors  learning (artificial intelligence)  stage-wise deep reinforcement learning  complex behaviors  manipulation robotics  high-level modules  object palm-touching task  weakly-supervised learning  informative shaping reward  informative supervised reward  efficient learning  Task analysis  Robot kinematics  End effectors  Cameras  Robot vision systems  Kinematics 
Abstract: Learning complex behaviors through reinforcement learning is particularly challenging when reward is only available upon successful completion of the full behavior. In manipulation robotics, so-called shaping rewards are often used to overcome this problem. However, these usually require human engineering or (partial)world models describing, e.g., the kinematics of the robot or high-level modules for perception. Here we propose an alternative method to learn an object palm-touching task through a weakly-supervised and stagewise learning of simpler tasks. First, the robot learns to fixate the object with its cameras. Second, the robot learns eye-hand coordination by learning to fixate its end effector. Third, using the previously acquired skills an informative shaping reward can be computed which facilitates efficient learning of the object palm-touching task. We demonstrate in simulation that learning the full task with this shaping reward is comparable to learning with an informative supervised reward.


Title: Bayesian Information Recovery from CNN for Probabilistic Inference
Key Words: Bayes methods  Gaussian distribution  image classification  image fusion  learning (artificial intelligence)  mobile robots  navigation  neural nets  pose estimation  probability  robot vision  target tracking  probabilistic inference approach  light conditions  trajectory estimation  simulated unreal engine environment  uncertainty covariance  robot localization problem  robot pose  hidden state mean prediction  high-level state information  inference task  CNN feature likelihood  Bayesian framework  spatially-varying Gaussian distribution  generative viewpoint-dependent model  CNN classifier  visual observations  system hidden state  combinatorial data association  hand-engineered image features  high-dimensional visual measurements  Bayesian information recovery  Robots  Trajectory  Cameras  Bayes methods  Estimation  Uncertainty  Neural networks 
Abstract: Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.


Title: Inertial Velocity and Attitude Estimation for Quadrotors
Key Words: aircraft control  attitude control  autonomous aerial vehicles  drag  helicopters  inertial navigation  Kalman filters  linear drag parameters  drag forces  linear drag model  IMU  inertial measurement unit  quadrotor UAV  body-fixed z axis  attitude estimation  inertial velocity  Aerodynamics  Sensors  Accelerometers  Estimation  Magnetometers  Kalman filters  Velocity measurement 
Abstract: This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.


Title: Quadtree-Accelerated Real-Time Monocular Dense Mapping
Key Words: autonomous aerial vehicles  image fusion  image motion analysis  image reconstruction  image resolution  mobile robots  path planning  quadtrees  robot vision  stereo image processing  real-time monocular dense mapping  truncated signed distance function  dense 3D maps  resolution depth maps  pixels  dynamic belief propagation  pixel selection  depth map  intensity image  quadtree structure  single localized moving camera  high-quality dense depth maps  robotic navigation  Cameras  Three-dimensional displays  Belief propagation  Estimation  Optimization  Real-time systems  Image resolution 
Abstract: In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.


Title: The Deformable Quad-Rotor Enabled and Wasp-Pedal-Carrying Inspired Aerial Gripper
Key Words: aerodynamics  aircraft control  autonomous aerial vehicles  controllability  deformation  grippers  helicopters  mobile robots  stability  aerial gripper design  REMS  quadrotor body  quadrotor deformation  rigid elements based morphing structure  aerodynamic flow  wasp grasping behavior  stability  unmanned aerial vehicles  Grippers  Grasping  Strain  Payloads  Rotors  Manipulators  Gravity 
Abstract: The paper presents the development of a novel deformable quad-rotor enabled aerial gripper. The mechanism of our deformable quad-rotor is based on simultaneous expansion or contraction of the quad-rotor body, which is generated by controlling a rigid elements based morphing structure (REMS). Such deformation results in a highly deformable quad-rotor that can not only perform morphological adaptation in response to environmental changes and obstacles, but also improve the flight performance by contracting to facilitate the agility/maneuverability or by expanding to enhance the stability. Meanwhile, inspired by the wasp grasping behavior, such controllable expansion and contraction from the REMS ingeniously enable a new function of aerial gripper. In this paper, we start to detail the mechanism and design of the REMS based deformable quad-rotor, then present the quad-rotor deformation enabled aerial gripper design, its dynamics modeling, the grasping function and analysis. The simulation was conducted in order to graphically show the elicited aerodynamic flow situation during expansion or contraction of the quad-rotor with and without carrying payload. Experiments were further implemented to validate the grasping function of the gripper and the flight performance of the quad-rotor. Finally, two case studies on the new aerial gripper were performed. All results demonstrate the excellent performance of the deformable quad-rotor enabled aerial gripper, that is, it has the advantages of both flight maneuverability and grasping capability during performing tasks.


Title: Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions
Key Words: adaptive control  helicopters  mobile robots  optimisation  predictive control  robust control  trajectory control  uncertain systems  wind disturbances  cost function  optimal reference input  quadrotor  MPC  trajectory tracking error  predictive approach  adaptive control strategies  unmodeled dynamics  dynamic environments  automated systems  adaptive model predictive control  nonadaptive approach  Adaptation models  Predictive models  Trajectory tracking  Uncertainty  Adaptive control  Vehicle dynamics 
Abstract: Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L1 adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.


Title: Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator
Key Words: aerospace control  autonomous aerial vehicles  convolutional neural nets  grippers  image colour analysis  learning (artificial intelligence)  manipulators  path planning  rescue robots  robot vision  SLAM (robots)  autonomous wristband placement  robotic system  automatic wristband placement  remote sensor readings  continuous health monitoring  unmanned aerial manipulator  automatic wrist detection  RGB-D camera  convolutional neural network  Faster R-CNN  passive detachable gripper  VGG-16 neural network  target localization  trajectory planning  machine learning  parallel delta manipulator  search-and-rescue aerial manipulator  search and rescue operations  unmanned aerial vehicles  Manipulators  Wrist  Cameras  Grippers  Robot kinematics  Robot sensing systems 
Abstract: A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.


Title: NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor
Key Words: cameras  geophysical image processing  image colour analysis  image sensors  vegetation mapping  vegetation index estimation  Microsoft Kinect V2  vegetation monitoring purposes  ROS point cloud generation tools  active IR camera  active RGB-D sensor technology  RGB camera  NDVI point cloud generator tool  3D NDVI maps  Conferences  Intelligent robots 
Abstract: In this manuscript, a NDVI point cloud generator tool based on low-cost active RGB-D sensor is presented. Taking advantage of currently available ROS point cloud generation tools and RGB-D sensor technology (like Microsoft Kinect), that includes an inbuilt active IR camera and a RGB camera, 3D NDVI maps can be quickly and easily generated for vegetation monitoring purposes. When using low-cost sensors for vegetation index estimation, it is necessary to apply a rigorous methodology for extracting reliable information. In this paper, the methodology for NDVI generation using a low-cost sensor as well as experiments to evaluate its performance is presented. The experiments performed show that it is possible to obtain a reliable NDVI point cloud from a Kinect V2.


Title: Unsupervised Object Proposal Using Depth Boundary Density and Density Uniformity
Key Words: feature extraction  image colour analysis  image texture  learning (artificial intelligence)  object detection  object recognition  RGB-D object proposal methods  robot-computer vision area  bounding box  object recognition  density uniformity  unsupervised object proposal  depth boundary density difference  depth images  overlapping objects  texture objects  RGB images  object region extraction methods  window scoring  Proposals  Computational efficiency  Microsoft Windows  Object detection  Feature extraction  Search problems  Image edge detection 
Abstract: Object proposal that detects candidate bounding boxes of objects in images is an effective way of accelerating object recognition in the robot/computer vision area. We propose an accurate and fast object proposal method using depth images. Existing proposal methods can be roughly divided into two categories: window scoring and object region extraction. The window scoring methods usually have higher efficiency than object region extraction methods. The previous methods using RGB images detect an excessive number of boxes due to edges of texture objects. These methods also may misdetect overlapping objects as one candidate bounding box. To tackle these problems, we propose a novel and effective objectness measure using depth images. The proposed method evaluates objectness by using depth boundary density difference between inner and outer regions of a candidate bounding box. We also consider the uniformity of the outer boundary density in a candidate bounding box to divide overlapping objects into individual candidate bounding boxes. Our reasonable assumption here is that the depth boundary of an object has a closed loop. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging toy-dataset [1] of complex crowded scenes.


Title: LIMO: Lidar-Monocular Visual Odometry
Key Words: cameras  distance measurement  feature extraction  mobile robots  motion estimation  object tracking  optical radar  pose estimation  robot vision  stereo image processing  visual localization  depth extraction algorithm  camera feature tracks  outlier rejection  sensor combination  LIMO  lidar-monocular visual odometry  higher level functionality  autonomous driving  precise motion estimate  powerful algorithms  great majority  binocular imagery  bundle adjustment  LIDAR measurements  Feature extraction  Laser radar  Cameras  Estimation  Three-dimensional displays  Calibration  Visual odometry 
Abstract: Higher level functionality in autonomous driving depends strongly on a precise motion estimate of the vehicle. Powerful algorithms have been developed. However, their great majority focuses on either binocular imagery or pure LIDAR measurements. The promising combination of camera and LIDAR for visual localization has mostly been unattended. In this work we fill this gap, by proposing a depth extraction algorithm from LIDAR measurements for camera feature tracks and estimating motion by robustified keyframe based Bundle Adjustment. Semantic labeling is used for outlier rejection and weighting of vegetation landmarks. The capability of this sensor combination is demonstrated on the competitive KITTI dataset, achieving a placement among the top 15. The code is released to the community.


Title: PCAOT: A Manhattan Point Cloud Registration Method Towards Large Rotation and Small Overlap
Key Words: computational geometry  image registration  iterative methods  principal component analysis  Manhattan world assumption  transformation estimation  overlap estimation  ICP  rotation angle  PCAOT  Manhattan point cloud registration method  robot mapping  iterative closest point  robot localization  principal coordinate alignment with overlap tuning  3D cuboid  Three-dimensional displays  Estimation  Tuning  Iterative closest point algorithm  Mathematical model  Filtering  Task analysis 
Abstract: Point cloud registration is a popular research topic and has been widely used in many tasks, such as robot mapping and localization. It is a challenging problem when the overlap is small, or the rotation is large. The problem has not been well solved by existing methods such as the iterative closest point (ICP) and its variants. In this paper, a novel method named principal coordinate alignment with overlap tuning (PCAOT) is proposed based on the Manhattan world assumption. It solves two key problems together, the transformation estimation and the overlap estimation. The overlap is represented by a 3D cuboid and the transformation is computed only within the overlap region. Instead of finding point correspondence as in traditional methods, we estimate the rotation by principal coordinates alignment, which is faster and less sensitive than ICP and its variants to small overlaps and large rotations. Evaluations demonstrate that our method achieves much better results than the ICP and its variants when the overlap ratio is smaller than 50%, or the rotation angle is larger than 60°. Especially, it is effective when the overlap ratio is less than 30%, or the rotation angle is larger than 90°.


Title: Minimal Construct: Efficient Shortest Path Finding for Mobile Robots in Polygonal Maps
Key Words: collision avoidance  graph theory  mobile robots  navigation  mobile robots  polygonal maps  navigational software  shortest collision-free path  Dijkstra algorithm  visibility graph algorithm  minimal construct  visibility graph-based shortest path algorithms  shortest path finding  A* algorithm  Navigation  Heuristic algorithms  Mobile robots  Software  Complexity theory  Standards 
Abstract: With the advent of polygonal maps finding their way into the navigational software of mobile robots, the Visibility Graph can be used to search for the shortest collision-free path. The nature of the Visibility Graph-based shortest path algorithms is such that first the entire graph is computed in a relatively time-consuming manner. Then, the graph can be searched efficiently any number of times for varying start and target state combinations with the A* or the Dijkstra algorithm. However, real-world environments are typically too dynamic for a map to remain valid for a long time. With the goal of obtaining the shortest path quickly in an ever changing environment, we introduce a rapid path finding algorithm-Minimal Construct-that discovers only a necessary portion of the Visibility Graph around the obstacles that actually get in the way. Collision tests are computed only for lines that seem heuristically promising. This way, shortest paths can be found much faster than with a state-of-the-art Visibility Graph algorithm and as our experiments show, even grid-based A* searches are outperformed in most cases with the added benefit of smoother and shorter paths.


Title: Trajectory Planning for Heterogeneous Robot Teams
Key Words: collision avoidance  graph theory  helicopters  mobile robots  trajectory optimisation (aerospace)  trajectory planning method  heterogeneous mobile robot teams  graph-planning techniques  trajectory optimization  differential drive robots  inter-robot collision constraints  close-proximity flight  rotorcraft  quadrotors  Collision avoidance  Trajectory  Robot kinematics  Mobile robots  Schedules 
Abstract: We describe a trajectory planning method for heterogeneous mobile robot teams in known environments. We consider two core problems that arise with heterogeneous robot teams: asymmetric inter-robot collision constraints and varying dynamic limits. Asymmetric collision constraints are important for close-proximity flight of rotorcraft due to the downwash effect, which complicates spatial coordination. Varying dynamic limits complicate temporal coordination between robots and must be taken into account during planning. Our method builds upon a hybrid planner that combines graph-planning techniques with trajectory optimization and scales well to large homogeneous robot teams. We extend the hybrid planning approach to include the additional spatial and temporal coordination to support heterogeneous teams. Our method scales well with the number of robots and robot types and we demonstrate our approach on a team of 15 physical robots of 4 different types, including quadrotors and differential drive robots.


Title: A Motion Planning Approach for Marsupial Robotic Systems
Key Words: graph theory  mobile robots  multi-robot systems  path planning  free-space regions  topological graph planning  high-level motion plan  low-level path planner  motion planning approach  marsupial robotic systems  automatic coordination  heterogeneous multirobot teams  marsupial-based subset  carrier robots  passenger robots  high-level watershed segmentation  Robot kinematics  Planning  Trajectory  Robot sensing systems  Collision avoidance  Unmanned aerial vehicles 
Abstract: This paper outlines an algorithmic approach for the automatic coordination and planning of heterogeneous multi-robot teams. Specifically, this work addresses the marsupial-based subset of multi-robot teams, where “carrier” robots transport and deploy “passenger” robots. The approach starts with a high-level watershed segmentation of the world to determine the free-space regions accessible by each robot in the team. Topological graph planning then decides the high-level motion plan for each robot between these free-space regions. Finally, a low-level path planner generates optimized, dynamically-feasible trajectories for each robot along the topological path. The performance of the approach is evaluated in simulation and through hardware experiments.


Title: Motion Planning and Goal Assignment for Robot Fleets Using Trajectory Optimization
Key Words: integer programming  mobile robots  multi-robot systems  optimal control  path planning  quadratic programming  mixed integer quadratic programming  autonomous robots  automating fleets  trajectory optimization  robot fleets  fleet-wide boolean decision variables  phase solves  two-phase approach  nonholonomic robots  Optimal Control  fleet management problem  performance criterion  motion planning  goal assignment  Robot kinematics  Collision avoidance  Aerospace electronics  Indexes  Trajectory  Geometry 
Abstract: This paper is concerned with automating fleets of autonomous robots. This involves solving a multitude of problems, including goal assignment, motion planning, and coordination, while maximizing some performance criterion. While methods for solving these sub-problems have been studied, they address only a facet of the overall problem, and make strong assumptions on the use-case, on the environment, or on the robots in the fleet. In this paper, we formulate the overall fleet management problem in terms of Optimal Control. We describe a scheme for solving this problem in the particular case of fleets of non-holonomic robots navigating in an environment with obstacles. The method is based on a two-phase approach, whereby the first phase solves for fleet-wide boolean decision variables via Mixed Integer Quadratic Programming, and the second phase solves for real-valued variables to obtain an optimized set of trajectories for the fleet. Examples showcasing the features of the method are illustrated, and the method is validated experimentally.


Title: Re-Establishing Communication in Teams of Mobile Robots
Key Words: mobile robots  multi-robot systems  optimisation  path planning  probability  tree searching  wireless connection  constrained optimization problem  branch-and-bound approach  locally available information  belief  mobile robots  Task analysis  Robot kinematics  Search problems  Mobile robots  Markov processes 
Abstract: As communication is important for cooperation, teams of mobile robots need a way to re-establish a wireless connection if they get separated. We develop a method for mobile robots to maintain a belief of each other's positions using locally available information. They can use their belief to plan paths with high probabilities of reconnection. This approach also works for subteams cooperatively searching for a robot or group of robots that they would like to reconnect with. The problem is formulated as a constrained optimization problem which is solved using a branch-and-bound approach. We present simulation results showing the effectiveness of this strategy at reconnecting teams of up to five robots and compare the results to two other strategies.


Title: Multi-Agent Planning for Coordinated Robotic Weed Killing
Key Words: agriculture  crops  environmental factors  industrial robots  mobile robots  multi-agent systems  path planning  multiagent planning  coordinated robotic Weed killing  coordinated multiagent weeding  partial environmental information  coordination strategies  weeding performance  autonomous agricultural robots  system performance  Weed World  coordinated weeding policies  realistic weed generation  initial seed bank densities  weeding process  required number  Agriculture  Robot kinematics  Optimization  Immune system  Chemicals  Soil 
Abstract: This work presents a strategy for coordinated multi-agent weeding under conditions of partial environmental information. The goal of this work is to demonstrate the feasibility of coordination strategies for improving the weeding performance of autonomous agricultural robots. We show that, given a sufficient number of agents, the algorithm can successfully weed fields with various initial seed bank densities, even when multiple days are allowed to elapse before weeding commences. Furthermore, the use of coordination between agents is demonstrated to strongly improve system performance as the number of agents increases, enabling the system to eliminate all the weeds in the field, as in the case of full environmental information, when the planner without coordination failed to do so. As a domain to test our algorithms, we have developed an open source simulation environment, Weed World, which allows real-time visualization of coordinated weeding policies, and includes realistic weed generation. In this work, experiments are conducted to determine the required number of agents and their required transit speed, for given initial seed bank densities and varying allowed days before the start of the weeding process.


Title: Intelligent Robotic IoT System (IRIS)Testbed
Key Words: Global Positioning System  intelligent robots  IP networks  middleware  mobile radio  mobile robots  multi-robot systems  personal area networks  protocols  robot vision  SLAM (robots)  wireless LAN  IPv6 network stack  individual robots  system implementation details  Intelligent robotic IoT system  modular source testbed  portable source testbed  open-source testbed  robotic wireless network research  IRIS  Time Difference of Arrival localization system  Time Difference of Arrival localization system  static global positioning system  multirobot testbeds  multirobot testbeds  Programmable Wireless Communication Stack  scalable source testbed  lightweight publish-subscribe overlay protocol  ROMANO  modular architecture  Iris recognition  Iris  Robot kinematics  Protocols  Transceivers  Ultrasonic imaging 
Abstract: We present the Intelligent Robotic IoT System (IRIS), a modular, portable, scalable, and open-source testbed for robotic wireless network research. There are two key features that separate IRIS from most of the state-of-the-art multi-robot testbeds. (1)Portability: IRIS does not require a costly static global positioning system such as a VICON system nor time-intensive vision-based SLAM for its operation. Designed with an inexpensive Time Difference of Arrival (TDoA)localization system with centimeter level accuracy, the IRIS testbed can be deployed in an arbitrary uncontrolled environment in a matter of minutes. (2)Programmable Wireless Communication Stack: IRIS comes with a modular programmable low-power IEEE 802.15.4 radio and IPv6 network stack on each node. For the ease of administrative control and communication, we also developed a lightweight publish-subscribe overlay protocol called ROMANO that is used for bootstrapping the robots (also referred to as the IRISbots), collecting statistics, and direct control of individual robots, if needed. We detail the modular architecture of the IRIS testbed design along with the system implementation details and localization performance statistics.


Title: SEAR: A Polynomial- Time Multi-Robot Path Planning Algorithm with Expected Constant-Factor Optimality Guarantee
Key Words: computational complexity  graph theory  mobile robots  multi-robot systems  optimisation  path planning  statistical distributions  polynomial-time multirobot path planning algorithm  expected constant-factor optimality guarantee  arbitrary initial goal arrangements  continuous 2D domains  continuous 3D domains  uniformly randomly distributed  microMVP platform  nonholonomic robots  near-optimal solutions  nonpolynomial time  initial goal configuration footprints  constant-factor expansion  Robots  Path planning  Collision avoidance  Labeling  Routing  Pipelines  Planning 
Abstract: We study the labeled multi-robot path planning problem in continuous 2D and 3D domains in the absence of obstacles where robots must not collide with each other. For an arbitrary number of robots in arbitrary initial and goal arrangements, we derive a polynomial time, complete algorithm that produces solutions with constant-factor optimality guarantees on both makespan and distance optimality, in expectation, under the assumption that the robot labels are uniformly randomly distributed. Our algorithm only requires a small constant-factor expansion of the initial and goal configuration footprints for solving the problem, i.e., the problem can be solved in a fairly small bounded region. Beside theoretical guarantees, we present a thorough computational evaluation of the proposed solution. In addition to the baseline implementation, adapting an effective (but non-polynomial time) routing subroutine, we also provide a highly efficient implementation that quickly computes near-optimal solutions. Hardware experiments on the microMVP platform composed of non-holonomic robots confirms the practical applicability of our algorithmic pipeline.


Title: Towards Peak Torque Minimization for Modular Self-Folding Robots
Key Words: mobile robots  torque  trees (mathematics)  two-dimensional patterns  robotic inertia  modular architecture  minimal bounding box  robotic base selection  modular origami robot  modular robotic systems  peak torque minimization  modular self-folding robots  capacitated spanning tree heuristic algorithms  Mori  Robots  Torque  Planning  Shape  Heuristic algorithms  Computer architecture  Force 
Abstract: Modular self-folding robots are versatile systems that can change their own shape from two-dimensional patterns at instant commands. This reconfigurability is commonly restrained by power limitation in autonomous environments, The robotic systems with insufficient torque may lead to inaccurate movements and even transformation failures. This paper presents methodology for optimized reconfiguration planning with torque limitation in modular self-folding robots. We determine reconfiguration schemes with optimal initial pattern and robotic base that result in minimal peak torque by minimizing robotic inertia of the modular architecture. We present minimal bounding box and capacitated spanning tree heuristic algorithms to generate optimal initial patterns and propose 3 heuristic rules for robotic base selection. Our approach is demonstrated in simulation by applying the algorithms to the robotic concept of Mori, a modular origami robot. The simulation results show that the proposed algorithms yield reconfiguration schemes with low peak torque, thereby appropriate for real-time applications in modular robotic systems.


Title: Passive Nonlinear Impedance Control for Port-Hamiltonian Systems
Key Words: closed loop systems  control system synthesis  feedback  nonlinear control systems  numerical analysis  controlled system  passive nonlinear impedance control  port-Hamiltonian system  nonholonomic system  fully actuated mechanical systems  closed loop system  numerical simulation  two-wheeled vehicle  feedback controller  generalized canonical transformation  Impedance  Control systems  Mechanical systems  Symmetric matrices  Man-machine systems  Mathematical model  Robots 
Abstract: This paper describes a procedure to design a passive nonlinear impedance control for port-Hamiltonian systems. By expressing the system with the port-Hamiltonian system, the proposed method can be applied to the nonholonomic system as well as fully actuated mechanical systems. The feedback controller for nonlinear impedance control is acquired by utilizing the results of generalized canonical transformation for port-Hamiltonian system. In addition, we investigate the passivity of the closed loop system and discuss the characteristics of the controlled system. A numerical simulation of two-wheeled vehicle shows the effectiveness of the proposed control method.


Title: Riding and Speed Governing for Parallel Two-Wheeled Scooter Based on Sequential Online Learning Control by Humanoid Robot
Key Words: cascade control  closed loop systems  control engineering computing  humanoid robots  learning (artificial intelligence)  mobile robots  motion control  motorcycles  torque control  velocity control  wheels  foot torque control  speed governing control  parallel two-wheeled scooter  sequential online tuning  controller gains  sequential online learning control method  SGD-based open-loop learning control  HRP2-JSK humanoid robot  cascade connection  minibatch-based closed-loop learning control  Motorcycles  Tuning  Foot  Humanoid robots  Damping  Control systems  Torque 
Abstract: The sequential online tuning for controller gains is required for the continuous action of the riding into parallel two-wheeled scooter and the speed governing after riding by humanoid robot. The implemented controllers are different between the riding and the speed governing, and these tuning strategies are also different. In particular, the riding requires the immediate tuning in the short riding phase and the speed governing requires the accurate tuning to regulate the speed of humanoid robot. To the above requirements, this paper proposes the Sequential Online Learning Control (SOLC)method composed of the cascade connection of SGD-based open-loop Learning Control (SLC)and Mini-batch-based closed-loop Learning Control (MLC). SLC contributes the damping gain online tuning for the foot torque control during execution of riding, and MLC contributes the PID gains online tuning for the speed governing control. Finally, we show the validity of SOLC through the sequential experiment of riding and speed governing for parallel two-wheeled scooter by life-sized humanoid robot HRP2-JSK.


Title: Dynamic Modelling and Motion Planning for the Nonprehensile Manipulation and Locomotion Tasks of the Quadruped Rsbot*This work is supported by the project of Robotics Innovation Based on Advanced Materials under Ritsumeikan Global Innovation Research Organization (R-GIRO)
Key Words: legged locomotion  manipulator dynamics  motion control  path planning  Drive Mode  Inchworm Mode  Scoot Mode  universal model  dynamic equation  contact force constraints  system state variables  system state paths  robot motions  nonprehensile manipulation  locomotion tasks  quadruped robot  dynamic modelling  motion planning method  state acceleration constraints  Robot kinematics  Legged locomotion  Force  Friction  Mathematical model  Planning 
Abstract: This paper presents the dynamic modelling and motion planning method for a quadruped robot that uses its legs for nonprehensile manipulation as well as locomotion. Three different working modes named Drive Mode, Inchworm Mode and Scoot Mode are proposed to enable the robot to move forward together with the object. We firstly introduce a universal model for these modes and deduce its dynamic equation. Then the contact force constraints are combined and mapped to the system state variables. Based on the acquired state acceleration constraints, the motion planning problem can be solved by designing system state paths in the phase space. After that, we described the mathematical problems within the three working modes and generate the robot motions accordingly. Finally, experimental results obtained through simulations and physical tests are reported to demonstrate the effectiveness of our method.


Title: Fuzzy-Based Feedback Control of a Tip-Mounted Module for Robot-Assisted Endoscopy
Key Words: actuators  biomedical optical imaging  cancer  closed loop systems  dexterous manipulators  endoscopes  feedback  medical robotics  position control  surgery  telerobotics  three-term control  intestinal perforation  sensory feedback  tip-mounted robotic system  commercially-available endoscopic tools  feedback sensing  on-board actuators  tool motion  endoscope motion  alternative high-energy-density actuation strategies  monolithic circuit-inspired manufacturing processes  printed-circuit-inspired manufacturing processes  distally-mounted module  proximal motor package  fuzzy-tuned PID/PWM controller  closed-loop position-controlled trajectory execution  distal loop closure  endoscope-mounted robotic module  proximal actuation  controller performance  feedback control  robot-assisted endoscopy  nascent endoscopic therapeutic procedures  endoscopic submucosal dissection  mid-size cancerous neoplasia  gastrointestinal tract  distal dexterity  cognitive loading  tip-mounted module  realtime rate-based teleoperation  endoscopic module for on-demand robotic assistance  Robot sensing systems  Actuators  Tools  Endoscopes  Cooling 
Abstract: Nascent endoscopic therapeutic procedures, such as endoscopic submucosal dissection, enable unparalleled access to and removal of mid-size cancerous neoplasia from within the gastrointestinal tract. However, the remote locations of these lesions often incur substantial distal dexterity which imparts appreciable cognitive loading on the clinician and opens up the possibility of adverse events such as intestinal perforation due to limited dexterity and a lack of sensory feedback. In this work, we introduce a mm-scale, tip-mounted robotic system, EndoMODRA (Endoscopic Module for On-Demand Robotic Assistance), which interfaces with commercially-available endoscopic tools and provides additional dexterity and feedback sensing using on-board actuators and sensors, decoupling tool motion from endoscope motion. Leveraging alternative high-energy-density actuation strategies and monolithic, printed-circuit-inspired manufacturing processes, all actuation and sensing is fully contained within the distally-mounted module, obviating the need for a continuous mechanical transmission to a proximal motor package. We develop a fuzzy-tuned PID/PWM controller for closing the loop distally to enable closed-loop position-controlled trajectory execution using onboard actuation and sensing, realizing fully -distal loop closure in an endoscope-mounted robotic module with no proximal actuation or sensing component. Controller performance is validated on a fully-integrated module with on-board sensing, demonstrating the ability to execute pre-determined trajectories as well as real-time rate-based teleoperation.


Title: A Real- Time Solver for Time-Optimal Control of Omnidirectional Robots with Bounded Acceleration
Key Words: approximation theory  boundary-value problems  closed loop systems  maximum principle  mobile robots  optimisation  bounded acceleration  boundary value problem  optimization problem  parameterized control space  two-stage optimal control solver  real- time solver  time-optimal control  omnidirectional robots  TOC-ORBA problem  approximate solutions  exact solutions  Pontryagin's maximum principle  closed loop controller  TSOCS  Acceleration  Robot kinematics  Trajectory  Mobile robots  Optimal control  Real-time systems 
Abstract: We are interested in the problem of time-optimal control of omnidirectional robots with bounded acceleration (TOC-ORBA). While there exist approximate solutions for such problems, and exact solutions with unbounded acceleration, exact solvers to the TOC-ORBA problem have remained elusive until now. In this paper, we present a real-time solver for true time-optimal control of omnidirectional robots with bounded acceleration. We first derive the general parameterized form of the solution to the TOC-ORBA problem by application of Pontryagin's maximum principle. We then frame the boundary value problem of TOC-ORBA as an optimization problem over the parameterized control space. To overcome local minima and poor initial guesses to the optimization problem, we introduce a two-stage optimal control solver (TSOCS): The first stage computes an upper bound to the total time for the TOC-ORBA problem and holds the time constant while optimizing the parameters of the trajectory to approach the boundary value conditions. The second stage uses the parameters found by the first stage, and relaxes the constraint on the total time to solve for the parameters of the complete TOC-ORBA problem. Furthermore, we implement TSOCS as a closed loop controller to overcome actuation errors on real robots in realtime. We empirically demonstrate the effectiveness of TSOCS in simulation and on real robots, showing that 1) it runs in real time, generating solutions in less than 0.5ms on average; 2) it generates faster trajectories compared to an approximate solver; and 3) it is able to solve TOC-ORBA problems with nonzero final velocities that were previously unsolvable in real-time.


Title: A Variable Degree-of-Freedom and Self-Sensing Soft Bending Actuator Based on Conductive Liquid Metal and Thermoplastic Polymer Composites
Key Words: grippers  liquid metals  plastic deformation  pneumatic actuators  polymers  shape memory effects  self-sensing soft bending actuator  conductive liquid metal  thermoplastic polymer composites  thermoplastic shape memory epoxy  bending strain  pneumatic actuators  contact force  Actuators  Robot sensing systems  Force  Resistance  Force sensors  Shape  Yarn 
Abstract: This paper presents a soft actuator embedded with conductive liquid metal and shape memory epoxy (SME) which function together to enable self-sensing, tunable mechanical degrees of freedom (DoF), and variable stiffness. We embedded thermoplastic shape memory epoxy in the bottom portion of the actuator. Different sections of the SME could be selectively softened by an implanted conductive silver yarn located at different positions. When an electric current passes through the conductive silver yarn, it induces a phase transition that changes the epoxy from stiff state to compliant state. Each section of SME could be softened within 5 s by applying a current of 200 mA to the silver yarn. To acquire the strain curvature, eGaIn was infused into a microchannel surrounding the chambers of the soft actuator. A spiral-shaped eGaIn sensor was also attached to the tip of the actuator to perceive the contact with reliable dynamic force response. Systematic experiments were performed to characterize the stiffness, tunable DoF, and sensing property. We show the ability of the soft composite actuator to support a weight of 200g at the tip (as a cantilever) while maintaining the shape and the ability to recover its original shape after large bending deformation. In particular, seven different motion patterns could be achieved under the same pneumatic pressure of the actuator due to selectively heating the SME sections. A gripper which was fabricated by assembling two actuators to a base was able to grasp the weight up to 56 times of a single actuator through an appropriate motion pattern. For demonstration purposes, the gripper was used to grasp various objects by adjusting the DoF and stiffness with real-time feedback of the bending strain and the contact force.


Title: A New Manufacturing Process for Soft Robots and Soft/Rigid Hybrid Robots
Key Words: adhesion  adhesives  design engineering  inflatable structures  robots  textiles  multichambered inflatable structures  thermal adhesive film  heat press  bond strength  soft-rigid hybrid robotic arm  Conferences  Intelligent robots 
Abstract: We present a novel manufacturing process for creating monolithic, multi-chambered inflatable structures including both soft and rigid components. Specifically, our process involves stacking layers of textiles or plastics and thermal adhesive film, then bonding the structure with a heat press or in an oven. Several different ways of arranging textiles and thermal adhesive film in order to achieve airtight structures are presented. Since this process only uses materials that bend, but do not stretch, it permits the easy inclusion of rigid structures such as circuit boards, plates that constrain inflatable chambers to bend in specified locations, and rigid pieces that enable sections of a robot to be connected in a modular fashion. Additionally, the process permits folding layers before their assembly, leading to more complex geometries. We present three different possible seam types, and enumerate the different types of corners that can be constructed without leaking. We present measurements of the ability of these structures to support pressure and measurements of the strength of bonds between textiles and other materials. Finally, we present two examples of robots constructed using this manufacturing method, including a hybrid soft/rigid robotic arm and a soft robot that can roll along the ground.


Title: Magnetic-Field-Inspired Navigation for Soft Continuum Manipulator*This work was supported in part by King's College London, the EPSRC in the framework of the NCNR (National Centre for Nuclear Robotics) project (EP/R02572X/1), the STIFF-FLOP project grant from the European Communities Seventh Framework Programme under grant agreement 287728, and the Indonesia Endowment Fund for Education, Ministry of Finance Republic of Indonesia.
Key Words: collision avoidance  manipulators  mobile robots  navigation  path planning  2-segment soft continuum arm  unknown environments  reactive navigation method  magnetic fields  soft continuum manipulator  magnetic-field-inspired navigation  Manipulators  Navigation  Force  Wires  Collision avoidance  Service robots 
Abstract: Taking inspiration from the properties of magnetic fields, we propose a reactive navigation method for soft continuum manipulators operating in unknown environments. The proposed navigation method outperforms previous works since it is able to successfully achieve collision-free movements towards the goal in environments with convex obstacles without relying on a priori information of the obstacles' shapes and locations. Simulations for the kinematic model of a soft continuum manipulator and preliminary experiments with a 2-segments soft continuum arm are performed, showing promising results and the potential for our approach to be applied widely.


Title: Real-Time Shape Estimation of an Elastic Rod Using a Robot Manipulator Equipped with a Sense of Force
Key Words: elasticity  end effectors  force control  manipulators  position control  rods (structures)  time shape estimation  robot manipulator equipped  real-time method  optical sensing devices  force/torque information  discretized Kirchhoff elastic rod model  three-dimensional shape  force information  manipulator end-effector  elastic strip  typical elastic rod  average calculation time  strip shape  size 142.0 mm  Shape  Manipulators  Gravity  Torque  Estimation  Sensors 
Abstract: This paper proposes a real-time method for estimating the shape of an elastic rod using a robot manipulator equipped with a sense of force. The proposed method does not use optical sensing devices, such as cameras or lasers, but relies only upon the sense of force in the manipulator. In the proposed method, the deformation of an elastic rod is calculated from the obtained force/torque information using the discretized Kirchhoff elastic rod model, and the three-dimensional shape of the rod is then estimated. Furthermore, by integrating the force information with the orientation of the manipulator end-effector, the proposed method can evaluate the effect of gravity on the shape estimation accurately. Experiments were carried out to verify the proposed method, where a thin elastic strip was employed as a typical elastic rod, attached to the end-effector of the robot manipulator, bent and twisted into various shapes. The results show that the proposed method that compensates for gravity is better than a method without gravity compensation, and it estimated the 142 mm length strip shape with a position error no greater than 7.76 mm and an average calculation time of 4.24 ms.


Title: FOCS: Planning by Fusion of Optimal Control & Search and its Application to Navigation
Key Words: graph theory  optimal control  path planning  car-like vehicle  Hamilton-Jacobi-Bellman equation  FOCS  minimum-time path  returned path  sub-optimality  path planning  Search-based Planning  Optimal Control & Search  Planning  Optimal control  Robots  Optimized production technology  Heuristic algorithms  Dynamic programming  Search problems 
Abstract: Both Optimal Control and Search-based Planning are used extensively for path planning and have their own set of advantages and disadvantages. In this paper, we propose an algorithm FOCS (Fusion of Optimal Control and Search) that combines these two classes of approaches together. FOCS finds a path exploiting the advantages of both approaches while providing a bound on the sub-optimality of its solution. The returned path is a concatenation of the path found in the implicit graph constructed by search and the path generated by following the negative gradient of the value function obtained as a solution of the Hamilton-Jacobi-Bellman equation. We analyze the algorithm and illustrate its effectiveness in finding a minimum-time path for a car-like vehicle in different environments.


Title: Quotient-Space Motion Planning
Key Words: mobile robots  motion control  path planning  quotient-space motion planning  OMPL  robot  Quotient-space roadMap Planner  roadmap-based motion planning algorithm  nested quotient-space decomposition  open motion planning library  Planning  Manipulators  Runtime  Visualization  Probabilistic logic  Manifolds 
Abstract: A motion planning algorithm computes the motion of a robot by computing a path through its configuration space. To improve the runtime of motion planning algorithms, we propose to nest robots in each other, creating a nested quotient-space decomposition of the configuration space. Based on this decomposition we define a new roadmap-based motion planning algorithm called the Quotient-space roadMap Planner (QMP). The algorithm starts growing a graph on the lowest dimensional quotient space, switches to the next quotient space once a valid path has been found, and keeps updating the graphs on each quotient space simultaneously until a valid path in the configuration space has been found. We show that this algorithm is probabilistically complete and outperforms a set of state-of-the-art algorithms implemented in the open motion planning library (OMPL).


Title: Computing a Collision-Free Path Using the Monogenic Scale Space
Key Words: collision avoidance  Laplace equations  mobile robots  multi-robot systems  position control  static obstacles  dynamic obstacles  mobile robot  safe path  goal position  Laplace equation  collision-free path  rectangular bounded domain  monogenic scale space  environment map  nonconvex environments  functionalities  Kernel  Laplace equations  Mathematical model  Mobile robots  Magnetic domains  Magnetic resonance imaging 
Abstract: Mobile robots have been used for various purposes with different functionalities which require them to freely move in environments containing both static and dynamic obstacles to accomplish given tasks. One of the most relevant capabilities in terms of navigating a mobile robot in such an environment is to find a safe path to a goal position. This paper shows that there exists an accurate solution to the Laplace equation which allows finding a collision-free path and that it can be efficiently calculated for a rectangular bounded domain such as a map which is represented as an image. This is accomplished by the use of the monogenic scale space resulting in a vector field which describes the attracting and repelling forces from the obstacles and the goal. The method is shown to work in reasonably convex domains and by the use of tessellation of the environment map for non-convex environments.


Title: Automatic Parameter Tuning of Motion Planning Algorithms
Key Words: Bayes methods  manipulators  mobile robots  motion control  optimisation  path planning  sampling methods  random sampling  AUC-Bandit  random forest  motion planning algorithms  RRT-connect  table-top-reaching scenario  BKPIECE  random scenarios  parameter configurations  automatic parameter tuning  motion planning  default parameter values  Bayesian optimisation  KUKA LWR robotic arm  Planning  Tuning  Optimization  Bayes methods  Manipulators  Mathematical model 
Abstract: Motion planning algorithms attempt to find a good compromise between planning time and quality of solution. Due to their heuristic nature, they are typically configured with several parameters. In this paper we demonstrate that, in many scenarios, the widely used default parameter values are not ideal. However, finding the best parameters to optimise some metric(s) is not trivial because the size of the parameter space can be large. We evaluate and compare the efficiency of four different methods (i.e. random sampling, AUC-Bandit, random forest, and bayesian optimisation) to tune the parameters of two motion planning algorithms, BKPIECE and RRT-connect. We present a table-top-reaching scenario where the seven degrees-of-freedom KUKA LWR robotic arm has to move from an initial to a goal pose in the presence of several objects in the environment. We show that the best methods for BKPIECE (AUC-Bandit) and RRT-Connect (random forest) improve the performance by 4.5x and 1.26x on average respectively. Then, we generate a set of random scenarios of increasing complexity, and we observe that optimal parameters found in simple environments perform well in more complex scenarios. Finally, we find that the time required to evaluate parameter configurations can be reduced by more than 2/3 with low error. Overall, our results demonstrate that for a variety of motion planning problems it is possible to find solutions that significantly improve the performance over default configurations while requiring very reasonable computation times.


Title: Perception-Driven Sparse Graphs for Optimal Motion Planning
Key Words: collision avoidance  graph theory  mobile robots  optimal control  optimisation  robot vision  trajectory control  motion plan generation  planning subproblem  mapping subproblem  optimal motion planning  perception-driven sparse graphs  optimal trajectory  plan graphs  visual sensors  Planning  Trajectory  Robot sensing systems  Collision avoidance  Heuristic algorithms 
Abstract: Most existing motion planning algorithms assume that a map (of some quality) is fully determined prior to generating a motion plan. In many emerging applications of robotics, e.g., fast-moving agile aerial robots with constrained embedded computational platforms and visual sensors, dense maps of the world are not immediately available, and they are computationally expensive to construct. We propose a new algorithm for generating plan graphs which couples the perception and motion planning processes for computational efficiency. In a nutshell, the proposed algorithm iteratively switches between the planning sub-problem and the mapping sub-problem, each updating based on the other until a valid trajectory is found. The resulting trajectory retains a provable property of providing an optimal trajectory with respect to the full (unmapped) environment, while utilizing only a fraction of the sensing data in computational experiments.


Title: Social Cohesion in Autonomous Driving
Key Words: automobiles  control engineering computing  mobile robots  road safety  road traffic  statistical analysis  traffic information systems  social cohesion  autonomous driving  autonomous car  perception issues  incorrect dynamics models  obscure rules  human traffic systems  exact failure mode  socially cohesive cars  nearby human drivers  socially acceptable behavior  Automobiles  Roads  Autonomous automobiles  Trajectory  Autonomous vehicles 
Abstract: Autonomous cars can perform poorly for many reasons. They may have perception issues, incorrect dynamics models, be unaware of obscure rules of human traffic systems, or follow certain rules too conservatively. Regardless of the exact failure mode of the car, often human drivers around the car are behaving correctly. For example, even if the car does not know that it should pull over when an ambulance races by, other humans on the road will know and will pull over. We propose to make socially cohesive cars that leverage the behavior of nearby human drivers to act in ways that are safer and more socially acceptable. The simple intuition behind our algorithm is that if all the humans are consistently behaving in a particular way, then the autonomous car probably should too. We analyze the performance of our algorithm in a variety of scenarios and conduct a user study to assess people's attitudes towards socially cohesive cars. We find that people are surprisingly tolerant of mistakes that cohesive cars might make in order to get the benefits of driving in a car with a safer, or even just more socially acceptable behavior.


Title: Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization
Key Words: human-robot interaction  iterative methods  learning (artificial intelligence)  mobile robots  Pareto optimisation  path planning  nonlinear multiobjective optimization  socially assistive robots  complex environments  stochastic human environments  subtle social norms  socially-aware navigation  multiobjective optimization tool  PaC-cET  nonlinear human navigation behavior  autonomously-sensed distance-based features  social costs  finely-tuned linear combination  optimized future trajectory point  PaCcET-based trajectory planner  human-robot interaction community  Pareto concavity elimination transformation  model-based approaches  Navigation  Trajectory  Optimization  Robot sensing systems  Reinforcement learning 
Abstract: For socially assistive robots (SAR)to be accepted into complex and stochastic human environments, it is important to account for subtle social norms. In this paper, we propose a novel approach to socially-aware navigation (SAN)which garnered an immense interest in the Human-Robot Interaction (HRI)community. We use a multi-objective optimization tool called the Pareto Concavity Elimination Transformation (PaC-cET)to capture the non-linear human navigation behavior, a novel contribution to the community. A candidate point on a trajectory is scored (1)for its progress towards the goal, and (2)based on autonomously-sensed distance-based features that capture the social norms and associated social costs. Rather than use a finely-tuned linear combination of these costs, we use PaCcET to select an optimized future trajectory point, associated with a non-linear combination of the costs. Existing research in this domain concentrates on geometric reasoning, model-based, and learning approaches, which have their own pros and cons. This approach is distinct from prior work in this area. We showed in a simulation that the PaCcET-based trajectory planner not only is able to avoid collisions and reach the intended destination in static and dynamic environments but also considers a human's personal space i.e. rules of proxemics in the trajectory selection process.


Title: Ladder Climbing with a Snake Robot
Key Words: gait analysis  legged locomotion  mobile robots  motion control  gait design method  ladder climbing method  snake robot  Snake robots  Shape  Propulsion  Modeling  Mathematical model 
Abstract: This paper presents a method that allows a snake robot to climb a ladder. We propose a ladder climbing method for a snake robot that has a smooth surface shape. We design a novel gait for the snake using a gait design method that configures the target form of the snake robot by connecting simple shapes. The climbing motion is executed via shift control and the corresponding motion required to catch the next step on the ladder. In addition, we developed a snake robot that has a smooth exterior body surface through construction of pectinate-shaped parts of the links. We demonstrated the effectiveness of both the proposed gait and the design of the snake robot experimentally.


Title: Modeling of Robotic Fish Propelled by a Servo/IPMC Hybrid Tail
Key Words: actuators  biomimetics  electroactive polymer actuators  mobile robots  motion control  muscle  propulsion  robot dynamics  servomotors  steering systems  IPMC soft actuator  two-link tail motion dynamics  body motion dynamics  servo motor  propelled fluid  actuation dynamics  ionic polymer-metal composite artificial muscle  servo-IPMC hybrid tail  flapping motion  robotic fish propulsion  steering system  turning speed  Fish  Servomotors  Dynamics  Actuators  Two dimensional displays  Robot sensing systems 
Abstract: This paper presents modeling of robotic fish propelled by a hybrid tail with Servo and IPMC actuated two joints. The first joint is driven by a servo motor, which generates flapping motion for main propulsion. The second joint is actuated by a soft actuator, or ionic polymer-metal composite (IPMC) artificial muscle, which directs the propelled fluid for steering. A dynamic model is developed to capture the 2D motion dynamics of the robotic fish. The model fully captures the actuation dynamics of the IPMC soft actuator, two-link tail motion dynamics, and body motion dynamics. Experimental results have shown that the robotic fish is capable of swimming forward (up to 0.45 body length/second) and turning left and right (up to 40 degree/sec) with a small turning radius (less than half a body length). Finally, the dynamic model has been validated with experimental data, in terms of steady-state forward speed and turning speed versus the flapping frequency.


Title: Blade-Type Crawler Capable of Running on the Surface of Water as Bio-Inspired by a Basilisk Lizard
Key Words: blades  legged locomotion  motion control  robot dynamics  hard-to-reach-locations  water surface  basilisk lizard  blade-type crawler robot  terrain adaptability  Crawlers  Blades  Wheels  Rough surfaces  Surface roughness  Legged locomotion 
Abstract: For unmanned rescue, observation, and/or research, vehicles with high terrain adaptability, high speed, and high reliability are needed to reach hard-to-reach-locations. In order to extend the areas that can be explored, we propose a method and a robot capable of running on the surface of water without having to bypass the puddles and streams that exist on uneven terrain. The method that enables the robot to run on the water surface is bio-inspired by the basilisk lizard that can walk on the surface of water. We developed a blade-type crawler robot with a simple and reliable mechanism, capable of traversing uneven terrain at high speed. The robot with the method was tested on a real water surface and the result confirmed the ability of the robot to run on the water surface.


Title: Bio-Inspired Design of a Gliding-Walking Multi-Modal Robot
Key Words: aerospace robotics  design engineering  legged locomotion  Pteromyini  multimodal robot gliding  multimodal robot walking  multimodal locomotion robot  regulated motor torques  robot design  flexible membrane  terrestrial locomotion  aerial locomotion  flying squirrel  bio-inspired design  Legged locomotion  Aerodynamics  Muscles  Drag  Stability analysis  Thermal stability 
Abstract: Versatile multi-modal robots are advantageous for their wider operational environments. By taking design principles from observation of Pteromyini, commonly known as the flying squirrel, which shows balanced performances in both aerial and terrestrial locomotion, a novel robotic platform with the ability of gliding and walking is designed. The flexible membrane and gliding method of Pteromyini have been applied to the robot design. The legs of the robot were optimized to perform with regulated motor torques in both walking and gliding. The robot glided with an average gliding ratio of 1.88 and controlled its angle-of-attack for slowing down to land safely. The robot was able to walk utilizing different gait patterns. These results demonstrated our robot's balanced multi-modal locomotion of gliding and walking.


Title: Design of Lizard-Inspired Robot with Lateral Body Motion
Key Words: legged locomotion  motion control  robot dynamics  bipedal running  4-bar mechanism  hind leg  revolute joints  dynamic model  lizard-inspired robot  lateral body motion  Legged locomotion  Dynamics  Foot  Atmospheric modeling  Force  Mathematical model 
Abstract: A new lizard-inspired robot is presented in this paper, which enables to maintain its moving direction by lateral body motions even during high-speed bipedal running. First, a dynamic model for lizard-inspired robot is derived to simulate the lateral body motion of real lizard. Based upon the simulation using dynamic model, the lizard-inspired robot is tactfully built so that its hind leg is optimally designed on a 4-bar mechanism and its body is simplified to consist of two body links and a tail connected by two revolute joints. The experiments verify that the proposed robot can maintain its moving direction via proper lateral motions during high-speed bipedal running similar to that of real lizard.


Title: Natural Dynamics Exploitation of Dynamic Soaring: Towards Bio-Inspired and Energy Efficient Flying Locomotion
Key Words: biomimetics  energy conservation  gait analysis  legged locomotion  motion control  robot dynamics  robust control  trajectory control  energy efficient flying locomotion  flying robots  robust gaits  albatross dynamic soaring  biological perspectives  trajectory control  mechanical energy regulation  bio-inspired locomotion  seabirds  stability  Mechanical energy  Aerodynamics  Trajectory  Mathematical model  Birds  Robots  Bio-inspired locomotion  Energy efficiency  Natural dynamics exploitation  Dynamic soaring  Cyclic tasks 
Abstract: Albatross has an energy efficient flying pattern (dynamic soaring) among seabirds. This interesting point encourages us to exploit its flying natural dynamics so as to control the flying robots on energy efficient and robust gaits. In doing so, we study the albatross dynamic soaring from analytical and biological perspectives and realize that to generate the dynamic soaring instead of trajectory control, the mechanical energy should be regulated. Accordingly, the control objective is set to mechanical energy regulation, and the bank angle and lift coefficient are computed to satisfy this objective. The presented method is simulated on a standard albatross model and generates two different types of dynamic soaring; O-shaped and a-shaped patterns. In addition, by means of simulations, it is investigated that the presented method is robust in face of variations in initial conditions and unexpected disturbances in the environment's model; i.e., they cannot disturb the stability and cyclic behavior of the system. Moreover, the simulation results are compared with pieces of natural evidence from albatross and interesting similarities are observed.


Title: Development of High-Speed Type Peristaltic Crawling Robot for Long-Distance and Complex-Line Sewer Pipe Inspection
Key Words: electroactive polymer actuators  inspection  mobile robots  pipelines  sanitary engineering  sewer pipe inspection  locomotion  artificial muscle fastening  high-speed type peristaltic crawling robot  Muscles  Cameras  Robot vision systems  Mathematical model  Inspection  Contracts 
Abstract: Currently, serious accidents are caused frequently by the aging of sewer pipes. Therefore, to inspect sewer pipes, we developed a peristaltic crawling robot that reproduces the locomotion of an earthworm. This robot can drive for more than 100m, and it can be used for the maintenance of sewer pipes (100A pipes). However, the speed of the robot is low. There are two causes. First, the units of the previous robot have steps of artificial muscle fastening. These steps increase the diameter of the artificial muscles. A smaller diameter of the artificial muscles is advantageous for the speed of the robot inside the pipes. Second, the previous robot has slow air response. In this study, we used large-sized solenoid valves to overcome this drawback.


Title: Learning and Generation of Actions from Teleoperation for Domestic Service Robots*This work was supported by JST, CREST
Key Words: Gaussian processes  hidden Markov models  home automation  intelligent robots  mobile robots  motion control  service robots  telerobotics  autonomous household chores  body motions  object-dependent Gaussian process  domestic household chores  domestic service robots  motion primitives  teleoperation  motion learning  reference-point Gaussian process  hidden semiMarkov model  Task analysis  Trajectory  Motion segmentation  Service robots  End effectors 
Abstract: In this paper, we propose a method for motion learning aimed at the execution of autonomous household chores by service robots in real environments. For robots to act autonomously in a real environment, it is necessary to define the appropriate actions for the environment. However, it is difficult to define these actions manually. Therefore, body motions that are common to multiple actions are defined as motion primitives. Complex actions can then be learned by combining these motion primitives. For learning motion primitives, we propose a reference-point and object-dependent Gaussian process hidden semi-Markov model (RPOD-GP-HSMM). For verification, a robot is teleoperated to perform the actions included in several domestic household chores. The robot then learns the associated motion primitives from the robot's body information and object information.


Title: Proxemics and Approach Evaluation by Service Robot Based on User Behavior in Domestic Environment
Key Words: control engineering computing  fuzzy reasoning  human-robot interaction  intelligent robots  interactive systems  service robots  user behavior  intelligent service robots  human-friendly interactive features  MIRob platform  fuzzy interference system  domestic environment  proxemics  Service robots  Robot sensing systems  Navigation  Robot kinematics  Wrist  Task analysis  Proxemics  Human behavior  Human-robot interaction  Service robots  Human-centered robotics 
Abstract: Intelligent service robots are used at a significant level to uplift the living standards of domestic users. These robots are expected to possess human-friendly interactive features. Service robots should be able to provide a variety of tasks to support independent living of users in domestic environments. Therefore, a service robot often needs to approach users to execute these services and the approach toward the users should be human friendly. In order to achieve this, proxemics planner of a service robot should be cable of deciding the approaching proxemics based on user behavior. This paper proposes a method to decide the approaching proxemics based on the behavior of the user. A fuzzy interference system has been designed to decide the proxemics based on the user behavior identified through body parameters. This leads to an effective interaction mechanism initiated by a robot in such a way that the approaching scenario looks more humanlike. The proposed concept has been implemented on MIRob platform and experiments were conducted in an artificially created domestic environment. The experimental results of the proposed system have been compared with results of a human study to evaluate the performance of the system.


Title: Robot Approaching and Engaging People in a Human-Robot Companion Framework
Key Words: gradient methods  human-robot interaction  path planning  encounter point  human-robot group  user study  ESFM  extended social force model  dynamic environment  navigation behaviour  human-robot companion framework  gradient descent method  Robots  Force  Task analysis  Dynamics  Measurement  Collision avoidance  Navigation 
Abstract: This paper presents a new model to make robots capable of approaching and engaging people with a human-like behavior, while they are walking in a side-by-side formation with a person. This method extends our previous work [1], which allows the robot to adapt its navigation behaviour according to the person being accompanied and the dynamic environment. In the current work, the robot is able to predict the best encounter point between the human-robot group and the approached person. Then, in the encounter point the robot modifies its position to achieve an engagement with both people. The encounter point is computed using a gradient descent method that takes into account all people predictions. Moreover, we make use of the Extended Social Force Model (ESFM), and it is modified to include the dynamic goal. The method has been validated over several situations and in real-life experiments, in addition, a user study has been realized to reveal the social acceptability of the robot in this task.


Title: A 7-Dof Wire-Driven Lightweight Arm with Wide Wrist Motion Range
Key Words: health and safety  motion control  prototypes  robots  sensors  human safety  wrist mechanism  wide wrist motion range  sensors  robot prototype  integrated wrist-elbow mechanisms  shoulder mechanism  robot safety  robot arms  7-DOF wire-driven lightweight arm  Wires  Wrist  Shoulder  Manipulators  Collision avoidance  Robot sensing systems 
Abstract: Till date, various seven-degrees-of-freedom (7-DOF)robot arms have been developed globally. In general, the robot arms utilized in factories are required to possess speed, power, and accuracy. They are isolated from humans using a fence to ensure human safety. However, a home robot should work near humans at an appropriate speed without a fence. One approach to meeting this requirement involves the installation of various sensors on the robot to control and stop the robot safely even if a collision has occurred. However, a robot system is complicated and expensive. In order to give inherent safety to the robot, we should lighten the robot arm. In this study, a 7-DOF lightweight arm with a wide wrist-motion range is introduced. The weight of movable parts is approximately 2.87 kg. To achieve such properties, we propose the use of three mechanisms: a shoulder mechanism with hollow cylinders, a wrist mechanism with a wide workspace, and an integrated wrist and elbow mechanisms of high power. To verify its feasibility, a prototype of the robot is designed and developed. The experimental results demonstrate its powerful performance and wide workspace of the wrist.


Title: RAMCIP - A Service Robot for MCI Patients at Home
Key Words: assisted living  cognition  diseases  geriatrics  handicapped aids  human-robot interaction  medical robotics  service robots  daily activities  Mild Cognitive Impairments  discreet assistance  MCI patients  service robot  home  RAMCIP robot  cognitive training games  robotic manipulations  discreet user monitoring  medication activities  proactive assistance provision  human-robot communication  Service robots  Information technology  Intelligent robots  Computer science  Companies  Random access memory 
Abstract: This video features RAMCIP, a new service robot developed to provide proactive and discreet assistance to elderly with Mild Cognitive Impairments (MCI), supporting their daily activities at home. Starting with a thorough analysis of needs and requirements of the target population, the RAMCIP robot was developed as an integrated ensemble of advanced H/W and S/W components, realizing the robot skills of perception, cognition, safe navigation, grasping, manipulation, and human-robot communication, ample to operate in real, rather challenging domestic environments. The RAMCIP use-cases include proactive assistance provision to user's cooking, eating and medication activities, through discreet user monitoring and robot interventions by reminders and robotic manipulations., RAMCIP can bring the medicine, recognize fallen objects and electric appliance that has been forgotten turned on. It also recognizes the user walking in low-light conditions and turns on the light, as well as detects cases of emergency such as a fall. The robot provides also the user with cognitive training games and stimulates the user to contact with relatives through video-calls. Pilot trials of the RAMCIP robot have been performed in real homes of more than ten different users, in Barcelona, Spain; the video at hand exhibits the robot performing the target use cases.


Title: Nonlinear Analysis of an Indirectly Controlled Sliding Locomotion Robot
Key Words: legged locomotion  motion control  robot dynamics  vibrations  wheels  indirectly controlling mechanism  indirectly controlled locomotion robots  inefficient locomotion  Arnold tongue  energy efficiency  indirectly controlled sliding locomotion  active wobbling mass  slippery road surface  stable energy efficient locomotion  sliding locomotion robot  nonlinear analysis  Force  Legged locomotion  Tongue  Robot kinematics  Frequency estimation  Friction 
Abstract: With the purpose of achieving stable and energy efficient locomotion on the slippery road surface, a sliding locomotion robot without joint torque but indirectly controlled by an active wobbling mass is recently proposed. In this paper, we deepen the analysis of the mechanism of the indirectly controlled sliding locomotion for further optimization and generalization. First, we derive the equations of dynamics and control. Second, we estimate the natural frequency of the robot, the moving speed and energy efficiency are also evaluated with respect to forcing amplitude and frequency of the wobbling mass. Third, the Arnol'd tongue is introduced to analyze the relationship between achieving efficient locomotion and being entrained. In addition, phase oscillation and synchronization phenomenon are analyzed via hysteresis plot to further interpret the unusual shapes of the Arnol'd tongues. Finally, we analyze the entrained, however, inefficient locomotion by reconfirming the rolling constraints from the mechanical energy dissipation point of view. Our results help better understanding of the indirectly controlling mechanism, and the methods can be applied to other indirectly controlled locomotion robots.


Title: Planning Topological Navigation for Complex Indoor Environments
Key Words: humanoid robots  mobile robots  multi-robot systems  planning (artificial intelligence)  artificial intelligence planning  topological navigation planning  symbolic representation  European Robotics League  humanoid robot Pepper  high level acting  high level reasoning  mobile robot  complex indoor environments  Navigation  Planning  Task analysis  Measurement  Robot kinematics  Indoor environments 
Abstract: The ability to move around the environment is one of the most important capabilities of a mobile robot. Although navigation is considered an already achieved capacity, there is still much work to be done to integrate navigation with high level reasoning and acting. Navigate in indoor environments also involve complex actions, such as opening doors, use elevators, and many others. We propose a topological navigation system based on Artificial Intelligence (AI) Planning. Starting from a symbolic representation of the environment, navigation tasks are divided into phases, in which different actions are required. This approach has demonstrated to be very effective to plan the operations of a robot at indoor environments. The final result is method compact, efficient and scalable. Our system has been successfully tested at European Robotics League in the humanoid robot Pepper.


Title: Joint Stem Detection and Crop-Weed Classification for Plant-Specific Treatment in Precision Farming
Key Words: agricultural robots  agriculture  agrochemicals  control engineering computing  convolutional neural nets  crops  image classification  image segmentation  learning (artificial intelligence)  robot vision  spraying  crop production  robots  mechanical treatments  class-wise stem detection  conventional weed control  spraying process  convolutional network  farming process  agrochemicals  environmental impact  pixel-wise semantic segmentation  Agriculture  Decoding  Image segmentation  Feature extraction  Semantics  Task analysis  Robots 
Abstract: Applying agrochemicals is the default procedure for conventional weed control in crop production, but has negative impacts on the environment. Robots have the potential to treat every plant in the field individually and thus can reduce the required use of such chemicals. To achieve that, robots need the ability to identify crops and weeds in the field and must additionally select effective treatments. While certain types of weed can be treated mechanically, other types need to be treated by (selective) spraying. In this paper, we present an approach that provides the necessary information for effective plant-specific treatment. It outputs the stem location for weeds, which allows for mechanical treatments, and the covered area of the weed for selective spraying. Our approach uses an end-to-end trainable fully convolutional network that simultaneously estimates stem positions as well as the covered area of crops and weeds. It jointly learns the class-wise stem detection and the pixel-wise semantic segmentation. Experimental evaluations on different real-world datasets show that our approach is able to reliably solve this problem. Compared to state-of-the-art approaches, our approach not only substantially improves the stem detection accuracy, i.e., distinguishing crop and weed stems, but also provides an improvement in the semantic segmentation performance.


Title: Seeing the Wood for the Trees: Reliable Localization in Urban and Natural Environments
Key Words: feature extraction  geophysical image processing  image matching  image segmentation  robot vision  vegetation mapping  reliable localization  urban environments  natural environments  current state-of-the-art global approaches  structure-poor vegetated areas  orchards  environments clutter  repeatable extraction  distinctive landmarks  natural forests  tree trunks  foliage intertwines  planar structure  place recognition  feature extraction module segments  reliable object-sized segments  heavy clutter  foliage-heavy forest  urban scenarios  random forest  shape descriptor  Feature extraction  Vegetation  Three-dimensional displays  Forestry  Reliability  Clutter  Hidden Markov models 
Abstract: In this work we introduce Natural Segmentation and Matching (NSM), an algorithm for reliable localization, using laser, in both urban and natural environments. Current state-of-the-art global approaches do not generalize well to structure-poor vegetated areas such as forests or orchards. In these environments clutter and perceptual aliasing prevents repeatable extraction of distinctive landmarks between different test runs. In natural forests, tree trunks are not distinctive, foliage intertwines and there is a complete lack of planar structure. In this paper we propose a method for place recognition which uses a more involved feature extraction process which is better suited to this type of environment. First, a feature extraction module segments stable and reliable object-sized segments from a point cloud despite the presence of heavy clutter or tree foliage. Second, repeatable oriented key poses are extracted and matched with a reliable shape descriptor using a Random Forest to estimate the current sensor's position within the target map. We present qualitative and quantitative evaluation on three datasets from different environments - the KITTI benchmark, a parkland scene and a foliage-heavy forest. The experiments show how our approach can achieve place recognition in woodlands while also outperforming current state-of-the-art approaches in urban scenarios without specific tuning.


Title: A Novel Autonomous Robot for Greenhouse Applications
Key Words: agriculture  cameras  greenhouses  mobile robots  robot vision  autonomous robot  low-cost 3D camera  greenhouse headland  greenhouse heating system  agricultural robot  greenhouse applications  Green products  Rails  Mobile robots  Tools  Wheels  Task analysis 
Abstract: This paper presents a novel agricultural robot for greenhouse applications. In many greenhouses, including the greenhouse used in this work, sets of pipes run along the floor between plant rows. These pipes are components of the greenhouse heating system, and doubles as rails for trolleys used by workers. A flat surface separates the start of each rail set at the greenhouse headland. If a robot is to autonomously drive along plant rows, and also be able to move from one set of rails to the next, it must be able to locomote both on rails and on flat surfaces. This puts requirements on mechanical design and navigation, as the robot must cope with two very different operational environments. The robot presented in this paper has been designed to overcome these challenges and allows for autonomous operation both in open environments and on rails by using only low-cost sensors. The robot is assembled using a modular system created by the authors and tested in a greenhouse during ordinary operation. Using the robot, we map the environment and automatically determine the starting point of each rail in the map. We also show how we are able to identify rails and estimate the robots pose relative to theses using only a low-cost 3D camera. When a rail is located, the robot makes the transition from floor to rail and travels along the row of plants before it moves to the next rail set which it has identified in the map. The robot is used for UV treatment of cucumber plants.


Title: The use of dynamic sensing strategies to improve detection for a pepper harvesting robot
Key Words: agricultural products  agriculture  feature extraction  greenhouses  industrial robots  least squares approximations  object detection  profitability  robot vision  predicted profitability  viewpoint location  pepper harvesting robot  dynamic sensing strategies  harvesting utility cost function  occlusion level detection  fruit  image analysis  Robot sensing systems  Heuristic algorithms  Prediction algorithms  Cameras  Manipulators 
Abstract: This paper presents the use of dynamic sensing strategies to improve detection results for a pepper harvesting robot. The algorithm decides if an additional viewpoint is needed and selects the best-fit viewpoint location from a predefined set of locations based on the predicted profitability of such an action. The suggestion of a possible additional viewpoint is based on image analysis for fruit and occlusion level detection, prediction of the expected number of additional targets sensed from that viewpoint, and final decision if choosing the additional viewpoint is beneficial. The developed heuristic was applied on 96 greenhouse images of 30 sweet peppers and resulted in up to 19% improved detection. The harvesting utility cost function decreased by up to 10% compared to the conventional single viewpoint strategy.


Title: Dolphin: A Task Orchestration Language for Autonomous Vehicle Networks
Key Words: autonomous aerial vehicles  autonomous underwater vehicles  control engineering computing  public domain software  software packages  specification languages  unmanned aerial vehicles  task orchestration language  autonomous vehicle networks  extensible programming language  Dolphin program  orchestrated execution  multiple vehicles  one-vehicle tasks  event-based task flow  Dolphin language  autonomous vehicles  unmanned underwater vehicles  Groovy DSL  software packages  robotic toolkits  open-source toolchain  Task analysis  Dolphins  DSL  Autonomous vehicles  Engines  Runtime  Java 
Abstract: We present Dolphin, an extensible programming language for autonomous vehicle networks. A Dolphin program expresses an orchestrated execution of tasks defined compositionally for multiple vehicles. Building upon the base case of elementary one-vehicle tasks, the built-in operators include support for composing tasks in several forms, for instance according to concurrent, sequential, or event-based task flow. The language is implemented as a Groovy DSL, facilitating extension and integration with external software packages, in particular robotic toolkits. The paper describes the Dolphin language, its integration with an open-source toolchain for autonomous vehicles, and results from field tests using unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs).


Title: π-SoC: Heterogeneous SoC Architecture for Visual Inertial SLAM Applications
Key Words: energy consumption  mobile computing  mobile robots  optimisation  SLAM (robots)  system-on-chip  visual inertial SLAM applications  autonomous vehicles  robotics  core technologies  battery-powered mobile devices  energy budget  energy consumption  energy efficiency  visual inertial SLAM workloads  60 FPS performance  heterogeneous SoC architecture  simultaneous localization and mapping  hardware accelerator  IO interface  memory hierarchy  Simultaneous localization and mapping  Feature extraction  Three-dimensional displays  Instruction sets  Power demand  Graphics processing units  Computer architecture 
Abstract: In recent years, we have observed a clear trend in the rapid rise of autonomous vehicles and robotics. One of the core technologies enabling these applications, Simultaneous Localization And Mapping (SLAM), imposes two main challenges: first, these workloads are computationally intensive and they often have real-time requirements; second, these workloads run on battery-powered mobile devices with limited energy budget. Hence, performance should be improved while simultaneously reducing energy consumption, two rather contradicting goals by conventional wisdom. Previous attempts to optimize SLAM performance and energy efficiency usually involve optimizing one function and fail to approach the problem systematically. In this paper, we first study the characteristics of visual inertial SLAM workloads on existing heterogeneous SoCs. Then based on the initial findings, we propose π-SoC, a heterogeneous SoC design that systematically optimize the IO interface, the memory hierarchy, as well as the the hardware accelerator. We implemented this system on a Xilinx Zynq UltraScale MPSoC and was able to deliver over 60 FPS performance with average power less than 5 W.


Title: vTSL - A Formally Verifiable DSL for Specifying Robot Tasks
Key Words: constraint handling  control engineering computing  formal specification  formal verification  learning (artificial intelligence)  mobile robots  robot programming  specification languages  vTSL  formally verifiable DSL  robot tasks  preprogramming  automated planning  symbolic learning  robotic application  user-defined tasks  integrity constraints  robotic platform  verifiable task specification language  task-specific constraints  robotic systems  Task analysis  DSL  Semantics  Planning  Loading  Robot sensing systems 
Abstract: Preprogramming of tasks still plays an important role in complex robotic systems despite the advances in automated planning and symbolic learning. Often, it is desired that end-users implement further tasks to adapt the robotic application to their needs. These user-defined tasks have to meet safety and integrity constraints for protecting the robotic platform and its users. We introduce a verifiable task specification language (vTSL) that enables to automatically prove that a task specification satisfies a set of predefined or task-specific constraints. We illustrate our approach using an example of a self-driving vehicle for intra-logistics and report experiences with two commercial applications.


Title: GPU-Accelerated Next-Best-View Coverage of Articulated Scenes
Key Words: embedded systems  graphics processing units  mobile robots  path planning  rendering (computer graphics)  robot vision  costmap computation  path planning  simulation  viewpoint candidates  multiple device classes  multiGPU servers  utility map  robots  complex articulated scenes  GPU-accelerated next-best-view coverage  next-best-view algorithms  mapping tasks  articulated environments  obstructed areas  degrees of freedom  embedded devices  next-best-view approach  embedded systems  graphics processing units  OpenGL  Graphics processing units  Task analysis  Cameras  Robot sensing systems  Planning  Solid modeling 
Abstract: Next-best-view algorithms are commonly used for covering known scenes, for example in search, maintenance, and mapping tasks. In this paper, we consider the problem of planning a strategy for covering articulated environments where the robot also has to manipulate objects to inspect obstructed areas. This problem is particularly challenging due to the many degrees of freedom resulting from the articulation. We propose to exploit graphics processing units present in many embedded devices to parallelize the computations of a greedy next-best-view approach. We implemented algorithms for costmap computation, path planning, as well as simulation and evaluation of viewpoint candidates in OpenGL for Embedded Systems and benchmarked the implementations on multiple device classes ranging from smartphones to multi-GPU servers. We introduce a heuristic for estimating a utility map from images rendered with strategically placed spherical cameras and show in simulation experiments that robots can successfully explore complex articulated scenes with our system.


Title: Sinc-Based Dynamic Movement Primitives for Encoding Point-to-point Kinematic Behaviors
Key Words: control engineering computing  learning (artificial intelligence)  robot kinematics  robot programming  simple learning technique  sinc functions  sinc-based dynamic movement primitives  point-to-point kinematic behaviors  Complexity theory  Kinematics  Biological system modeling  Computational modeling  Frequency modulation  Encoding 
Abstract: This work proposes the utilization of sinc functions as kernels of Dynamic Movement Primitives (DMP) models for encoding point-to-point kinematic behaviors. The proposed method presents a number of advantages with respect to the state of the art, as it (i) involves a simple learning technique, (ii) provides a method to determine the minimum required number of basis functions, based on the frequency content of the demonstrated motion and (iii) provides the ability to pre-define the reproduction accuracy of the learned behavior. The ability of the proposed model to accurately reproduce the behavior is demonstrated through simulations and experiments. Comparisons with the Gaussian-based DMP model show the proposed method's superiority in terms of computational complexity of learning and accuracy for a specific number of kernels.


Title: An Optimization-Based Approach to Dual-Arm Motion Planning with Closed Kinematics
Key Words: collision avoidance  constraint handling  humanoid robots  manipulator kinematics  mobile robots  optimisation  probability  dual-arm motion planning  collision-free motions  dual-arm robot  kinematic constraints  closed kinematic chain  constrained problems  sampling-based planners  random sample  closure constraint  equality constraints  gripped object  optimization-based planning approach  probability  augmented Lagrangian method  constraints handling  RRT  CHOMP  TrajOpt  trajectory optimization approach  twelve degrees of freedom  Kinematics  Planning  Collision avoidance  Manipulators  Optimization  Trajectory 
Abstract: This paper addresses the optimization-based planning of collision-free motions for a dual-arm robot with kinematic constraints. Such problems arise, for example, when the robot has to move an object with both arms, whereby the two arms and the gripped object form a closed kinematic chain. Such constrained problems are hard to solve with sampling-based planners, because the probability that a random sample satisfies the closure constraint is practically zero. In contrast, the solution of optimization problems with equality constraints is a well-understood field of research. This paper formulates the motion planning task as optimization problem and proposes a numerical solution using the augmented Lagrangian method for handling constraints. The planner is compared to RRTs, CHOMP and TrajOpt on a set of randomly generated problems for a dual-arm robot with twelve degrees of freedom highlighting the advantages of optimization-based planning.


Title: Smooth Point-to-Point Trajectory Planning in $SE$ (3)with Self-Collision and Joint Constraints Avoidance
Key Words: collision avoidance  end effectors  manipulator dynamics  manipulator kinematics  smooth point-to-point trajectory planning  joint constraints avoidance  serial robotic structures  time-optimal SE(3) trajectory  robot end-effector  4th order dynamics flexible joint robots  self-collision avoidance  point-to-point trajectory planner  Trajectory  End effectors  Interpolation  Planning  Collision avoidance 
Abstract: In this paper we introduce a novel point-to-point trajectory planner for serial robotic structures that combines the ability to avoid self-collisions and to respect motion constraints, while complying with the requirement of being C4 continuous. The latter property makes our approach also suited for 4th order dynamics flexible joint robots, which gained significant practical relevance recently. In particular, we address the problem of generating a smooth, kinematically nearly time-optimal SE(3) trajectory while simultaneously avoiding potential collisions of the robot end-effector with its base as well as respecting the Cartesian unreachable states induced by the joint limits of the proximal kinematic structure.


Title: Collision-Free Path Planning of Dual-Manipulator System Based on Energy Conversion
Key Words: collision avoidance  elasticity  manipulators  mobile robots  path planning  springs (mechanical)  dual-manipulator moves  original paths  ends-fixed elastic ropes  manipulators  initial paths  elastic potential energy  manipulator bodies  virtual spring  energy perspective  dual-manipulator path-planning problem  energy conversion  dual-manipulator system  collision-free path planning  Manipulators  Path planning  Springs  Potential energy  Mobile robots 
Abstract: This paper is a preliminary exploration of how to solve the dual-manipulator path-planning problem from an energy perspective. A virtual spring is set up between the two manipulator bodies and becomes compressed as they move into the area of danger, thus producing elastic potential energy. The initial paths of the manipulators are modelled as two ends-fixed elastic ropes. The elastic potential energy stored in the virtual spring is distributed between the two elastic ropes in a certain proportion so as to deform them. In this way, the original paths of the two manipulators will deviate toward the direction of their respective bases thereby avoiding any collision crisis that may potentially occur. When the dual-manipulator moves away from the danger area, the elastic potential energy caused by the deviation of the elastic ropes will be converted back into energy stored by the virtual spring, such that the elastic ropes revert to their original state and drive the manipulators back to their initial paths. Simple but representative simulations are established and results of the simulations show the reliability of our proposed method.


Title: CROC: Convex Resolution of Centroidal Dynamics Trajectories to Provide a Feasibility Criterion for the Multi Contact Planning Problem
Key Words: approximation theory  computational geometry  legged locomotion  linear programming  motion control  path planning  sampling methods  trajectory control  CROC  feasibility criterion  multicontact planning problem  transition feasibility problem  legged robot  conservative reformulation  convex reformulation  Bezier curve  transition problem  sampling-based contact planner  motion generation methods  center of mass trajectory  convex resolution of centroidal dynamics trajectories  free control point  contact sequences  motion synthesis problems  linear program  Trajectory  Dynamics  Planning  Acceleration  Legged locomotion  Kinematics 
Abstract: We tackle the transition feasibility problem, that is the issue of determining whether there exists a feasible motion connecting two configurations of a legged robot. To achieve this we introduce CROC, a novel method for computing centroidal dynamics trajectories in multi-contact planning contexts. Our approach is based on a conservative and convex reformulation of the problem, where we represent the center of mass trajectory as a Bezier curve comprising a single free control point as a variable. Under this formulation, the transition problem is solved efficiently with a Linear Program (LP)of low dimension. We use this LP as a feasibility criterion, incorporated in a sampling-based contact planner, to discard efficiently unfeasible contact plans. We are thus able to produce robust contact sequences, likely to define feasible motion synthesis problems. We illustrate this application on various multi-contact scenarios featuring HRP2 and HyQ. We also show that we can use CROC to compute valuable initial guesses, used to warm-start non-linear solvers for motion generation methods. This method could also be used for the 0 and 1-Step capturability problem. The source code of CROC is available under an open source BSD-2 License.


Title: Variations on a Theme: “It's a Poor Sort of Memory that Only Works Backwards”
Key Words: learning (artificial intelligence)  mobile robots  rendering (computer graphics)  mobile robots  virtual scene rendering approach  episodic memories  robotic agent  knowledge based approach  model learning  Task analysis  Games  Engines  Rendering (computer graphics)  Mobile robots  Solid modeling 
Abstract: Adapting the perceptual capabilities of mobile robots to new objects or new environments can be a time consuming task. In this paper we focus on specializing perceptual capabilities of mobile robots to new objects through a knowledge based, virtual scene rendering approach. Episodic memories of a robotic agent, gathered during the execution of a task are considered to be the main "theme". Variations of this theme are then generated based on background knowledge about the objects and data gathered with the purpose of learning new models for detection and recognition. We demonstrate the applicability of our approach by adapting the perceptual capabilities of a mobile robot performing pick and place tasks, to recognize new sets of objects.


Title: Attitude Estimation from Polarimetric Cameras
Key Words: attitude control  autonomous aerial vehicles  cameras  image sensors  mobile robots  path planning  robot vision  robotic applications  attitude estimation  polarimetric camera  path planning applications  visual systems  perspective cameras  depth cameras  catadioptric cameras  systems capture information  sky regions  visual cue  vision applications  sky information  polarimetric sensors  visual sensors  navigation applications  unmanned aerial vehicle  Cameras  Scattering  Robot vision systems  Sun  Estimation  Atmospheric modeling 
Abstract: In the robotic field, navigation and path planning applications benefit from a wide range of visual systems (e.g, perspective cameras, depth cameras, catadioptric cameras, etc.). In outdoor conditions, these systems capture information in which sky regions cover a major segment of the images acquired. However, sky regions are discarded and are not considered as visual cue in vision applications. In this paper, we propose to estimate attitude of Unmanned Aerial Vehicle (UAV) from sky information using a polarimetric camera. Theoretically, we provide a framework estimating the attitude from the skylight polarized patterns. We showcase this formulation on both simulated and real-word data sets which proved the benefit of using polarimetric sensors along with other visual sensors in robotic applications.


Title: The Earth Ain't Flat: Monocular Reconstruction of Vehicles on Steep and Graded Roads from a Moving Camera
Key Words: cameras  image reconstruction  pose estimation  road vehicles  SLAM (robots)  stereo image processing  traffic engineering computing  local bundle-adjustment like procedure  3D pose  semantic cues  moving ego vehicle  shape estimation  plain roads  monocular localization demonstrations  autonomous driving systems  traffic participants  moving camera  monocular reconstruction  arbitrarily-shaped roads  monocular object localization  road plane configurations  local ground plane  local planar patches  monocular camera  Shape  Roads  Three-dimensional displays  Cameras  Image reconstruction  Automobiles  Surface reconstruction 
Abstract: Accurate localization of other traffic participants is a vital task in autonomous driving systems. State-of-the-art systems employ a combination of sensing modalities such as RGB cameras and LiDARs for localizing traffic participants, but monocular localization demonstrations have been confined to plain roads. We demonstrate - to the best of our knowledge - the first results for monocular object localization and shape estimation on surfaces that are non-coplanar with the moving ego vehicle mounted with a monocular camera. We approximate road surfaces by local planar patches and use semantic cues from vehicles in the scene to initialize a local bundle-adjustment like procedure that simultaneously estimates the 3D pose and shape of the vehicles, and the orientation of the local ground plane on which the vehicle stands. We also demonstrate that our approach transfers from synthetic to real data, without any hyperparameter-/fine-tuning. We evaluate the proposed approach on the KITTI and SYNTHIA-SF benchmarks, for a variety of road plane configurations. The proposed approach significantly improves the state-of-the-art for monocular object localization on arbitrarily-shaped roads.


Title: Towards a Context Enhanced Framework for Multi Object Tracking in Human Robot Collaboration
Key Words: human-robot interaction  manipulators  object detection  object tracking  robot vision  uninterrupted completion  functional accuracy  multiple objects  HRC setting  robust object tracker  functional role  object tacker  robotic manipulation  HRC assembly process  multiobject tracking  goal-oriented human robot collaborative scenario  context enhanced framework  Robot kinematics  Cognition  Task analysis  Object tracking  Three-dimensional displays 
Abstract: In a goal-oriented Human Robot Collaborative (HRC) scenario, where the goal is to complete an assembly process, a robust object tracker might not necessarily fulfill its functional role due to the dynamic nature of HRC. Moreover, for an efficient HRC, the functional role of the object tacker should not only be limited to localizing and tracking objects for robotic manipulation. It should also help to determine the current state of the assembly process and verify if the chosen action has been successfully performed and thus to enable an uninterrupted completion of an HRC assembly process. We present a Context Enhanced Framework for Multi Object Tracking, that i) allows uninterrupted completion of an assembly process, ii) improves the overall functional accuracy of the object tracker from 49 percent to 96 percent, and iii) enables the object tracker to handle multiple instance of multiple objects in a HRC setting.


Title: Real-time 3D Reconstruction Using a Combination of Point-Based and Volumetric Fusion
Key Words: cameras  image colour analysis  image fusion  image motion analysis  image reconstruction  image segmentation  iterative methods  object detection  stereo image processing  3D reconstruction technologies  point-based and volumetric representation  Kinect sensors  Xtion sensors  augmented reality  robotic teleoperation  medical diagnosis  KinectFusion  KinFu  GPU-based region growing method  weighted iterative closest point algorithm  moving object  fast motion camera  truthful reconstruction  low-cost commodity sensors  volumetric fusion  camera tracking  Cameras  Three-dimensional displays  Pose estimation  Sensors  Real-time systems  Iterative closest point algorithm  Systematics 
Abstract: Real-time 3D reconstruction using low-cost commodity sensors like Kinect or Xtion has been successfully applied in a wide range of fields like augmented reality, robotic teleoperation, and medical diagnosis. Due to the assumption of static scene, popular 3D reconstruction technologies such as KinectFusion and KinFu, find truthful reconstruction with fast motion camera or segmenting a moving object to be a challenge. In this paper, we propose a weighted iterative closest point (ICP) algorithm that uses both depth and RGB information to enhance the stability of camera tracking. Additionally, a GPU-based region growing method that combines depth, normal and intensity level as similarity criteria, is also applied to segment foreground moving objects accurately. For real-time processing and GPU memory efficiency, we also design a combination of point-based and volumetric representation to reconstruct moving objects and static scene, respectively. Both qualitative and quantitative results show that our proposed method improves real-time 3D reconstruction on the performance of camera tracking and segmentation of moving objects with reduced computational complexity.


Title: P-CAP: Pre-Computed Alternative Paths to Enable Aggressive Aerial Maneuvers in Cluttered Environments
Key Words: autonomous aerial vehicles  collision avoidance  data structures  graph theory  mobile robots  navigation  probability  search problems  p-CAP  pre-computed alternative paths  cluttered environments  fast autonomous flight  autonomous navigation  complex environment  continuous heuristic search  k-connected grid  probabilistic scheme  onboard sensors  prior map information  data structure  flight experiments  unstructured environments  aggressive aerial maneuvers  graph  forests-like environments  obstacles avoidance  Navigation  Sensors  Switches  Collision avoidance  Forestry  Gold  Planning 
Abstract: We propose a novel method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous heuristic search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle progresses, modification of the graph with data from onboard sensors is expensive as is search on the graph, especially if the paths must be kino-dynamically feasible. We suggest that computation needed to find safe paths during fast flight can be greatly reduced if we precompute and carefully arrange a dense set of alternative paths before the flight. Any prior map information can be used to prune the alternative paths to come up with a data structure that enables very fast online computation to deal with obstacles that are not on the map but only detected by onboard sensors. To test this idea, we have conducted a large number of flight experiments in structured (large industrial facilities) and unstructured (forests-like) environments. We show that even in the most unstructured environments, this method enables flight at a speed up to 10m/s while avoiding obstacles detected from onboard sensors.


Title: Motion Planning for a Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  collision avoidance  feedback  mobile robots  robot dynamics  trees (mathematics)  cruise-to-hover transition  hover-to-cruise transition  motion planner  motion planning  aerobatic fixed-wing  fixed-wing unmanned aerial vehicle  static obstacles  goal region  rapidly-exploring random trees algorithm  Aircraft  Trajectory  Libraries  Aerodynamics  Atmospheric modeling  Heuristic algorithms  Planning 
Abstract: A motion planner is developed for guiding a small aerobatic fixed-wing unmanned aerial vehicle to a desired goal region in a highly constrained, three-dimensional, known environment with static obstacles. The planner is based on the Rapidly-Exploring Random Trees (RRT) algorithm, and pieces together feasible trajectories from a library of motion primitives. Among other more conventional motion primitives, the library includes three extreme maneuvers: a cruise-to-hover transition, a hover-to-cruise transition, and an aggressive turn-around. The algorithm is efficient; it can be run in real-time to rapidly generate a plan starting from the aircraft's configuration at run-time. The motion planner is closely coupled to a feedback controller. Simulations using an aircraft dynamics model demonstrate the effectiveness of the system to guide and control the aircraft to a desired goal region. Preliminary flight test results are also presented.


Title: First Experimental Results on Motion Planning for Transportation in Aerial Long-Reach Manipulators with Two Arms
Key Words: autonomous aerial vehicles  collision avoidance  manipulators  mobile robots  search problems  transportation  aerial robotic system  RRT* algorithms  motion planning problem  dual arm  aerial platform  passive revolute joint  long-reach manipulation  long-bar extension  aerial long-reach manipulators  cluttered environment  transportation  Manipulators  Planning  Trajectory  Transportation  Bars  Task analysis 
Abstract: This paper presents the motion planning of a novel aerial robotic system with a long-bar extension and two arms for long-reach manipulation in cluttered environments. The novel aerial long-reach manipulator includes a passive revolute joint between the aerial platform and the dual arm. This feature minimises the torque induced to the aerial system in case of unexpected collisions of the manipulator. The motion planning problem is addressed considering jointly the complete set of configuration variables for the aerial platform and the dual arm. Furthermore, the planner has been built over the fundamentals of RRT* algorithms in order to optimise the performance of the trajectories in terms of energy and time. The proposed planning method has been experimentally validated in a realistic industrial scenario, the transportation of a long bar through a cluttered environment consisting of several pipe structures.


Title: Sparse 3D Topological Graphs for Micro-Aerial Vehicle Planning
Key Words: autonomous aerial vehicles  computational geometry  graph theory  image colour analysis  mobile robots  path planning  topology  Euclidean signed distance field  3D generalized Voronoi diagram  RGB-D sensing  global planning  skeleton diagram  topological information  noisy sensor data  sparse map representations  compact map representations  MAV  microaerial vehicle planning  sparse 3D topological graphs  Planning  Three-dimensional displays  Two dimensional displays  Skeleton  Robot sensing systems  Topology 
Abstract: Micro-Aerial Vehicles (MAVs) have the advantage of moving freely in 3D space. However, creating compact and sparse map representations that can be efficiently used for planning for such robots is still an open problem. In this paper, we take maps built from noisy sensor data and construct a sparse graph containing topological information that can be used for 3D planning. We use a Euclidean Signed Distance Field, extract a 3D Generalized Voronoi Diagram (GVD), and obtain a thin skeleton diagram representing the topological structure of the environment. We then convert this skeleton diagram into a sparse graph, which we show is resistant to noise and changes in resolution. We demonstrate global planning over this graph, and the orders of magnitude speed-up it offers over other common planning methods. We validate our planning algorithm in real maps built onboard an MAV, using RGB-D sensing.


Title: Motion Planning for a UAV with a Straight or Kinked Tether
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  mobile robots  motion control  multi-robot systems  robot vision  confined environment  cluttered environment  tethered aerial vehicles  tethered agent  nonfree space  motion planning frameworks  motion planning strategies  motion planning algorithms  UAV  robotic locomotion  reachable configuration space  marsupial heterogeneous robotic teams  Fotokite Pro  Planning  Visualization  Casting  Cameras  Robot sensing systems  Unmanned aerial vehicles 
Abstract: This paper develops and compares two motion planning algorithms for a tethered UAV with and without the possibility of the tether contacting the confined and cluttered environment. Tethered aerial vehicles have been studied due to their advantages such as power duration, stability, and safety. However, the disadvantages brought in by the extra tether have not been well investigated by the robotic locomotion community, especially when the tethered agent is locomoting in a non-free space occupied with obstacles. In this work, we propose two motion planning frameworks that (1) reduce the reachable configuration space by taking into account the tether and (2) deliberately plan (and relax) the contact point(s) of the tether with the environment and enable an equivalent reachable configuration space as the non-tethered counterpart would have. Both methods are tested on a physical robot, Fotokite Pro. With our approaches, tethered aerial vehicles could find their applications in confined and cluttered environments with obstacles as opposed to ideal free space, while still maintaining the advantages from the usage of a tether. The motion planning strategies are particularly suitable for marsupial heterogeneous robotic teams, such as visual servoing/assisting for another mobile, tele-operated primary robot.


Title: Persistent Monitoring with Refueling on a Terrain Using a Team of Aerial and Ground Robots
Key Words: aerospace robotics  integer programming  linear programming  multi-robot systems  path planning  tree searching  terrain  persistent monitoring  heterogeneous team  aerial robots  ground robots  MILP formulation  branch-and-cut framework  separation algorithm  Fuels  Monitoring  Unmanned aerial vehicles  Routing  Robot sensing systems  Kernel 
Abstract: There are many applications such as surveillance and mapping that require persistent monitoring of terrains. In this work, we consider a heterogeneous team of aerial and ground robots that are tasked with monitoring a terrain along a given path. Both types of robots are equipped with cameras that can monitor the terrain within their fields-of-view. We also consider the ability of the aerial robots to land occasionally on the terrain to recharge. The objective is to find a path for all the robots to reduce the time required. Determining optimal routes for the robots is a challenging problem because of constrained visibility due to the terrain and fuel limitations of the robots. We devise an MILP formulation for the problem using a 1.5 dimensional representation model. A branch-and-cut framework is used to implement the MILP and involves the design of a separation algorithm to compute valid inequalities. We report results from extensive simulations and proof-of-concept field experiments to show the efficacy of our approach.


Title: A Mobility Model Based on Improved Artificial Potential Fields for Swarms of UAVs
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  path planning  remotely operated vehicles  information sharing  path planning  obstacles avoidance  mobility model  swarms  UAV  involved UAVs collaborate  mobility strategies  autonomous UAVs  collaborative tasks  multiple platforms  artificial potential fields principle  APF principle  Path planning  Sensors  Adaptation models  Collaboration  Task analysis  Laser radar  Collision avoidance 
Abstract: A combination of several autonomous UAVs can be used to perform collaborative tasks. Such a combination is referred to as a swarm of drones. The use of multiple platforms can extend the system global capacities thanks to the resulting variety of embedded sensors and to information sharing. In this case, path planning and thus obstacles avoidance is still a major task. To deal with this issue, mobility models have to be implemented. Our contribution presented in this paper is a mobility model for swarms of UAVs based on the Artificial Potential Fields (APF) principle. In our model, the involved UAVs collaborate by sharing data about the obstacles that they detected. By doing so, a UAV which is not close enough to an obstacle to detect it thanks to its own sensors will still have the proper data to take this obstacle into account in its path planning. To validate our mobility strategies with realistic constraints we simulate the performances of existing sensors and transmitters, and consider real-world environment.


Title: UAV/UGV Search and Capture of Goal-Oriented Uncertain Targets*This research was supported in part by ISF grant #1337/15 and part by a grant from MOST, Israel and the JST Japan
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  optimisation  probability  remotely operated vehicles  UAV/UGV collaborative efforts  stochastic-temporal belief  attacker capture  defender real-time algorithmic framework  probability optimization  goal-oriented uncertain targets  UAV/UGV search  Games  Uncertainty  Search problems  Real-time systems  Task analysis  Mathematical model  Roads 
Abstract: This paper considers a new, complex problem of UAV/UGV collaborative efforts to search and capture attackers under uncertainty. The goal of the defenders (UAV/UGV team) is to stop all attackers as quickly as possible, before they arrive at their selected goal. The uncertainty considered is twofold: the defenders do not know the attackers' location and destination, and there is also uncertainty in the defenders' sensing. We suggest a real-time algorithmic framework for the defenders, combining entropy and stochastic-temporal belief, that aims at optimizing the probability of a quick and successful capture of all of the attackers. We have empirically evaluated the algorithmic framework, and have shown its efficiency and significant performance improvement compared to other solutions.


Title: Lightweight Collision Avoidance for Resource-Constrained Robots
Key Words: collision avoidance  control system synthesis  mobile robots  motion control  resource-constrained robot  controller design  lightweight collision avoidance strategy  embedded control  reference control input  dynamic environment  low level motion control  on-board sensors  vehicle  physical robots  low computational requirements  Collision avoidance  Robot sensing systems  Navigation  Vehicle dynamics 
Abstract: One of the safest and most reliable strategies for vehicle's collision avoidance is embedded control at low level to guarantee safe motion in all situations using on-board sensors. In this paper, we propose a novel lightweight collision avoidance strategy that can be implemented as a low level motion control to achieve safe motion while simultaneously tracking the robot's reference control input. This strategy is designed to be general so that it can be easily integrated with most control designs, with the primary target of resource-constrained robot swarms that act in real-time, dynamic environments. The main advantages of our approach are a very simple structure and low computational requirements. We verified the effectiveness of the proposed collision avoidance strategy through two simulated scenarios and with physical robots. We believe our design can be directly used in many areas, such as autonomous driving, intelligent transportation and planetary exploration.


Title: An Improved Formulation for Model Predictive Control of Legged Robots for Gait Planning and Feedback Control
Key Words: feedback  legged locomotion  numerical stability  pendulums  predictive control  robot dynamics  robust control  gait planning  feedback control  MPC scheme  long prediction horizons  low dimensional models  model predictive control scheme  numerical stability  linear inverted pendulum model  LIPM  legged robots dynamics  external disturbance  robustness  Optimization  Legged locomotion  Numerical models  Acceleration  Planning  Numerical stability 
Abstract: Predictive control methods for walking commonly use low dimensional models, such as a Linear Inverted Pendulum Model (LIPM), for simplifying the complex dynamics of legged robots. This paper identifies the physical limitations of the modeling methods that do not account for external disturbances, and then analyzes the issues of numerical stability of Model Predictive Control (MPC)using different models with variable receding horizons. We propose a new modeling formulation that can be used for both gait planning and feedback control in an MPC scheme. The advantages are the improved numerical stability for long prediction horizons and the robustness against various disturbances. Benchmarks were rigorously studied to compare the proposed MPC scheme with the existing ones in terms of numerical stability and disturbance rejection. The effectiveness of the controller is demonstrated in both MATLAB and Gazebo simulations.


Title: Cable-Driven Actuation for Highly Dynamic Robotic Systems
Key Words: actuators  cables (mechanical)  control engineering computing  cooling  legged locomotion  pulleys  robot dynamics  torque control  cable-pulley system  light-weight  primary cooling element  power density  active elements  total leg weight  resulting robotic leg  low inertia  high torque transparency  low manufacturing cost  Capler-Leg system  experimental setup  cable-pulley design  cable-driven actuation  highly dynamic robotic systems  articulated robotic limb  single-stage cable-pulley transmission  high-gap radius motor  Torque  Legged locomotion  Pulleys  Mechanical cables  Creep  Resistance 
Abstract: This paper presents the design and experimental evaluations of an articulated robotic limb called Capler-Leg. The key element of Capler-Leg is its single-stage cable-pulley transmission combined with a high-gap radius motor. Our cable-pulley system is designed to be as light-weight as possible and to additionally serve as the primary cooling element, thus significantly increasing the power density and efficiency of the overall system. The total weight of active elements on the leg, i.e. the stators and the rotors, contribute more than 60 % of the total leg weight, which is an order of magnitude higher than most existing robots. The resulting robotic leg has low inertia, high torque transparency, low manufacturing cost, no backlash, and a low number of parts. The Capler-Leg system itself, serves as an experimental setup for evaluating the proposed cable-pulley design in terms of robustness and efficiency. A continuous jump experiment shows a remarkable 96.5 % recuperation rate, measured at the battery output. This means that almost all the mechanical energy output during push-off is returned back to the battery during touch-down.


Title: A Control Architecture with Online Predictive Planning for Position and Torque Controlled Walking of Humanoid Robots
Key Words: gait analysis  humanoid robots  legged locomotion  path planning  position control  predictive control  robot kinematics  torque control  inverse kinematics algorithm  iCub  center of mass trajectory  table-cart model  predictive controller  footstep positions  robot kinematic model  control loops  layered control architecture  humanoid robots  torque controlled walking  online predictive planning  stack-of-task QP-based torque controller  position controlled walking  Legged locomotion  Trajectory  Computer architecture  Mathematical model  Humanoid robots  Robot kinematics 
Abstract: A common approach to the generation of walking patterns for humanoid robots consists in adopting a layered control architecture. This paper proposes an architecture composed of three nested control loops. The outer loop exploits a robot kinematic model to plan the footstep positions. In the mid layer, a predictive controller generates a Center of Mass trajectory according to the well-known table-cart model. Through a whole-body inverse kinematics algorithm, we can define joint references for position controlled walking. The outcomes of these two loops are then interpreted as inputs of a stack-of-task QP-based torque controller, which represents the inner loop of the presented control architecture. This resulting architecture allows the robot to walk also in torque control, guaranteeing higher level of compliance. Real world experiments have been carried on the humanoid robot iCub.


Title: Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks
Key Words: control engineering computing  human-robot interaction  recurrent neural nets  proactive robot assistants  freeform collaborative tasks  multimodal recognition  generic subtasks  successful human-robot collaboration  shared understanding  current goals  nonlinear tasks  freeform tasks  explicit task model  robot partners  meaningful task knowledge  multimodal recurrent neural networks  short-term memory units  real-time subtask recognition  context-aware assistance  generic assembly tasks  specific subtasks  individual modalities  high-level representations  nonlinear connection layer  multimodal subtask recognition system  predictive assistance  human partner  human-robot team  assembly task  similar subtasks  freeform assembly scenario  RNN  Task analysis  Robot kinematics  Fasteners  Feature extraction  Activity recognition  Recurrent neural networks 
Abstract: Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.


Title: Virtual Borders: Accurate Definition of a Mobile Robot's Workspace Using Augmented Reality
Key Words: augmented reality  human-robot interaction  mobile robots  navigation  path planning  service robots  mobile robot  human-aware navigation  nonexpert users  vacuum cleaning  human-robot interface  augmented reality application  teaching time  baseline methods  user-defined virtual borders  Education  Navigation  Robot kinematics  Visualization  Robot sensing systems  Mobile robots 
Abstract: We address the problem of interactively controlling the workspace of a mobile robot to ensure a human-aware navigation. This is especially of relevance for non-expert users living in human-robot shared spaces, e.g. home environments, since they want to keep the control of their mobile robots, such as vacuum cleaning or companion robots. Therefore, we introduce virtual borders that are respected by a robot while performing its tasks. For this purpose, we employ a RGB-D Google Tango tablet as human-robot interface in combination with an augmented reality application to flexibly define virtual borders. We evaluated our system with 15 non-expert users concerning accuracy, teaching time and correctness and compared the results with other baseline methods based on visual markers and a laser pointer. The experimental results show that our method features an equally high accuracy while reducing the teaching time significantly compared to the baseline methods. This holds for different border lengths, shapes and variations in the teaching process. Finally, we demonstrated the correctness of the approach, i.e. the mobile robot changes its navigational behavior according to the user-defined virtual borders.


Title: Multi-Modal Robot Apprenticeship: Imitation Learning Using Linearly Decayed DMP+ in a Human-Robot Dialogue System
Key Words: human computer interaction  human-robot interaction  interactive systems  learning (artificial intelligence)  robot programming  linear decay system  seamless learning  multimodal robot apprenticeship  imitation learning  linearly decayed DMP  human-robot dialogue system  robot learning  robots  single demonstration modality  multimodal learning approach  natural interaction modalities  Task analysis  Trajectory  Ontologies  Convergence  Robot learning  Kernel 
Abstract: Robot learning by demonstration gives robots the ability to learn tasks which they have not been programmed to do before. The paradigm allows robots to work in a greater range of real-world applications in our daily life. However, this paradigm has traditionally been applied to learn tasks from a single demonstration modality. This restricts the approach to be scaled to learn and execute a series of tasks in a real-life environment. In this paper, we propose a multi-modal learning approach using DMP+ with linear decay integrated in a dialogue system with speech and ontology for the robot to learn seamlessly through natural interaction modalities (like an apprentice) while learning or re-learning is done on the fly to allow partial updates to a learned task to reduce potential user fatigue and operational downtime in teaching. The performance of new DMP+ with linear decay system is statistically benchmarked against state-of-the-art DMP implementations. A gluing demonstration is also conducted to show how the system provides seamless learning of multiple tasks in a flexible manufacturing set-up.


Title: A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments
Key Words: decision making  Gaussian processes  indoor navigation  mobile robots  path planning  signal processing  wireless sensor networks  social robot navigation  networked service  wireless networks  Gaussian Process  robotic wheelchair operation  sub-optimal path  communication-aware planning constraints  connectivity issues  human-populated indoor environments  transient-goal driven communication-aware navigation strategy  human-aware planning constraints  radio signal strength constraints  decision making capabilities  shopping mall  Robot sensing systems  Navigation  Transient analysis  Mobile robots  Fading channels  Wireless communication 
Abstract: Robots deployed in large human-populated indoor environments such as shopping malls, airports etc., inadvertently communicate via wireless networks for enhanced perception and decision making capabilities. Owing to highly dynamic signal attenuation characteristics in such environments, connectivity issues may arise during robotic navigation, leading to disruption in information flow causing potential danger. Exact modeling of signal propagation for estimating spatial signal variation is usually challenging. Moreover, the presence of dynamic humans also add a layer of temporal signal variation complexities. Thus, this paper introduces a generative approach for embedding radio signal strength constraints within networked service/social robot navigation in large human-populated environments. Initially, we propose a Gaussian Process based online spatio-temporal signal strength prediction model that, as opposed to the current state of the art, also aims to take into account the temporal fading arising due to the presence of human crowds. We then devise a transient-goal driven navigation strategy to realize a sub-optimal path towards a goal, that is aimed at resolving both communication-aware and human-aware planning constraints. Evaluations of the proposed signal prediction model demonstrate the advantages of our approach with respect to the current state of the art. The efficacy of the navigation strategy in also demonstrated simulations and using hardware experiments conducted on a robotic wheelchair operating in a large shopping mall.


Title: Optimizing Contextual Ergonomics Models in Human-Robot Interaction
Key Words: biomechanics  ergonomics  Gaussian processes  human-robot interaction  learning (artificial intelligence)  muscle  physiological models  accurate biomechanical simulations  robot control loops  high-dimensional musculoskeletal model  human-robot interaction  current ergonomic assessment procedures  ergonomic scores  ergonomic scoring  Gaussian process latent variable models  Ergonomics  Biological system modeling  Context modeling  Task analysis  Data models  Muscles 
Abstract: Current ergonomic assessment procedures require observation and manual annotation of postures by an expert, after which ergonomic scores are inferred from these annotations. Our aim is to automate this procedure and to enable robots to optimize their behavior with respect to such scores. A particular challenge is that ergonomic scoring requires accurate biomechanical simulations which are computationally too expensive to use in robot control loops or optimization. To address this, we learn Contextual Ergonomics Models, which are Gaussian Process Latent Variable Models that have been trained with full musculoskeletal simulations for specific tasks contexts. Contextual Ergonomics Models enable search in a low-dimensional latent space, whilst the cost function can be defined in terms of the full high-dimensional musculoskeletal model, which can be quickly reconstructed from the latent space. We demonstrate how optimizing Contextual Ergonomics Models leads to significantly reduced muscle activation in an experiment with eight subjects performing a drilling task.


Title: Drivers' Manoeuvre Prediction for Safe HRI
Key Words: control engineering computing  decision making  human-robot interaction  mobile robots  motion control  road safety  road traffic control  traffic engineering computing  safe HRI  autonomous vehicles  decision-making systems  vehicles robots  human-robot interaction  autonomous agent  human driver interacts  motion tracking data  manoeuvre classification  drivers manoeuvre prediction  human-vehicle interaction  Task analysis  Vehicles  Robots  Roads  Decision making  Predictive models  Training 
Abstract: Machines with high levels of autonomy such as robots and our growing need to interact with them creates challenges to ensure safe operation. The recent interest to create autonomous vehicles through the integration of control and decision-making systems makes such vehicles robots too. We therefore applied estimation and decision-making mechanisms currently investigated for human-robot interaction to human-vehicle interaction. In other words, we define the vehicle as an autonomous agent with which the human driver interacts, and focus on understanding the human intentions and decision-making processes. These are then integrated into the ro-bot`s/vehicle's own control and decision-making system not only to understand human behaviour while it occurs but to predict the next actions. To obtain knowledge about the human's intentions, this work relies heavily on the use of motion tracking data (i.e. skeletal tracking, body posture)gathered from drivers whilst driving. We use a data-driven approach to both classify current driving manoeuvres and predict future manoeuvres, by using a fixed prediction window and augmenting a standard set of manoeuvres. Results are validated against drivers of different sizes, seat preferences and levels of driving expertise to evaluate the robustness of the methods; precision and recall metrics higher than 95% for manoeuvre classification and 90% for manoeuvre prediction with time-windows of up to 1.3 seconds are obtained. The idea of prediction adds a highly novel aspect to human-robot/human-vehicle interaction, allowing for decision and control at a later point.


Title: Human Gaze Following for Human-Robot Interaction
Key Words: control engineering computing  face recognition  gaze tracking  human-robot interaction  learning (artificial intelligence)  single 2D image  human gaze predictions  human-robot interaction tasks  fluent interactions  mutual gaze prediction  gaze heat map statistics  referential gaze  deep learning approach  human gaze fixations  Task analysis  Real-time systems  Head  Cameras  Robot vision systems  Videos 
Abstract: Gaze provides subtle informative cues to aid fluent interactions among people. Incorporating human gaze predictions can signify how engaged a person is while interacting with a robot and allow the robot to predict a human's intentions or goals. We propose a novel approach to predict human gaze fixations relevant for human-robot interaction tasks-both referential and mutual gaze-in real time on a robot. We use a deep learning approach which tracks a human's gaze from a robot's perspective in real time. The approach builds on prior work which uses a deep network to predict the referential gaze of a person from a single 2D image. Our work uses an interpretable part of the network, a gaze heat map, and incorporates contextual task knowledge such as location of relevant objects, to predict referential gaze. We find that the gaze heat map statistics also capture differences between mutual and referential gaze conditions, which we use to predict whether a person is facing the robot's camera or not. We highlight the challenges of following a person's gaze on a robot in real time and show improved performance for referential gaze and mutual gaze prediction.


Title: A Natural Adaptive Control Law for Robot Manipulators
Key Words: adaptive control  control system synthesis  geometry  manipulators  natural adaptive control law  robot manipulators  robot parameters  coordinate-invariant differential geometric structure  Adaptive control  Symmetric matrices  Robot kinematics  Lead  Manipulators  Measurement 
Abstract: Existing adaptive robot control laws typically require an engineering choice of a constant adaptation gain matrix, which often involves repeated and time-consuming trial and error. Moreover, physical consistency of the estimated inertial parameters or the uniform positive definiteness of the estimated robot mass matrix cannot in general be guaranteed without nonsmooth corrections, e.g., projection to the boundary of the feasible parameter set. In this paper we present a natural adaptive control law that mitigates many of these difficulties, by exploiting the coordinate-invariant differential geometric structure of the space of physically consistent inertial parameters. Our approach provides a more generalizable and physically consistent adaptation law for the robot parameters without significant additional computations compared to existing methods. Simulation results showing markedly improved tracking error convergence over existing adaptive control laws are provided as validation.


Title: Map-based Deep Imitation Learning for Obstacle Avoidance
Key Words: collision avoidance  decision making  inference mechanisms  learning (artificial intelligence)  mobile robots  optimisation  robot vision  SLAM (robots)  mobile robots  deep imitation learning algorithm  egocentric local occupancy maps  fast feed-forward inferences  policy robustness  optimal decision making  obstacle avoidance policy  map-based deep imitation learning  value iteration networks  near-optimal continuous action commands  planning-based scenarios  Collision avoidance  Robot kinematics  Mobile robots  Training  Neural networks  Trajectory 
Abstract: Making an optimal decision to avoid obstacles while heading to the goal is one of the fundamental challenges for mobile robots equipped with limited computational resources. In this paper, we present a deep imitation learning algorithm that develops a computationally efficient obstacle avoidance policy based on egocentric local occupancy maps. The trained model embedded with a variant of the value iteration networks is able to provide near-optimal continuous action commands through fast feed-forward inferences and generalize well to unseen planning-based scenarios. To improve the policy robustness, we augment the training data set with artificially generated maps, which effectively alleviates the shortage of catastrophic samples in normal demonstrations. Extensive experiments on a Segway robot show the effectiveness of the proposed approach in terms of solution optimality, robustness as well as computation time.


Title: Wireframe Mapping for Resource-Constrained Robots
Key Words: mobile robots  path planning  simulation mapping  wireframe mapping  resource-constrained robots  wireframe representation  particle filter  sparse wireframe map structure  map representation  wireframe structure  occupancy grid map  discrete map errors  Simultaneous localization and mapping  Uncertainty  Two dimensional displays  Geometry  Navigation 
Abstract: This paper presents a novel wireframe map structure for resource-constrained robots operating in a rectilinear 2D environment. The wireframe representation compactly represents geometry, in addition to transient situations such as occlusions and boundaries of unexplored regions. We formulate a particle filter to suit this sparse wireframe map structure. Functions for calculating the likelihood of scans, merging wireframes, and resampling are developed to accommodate this map representation. The wireframe structure with the particle filter allows for severe discrete map errors to be corrected, leading to accurate maps with small storage requirements. We show in a simulation study that the algorithm attains a map of an environment with 1 % error, compared to an occupancy grid map obtained with GMapping which attained 23% error with the same storage requirements. A simulation mapping a large environment demonstrates the algorithms scalability.


Title: Improving Trajectory Optimization Using a Roadmap Framework
Key Words: mobile robots  optimisation  path planning  sampling methods  trajectory control  trajectory optimization process  sampling-based planners  motion planning system  multiquery roadmap  sparse roadmap framework  optimization-based motion planners  Planning  Trajectory optimization  Robots  Dynamics  Task analysis  Collision avoidance 
Abstract: We present an evaluation of several representative sampling-based and optimization-based motion planners, and then introduce an integrated motion planning system which incorporates recent advances in trajectory optimization into a sparse roadmap framework. Through experiments in 4 common application scenarios with 5000 test cases each, we show that optimization-based or sampling-based planners alone are not effective for realistic problems where fast planning times are required. To the best of our knowledge, this is the first work that presents such a systematic and comprehensive evaluation of state-of-the-art motion planners, which are based on a significant amount of experiments. We then combine different stand-alone planners with trajectory optimization. The results show that the combination of our sparse roadmap and trajectory optimization provides superior performance over other standard sampling-based planners' combinations. By using a multi-query roadmap instead of generating completely new trajectories for each planning problem, our approach allows for extensions such as persistent control policy information associated with a trajectory across planning problems. Also, the sub-optimality resulting from the sparsity of roadmap, as well as the unexpected disturbances from the environment, can both be overcome by the real-time trajectory optimization process.


Title: PH Model-Based Shape Reconstruction of Heterogeneous Continuum Closed Loop Kinematic Chain: An Application to Skipping Rope
Key Words: closed loop systems  manipulator dynamics  manipulator kinematics  mobile robots  position control  skipping rope  soft robotics  demanding field  shape reconstruction method  kinematic behavior  heterogeneous continuum robot  closed loop kinematic configuration  Pythagorean Hodograph curves  Compact Bionic Handling Arms  intermediate flexible rope  PH model-based shape reconstruction  heterogeneous continuum closed loop kinematic chain  continuum robots  Manipulators  Shape  Kinematics  Biological system modeling  Electron tubes  Mathematical model 
Abstract: Soft robotics is a swiftly growing research area these days. Modeling continuum robots accurately is still a demanding field. The paper aims to propose a shape reconstruction method and the estimation of the kinematic behavior of heterogeneous continuum robot in closed loop kinematic configuration, by using Pythagorean Hodograph (PH) curves. The validation of the model approach has been tested on cooperative continuum robots, namely Compact Bionic Handling Arms (CBHA), driving an intermediate flexible rope (a passive flexible link), by using a 3D tracking system. Experimental comparison of the proposed approach with the existing approaches is performed in terms of accuracy as well as the time cost.


Title: Optimal Feedback Control Based on Analytical Linear Models Extracted from Neural Networks Trained for Nonlinear Systems
Key Words: control system synthesis  feedback  linear systems  neurocontrollers  nonlinear control systems  optimal control  robots  neural network  mathematical models  control theory  optimal feedback control  analytical linear models  nonlinear systems  robots  soft structures  flexible musculoskeletal systems  systematic design policy  conventional robotics  linear system models  Mathematical model  Neural networks  Computational modeling  Manipulators  Control theory  Aerospace electronics 
Abstract: A number of researches have been focusing on the development and control of robots with soft structures such as flexible musculoskeletal systems. Thus far, it has been reported that these robots can achieve high adaptability to environments despite their extremely simple controllers. However, because these robots are difficult to model mathematically, there is still no systematic design policy, in which control theory has been playing a role in conventional robotics, for constituting simple controllers. To tackle this problem, we propose a new approach using a neural network to obtain mathematical models. In particular, with this method, the control theory is applied to linear system models extracted from a network trained to express the forward dynamics of a robot. Through simulations, the validity and advantage of the proposed method was successfully confirmed.


Title: Learning to Grasp by Extending the Peri-Personal Space Graph
Key Words: dexterous manipulators  graph theory  grippers  learning (artificial intelligence)  mobile robots  motion control  position control  robot vision  robot model  infant learning  human infants  robotic learning agent  analogous models  deliberate grasp action  Palmar reflex  PPS graph  peri-personal space graph model  grasp learning  jerky submotions  gripper fingers  Manipulators  Reliability  Grippers  Robot sensing systems  Visualization  Trajectory 
Abstract: We present a robot model of early reach and grasp learning, inspired by infant learning without prior knowledge of the geometry, kinematics, or dynamics of the arm. Human infants at reach onset are capable of using a sequence of jerky submotions to bring the hand to the position of a nearby object. A robotic learning agent can produce qualitatively similar behavior by using a graph representation to encode a set of safe, potentially useful arm states and feasible moves between them. These observations show that the Peri-Personal Space (PPS) Graph model is sufficient for early reaching and suggest that infants may use analogous models during this phase. In this paper, we show that the PPS Graph, with a simulated Palmar reflex (a reflex in infants that closes the fingers when the palm is touched), allows accidental grasps to occur during continued reaching practice. Given these occasional events, the agent can bootstrap to a simple deliberate grasp action. In particular, the agent must learn three new necessary conditions for a grasp: the hand should be open as the grasp begins, the final motion of the hand should be led by the gripper opening so that it reaches the target first, and the wrist must be oriented such that the gripper fingers may close around the target object, often requiring the opening to be perpendicular to the object's major axis. Combined with the existing capability to reach and interact with target objects, knowledge of these conditions allows the agent to learn increasingly reliable purposeful grasps. The first two conditions are addressed in this paper, and allow 45% of grasps to succeed. This work contributes toward the larger goal of foundational robot learning after the model of infant learning, with minimal prior knowledge of its own anatomy or its environment. The ability to grasp will allow the agent to control the motion and position of objects, providing a richer representation for its environment and new experiences to learn from.


Title: Impedance Control of a High Performance Twisted-Coiled Polymer Actuator
Key Words: actuators  closed loop systems  control nonlinearities  control system synthesis  damping  digital control  force control  manipulators  motion control  position control  stability  worst position error  impedance control  angular position reference  control system  backstepping control law  torque-based law  variable stiffness  position control  model-based impedance controller  Joule heating capability  nylon fibers  embedded controller  high performance super-coiled polymer actuators  1-link robotic arm  high performance twisted-coiled polymer actuator  Actuators  Impedance  Mathematical model  Force  Damping  Strain  Water heating 
Abstract: This paper presents a 1-link robotic arm that is antagonistically driven by one pair of a high performance super-coiled polymer actuators with an embedded controller. The actuator which is made from Spandex and nylon fibers is low-cost, easy to fabricate and light-weight. Moreover, it can generate large displacement and provide Joule heating capability. The main contribution of the paper is the model-based impedance controller, which enables position control of the antagonistic joint with variable stiffness and damping. The impedance control is a torque-based law, which in turn depends on a proposed backstepping control law to control the force of each actuator. The control system is proved to be stable using dissipativity stability theory and verified through experiments. Experimental results show that our system can track the angular position reference with the worst position error of 0.43deg and root-mean squared error of 0.16deg at steady state for sinusoidal waveform tracking (with the frequency of 0.1Hz), and the worst position error of 0.2deg for set-point regulation.


Title: Jumping Motion Generation of a Humanoid Robot Utilizing Human-Like Joint Elasticity
Key Words: humanoid robots  legged locomotion  human-like joint elasticity  jumping motion generation  leaf springs  joint mechanism  joint stiffness  active pushing-off  countermovement jump method  spring behavior  active joint driving  high-power movement  humanoid robots  Elasticity  Legged locomotion  Springs  Humanoid robots  Trajectory  Force 
Abstract: To improve the movement ability of humanoid robots, instead of traditional methods dependent on only power of actuators, there is possibility that utilizing elasticity inspired from collaboration of muscle and tendon of human is effective to achieve high-power movement. In this study, we aimed to realize a jumping motion that accumulates energy more appropriately in spring by combining active joint driving with spring behavior like human tendons and muscles. We proposed a countermovement jump method using the resonance with the leg's active pushing-off movement and leg stiffness. To achieve active pushing-off and joint stiffness, we developed a new joint mechanism using leaf springs and an actuator unit with a worm gear. We then performed experiments to evaluate the effectiveness of the proposed mechanism and methods. Finally, the robot achieved a countermovement jump using active kicking and leg's elasticity.


Title: Secure Data Recording and Bio-Inspired Functional Integrity for Intelligent Robots
Key Words: data recording  digital forensics  intelligent robots  security of data  modern robots  complex machines  bio-inspired functional integrity  secure data recording  uncontrolled environment  flight data recorder  intelligent robots  transparent function  Digital signatures  Intelligent robots  Public key  Forensics 
Abstract: As modern robots become more intelligent, also their use will broaden in public and professional areas. While the aim is to make robots beneficial to humans and society, using those complex machines in complex environments will eventually lead to incidents. To enable forensic investigations, ethical evaluations and transparent function of intelligent robots in a society, we contribute the concept of a secure robot data recorder that is similar to a flight data recorder in airplanes. However, since robots work in a highly networked and uncontrolled environment, our concept pays special attention to security and tamper proofness. In addition, we extend the concept with an approach inspired by cockroaches to increase the functional integrity of the robot. We present a prototype implementation along with discussions on the required properties and limits of secure data recording.


Title: Master-Slave Coordination Using Virtual Constraints for a Redundant Dual-Arm Haptic Interface
Key Words: force feedback  redundant manipulators  master-slave coordination  virtual constraints  redundant dual-arm haptic interface  force interaction  immersive haptic interface  task demonstration  robotic systems  haptic feedback  Robot kinematics  Task analysis  Haptic interfaces  Manipulators  Kinematics  Tools 
Abstract: Programming robots for tasks involving force interaction is difficult, since both the knowledge of the task and the dynamics of the robots are necessary. An immersive haptic interface for task demonstration is proposed, where the operator can sense and act through the robot. This is achieved by coupling two robotic systems with virtual constraints such that they have the same coordinates in the operational space disregarding a fixed offset. Limitations caused by the singular configurations or the reach of the robots are naturally reflected to either side as haptic feedback.


Title: Gaussian Process Dynamic Programming for Optimizing Ungrounded Haptic Guidance
Key Words: dynamic programming  Gaussian processes  gyroscopes  haptic interfaces  human-robot interaction  Gaussian process dynamic programming  ungrounded haptic guidance  human-robot interactions  haptic devices  ungrounded control moment gyroscope haptic device  cued haptic direction  Haptic interfaces  Torque  Brushless motors  Quaternions  Task analysis  Gaussian processes  Robots 
Abstract: Adapting robot actions to human motions can make human-robot interactions (HRI) more effective. Here, we aim to optimize guidance from haptic devices based on a user's response to produce better task performance. We used Gaussian processes to model the motions a human user made in response to applied torques from an ungrounded control moment gyroscope haptic device. We then used Gaussian process dynamic programming to generate optimized haptic cues to guide the user to rotate the device toward 3D targets. We compared the performance of naive and optimized policies in simulations and with a human user, and found that dynamic programming can significantly improve haptic guidance in cases where human responses are highly variable or inconsistent with the cued haptic direction.


Title: A Novel Input Device for Robotic Prosthetic Hand: Design and Preliminary Results
Key Words: biomechanics  biomedical electrodes  electromyography  medical robotics  medical signal processing  multilayer perceptrons  prosthetics  signal classification  medical electrodiagnostic techniques  EMG signal  impedance change  skin  noncontact manner  hand movements  novel input device  robotic prosthetic hand  capacitance change  data processing  deformation  electrode  sensor  multilayer perceptron  classification success rates  Skin  Electrodes  Capacitance  Muscles  Robot sensing systems  Electromyography  Input devices 
Abstract: In this paper, we propose a novel input device for a robotic prosthetic hand based on capacitance change. The proposed device can sense the deformation of the skin due to the activity of the muscle by measuring the capacitance change between the skin and the electrode. Therefore, it can be used as a sensor for estimating a user's intention through medical electrodiagnostic techniques such as electromyogram (EMG)and force myography (FMG). The proposed device can acquire data in a non-invasive way and is advantageous with easier data processing than that for an EMG signal. Moreover, it is resistant to the impedance change of skin because the capacitance is measured in a non-contact manner, unlike the existing methods which work with direct contact with the skin such as EMG. Additionally, unlike FMG, the device is lightly attached to the skin without being strongly fixed with velcro, which offsets problems that occur while re-wearing the device. To demonstrate the feasibility of the proposed idea, three of the newly developed input devices were used to classify four hand movements (fist, scissors, paper, and rest)using a multilayer perceptron (MLP). As a result, the classification success rates for the fist, paper, scissor, and rest motions were obtained as 99.3%, 98.3%, 98.4%, and 99.1%, respectively.


Title: Continuous State-Action-Observation POMDPs for Trajectory Planning with Bayesian Optimisation
Key Words: belief networks  decision making  decision theory  Hilbert spaces  Markov processes  mobile robots  optimisation  path planning  trees (mathematics)  trajectory planning  POMDP solvers  CBTS  dynamic sampling  robot parking problems  bayesian optimisation  partially observable Markov decision process  reproducing kernel Hilbert spaces  kCBTS  continuous belief tree search  RKHS  Trajectory  Planning  Robots  Optimization  Kernel  Bayes methods  Mathematical model 
Abstract: Decision making under uncertainty is a challenging task, especially when dealing with complex robotics scenarios. The Partially Observable Markov Decision Process (POMDP) framework, designed to solve this problem, was subject to much work lately. Most POMDP solvers, however, focus on planning in discrete state, action and/or observations spaces, which does not truly reflect the complexity of most real world problems. This paper addresses the issue by devising a method for solving POMDPs with continuous state, action and observations spaces. The proposed planner, Continuous Belief Tree Search (CBTS), uses Bayesian Optimisation (BO) to dynamically sample promising actions while constructing a belief tree. This dynamic sampling allows for richer action selection than offline action discretisation. CBTS is complemented by a novel trajectory generation technique, relying on the theory of Reproducing Kernel Hilbert Spaces (RKHS), yielding trajectories amenable for robotics applications. The resulting trajectory planner kCBTS outperforms other continuous planners on space modelling and robot parking problems.


