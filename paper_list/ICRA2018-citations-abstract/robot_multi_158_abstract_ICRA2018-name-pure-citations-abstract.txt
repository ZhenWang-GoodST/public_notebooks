total paper: 158
Title: Design and kinematics characterization of a laser-profiled continuum manipulator for the guidance of bronchoscopic instruments
Abstract: Bronchoscopic intervention, as a minimally invasive method for the diagnosis and treatment of lung diseases, has attracted more and more attention in recent years. However, existing endobronchial instruments lack the steerability accessing the peripheral airways with difficult bifurcations. This paper presents a novel wire-driven dexterous manipulator for the guidance of such instruments. Precision laser profiling is used to cut a stainless steel tube into multiple interlocked segments with revolute joints. The outer diameter of the manipulator is 2.20 mm which is small enough to be inserted into the working channels of most commercial bronchoscopes and distal airways, while keeping a large inner lumen with a diameter of 1.44 mm for passing various bronchoscopic instruments. The small bending radius provides enough flexibility to navigate inside the complex bronchial tree. Two kinematic models are proposed to predict the manipulator configuration from the translation of actuation wires. The former model is geometrically derived with the assumption of constant curvature bending and the latter one is statistically driven by capturing the motion trajectories of manipulator joints. A prototype of our low-cost add-on instrument guidance robot for bronchoscopic intervention is presented which can be easily integrated into current clinical routine.


Title: Deep Neural Networks for Multiple Speaker Detection and Localization
Abstract: We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.


Title: Requirements Based Design and End-to-End Dynamic Modeling of a Robotic Tool for Vitreoretinal Surgery
Abstract: Despite several robots having been proposed for vitreoretinal surgery, there is limited information on their dynamic modeling. This gap leads to sub-optimal motor selection and hinders the application of advanced control schemes that would fulfill the goal of micro-precise surgery. This paper presents the design process and a dynamics study of a multi-Degree of Freedom (DoF) robotic system, which is inspired by established co-manipulation architectures. A rigorous kinematics and dynamics analysis of the robot's part that is responsible for manipulating the surgical tool during the retinal surgery phase is provided. In particular, the Euler-Lagrange equations of motion, which describe the dynamics of the 3-link surgical manipulator, are combined with novel analytical models of each link's corresponding transmission mechanism, including an anti-backlash lead screw assembly and a worm drive. The resulting models, transferable to existing manipulators, provide a meticulous analysis of the robot's performance that can be used both for mechanical design and control purposes.


Title: Differentiation of C2C12 Myoblasts and Characterization of Electro-Responsive Beating Behavior of Myotubes Using Circularly Distributed Multiple Electrodes for Bio-Syncretic Robot
Abstract: Micro-robots have a great application prospect in the biomedical field due to the feature of small size. To solve the issues of energy supply and bio-compatibility of micro-robots, bio-syncretic micro-robots composed of biological materials and electromechanical systems have been studied widely. The skeletal muscle is a potential material to develop bio-actuator for the bio-syncretic robots on account of the great contraction force and the controllability. However, the low differentiation quality of C2C12s and the control of the bio-syncretic robots are the two of the main challenges for the development of the bio-syncretic robots based on the skeleton muscle. In this paper, an approach based on circularly distributed multiple electrodes (CDMEs) was proposed to improve the differentiation of C2C12 myoblast cells and characterize the electro-responsive beating behavior of myotubes for the development of bio-syncretic robots. Three groups of C2C12 blasts were used to fulfill the differentiation experiments without electrical stimulation and with electrical stimulation using parallel electrodes and CDMEs respectively, for evaluating the effect of CDMEs on C2C12 differentiation. It was demonstrated that electrical field through CDMEs can improve the differentiation quality of C2C12 blasts into myotubes in terms of intensity, length, and widths. Then, the effect of electrical stimulation on the beating behaviors of myotubes was also investigated with CDMEs, and it was shown that the beating amplitudes of myotubes were significantly affected by the frequencies, amplitude and direction of electrical stimulation with respect to the myotubes, which is fundamental for the control of the micro-robot based on skeletal muscle cells. The proposed approach is useful for not only the development of the bio-syncretic robots, but also the study of muscle tissue engineering.


Title: Compliant Low Profile Multi-Axis Force Sensors
Abstract: The development of soft, compliant force sensors is greatly sought after in areas such as soft robotics and prosthetics. Nevertheless, solutions for measuring forces in multiple axes, while being mechanically compliant, have been few and far between. Here we present a compliant sensor able to detect forces tangential and normal to the sensor surface. The transduction mechanism is based on the deformation of laser-machined carbon fiber composite (CFC) micro-scale meanders, encapsulated within elastomers layers. Strains in the elastomer are transmitted to the meanders, causing changes in the electrical resistance of the sensor contact mechanics. Configuring the meanders in a radial pattern, segmenting them into quadrants (two antagonist pairs) and biasing the center of the sensor out-of-plane enables detection of forces in multiple axis via differential measurement. Sensors were manufactured using a custom fabrication process and exhibited high mechanical compliance with a very low form factor. The sensors were experimentally characterized and demonstrated large differential changes in resistance (up to 26 kÎ© for tangential forces applied to the sensor surface). We integrated our sensor onto a soft robotic gripper finger and demonstrated the ability to detect changes in friction at the actuator surface, thus demonstrating their potential for real world applications.


Title: Reactive Planar Manipulation with Convex Hybrid MPC
Abstract: This paper presents a reactive controller for planar manipulation tasks that leverages machine learning to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes. To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from machine learning, this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem.


Title: Modeling and Control of Multi-Arm and Multi-Leg Robots: Compensating for Object Dynamics During Grasping
Abstract: We consider a virtual manipulator in grasping scenarios which allows us to capture the effect of the object dynamics. This modeling approach turns a multi-arm robot into an underactuated system. We observe that controlling floating-base multi-leg robots is fundamentally similar. The Projected Inverse Dynamics Control approach is employed for decoupling contact consistent motion generation and controlling contact wrenches. The proposed framework for underactuated robots has been evaluated on an enormous robot hand composed of four KUKA LWR IV+ representing fingers cooperatively manipulating a 9kg box with total 28 actuated DOF and six virtual DOF representing the object as additional free-floating robot link. Finally, we validate the same approach on ANYmal, a floating-base quadruped with 12 actuated DOF. Experiments are performed both in simulation and real world.


Title: Multi-Priority Cartesian Impedance Control Based on Quadratic Programming Optimization
Abstract: In this work we introduced a prioritized Cartesian impedance control under the framework of the Quadratic Programming (QP) optimization. In particular, we present a formulation which is simpler than full inverse dynamics, avoids any matrix pseudo-inversion, inverse kinematics computation and considers strict priorities among tasks. Our formulation is based on QP optimization permitting to take into account also explicit inequality constraints. We compare in simulation the tracking results obtained with a classical algebraic implementation against those derived from the proposed QP implementation taking into account joint torque limits. We consider the classical Cartesian impedance controller and a simplified version, also known as Virtual Model Control. Finally the proposed method was implemented and validated on a humanoid upper-body torque controlled robot. Experimental trials involving various physical interaction conditions were executed to demonstrate the performance of the proposed method.


Title: Contact Point Localization for Articulated Manipulators with Proprioceptive Sensors and Machine Learning
Abstract: A model-based Machine Learning (ML) approach is presented to detect and localize external contacts on a 6 degree of freedom (DoF) serial manipulator. This approach only requires the use of proprioceptive sensors (joint positions, velocities and one-dimensional (ID) joint torques already available in the robot arm). Good results are obtained with Random Forests (RFs) and Multi-Layer-Perceptrons (MLPs) leading to a precise localization of the contact link and its orientation. Apart from the link in contact and the orientation of the force, RFs and MLPs are also able to differentiate between contact points on the same link and orientation but with different distances to the joint axis. We experimentally verify this approach on simulated and real data obtained from the Kinova Jaco 2 manipulator and compare it to an optimization based approach.


Title: $L_{1}$ Robustness of Computed Torque Method for Robot Manipulators
Abstract: This paper revisits computed torque method for robot manipulators and aims at developing its new framework based on the L1 robustness, in which the Lâ norm together with its induced norm is employed to characterize model uncertainties and a performance measure. More precisely, we consider the L1 robust stability and performance for a given robot manipulator with a computed torque controller. We first show that the modelling errors in the computed torque method can be divided into an exogenous disturbance and a multiplicative model uncertainty, which are bounded in terms of the Lâ norm and its induced norm, respectively. It is next shown that the robot manipulator with the computed torque controller can be equivalently represented by an interconnection of a continuous-time linear time-invariant (LTI) nominal plant and a stabilizing controller together with the Lâ-induced norm bounded model uncertainty. Based on the interconnected representation, the L1 robust stability condition and an upper bound of the L1 performance against the exogenous disturbance with respect to all model uncertainties in a class of a bounded Lâ-induced norm are dealt with by using the small-gain theorem. Finally, the effectiveness of the theoretical results is demonstrated through some experiment results.


Title: Coverage Path Planning Under the Energy Constraint
Abstract: In the coverage path planning problem, a common assumption is that the robot can fully cover the environment without recharging. However, in reality most mobile robot systems operate under battery limitations. To incorporate this constraint, we consider the problem when the working environment is large and the robot needs to recharge multiple times to fully cover the environment. We focus on a geometric version where the environment is represented as a polygonal grid with a single charging station. Energy consumption throughout the environment is assumed to be uniform and proportional to the distance traveled. We first present a constant-factor approximation algorithm for contour-connected environments. We then extend the algorithm for general environments. We also validate the results in experiments performed with an aerial robot.


Title: The Dubins Car and Other Arm-Like Mobile Robots
Abstract: This paper investigates the connection between the kinematics of robots arms and the shortest paths for mobile robots. Lagrange multipliers are used to show that the shortest paths are equivalent to arms in configurations that balance an external force, while applying equal torques and forces at each joint. Analysis of the arm Jacobian yields a further geometric interpretations of optimal paths, constraining the locations of rotation centers and the directions of translations that may occur along optimal paths.


Title: Online Falling-Over Control of Humanoids Exploiting Energy Shaping and Distribution Methods
Abstract: This paper proposes a novel fall control technique based on energy concepts, which can be applied online to mitigate the impact forces incurred during the falling over of humanoids. The technique reduces the total energy using a nonlinear control tool, called energy shaping (ES), and further distributes the reduced energy over multiple contacts by means of energy distribution polygons (EDP). We also include an effective orientation control to safeguard the end-effectors in the event of ground impacts. The performance of the proposed method is numerically evaluated by dynamic simulations under the sudden falling over scenario of the humanoid robot for both lateral and sagittal falls. The effectiveness of the proposed ES and EDP concepts are verified by diverse comparative simulations with total energy, distribution, and impact forces.


Title: MaestROB: A Robotics Framework for Integrated Orchestration of Low-Level Control and High-Level Reasoning
Abstract: This paper describes a framework called MaestROBe It is designed to make the robots perform complex tasks with high precision by simple high-level instructions given by natural language or demonstration. To realize this, it handles a hierarchical structure by using the knowledge stored in the forms of ontology and rules for bridging among different levels of instructions. Accordingly, the framework has multiple layers of processing components; perception and actuation control at the low level, symbolic planner and Watson APIs for cognitive capabilities and semantic understanding, and orchestration of these components by a new open source robot middleware called Project Intu at its core. We show how this framework can be used in a complex scenario where multiple actors (human, a communication robot, and an industrial robot) collaborate to perform a common industrial task. Human teaches an assembly task to Pepper (a humanoid robot from SoftBank Robotics) using natural language conversation and demonstration. Our framework helps Pepper perceive the human demonstration and generate a sequence of actions for UR5 (collaborative robot arm from Universal Robots), which ultimately performs the assembly (e.g. insertion) task.


Title: Ctrl-MORE: A Framework to Integrate Controllers of Multi-DoF Robot for Developers and Users
Abstract: In recent years, many different feedback controllers for robotic applications have been proposed and implemented. However, the high coupling between the different software modules made their integration into one common architecture difficult. Consequently, this has hindered the ability of a user to employ the different controllers into a single, general and modular framework. To address this problem, we present Ctrl-MORE, a software architecture developed to fill the gap between control developers and other users in robotic applications. On one hand, Ctrl-MORE aims to provide developers with an opportunity to integrate easily and share their controllers with other roboticists working in different areas. For example, manipulation, locomotion, vision and so on. On the other hand, it provides to end-users a tool to apply the additional control strategies that guarantee the execution of desired behaviors in a transparent, yet efficient way. The proposed control architecture allows an easier integration of general purpose feedback controllers, such as stabilizers, with higher control layers such as trajectory planners, increasing the robustness of the overall system.


Title: ModQuad: The Flying Modular Structure that Self-Assembles in Midair
Abstract: We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.


Title: Design Considerations and Redundancy Resolution for Variable Geometry Continuum Robots
Abstract: Current multi-backbone continuum robots are limited to a constant cross-sectional diameter. This paper proposes a design alternative that overcomes this limitation. The ability to change the diameter of a continuum robot expands the repertoire of kinematic redundancy and enables kinematic parameter adaptation to optimize performance. A continuum robot design based on the angulated scissor mechanism is presented along with its position analysis. An exploration of admissible design parameter values for a given continuum robot segment with a desired maximum curvature while maintaining an open bore along its center is also carried out. A design presenting how this mechanism can be incorporated into a continuum robot is shown and a strategy for minimizing joint forces and avoiding joint limits is formulated as a gradient descent redundancy resolution problem in a simulation case study. The simulation results show that varying the diameter can significantly reduce joint forces while preserving the workspace and avoiding joint limits. This work is a first step towards continuum robots with situational awareness that will use their sensing capabilities to adapt their structure in order to optimize task execution performance.


Title: Cubic Range Error Model for Stereo Vision with Illuminators
Abstract: Use of low-cost depth sensors, such as a stereo camera setup with illuminators, is of particular interest for numerous applications ranging from robotics and transportation to mixed and augmented reality. The ability to quantify noise is crucial for these applications, e.g., when the sensor is used for map generation or to develop a sensor scheduling policy in a multi-sensor setup. Range error models provide uncertainty estimates and help weigh the data correctly in instances where range measurements are taken from different vantage points or with different sensors. Such a model is derived in this work. We show that the range error for stereo systems with integrated illuminators is cubic and validate the proposed model experimentally with an off-the-shelf structured light stereo system. The experiments confirm the validity of the model and simplify the application of this type of sensor in robotics.


Title: Available Wrench Set for Planar Mobile Cable-Driven Parallel Robots
Abstract: Cable-Driven Parallel Robots (CDPRs) have several advantages over conventional parallel manipulators most notably a large workspace. CDPRs whose workspace can be further increased by modification of the geometric architecture are known as Reconfigurable Cable Driven Parallel Robots(RCDPRs). A novel concept of RCDPRs, known as Mobile CDPR (MCDPR) that consists of a CDPR carried by multiple mobile bases, is studied in this paper. The system is capable of autonomously navigating to a desired location then deploying to a standard CDPR. In this paper, we analyze the Static equilibrium (SE) of the mobile bases when the system is fully deployed. In contrast to classical CDPRs we show that the workspace of the MCDPR depends, not only on the tension limits, but on the SE constraints as well. We demonstrate how to construct the Available Wrench Set (AWS) for a planar MCDPR wih a point-mass end-effector using both the convex hull and Hyperplane shifting methods. The obtained results are validated in simulation and on an experimental platform consisting of two mobile bases and a CDPR with four cables.


Title: Adversarial Training for Adverse Conditions: Robust Metric Localisation Using Appearance Transfer
Abstract: We present a method of improving visual place recognition and metric localisation under very strong appearance change. We learn an invertable generator that can transform the conditions of images, e.g. from day to night, summer to winter etc. This image transforming filter is explicitly designed to aid and abet feature-matching using a new loss based on SURF detector and dense descriptor maps. A network is trained to output synthetic images optimised for feature matching given only an input RGB image, and these generated images are used to localize the robot against a previously built map using traditional sparse matching approaches. We benchmark our results using multiple traversals of the Oxford RobotCar Dataset over a year-long period, using one traversal as a map and the other to localise. We show that this method significantly improves place recognition and localisation under changing and adverse conditions, while reducing the number of mapping runs needed to successfully achieve reliable localisation.


Title: Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming
Abstract: Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.


Title: Planning-Aware Communication for Decentralised Multi-Robot Coordination
Abstract: We present an algorithm for selecting when to communicate during online planning phases of coordinated multi-robot missions. The key idea is that a robot decides to request communication from another robot by reasoning over the predicted information value of communication messages over a sliding time-horizon, where communication messages are probability distributions over action sequences. We formulate this problem in the context of the recently proposed decentralised Monte Carlo tree search (Dec-MCTS) algorithm for online, decentralised multi-robot coordination. We propose a particle filter for predicting the information value, and a polynomial-time belief-space planning algorithm for finding the optimal communication schedules in an online and decentralised manner. We evaluate the benefit of informative communication planning for a multi-robot information gathering scenario with 8 simulated robots. Our results show reductions in channel utilisation of up to four-fifths with surprisingly little impact on coordination performance.


Title: Multi-Robot Realization Based on Goal Adjacency Constraints
Abstract: This paper considers the problem of multi-robot realization. A realization is a set of robot positions where pairwise distances are either bounded from above or from below by a given adjacency threshold - depending on whether the respective robot pairs are to be adjacent or not. In the realization problem, unlike the related coordinated navigation or formation control problems, exact goal positions or relative distances need not be specified. Rather, only pairwise adjacency constraints are given and the robots' positions are required to satisfy these constraints. Applications of realization problem include multi-robots involved in team games (playing soccer, etc), patrolling and area coverage. We present a novel solution to this problem in which the robots simultaneously navigate to find a realization of a given adjacency matrix without colliding with each other along the way. In this solution, complete information about pairwise distances and free configuration space are encoded using an artificial potential function over the cross product space of the robots' simultaneous positions and proximity variables. The closed-loop dynamics governing the motion of each velocity-controlled robot take the form of the appropriate projection of the gradient of this function while pairwise distances are adjusted accordingly. Our extensive simulations demonstrate that the proposed approach has considerably higher realization percentage and shorter movement distances in comparison to a standard 2-stage approach.


Title: Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication
Abstract: We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.


Title: An Energy-Based Approach for the Multi-Rate Control of a Manipulator on an Actuated Base
Abstract: In this paper we address the problem of controlling a robotic system mounted on an actuated floating base for space applications. In particular, we investigate the stability issues due to the low rate of the base control unit. We propose a passivity-based stabilizing controller based on the time domain passivity approach. The controller uses a variable damper regulated by a designed energy observer. The effectiveness of the proposed strategy is validated on a base-manipulator multibody simulation.


Title: Optimal Intermittent Deployment and Sensor Selection for Environmental Sensing with Multi-Robot Teams
Abstract: In this paper, we formulate an environmental sensing problem for multi-robot teams that couples intermittent deployments with the selection of team composition and sensor type over time. We suppose that a multi-robot team needs to autonomously sense an environmental process and find the optimal policy for deploying heterogeneous robots. In addition, heterogeneous robot teams can be composed in various ways by selecting different mobility and sensor types which have varying accuracies and costs, resulting in a more complex problem. The question is then how to find an optimal intermittent deployment and sensor selection policy that captures both cost and estimation accuracy based on partial environmental information. By utilizing structural results from partially observable Markov decision processes (POMDP) and exploiting submodularity, an optimal policy, which minimizes cost while maintaining a high accuracy, can be achieved in this paper. The effectiveness of this method is demonstrated by simulation results and comparisons with naive policies.


Title: Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning
Abstract: In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.


Title: Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints
Abstract: Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.


Title: Time-Contrastive Networks: Self-Supervised Learning from Video
Abstract: We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.


Title: Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints
Abstract: Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.


Title: GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation
Abstract: Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.


Title: Stiffness Variability in Jamming of Compliant Granules and a Case Study Application in Climbing Vertical Shafts
Abstract: Jamming of granular media has been shown to possess the property of stiffness variation, transitioning from a soft to a quasi-solid state depending on the packing density of the granules. Recently, a gradual stiffness change for bending has been reported by using compliant, cubic shaped granules. Here we demonstrate that the same method and material also exhibits a gradual stiffness change for compression. As a potential application of âcompliant jammingâ, a bio-inspired robotic platform with jamming membranes as end effectors is designed and tasked with climbing straight vertical shafts. First, the benefit of varying the bending stiffness is investigated in the climbing task by measuring the friction force that the end effectors are applying to the shaft walls, especially if the walls are irregularly shaped. Then the role of compressive stiffness variation is explored by analyzing the performance of the robot in the climbing task, showing multi-modal properties of jamming membranes: (i) enabling a pressure sensor to detect the shaft walls, acting (ii) as grippers that actively use the irregularities of the walls to climb up by state-switching the granular material and (iii) as force dissipators that can dissipate internal forces caused by closed kinematic chains.


Title: A Geometric and Unified Approach for Modeling Soft-Rigid Multi-Body Systems with Lumped and Distributed Degrees of Freedom
Abstract: In this paper, a geometric and unified model of soft-rigid multi-body systems is presented, based on a discrete Cosserat approach of the soft-body dynamics. The model is in fact a generalization to soft and hybrid systems of the geometric theory of rigid robotics characterized by the exponential map. A generalization of the recursive Newton-Euler algorithm is also presented, able to solve inverse and forward dynamic problems with linear O(N) complexity. The proposed model provides several improvements with respect to the existing flexible multi-body models, which make it particularly suitable to study the dynamics of modern soft robots as shown for a multi-body system inspired by motile bacteria.


Title: Completion Time Analysis for Automated Manufacturing Systems with Parallel Processing Modules
Abstract: This paper analyzes the completion time of automated manufacturing systems, especially a dual-armed cluster tool, equipped with parallel processing modules (PMs). Cluster tools, which consist of multiple PMs, a transport robot, and loadlocks where wafer lots are loaded and unloaded, perform semiconductor manufacturing processes, such as lithography, etching, deposition, and testing. Wafer lots are transported by overhead hoist transports (OHTs) between tools or stockers where wafer lots are stored. To reduce the idle time of OHTs or cluster tools, it is essential to estimate the time when all wafers of a lot finish processing in a tool. Hence, we derive closed-form expressions for the completion time of wafer lots, especially in dual-armed cluster tools with parallel PMs to reflect real circumstances of fabs. We finally show that the formulas derived can be used even when there are small processing time variations with numerical experiments.


Title: Reliably Arranging Objects in Uncertain Domains
Abstract: A crucial challenge in robotics is achieving reliable results in spite of sensing and control uncertainty. In this work, we explore the conformant planning approach to robot manipulation. In particular, we tackle the problem of pushing multiple planar objects simultaneously to achieve a specified arrangement without external sensing. Conformant planning is a belief-state planning problem. A belief state is the set of all possible states of the world, and the goal is to find a sequence of actions that will bring an initial belief state to a goal belief state. To do forward belief-state planning, we created a deterministic belief-state transition model from supervised learning based on off-line physics simulations. We compare our method with an on-line physics-based manipulation approach and show significantly reduced planning times and increased robustness in simulated experiments. Finally, we demonstrate the success of this approach in simulations and physical robot experiments.


Title: RoboTSP â A Fast Solution to the Robotic Task Sequencing Problem
Abstract: In many industrial robotics applications, such as spot-welding, spray-painting or drilling, the robot is required to visit successively multiple targets. The robot travel time among the targets is a significant component of the overall execution time. This travel time is in turn greatly affected by the order of visit of the targets, and by the robot configurations used to reach each target. Therefore, it is crucial to optimize these two elements, a problem known in the literature as the Robotic Task Sequencing Problem (RTSP). Our contribution in this paper is two-fold. First, we propose a fast, near-optimal, algorithm to solve RTSP. The key to our approach is to exploit the classical distinction between task space and configuration space, which, surprisingly, has been so far overlooked in the RTSP literature. Second, we provide an open-source implementation of the above algorithm, which has been carefully benchmarked to yield an efficient, ready-to-use, software solution. We discuss the relationship between RTSP and other Traveling Salesman Problem (TSP) variants, such as the Generalized Traveling Salesman Problem (GTSP), and show experimentally that our method finds motion sequences of the same quality but using several orders of magnitude less computation time than existing approaches.


Title: Modeling and Control of Brachiating Robots Traversing Flexible Cables
Abstract: This paper describes the dynamic modeling and locomotion control of a two-link underactuated brachiating robot traversing a flexible cable. A multi-body system comprised of a two-link robot, a flexible cable, and coupling soft junctions is modeled dynamically. This model is used to formulate an energy-minimizing optimal control strategy that includes the effects of cable vibration induced by robot locomotion. Optimized trajectories and control torque profiles are obtained via multiple-shooting and parametric trajectory approaches. Simulation results show that these optimal torque profiles result in energy-efficient continuous brachiation over a flexible cable. Additional studies examine how the optimal torque profiles change depending on the robot's initial position along a catenary cable.


Title: Planning Hybrid Driving-Stepping Locomotion on Multiple Levels of Abstraction
Abstract: Navigating in search and rescue environments is challenging, since a variety of terrains has to be considered. Hybrid driving-stepping locomotion, as provided by our robot Momaro, is a promising approach. Similar to other locomotion methods, it incorporates many degrees of freedom - offering high flexibility but making planning computationally expensive for larger environments. We propose a navigation planning method, which unifies different levels of representation in a single planner. In the vicinity of the robot, it provides plans with a fine resolution and a high robot state dimensionality. With increasing distance from the robot, plans become coarser and the robot state dimensionality decreases. We compensate this loss of information by enriching coarser representations with additional semantics. Experiments show that the proposed planner provides plans for large, challenging scenarios in feasible time.


Title: Robot Navigation in Complex Workspaces Using Harmonic Maps
Abstract: Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline âtuningâ of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.


Title: Backprop-MPDM: Faster Risk-Aware Policy Evaluation Through Efficient Gradient Optimization
Abstract: In Multi-Policy Decision-Making (MPDM), many computationally-expensive forward simulations are performed in order to predict the performance of a set of candidate policies. In risk-aware formulations of MPDM, only the worst outcomes affect the decision making process, and efficiently finding these influential outcomes becomes the core challenge. Recently, stochastic gradient optimization algorithms, using a heuristic function, were shown to be significantly superior to random sampling. In this paper, we show that accurate gradients can be computed - even through a complex forward simulation - using approaches similar to those in deep networks. We show that our proposed approach finds influential outcomes more reliably, and is faster than earlier methods, allowing us to evaluate more policies while simultaneously eliminating the need to design an easily-differentiable heuristic function. We demonstrate significant performance improvements in simulation as well as on a real robot platform navigating a highly dynamic environment.


Title: An MPC Walking Framework with External Contact Forces
Abstract: In this work, we present an extension to a linear Model Predictive Control (MPC) scheme that plans external contact forces for the robot when given multiple contact locations and their corresponding friction cone. To this end, we set up a two-step optimization problem. In the first optimization, we compute the Center of Mass (CoM) trajectory, foot step locations, and introduce slack variables to account for violating the imposed constraints on the Zero Moment Point (ZMP). We then use the slack variables to trigger the second optimization, in which we calculate the optimal external force that compensates for the ZMP tracking error. This optimization considers multiple contacts positions within the environment by formulating the problem as a Mixed Integer Quadratic Program (MIQP) that can be solved at a speed between 100-300 Hz. Once contact is created, the MIQP reduces to a single Quadratic Program (QP) that can be solved in real-time (<; 1kHz). Simulations show that the presented walking control scheme can withstand disturbances 2-3Ã larger with the additional force provided by a hand contact.


Title: Mark Yourself: Road Marking Segmentation via Weakly-Supervised Annotations from Multimodal Data
Abstract: This paper presents a weakly-supervised learning system for real-time road marking detection using images of complex urban environments obtained from a monocular camera. We avoid expensive manual labelling by exploiting additional sensor modalities to generate large quantities of annotated images in a weakly-supervised way, which are then used to train a deep semantic segmentation network. At run time, the road markings in the scene are detected in real time in a variety of traffic situations and under different lighting and weather conditions without relying on any preprocessing steps or predefined models. We achieve reliable qualitative performance on the Oxford RobotCar dataset, and demonstrate quantitatively on the CamVid dataset that exploiting these annotations significantly reduces the required labelling effort and improves performance.


Title: Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments
Abstract: We present a self-supervised approach to ignoring âdistractorsâ in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.


Title: Planning Ergonomic Sequences of Actions in Human-Robot Interaction
Abstract: In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.


Title: Playdough to Roombots: Towards a Novel Tangible User Interface for Self-reconfigurable Modular Robots
Abstract: One of the main strengths of self-reconfigurable modular robots (SRMR) is their ability to shape-shift and dynamically change their morphology. In the case of our SRMR system âRoombotsâ, these shapes can be quite arbitrary for a great variety of tasks while the major utility is envisioned to be self-reconfigurable furniture. As such, the ideas and inspirations from users quickly need to be translated into the final Roombots shape. This involves a multitude of separate processes and - most importantly - requires an intuitive user interface. Our current approach led to the development of a tangible user interface (TUI) which involves 3D-scanning of a shape formed by modeling clay and the necessary steps to prepare the digitized model to be formed by Roombots. The system is able to generate a solution in less than two minutes for our target use as demonstrated with various examples.


Title: Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications
Abstract: Fast and robust person detection is one of the most important tasks for robotic applications involving human interaction. Particularly in mobile robotics this task is still challenging. Though there are already reliable and real-time capable approaches, they are usually computationally expensive. They either require GPUs or multiple CPU cores in order to work properly. Furthermore, some of the approaches are designed for special environments and sensor types, which reduces general applicability. In this work, we present a robust, generic and lightweight solution for real-time 3D person detection. Since our approach requires only a single CPU thread, it can be run as a background process and is suitable for smaller robotic systems. We demonstrate applicability to indoor and outdoor scenarios using different 3D sensor types separately. Moreover, we are able to show that the proposed method outperforms other state-of-the-art approaches, including a DCNN.


Title: Real-Time Identification of Robot Payload Using a Multirate Quaternion-Based Kalman Filter and Recursive Total Least-Squares
Abstract: The paper describes an estimation and identification procedure that allows to reconstruct the inertial parameters of a rigid load attached to the end-effector of an industrial manipulator. In particular, the proposed method adopts a multirate quaternion-based Kalman filter, fusing measurements obtained from robot kinematics and inertial sensors at possibly different sampling frequencies, to estimate linear accelerations and angular velocities/accelerations of the load. Then, a recursive total least-squares (RTLS) process is executed to identify the load parameters. Both steps of the estimation and identification procedure are performed in real-time, without the need for offline post-processing of measured data.


Title: Recognizing Objects in-the-Wild: Where do we Stand?
Abstract: The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for realworld applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance.


Title: Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.


Title: Multi-Agent Time-Based Decision-Making for the Search and Action Problem
Abstract: Many robotic applications, such as search-and-rescue, require multiple agents to search for and perform actions on targets. However, such missions present several challenges, including cooperative exploration, task selection and allocation, time limitations, and computational complexity. To address this, we propose a decentralized multi-agent decision-making framework for the search and action problem with time constraints. The main idea is to treat time as an allocated budget in a setting where each agent action incurs a time cost and yields a certain reward. Our approach leverages probabilistic reasoning to make near-optimal decisions leading to maximized reward. We evaluate our method in the search, pick, and place scenario of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), by using a probability density map and reward prediction function to assess actions. Extensive simulations show that our algorithm outperforms benchmark strategies, and we demonstrate system integration in a Gazebo-based environment, validating the framework's readiness for field application.


Title: Multi-robot Dubins Coverage with Autonomous Surface Vehicles
Abstract: In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.


Title: How Many Robots are Enough: A Multi-Objective Genetic Algorithm for the Single-Objective Time-Limited Complete Coverage Problem
Abstract: Complete coverage, which is the foundation of many robotic applications, aims to cover an area as quickly as possible. This study investigates the time-limited version of multi-robot complete coverage problem, that is, to find the least number of robots and allocate tasks properly to them such that they can finish a known mission within the time limit. This version of problem can be tackled straightforwardly based on optimizing the task-allocation to a fixed number of robots and enumerating the number. However, the number-fixed problem is NP-hard and the existing algorithm for the number-fixed problem allows intersecting tasks (possibly causing robots' interference) and endures high approximation factor. In this study, the time-limited complete coverage problem is tackled with a multi-objective approach, instead of enumerating robots' number and optimizing each number-fixed problem one by one. The multi-objective GA, Mofint, at first estimates the lower and upper bounds of the number of robots. It abstracts each task as a weighted node of a graph. Then, Mofint evolves individuals, each individual being a forest containing a certain number (within the bounds) of non-intersecting trees. Mofint can finally obtain higher precision than existing work with less time: the approximation factor for Mofint is 1.1 to 1.5 times the ideal allocation when robots' number is fixed, while for existing work is 1.5 to 2. Due to its higher precision, the least number of robots obtained in the experiments by Mofint is 0.6 times of existing work.


Title: Accelerating Model Learning with Inter-Robot Knowledge Transfer
Abstract: Online learning of a robot's inverse dynamics model for trajectory tracking necessitates an interaction between the robot and its environment to collect training data. This is challenging for physical robots in the real world, especially for humanoids and manipulators due to their large and high dimensional state and action spaces, as a large amount of data must be collected over time. This can put the robot in danger when learning tabula rasa and can also be a time-intensive process especially in a multi-robot setting, where each robot is learning its model from scratch. We propose accelerating learning of the inverse dynamics model for trajectory tracking tasks in this multi-robot setting using knowledge transfer, where robots share and re-use data collected by preexisting robots, in order to speed up learning for new robots. We propose a scheme for collecting a sample of correspondences from the robots for training transfer models, and demonstrate, in simulations, the benefit of knowledge transfer in accelerating online learning of the inverse dynamics model between several robots, including between a low-cost Interbotix PhantomX Pincher arm, and a more expensive and relatively heavier Kuka youBot arm. We show that knowledge transfer can save up to 63% of training time of the youBot arm compared to learning from scratch, and about 58% for the lighter Pincher arm.


Title: Learning Coupled Forward-Inverse Models with Combined Prediction Errors
Abstract: Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models-that is, learning their parameters and their responsibilities-has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously. In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions.


Title: Data-Efficient Decentralized Visual SLAM
Abstract: Decentralized visual simultaneous localization and mapping (SLAM) is a powerful tool for multi-robot applications in environments where absolute positioning is not available. Being visual, it relies on cheap, lightweight and versatile cameras, and, being decentralized, it does not rely on communication to a central entity. In this work, we integrate state-of-the-art decentralized SLAM components into a new, complete decentralized visual SLAM system. To allow for data association and optimization, existing decentralized visual SLAM systems exchange the full map data among all robots, incurring large data transfers at a complexity that scales quadratically with the robot count. In contrast, our method performs efficient data association in two stages: first, a compact full-image descriptor is deterministically sent to only one robot. Then, only if the first stage succeeded, the data required for relative pose estimation is sent, again to only one robot. Thus, data association scales linearly with the robot count and uses highly compact place representations. For optimization, a state-of-the-art decentralized pose-graph optimization method is used. It exchanges a minimum amount of data which is linear with trajectory overlap. We characterize the resulting system and identify bottlenecks in its components. The system is evaluated on publicly available datasets and we provide open access to the code. Supplementary Material Data and code are at: https://github.com/uzh-rpg/dslam_open.


Title: SAT-C: An Efficient Control Strategy for Assembly of Heterogeneous Stress-Engineered MEMS Microrobots
Abstract: We present a new efficient control framework for controlling groups of heterogeneous stress-engineered MEMS microrobots for accomplishing micro-assembly. The objective is to maximize the number of controllable microrobots in the system while keeping the number of external global signals as low as possible. This work proposes a theoretical control strategy that could complete multiple-shapes microassembly from arbitrary initial configuration where all the control primitives can be accompanied with a constant number (O(1)) of control pulses of the power delivery waveform. We focus on microrobotic systems that can be modeled as nonholonomic unicycles. We validate the control policy with hardware experiments for implementing planar assembly using multiple macroscale robots with direct drive wheels. These results lay the foundation for developing new methods to control of a large number of MEMS microrobots.


Title: Robotic Intracellular Manipulation: 3D Navigation and Measurement Inside a Single Cell
Abstract: Magnetic micromanipulation is an untethered technique and has enabled numerous applications in the scale of millimeters to micrometers from the tissue level to cell level. However, existing systems are not capable of maneuvering a sub-micrometer object for precise force control, preventing the realization of intracellular manipulation or `fantastic voyage' inside a single cell. The magnetic micromanipulation task achieved in this work is sub-micrometer position control and piconewton force control of a sub-micron (0.7 Î¼m) magnetic bead inside a single human bladder cancer cell (RT4). The magnetic bead was 3D positioned in the cell using a generalized predictive controller that effectively tackled the control challenge caused by the slow visual feedback (1 Hz) from high-resolution confocal microscopy. The average positioning error was quantified to be 0.43 Î¼m, which is slightly larger than Brownian motion-imposed constraint (0.31 Î¼m). The system is capable of three-dimensionally applying a maximum force of 60 pN with a resolution of 4 pN. In experiments, a 0.7 Î¼m magnetic bead was controlled to move from an initial position in a cell to target positions on the cell nucleus. Force-displacement data were obtained from multiple locations along the cell nucleus' major and minor axes. The results revealed, for the first time, significantly higher stiffness exists in the cell nucleus' major axis than the minor axis. This stiffness polarity was likely attributed to the aligned stress fibers of actin filament inside the cells.


Title: ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition
Abstract: Vision and touch are two of the important sensing modalities for humans and they offer complementary information for sensing the environment. Robots could also benefit from such multi-modal sensing ability. In this paper, addressing for the first time (to the best of our knowledge) texture recognition from tactile images and vision, we propose a new fusion method named Deep Maximum Covariance Analysis (DMCA) to learn a joint latent space for sharing features through vision and tactile sensing. The features of camera images and tactile data acquired from a GelSight sensor are learned by deep neural networks. But the learned features are of a high dimensionality and are redundant due to the differences between the two sensing modalities, which deteriorates the perception performance. To address this, the learned features are paired using maximum covariance analysis. Results of the algorithm on a newly collected dataset of paired visual and tactile data relating to cloth textures show that a good recognition performance of greater than 90% can be achieved by using the proposed DMCA framework. In addition, we find that the perception performance of either vision or tactile sensing can be improved by employing the shared representation space, compared to learning from unimodal data.


Title: Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals
Abstract: Complex contact manipulation tasks can be decomposed into sequences of motor primitives. Individual primitives often end with a distinct contact state, such as inserting a screwdriver tip into a screw head or loosening it through twisting. To achieve robust execution, the robot should be able to verify that the primitive's goal has been reached as well as disambiguate it from erroneous contact states. In this paper, we introduce and evaluate a framework to autonomously construct manipulation graphs from manipulation demonstrations. Our manipulation graphs include sequences of motor primitives for performing a manipulation task as well as corresponding contact state information. The sensory models for the contact states allow the robot to verify the goal of each motor primitive as well as detect erroneous contact changes. The proposed framework was experimentally evaluated on grasping, unscrewing, and insertion tasks on a Barrett arm and hand equipped with two BioTacs. The results of our experiments indicate that the learned manipulation graphs achieve more robust manipulation executions by confirming sensory goals as well as discovering and detecting novel failure modes.


Title: Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging
Abstract: This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an âodometry backboneâ to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.


Title: Task-Specific Sensor Planning for Robotic Assembly Tasks
Abstract: When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.


Title: Active Motion-Based Communication for Robots with Monocular Vision
Abstract: In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.


Title: Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy
Abstract: In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.


Title: Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller
Abstract: Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.


Title: Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments
Abstract: Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.


Title: Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement
Abstract: The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.


Title: Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation
Abstract: For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as âphysics reasoningâ) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.


Title: Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks
Abstract: While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.


Title: Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes
Abstract: Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.


Title: Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration
Abstract: Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.


Title: A Tensegrity-Inspired Compliant 3-DOF Compliant Joint
Abstract: Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.


Title: SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control
Abstract: In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.


Title: Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
Abstract: This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.


Title: A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
Abstract: In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.


Title: Vision-Based Global Localization Using Ceiling Space Density
Abstract: Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.


Title: Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
Abstract: Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.


Title: Robot Assisted Carpentry for Mass Customization
Abstract: Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.


Title: Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms
Abstract: Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 Î¼m magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.


Title: SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
Abstract: SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.


Title: Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing
Abstract: This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.


Title: Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
Abstract: In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.


Title: Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking
Abstract: We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/Îµ) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.


Title: A Synchronization Scheme for Position Control of Multiple Rope-Climbing Robots
Abstract: The ability of rope-climbing robots in aloft operation is limited by its self-supporting and locomotion ability. In many applications, a given task is also too complex to be achieved by a single rope-climbing robot acting alone. The solution of multiple rope-climbing robots can overcome the limitations. However, existing control methods for rope-climbing robots are limited to single robot, and the open issue of coordination between multiple rope-climbing robots has not been systematically addressed. This paper presents a new synchronization scheme for position control of multiple rope-climbing robots, such that each robot moves to the corresponding desired position while synchronizing the heights between each other. Maintaining the same height is very important to guarantee the stability of the task-oriented manipulator installed among multiple robots, when it is performing the manipulation task. The development of the proposed controller is based on the singular perturbation approach, by treating the fast actuator dynamics as a perturbation of the slow robot dynamics, such that the lowest control complexity is achieved. The exponential stability of the overall system that consists of the fast and slow subsystems is proved by using Tikhonov' s theorem. Experimental results are presented to illustrate the performance of the proposed controller.


Title: Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching
Abstract: This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select and execute among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu.


Title: Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration
Abstract: We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.


Title: PIRVS: An Advanced Visual-Inertial SLAM System with Flexible Sensor Fusion and Hardware Co-Design
Abstract: In this paper, we present the PerceptIn Robotics Vision System (PIRVS), a visual-inertial computing hardware with embedded simultaneous localization and mapping (SLAM) algorithm. The PIRVS hardware is equipped with a multi-core processor, a global-shutter stereo camera, and an IMU with precise hardware synchronization. The PIRVS software features a flexible sensor fusion approach to not only tightly integrate visual measurements with inertial measurements and also to loosely couple with additional sensor modalities. It runs in real-time on both PC and the PIRVS hardware. We perform a thorough evaluation of the proposed system using multiple public visual-inertial datasets. Experimental results demonstrate that our system reaches comparable accuracy of state-of-the-art visual-inertial algorithms on PC, while being more efficient on the PIRVS hardware.


Title: Principal Components of Touch
Abstract: Our human sense of touch enables us to manipulate our surroundings; therefore, complex robotic manipulation will require artificial tactile sensing. Typically tactile sensor arrays are used in robotics, implying that a straightforward way of interpreting multidimensional data is required. In this paper we present a simple visualisation approach based on applying principal component analysis (PCA) to systematically collected sets of tactile data. We apply the visualisation approach to 4 different types of tactile sensor, encompassing fingertips and vibrissal arrays. The results show that PCA can reveal structure and regularities in the tactile data, which also permits the use of simple classifiers such as k-NN to achieve good inference. Additionally, the Euclidean distance in principal component space gives a measure of sensitivity, which can aid visualisation and also be used to find regions in the tactile input space where the sensor is able to perceive with higher accuracy. We expect that these observations will generalise, and thus offer the potential for novel control methods based on touch.


Title: Estimation of Object Orientation Using Conductive Ink and Fabric Based Multilayered Tactile Sensor
Abstract: Robots, either made from hard or soft materials, are being used increasingly for unknown object manipulation tasks in unstructured environments. To hold an object firmly and do the required task, the orientation of the object with respect to the robotic hand gripper is one of the necessary key information. Humans can sense the orientation of an object based on vision, kinesthetic sensation, or touch sensation. Similarly, robots shall also be able to estimate grasped object orientation just based on tactile sensing without knowing manipulator kinesthetic or kinematics. Existing sensors are mostly based on vision or rigid inertial measurement units (such as accelerometers, gyroscopes, magnetometers), which require additional setup and are typically not compliant with the arbitrary surfaces of the unknown obj ects. This paper discusses a new approach for object orientation estimation from a multilayered tactile sensor based on conductive silver ink and conductive fabric. Fabric based sensors are flexible and can confer to both hard and soft surfaces. Experimental results show that the tactile sensor developed is able to estimate the tilt angle without any information about manipulator kinematics.


Title: Color-Based Sensing of Bending Deformation on Soft Robots
Abstract: This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The working principle of our approach is based on using compact color sensors to detect deformation that is visualized by the change of color ratios. Two novel designs are presented to generate color signals on 3D printed objects, which we call an external signal generator and an internal signal generator. Signal processing and calibration methods are developed to transform the raw RGB-data into a meaningful deformation metric. Our experimental tests taken on soft pneumatic actuators verify that color signals can be stably generated and captured to indicate the bending deformation. The results also demonstrate the usability of this sensing approach in deformation control.


Title: Geometry-based Direct Simulation for Multi-Material Soft Robots
Abstract: Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.


Title: Popcorn-Driven Robotic Actuators
Abstract: Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat. Although this transition is irreversible, it carries potential for several robotic applications. Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability. We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire. As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump. Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers. Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.


Title: Departure and Conflict Management in Multi-Robot Path Coordination
Abstract: This paper addresses the problem of multi-robot path coordination, considering specific features that arise in applications such as automatic aircraft taxiing or driver-less cars coordination. The first feature is departure events: when robots arrive at their destinations (e.g. the runway for takeoff), they can be removed from the coordination diagram. The second feature is the âno-backward-movementâ constraint: the robots can only move forward on their assigned paths. These features can interact to give rise to complex conflict situations, which existing planners are unable to solve in practical time. We propose a set of algorithms to efficiently account for these features and validate these algorithms on a realistic model of Charles de Gaulle airport.


Title: A Single-Planner Approach to Multi-Modal Humanoid Mobility
Abstract: In this work, we present an approach to planning for humanoid mobility. Humanoid mobility is a challenging problem, as the configuration space for a humanoid robot is intractably large, especially if the robot is capable of performing many types of locomotion. For example, a humanoid robot may be able to perform such tasks as bipedal walking, crawling, and climbing. Our approach is to plan for all these tasks within a single search process. This allows the search to reason about all the capabilities of the robot at any point, and to derive the complete solution such that the plan is guaranteed to be feasible. A key observation is that we often can roughly decompose a mobility task into a sequence of smaller tasks, and focus planning efforts to reason over much smaller search spaces. To this end, we leverage the results of a recently developed framework for planning with adaptive dimensionality, and incorporate the capabilities of available controllers directly into the planning process. The resulting planner can also be run in an interleaved fashion alongside execution so that time spent idle is much reduced.


Title: Collision-Free Motion Planning for Human-Robot Collaborative Safety Under Cartesian Constraint
Abstract: This paper presents a real-time motion planning and control design of a robotic arm for human-robot collaborative safety. A novel collision-free motion planning method is proposed not only to keep robot body from colliding with objects but also preserve the execution of robot's original task under the Cartesian constraint of the environment. Multiple KinectV2 depth cameras are utilized to model and track dynamic obstacles (e.g. Humans and objects) inside the robot workspace. Depth images are applied to generate point cloud of segmented objects in the environment. A K-nearest neighbor (KNN) searching algorithm is used to cluster and find the closest point from the obstacle to the robot. Then a Kalman filter is applied to estimate the obstacle position and velocity. For the collision avoidance in collaborative operation, attractive and repulsive potential is generated for robot end effector based on the task specification and obstacle observation. Practical experiments show that the 6-DOF robot arm can effectively avoid an obstacle in a constrained environment and complete the original task.


Title: A Model-Based Hierarchical Controller for Legged Systems Subject to External Disturbances
Abstract: Legged robots have many potential applications in real-world scenarios where the tasks are too dangerous for humans, and compliance is needed to protect the system against external disturbances and impacts. In this paper, we propose a model-based controller for hierarchical tasks of legged systems subject to external disturbance. The control framework is based on projected inverse dynamics controller, such that the control law is decomposed into two orthogonal subspaces, i.e., the constrained and the unconstrained subspaces. The unconstrained component controls multiple desired tasks with impedance responses. The constrained space controller maintains the contact subject to unknown external disturbances, without the use of any force/torque sensing at the contact points. By explicitly modelling the external force, our controller is robust to external disturbances and errors arising from incorrect dynamic model information. The main contributions of this paper include (1) incorporating an impedance controller to control external disturbances and allow impedance shaping to adjust the behaviour of the motion under external disturbances, (2) optimising contact forces within the constrained subspace that also takes into account the external disturbances without using force/torque sensors at the contact locations. The techniques are evaluated on the ANYmal quadruped platform under a variety of scenarios.


Title: Temporal Spatial Inverse Semantics for Robots Communicating with Humans
Abstract: Effective communication between humans often embeds both temporal and spatial context. While spatial context captures the geographic settings of objects in the environment, temporal context describes their changes over time. In this paper, we propose temporal spatial inverse semantics (TeSIS) to extend the inverse semantics approach to also consider the temporal context for robots communicating with humans. Inverse semantics generates natural language requests while taking into account how well the human listeners would interpret those requests given the current spatial context. Compared to inverse semantics, our approach incorporates also temporal context by referring to spatial context information in the past. To achieve this, we extend the sentence structure in inverse semantics to generate sentences that can refer to not only the current but also previous states of the environment. A new metric based on the extended sentence structure is developed by breaking a single sentence into multiple independent sentences that refer to environment states at different times. Using this approach, we are able to generate sentences such as âPlease pick up the cup beside the oven that was on the dining tableâ. To evaluate our approach, we randomly generate scenarios in an experimental domain. Each scenario includes the description of the current and several immediate previous states. Natural language sentences are then generated for these scenarios using both inverse semantics that uses only the spatial context and our approach. Amazon MTurk is used to compare the sentences generated and results show that TeSIS achieves better accuracy, sometimes by a significant margin, than the baseline.


Title: Human in the Loop of Robot Learning: EEG-Based Reward Signal for Target Identification and Reaching Task
Abstract: Shared control and shared autonomy play an important role in assistive technologies, allowing the offloading of the cognitive burden required for control from the user to the intelligent robotic device. In this context, electrophysiological measures of error detection, directly measured from a person's brain activity as Error-related Potentials (ErrPs), can be exploited to provide passive adaptation of an external semi-autonomous system to the human. This concept was implemented in an online robot learning task, where user's evaluation of the robot's actions, in terms of detected ErrP, was exploited to update a reward function in a Reinforcement Learning (RL) framework. Results from both simulated and experimental studies show that the introduction of human evaluation in the robot learning loop allows for: (1) the acceleration of optimal policy learning in a target reaching task, (2) the introduction of a further degree of control in robot learning, namely identification of one among multiple targets, according to the user's will. Overall, presented results support the potential of human-robot co-adaptive and co-operative strategies to develop human-centered assistive technologies.


Title: The Hands-Free Push-Cart: Autonomous Following in Front by Predicting User Trajectory Around Obstacles
Abstract: This paper demonstrates an autonomous mobile robot that follows a walking user while staying ahead of them. Despite several useful applications for autonomous push-carts, this problem has received much less attention than the easier problem of following from behind. In contrast to previous work, we use multi-modal person detection and a human-motion model that considers obstacles to predict the future path of the user. We implement the system with a modular architecture of obstacle mapper, human tracker, human motion model, robot motion planner and robot motion controller. We report on the performance of the robot in real-world experiments. We believe that approaches to this largely overlooked problem could be useful in real industrial, domestic and entertainment applications in the near future.


Title: Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach
Abstract: The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.


Title: Multi3: Multi-Sensory Perception System for Multi-Modal Child Interaction with Multiple Robots
Abstract: Child-robot interaction is an interdisciplinary research area that has been attracting growing interest, primarily focusing on edutainment applications. A crucial factor to the successful deployment and wide adoption of such applications remains the robust perception of the child's multi-modal actions, when interacting with the robot in a natural and untethered fashion. Since robotic sensory and perception capabilities are platform-dependent and most often rather limited, we propose a multiple Kinect-based system to perceive the child-robot interaction scene that is robot-independent and suitable for indoors interaction scenarios. The audio-visual input from the Kinect sensors is fed into speech, gesture, and action recognition modules, appropriately developed in this paper to address the challenging nature of child-robot interaction. For this purpose, data from multiple children are collected and used for module training or adaptation. Further, information from the multiple sensors is fused to enhance module performance. The perception system is integrated in a modular multi-robot architecture demonstrating its flexibility and scalability with different robotic platforms. The whole system, called Multi3, is evaluated, both objectively at the module level and subjectively in its entirety, under appropriate child-robot interaction scenarios containing several carefully designed games between children and robots.


Title: Multi-Robot Coordination in Dynamic Environments Shared with Humans
Abstract: This work addresses multi-robot coordination in social human-populated environments using a market-based framework for solving the Multi-Robot Task Allocation (MRTA) problem. Humans are considered in the proposed coordination mechanism by means of accounting for social costs in bid evaluations and requesting collaboration in socially blocking situations. Initially, the effect of a realistic environment with varying number of static/moving humans on the behavior and performance of our method is studied through an extensive suite of experiments in a high-fidelity simulator. Results show that the total traveled distance and time are increased when humans are present in the environments. Localization noise is also increased particularly in the case of static people. In the second series of experiments, a number of problematic cases resulting in longer modified paths, blocked passages, and long waits have been investigated. A comparative study targeting human-agnostic navigation and planning, human-aware navigation and human-agnostic planning, and human-aware navigation and planning has been conducted. Both simulated and real robot experiments confirm the effectiveness of accounting for humans at both team and individual levels. This leads to respecting social constraints as well as achieving a better performance based on MRTA metrics.


Title: Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning
Abstract: The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.


Title: Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
Abstract: Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.


Title: A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration
Abstract: The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.


Title: A Scalable Multi-Robot Task Allocation Algorithm
Abstract: In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.


Title: Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis
Abstract: Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.


Title: 2D SLAM Correction Prediction in Large Scale Urban Environments
Abstract: Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.


Title: Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition
Abstract: Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.


Title: EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots
Abstract: A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.


Title: Robust, Compliant Assembly via Optimal Belief Space Planning
Abstract: In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.


Title: Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning
Abstract: We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.


Title: Caging Loops in Shape Embedding Space: Theory and Computation
Abstract: We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.


Title: Generalized Task-Parameterized Skill Learning
Abstract: Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.


Title: Topological Multi-Robot Belief Space Planning in Unknown Environments
Abstract: In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.


Title: On Time Optimization of Centroidal Momentum Dynamics
Abstract: Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing â â Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.


Title: Human-guided Optical Manipulation of Multiple Microscopic Objects
Abstract: Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.


Title: Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator
Abstract: Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.


Title: AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection
Abstract: We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net.


Title: Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction
Abstract: Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.


Title: Surface Edge Explorer (see): Planning Next Best Views Directly from 3D Observations
Abstract: Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.


Title: Fusing Object Context to Detect Functional Area for Cognitive Robots
Abstract: A cognitive robot usually needs to perform multiple tasks in practice and needs to locate the desired area for each task. Since deep learning has achieved substantial progress in image recognition, to solve this area detection problem, it is straightforward to label a functional area (affordance) image dataset and apply a well-trained deep-model-based classifier on all the potential image regions. However, annotating the functional area is time consuming and the requirement of large amount of training data limits the application scope. We observe that the functional area are usually related to the surrounding object context. In this work, we propose to use the existing object detection dataset and employ the object context as effective prior to improve the performance without additional annotated data. In particular, we formulate a two-stream network that fuses the object-related and functionality-related feature for functional area detection. The whole system is formulated in an end-to-end manner and easy to implement with current object detection framework. Experiments demonstrate that the proposed network outperforms current method by almost 20% in terms of precision and recall.


Title: Ultra-Fast Multi-Scale Shape Estimation of Light Transport Matrix for Complex Light Reflection Objects
Abstract: 3D measurement of target objects characterized by specular reflection or subsurface scatterings cannot be measured by traditional 3D measurement methods because these targets have multiple light paths that make it difficult to determine the unique surface. We define these objects as complex light reflection objects. In this case, 3D measurement methods based on Light Transport (LT) Matrix estimation may be a solution to measure these complex light reflection objects, because LT Matrix captures every light path, and we can identify all 3D points on the target shape by using LT Matrix. However, these methods either provide low resolution results, or they are too slow for use in robot vision in practice. In this paper, we suppress the computational cost of LT Matrix estimation by dividing LT Matrix estimation into multi-scale. The proposed method reduces the number of candidate combinations between camera pixels and projector pixels greatly by using the information given by low resolution observations. The proposed algorithm allows high resolution measurement of the LT Matrix very efficiently. Furthermore, careful implementation of our method by using a sparse matrix representation achieves memory efficiency. We evaluated our method by measuring 3D points for a 256 Ã 256 resolution projector and camera system, which is an LT matrix 4096 times larger than that developed in our previous study [1] and 100 times faster than our naÃ¯ve implementation of [2].


Title: Intelligent Shipwreck Search Using Autonomous Underwater Vehicles
Abstract: This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.


Title: Composable Deep Reinforcement Learning for Robotic Manipulation
Abstract: Model-free deep reinforcement learning has been shown to exhibit good performance in domains ranging from video games to simulated robotic manipulation and locomotion. However, model-free methods are known to perform poorly when the interaction time with the environment is limited, as is the case for most real-world robotic tasks. In this paper, we study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation. The application of this method to real-world manipulation is facilitated by two important features of soft Q-learning. First, soft Q-learning can learn multimodal exploration strategies by learning policies represented by expressive energy-based models. Second, we show that policies learned with soft Q-learning can be composed to create new policies, and that the optimality of the resulting policy can be bounded in terms of the divergence between the composed policies. This compositionality provides an especially valuable tool for real-world manipulation, where constructing new policies by composing existing skills can provide a large gain in efficiency over training from scratch. Our experimental evaluation demonstrates that soft Q-learning is substantially more sample efficient than prior model-free deep reinforcement learning methods, and that compositionality can be performed for both simulated and real-world tasks.


Title: Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning
Abstract: Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots on rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. We validate the learned sensor-level collision avoidance policy in a variety of simulated scenarios with thorough performance evaluations and show that the final learned policy is able to find time efficient, collision-free paths for a large-scale robot system. We also demonstrate that the learned policy can be well generalized to new scenarios that do not appear in the entire training period, including navigating a heterogeneous group of robots and a large-scale scenario with 100 robots. Videos are available at https://sites.google.com/view/drlmaca.


Title: Overcoming Exploration in Reinforcement Learning with Demonstrations
Abstract: Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.


Title: Fast Image-Based Geometric Change Detection Given a 3D Model
Abstract: 3D models of the environment are used in numerous robotic applications and should reflect the current state of the world. In this paper, we address the problem of quickly finding structural changes between the current state of the world and a given 3D model using a small number of images. Our approach finds inconsistencies between pairs of images by re-projecting an image onto another one by passing through the given 3D model. This process leads to ambiguities, which we resolve by combining multiple images such that the 3D location of the change can be estimated. A focus of our approach is that it can be executed fast enough to allow the operation on a mobile system. We implemented our approach in C++ and released it as open source software. We tested it on existing datasets as well as on self-recorded image sequences and 3D models, which we publicly share. Our experiments show that our method quickly finds changes in the geometry of a scene.


Title: Multimodal 2D Image to 3D Model Registration via a Mutual Alignment of Sparse and Dense Visual Features
Abstract: Many fields of application could benefit from an accurate registration of measurements of different modalities over a known 3D model. However, aligning a 2D image to a 3D model is a challenging task and is even more complex when the two have a different modality. Most of the 2D/3D registration methods are based on either geometric or dense visual features. Both have their own advantages and their own drawbacks. We propose, in this paper, to mutually exploit the advantages of one feature type to reduce the drawbacks of the other one. For this, an hybrid registration framework has been designed to mutually align geometrical and dense visual features in order to obtain an accurate final 2D/3D alignment. We evaluate and compare the proposed registration method on real data acquired by a robot equipped with several visual sensors. The results highlights the robustness of the method and its ability to produce wide convergence domain and a high registration accuracy.


Title: Adaptive Sampling and Online Learning in Multi-Robot Sensor Coverage with Mixture of Gaussian Processes
Abstract: We consider the problem of online environmental sampling and modeling for multi-robot sensor coverage, where a team of robots spread out over the workspace in order to optimize the overall sensing performance. In contrast to most existing works on multi-robot coverage control that assume prior knowledge of the distribution of environmental phenomenon, also known as density function, we relax this assumption and enable the robot team to efficiently learn the model of the unknown density function Online using adaptive sampling and non-parametric inference such as Gaussian Process (GP). To capture significantly different components of the environmental phenomenon, we propose a new approach with mixture of locally learned Gaussian Processes for collective model learning and an information-theoretic criterion for simultaneous adaptive sampling in multi-robot coverage. Our approach demonstrates a better generalization of the environment modeling and thus the improved performance of coverage without assuming the density function is known a priori. We demonstrate the effectiveness of our algorithm via simulations of information gathering from indoor static sensors.


Title: Coordinated Dense Aerial Traffic with Self-Driving Drones
Abstract: In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.


Title: Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems
Abstract: A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.


Title: Distance-Based Multi-Robot Coordination on Pocket Drones
Abstract: We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.


Title: Cooperative Adaptive Control for Cloud-Based Robotics
Abstract: This paper studies collaboration through the cloud in the context of cooperative adaptive control for robot manipulators. We first consider the case of multiple robots manipulating a common object through synchronous centralized update laws to identify unknown inertial parameters. Through this development, we introduce a notion of Collective Sufficient Richness, wherein parameter convergence can be enabled through teamwork in the group. The introduction of this property and the analysis of stable adaptive controllers that benefit from it constitute the main new contributions of this work. Building on this original example, we then consider decentralized update laws, time-varying network topologies, and the influence of communication delays on this process. Perhaps surprisingly, these nonidealized networked conditions inherit the same benefits of convergence being determined through collective effects for the group. Simple simulations of a planar manipulator identifying an unknown load are provided to illustrate the central idea and benefits of Collective Sufficient Richness.


Title: Put-in-Box Task Generated from Multiple Discrete Tasks by aHumanoid Robot Using Deep Learning
Abstract: For robots to have a wide range of applications, they must be able to execute numerous tasks. However, recent studies into robot manipulation using deep neural networks (DNN) have primarily focused on single tasks. Therefore, we investigate a robot manipulation model that uses DNNs and can execute long sequential dynamic tasks by performing multiple short sequential tasks at appropriate times. To generate compound tasks, we propose a model comprising two DNNs: a convolutional autoencoder that extracts image features and a multiple timescale recurrent neural network (MTRNN) to generate motion. The internal state of the MTRNN is constrained to have similar values at the initial and final motion steps; thus, motions can be differentiated based on the initial image input. As an example compound task, we demonstrate that the robot can generate a âPut-In-Boxâ task that is divided into three subtasks: open the box, grasp the object and put it into the box, and close the box. The subtasks were trained as discrete tasks, and the connections between each subtask were not trained. With the proposed model, the robot could perform the Put-In-Box task by switching among subtasks and could skip or repeat subtasks depending on the situation.


Title: Q-CP: Learning Action Values for Cooperative Planning
Abstract: Research on multi-robot systems has demonstrated promising results in manifold applications and domains. Still, efficiently learning an effective robot behaviors is very difficult, due to unstructured scenarios, high uncertainties, and large state dimensionality (e.g, hyper-redundant and groups of robot). To alleviate this problem, we present Q-CP a cooperative model-based reinforcement learning algorithm, which exploits action values to both (1) guide the exploration of the state space and (2) generate effective policies. Specifically, we exploit Q-learning to attack the curse-of-dimensionality in the iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on different stochastic cooperative (general-sum) games: (1) a simple cooperative navigation problem among 3 robots, (2) a cooperation scenario between a pair of KUKA YouBots performing hand-overs, and (3) a coordination task between two mobile robots entering a door. The obtained results show the effectiveness of Q- CP in the chosen applications, where action values drive the exploration and reduce the computational demand of the planning process while achieving good performance.


Title: Radiation Source Localization in GPS-Denied Environments Using Aerial Robots
Abstract: This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.


Title: Towards X-Ray Medical Imaging with Robots in the Open: Safety Without Compromising Performances
Abstract: In this paper, a control solution featuring an energetic constraint is developed to improve the safety of a robotic manipulator sharing its workspace with humans. This general control structure, exploits a generic safe controller that ensures the respect of multiple constraints thanks to a Linear Quadratic Problem formulation. With a unified energetic formulation, the controller allows to explicitly limit both the kinetic energy when moving and the wrench applied to the environment in case of contact with an unexpected obstacle. This control approach is experimented on a redundant Kuka LWR4+ robot which end-effector shall precisely point toward a given location while following a trajectory.


Title: Semi-Autonomous Laparoscopic Robotic Electro-Surgery with a Novel 3D Endoscope
Abstract: This paper reports a robotic laparoscopic surgery system performing electro-surgery on porcine cadaver kidney, and evaluates its accuracy in an open loop control scheme to conduct targeting and cutting tasks guided by a novel 3D endoscope. We describe the design and integration of the novel laparoscopic imaging system that is capable of reconstructing the surgical field using structured light. A targeting task is first performed to determine the average positioning error of the system as guided by the laparoscopic camera. The imaging system is then used to reconstruct the surface of a porcine cadaver kidney, and generate a cutting trajectory with consistent depth. The paper concludes by using the robotic system in open loop control to cut this trajectory using a multi degree of freedom electro-surgical tool. It is demonstrated that for a cutting depth of 3 mm, the robotic surgical system follows the trajectory with an average depth of 2.44 mm and standard deviation of 0.34 mm. The average positional accuracy of the system was 2.74Â±0.99 mm.


Title: Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
Abstract: We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.


Title: Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots
Abstract: This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.


Title: Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace
Abstract: The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.


Title: Grasp Planning for Load Sharing in Collaborative Manipulation
Abstract: In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.


Title: Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration
Abstract: The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.


Title: Deep Auxiliary Learning for Visual Localization and Odometry
Abstract: Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.


Title: Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
Abstract: In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.


Title: LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation
Abstract: Electrical motor and hydraulic actuation widely-used in robotics are âinternal actuationâ with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as âexternal actuationâ, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.


Title: Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration
Abstract: In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.


Title: Selection and Compression of Local Binary Features for Remote Visual SLAM
Abstract: In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.


Title: Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty
Abstract: Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.


Title: GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability
Abstract: In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as âlegsâ or âwheelsâ of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.


Title: A Robust Robot Design for Item Picking
Abstract: In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.


Title: Intent-Aware Multi-Agent Reinforcement Learning
Abstract: This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.


Title: Probabilistic Graph Security for Networked Multi-Robot Systems
Abstract: In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time.


Title: Controlling the Interaction of a Multi-Robot System with External Entities
Abstract: In this paper we consider a multi-robot system that shares the environment with external entities, and we propose a methodology for controlling the interaction with them. In particular, we consider the problem of achieving a desired dynamic interaction model, in such a way that the multi-robot system exchanges desired forces with external entities. This is obtained by introducing local deformations of the coupling actions among the robots. The proposed method ensures preservation of the passivity property, which provides safety guarantees in the interaction with the (possibly poorly known) external entities.


Title: From Swarms to Stars: Task Coverage in Robot Swarms with Connectivity Constraints
Abstract: Swarm robotics carries the potential of solving complex tasks using simple devices. To do so, however, one must define distributed control algorithms capable of producing globally coordinated behaviours. We propose a methodology to address the problem of the spatial coverage of multiple tasks with a swarm of robots that must not lose global connectivity. Our methodology comprises two layers: (i) a distributed Robot Navigation Controller (RNC) is responsible for simultaneously guaranteeing connectivity and pursuit of multiple tasks; and (ii) a global Task Scheduling Controller approximates the optimal strategy for the RNC with minimal computational load. Our contributions include: (i) a qualitative analysis of the literature on connectivity assessment, (ii) our proposed methodology, (iii) simulations in a multi-physics environment, (iv) real-life robot experiments, and (v) the experimental validation of connectivity, coverage optimality, and fault-tolerance.


Title: Using Information Invariants to Compare Swarm Algorithms and General Multi-Robot Algorithms
Abstract: Robotic swarms are decentralized multi-robot systems whose members use local information from proximal neighbors to execute simple reactive control laws that result in emergent collective behaviors. In contrast, members of a general multi-robot system may have access to global information, all-to-all communication or sophisticated deliberative collaboration. Some algorithms in the literature are applicable to robotic swarms. Others require the extra complexity of general multi-robot systems. Given an application domain, a system designer or supervisory operator must choose an appropriate system or algorithm respectively that will enable them to achieve their goals while satisfying mission constraints (e.g, bandwidth, energy, time limits). In this paper, we compare representative swarm and general multi-robot algorithms in two application domains - navigation and dynamic area coverage - with respect to several metrics (e.g, completion time, distance travelled). Our objective is to characterize each class of algorithms to inform offline system design decisions by engineers or online algorithm selection decisions by supervisory operators. Our contributions are (a) an empirical performance comparison of representative swarm and general multi-robot algorithms in two application domains, (b) a comparative analysis of the algorithms based on the theory of information invariants, which provides a theoretical characterization supported by our emnirical results.


Title: Learning Robust Policies for Object Manipulation with Robot Swarms
Abstract: Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.


Title: Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning
Abstract: We address the integrated prediction, planning, and control problem that enables a single follower robot (the photographer) to quickly re-establish visual contact with a moving target (the subject) that has escaped the follower's field of view. We deal with this scenario, which reactive controllers are typically ill-equipped to handle, by making plausible predictions about the long- and short-term behavior of the target, and planning pursuit paths that will maximize the chance of seeing the target again. At the core of our pursuit method is the use of predictive models of target behavior, which help narrow down the set of possible future locations of the target to a few discrete hypotheses, as well as the use of combinatorial search in physical space to check those hypotheses efficiently. We model target behavior in terms of a learned navigation reward function, using Inverse Reinforcement Learning, based on semantic terrain features of satellite maps. Our pursuit algorithm continuously predicts the latent destination of the target and its position in the future, and relies on efficient graph representation and search methods in order to navigate to locations at which the target is most likely to be seen at an anticipated time. We perform extensive evaluation of our predictive pursuit algorithm over multiple satellite maps, thousands of simulation scenarios, against state-of-the art MDP and POMDP solvers. We show that our method significantly outperforms them by exploiting domain-specific knowledge, while being able to run in real-time.


