total paper: 250
Title: Automatic Optimized 3D Path Planner for Steerable Catheters with Heuristic Search and Uncertainty Tolerance
Key Words: catheters  drugs  medical robotics  needles  path planning  surgery  RRT-Connect  sample-based algorithms  obstacle occupancy  insertion procedure  catheter modeling  asymptotically-optimal solution  BIT* algorithm  sample-based heuristic search  drug delivery  multisegment steerable probe  programmable bevel-tip needle  EDEN2020  neurosurgeon  minimally invasive neurosurgery  automatic planner  steerable catheters  Neurosurgery  Catheters  Three-dimensional displays  Kinematics  Needles  Planning  Uncertainty 
Abstract: In this paper, an automatic planner for minimally invasive neurosurgery is presented. The solution provides the neurosurgeon with the best path to connect a user-defined entry point with a target in accordance with a specific cost function. The approach guarantees the avoidance of obstacles which can be found along the insertion pathway. The method is tailored to the EDEN2020* programmable bevel-tip needle, a multisegment steerable probe intended to be used to perform drug delivery for the treatment of glioblastomas. A sample-based heuristic search inspired by the BIT* algorithm is used to define the asymptotically-optimal solution in terms of path length, followed by a smoothing phase to meet the required kinematic constraints of the needle. To account for inaccuracies in catheter modeling, which could determine unexpected control errors over the insertion procedure, an uncertainty margin is defined in order to increase the algorithm's safety. The feasibility of the proposed solution was demonstrated by testing the method in simulated neurosurgical scenarios with different degrees of obstacle occupancy and against other sample-based algorithms present in literature: RRT, RRT* and an enhanced version of the RRT-Connect.


Title: Design and kinematics characterization of a laser-profiled continuum manipulator for the guidance of bronchoscopic instruments
Key Words: dexterous manipulators  diseases  lung  manipulator kinematics  medical robotics  patient treatment  kinematics characterization  laser-profiled continuum manipulator  bronchoscopic instruments  bronchoscopic intervention  minimally invasive method  lung diseases  endobronchial instruments  peripheral airways  precision laser profiling  commercial bronchoscopes  distal airways  kinematic models  manipulator configuration  actuation wires  manipulator joints  instrument guidance robot  wire-driven dexterous manipulator  Manipulators  Wires  Instruments  Electron tubes  Surgery  Kinematics 
Abstract: Bronchoscopic intervention, as a minimally invasive method for the diagnosis and treatment of lung diseases, has attracted more and more attention in recent years. However, existing endobronchial instruments lack the steerability accessing the peripheral airways with difficult bifurcations. This paper presents a novel wire-driven dexterous manipulator for the guidance of such instruments. Precision laser profiling is used to cut a stainless steel tube into multiple interlocked segments with revolute joints. The outer diameter of the manipulator is 2.20 mm which is small enough to be inserted into the working channels of most commercial bronchoscopes and distal airways, while keeping a large inner lumen with a diameter of 1.44 mm for passing various bronchoscopic instruments. The small bending radius provides enough flexibility to navigate inside the complex bronchial tree. Two kinematic models are proposed to predict the manipulator configuration from the translation of actuation wires. The former model is geometrically derived with the assumption of constant curvature bending and the latter one is statistically driven by capturing the motion trajectories of manipulator joints. A prototype of our low-cost add-on instrument guidance robot for bronchoscopic intervention is presented which can be easily integrated into current clinical routine.


Title: An Observer-Based Fusion Method Using Multicore Optical Shape Sensors and Ultrasound Images for Magnetically-Actuated Catheters
Key Words: biomedical ultrasonics  catheters  endoscopes  feedforward neural nets  image fusion  Kalman filters  medical image processing  medical robotics  observers  state estimation  surgery  multicore optical shape sensors  ultrasound images  magnetically-actuated catheters  minimally invasive surgery  flexible medical instruments  endoscopes  magnetically actuated catheters  steering precision  conventional catheters  actuation method  accurate tip position  precise control  robust sensor fusion algorithm  template-based tracker  convolutional neural network based tracker  observer-based fusion  Euclidean error  Luenberger observer  Kalman filter  Catheters  Fiber gratings  Optical sensors  Shape  Multicore processing 
Abstract: Minimally invasive surgery involves using flexible medical instruments such as endoscopes and catheters. Magnetically actuated catheters can provide improved steering precision over conventional catheters. However, besides the actuation method, an accurate tip position is required for precise control of the medical instruments. In this study, the tip position obtained from transverse 2D ultrasound images and multicore optical shape sensors are combined using a robust sensor fusion algorithm. The tip position is tracked in the ultrasound images using a template-based tracker and a convolutional neural network based tracker, respectively. Experimental results for a rhombus path are presented, where data obtained from both tracking sources are fused using Luenberger and Kalman state estimators. The mean and standard deviation of the Euclidean error for the Luenberger observer is 0.2 ± 0.11 [mm] whereas for the Kalman filter it is 0.18 ± 0.13 [mm], respectively.


Title: Deep Neural Networks for Multiple Speaker Detection and Localization
Key Words: acoustic generators  encoding  human-robot interaction  microphone arrays  neural nets  speaker recognition  deep neural networks  multiple speaker detection  simultaneous detection  multiple sound sources  human-robot interaction  neural network-based sound source localization methods  single sound source  likelihood-based encoding  network output  sound mixtures  spatial spectrum-based approaches  Encoding  Delays  Robots  Artificial neural networks  Microphones  Estimation 
Abstract: We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.


Title: Inertial Machine Monitoring System for Automated Failure Detection
Key Words: condition monitoring  failure analysis  neural nets  production engineering computing  productivity  sensors  support vector machines  support vector machines  combine industrial equipment failure  inertial machine monitoring system  manufacturing productivity  3D printer  neural networks  smart manufacturing technologies  automated failure detection  Internet-of-Things sensors  Feature extraction  Robot sensing systems  Vibrations  Monitoring  Accelerometers  Databases  Three-dimensional displays 
Abstract: Smart manufacturing technologies are emerging which combine industrial equipment with Internet-of-Things (IoT) sensors to monitor and improve productivity of manufacturing. This allows for new opportunities to explore algorithms for predicting machine failures from attached sensor data. This paper presents a solution to non-invasively upgrade an existing machine with an Inertial Machine Monitoring System (IMMS) to detect and classify equipment failure or degraded state. We also provide a strategy to optimize the amount, placement locations, and efficiency of the sensors. In experiments, the system collected data from 36 inertial sensors placed at multiple locations on a 3D printer. Normal operation vs. 10 types of realworld abnormal equipment behavior (loose belt, failures of machine components) were detected and classified by Support Vector Machines and Neural Networks. Using under 1 minute of recording while running a test print, a recursively discovered best subset of 4 to 9 sensors yielded 11-way classification accuracy over 99%. Our results suggest that even a small sensor network and short test program can yield effective detection of machine degraded state and can facilitate early remediation.


Title: Parallel Pick and Place Using Two Independent Untethered Mobile Magnetic Microgrippers
Key Words: end effectors  freight handling  grippers  industrial robots  micromanipulators  microrobots  mobile robots  position control  independent untethered mobile magnetic microgrippers  parallel targeted cargo delivery  two-microgripper pair  local magnetic interactions  global magnetic field  end effectors  parallel pick and place  3D microgrippers configuration  Grippers  Magnetic separation  Barium  Magnetic hysteresis  Magnetoelasticity  Micromagnetics  Task analysis  magnetic microgripper  multi-agent control at microscales  soft robotics  targeted cargo delivery 
Abstract: Untethered mobile microgrippers exhibit flexibility and agility in small and constrained environments as precise and accurate robotic end-effectors, with promising potential applications in cell manipulation and microassembly. Here, we propose the first scheme to independently and simultaneously position two microgrippers on a horizontal plane for parallel targeted cargo delivery using a single global input. The separation and orientation of the two-microgripper pair are modulated by the local magnetic interactions between the two microgrippers, which are governed by a global magnetic field. The microgripper action of grasping or releasing cargoes is fully controlled by the global magnetic field without requiring additional thermal, chemical, or other stimuli. Thus, the proposed strategy only requires a single input, i.e., a global magnetic field, to control two microgrippers and therefore is simple to implement and fast-acting. As a demonstration, two microgrippers are maneuvered by a global magnetic field to pick up two cargoes and deliver them to their respective destinations. The parallel operation of two microgrippers can potentially double the overall throughput and enable the tasks that require team cooperations. The two 3D microgrippers configuration is intuitive in teleoperations, since it imitates the two-hand case of human beings.


Title: Requirements Based Design and End-to-End Dynamic Modeling of a Robotic Tool for Vitreoretinal Surgery
Key Words: manipulator dynamics  manipulator kinematics  medical robotics  motion control  surgery  end-to-end dynamic modeling  robotic tool  vitreoretinal surgery  sub-optimal motor selection  microprecise surgery  surgical tool  3-link surgical manipulator  anti-backlash lead screw assembly  multi-Degree of Freedom robotic system  dynamics analysis  rigorous kinematics analysis  Euler-Lagrange equations of motion  Surgery  Manipulator dynamics  Tools  Mathematical model  Dynamics 
Abstract: Despite several robots having been proposed for vitreoretinal surgery, there is limited information on their dynamic modeling. This gap leads to sub-optimal motor selection and hinders the application of advanced control schemes that would fulfill the goal of micro-precise surgery. This paper presents the design process and a dynamics study of a multi-Degree of Freedom (DoF) robotic system, which is inspired by established co-manipulation architectures. A rigorous kinematics and dynamics analysis of the robot's part that is responsible for manipulating the surgical tool during the retinal surgery phase is provided. In particular, the Euler-Lagrange equations of motion, which describe the dynamics of the 3-link surgical manipulator, are combined with novel analytical models of each link's corresponding transmission mechanism, including an anti-backlash lead screw assembly and a worm drive. The resulting models, transferable to existing manipulators, provide a meticulous analysis of the robot's performance that can be used both for mechanical design and control purposes.


Title: Differentiation of C2C12 Myoblasts and Characterization of Electro-Responsive Beating Behavior of Myotubes Using Circularly Distributed Multiple Electrodes for Bio-Syncretic Robot
Key Words: biomechanics  cellular biophysics  electromechanical actuators  medical robotics  microrobots  muscle  physiological models  tissue engineering  ultrasonic therapy  electrical stimulation  myotubes  bio-syncretic robot  circularly distributed multiple electrodes  C2C12 myoblasts  electro-responsive beating behavior  biomedical field  C2C12 differentiation  muscle tissue engineering  Electrodes  Electrical stimulation  Muscles  Robots  Electric fields  Biological materials  Force 
Abstract: Micro-robots have a great application prospect in the biomedical field due to the feature of small size. To solve the issues of energy supply and bio-compatibility of micro-robots, bio-syncretic micro-robots composed of biological materials and electromechanical systems have been studied widely. The skeletal muscle is a potential material to develop bio-actuator for the bio-syncretic robots on account of the great contraction force and the controllability. However, the low differentiation quality of C2C12s and the control of the bio-syncretic robots are the two of the main challenges for the development of the bio-syncretic robots based on the skeleton muscle. In this paper, an approach based on circularly distributed multiple electrodes (CDMEs) was proposed to improve the differentiation of C2C12 myoblast cells and characterize the electro-responsive beating behavior of myotubes for the development of bio-syncretic robots. Three groups of C2C12 blasts were used to fulfill the differentiation experiments without electrical stimulation and with electrical stimulation using parallel electrodes and CDMEs respectively, for evaluating the effect of CDMEs on C2C12 differentiation. It was demonstrated that electrical field through CDMEs can improve the differentiation quality of C2C12 blasts into myotubes in terms of intensity, length, and widths. Then, the effect of electrical stimulation on the beating behaviors of myotubes was also investigated with CDMEs, and it was shown that the beating amplitudes of myotubes were significantly affected by the frequencies, amplitude and direction of electrical stimulation with respect to the myotubes, which is fundamental for the control of the micro-robot based on skeletal muscle cells. The proposed approach is useful for not only the development of the bio-syncretic robots, but also the study of muscle tissue engineering.


Title: Compliant Low Profile Multi-Axis Force Sensors
Key Words: carbon fibre reinforced composites  compliant mechanisms  deformation  elastomers  force sensors  strain sensors  multiaxis force sensors  soft force sensors  compliant force sensors  microscale meanders  elastomers layers  sensor contact mechanics  differential measurement  laser-machined carbon fiber composite micro-structures  mechanical compliance  Robot sensing systems  Resistance  Fabrication  Geometry  Force sensors  Contacts  Carbon  Soft Material Robotics  Wearable Robots 
Abstract: The development of soft, compliant force sensors is greatly sought after in areas such as soft robotics and prosthetics. Nevertheless, solutions for measuring forces in multiple axes, while being mechanically compliant, have been few and far between. Here we present a compliant sensor able to detect forces tangential and normal to the sensor surface. The transduction mechanism is based on the deformation of laser-machined carbon fiber composite (CFC) micro-scale meanders, encapsulated within elastomers layers. Strains in the elastomer are transmitted to the meanders, causing changes in the electrical resistance of the sensor contact mechanics. Configuring the meanders in a radial pattern, segmenting them into quadrants (two antagonist pairs) and biasing the center of the sensor out-of-plane enables detection of forces in multiple axis via differential measurement. Sensors were manufactured using a custom fabrication process and exhibited high mechanical compliance with a very low form factor. The sensors were experimentally characterized and demonstrated large differential changes in resistance (up to 26 kΩ for tangential forces applied to the sensor surface). We integrated our sensor onto a soft robotic gripper finger and demonstrated the ability to detect changes in friction at the actuator surface, thus demonstrating their potential for real world applications.


Title: Reactive Planar Manipulation with Convex Hybrid MPC
Key Words: closed loop systems  learning (artificial intelligence)  manipulators  optimal control  optimisation  predictive control  Model Predictive Control formulation  optimal sequence  robot motions  desired object motion  multiple contact modes  frictional interactions  combinatorial complexity  optimal mode sequences offline  optimal control inputs  convex hybrid MPC program  planar manipulation experimental setup  convex hybrid MPC formulation  closed-loop performance  reactive planar manipulation  reactive controller  planar manipulation tasks  optimization program  machine learning  Task analysis  Force  Schedules  Friction  Predictive control  Manipulators  Optimization 
Abstract: This paper presents a reactive controller for planar manipulation tasks that leverages machine learning to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes. To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from machine learning, this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem.


Title: Decentralized Adaptive Control for Collaborative Manipulation
Key Words: adaptive control  decentralised control  Lyapunov methods  manipulators  multi-robot systems  stability  center-of-mass measurements  angular velocity  local measurements  collaborative manipulation  decentralized adaptive controller  common payload  agent positions  payload properties  Lyapunov-style analysis  stability  convergence  Payloads  Robots  Collaboration  Angular velocity  Velocity measurement  Task analysis  Stability analysis 
Abstract: This paper presents a design for a decentralized adaptive controller that allows a team of agents to manipulate a common payload in $\mathbb{R}^{2}$ or $\mathbb{R}^{3}$. The controller requires no communication between agents and requires no a priori knowledge of agent positions or payload properties. The agents can control the payload to track a reference trajectory in linear and angular velocity with center-of-mass measurements, in angular velocity using only local measurements and a common frame, and can stabilize its rotation with only local measurements. The controller is designed via a Lyapunov-style analysis and has proven stability and convergence. The controller is validated in simulation and experimentally with four robots manipulating an object in the plane.


Title: Modeling and Control of Multi-Arm and Multi-Leg Robots: Compensating for Object Dynamics During Grasping
Key Words: actuators  dexterous manipulators  humanoid robots  legged locomotion  manipulator dynamics  manipulator kinematics  mobile robots  motion control  object dynamics compensation  ANYmal  free-floating robot link  KUKA LWR IV+ representing fingers  contact wrenches control  floating-base multileg robots control  virtual DOF  enormous robot hand  underactuated robots  contact consistent motion generation  Projected Inverse Dynamics Control approach  underactuated system  multiarm robot  modeling approach  grasping scenarios  virtual manipulator  mass 9.0 kg  Grasping  Dynamics  Task analysis  Jacobian matrices  Manipulator dynamics 
Abstract: We consider a virtual manipulator in grasping scenarios which allows us to capture the effect of the object dynamics. This modeling approach turns a multi-arm robot into an underactuated system. We observe that controlling floating-base multi-leg robots is fundamentally similar. The Projected Inverse Dynamics Control approach is employed for decoupling contact consistent motion generation and controlling contact wrenches. The proposed framework for underactuated robots has been evaluated on an enormous robot hand composed of four KUKA LWR IV+ representing fingers cooperatively manipulating a 9kg box with total 28 actuated DOF and six virtual DOF representing the object as additional free-floating robot link. Finally, we validate the same approach on ANYmal, a floating-base quadruped with 12 actuated DOF. Experiments are performed both in simulation and real world.


Title: Multi-Priority Cartesian Impedance Control Based on Quadratic Programming Optimization
Key Words: collision avoidance  humanoid robots  human-robot interaction  motion control  quadratic programming  robot dynamics  service robots  torque control  prioritized Cartesian impedance control  inverse dynamics  matrix pseudoinversion  inverse kinematics computation  QP optimization  QP implementation  classical Cartesian impedance controller  humanoid upper-body torque controlled robot  quadratic programming optimization  inequality constraints  multipriority Cartesian impedance control  algebraic implementation  joint torque limits  virtual model control  Task analysis  Impedance  Robots  Force  Torque  Optimization  Acceleration 
Abstract: In this work we introduced a prioritized Cartesian impedance control under the framework of the Quadratic Programming (QP) optimization. In particular, we present a formulation which is simpler than full inverse dynamics, avoids any matrix pseudo-inversion, inverse kinematics computation and considers strict priorities among tasks. Our formulation is based on QP optimization permitting to take into account also explicit inequality constraints. We compare in simulation the tracking results obtained with a classical algebraic implementation against those derived from the proposed QP implementation taking into account joint torque limits. We consider the classical Cartesian impedance controller and a simplified version, also known as Virtual Model Control. Finally the proposed method was implemented and validated on a humanoid upper-body torque controlled robot. Experimental trials involving various physical interaction conditions were executed to demonstrate the performance of the proposed method.


Title: Responsive and Reactive Dual-Arm Robot Coordination
Key Words: collision avoidance  control engineering computing  industrial robots  manipulators  mobile robots  motion control  multi-robot systems  path planning  dual-arm robot coordination  temporal coordination  spatial coordination  shared workspace  industrial service-oriented robotics  user experience  execution performance  independently planned motions  dual-arm manipulator  motion commands  robot motion  ABB YuMi robot  Robot kinematics  Trajectory  Collision avoidance  Task analysis  Service robots  Manipulators 
Abstract: The need for temporal and spatial coordination of two robot arms moving independently in a shared workspace frequently arises in industrial and service-oriented robotics alike. Today, this problem is often solved manually, leading to a negative impact on user experience as well as on execution performance. In this paper, we present an algorithm that is able to automatically coordinate independently planned motions of a dual-arm manipulator during execution. In addition, the algorithm is capable of refining the plan upon receiving new motion commands during the robot motion. We demonstrate the effectiveness and efficiency of the proposed approach on an ABB YuMi robot working on an industrial palletizing task.


Title: Contact Point Localization for Articulated Manipulators with Proprioceptive Sensors and Machine Learning
Key Words: control engineering computing  learning (artificial intelligence)  manipulator dynamics  manipulator kinematics  multilayer perceptrons  optimisation  position control  contact point localization  articulated manipulators  proprioceptive sensors  machine learning  joint positions  one-dimensional joint torques  robot arm  RFs  contact link  contact points  Kinova Jaco 2 manipulator  optimization based approach  ML approach  serial manipulator  random forests  multilayer perceptrons  MLP  Force  Torque  Three-dimensional displays  Robot sensing systems  Manipulator dynamics 
Abstract: A model-based Machine Learning (ML) approach is presented to detect and localize external contacts on a 6 degree of freedom (DoF) serial manipulator. This approach only requires the use of proprioceptive sensors (joint positions, velocities and one-dimensional (ID) joint torques already available in the robot arm). Good results are obtained with Random Forests (RFs) and Multi-Layer-Perceptrons (MLPs) leading to a precise localization of the contact link and its orientation. Apart from the link in contact and the orientation of the force, RFs and MLPs are also able to differentiate between contact points on the same link and orientation but with different distances to the joint axis. We experimentally verify this approach on simulated and real data obtained from the Kinova Jaco 2 manipulator and compare it to an optimization based approach.


Title: $L_{1}$ Robustness of Computed Torque Method for Robot Manipulators
Key Words: continuous time systems  linear systems  manipulators  robust control  stability  time-varying systems  torque control  uncertain systems  robot manipulator  L1 robustness  L1 robust stability condition  performance measure  induced norm bounded model uncertainty  continuous-time linear time-invariant nominal plant  multiplicative model uncertainty  exogenous disturbance  modelling errors  computed torque controller  model uncertainties  computed torque method  Torque  Manipulator dynamics  Computational modeling  Uncertainty  Robustness 
Abstract: This paper revisits computed torque method for robot manipulators and aims at developing its new framework based on the L1 robustness, in which the L∞ norm together with its induced norm is employed to characterize model uncertainties and a performance measure. More precisely, we consider the L1 robust stability and performance for a given robot manipulator with a computed torque controller. We first show that the modelling errors in the computed torque method can be divided into an exogenous disturbance and a multiplicative model uncertainty, which are bounded in terms of the L∞ norm and its induced norm, respectively. It is next shown that the robot manipulator with the computed torque controller can be equivalently represented by an interconnection of a continuous-time linear time-invariant (LTI) nominal plant and a stabilizing controller together with the L∞-induced norm bounded model uncertainty. Based on the interconnected representation, the L1 robust stability condition and an upper bound of the L1 performance against the exogenous disturbance with respect to all model uncertainties in a class of a bounded L∞-induced norm are dealt with by using the small-gain theorem. Finally, the effectiveness of the theoretical results is demonstrated through some experiment results.


Title: Coverage Path Planning Under the Energy Constraint
Key Words: approximation theory  geometry  mobile robots  path planning  energy constraint  coverage path planning problem  battery limitations  working environment  geometric version  polygonal grid  single charging station  energy consumption  constant-factor approximation algorithm  contour-connected environments  aerial robot  mobile robot systems  Robots  Charging stations  Approximation algorithms  Path planning  Batteries  Partitioning algorithms  Energy consumption 
Abstract: In the coverage path planning problem, a common assumption is that the robot can fully cover the environment without recharging. However, in reality most mobile robot systems operate under battery limitations. To incorporate this constraint, we consider the problem when the working environment is large and the robot needs to recharge multiple times to fully cover the environment. We focus on a geometric version where the environment is represented as a polygonal grid with a single charging station. Energy consumption throughout the environment is assumed to be uniform and proportional to the distance traveled. We first present a constant-factor approximation algorithm for contour-connected environments. We then extend the algorithm for general environments. We also validate the results in experiments performed with an aerial robot.


Title: The Dubins Car and Other Arm-Like Mobile Robots
Key Words: force control  Jacobian matrices  mobile robots  optimal control  path planning  robot kinematics  torque control  Dubins car  lagrange multipliers  external force  equal torques  arm Jacobian yields  optimal paths  arm-like mobile robots  robots arm kinematics  geometric interpretations  rotation center locations  Kinematics  Mobile robots  Trajectory  Automobiles  Manipulators  Mathematical model 
Abstract: This paper investigates the connection between the kinematics of robots arms and the shortest paths for mobile robots. Lagrange multipliers are used to show that the shortest paths are equivalent to arms in configurations that balance an external force, while applying equal torques and forces at each joint. Analysis of the arm Jacobian yields a further geometric interpretations of optimal paths, constraining the locations of rotation centers and the directions of translations that may occur along optimal paths.


Title: Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  path planning  trajectory control  motion planning  robotics community  FaSTrack  sensor measurements  meta-planning notion  Crazyflie 2.0 quadrotor  adaptive realtime safe trajectory planning  safety guarantee  online planner  offline computation  motion plans  modular safety guarantee  Planning  Trajectory  Safety  Real-time systems  Robustness  Navigation  Computational modeling 
Abstract: Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of “meta-planning” in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.


Title: Online Falling-Over Control of Humanoids Exploiting Energy Shaping and Distribution Methods
Key Words: end effectors  humanoid robots  nonlinear control systems  position control  energy distribution polygons  humanoid robot  lateral falls  sagittal falls  EDP concepts  total energy  impact forces  online falling-over control  fall control technique  energy concepts  orientation control  energy shaping  nonlinear control  ES concepts  humanoids  end effectors  Force  Numerical models  Energy conversion  Robot kinematics  Position control  Dynamics 
Abstract: This paper proposes a novel fall control technique based on energy concepts, which can be applied online to mitigate the impact forces incurred during the falling over of humanoids. The technique reduces the total energy using a nonlinear control tool, called energy shaping (ES), and further distributes the reduced energy over multiple contacts by means of energy distribution polygons (EDP). We also include an effective orientation control to safeguard the end-effectors in the event of ground impacts. The performance of the proposed method is numerically evaluated by dynamic simulations under the sudden falling over scenario of the humanoid robot for both lateral and sagittal falls. The effectiveness of the proposed ES and EDP concepts are verified by diverse comparative simulations with total energy, distribution, and impact forces.


Title: MaestROB: A Robotics Framework for Integrated Orchestration of Low-Level Control and High-Level Reasoning
Key Words: humanoid robots  human-robot interaction  industrial robots  inference mechanisms  intelligent robots  middleware  multi-robot systems  ontologies (artificial intelligence)  robot programming  service robots  MaestROB  integrated orchestration  low-level control  high-level reasoning  MaestROBe  complex tasks  simple high-level instructions  hierarchical structure  ontology  actuation control  symbolic planner  Watson APIs  cognitive capabilities  semantic understanding  open source robot middleware  complex scenario  communication robot  industrial robot  common industrial task  assembly task  humanoid robot  SoftBank Robotics  natural language conversation  human demonstration  collaborative robot arm  Universal Robots  robotic framework  Task analysis  Service robots  Natural languages  Robot kinematics  Middleware  Robot sensing systems 
Abstract: This paper describes a framework called MaestROBe It is designed to make the robots perform complex tasks with high precision by simple high-level instructions given by natural language or demonstration. To realize this, it handles a hierarchical structure by using the knowledge stored in the forms of ontology and rules for bridging among different levels of instructions. Accordingly, the framework has multiple layers of processing components; perception and actuation control at the low level, symbolic planner and Watson APIs for cognitive capabilities and semantic understanding, and orchestration of these components by a new open source robot middleware called Project Intu at its core. We show how this framework can be used in a complex scenario where multiple actors (human, a communication robot, and an industrial robot) collaborate to perform a common industrial task. Human teaches an assembly task to Pepper (a humanoid robot from SoftBank Robotics) using natural language conversation and demonstration. Our framework helps Pepper perceive the human demonstration and generate a sequence of actions for UR5 (collaborative robot arm from Universal Robots), which ultimately performs the assembly (e.g. insertion) task.


Title: Ctrl-MORE: A Framework to Integrate Controllers of Multi-DoF Robot for Developers and Users
Key Words: control system synthesis  feedback  mobile robots  multi-robot systems  path planning  robust control  software architecture  trajectory control  multiDoF robot  robotic applications  modular framework  software architecture  control developers  feedback controllers  coupling  software modules  Ctrl-MORE  manipulation  locomotion  vision  stabilizers  trajectory planners  robustness  Robots  Documentation  Software  Task analysis  Computer architecture  Hardware  Tools 
Abstract: In recent years, many different feedback controllers for robotic applications have been proposed and implemented. However, the high coupling between the different software modules made their integration into one common architecture difficult. Consequently, this has hindered the ability of a user to employ the different controllers into a single, general and modular framework. To address this problem, we present Ctrl-MORE, a software architecture developed to fill the gap between control developers and other users in robotic applications. On one hand, Ctrl-MORE aims to provide developers with an opportunity to integrate easily and share their controllers with other roboticists working in different areas. For example, manipulation, locomotion, vision and so on. On the other hand, it provides to end-users a tool to apply the additional control strategies that guarantee the execution of desired behaviors in a transparent, yet efficient way. The proposed control architecture allows an easier integration of general purpose feedback controllers, such as stabilizers, with higher control layers such as trajectory planners, increasing the robustness of the overall system.


Title: Multilayered Kinodynamics Simulation for Detailed Whole-Body Motion Generation and Analysis
Key Words: biomedical measurement  fracture  gait analysis  injuries  kinematics  Monte Carlo methods  whole-body motions  whole-body motion generation  vertical contact force  human motion mechanisms  whole-body human model  MLKD Sim  multilayered kinodynamics simulation  Dynamics  Computational modeling  Force  Legged locomotion  Kinematics  Data models  Analytical models 
Abstract: This study generates and analyzes unsafe human motions that cannot be measured experimentally in laboratories with dynamic consistency. Detailed whole-body motions are generated by a multilayered kinodynamics simulation (MLKD Sim) that uses a detailed digital whole-body human model and a simple motion-representation model that parametrically represents human motion mechanisms. First, we develop the simple motion-representation model that represents human motion and contact force data that are experimentally measured in a laboratory, and we identify this model's parameters based on these experimental data. Forward dynamics computation of this motion-representation model with changing model and/or environmental parameters simulates motion modification as well as a contact force with dynamic consistency. Finally, the mapping function from the motion-representation model's motion to the detailed motion identified from the experimental data is used to reconstruct the detailed whole-body motion. MLKD Sim reconstructs a vertical contact force with average error of 2.18E+02 N, center of mass trajectory with average error of 3.31E-02 m, ankle joint angle with average error of 1.11E-01 rad (2.95E+00%), and ankle joint torque with average error of 6.13E+01 Nm (1.93E+01%). Unsafe motion simulation results show that the physical load on the hip, knee, and ankle joints increases by 9.23E+01%, 5.42E+02%, and 1.45E+02% respectively with 0.5-m level difference in a running surface. These results imply that when sprinting in an unknown environment, we need to protect, in order, the knee ankle, and hip joints. This study conducts detailed dynamics and kinematics analysis of unsafe human motions that cannot be measured experimentally in laboratories to prevent injuries, falls, and fatigue, and these results should find applications in the fields of medicine and welfare.


Title: End-to-end Learning of Multi-sensor 3D Tracking by Detection
Key Words: image matching  learning (artificial intelligence)  linear programming  object detection  object tracking  target tracking  3D trajectories  multisensor 3D tracking  end-to-end learning  convolutional networks  linear program  LIDAR data  Trajectory  Three-dimensional displays  Laser radar  Tracking  Cameras  Neural networks  Radar tracking 
Abstract: In this paper we propose a novel approach to tracking by detection that can exploit both cameras as well as LIDAR data to produce very accurate 3D trajectories. Towards this goal, we formulate the problem as a linear program that can be solved exactly, and learn convolutional networks for detection as well as matching in an end-to-end manner. We evaluate our model in the challenging KITTI dataset and show very competitive results.


Title: ModQuad: The Flying Modular Structure that Self-Assembles in Midair
Key Words: attitude control  autonomous aerial vehicles  mobile robots  multi-robot systems  robot dynamics  self-assembly  midair  modular robotic structure  self-assemble  agile flying modules  quadrotor platform  ModQuad swarm  modular flying structures  decentralized modular attitude controller  docking method  flying modular structure  flying structure assembling  cooperative flying method  Robot kinematics  Rotors  Buildings  Payloads  Shape  Task analysis 
Abstract: We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.


Title: Autonomous Battery Exchange of UAVs with a Mobile Ground Base
Key Words: autonomous aerial vehicles  control engineering computing  mobile robots  multi-robot systems  planetary rovers  small scale UAV  autonomous battery exchange operation  autonomous operations  landed UAV  ground rover  autonomous outdoor experiments  collaborative software framework  robotic systems  persistence  battery exchange mechanism  service station  robotic arm  mobile ground base  Batteries  Task analysis  Actuators  Robot kinematics  Planning  Manipulators 
Abstract: This paper presents the autonomous battery exchange operation for small scale UAVs, using a mobile ground base that carries a robotic arm and a service station containing the battery exchange mechanism. The goal of this work is to demonstrate the means to increase the autonomy and persistence of robotic systems without requiring human intervention. The design and control of the system and its components are presented in detail, as well as the collaborative software framework used to plan and execute complex missions. Finally, the results of autonomous outdoor experiments are presented, in which the ground rover successfully localizes, retrieves, services, and deploys the landed UAV, proving its capacity to extend and enhance autonomous operations.


Title: Development of an Fast-Omnidirectional Treadmill (F-ODT) for Immersive Locomotion Interface
Key Words: belts  computer based training  gears  medical computing  patient rehabilitation  pulleys  virtual reality  power transmission performance  weight structure  power transmission efficiency  transversal treadmills  omnidirectional treadmills  fast-omnidirectional treadmill  Geared Omni-pulley  power transmission mechanism  power transmission inefficiency  omnidirectional walking  human locomotion  virtual environment  natural navigation  immersive navigation  immersive locomotion interface  virtual reality environments  locomotion interface platform  F-ODT system  independent Y-axis motion  Belts  Motion segmentation  Power transmission  Torque  Synchronous motors  Angular velocity  Acceleration 
Abstract: To achieve immersive and natural navigation in a virtual environment through human locomotion, it is necessary to generate a 2-dimensional infinite ground for omnidirectional walking. However, the existing omnidirectional treadmills are heavy, complex and exhibit low acceleration due to power transmission inefficiency. In this paper, we present a novel fast-omnidirectional treadmill (F-ODT) with a new power transmission mechanism called the Geared Omni-pulley. This mechanism ensures higher power transmission efficiency for driving the belts of the multiple transversal treadmills for independent Y-axis motion. Due to the improved power transmission performance combined with a simpler and relatively light-weight structure, the proposed 2D treadmill can generate a maximum speed of 3m/sec with an acceleration of 3m/sec2. Based on the improved performance, the F-ODT system can be used as a locomotion interface platform in various virtual reality environments such as training of soldiers, gaming/educational experiences and gait rehabilitation.


Title: Design Considerations and Redundancy Resolution for Variable Geometry Continuum Robots
Key Words: Jacobian matrices  manipulator kinematics  mobile robots  redundant manipulators  design alternative  kinematic redundancy  kinematic parameter adaptation  continuum robot design  admissible design parameter values  joint forces  gradient descent redundancy resolution problem  variable geometry continuum  joint limits  multibackbone continuum robots  continuum robot segment  situational awareness  task execution performance  Couplings  Kinematics  Elbow  Robot sensing systems  Redundancy  Fasteners  Continuum robots  variable geometry robots  redundancy  angulated scissor mechanism  kinematics 
Abstract: Current multi-backbone continuum robots are limited to a constant cross-sectional diameter. This paper proposes a design alternative that overcomes this limitation. The ability to change the diameter of a continuum robot expands the repertoire of kinematic redundancy and enables kinematic parameter adaptation to optimize performance. A continuum robot design based on the angulated scissor mechanism is presented along with its position analysis. An exploration of admissible design parameter values for a given continuum robot segment with a desired maximum curvature while maintaining an open bore along its center is also carried out. A design presenting how this mechanism can be incorporated into a continuum robot is shown and a strategy for minimizing joint forces and avoiding joint limits is formulated as a gradient descent redundancy resolution problem in a simulation case study. The simulation results show that varying the diameter can significantly reduce joint forces while preserving the workspace and avoiding joint limits. This work is a first step towards continuum robots with situational awareness that will use their sensing capabilities to adapt their structure in order to optimize task execution performance.


Title: Cubic Range Error Model for Stereo Vision with Illuminators
Key Words: cameras  image sensors  robot vision  stereo image processing  telecommunication scheduling  cubic range error model  stereo vision  low-cost depth sensors  stereo camera setup  robotics  augmented reality  map generation  sensor scheduling policy  multisensor setup  range error models  uncertainty estimates  range measurements  integrated illuminators  off-the-shelf structured light stereo system  Cameras  Robot sensing systems  Uncertainty  Lighting  Geometry 
Abstract: Use of low-cost depth sensors, such as a stereo camera setup with illuminators, is of particular interest for numerous applications ranging from robotics and transportation to mixed and augmented reality. The ability to quantify noise is crucial for these applications, e.g., when the sensor is used for map generation or to develop a sensor scheduling policy in a multi-sensor setup. Range error models provide uncertainty estimates and help weigh the data correctly in instances where range measurements are taken from different vantage points or with different sensors. Such a model is derived in this work. We show that the range error for stereo systems with integrated illuminators is cubic and validate the proposed model experimentally with an off-the-shelf structured light stereo system. The experiments confirm the validity of the model and simplify the application of this type of sensor in robotics.


Title: Validation of the Robot Rendezvous and Grasping Manoeuvre Using Microgravity Simulators
Key Words: aerospace robotics  artificial satellites  control system synthesis  end effectors  industrial robots  multi-robot systems  path planning  space debris  space vehicles  robot rendezvous  grasping manoeuvre  unmanned chaser satellite  performing rendezvous  grasping manoeuvres  space debris  manoeuvres high disturbances  manipulator arm end-effector  robotic subsystem  chaser rendezvous  planar air-bearing microgravity simulators  industrial robots  specified test-bed system  Manipulators  Satellites  Orbits  Space vehicles  Service robots  Control systems 
Abstract: Robots mounted on an unmanned chaser satellite could be used for performing rendezvous and grasping manoeuvres in order to repair satellites or remove space debris from orbit. Use of manipulators for such purposes is challenging, since the performed task need to be done autonomously, accurately and with high level of robustness. During manoeuvres high disturbances might appear e.g. due to contact between the manipulator arm end-effector and the target spacecraft. In this paper an approach for validation of the robotic subsystem during chaser rendezvous and grasping manoeuvre has been shown. Two type of testbed systems were used: planar air-bearing microgravity simulators and a test-bed system with industrial robots. The proposed approach took advantage of possible replacement of particular subsystem in reference model or reference hardware in specified test-bed system. The list of tests performed are included in the paper.


Title: Collision-Based Contact Mode Estimation for Dynamic Rigid Body Capture
Key Words: aerospace robotics  collision avoidance  manipulator dynamics  mobile robots  motion estimation  multi-robot systems  particle filtering (numerical methods)  robot vision  space debris  vehicle dynamics  space debris  Brach collision model  collision-based contact mode estimation  particle filter  pre-capture phase  motion estimation error  reasonable computation resources  collision-triggered filter  moving rigid body  force-torque sensor  dynamic rigid body capture  Estimation  Robot sensing systems  Computational modeling  Collision avoidance  Predictive models  Bayes methods 
Abstract: This paper proposes real-time collision-based contact mode estimation with only a force-torque sensor for capturing a moving rigid body. The contact modes are defined for determining when to generate the signal to close the robotic hand for establishing object closure. In our particle filter approach, collision-triggered filter is used to determine the contact mode with the least amount of computation. Brach's collision model is used for our collision model-based approach for a rigid body because it is computationally light-weighted and enables the sampling of three collision properties for the particle filter. The validity of our method is experimentally demonstrated by achieving the highest success rate using the reasonable computation resources required (average of 3.9 milliseconds and worst of 6.1 milliseconds with our setup), and verifying each computation resource (or number of particles) based on the size of motion estimation error in the pre-capture phase.


Title: Available Wrench Set for Planar Mobile Cable-Driven Parallel Robots
Key Words: cables (mechanical)  end effectors  manipulator kinematics  mobile robots  robot dynamics  geometric architecture  parallel manipulators  convex hull methods  hyperplane shifting methods  point-mass end-effector  static equilibrium  mobile cable-driven parallel robots  available wrench set  Task analysis  Parallel robots  Power cables  Collision avoidance  Prototypes  Wheels 
Abstract: Cable-Driven Parallel Robots (CDPRs) have several advantages over conventional parallel manipulators most notably a large workspace. CDPRs whose workspace can be further increased by modification of the geometric architecture are known as Reconfigurable Cable Driven Parallel Robots(RCDPRs). A novel concept of RCDPRs, known as Mobile CDPR (MCDPR) that consists of a CDPR carried by multiple mobile bases, is studied in this paper. The system is capable of autonomously navigating to a desired location then deploying to a standard CDPR. In this paper, we analyze the Static equilibrium (SE) of the mobile bases when the system is fully deployed. In contrast to classical CDPRs we show that the workspace of the MCDPR depends, not only on the tension limits, but on the SE constraints as well. We demonstrate how to construct the Available Wrench Set (AWS) for a planar MCDPR wih a point-mass end-effector using both the convex hull and Hyperplane shifting methods. The obtained results are validated in simulation and on an experimental platform consisting of two mobile bases and a CDPR with four cables.


Title: Detection and Resolution of Motion Conflict in Visual Inertial Odometry
Key Words: distance measurement  inertial navigation  motion estimation  motion conflict detection  motion estimation  motion conflict resolution  visual-inertial odometry  Motion Conflict aware Visual Inertial Odometry  Visualization  Cameras  Estimation  Robustness  Simultaneous localization and mapping  Hidden Markov models 
Abstract: In this paper, we present a novel method to detect and resolve motion conflicts in visual-inertial odometry. Recently, it has been common to integrate an IMU sensor with visual odometry in order to improve localization accuracy and robustness. However, when a disagreement between the two sensor modalities occurs, the localization accuracy reduces drastically and leads to irreversible errors. In such conditions, multiple motion estimates based on the set of observations used are possible. This creates a conflict (motion conflict) in determining which observations to use for accurate ego-motion estimation. Therefore, we present a method to detect motion conflicts based on per-frame positional estimate discrepancy and per-landmark reprojection errors. Additionally, we also present a method to resolve motion conflicts by eliminating inconsistent IMU and landmark measurements. Finally, we implement Motion Conflict aware Visual Inertial Odometry (MC-VIO) by combining both detection and resolution of motion conflicts. We perform quantitative and qualitative evaluation of MC-VIO on visually and inertially challenging datasets. Experimental results indicate that the MC-VIO algorithm reduces the increase in absolute trajectory error by 80% and the relative pose error by 60% for scenes with motion conflict, in comparison to the state-of-the-art reference VIO algorithm.


Title: Adversarial Training for Adverse Conditions: Robust Metric Localisation Using Appearance Transfer
Key Words: feature extraction  image filtering  image recognition  adversarial training  adverse conditions  robust metric localisation  appearance transfer  visual place recognition  invertable generator  image transforming filter  feature-matching  dense descriptor maps  output synthetic images  input RGB image  generated images  multiple traversals  reliable localisation  Generators  Detectors  Measurement  Feature extraction  Computer architecture  Training  Pipelines 
Abstract: We present a method of improving visual place recognition and metric localisation under very strong appearance change. We learn an invertable generator that can transform the conditions of images, e.g. from day to night, summer to winter etc. This image transforming filter is explicitly designed to aid and abet feature-matching using a new loss based on SURF detector and dense descriptor maps. A network is trained to output synthetic images optimised for feature matching given only an input RGB image, and these generated images are used to localize the robot against a previously built map using traditional sparse matching approaches. We benchmark our results using multiple traversals of the Oxford RobotCar Dataset over a year-long period, using one traversal as a map and the other to localise. We show that this method significantly improves place recognition and localisation under changing and adverse conditions, while reducing the number of mapping runs needed to successfully achieve reliable localisation.


Title: Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming
Key Words: autonomous aerial vehicles  concave programming  knapsack problems  mobile robots  multi-robot systems  stochastic programming  chance-constrained 0-1 knapsack problem  variance-mean plane  deterministic knapsack problems  multirobot team selection problem  optimal chance constrained knapsack problem  2D discrete optimization problem  risk-averse knapsack problem  Robots  Optimization  Random variables  Task analysis  Batteries  Linear programming  Approximation algorithms 
Abstract: Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.


Title: Planning-Aware Communication for Decentralised Multi-Robot Coordination
Key Words: control engineering computing  mobile robots  Monte Carlo methods  multi-robot systems  path planning  planning (artificial intelligence)  statistical distributions  tree searching  decentralised multirobot coordination  coordinated multirobot missions  polynomial-time belief-space planning algorithm  informative communication planning  planning-aware communication  multirobot information gathering  robot simulation  decentralised Monte Carlo tree search  Planning  Robot kinematics  Prediction algorithms  Probability distribution  Australia  Cognition 
Abstract: We present an algorithm for selecting when to communicate during online planning phases of coordinated multi-robot missions. The key idea is that a robot decides to request communication from another robot by reasoning over the predicted information value of communication messages over a sliding time-horizon, where communication messages are probability distributions over action sequences. We formulate this problem in the context of the recently proposed decentralised Monte Carlo tree search (Dec-MCTS) algorithm for online, decentralised multi-robot coordination. We propose a particle filter for predicting the information value, and a polynomial-time belief-space planning algorithm for finding the optimal communication schedules in an online and decentralised manner. We evaluate the benefit of informative communication planning for a multi-robot information gathering scenario with 8 simulated robots. Our results show reductions in channel utilisation of up to four-fifths with surprisingly little impact on coordination performance.


Title: Multi-Robot Realization Based on Goal Adjacency Constraints
Key Words: closed loop systems  matrix algebra  mobile robots  multi-robot systems  navigation  path planning  position control  velocity control  pairwise distances  velocity-controlled robot  multirobot realization  goal adjacency constraints  robot positions  exact goal positions  relative distances  pairwise adjacency constraints  multirobots  adjacency matrix  adjacency threshold  robot pairs  coordinated navigation  closed-loop dynamics  Conferences  Automation  Australia 
Abstract: This paper considers the problem of multi-robot realization. A realization is a set of robot positions where pairwise distances are either bounded from above or from below by a given adjacency threshold - depending on whether the respective robot pairs are to be adjacent or not. In the realization problem, unlike the related coordinated navigation or formation control problems, exact goal positions or relative distances need not be specified. Rather, only pairwise adjacency constraints are given and the robots' positions are required to satisfy these constraints. Applications of realization problem include multi-robots involved in team games (playing soccer, etc), patrolling and area coverage. We present a novel solution to this problem in which the robots simultaneously navigate to find a realization of a given adjacency matrix without colliding with each other along the way. In this solution, complete information about pairwise distances and free configuration space are encoded using an artificial potential function over the cross product space of the robots' simultaneous positions and proximity variables. The closed-loop dynamics governing the motion of each velocity-controlled robot take the form of the appropriate projection of the gradient of this function while pairwise distances are adjusted accordingly. Our extensive simulations demonstrate that the proposed approach has considerably higher realization percentage and shorter movement distances in comparison to a standard 2-stage approach.


Title: Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication
Key Words: aerospace robotics  asymptotic stability  compensation  controllability  distributed control  helicopters  mobile robots  trajectory optimisation (aerospace)  exponential stability  distributed compensation scheme  controllability  local optimization problem  entire assembly  distributed wrench controller  rigidly attached quadrotor aerial robots  multiple quadrotors  subsequent trajectory optimization  output wrench space  control wrench  group control authority  Robot kinematics  Trajectory  Torque  Three-dimensional displays  Payloads  Unmanned aerial vehicles 
Abstract: We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.


Title: An Energy-Based Approach for the Multi-Rate Control of a Manipulator on an Actuated Base
Key Words: aerospace robotics  damping  manipulators  observers  stability  vibration control  energy-based approach  multirate control  robotic system  actuated floating base  space applications  stability issues  time domain passivity approach  base-manipulator multibody simulation  passivity-based stabilizing controller  energy observer design  Manipulators  Satellites  Jacobian matrices  Stability analysis  Delays  Time-domain analysis 
Abstract: In this paper we address the problem of controlling a robotic system mounted on an actuated floating base for space applications. In particular, we investigate the stability issues due to the low rate of the base control unit. We propose a passivity-based stabilizing controller based on the time domain passivity approach. The controller uses a variable damper regulated by a designed energy observer. The effectiveness of the proposed strategy is validated on a base-manipulator multibody simulation.


Title: Optimal Intermittent Deployment and Sensor Selection for Environmental Sensing with Multi-Robot Teams
Key Words: decision theory  Markov processes  multi-robot systems  partial environmental information  optimal policy  optimal intermittent deployment  multirobot team  environmental sensing problem  team composition  environmental process  heterogeneous robots  heterogeneous robot teams  sensor types  sensor selection policy  Robot sensing systems  Robot kinematics  Markov processes  Computational modeling  Delays 
Abstract: In this paper, we formulate an environmental sensing problem for multi-robot teams that couples intermittent deployments with the selection of team composition and sensor type over time. We suppose that a multi-robot team needs to autonomously sense an environmental process and find the optimal policy for deploying heterogeneous robots. In addition, heterogeneous robot teams can be composed in various ways by selecting different mobility and sensor types which have varying accuracies and costs, resulting in a more complex problem. The question is then how to find an optimal intermittent deployment and sensor selection policy that captures both cost and estimation accuracy based on partial environmental information. By utilizing structural results from partially observable Markov decision processes (POMDP) and exploiting submodularity, an optimal policy, which minimizes cost while maintaining a high accuracy, can be achieved in this paper. The effectiveness of this method is demonstrated by simulation results and comparisons with naive policies.


Title: Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning
Key Words: cables (mechanical)  dynamic programming  mobile robots  multi-robot systems  optimal control  path planning  planning problems  aerial robots  transportation task  ground robots  nonrigid inextensible cables  heterogeneous multirobot system  multiple aerial vehicles  general constrained optimal planning problem  multiple ground vehicles  cooperative object transportation  modeling problems  dynamic programming  Vehicle dynamics  Manipulators  Load modeling  Unmanned aerial vehicles  Dynamics 
Abstract: In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.


Title: Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints
Key Words: autonomous aerial vehicles  delays  distributed control  mobile robots  multi-robot systems  intermittent communications  high-level decision skills  distributed decision architecture  hybrid planner  distributed execution algorithm  delays  surveillance missions  ground robots  heterogeneous robots  field multirobot missions  autonomous aerial robot  unavoidable disturbances  integrating planning and execution  communication constrains  time constraints  decentralized repairs  Maintenance engineering  Planning  Computer architecture  Robot kinematics  Surveillance  Delays 
Abstract: Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.


Title: Time-Contrastive Networks: Self-Supervised Learning from Video
Key Words: image representation  learning (artificial intelligence)  pose estimation  robot programming  robot vision  video signal processing  time-contrastive networks  robotic behaviors  robotic imitation settings  human poses  viewpoint-invariant representation  end-effectors  reinforcement learning algorithm  self-supervised learning  robotic systems  Robots  Task analysis  Visualization  Learning (artificial intelligence)  Training  Liquids  Lighting 
Abstract: We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.


Title: Elastic LiDAR Fusion: Dense Map-Centric Continuous-Time SLAM
Key Words: image reconstruction  mobile robots  optical radar  optimisation  probability  radar imaging  robot vision  sensor fusion  SLAM (robots)  dense map-centric continuous-time SLAM  CT-SLAM  computational complexity  surfel fusion  global batch trajectory optimization  probabilistic surface element fusion  map deformation  global trajectory optimization  Continuous-Time SLAM  global batch optimization  multimodal sensor fusion  continuous-time trajectory representation  elastic LiDAR fusion  Laser radar  Trajectory optimization  Simultaneous localization and mapping  Strain  Interpolation 
Abstract: The concept of continuous-time trajectory representation has brought increased accuracy and efficiency to multi-modal sensor fusion in modern SLAM. However, regardless of these advantages, its offline property caused by the requirement of global batch optimization is critically hindering its relevance for real-time and life-long applications. In this paper, we present a dense map-centric SLAM method based on a continuous-time trajectory to cope with this problem. The proposed system locally functions in a similar fashion to conventional Continuous-Time SLAM (CT-SLAM). However, it removes the need for global trajectory optimization by introducing map deformation. The computational complexity of the proposed approach for loop closure does not depend on the operation time, but only on the size of the space it explored before the loop closure. It is therefore more suitable for long term operation compared to the conventional CT-SLAM. Furthermore, the proposed method reduces uncertainty in the reconstructed dense map by using probabilistic surface element (surfel) fusion. We demonstrate that the proposed method produces globally consistent maps without global batch trajectory optimization, and effectively reduces LiDAR noise by surfel fusion.


Title: Design, modeling and control of t3-multirotor: a tilting thruster type multirotor
Key Words: aerospace components  attitude control  helicopters  large-scale systems  servomechanisms  tilting thruster type multirotor  mechanically separated thrusters  fuselage posture  relative attitude control  T3-multirotor  translational acceleration  servo-linkage mechanism  dynamically complex system  autonomous level flight  Servomotors  Mathematical model  Force  Torque  Dynamics  Attitude control  Analytical models 
Abstract: This paper presents a new design of multirotor, named as `Tilting Thruster Type' (T3)-multirotor. The new platform is equipped with mechanically separated thrusters, which can take any fuselage posture within a specified range regardless of any direction of translational acceleration. A specially designed servo-linkage mechanism is employed for relative attitude control between the thruster and the fuselage. Mathematical modeling and analysis of the new platform are conducted to explore the control method of the dynamically complex system. For demonstrating the potential of the new T3-multirotor, an autonomous level flight is performed where the fuselage maintains zero roll and pitch angle during the entire flight. Both simulation and experimental results are provided with detailed analysis.


Title: An Empirical Evaluation of Ground Effect for Small-Scale Rotorcraft
Key Words: aircraft control  autonomous aerial vehicles  helicopters  propellers  rotors  helicopter ground effect  hover performance  multirotor UAV  rotor performance  single-rotor configuration  fixed propellers  propeller configuration  UAV flight controller  flight stability  ground effect  helicopter models  Cheeseman-Bennett model  small-scale rotorcraft  Rotors  Propellers  Mathematical model  Atmospheric modeling  Blades  Helicopters 
Abstract: Ground effect refers to the apparent increase in lift that an aircraft experiences when it flies close to the ground. For helicopters, this effect has been modeled since the 1950's based on the work of Cheeseman and Bennett, perhaps the most common method for predicting hover performance due to ground effect. This model, however, is based on assumptions that do not hold for small-scale rotorcraft because it was developed specifically for conventional helicopters. It is not clear if the Cheeseman-Bennett model can be applied to today's multirotor UAVs. In this paper, we compare the Cheeseman-Bennett model to experimental results for rotor performance due to ground effect in several small-scale multirotor and single-rotor configurations. Experimental findings suggest that some of the conventional thinking surrounding helicopter ground effect cannot be applied directly to rotorcraft using fixed propellers at variable speeds (e.g. multirotors), and that it is necessary to adjust the helicopter models to better reflect the differences in such aircraft. The experimental results for multirotors presented are for multiple propeller configurations, speeds and spacings. Ultimately, this work will facilitate the development of an improved UAV flight controller that can accurately account for ground effect to improve flight stability near surfaces and structures.


Title: The UNAV, a Wind-Powered UAV for Ocean Monitoring: Performance, Control and Validation
Key Words: actuators  aerodynamics  aerospace components  aircraft control  autonomous aerial vehicles  autonomous underwater vehicles  drag  hydrodynamics  vehicle dynamics  UNAv  Unmanned Nautical Air-water vehicle  albatrosses  sailboats  wind power  ocean monitoring  wind-powered UAV  multiinput longitudinal flight controller  trim analysis  sailboat  airborne wings  gravity-cancelling force  high lift-to-drag ratio  albatross  span-wise axes  vertical surface-piercing hydrofoil keel  vertical wing-sail  glider-type airframe  Drag  Force  Sea surface  Aerodynamics  Wind  Atmospheric modeling 
Abstract: Wind power is the source of propulsive energy for sailboats and albatrosses. We present the UNAv, an Unmanned Nautical Air-water vehicle, that borrows features from both. It is composed of a glider-type airframe fitted with a vertical wing-sail extending above the center of mass of the system and a vertical surface-piercing hydrofoil keel extending below. The sail and keel are both actuated in pitch about their span-wise axes. Like an albatross, the UNAv is fully streamlined, high lift-to-drag ratio and generates the gravity-cancelling force by means of its airborne wings. Like a sailboat, the UNAv interacts with water and may access the full magnitude of the wind. A trim analysis predicts that a 3.4-meter span, 3 kg system could stay airborne in winds as low as 2.8 m/s (5.5 knots), and travel several times faster than the wind speed. Trim flight requires the ability to fly at extreme low height with the keel immersed in water. For that purpose, a multi-input longitudinal flight controller that leverages fast flap actuation is presented. The flight maneuver is demonstrated experimentally.


Title: Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints
Key Words: cooperative systems  decision making  distributed control  Gaussian processes  multi-robot systems  path planning  Gaussian processes  path planning  path clustering  multi-robot exploration  inter-robot communication constraints  information-theoretic utility function  Max-sum algorithm  distributed decision-making algorithm  multirobot information gathering  inter-robot restrictions  distributed multirobot cooperation  Clustering algorithms  Robot kinematics  Robot sensing systems  Heuristic algorithms  Linear programming 
Abstract: Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.


Title: GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation
Key Words: autonomous aerial vehicles  distance measurement  graph theory  Kalman filters  mobile robots  nonlinear filters  optimisation  pose estimation  robot vision  sensor fusion  SLAM (robots)  GOMSF  proprioceptive measurements  exteroceptive measurements  navigation algorithms  agile mobile robots  Unmanned Aerial Vehicles  UAV pose estimation  graph optimization based multisensor fusion  6 Degree-of-Freedom visual-inertial odometry poses  extended Kalman filter  Robot sensing systems  Robot kinematics  Optimization  Pose estimation  Global Positioning System  Time measurement 
Abstract: Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.


Title: Encoder-Camera-Ground Penetrating Radar Tri-Sensor Mapping for Surface and Subsurface Transportation Infrastructure Inspection
Key Words: automatic optical inspection  cameras  graph theory  ground penetrating radar  image fusion  image reconstruction  optimisation  pose estimation  structural engineering computing  transportation  GPR  wheel encoder  sensing suite  data collection scheme  ALs  types data streams  camera images  data fusion  sensory data  sensor fusion approach  encoder-camera-ground penetrating radar tri-sensor mapping  subsurface transportation infrastructure inspection  algorithmic development  multiple sensors  multimodal mapping  Ground penetrating radar  Cameras  Inspection  Synchronization  Robot sensing systems  Three-dimensional displays 
Abstract: We report system and algorithmic development for a sensing suite comprising multiple sensors for both surface and subsurface transportation infrastructure inspection focusing on multi-modal mapping for inspection. The sensing suite contains a camera, a ground penetrating radar (GPR), and a wheel encoder. We design the sensing suite and propose a data collection scheme using customized artificial landmarks (ALs). We use ALs to synchronize two types data streams: camera images that are temporally evenly-spaced and GPR/encoder data that are spatially evenly-spaced. We also employ pose graph optimization with synchronization as penalty functions to further refine synchronization and perform data fusion for 3D reconstruction. We have implemented the system and tested it in physical experiments. The results show that our system successfully fuses three sensory data and product metric 3D reconstruction. The sensor fusion approach reduces the end-to-end distance error from 7.45cm to 3.10cm.


Title: Stiffness Variability in Jamming of Compliant Granules and a Case Study Application in Climbing Vertical Shafts
Key Words: bending  biomechanics  elastic constants  elasticity  end effectors  force measurement  friction  granular materials  legged locomotion  pressure sensors  shafts  cubic shaped granules  gradual stiffness change  jamming membranes  end effectors  bending stiffness  climbing task  shaft walls  compressive stiffness variation  multimodal properties  granular material  stiffness variability  quasisolid state  packing density  compliant granules jamming  granular media jamming  bioinspired robotic platform  straight vertical shafts climbing  friction force measurement  pressure sensor  force dissipators  Jamming  Biomembranes  End effectors  Shape  Shafts  Legged locomotion  Soft robotics  variable stiffness joints  vacuum jamming  universal gripper  climbing 
Abstract: Jamming of granular media has been shown to possess the property of stiffness variation, transitioning from a soft to a quasi-solid state depending on the packing density of the granules. Recently, a gradual stiffness change for bending has been reported by using compliant, cubic shaped granules. Here we demonstrate that the same method and material also exhibits a gradual stiffness change for compression. As a potential application of “compliant jamming”, a bio-inspired robotic platform with jamming membranes as end effectors is designed and tasked with climbing straight vertical shafts. First, the benefit of varying the bending stiffness is investigated in the climbing task by measuring the friction force that the end effectors are applying to the shaft walls, especially if the walls are irregularly shaped. Then the role of compressive stiffness variation is explored by analyzing the performance of the robot in the climbing task, showing multi-modal properties of jamming membranes: (i) enabling a pressure sensor to detect the shaft walls, acting (ii) as grippers that actively use the irregularities of the walls to climb up by state-switching the granular material and (iii) as force dissipators that can dissipate internal forces caused by closed kinematic chains.


Title: A Geometric and Unified Approach for Modeling Soft-Rigid Multi-Body Systems with Lumped and Distributed Degrees of Freedom
Key Words: elasticity  geometry  inverse problems  Newton method  robot dynamics  discrete Cosserat approach  soft-body dynamics  geometric theory  recursive Newton-Euler algorithm  forward dynamic problems  soft robots  soft-rigid multibody systems  inverse problems  linear complexity  Kinematics  Fasteners  Strain  Heuristic algorithms  Algebra  Soft robotics 
Abstract: In this paper, a geometric and unified model of soft-rigid multi-body systems is presented, based on a discrete Cosserat approach of the soft-body dynamics. The model is in fact a generalization to soft and hybrid systems of the geometric theory of rigid robotics characterized by the exponential map. A generalization of the recursive Newton-Euler algorithm is also presented, able to solve inverse and forward dynamic problems with linear O(N) complexity. The proposed model provides several improvements with respect to the existing flexible multi-body models, which make it particularly suitable to study the dynamics of modern soft robots as shown for a multi-body system inspired by motile bacteria.


Title: Completion Time Analysis for Automated Manufacturing Systems with Parallel Processing Modules
Key Words: cluster tools  etching  hoists  industrial robots  lithography  lot sizing  manufacturing systems  materials testing  parallel processing  scheduling  semiconductor device manufacture  semiconductor industry  storage  semiconductor manufacturing processes  lithography  etching  materials testing  scheduling  lot finish processing  stockers  overhead hoist transports  wafer lots  transport robot  dual-armed cluster tool  parallel processing modules  automated manufacturing systems  completion time analysis  Tools  Robots  Task analysis  Switches  Optimal scheduling  Job shop scheduling  Time factors 
Abstract: This paper analyzes the completion time of automated manufacturing systems, especially a dual-armed cluster tool, equipped with parallel processing modules (PMs). Cluster tools, which consist of multiple PMs, a transport robot, and loadlocks where wafer lots are loaded and unloaded, perform semiconductor manufacturing processes, such as lithography, etching, deposition, and testing. Wafer lots are transported by overhead hoist transports (OHTs) between tools or stockers where wafer lots are stored. To reduce the idle time of OHTs or cluster tools, it is essential to estimate the time when all wafers of a lot finish processing in a tool. Hence, we derive closed-form expressions for the completion time of wafer lots, especially in dual-armed cluster tools with parallel PMs to reflect real circumstances of fabs. We finally show that the formulas derived can be used even when there are small processing time variations with numerical experiments.


Title: Reliably Arranging Objects in Uncertain Domains
Key Words: learning (artificial intelligence)  manipulators  mobile robots  multi-robot systems  path planning  control uncertainty  conformant planning approach  robot manipulation  multiple planar objects  specified arrangement  external sensing  belief-state planning problem  initial belief state  forward belief-state planning  deterministic belief-state transition model  off-line physics simulations  on-line physics-based manipulation approach  physical robot experiments  uncertain domains  Planning  Robot sensing systems  Task analysis  Reliability  Computational modeling  Uncertainty 
Abstract: A crucial challenge in robotics is achieving reliable results in spite of sensing and control uncertainty. In this work, we explore the conformant planning approach to robot manipulation. In particular, we tackle the problem of pushing multiple planar objects simultaneously to achieve a specified arrangement without external sensing. Conformant planning is a belief-state planning problem. A belief state is the set of all possible states of the world, and the goal is to find a sequence of actions that will bring an initial belief state to a goal belief state. To do forward belief-state planning, we created a deterministic belief-state transition model from supervised learning based on off-line physics simulations. We compare our method with an on-line physics-based manipulation approach and show significantly reduced planning times and increased robustness in simulated experiments. Finally, we demonstrate the success of this approach in simulations and physical robot experiments.


Title: RoboTSP – A Fast Solution to the Robotic Task Sequencing Problem
Key Words: industrial robots  travelling salesman problems  Robotic Task Sequencing Problem  industrial robotics applications  spray-painting  robot travel time  execution time  robot configurations  task space  configuration space  RTSP literature  Generalized Traveling Salesman Problem  Task analysis  Measurement  Collision avoidance  Service robots  Planning  Space exploration 
Abstract: In many industrial robotics applications, such as spot-welding, spray-painting or drilling, the robot is required to visit successively multiple targets. The robot travel time among the targets is a significant component of the overall execution time. This travel time is in turn greatly affected by the order of visit of the targets, and by the robot configurations used to reach each target. Therefore, it is crucial to optimize these two elements, a problem known in the literature as the Robotic Task Sequencing Problem (RTSP). Our contribution in this paper is two-fold. First, we propose a fast, near-optimal, algorithm to solve RTSP. The key to our approach is to exploit the classical distinction between task space and configuration space, which, surprisingly, has been so far overlooked in the RTSP literature. Second, we provide an open-source implementation of the above algorithm, which has been carefully benchmarked to yield an efficient, ready-to-use, software solution. We discuss the relationship between RTSP and other Traveling Salesman Problem (TSP) variants, such as the Generalized Traveling Salesman Problem (GTSP), and show experimentally that our method finds motion sequences of the same quality but using several orders of magnitude less computation time than existing approaches.


Title: Modeling and Control of Brachiating Robots Traversing Flexible Cables
Key Words: cables (mechanical)  legged locomotion  manipulator dynamics  motion control  optimal control  torque control  trajectory control  vibration control  brachiating robots  coupling soft junctions  multiple-shooting  parametric trajectory approaches  catenary cable  energy-efficient continuous brachiation  optimal torque profiles  control torque profiles  optimized trajectories  robot locomotion  cable vibration  energy-minimizing optimal control strategy  two-link robot  multibody system  flexible cable  two-link underactuated brachiating robot  locomotion control  dynamic modeling  Junctions  Mathematical model  Grippers  Legged locomotion  Trajectory  Robot kinematics 
Abstract: This paper describes the dynamic modeling and locomotion control of a two-link underactuated brachiating robot traversing a flexible cable. A multi-body system comprised of a two-link robot, a flexible cable, and coupling soft junctions is modeled dynamically. This model is used to formulate an energy-minimizing optimal control strategy that includes the effects of cable vibration induced by robot locomotion. Optimized trajectories and control torque profiles are obtained via multiple-shooting and parametric trajectory approaches. Simulation results show that these optimal torque profiles result in energy-efficient continuous brachiation over a flexible cable. Additional studies examine how the optimal torque profiles change depending on the robot's initial position along a catenary cable.


Title: A Failure-Tolerant Approach to Synchronous Formation Control of Mobile Robots Under Communication Delays
Key Words: delays  mobile robots  motion control  multi-robot systems  switching systems (control)  topology  failure-tolerant approach  mobile robots  communication delays  robot malfunction  robot formation control  system malfunction  synchronous formation control problem  network connectivity  motion synchronism  robot replacements  synchronous formation control method  recursive switched topology control strategy  neighboring robots  Topology  Switches  Robot kinematics  Network topology  Synchronization 
Abstract: Robot malfunction is inevitable in practical applications of the robot formation control due to uncontrolled crashing, system malfunction or communication loss. In this paper, we study the synchronous formation control problem in the presence of robot malfunctions. Our main idea is to improve the network connectivity and motion synchronism of the robot formation through a series of topology switchings and robot replacements. Firstly, the synchronous formation control method is introduced which enables the robots to tracking their desired trajectories while keeping predefined formation shapes. Secondly, a recursive switched topology control strategy is proposed to restore the formation shape as well as to improve the network connectivity and motion synchronism in the presence of robot malfunctions. Thirdly, the convergence analysis of the proposed control system is presented and a sufficient condition is obtained under an average dwell time scheme. What's more, the proposed approach is fully distributed and the communication delays between neighboring robots also have been taken into consideration. Simulation results demonstrate the effectiveness of the proposed approach.


Title: Planning Hybrid Driving-Stepping Locomotion on Multiple Levels of Abstraction
Key Words: legged locomotion  path planning  navigating  rescue environments  locomotion methods  navigation planning method  hybrid driving-stepping locomotion planning  Momaro robot  robot state dimensionality  Planning  Robot sensing systems  Legged locomotion  Semantics  Motion segmentation 
Abstract: Navigating in search and rescue environments is challenging, since a variety of terrains has to be considered. Hybrid driving-stepping locomotion, as provided by our robot Momaro, is a promising approach. Similar to other locomotion methods, it incorporates many degrees of freedom - offering high flexibility but making planning computationally expensive for larger environments. We propose a navigation planning method, which unifies different levels of representation in a single planner. In the vicinity of the robot, it provides plans with a fine resolution and a high robot state dimensionality. With increasing distance from the robot, plans become coarser and the robot state dimensionality decreases. We compensate this loss of information by enriching coarser representations with additional semantics. Experiments show that the proposed planner provides plans for large, challenging scenarios in feasible time.


Title: Robot Navigation in Complex Workspaces Using Harmonic Maps
Key Words: geometry  mobile robots  motion control  path planning  robot vision  SLAM (robots)  complex workspaces  harmonic maps  Artificial Potential Fields  autonomous robot navigation control schemes  local minima  APF based control scheme  goal configuration  multiply connected compact 2D workspaces  Harmonic analysis  Navigation  Robot kinematics  Convergence  Tuning  Trajectory 
Abstract: Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline “tuning” of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.


Title: Backprop-MPDM: Faster Risk-Aware Policy Evaluation Through Efficient Gradient Optimization
Key Words: decision making  gradient methods  learning (artificial intelligence)  Markov processes  optimisation  stochastic processes  multipolicy decision-making  gradient optimization  risk-aware policy evaluation  backprop-MPDM policy  robot platform  easily-differentiable heuristic function  random sampling  stochastic gradient optimization algorithms  decision making process  risk-aware formulations  Robots  Computational modeling  Trajectory  Navigation  Decision making  Cost function 
Abstract: In Multi-Policy Decision-Making (MPDM), many computationally-expensive forward simulations are performed in order to predict the performance of a set of candidate policies. In risk-aware formulations of MPDM, only the worst outcomes affect the decision making process, and efficiently finding these influential outcomes becomes the core challenge. Recently, stochastic gradient optimization algorithms, using a heuristic function, were shown to be significantly superior to random sampling. In this paper, we show that accurate gradients can be computed - even through a complex forward simulation - using approaches similar to those in deep networks. We show that our proposed approach finds influential outcomes more reliably, and is faster than earlier methods, allowing us to evaluate more policies while simultaneously eliminating the need to design an easily-differentiable heuristic function. We demonstrate significant performance improvements in simulation as well as on a real robot platform navigating a highly dynamic environment.


Title: An MPC Walking Framework with External Contact Forces
Key Words: compensation  integer programming  legged locomotion  linear systems  predictive control  quadratic programming  hand contact  MPC walking framework  external contact forces  two-step optimization problem  Zero Moment Point  ZMP tracking error  friction cone  walking control scheme  linear model predictive control scheme  multiple contact locations  center of mass trajectory  mixed integer quadratic program  frequency 100.0 Hz to 300.0 Hz  Optimization  Force  Legged locomotion  Trajectory  Friction  Dynamics 
Abstract: In this work, we present an extension to a linear Model Predictive Control (MPC) scheme that plans external contact forces for the robot when given multiple contact locations and their corresponding friction cone. To this end, we set up a two-step optimization problem. In the first optimization, we compute the Center of Mass (CoM) trajectory, foot step locations, and introduce slack variables to account for violating the imposed constraints on the Zero Moment Point (ZMP). We then use the slack variables to trigger the second optimization, in which we calculate the optimal external force that compensates for the ZMP tracking error. This optimization considers multiple contacts positions within the environment by formulating the problem as a Mixed Integer Quadratic Program (MIQP) that can be solved at a speed between 100-300 Hz. Once contact is created, the MIQP reduces to a single Quadratic Program (QP) that can be solved in real-time (<; 1kHz). Simulations show that the presented walking control scheme can withstand disturbances 2-3× larger with the additional force provided by a hand contact.


Title: Empirical Quantification and Modeling of Muscle Deformation: Toward Ultrasound-Driven Assistive Device Control
Key Words: biomechanics  biomedical ultrasonics  electromyography  medical image processing  medical robotics  medical signal processing  muscle  assistive device sensor locations  real-time ultrasound scanning  muscle cross-sectional area  force-associated deformation signals  motion capture  ultrasound scanner  high-DoF assistive devices  B-mode ultrasound  exoskeletons  biosignal-driven prostheses  surface electromyography  toward ultrasound-driven assistive device control  empirical quantification  muscle deformation models  Muscles  Strain  Ultrasonic imaging  Elbow  Assistive devices  Deformable models  Ultrasonic variables measurement 
Abstract: Surface electromyography is currently the sensing modality of choice for control of biosignal-driven prostheses and exoskeletons; however, the sensor's noisy and aggregate nature inhibits collection of distinguishable signal streams to robustly manipulate multiple device degrees of freedom (DoF). We here explore 2D B-mode ultrasound as an alternative source of muscle activation data (namely, muscle deformation) that can be more precisely localized, allowing for the theoretical collection of multiple naturally-varying signals that could be used to control high-DoF assistive devices. We here present a proof-of-concept study showing a) the observability of muscle deformation via ultrasound, and b) novel descriptions of the spatially-varying nature of the signal. These analyses are accomplished through the study of nine volumetric scans of the biceps brachii under varied elbow angle and loading conditions, collected and spatially localized using an ultrasound scanner and motion capture. We here establish the feasibility of measuring several force-associated deformation signals (including muscle cross-sectional area and thickness) via real-time ultrasound scanning and quantify the spatial variation of these signals. Additionally, we propose future applications for both our signal characterizations and the generated muscle volume data set, including better design of assistive device sensor locations and validation of existing muscle deformation models.


Title: Multi-View 3D Entangled Forest for Semantic Segmentation and Mapping
Key Words: image fusion  image reconstruction  image segmentation  learning (artificial intelligence)  multiview frame fusion technique  perceived 3D structure  semantic labelling task  human interaction  verbal references  location related services  multiview 3D entangled forest  semantic maps  offline reconstruction  single frames  online multiview semantic segmentation  batch approach  Semantics  Three-dimensional displays  Simultaneous localization and mapping  Forestry  Labeling  Context modeling  Standards 
Abstract: Applications that provide location related services need to understand the environment in which humans live such that verbal references and human interaction are possible. We formulate this semantic labelling task as the problem of learning the semantic labels from the perceived 3D structure. In this contribution we propose a batch approach and a novel multi-view frame fusion technique to exploit multiple views for improving the semantic labelling results. The batch approach works offline and is the direct application of an existing single-view method to scene reconstructions with multiple views. The multi-view frame fusion works in an incremental fashion accumulating the single-view results, hence allowing the online multi-view semantic segmentation of single frames and the offline reconstruction of semantic maps. Our experiments show the superiority of the approaches based on our fusion scheme, which leads to a more accurate semantic labelling.


Title: Mark Yourself: Road Marking Segmentation via Weakly-Supervised Annotations from Multimodal Data
Key Words: feature extraction  image segmentation  object detection  object recognition  traffic engineering computing  unsupervised learning  video signal processing  visual databases  road marking segmentation  weakly-supervised annotations  multimodal data  weakly-supervised learning system  complex urban environments  monocular camera  expensive manual labelling  annotated images  deep semantic segmentation network  road markings  traffic situations  weather conditions  sensor modalities  lighting  qualitative performance  real-time road marking detection  labelling effort  Oxford RobotCar dataset  CamVid dataset  Roads  Laser radar  Cameras  Image segmentation  Real-time systems  Labeling  Semantics 
Abstract: This paper presents a weakly-supervised learning system for real-time road marking detection using images of complex urban environments obtained from a monocular camera. We avoid expensive manual labelling by exploiting additional sensor modalities to generate large quantities of annotated images in a weakly-supervised way, which are then used to train a deep semantic segmentation network. At run time, the road markings in the scene are detected in real time in a variety of traffic situations and under different lighting and weather conditions without relying on any preprocessing steps or predefined models. We achieve reliable qualitative performance on the Oxford RobotCar dataset, and demonstrate quantitatively on the CamVid dataset that exploiting these annotations significantly reduces the required labelling effort and improves performance.


Title: Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments
Key Words: cameras  distance measurement  feature extraction  image classification  image sensors  learning (artificial intelligence)  mobile robots  motion estimation  object detection  pose estimation  robot vision  SLAM (robots)  stereo image processing  self-supervised distractor learning  robust monocular visual odometry  self-supervised approach  distractors  camera images  cluttered urban environments  per-pixel ephemerality mask  depth map  deep convolutional network  monocular visual odometry pipeline  sparse features  dense photometric matching  metric-scale VO  single camera  robust VO methods  odometry drift  egomotion estimation  moving vehicles  urban traffic  vehicle motion  ephemerality  offline multisession mapping approaches  Three-dimensional displays  Cameras  Robustness  Visual odometry  Motion estimation  Entropy  Training data 
Abstract: We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.


Title: Planning Ergonomic Sequences of Actions in Human-Robot Interaction
Key Words: ergonomics  human-robot interaction  multi-agent systems  multi-robot systems  path planning  optimization formulation  ergonomic situations  human-robot interaction  human-robot collaboration  motion planning problem  multiagent case  human robot  Ergonomics  Task analysis  Robot kinematics  Planning  Cost function 
Abstract: In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.


Title: Playdough to Roombots: Towards a Novel Tangible User Interface for Self-reconfigurable Modular Robots
Key Words: control engineering computing  furniture  mobile robots  robot dynamics  user interfaces  self-reconfigurable modular robots  shape-shift  self-reconfigurable furniture  intuitive user interface  tangible user interface  Roombots shape  3D shape scanning  SRMR system  Shape  Three-dimensional displays  User interfaces  Solid modeling  Robots  Planning  Buildings  tangible user interface  self-reconfigurable modular robots  deformable material  shape formation 
Abstract: One of the main strengths of self-reconfigurable modular robots (SRMR) is their ability to shape-shift and dynamically change their morphology. In the case of our SRMR system “Roombots”, these shapes can be quite arbitrary for a great variety of tasks while the major utility is envisioned to be self-reconfigurable furniture. As such, the ideas and inspirations from users quickly need to be translated into the final Roombots shape. This involves a multitude of separate processes and - most importantly - requires an intuitive user interface. Our current approach led to the development of a tangible user interface (TUI) which involves 3D-scanning of a shape formed by modeling clay and the necessary steps to prepare the digitized model to be formed by Roombots. The system is able to generate a solution in less than two minutes for our target use as demonstrated with various examples.


Title: Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications
Key Words: graphics processing units  human computer interaction  mobile robots  object detection  robot vision  stereo image processing  mobile robotics  3D sensor types  indoor applications  outdoor applications  outdoor scenarios  indoor scenarios  smaller robotic systems  single CPU thread  multiple CPU cores  human interaction  robotic applications  robust person detection  robust real-time 3D person detection  Three-dimensional displays  Robot sensing systems  Feature extraction  Visualization  Pipelines  Real-time systems 
Abstract: Fast and robust person detection is one of the most important tasks for robotic applications involving human interaction. Particularly in mobile robotics this task is still challenging. Though there are already reliable and real-time capable approaches, they are usually computationally expensive. They either require GPUs or multiple CPU cores in order to work properly. Furthermore, some of the approaches are designed for special environments and sensor types, which reduces general applicability. In this work, we present a robust, generic and lightweight solution for real-time 3D person detection. Since our approach requires only a single CPU thread, it can be run as a background process and is suitable for smaller robotic systems. We demonstrate applicability to indoor and outdoor scenarios using different 3D sensor types separately. Moreover, we are able to show that the proposed method outperforms other state-of-the-art approaches, including a DCNN.


Title: Human Motion Capture Using a Drone
Key Words: calibration  cameras  image motion analysis  image reconstruction  image sensors  mobile robots  robot vision  motion capture systems  calibrated cameras  indoor environments  on-board RGB camera  autonomously flying drone  3D human MoCap  drone-based system  human motion capture  consumer drone  motion reconstruction  reconstruction algorithm  Cameras  Drones  Two dimensional displays  Three-dimensional displays  Image reconstruction  Tracking  Joints 
Abstract: Current motion capture (MoCap) systems generally require markers and multiple calibrated cameras, which can be used only in constrained environments. In this work we introduce a drone-based system for 3D human MoCap. The system only needs an autonomously flying drone with an on-board RGB camera and is usable in various indoor and outdoor environments. A reconstruction algorithm is developed to recover full-body motion from the video recorded by the drone. We argue that, besides the capability of tracking a moving subject, a flying drone also provides fast varying viewpoints, which is beneficial for motion reconstruction. We evaluate the accuracy of the proposed system using our new DroCap dataset and also demonstrate its applicability for MoCap in the wild using a consumer drone.


Title: Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling
Key Words: Bayes methods  convolution  feedforward neural nets  filtering theory  intelligent transportation systems  mobile robots  Monte Carlo methods  road traffic  time series  traffic engineering computing  unsupervised learning  complex interactions  dynamic occupancy grid prediction  urban autonomous driving  deep learning approach  long-term situation prediction  intelligent vehicles  complex downtown scenarios  multiple road users  motor vehicles  Bayesian filtering technique  environment representation  machine learning  deep convolutional neural network  spatially distributed velocity estimates  raw data sequence  input time series  multiple sensors  convolutional neural networks  road user interaction  pixel-wise balancing  static cells  dynamic cells  unsupervised learning character  pedestrians  bikes  distributed velocity estimation  Monte-Carlo simulation  Vehicle dynamics  Machine learning  Sensor fusion  Roads  Time series analysis  Laser radar 
Abstract: Long-term situation prediction plays a crucial role for intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation. Experiments show the ability to model complex interactions.


Title: Scalable Decision Making with Sensor Occlusions for Autonomous Driving
Key Words: collision avoidance  decision making  Markov processes  mobile robots  optimisation  path planning  road safety  road vehicles  road users  scalable decision making  sensor occlusions  POMDP solution techniques  optimal avoidance strategy  decomposition method  computational cost  partially observable Markov decision process  robust navigation  autonomous driving  Automobiles  Uncertainty  Roads  Acceleration  Autonomous vehicles  Approximation algorithms  Robot sensing systems 
Abstract: Autonomous driving in urban areas requires avoiding other road users with only partial observability of the environment. Observations are only partial because obstacles can occlude the field of view of the sensors. The problem of robust and efficient navigation under uncertainty can be framed as a partially observable Markov decision process (POMDP). In order to bypass the computational cost of scaling the formulation to avoiding multiple road users, this paper demonstrates a decomposition method that leverages the optimal avoidance strategy for a single user. We evaluate the performance of two POMDP solution techniques augmented with the decomposition method for scenarios involving a pedestrian crosswalk and an intersection.


Title: Real-Time Identification of Robot Payload Using a Multirate Quaternion-Based Kalman Filter and Recursive Total Least-Squares
Key Words: end effectors  industrial manipulators  Kalman filters  least squares approximations  recursive estimation  robot kinematics  least-squares process  multirate quaternion-based Kalman filter  recursive total least-squares  inertial parameters  rigid load  robot kinematics  inertial sensors  robot payload real-time identification  end-effector  industrial manipulator  Kalman filters  Quaternions  Robot kinematics  Service robots  Robot sensing systems  Estimation 
Abstract: The paper describes an estimation and identification procedure that allows to reconstruct the inertial parameters of a rigid load attached to the end-effector of an industrial manipulator. In particular, the proposed method adopts a multirate quaternion-based Kalman filter, fusing measurements obtained from robot kinematics and inertial sensors at possibly different sampling frequencies, to estimate linear accelerations and angular velocities/accelerations of the load. Then, a recursive total least-squares (RTLS) process is executed to identify the load parameters. Both steps of the estimation and identification procedure are performed in real-time, without the need for offline post-processing of measured data.


Title: Encoderless Gimbal Calibration of Dynamic Multi-Camera Clusters
Key Words: angular measurement  calibration  cameras  encoderless gimbal calibration  dynamic multiCamera Clusters  Dynamic Camera Clusters  multicamera systems  cameras  joint angle measurements  time-varying transformation  static camera  motor encoders  transformation chain  encoderless gimbal mechanism  online estimation  Cameras  Calibration  Robot vision systems  Estimation  Reluctance motors  Kinematics  Vehicle dynamics 
Abstract: Dynamic Camera Clusters (DCCs) are multi-camera systems where one or more cameras are mounted on actuated mechanisms such as a gimbal. Existing methods for DCC calibration rely on joint angle measurements to resolve the time-varying transformation between the dynamic and static camera. This information is usually provided by motor encoders, however, joint angle measurements are not always readily available on off-the-shelf mechanisms. In this paper, we present an encoderless approach for DCC calibration which simultaneously estimates the kinematic parameters of the transformation chain as well as the unknown joint angles. We also demonstrate the integration of an encoderless gimbal mechanism with a state-of-the art VIO algorithm, and show the extensions required in order to perform simultaneous online estimation of the joint angles and vehicle localization state. The proposed calibration approach is validated both in simulation and on a physical DCC composed of a 2-DOF gimbal mounted on a UAV. Finally, we show the experimental results of the calibrated mechanism integrated into the OKVIS VIO package, and demonstrate successful online joint angle estimation while maintaining localization accuracy that is comparable to a standard static multi-camera configuration.


Title: High-Precision Depth Estimation with the 3D LiDAR and Stereo Fusion
Key Words: feedforward neural nets  optical radar  radar imaging  stereo image processing  LiDAR  compact convolution module  dense stereo depth information  sparse 3D LiDAR  deep convolutional neural network architecture  stereo fusion  high-precision depth estimation  off-the-shelf stereo algorithm  Three-dimensional displays  Laser radar  Estimation  Computer architecture  Sensors  Reliability  Image color analysis 
Abstract: We present a deep convolutional neural network (CNN) architecture for high-precision depth estimation by jointly utilizing sparse 3D LiDAR and dense stereo depth information. In this network, the complementary characteristics of sparse 3D LiDAR and dense stereo depth are simultaneously encoded in a boosting manner. Tailored to the LiDAR and stereo fusion problem, the proposed network differs from previous CNNs in the incorporation of a compact convolution module, which can be deployed with the constraints of mobile devices. As training data for the LiDAR and stereo fusion is rather limited, we introduce a simple yet effective approach for reproducing the raw KITTI dataset. The raw LiDAR scans are augmented by adapting an off-the-shelf stereo algorithm and a confidence measure. We evaluate the proposed network on the KITTI benchmark and data collected by our multi-sensor acquisition system. Experiments demonstrate that the proposed network generalizes across datasets and is significantly more accurate than various baseline approaches.


Title: Recognizing Objects in-the-Wild: Where do we Stand?
Key Words: cameras  image classification  image colour analysis  image representation  learning (artificial intelligence)  mobile robots  neural nets  object recognition  robot vision  multiview object dataset  RGB-D camera  deep convolutional networks  Web images  robotic system  autonomous agents  good visual perceptual systems  robotic vision research communities  human-populated environments  robot vision  real-life robotic data  object classification  deep representations  object recognition algorithms  real-life application  mobile robot  Task analysis  Clutter  Visualization  Mobile robots  Cameras  Robot vision systems 
Abstract: The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for realworld applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance.


Title: Gemsketch: Interactive Image-Guided Geometry Extraction from Point Clouds
Key Words: feature extraction  interactive systems  solid modelling  multiple-view point clouds  cuboids  interactive system  interactive image-guided geometry extraction  gemsketch  Three-dimensional displays  Shape  Geometry  Solid modeling  Tools  Cameras  Data mining 
Abstract: We introduce an interactive system for extracting the geometries of generalized cylinders and cuboids from single-or multiple-view point clouds. Our proposed method is intuitive and only requires the object's silhouettes to be traced by the user. Leveraging the user's perceptual understanding of what an object looks like, our proposed method is capable of extracting accurate models, even in the presence of occlusion, clutter or incomplete point cloud data, while preserving the original object's details and scale. We demonstrate the merits of our proposed method through a set of experiments on a public RGB-D dataset. We extracted 16 objects from the dataset using at most two views of each object. Our extracted models represent a high degree of visual similarity to the original objects. Further, we achieved a mean normalized Hausdorff distance of 5.66% when comparing our extracted models with the dataset's ground truths.


Title: Aided Inertial Navigation with Geometric Features: Observability Analysis
Key Words: cameras  inertial navigation  Monte Carlo methods  observability  optical radar  radar imaging  radionavigation  sonar imaging  stereo image processing  Monte Carlo simulations  VINS  plane features  bearing measurements  point features  bearing sensor  vision-aided INS  generic exteroceptive range  inertial navigation systems  observability analysis  Observability  Jacobian matrices  Sensors  Position measurement  Gravity  Rotation measurement  Current measurement 
Abstract: In this paper, we perform observability analysis for inertial navigation systems (INS) aided by generic exteroceptive range and/or bearing sensors with different geometric features including points, lines and planes. While the observability of vision-aided INS (VINS, which uses camera as a bearing sensor) with point features has been extensively studied in the literature, we analytically show that the same observability property remains if using generic range and/or bearing measurements, and if global measurements are also available, as expected, some unobservable directions dismiss. We study in-depth the effects of four degenerate motions on the system observability. In particular, building upon the observability analysis of the aided INS with point features, we perform observability analysis for the same system but with line and plane features, respectively, and show that there exist 5 (and 6) unobservable directions for a single line (and plane) feature. Moreover, we, for the first time, analytically derive the unobservable directions for the cases of multiple lines/planes. We validate our analysis through Monte Carlo simulations.


Title: Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response
Key Words: approximation theory  computational complexity  greedy algorithms  mobile robots  multi-robot systems  optimisation  service robots  N task arrivals  service tasks  redeployment cost  one-stage greedy algorithm  constant-factor approximation algorithm  service cost  multiple service robots  autonomous robots  re-deployment algorithms  task response optimization  NP-hard  Robots  Task analysis  Time factors  Approximation algorithms  Probability distribution  Measurement  Vehicle dynamics 
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.


Title: Multi-Agent Time-Based Decision-Making for the Search and Action Problem
Key Words: computational complexity  control engineering computing  decision making  multi-agent systems  multi-robot systems  probability  rescue robots  search-and-rescue  task allocation  probabilistic reasoning  Gazebo-based environmenT  multiagent time-based decision-making  Mohamed Bin Zayed International Robotics Challenge  near-optimal decisions  agent action  allocated budget  time constraints  decentralized multiagent decision-making framework  computational complexity  task selection  missions present several challenges  robotic applications  action problem  Task analysis  Search problems  Decision making  Planning  Time factors  Robots  Probabilistic logic 
Abstract: Many robotic applications, such as search-and-rescue, require multiple agents to search for and perform actions on targets. However, such missions present several challenges, including cooperative exploration, task selection and allocation, time limitations, and computational complexity. To address this, we propose a decentralized multi-agent decision-making framework for the search and action problem with time constraints. The main idea is to treat time as an allocated budget in a setting where each agent action incurs a time cost and yields a certain reward. Our approach leverages probabilistic reasoning to make near-optimal decisions leading to maximized reward. We evaluate our method in the search, pick, and place scenario of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), by using a probability density map and reward prediction function to assess actions. Extensive simulations show that our algorithm outperforms benchmark strategies, and we demonstrate system integration in a Gazebo-based environment, validating the framework's readiness for field application.


Title: Multi-robot Dubins Coverage with Autonomous Surface Vehicles
Key Words: computational complexity  mobile robots  multi-robot systems  path planning  remotely operated vehicles  travelling salesman problems  multirobot Dubins coverage  aerial monitoring  single robot approaches  multirobot approaches  Dubins vehicle kinematics  environmental monitoring  multirobot team  Dubins vehicles  NP-complete problems  salesman problem-k-TSP-formulation  autonomous surface vehicles  large scale coverage operations  marine exploration  Robot sensing systems  Clustering algorithms  Task analysis  Lakes  Multi-robot systems  Kinematics 
Abstract: In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.


Title: How Many Robots are Enough: A Multi-Objective Genetic Algorithm for the Single-Objective Time-Limited Complete Coverage Problem
Key Words: computational complexity  genetic algorithms  multi-robot systems  trees (mathematics)  multiobjective genetic algorithm  multirobot complete coverage problem  task-allocation  number-fixed problem  multiobjective GA  Mofint  single-objective time-limited complete coverage problem  Robots  Vegetation  Task analysis  Genetic algorithms  Resource management  Optimization  Approximation algorithms 
Abstract: Complete coverage, which is the foundation of many robotic applications, aims to cover an area as quickly as possible. This study investigates the time-limited version of multi-robot complete coverage problem, that is, to find the least number of robots and allocate tasks properly to them such that they can finish a known mission within the time limit. This version of problem can be tackled straightforwardly based on optimizing the task-allocation to a fixed number of robots and enumerating the number. However, the number-fixed problem is NP-hard and the existing algorithm for the number-fixed problem allows intersecting tasks (possibly causing robots' interference) and endures high approximation factor. In this study, the time-limited complete coverage problem is tackled with a multi-objective approach, instead of enumerating robots' number and optimizing each number-fixed problem one by one. The multi-objective GA, Mofint, at first estimates the lower and upper bounds of the number of robots. It abstracts each task as a weighted node of a graph. Then, Mofint evolves individuals, each individual being a forest containing a certain number (within the bounds) of non-intersecting trees. Mofint can finally obtain higher precision than existing work with less time: the approximation factor for Mofint is 1.1 to 1.5 times the ideal allocation when robots' number is fixed, while for existing work is 1.5 to 2. Due to its higher precision, the least number of robots obtained in the experiments by Mofint is 0.6 times of existing work.


Title: Joint Multi-Policy Behavior Estimation and Receding-Horizon Trajectory Planning for Automated Urban Driving
Key Words: collision avoidance  Markov processes  mobile robots  multi-robot systems  path planning  road vehicles  multipolicy decision-making  traffic participants  planned trajectory  ego-vehicle  safe trajectories  multiple motion policies  receding-horizon planner  simulated multivehicle intersection scenarios  joint multipolicy behavior  automated urban driving  urban environments  autonomous vehicle  multiple motion hypothesis  joint behavior estimation  observable Markov decision processes  receding-horizon control  receding-horizon trajectory planning  Trajectory  Planning  Estimation  Space vehicles  Uncertainty  Roads  Computational modeling 
Abstract: When driving in urban environments, an autonomous vehicle must account for the interaction with other traffic participants. It must reason about their future behavior, how its actions affect their future behavior, and potentially consider multiple motion hypothesis. In this paper we introduce a method for joint behavior estimation and trajectory planning that models interaction and multi-policy decision-making. The method leverages Partially Observable Markov Decision Processes to estimate the behavior of other traffic participants given the planned trajectory for the ego-vehicle, and Receding-Horizon Control for generating safe trajectories for the ego-vehicle. To achieve safe navigation we introduce chance constraints over multiple motion policies in the receding-horizon planner. These constraints account for uncertainty over the behavior of other traffic participants. The method is capable of running in real-time and we show its performance and good scalability in simulated multi-vehicle intersection scenarios.


Title: Best Response Model Predictive Control for Agile Interactions Between Autonomous Ground Vehicles
Key Words: game theory  information theory  mobile robots  nonlinear control systems  predictive control  remotely operated vehicles  stochastic systems  best response model predictive control  AutoRally platforms  nonlinear stochastic systems  information theoretic model predictive control algorithm  iterated best response  game theoretic notion  autonomous control  autonomous ground vehicles  Games  Stochastic processes  Predictive control  Nash equilibrium  Optimization  Vehicle dynamics  Prediction algorithms 
Abstract: We introduce an algorithm for autonomous control of multiple fast ground vehicles operating in close proximity to each other. The algorithm is based on a combination of the game theoretic notion of iterated best response, and an information theoretic model predictive control algorithm designed for non-linear stochastic systems. We test the algorithm on two one-fifth scale AutoRally platforms traveling at speeds upwards of 8 meters per second, while maintaining a following distance of under two meters from bumper-to-bumper.


Title: Accelerating Model Learning with Inter-Robot Knowledge Transfer
Key Words: learning (artificial intelligence)  manipulator dynamics  multi-robot systems  robot programming  training transfer models  online learning  inverse dynamics model  model learning  inter-robot knowledge transfer  multirobot setting  trajectory tracking tasks  robot inverse dynamics model  tabula rasa learning  robot learning  Interbotix PhantomX Pincher arm  Kuka youBot arm  Adaptation models  Manipulator dynamics  Data models  Acceleration  Task analysis 
Abstract: Online learning of a robot's inverse dynamics model for trajectory tracking necessitates an interaction between the robot and its environment to collect training data. This is challenging for physical robots in the real world, especially for humanoids and manipulators due to their large and high dimensional state and action spaces, as a large amount of data must be collected over time. This can put the robot in danger when learning tabula rasa and can also be a time-intensive process especially in a multi-robot setting, where each robot is learning its model from scratch. We propose accelerating learning of the inverse dynamics model for trajectory tracking tasks in this multi-robot setting using knowledge transfer, where robots share and re-use data collected by preexisting robots, in order to speed up learning for new robots. We propose a scheme for collecting a sample of correspondences from the robots for training transfer models, and demonstrate, in simulations, the benefit of knowledge transfer in accelerating online learning of the inverse dynamics model between several robots, including between a low-cost Interbotix PhantomX Pincher arm, and a more expensive and relatively heavier Kuka youBot arm. We show that knowledge transfer can save up to 63% of training time of the youBot arm compared to learning from scratch, and about 58% for the lighter Pincher arm.


Title: Learning Coupled Forward-Inverse Models with Combined Prediction Errors
Key Words: learning (artificial intelligence)  robots  multiple solutions  inverse space  forward models  paired forward-inverse models  multiple modules  local minima  training multiple models-that  monolithic complex network  efficient alternative  multiple simple models  complex models  unstructured environments  combined prediction errors  coupled forward-inverse models  Inverse problems  Computational modeling  Data models  Predictive models  Adaptation models  Robots  Context modeling 
Abstract: Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models-that is, learning their parameters and their responsibilities-has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously. In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions.


Title: Deep Learning a Quadrotor Dynamic Model for Multi-Step Prediction
Key Words: aircraft control  autonomous aerial vehicles  control engineering computing  helicopters  learning (artificial intelligence)  mobile robots  motion control  predictive control  recurrent neural nets  robot dynamics  robot kinematics  trajectory control  quadrotor dynamic model  motion prediction  dynamic systems  long horizons  deep learning  deep recurrent neural networks  quadrotor motion model  initial system state  motor speeds  prediction horizon  recurrent neural network state initialization  quadrotor vehicle flights  indoor flight arena  hybrid network architecture  system identification methods  robust state predictions  time 2.0 s  frequency 100.0 Hz  Mathematical model  Predictive models  Vehicle dynamics  Aerodynamics  Recurrent neural networks  Training 
Abstract: We develop a multi-step motion prediction modeling method for dynamic systems over long horizons using deep learning. Building on previous work, we propose a novel hybrid network architecture, by combining deep recurrent neural networks with a quadrotor motion model created using classic system identification methods. The proposed model takes only the initial system state and motor speeds over the prediction horizon as inputs and returns robust state predictions for up to two seconds of motion at 100 Hz. We employ recurrent neural network state initialization during training, to exploit real-world dataset collected from quadrotor vehicle flights in an indoor flight arena. Our experiments demonstrate that the proposed hybrid network model consistently outperforms both black box and rigid body dynamics predictions over single and multi-step prediction scenarios, with an order of magnitude improvements in velocity estimates in particular.


Title: Data-Efficient Decentralized Visual SLAM
Key Words: cameras  data mining  graph theory  image sensors  multi-robot systems  optimisation  pose estimation  robot vision  SLAM (robots)  decentralized visual SLAM system  decentralized SLAM components  data-efficient decentralized visual SLAM  pose-graph optimization method  data association scales  robot count  data transfers  robots  map data  visual SLAM systems exchange  versatile cameras  lightweight cameras  cheap cameras  multirobot applications  mapping  Supplementary Material Data  Simultaneous localization and mapping  Visualization  Optimization  Pose estimation  Trajectory  Bandwidth 
Abstract: Decentralized visual simultaneous localization and mapping (SLAM) is a powerful tool for multi-robot applications in environments where absolute positioning is not available. Being visual, it relies on cheap, lightweight and versatile cameras, and, being decentralized, it does not rely on communication to a central entity. In this work, we integrate state-of-the-art decentralized SLAM components into a new, complete decentralized visual SLAM system. To allow for data association and optimization, existing decentralized visual SLAM systems exchange the full map data among all robots, incurring large data transfers at a complexity that scales quadratically with the robot count. In contrast, our method performs efficient data association in two stages: first, a compact full-image descriptor is deterministically sent to only one robot. Then, only if the first stage succeeded, the data required for relative pose estimation is sent, again to only one robot. Thus, data association scales linearly with the robot count and uses highly compact place representations. For optimization, a state-of-the-art decentralized pose-graph optimization method is used. It exchanges a minimum amount of data which is linear with trajectory overlap. We characterize the resulting system and identify bottlenecks in its components. The system is evaluated on publicly available datasets and we provide open access to the code. Supplementary Material Data and code are at: https://github.com/uzh-rpg/dslam_open.


Title: Automated Non-Invasive Measurement of Sperm Motility and Morphology Parameters
Key Words: biological techniques  biomedical measurement  cell motility  filtering theory  image reconstruction  image segmentation  medical image processing  probability  target tracking  motile cells  automation techniques  noninvasive measurement  adapted joint probabilistic data association filter  multisperm tracking  inherent inhomogeneous image intensity  quadratic cost function method  DIC image reconstruction  sperm motility measurement  differential interference contrast imaging method  sperm morphology measurement  image intensity  sperm subcellular structures  single sperm motility  sperm morphology parameters  illumination effect  Morphology  Switches  Head  Target tracking  Microscopy  Robots 
Abstract: Measuring the motility and morphology parameters of motile cells is important for revealing their functional characteristics. This paper presents automation techniques that, for the first time, enable automated, non-invasive measurement of motility and morphology parameters of individual sperms. Compared to the status quo of qualitative estimation of single sperm's motility and morphology based on embryologists' empirical experience, the automation techniques provide quantitative data in nearly real time. An adapted joint probabilistic data association filter (JPDAF) was used for multi-sperm tracking and tackled challenges of identifying sperms that intersect or have small spatial distances. Since the standard differential interference contrast (DIC) imaging method has side illumination effect which causes inherent inhomogeneous image intensity and poses difficulties for accurate sperm morphology measurement, we integrated total variation norm into the quadratic cost function method, which together effectively removed inhomogeneous image intensity and retained sperm's subcellular structures after DIC image reconstruction. In order to relocate the same sperm of interest identified under low magnification after switching to high magnification, coordinate transformation was conducted to handle the changes in the field of view caused by magnification switch. Experimental results demonstrated an accuracy of 95.6% in sperm motility measurement and errors <;10% in morphology measurement.


Title: Construction of Hepatic Lobule-Like Vascular Network by Using Magnetic Fields
Key Words: biomagnetism  biomedical materials  blood vessels  cellular biophysics  ferrites  gels  liver  molecular biophysics  proteins  tissue engineering  cell viability  multilayered structure  different magnetic poles  magnetic tweezer  magnetizer  alginate gel fibers  magnetic fibers  kinds veins  portal vein  central vein  3D cellular structure  transporting required nutrients  magnetic fields  vascular network  hepatic lobule-like  temperature 22.0 degC  time 3.0 d  Steel  Optical fiber networks  Veins  Magnetic flux  Three-dimensional displays  Electromagnetics  Toroidal magnetic fields 
Abstract: Fabrication of vascular network is an important research for transporting required nutrients and oxygen to the artificial tissues. In this paper, we propose a novel method to construct a hepatic lobule-like vascular network in a 3D cellular structure. The network is simply constructed by three types of veins, central vein, portal vein, and sinusoids. To realize these kinds veins, we utilize two different sizes of steel rods and magnetic fibers for delivering nutrients in 3D cellular structure. Alginate gel fibers embedding ferrite particles are prepared as the same length and are magnetized by magnetizer at 3T. A magnetic tweezer with seven poles is proposed to generate sufficient forces that can manipulate magnetized fibers. Here, two types of rods are magnetized to different magnetic poles in order to attract opposite the end of fibers. This manipulation process is performed in fibrinogen and thrombin solution with liver cells (RLC-18). After solidification of the solution, we deposit solutions with cells and fibers repeatedly, and therefore, a multi-layered structure can be constructed. In addition, we investigate cell a viability in fibrin gel according to the depth of the gel. The result is that the deeper the depth of the gel is, the lower the cell viability is. The cell viability is conducted in several condition. As a result, at the low temperature (here at 22 °C), the viability of cell is increased.


Title: SAT-C: An Efficient Control Strategy for Assembly of Heterogeneous Stress-Engineered MEMS Microrobots
Key Words: controllability  microrobots  mobile robots  motion control  multi-robot systems  position control  control primitives  control pulses  microrobotic systems  control policy  planar assembly  efficient control strategy  heterogeneous stress-engineered MEMS microrobots  efficient control framework  controllable microrobots  theoretical control strategy  multiple-shapes microassembly  arbitrary initial configuration  power delivery waveform  nonholonomic unicycles  multiple macroscale robots  direct drive wheels  Robots  Hysteresis  Microassembly  Micromechanical devices  Voltage control  Bandwidth  Actuators 
Abstract: We present a new efficient control framework for controlling groups of heterogeneous stress-engineered MEMS microrobots for accomplishing micro-assembly. The objective is to maximize the number of controllable microrobots in the system while keeping the number of external global signals as low as possible. This work proposes a theoretical control strategy that could complete multiple-shapes microassembly from arbitrary initial configuration where all the control primitives can be accompanied with a constant number (O(1)) of control pulses of the power delivery waveform. We focus on microrobotic systems that can be modeled as nonholonomic unicycles. We validate the control policy with hardware experiments for implementing planar assembly using multiple macroscale robots with direct drive wheels. These results lay the foundation for developing new methods to control of a large number of MEMS microrobots.


Title: Robotic Intracellular Manipulation: 3D Navigation and Measurement Inside a Single Cell
Key Words: biomagnetism  biomechanics  bioMEMS  Brownian motion  cancer  cellular biophysics  force control  medical robotics  micromanipulators  optical microscopy  patient treatment  position control  predictive control  magnetic bead  cell nucleus minor axes  cell nucleus major axes  stiffness polarity  sub-micrometer object  tissue level  untethered technique  3D navigation  robotic intracellular manipulation  force-displacement data  Brownian motion-imposed constraint  high-resolution confocal microscopy  slow visual feedback  generalized predictive controller  single human bladder cancer cell  piconewton force control  sub-micrometer position control  magnetic micromanipulation task  size 0.7 mum  frequency 1.0 Hz  distance 0.43 mum  Magnetic resonance imaging  Magnetic levitation  Force  Magnetic noise  Magnetic shielding  Magnetic devices  Magnetic separation 
Abstract: Magnetic micromanipulation is an untethered technique and has enabled numerous applications in the scale of millimeters to micrometers from the tissue level to cell level. However, existing systems are not capable of maneuvering a sub-micrometer object for precise force control, preventing the realization of intracellular manipulation or `fantastic voyage' inside a single cell. The magnetic micromanipulation task achieved in this work is sub-micrometer position control and piconewton force control of a sub-micron (0.7 μm) magnetic bead inside a single human bladder cancer cell (RT4). The magnetic bead was 3D positioned in the cell using a generalized predictive controller that effectively tackled the control challenge caused by the slow visual feedback (1 Hz) from high-resolution confocal microscopy. The average positioning error was quantified to be 0.43 μm, which is slightly larger than Brownian motion-imposed constraint (0.31 μm). The system is capable of three-dimensionally applying a maximum force of 60 pN with a resolution of 4 pN. In experiments, a 0.7 μm magnetic bead was controlled to move from an initial position in a cell to target positions on the cell nucleus. Force-displacement data were obtained from multiple locations along the cell nucleus' major and minor axes. The results revealed, for the first time, significantly higher stiffness exists in the cell nucleus' major axis than the minor axis. This stiffness polarity was likely attributed to the aligned stress fibers of actin filament inside the cells.


Title: ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition
Key Words: covariance analysis  feature extraction  image recognition  image texture  neural nets  touch (physiological)  tactile data  cloth textures  good recognition performance  perception performance  tactile sensing  shared representation space  feature sharing  cloth texture recognition  multimodal sensing ability  tactile images  Deep Maximum Covariance Analysis  learned features  DMCA framework  unimodal data  joint latent space  Gelsight sensor  deep neural networks  sensing modalities  Visualization  Tactile sensors  Cameras  Task analysis  Surface topography 
Abstract: Vision and touch are two of the important sensing modalities for humans and they offer complementary information for sensing the environment. Robots could also benefit from such multi-modal sensing ability. In this paper, addressing for the first time (to the best of our knowledge) texture recognition from tactile images and vision, we propose a new fusion method named Deep Maximum Covariance Analysis (DMCA) to learn a joint latent space for sharing features through vision and tactile sensing. The features of camera images and tactile data acquired from a GelSight sensor are learned by deep neural networks. But the learned features are of a high dimensionality and are redundant due to the differences between the two sensing modalities, which deteriorates the perception performance. To address this, the learned features are paired using maximum covariance analysis. Results of the algorithm on a newly collected dataset of paired visual and tactile data relating to cloth textures show that a good recognition performance of greater than 90% can be achieved by using the proposed DMCA framework. In addition, we find that the perception performance of either vision or tactile sensing can be improved by employing the shared representation space, compared to learning from unimodal data.


Title: Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals
Key Words: dexterous manipulators  graph theory  learning (artificial intelligence)  mobile robots  tactile sensors  erroneous contact states  manipulation demonstrations  motor primitive  manipulation task  insertion tasks  learned manipulation graphs  robust manipulation executions  sensory goals  multimodal sensory signals  complex contact manipulation tasks  contact state  contact state information  Barrett arm  BioTacs  contact changes  Robot sensing systems  Task analysis  Fasteners  Trajectory  Motion segmentation  Vibrations 
Abstract: Complex contact manipulation tasks can be decomposed into sequences of motor primitives. Individual primitives often end with a distinct contact state, such as inserting a screwdriver tip into a screw head or loosening it through twisting. To achieve robust execution, the robot should be able to verify that the primitive's goal has been reached as well as disambiguate it from erroneous contact states. In this paper, we introduce and evaluate a framework to autonomously construct manipulation graphs from manipulation demonstrations. Our manipulation graphs include sequences of motor primitives for performing a manipulation task as well as corresponding contact state information. The sensory models for the contact states allow the robot to verify the goal of each motor primitive as well as detect erroneous contact changes. The proposed framework was experimentally evaluated on grasping, unscrewing, and insertion tasks on a Barrett arm and hand equipped with two BioTacs. The results of our experiments indicate that the learned manipulation graphs achieve more robust manipulation executions by confirming sensory goals as well as discovering and detecting novel failure modes.


Title: Autonomous Multi-Joint Soft Exosuit for Assistance with Walking Overground
Key Words: actuators  biomechanics  force control  gait analysis  medical robotics  motion control  autonomous multijoint soft exosuit  human locomotion  assistive torques  gait assistance  overground walking  soft exosuit assists  ankle plantarflexion  hip flexion  hip extension  mobile actuation system  high assistive forces  force profiles  walking cycle  control adaptation method  force consistency  peak force  target force  country-course walking  RMS error  human energy economy  Legged locomotion  Hip  Belts  Force  Actuators  Thigh 
Abstract: Soft exosuits are a new approach for assisting with human locomotion, which applies assistive torques to the wearer through functional apparel. In this paper, we present a new version of autonomous multi-joint soft exosuit for gait assistance, particularly designed for overground walking. The soft exosuit assists with ankle plantarflexion, hip flexion, and hip extension, equally distributing the forces between ankle plantarflexion and hip flexion. A mobile actuation system was developed to generate high assistive forces, and Bowden cables are used to transmit the forces to the exosuit. A sensor harness connects two load cells and three IMU s per leg that are used to measure real-time data for a controller that commands desired force profiles as a function of the walking cycle. In addition, a control adaptation method was developed which adjusts control parameters while walking on irregular surfaces. In preliminary studies, the proposed method substantially improved the force consistency while walking over uneven terrain. Specifically, the number of steps where the peak force deviated from the target force decreased from 100 to 57 out of 250 steps, and RMS error on the peak force decreased from 90.0 N to 76.6 N with respect to 300 N target force. Also, a two-subject case study on country-course walking demonstrated the potential of this soft exosuit to improve human energy economy while walking overground.


Title: Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging
Key Words: expectation-maximisation algorithm  graph theory  mobile robots  multi-robot systems  optimisation  robot vision  SLAM (robots)  PCM  robust multirobot map  robust selection  robust SLAM methods  multirobot case  simultaneous localization and mapping  pairwise consistency set maximization  pairwise consistent measurement set maximization  odometry backbone  Simultaneous localization and mapping  Robot kinematics  Phase change materials  Trajectory  Robustness  Merging 
Abstract: This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an “odometry backbone” to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.


Title: Task-Specific Sensor Planning for Robotic Assembly Tasks
Key Words: feedback  multi-robot systems  open loop systems  path planning  robotic assembly  sensors  task-specific sensor planning  robotic assembly tasks  sensory feedback  task planning  open-loop simulation  task-specific uncertainty approximants  multirobot planner  multirobot tasks  Robot sensing systems  Task analysis  Uncertainty  Planning  Robotic assembly  Estimation 
Abstract: When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.


Title: Active Motion-Based Communication for Robots with Monocular Vision
Key Words: Bayes methods  decoding  estimation theory  image classification  Kalman filters  Monte Carlo methods  robot vision  online Bayesian estimation algorithm  monocular camera  receiver robot  sending robot  active motion-based communication  accurate trajectory classification  trajectory class distribution  active vision-based control policy  message decoding  trajectory identification  monocular vision model  receiving robot  Trajectory  Receivers  Cameras  Robot vision systems  Bayes methods  Estimation 
Abstract: In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.


Title: Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy
Key Words: control nonlinearities  mobile robots  observers  robot kinematics  robust control  steering systems  wheels  robust multi-model off-road steering strategy  path tracking algorithms  backstepping control strategy  two-wheel steering mobile robot  control law  dynamic models  kinematic models  observer  Mobile robots  Kinematics  Mathematical model  Trajectory  Observers  Dynamics 
Abstract: In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.


Title: Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller
Key Words: humanoid robots  mobile robots  motion control  multi-robot systems  optimal control  quadratic programming  human-humanoid collaborative tasks  multirobot quadratic program controller  human dynamics reconstruction  optimal robot controls  interaction motions  interaction forces  humanoid controller  co-manipulation tasks  robot platform simulation  optimization problem  Task analysis  Dynamics  Robot sensing systems  Mathematical model  Optimization  Humanoid robots 
Abstract: Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.


Title: Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments
Key Words: end effectors  humanoid robots  manipulators  mobile robots  motion control  stability  end-effectors  multicontact contact pose sequence planning  humanoid robot ARMAR-4  loco-manipulation tasks  contacts  loco-manipulation affordances  vision-based detection  whole-body multicontact tasks  motion planning  multicontact pose sequences  goal-directed planning  end-effector contact opportunities  autonomous detection  whole-body loco-manipulation actions  autonomous planning  humanoid robotics  humanoid robots  whole-body pose sequence planning  affordance-based multicontact  Planning  Humanoid robots  Task analysis  Motion segmentation  Robot sensing systems  Complexity theory 
Abstract: Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.


Title: Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement
Key Words: biomechanics  force measurement  force sensors  humanoid robots  humanoid robot  torque measurement  external forces  direct force measurements  regular force sensors  model-based estimator  floating-base kinematics  filtered measurement  contact force  additional estimation external force  model-based external force-moment estimation  Dynamics  Robot sensing systems  Kinematics  Force  Mathematical model 
Abstract: The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.


Title: Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation
Key Words: manipulators  multi-robot systems  path planning  physics reasoning  robot manipulation  manipulation planning  human-robot cooperation  multi-robot cooperation  Planning  Cognition  Estimation  Force  Robot sensing systems 
Abstract: For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as “physics reasoning”) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.


Title: Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks
Key Words: control engineering computing  evolutionary computation  gradient methods  humanoid robots  learning (artificial intelligence)  manipulator kinematics  motion control  operating systems (computers)  particle swarm optimisation  public domain software  robot programming  trees (mathematics)  full-body motion generation  open-source software package  inverse kinematics  arbitrary kinematic trees  evolutionary optimization  particle swarm optimization  cost functions  multigoal manipulation tasks  serial kinematic chains  dual-arm manipulation  multifinger hands  memetic algorithm  full-body motion specification  ROS  MoveIt!  Kinematics  Task analysis  Cost function  Robot kinematics  End effectors  Quaternions 
Abstract: While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.


Title: Bayesian Viewpoint-Dependent Robust Classification Under Model and Localization Uncertainty
Key Words: Bayes methods  image classification  pattern classification  Bayesian viewpoint-dependent robust classification  localization uncertainty  robust visual classification  black-box Bayesian classifier  localization error  spatial correlation  Uncertainty  Measurement uncertainty  Robots  Correlation  Bayes methods  Robustness  Training data 
Abstract: We propose an algorithm for robust visual classification of an object of interest observed from multiple views using a black-box Bayesian classifier which provides a measure of uncertainty, in the presence of significant ambiguity and classifier noise, and of localization error. The fusion of classifier outputs takes into account viewpoint dependency and spatial correlation among observations, as well as pose uncertainty when these observations are taken and a measure of confidence provided by the classifier itself. Our experiments confirm an improvement in robustness over state-of-the-art.


Title: Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes
Key Words: image colour analysis  image fusion  image reconstruction  image representation  image segmentation  learning (artificial intelligence)  neural net architecture  object detection  object tracking  pose estimation  robot vision  video cameras  video signal processing  reconstruction techniques  ground truth label generation  labeled object instances  object pose  video scene collection  annotation pipeline  DNN architecture  RGBD image  object meshes  human assisted ICP-fitting  3D dense reconstruction  RGBD camera  pixelwise labels  specific robotic manipulation task  training data  DNN pipelines  object segmentation  deep neural network architectures  cluttered scenes  real RGBD data  label fusion  Pipelines  Three-dimensional displays  Robot sensing systems  Image segmentation  Cameras  Image reconstruction 
Abstract: Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.


Title: Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration
Key Words: cognition  control engineering computing  groupware  human computer interaction  human-robot interaction  medical computing  medical robotics  neural nets  surgery  team working  user interfaces  early prediction capability  turn-taking actions  early turn-taking prediction  Spiking Neural networks  human robot collaboration  human teamwork  Cognitive Turn-taking Model  turn-taking prediction algorithms  CTTM  robotic scrub nurse  human turn-taking intentions  multimodal human communication cues  Neurons  Robot kinematics  Task analysis  Training  Teamwork 
Abstract: Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.


Title: A Tensegrity-Inspired Compliant 3-DOF Compliant Joint
Key Words: actuators  design engineering  geometry  mechatronics  motion control  optimisation  position control  robot dynamics  velocity control  tensegrity-inspired compliant three degree-of-freedom robotic joint  continuously soft materials  embedded sensing  position information  velocity information  geometry selection  optimization  theoretical configuration space  mechatronic design solutions  hardware prototype  low order dynamic systems  soft robotic systems  robotic limb  omnidirectional compliance  Tensegrity-Inspired Compliant 3-DOF Compliant joint  Robot kinematics  Robot sensing systems  Geometry  Force  Topology 
Abstract: Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.


Title: SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control
Key Words: cameras  closed loop systems  control engineering computing  gradient methods  image colour analysis  image segmentation  industrial robots  learning (artificial intelligence)  minimisation  neural nets  pose estimation  robot dynamics  robot vision  SE3-pose-Nets  deep visuomotor control  SE3-Nets  encoder-decoder structure  pose embedding  point-wise data associations  closed-loop control  scene dynamics  structred deep dynamics models  pose error minimization  gradient-based methods  Baxter robot  Three-dimensional displays  Predictive models  Transforms  Computational modeling  Data models  Aerospace electronics  Training 
Abstract: In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.


Title: Fast Object Learning and Dual-arm Coordination for Cluttered Stowing, Picking, and Packing
Key Words: grippers  humanoid robots  human-robot interaction  industrial manipulators  learning (artificial intelligence)  mobile robots  multi-robot systems  object detection  path planning  robot vision  service robots  robotic picking  cluttered bins  2017 Amazon Robotics Challenge  ARC  storage system  deep object perception pipeline  custom turntable capture system  transfer learning  robot arms  NimbRo Picking  stow-and-pick task  Task analysis  Training  Robot kinematics  Pipelines  Robot sensing systems  Semantics 
Abstract: Robotic picking from cluttered bins is a demanding task, for which Amazon Robotics holds challenges. The 2017 Amazon Robotics Challenge (ARC) required stowing items into a storage system, picking specific items, and packing them into boxes. In this paper, we describe the entry of team NimbRo Picking. Our deep object perception pipeline can be quickly and efficiently adapted to new items using a custom turntable capture system and transfer learning. It produces high-quality item segments, on which grasp poses are found. A planning component coordinates manipulation actions between two robot arms, minimizing execution time. The system has been demonstrated successfully at ARC, where our team reached second places in both the picking task and the final stow-and-pick task. We also evaluate individual components.


Title: Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
Key Words: decision making  human-robot interaction  intelligent transportation systems  learning (artificial intelligence)  probability  highway on-ramp-off-ramps  human-robot interaction policies  multimodal probabilistic model-based planning  traffic weaving scenario  human-in-the-loop simulation  candidate future robot actions  interaction history  action distributions  direct learning  candidate robot action sequences  human responses  massively parallel sampling  real-time robot policy construction  human-human exemplars  future human actions  multimodal probability distributions  inherent multimodal uncertainty  experienced drivers  entering exiting cars  decision making  Robots  Vehicles  Predictive models  History  Cognition  Probabilistic logic  Weaving 
Abstract: This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.


Title: A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  biomimetics  control system synthesis  elastomers  electroactive polymer actuators  force control  mobile robots  motion control  remotely operated vehicles  velocity control  thrust force  actuation layers  fin-like dielectric elastomer actuator  DEA design  fish fins undulatory motions  tunable DEAs  soft actuators  autonomous planar swimming  actuator designs  swimming speed  vertical swimming  underwater operation  elastomers  autonomous mobility  AUV  miniature autonomous underwater vehicle  modular dielectric elastomer actuator  Aquatic robots  Power supplies  Propulsion  Dielectric elastomer actuators 
Abstract: In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.


Title: Visual Grasping for a Lightweight Aerial Manipulator Based on NSGA-II and Kinematic Compensation
Key Words: autonomous aerial vehicles  calibration  collision avoidance  compensation  genetic algorithms  manipulator dynamics  manipulator kinematics  visual grasping  lightweight aerial manipulator  complex kinematics/dynamics  motion constraints  X8 coaxial octocopter  4-DoF manipulator  grasping control problem  NSGA-II method  trajectory planning  kinematic compensation-based visual trajectory tracking  trajectory generation  dynamic parameter calibration  Manipulator dynamics  Trajectory  Grasping  Kinematics  Acceleration  Visualization 
Abstract: The grasping control of an aerial manipulator in practical environments is challenging due to its complex kinematics/dynamics and motion constraints. This paper introduces a lightweight aerial manipulator, which is combined with an X8 coaxial octocopter and a 4-DoF manipulator. To address the grasping control problem, we develop an efficient scheme containing trajectory generation, visual trajectory tracking, and kinematic compensation. The NSGA-II method is utilized to implement the multiobjective optimization for trajectory planning. Motion constraints and collision avoidance are also considered in the optimization. A kinematic compensation-based visual trajectory tracking is introduced to address the coupled nature between manipulator and VAV body. No dynamic parameter calibration is needed. Finally, several experiments are performed to verify the stability and feasibility of the proposed approach.


Title: Track, Then Decide: Category-Agnostic Vision-Based Multi-Object Tracking
Key Words: computer vision  image colour analysis  image recognition  image segmentation  object detection  object tracking  object category  tracking-by-detection methods  segmentation mask-based tracker  pixel-precise masks  category-agnostic vision-based multiobject tracking  generic object proposals  class-agnostic multiobject tracking  Proposals  Three-dimensional displays  Tracking  Laser radar  Semantics  Detectors  Two dimensional displays 
Abstract: The most common paradigm for vision-based multi-object tracking is tracking-by-detection, due to the availability of reliable detectors for several important object categories such as cars and pedestrians. However, future mobile systems will need a capability to cope with rich human-made environments, in which obtaining detectors for every possible object category would be infeasible. In this paper, we address the problem of class-agnostic multi-object tracking using generic object proposals. We present an efficient segmentation mask-based tracker which associates pixel-precise masks reported by the segmentation. Our approach can utilize semantic information whenever it is available for classifying objects at the track level, while retaining the capability to track generic unknown objects in the absence of such information. We demonstrate experimentally that our approach achieves performance comparable to state-of-the-art tracking-by-detection methods for popular object categories such as cars and pedestrians. Additionally, we show that the proposed method can discover and robustly track a large variety of other objects.


Title: Vision-Based Global Localization Using Ceiling Space Density
Key Words: cameras  mobile robots  robot vision  service robots  home environments  free space density  available blueprint information  ceiling vision  robust localization information  robotic vacuum  superior localization results  vision-based global localization  ceiling space density  service robots  homes  self-localize  man-made constructions  documented blueprint  robot localization  smart home applications  movable objects  complicated task  horizontal range-finders  effective global localization approach  Cameras  Kernel  Three-dimensional displays  Robot vision systems  Simultaneous localization and mapping 
Abstract: Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.


Title: Beyond Pixels: Leveraging Geometry and Shape Cues for Online Multi-Object Tracking
Key Words: cameras  image motion analysis  object detection  object tracking  optimisation  pose estimation  data association method  tracking-by-detection framework  object detectors  object motions  online multiobject tracking  object shape  monocular camera  object pose  object motion  Three-dimensional displays  Shape  Target tracking  Roads  Trajectory  Cameras 
Abstract: This paper introduces geometry and object shape and pose costs for multi-object tracking in urban driving scenarios. Using images from a monocular camera alone, we devise pairwise costs for object tracks, based on several 3D cues such as object pose, shape, and motion. The proposed costs are agnostic to the data association method and can be incorporated into any optimization framework to output the pairwise data associations. These costs are easy to implement, can be computed in real-time, and complement each other to account for possible errors in a tracking-by-detection framework. We perform an extensive analysis of the designed costs and empirically demonstrate consistent improvement over the state-of-the-art under varying conditions that employ a range of object detectors, exhibit a variety in camera and object motions, and, more importantly, are not reliant on the choice of the association framework. We also show that, by using the simplest of associations frameworks (two-frame Hungarian assignment), we surpass the state-of-the-art in multi-object-tracking on road scenes. More qualitative and quantitative results can be found at https://junaidcs032.github.io/Geometry_ObjectShape_MOT/.


Title: Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
Key Words: feature extraction  image segmentation  learning (artificial intelligence)  manipulators  neural nets  robot vision  multitask domain adaptation  deep learning  successful grasping probability  transfer learning framework  domain-adversarial loss  candidate motor command  specified target object  instance segmentation mask  monocular RGB images  neural network  cluttered scenes  instance grasping  robotic manipulation  Grasping  Robots  Adaptation models  Data models  Feature extraction  Image segmentation  Neural networks 
Abstract: Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.


Title: Robot Assisted Carpentry for Mass Customization
Key Words: design engineering  furniture  mass production  mobile robots  product customisation  production engineering computing  mass customization  laymen editable templates  CNC fabrication  template based system  robotic fabrication system  mobile robots  standard carpentry tools  end-to-end design  template design  laymen users  robotics system  design tools  robot assisted carpentered items  Fabrication  Robots  Solid modeling  Tools  Standards  Face  Connectors 
Abstract: Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.


Title: Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms
Key Words: magnetic fields  medical robotics  microfluidics  microrobots  motion control  microscale devices  microrobotic devices  independent motions  magnetic elements  independent actuation  homogeneous magnetic field input  magnetic field signals  field generation source  magnetic microrobots  complex mechanism motions  multiagent mechanism motions  stationary devices  mobile devices  microfactories  microfluidic tools  medical procedures  remote applications  millimeter-scale robotic devices  magnetic mechanisms  degrees-of-freedom remote actuation  size 500.0 mum  size 0.6 mm  Magnetic resonance imaging  Magnetic devices  Magnetic moments  Torque  Mathematical model  Force  Wireless communication 
Abstract: Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 μm magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.


Title: SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
Key Words: augmented reality  autonomous aerial vehicles  mobile computing  mobile robots  navigation  robot vision  SLAM (robots)  visual SLAM  augmented reality systems  nonfunctional requirements  mobile phone-based AR application  tight energy budget  UAV navigation system  SLAMBench2  benchmarking framework  open source  close source  performance metrics  ORB-SLAM2  publicly-available software framework  SLAM applications  SLAM systems  SLAM algorithms  multiobjective head-to-head benchmarking  functional requirements  Simultaneous localization and mapping  Measurement  Trajectory  Benchmark testing  User interfaces  C++ languages 
Abstract: SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.


Title: The Dynamic Bearing Observability Matrix Nonlinear Observability and Estimation for Multi-Agent Systems
Key Words: geometry  group theory  Kalman filters  Lie groups  matrix algebra  multi-agent systems  multi-robot systems  nonlinear filters  multiagent formations  dynamic agents  algebraic properties  first-order derivatives  nonlinear observability theory  higher order derivatives  localization problem  dynamic bearing observability matrix nonlinear observability  multiagent systems  rigidity matrix  Observability  Robot sensing systems  Geometry  Manifolds  Cameras  Estimation 
Abstract: We consider the problem of localization in multiagent formations with bearing only measurements, and analyze the fundamental observability properties for dynamic agents. The current well-established approach is based on the socalled rigidity matrix, and its algebraic properties (e.g., its rank and nullspace). This method is typically motivated using first-order derivatives, and shows, among other facts, that the global scale of the formation is not observable. This work shows that current results represent an incomplete view of the problem. In particular, we show that 1) current methods are a particular instantiation of nonlinear observability theory, 2) we can introduce the concept of the dynamic bearing observability matrix from higher order derivatives to study the observability of dynamic formations, and 3) the global scale is, in fact, generally observable when the agents move according to known inputs. We use tools from Riemannian geometry and Lie group theory to tackle, in a general and principled way, the general formulation of the localization problem with states that include both rotations and translations. Finally, we verify our theoretical results by deriving and applying, in both simulations and real experiments on UAVs, a centralized Extended Kalman Filter on Lie groups that is able to estimate the global scale of a moving formation.


Title: Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing
Key Words: approximation theory  Monte Carlo methods  multi-robot systems  normal distribution  optimisation  probability  independent normally distributed random events  conditional probability distributions  multirobot task allocation problems  deterministic method  optimisation method  travel times  task durations  approximation methods  resource contention modelling  Robots  Task analysis  Uncertainty  Probability distribution  Random variables  Resource management 
Abstract: This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.


Title: Constrained-Action POMDPs for Multi-Agent Intelligent Knowledge Distribution
Key Words: decision theory  intelligent control  Markov processes  Monte Carlo methods  multi-agent systems  multi-robot systems  optimal control  optimisation  multiagent intelligent knowledge distribution  infinite-horizon policy  minimal constraint guarantees  constraint analysis  information content  Markov chain Monte Carlo analysis  probabilistic constraint satisfaction  partially observable Markov decision processes  action-based constraints  multiagent coordination  multiagent systems  communication requirements  constrained-action POMDPs  Markov processes  Collaboration  Monte Carlo methods  Bandwidth  Proposals  Entropy  Power capacitors 
Abstract: This paper addresses a fundamental question of multi-agent knowledge distribution: what information should be sent to whom and when, with the limited resources available to each agent? Intelligent Knowledge Distribution is a framework that answers these questions. Communication requirements for multi-agent systems can be rather high when an accurate picture of the environment and the state of other agents must be maintained. To reduce the impact of multi-agent coordination on systems, including communications, this paper introduces the concept of action-based constraints on partially observable Markov decision processes, rewards based upon the value of information driven by Kullback-Leibler Divergence, and probabilistic constraint satisfaction through discrete optimization and Markov chain Monte Carlo analysis. Intelligent Knowledge Distribution is driven by determining the information content an agent believes another agent will obtain by receiving certain information, along with the importance or relevance of that information to the system objective. To perform constraint analysis on an infinite-horizon policy, policies are represented as a Finite State Controller allowing Markov chain Monte Carlo analysis to determine a probabilistic level of guarantee that the constraints will be satisfied. The analysis of performance for an example mission presented in this paper shows the constrained controllers, during the highest constraint seen in simulations, can be constructed to meet minimal constraint guarantees (80%) while impacting the optimal value less than 50%, where the unconstrained optimal controller only satisfied the constraint 10% of the time.


Title: Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
Key Words: mobile robots  multi-robot systems  path planning  probability  potential contingency task  multirobot mission planning  expected mission completion time  probability  Task analysis  Robot kinematics  Uncertainty  Schedules  Marine vehicles  Resource management 
Abstract: In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.


Title: Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking
Key Words: computational complexity  distributed control  multi-robot systems  target tracking  O(hlog1/ε) communication rounds  distributed simultaneous action  multirobot multitarget tracking  multirobot assignment problems  Robot sensing systems  Target tracking  Approximation algorithms  Partitioning algorithms 
Abstract: We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/ε) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.


Title: How to Make Fat Autonomous Robots See all Others Fast?
Key Words: collision avoidance  computational complexity  deterministic algorithms  distributed algorithms  mobile robots  multi-robot systems  scheduling  fat autonomous robots  coordination problems  autonomous mobile robots  distributed robotics community  convex hull  nontransparent fat robots  deterministic distributed algorithm  semisynchronous scheduler  Robot kinematics  Fats  Cogeneration  Collision avoidance  Runtime  Computational modeling 
Abstract: The coordination problems arising in a team of autonomous mobile robots have received a lot of attention in the distributed robotics community. Along those lines, we study in this paper the problem of coordinating autonomous mobile robots to reposition on a convex hull so that each robot sees all others. In particular, we consider non-transparent fat robots operating in the 2-dimensional plane. They are abstracted as unit discs and they make local decisions with vision being the only mean of coordination among them. We develop a (deterministic) distributed algorithm that solves the problem for a team of N ≥ 3 fat robots in O(N) time avoiding collisions under the semi-synchronous scheduler. The main idea is to enforce the robots to reach a configuration in which (i) the robots' centers form a convex hull; (ii) all robots are on the convex hull's boundary; and (iii) each robot can see all other robots. The result is achieved assuming some reasonable conditions on the input configuration and showing that starting from any input configuration that satisfies our conditions, robots reach such a configuration in linear time and terminate.


Title: A Synchronization Scheme for Position Control of Multiple Rope-Climbing Robots
Key Words: actuators  asymptotic stability  manipulators  mobile robots  multi-robot systems  position control  robot dynamics  singularly perturbed systems  single rope-climbing robot  multiple rope-climbing robots  position control  Robot kinematics  Synchronization  Task analysis  Actuators  Mathematical model  Position control  multiple Rope-Climbing Robots  climbing robots  motion control 
Abstract: The ability of rope-climbing robots in aloft operation is limited by its self-supporting and locomotion ability. In many applications, a given task is also too complex to be achieved by a single rope-climbing robot acting alone. The solution of multiple rope-climbing robots can overcome the limitations. However, existing control methods for rope-climbing robots are limited to single robot, and the open issue of coordination between multiple rope-climbing robots has not been systematically addressed. This paper presents a new synchronization scheme for position control of multiple rope-climbing robots, such that each robot moves to the corresponding desired position while synchronizing the heights between each other. Maintaining the same height is very important to guarantee the stability of the task-oriented manipulator installed among multiple robots, when it is performing the manipulation task. The development of the proposed controller is based on the singular perturbation approach, by treating the fast actuator dynamics as a perturbation of the slow robot dynamics, such that the lowest control complexity is achieved. The exponential stability of the overall system that consists of the fast and slow subsystems is proved by using Tikhonov' s theorem. Experimental results are presented to illustrate the performance of the proposed controller.


Title: Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching
Key Words: grippers  image classification  image matching  object recognition  robot vision  robotic pick-and-place  image classification framework  2017 Amazon Robotics Challenge  MIT-Princeton Team system  category-agnostic affordance prediction algorithm  cross-domain image matching  Grasping  Robots  Clutter  Grippers  Robustness  Proposals  Task analysis 
Abstract: This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select and execute among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu.


Title: Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration
Key Words: learning (artificial intelligence)  manipulators  recurrent neural nets  robot vision  nonprehensile manipulation  recurrent neural network  raw images  VAE-GAN-based reconstruction  autoregressive multimodal action prediction  complex manipulation tasks  towel  weight  reconstruction-based regularization  vision-based multitask manipulation  end-to-end learning  multitask learning  low-cost robotic arm  robot arm trajectories  complex picking and placing tasks  Task analysis  Robots  Feature extraction  Neural networks  Image reconstruction  Training  Visualization 
Abstract: We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.


Title: Distributed Learning for the Decentralized Control of Articulated Mobile Robots
Key Words: decentralised control  distributed control  learning systems  mobile robots  multi-agent systems  highly cluttered evaluation environments  decentralized control architectures  central pattern generators  spatially distributed portions  articulated bodies  system-level objectives  reinforcement learning  independent agents  parallel environments  meta-level agent  homogeneous decentralized control  articulated locomotion  distributed learning  asynchronous advantage actor-critic algorithm  A3C  decentralized control policies  independently controlled portion  autonomous decentralized compliant control framework  compliant control baseline  articulated mobile robots  Shape  Decentralized control  Aerospace electronics  Robot kinematics  Admittance  Hardware 
Abstract: Decentralized control architectures, such as those conventionally defined by central pattern generators, independently coordinate spatially distributed portions of articulated bodies to achieve system-level objectives. State of the art distributed algorithms for reinforcement learning employ a different but conceptually related idea; independent agents simultaneously coordinating their own behaviors in parallel environments while asynchronously updating the policy of a system-or, rather, meta-level agent. This work, to the best of the authors' knowledge, is the first to explicitly explore the potential relationship between the underlying concepts in homogeneous decentralized control for articulated locomotion and distributed learning. We present an approach that leverages the structure of the asynchronous advantage actor-critic (A3C) algorithm to provide a natural framework for learning decentralized control policies on a single platform. Our primary contribution shows an individual agent in the A3C algorithm can be defined by an independently controlled portion of the robot's body, thus enabling distributed learning on a single platform for efficient hardware implementation. To this end, we show how the system is trained offline using hardware experiments implementing an autonomous decentralized compliant control framework. Our experimental results show that the trained agent outperforms the compliant control baseline by more than 40% in terms of steady progression through a series of randomized, highly cluttered evaluation environments.


Title: Sim-to-Real Transfer of Robotic Control with Dynamics Randomization
Key Words: calibration  mobile robots  multi-agent systems  multi-robot systems  robot dynamics  sim-to-real transfer  robotic control  dynamics randomization  training agents  training process  robotic arm  calibration error  Robots  Training  Adaptation models  Task analysis  Trajectory  Data models  Robustness 
Abstract: Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.


Title: PIRVS: An Advanced Visual-Inertial SLAM System with Flexible Sensor Fusion and Hardware Co-Design
Key Words: cameras  image fusion  robot vision  SLAM (robots)  stereo image processing  synchronisation  embedded simultaneous localization and mapping algorithm  multi-core processor  public visual-inertial datasets  PerceptIn Robotics Vision System  Hardware Co-Design  advanced visual-inertial SLAM System  state-of-the-art visual-inertial algorithms  additional sensor modalities  inertial measurements  visual measurements  flexible sensor fusion approach  PIRVS software features  precise hardware synchronization  global-shutter stereo camera  PIRVS hardware  visual-inertial computing hardware  Simultaneous localization and mapping  Hardware  Cameras  Feature extraction  Synchronization  Visualization 
Abstract: In this paper, we present the PerceptIn Robotics Vision System (PIRVS), a visual-inertial computing hardware with embedded simultaneous localization and mapping (SLAM) algorithm. The PIRVS hardware is equipped with a multi-core processor, a global-shutter stereo camera, and an IMU with precise hardware synchronization. The PIRVS software features a flexible sensor fusion approach to not only tightly integrate visual measurements with inertial measurements and also to loosely couple with additional sensor modalities. It runs in real-time on both PC and the PIRVS hardware. We perform a thorough evaluation of the proposed system using multiple public visual-inertial datasets. Experimental results demonstrate that our system reaches comparable accuracy of state-of-the-art visual-inertial algorithms on PC, while being more efficient on the PIRVS hardware.


Title: Talk Resource-Efficiently to Me: Optimal Communication Planning for Distributed Loop Closure Detection
Key Words: mobile robots  multi-robot systems  robot vision  SLAM (robots)  cooperative simultaneous localization and mapping  inter-robot loop closures  general resource-efficiency communication planning  sensory data sharing  distributed loop closure detection  optimal communication planning  CSLAM  Robot sensing systems  Distributed databases  Planning  Trajectory  Visualization  Metadata 
Abstract: Due to the distributed nature of cooperative simultaneous localization and mapping (CSLAM), detecting inter-robot loop closures necessitates sharing sensory data with other robots. A naïve approach to data sharing can easily lead to a waste of mission-critical resources. This paper investigates the logistical aspects of CSLAM. Particularly, we present a general resource-efficient communication planning framework that takes into account both the total amount of exchanged data and the induced division of labor between the participating robots. Compared to other state-of-the-art approaches, our framework is able to verify the same set of potential inter-robot loop closures while exchanging considerably less data and influencing the induced workloads. We develop a fast algorithm for finding globally optimal communication policies, and present theoretical analysis to characterize the necessary and sufficient conditions under which simpler strategies are optimal. The proposed framework is extensively evaluated with data from the KITTI odometry benchmark datasets.


Title: Vision Based Collaborative Path Planning for Micro Aerial Vehicles
Key Words: cameras  collision avoidance  covariance matrices  mobile robots  optimisation  path planning  robot vision  trees (mathematics)  microaerial vehicles  collaborative path-planning framework  localization uncertainty  two-step planning framework  visual-fidelity aerial vehicle simulator  Planning  Uncertainty  Cameras  Three-dimensional displays  Collaboration  Optimization  Path planning 
Abstract: In this paper, we present a collaborative path-planning framework for a group of micro aerial vehicles that are capable of localizing through vision. Each of the micro aerial vehicles is assumed to be equipped with a forward facing monocular camera. The vehicles initially use their captured images to build 3D maps through common features; and subsequently track these features to localize through 3D-2D correspondences. The planning algorithm, while connecting start locations to provided goal locations, also aims to reduce the localization uncertainty of the vehicles in the group. To achieve this, we develop a two-step planning framework: the first step attempts to build an improved map of the environment by solving the next-best-view problem for multiple cameras. We express this as a black-box optimization problem and solve it using the Covariance Matrix Adaption evolution strategy (CMA-ES). Once an improved map is available, the second stage of the planning framework performs belief space planning for the vehicles individually using the rapidly exploring random belief tree (RRBT) algorithm. Through the RRBT approach, the planner generates paths that ensure feature visibility while attempting to optimize path cost and reduce localization uncertainty. We validate our approach using experiments conducted in a high visual-fidelity aerial vehicle simulator, Microsoft AirSim.


Title: High Dynamic Range Sensing by a Multistage Six-Axis Force Sensor with Stopper Mechanism
Key Words: force measurement  force sensors  seals (stoppers)  torque measurement  high dynamic range six-axis force-torque sensor  HDR six-axis force-torque sensor  force measurement  stopper mechanism  multistage six-axis force sensor  high dynamic range sensing  HDR measurement  overload protection mechanism  low-rigidity flexure element  high-rigidity flexure element  Robot sensing systems  Force sensors  Force  Strain  Force measurement  Mathematical model 
Abstract: This paper describes the design of a high dynamic range (HDR) six-axis force/torque sensor. The sensor is composed of a high-rigidity flexure element detecting large force and a low-rigidity flexure element detecting small force. The overload on the low-rigidity flexure element is prevented by an overload protection mechanism. An HDR measurement is achieved by combining the outputs of the two flexure elements. A loading test for the designed sensor is performed, and the results indicate that the six-axis sensor measures force with a dynamic range from 0.01N to 1000 N.


Title: Principal Components of Touch
Key Words: biology computing  data visualisation  principal component analysis  sensor arrays  tactile sensors  touch (physiological)  vibrissal arrays  PCA  touch  complex robotic manipulation  tactile sensor arrays  principal component analysis  visualisation approach  k-NN  Euclidean distance  Principal component analysis  Tactile sensors  Data visualization  Sensor arrays  Pins 
Abstract: Our human sense of touch enables us to manipulate our surroundings; therefore, complex robotic manipulation will require artificial tactile sensing. Typically tactile sensor arrays are used in robotics, implying that a straightforward way of interpreting multidimensional data is required. In this paper we present a simple visualisation approach based on applying principal component analysis (PCA) to systematically collected sets of tactile data. We apply the visualisation approach to 4 different types of tactile sensor, encompassing fingertips and vibrissal arrays. The results show that PCA can reveal structure and regularities in the tactile data, which also permits the use of simple classifiers such as k-NN to achieve good inference. Additionally, the Euclidean distance in principal component space gives a measure of sensitivity, which can aid visualisation and also be used to find regions in the tactile input space where the sensor is able to perceive with higher accuracy. We expect that these observations will generalise, and thus offer the potential for novel control methods based on touch.


Title: Estimation of Object Orientation Using Conductive Ink and Fabric Based Multilayered Tactile Sensor
Key Words: accelerometers  dexterous manipulators  force sensors  grippers  manipulator kinematics  tactile sensors  fabric based multilayered tactile sensor  hard materials  soft materials  robotic hand gripper  kinesthetic sensation  grasped object orientation  tactile sensing  rigid inertial measurement units  object orientation estimation  conductive silver ink  conductive fabric  fabric based sensors  hard surfaces  soft surfaces  manipulator kinematics  object manipulation tasks  Ink  Fabrics  Tactile sensors  Piezoresistance  Silver  Fabric Tactile sensor  Multilayered sensor  Tilt sensing  Conductive silver ink 
Abstract: Robots, either made from hard or soft materials, are being used increasingly for unknown object manipulation tasks in unstructured environments. To hold an object firmly and do the required task, the orientation of the object with respect to the robotic hand gripper is one of the necessary key information. Humans can sense the orientation of an object based on vision, kinesthetic sensation, or touch sensation. Similarly, robots shall also be able to estimate grasped object orientation just based on tactile sensing without knowing manipulator kinesthetic or kinematics. Existing sensors are mostly based on vision or rigid inertial measurement units (such as accelerometers, gyroscopes, magnetometers), which require additional setup and are typically not compliant with the arbitrary surfaces of the unknown obj ects. This paper discusses a new approach for object orientation estimation from a multilayered tactile sensor based on conductive silver ink and conductive fabric. Fabric based sensors are flexible and can confer to both hard and soft surfaces. Experimental results show that the tactile sensor developed is able to estimate the tilt angle without any information about manipulator kinematics.


Title: Color-Based Sensing of Bending Deformation on Soft Robots
Key Words: image colour analysis  pneumatic actuators  robots  signal generators  three-dimensional printing  signal generator  color sensors  soft pneumatic actuators  soft actuators  multicolor 3D printing  soft robots  bending deformation  color-based sensing  Color  Strain  Actuators  Robot sensing systems  Signal generators  Soft robotics 
Abstract: This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The working principle of our approach is based on using compact color sensors to detect deformation that is visualized by the change of color ratios. Two novel designs are presented to generate color signals on 3D printed objects, which we call an external signal generator and an internal signal generator. Signal processing and calibration methods are developed to transform the raw RGB-data into a meaningful deformation metric. Our experimental tests taken on soft pneumatic actuators verify that color signals can be stably generated and captured to indicate the bending deformation. The results also demonstrate the usability of this sensing approach in deformation control.


Title: Geometry-based Direct Simulation for Multi-Material Soft Robots
Key Words: calibration  deformation  design engineering  elasticity  geometry  manipulators  motion control  optimisation  pneumatic actuators  shapes (structures)  three-dimensional printing  material properties  deformation simulation  deformed shape  geometry-based direct simulation  multimaterial soft robots  soft materials  motion simulation  robots fabrication  numerical optimization  pneumatic actuators  cable-driven  calibration  design engineering  manipulators  3D-printing  elasticity  Shape  Soft robotics  Strain  Computational modeling  Optimization  Numerical models  Deformable models 
Abstract: Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.


Title: Popcorn-Driven Robotic Actuators
Key Words: actuators  compressive strength  friction  granular flow  granular materials  grippers  ignition  mixtures  robot dynamics  inter-granular friction  granular fluids  jamming actuators  popcorn-driven actuation  robotics  popcorn-driven robotic actuators  popcorn kernels  expansion ratio  transition temperature  compression strength  hot oil  hot air  direct contact  heated Nichrome wire  popping force  biodegradability  Kernel  Heating systems  Robots  Jamming  Actuators  Force  Wires 
Abstract: Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat. Although this transition is irreversible, it carries potential for several robotic applications. Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability. We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire. As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump. Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers. Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.


Title: Clothoid-Based Global Path Planning for Autonomous Vehicles in Urban Scenarios
Key Words: curve fitting  mobile robots  path planning  road traffic  road vehicles  roads  autonomous vehicles  urban scenario  intelligent vehicles  kinematic constraints  continuous-curvature paths  low curvature derivatives  clothoid-based global path planning  road network representation  Roads  Path planning  Geometry  Autonomous vehicles  Wheels  Kinematics  Computational modeling 
Abstract: Intelligent vehicles require an efficient way to compute a feasible path that connects its current localization to a destination point. To achieve that, the knowledge about the road network, including its geometry, is important since connections between roads can be used in the path planning. This work consists on computing a feasible global path for autonomous vehicles with kinematic constraints. Piecewise linear continuous-curvature paths composed of clothoids, circular arcs, and straight lines are used for this purpose. Low curvature derivatives provide comfort to passengers. This approach provides a compact road network representation as only the parameters of the curves are stored. A real urban scenario with straight and curved roads, multiple lanes, intersections, and roundabouts is modeled and the proposed approach is validated. As a result of the proposed approaches, door-to-door global continuous-curvature paths are generated considering the shortest traveled distance.


Title: Departure and Conflict Management in Multi-Robot Path Coordination
Key Words: aircraft control  airports  mobile robots  multi-robot systems  path planning  automatic aircraft taxiing coordination  driver-less cars coordination  no-backward-movement constraint  complex conflict situations  Charles de Gaulle airport  multirobot path coordination  Robot kinematics  Planning  Aircraft  Collision avoidance  Airports  Automobiles 
Abstract: This paper addresses the problem of multi-robot path coordination, considering specific features that arise in applications such as automatic aircraft taxiing or driver-less cars coordination. The first feature is departure events: when robots arrive at their destinations (e.g. the runway for takeoff), they can be removed from the coordination diagram. The second feature is the “no-backward-movement” constraint: the robots can only move forward on their assigned paths. These features can interact to give rise to complex conflict situations, which existing planners are unable to solve in practical time. We propose a set of algorithms to efficiently account for these features and validate these algorithms on a realistic model of Charles de Gaulle airport.


Title: A Single-Planner Approach to Multi-Modal Humanoid Mobility
Key Words: humanoid robots  legged locomotion  path planning  planning (artificial intelligence)  search problems  planning efforts  planning process  single-planner approach  multimodal humanoid mobility  configuration space  humanoid robot  single search process  search spaces  adaptive dimensionality  Planning  Task analysis  Aerospace electronics  Legged locomotion  Superluminescent diodes  Humanoid robots 
Abstract: In this work, we present an approach to planning for humanoid mobility. Humanoid mobility is a challenging problem, as the configuration space for a humanoid robot is intractably large, especially if the robot is capable of performing many types of locomotion. For example, a humanoid robot may be able to perform such tasks as bipedal walking, crawling, and climbing. Our approach is to plan for all these tasks within a single search process. This allows the search to reason about all the capabilities of the robot at any point, and to derive the complete solution such that the plan is guaranteed to be feasible. A key observation is that we often can roughly decompose a mobility task into a sequence of smaller tasks, and focus planning efforts to reason over much smaller search spaces. To this end, we leverage the results of a recently developed framework for planning with adaptive dimensionality, and incorporate the capabilities of available controllers directly into the planning process. The resulting planner can also be run in an interleaved fashion alongside execution so that time spent idle is much reduced.


Title: Collision-Free Motion Planning for Human-Robot Collaborative Safety Under Cartesian Constraint
Key Words: collision avoidance  control system synthesis  end effectors  human-robot interaction  image segmentation  Kalman filters  nearest neighbour methods  robot vision  human-robot collaborative safety  Cartesian constraint  real-time motion planning  control design  robotic arm  multiple KinectV2 depth cameras  robot workspace  collision avoidance  robot end effector  collision-free motion planning method  6-DOF robot arm  Kalman filter  K-nearest neighbor searching algorithm  K-nearest neighbor searching algorithm  Robots  Collision avoidance  Force  Planning  Three-dimensional displays  Collaboration  Task analysis 
Abstract: This paper presents a real-time motion planning and control design of a robotic arm for human-robot collaborative safety. A novel collision-free motion planning method is proposed not only to keep robot body from colliding with objects but also preserve the execution of robot's original task under the Cartesian constraint of the environment. Multiple KinectV2 depth cameras are utilized to model and track dynamic obstacles (e.g. Humans and objects) inside the robot workspace. Depth images are applied to generate point cloud of segmented objects in the environment. A K-nearest neighbor (KNN) searching algorithm is used to cluster and find the closest point from the obstacle to the robot. Then a Kalman filter is applied to estimate the obstacle position and velocity. For the collision avoidance in collaborative operation, attractive and repulsive potential is generated for robot end effector based on the task specification and obstacle observation. Practical experiments show that the 6-DOF robot arm can effectively avoid an obstacle in a constrained environment and complete the original task.


Title: Sampling-Based Motion Planning with μ-Calculus Specifications Without Steering
Key Words: boundary-value problems  feedback  formal verification  linear quadratic control  motion control  path planning  probability  sampling methods  temporal logic  sampling-based motion planning  temporal logic specifications  linear dynamics  two-point boundary value problem  asymptotically optimal planning algorithm SST  local deterministic μ-calculus model  motion planning algorithm  deterministic μ-calculus specifications  multiple Kripke structures  abstracted Kripke structure  state-space  linear-quadratic regulator feedback control policy  complex liveness specification  steering function  kinodynamic planning algorithm SST  LQR feedback control policy  Calculus  Planning  Model checking  Trajectory  Reactive power  Lattices 
Abstract: While using temporal logic specifications with motion planning has been heavily researched, the reliance on having an available steering function is impractical and often suited only to basic problems with linear dynamics. This is because a steering function is a solution to an optimal two-point boundary value problem (OBVP); to our knowledge, it is nearly impossible to find an analytic solution to such problems in many cases. Addressing this issue, we have developed a means of combining the asymptotically optimal and probabilistically complete kinodynamic planning algorithm SST* with a local deterministic μ-calculus model checking procedure to create a motion planning algorithm with deterministic μ-calculus specifications that does not rely on a steering function. The procedure involves combining only the most pertinent information from multiple Kripke structures in order to create one abstracted Kripke structure storing the best paths to all possible proposition regions of the state-space. A linear-quadratic regulator (LQR) feedback control policy is then used to track these best paths, effectively connecting the trajectories found from multiple Kripke structures. Simulations demonstrate that it is possible to satisfy a complex liveness specification for infinitely often reaching specified regions of state-space using only forward propagation.


Title: A Model-Based Hierarchical Controller for Legged Systems Subject to External Disturbances
Key Words: control system synthesis  force control  legged locomotion  motion control  position control  robot dynamics  robot kinematics  robust control  model-based hierarchical controller  model-based controller  projected inverse dynamics controller  control law  constrained space controller  unknown external disturbances  impedance controller  legged systems  unconstrained component  contact forces  force sensors  torque sensors  ANYmal quadruped platform  contact locations  legged robots  Task analysis  Force  Legged locomotion  Aerospace electronics  Dynamics  Jacobian matrices 
Abstract: Legged robots have many potential applications in real-world scenarios where the tasks are too dangerous for humans, and compliance is needed to protect the system against external disturbances and impacts. In this paper, we propose a model-based controller for hierarchical tasks of legged systems subject to external disturbance. The control framework is based on projected inverse dynamics controller, such that the control law is decomposed into two orthogonal subspaces, i.e., the constrained and the unconstrained subspaces. The unconstrained component controls multiple desired tasks with impedance responses. The constrained space controller maintains the contact subject to unknown external disturbances, without the use of any force/torque sensing at the contact points. By explicitly modelling the external force, our controller is robust to external disturbances and errors arising from incorrect dynamic model information. The main contributions of this paper include (1) incorporating an impedance controller to control external disturbances and allow impedance shaping to adjust the behaviour of the motion under external disturbances, (2) optimising contact forces within the constrained subspace that also takes into account the external disturbances without using force/torque sensors at the contact locations. The techniques are evaluated on the ANYmal quadruped platform under a variety of scenarios.


Title: Temporal Spatial Inverse Semantics for Robots Communicating with Humans
Key Words: control engineering computing  human-robot interaction  natural language processing  Amazon MTurk  TeSIS  natural language sentences  extended sentence structure  spatial context information  human listeners  temporal spatial inverse semantics  temporal context  Semantics  Grounding  Pallets  Natural languages  Tires  Service robots 
Abstract: Effective communication between humans often embeds both temporal and spatial context. While spatial context captures the geographic settings of objects in the environment, temporal context describes their changes over time. In this paper, we propose temporal spatial inverse semantics (TeSIS) to extend the inverse semantics approach to also consider the temporal context for robots communicating with humans. Inverse semantics generates natural language requests while taking into account how well the human listeners would interpret those requests given the current spatial context. Compared to inverse semantics, our approach incorporates also temporal context by referring to spatial context information in the past. To achieve this, we extend the sentence structure in inverse semantics to generate sentences that can refer to not only the current but also previous states of the environment. A new metric based on the extended sentence structure is developed by breaking a single sentence into multiple independent sentences that refer to environment states at different times. Using this approach, we are able to generate sentences such as “Please pick up the cup beside the oven that was on the dining table”. To evaluate our approach, we randomly generate scenarios in an experimental domain. Each scenario includes the description of the current and several immediate previous states. Natural language sentences are then generated for these scenarios using both inverse semantics that uses only the spatial context and our approach. Amazon MTurk is used to compare the sentences generated and results show that TeSIS achieves better accuracy, sometimes by a significant margin, than the baseline.


Title: Human in the Loop of Robot Learning: EEG-Based Reward Signal for Target Identification and Reaching Task
Key Words: brain  control engineering computing  electroencephalography  human-robot interaction  intelligent robots  learning (artificial intelligence)  robot programming  target reaching task  assistive technologies  shared control  intelligent robotic device  electrophysiological measures  error detection  Error-related Potentials  semiautonomous system  online robot learning task  detected ErrP  robot learning loop  optimal policy learning  shared autonomy  reinforcement learning framework  Electroencephalography  Training  Graphical user interfaces  Microsoft Windows  Testing  Robot learning 
Abstract: Shared control and shared autonomy play an important role in assistive technologies, allowing the offloading of the cognitive burden required for control from the user to the intelligent robotic device. In this context, electrophysiological measures of error detection, directly measured from a person's brain activity as Error-related Potentials (ErrPs), can be exploited to provide passive adaptation of an external semi-autonomous system to the human. This concept was implemented in an online robot learning task, where user's evaluation of the robot's actions, in terms of detected ErrP, was exploited to update a reward function in a Reinforcement Learning (RL) framework. Results from both simulated and experimental studies show that the introduction of human evaluation in the robot learning loop allows for: (1) the acceleration of optimal policy learning in a target reaching task, (2) the introduction of a further degree of control in robot learning, namely identification of one among multiple targets, according to the user's will. Overall, presented results support the potential of human-robot co-adaptive and co-operative strategies to develop human-centered assistive technologies.


Title: Constructing Category-Specific Models for Monocular Object-SLAM
Key Words: cameras  feature extraction  mobile robots  object detection  pose estimation  robot vision  SLAM (robots)  category-specific models  real-time object-oriented SLAM  monocular camera  object-level models  category-level models  object deformations  discriminative object features  category models  object landmark observations  generic monocular SLAM framework  2D object features  sparse feature-based monocular SLAM  object instance retrieval  instance-independent monocular object-SLAM system  feature-based SLAM methods  time 2.0 d  time 3.0 d  Solid modeling  Simultaneous localization and mapping  Three-dimensional displays  Object oriented modeling  Pipelines  Two dimensional displays  Shape 
Abstract: We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category-level models from CAD collections which are now widely available. To alleviate the need for huge amounts of labeled data, we develop a rendering pipeline that enables synthesis of large datasets from a limited amount of manually labeled data. Using data thus synthesized, we learn category-level models for object deformations in 3D, as well as discriminative object features in 2D. These category models are instance-independent and aid in the design of object landmark observations that can be incorporated into a generic monocular SLAM framework. Where typical object-SLAM approaches usually solve only for object and camera poses, we also estimate object shape on-the-fty, allowing for a wide range of objects from the category to be present in the scene. Moreover, since our 2D object features are learned discriminatively, the proposed object-SLAM system succeeds in several scenarios where sparse feature-based monocular SLAM fails due to insufficient features or parallax. Also, the proposed category-models help in object instance retrieval, useful for Augmented Reality (AR) applications. We evaluate the proposed framework on multiple challenging real-world scenes and show - to the best of our knowledge - first results of an instance-independent monocular object-SLAM system and the benefits it enjoys over feature-based SLAM methods.


Title: DPDB-Net: Exploiting Dense Connections for Convolutional Encoders
Key Words: convolutional codes  decoding  image classification  image coding  image segmentation  neural net architecture  dense connections  Cam Vid dataset  Freiburg Forest dataset  convolutional encoders  multiple segmentation tasks  feature map explosion  residual network architecture  dense block  DPDB-Net  Dual-Path Dense-Block Network  encoder-decoder architectures  feature re-usage  dense networks  multiple classification tasks  feature exploration  densely connected networks  Decoding  Computer architecture  Semantics  Task analysis  Explosions  Image segmentation  Forestry 
Abstract: Densely connected networks for classification enable feature exploration and result in state-of-the-art performance on multiple classification tasks. The alternative to dense networks is the residual network which enables feature re-usage. In this work, we combine these orthogonal concepts for encoder-decoder architectures, which we call Dual-Path Dense-Block Network (DPDB-Net). We introduce a dense block which incorporates feature re-usage and new feature exploration in the encoder. Moreover, we discuss that feature re-usage by the residual network architecture leads to a feature map explosion in the decoder and, thus, is not advantageous in this part of the network. We evaluated our proposed architecture in multiple segmentation tasks and report state-of-the-art performance on the Freiburg Forest dataset and competitive results on the Cam Vid dataset.


Title: The Hands-Free Push-Cart: Autonomous Following in Front by Predicting User Trajectory Around Obstacles
Key Words: collision avoidance  mobile robots  motion control  object detection  trajectory control  autonomous mobile robot  walking user  autonomous push-carts  multimodal person detection  human-motion model  obstacle mapper  human tracker  human motion model  robot motion planner  robot motion controller  industrial entertainment applications  domestic entertainment applications  hands-free push-cart  predicting user trajectory  Robot sensing systems  Legged locomotion  Cameras  Tracking  Trajectory  Predictive models 
Abstract: This paper demonstrates an autonomous mobile robot that follows a walking user while staying ahead of them. Despite several useful applications for autonomous push-carts, this problem has received much less attention than the easier problem of following from behind. In contrast to previous work, we use multi-modal person detection and a human-motion model that considers obstacles to predict the future path of the user. We implement the system with a modular architecture of obstacle mapper, human tracker, human motion model, robot motion planner and robot motion controller. We report on the performance of the robot in real-world experiments. We believe that approaches to this largely overlooked problem could be useful in real industrial, domestic and entertainment applications in the near future.


Title: Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach
Key Words: collision avoidance  Markov processes  mobile robots  motion control  multi-agent systems  multi-robot systems  random processes  stochastic processes  motion trajectories  planning-based approach  dynamic objects  planning-based social force approach  joint long-term prediction  individual agent velocities  social forces  weighted random walk algorithm  stochastic motion policies  long-term predictions  multiple agents  joint motion  local interactions  long-term human motion prediction  dynamic environments  intelligent vehicles  mobile robots  Trajectory  Prediction algorithms  Force  Predictive models  Planning  Stochastic processes  Robots 
Abstract: The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.


Title: Multi3: Multi-Sensory Perception System for Multi-Modal Child Interaction with Multiple Robots
Key Words: computer games  control engineering computing  educational robots  gesture recognition  human-robot interaction  mobile robots  multi-robot systems  robot vision  speech recognition  robotic platforms  child-robot interaction scenarios  Multi3  robotic sensory  perception capabilities  speech recognition modules  gesture recognition modules  modular multirobot architecture  action recognition modules  indoors interaction scenarios  child-robot interaction scene  multiple Kinect-based system  multiple robots  Multimodal child interaction  Multisensory perception system  Speech recognition  Trajectory  Robot sensing systems  Microphone arrays 
Abstract: Child-robot interaction is an interdisciplinary research area that has been attracting growing interest, primarily focusing on edutainment applications. A crucial factor to the successful deployment and wide adoption of such applications remains the robust perception of the child's multi-modal actions, when interacting with the robot in a natural and untethered fashion. Since robotic sensory and perception capabilities are platform-dependent and most often rather limited, we propose a multiple Kinect-based system to perceive the child-robot interaction scene that is robot-independent and suitable for indoors interaction scenarios. The audio-visual input from the Kinect sensors is fed into speech, gesture, and action recognition modules, appropriately developed in this paper to address the challenging nature of child-robot interaction. For this purpose, data from multiple children are collected and used for module training or adaptation. Further, information from the multiple sensors is fused to enhance module performance. The perception system is integrated in a modular multi-robot architecture demonstrating its flexibility and scalability with different robotic platforms. The whole system, called Multi3, is evaluated, both objectively at the module level and subjectively in its entirety, under appropriate child-robot interaction scenarios containing several carefully designed games between children and robots.


Title: Multi-Robot Coordination in Dynamic Environments Shared with Humans
Key Words: human-robot interaction  mobile robots  multi-robot systems  navigation  path planning  market-based framework  coordination mechanism  social costs  bid evaluations  realistic environment  human-aware navigation  human-agnostic planning  social constraints  multirobot coordination  dynamic environments  social human-populated environments  multirobot task allocation problem  static humans  moving humans  high-fidelity simulator  localization noise  static people  blocked passages  human-aware planning  human-agnostic navigation  robot experiments  MRTA metrics  Robot kinematics  Task analysis  Navigation  Planning  Resource management  Measurement 
Abstract: This work addresses multi-robot coordination in social human-populated environments using a market-based framework for solving the Multi-Robot Task Allocation (MRTA) problem. Humans are considered in the proposed coordination mechanism by means of accounting for social costs in bid evaluations and requesting collaboration in socially blocking situations. Initially, the effect of a realistic environment with varying number of static/moving humans on the behavior and performance of our method is studied through an extensive suite of experiments in a high-fidelity simulator. Results show that the total traveled distance and time are increased when humans are present in the environments. Localization noise is also increased particularly in the case of static people. In the second series of experiments, a number of problematic cases resulting in longer modified paths, blocked passages, and long waits have been investigated. A comparative study targeting human-agnostic navigation and planning, human-aware navigation and human-agnostic planning, and human-aware navigation and planning has been conducted. Both simulated and real robot experiments confirm the effectiveness of accounting for humans at both team and individual levels. This leads to respecting social constraints as well as achieving a better performance based on MRTA metrics.


Title: Fully Convolutional Neural Networks for Road Detection with Multiple Cues Integration
Key Words: convergence  convolution  feature extraction  feedforward neural nets  gradient methods  image colour analysis  learning (artificial intelligence)  mobile robots  optical radar  position control  convolutional neural networks  multiple cues integration  autonomous driving  deep learning  road detection algorithms  pre-trained Resnet-lOl  RGB images  CNN  feature maps extraction  Lidar scanner  position map  image gradient  convergence  KITTI benchmark  Roads  Feature extraction  Laser radar  Three-dimensional displays  Task analysis  Fuses  Network architecture 
Abstract: Road detection from images is a key task in autonomous driving. The recent advent of deep learning (and in particular, CNN or convolutional neural networks) has greatly improved the performance of road detection algorithms. In this paper, we show how to fuse multiple different cues under the same convolutional network framework. Specifically, we adopt a pre-trained Resnet-lOl to extract feature maps from RGB images; we then connect it with three extra deconvolution layers. These deconvolution layers is trained conditioning on appropriate image cues, and in our case they are a height image (i.e. elevation map obtained by e.g. Lidar scanner), image gradient, and position map. We also design two skip layers to speed up the convergence. Experiments on KITTI benchmark show competitive performance of our new networks.


Title: Robust and Precise Vehicle Localization Based on Multi-Sensor Fusion in Diverse City Scenes
Key Words: Global Positioning System  Kalman filters  optical radar  road vehicles  satellite navigation  sensor fusion  LiDAR  localization system  GNSS RTK module  urban downtown  complementary sensors  precise localization system  robust localization system  precise vehicle localization  localization measurements  error-state Kalman filter  ambiguity resolution success rate  multisensor fusion framework  size 60.0 km  size 5.0 cm to 10.0 cm  Laser radar  Three-dimensional displays  Estimation  Sensors  Global navigation satellite system  Autonomous vehicles  Robustness 
Abstract: We present a robust and precise localization system that achieves centimeter-level localization accuracy in disparate city scenes. Our system adaptively uses information from complementary sensors such as GNSS, LiDAR, and IMU to achieve high localization accuracy and resilience in challenging scenes, such as urban downtown, highways, and tunnels. Rather than relying only on LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and altitude cues to significantly improve localization system accuracy and robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion framework and achieves a better ambiguity resolution success rate. An error-state Kalman filter is applied to fuse the localization measurements from different sources with novel uncertainty estimation. We validate, in detail, the effectiveness of our approaches, achieving 5-10cm RMS accuracy and outperforming previous state-of-the-art systems. Importantly, our system, while deployed in a large autonomous driving fleet, made our vehicles fully autonomous in crowded city streets despite road construction that occurred from time to time. A dataset including more than 60 km real traffic driving in various urban roads is used to comprehensively test our system.


Title: Safe Distributed Lane Change Maneuvers for Multiple Autonomous Vehicles Using Buffered Input Cells
Key Words: collision avoidance  computational geometry  decision making  feedback  mobile robots  position control  road safety  road vehicles  safe distributed lane change maneuvers  multiple autonomous vehicles  reciprocal collision avoidance method  autonomous cars  linear dynamics  buffered input cell  Voronoi cell  Voronoi diagrams  vehicles control input  control stack  freeway driving scenario  decision-making layer  trajectory planning layer  feedback controller  BIC method  human-driven car  Collision avoidance  Robots  Vehicle dynamics  Aerospace electronics  Traffic control  Autonomous vehicles  Planning 
Abstract: This paper introduces the Buffered Input Cell as a reciprocal collision avoidance method for multiple vehicles with high-order linear dynamics, extending recently proposed methods based on the Buffered Voronoi Cell [1] and generalized Voronoi diagrams [2]. We prove that if each vehicle's control input remains in its Buffered Input Cell at each time step, collisions will be avoided indefinitely. The method is fast, reactive, and only requires that each vehicle measures the relative position of neighboring vehicles. We incorporate this collision avoidance method as one layer of a complete lane change control stack for autonomous cars in a freeway driving scenario. The lane change control stack comprises a decision-making layer, a trajectory planning layer, a trajectory following feedback controller, and the Buffered Input Cell for collision avoidance. We show in simulations that collisions are avoided with multiple vehicles simultaneously changing lanes on a freeway. We also show in simulations that autonomous cars using the BIC method effectively avoid collisions with an aggressive human-driven car.


Title: Deep Predictive Models for Collision Risk Assessment in Autonomous Driving
Key Words: Bayes methods  collision avoidance  decision making  driver information systems  image colour analysis  learning (artificial intelligence)  recurrent neural nets  risk management  video streaming  Deep Predictive Models  collision risk assessment  autonomous driving  predictive approach  assisted driving  deep predictive model  video streams  RGB images  temporal information  multi-modal information  proprioceptive state  Bayesian convolutional LSTM  decision making  Predictive models  Accidents  Stochastic processes  Uncertainty  Bayes methods  Cameras  Tensile stress 
Abstract: In this paper, we investigate a predictive approach for collision risk assessment in autonomous and assisted driving. A deep predictive model is trained to anticipate imminent accidents from traditional video streams. In particular, the model learns to identify cues in RGB images that are predictive of hazardous upcoming situations. In contrast to previous work, our approach incorporates (a) temporal information during decision making, (b) multi-modal information about the environment, as well as the proprioceptive state and steering actions of the controlled vehicle, and (c) information about the uncertainty inherent to the task. To this end, we discuss Deep Predictive Models and present an implementation using a Bayesian Convolutional LSTM. Experiments in a simple simulation environment show that the approach can learn to predict impending accidents with reasonable accuracy, especially when multiple cameras are used as input sources.


Title: Predicting Ego-Vehicle Paths from Environmental Observations with a Deep Neural Network
Key Words: driver information systems  feature extraction  image motion analysis  learning (artificial intelligence)  neural nets  road vehicles  static vehicle environment  grid-based prediction  varying assistance tasks  baseline approaches  environmental observations  deep neural network  advanced driver assistance systems  predictive model  road topologies  environmental properties  path extraction  ego-vehicle path prediction  ego-vehicle motion  Predictive models  Vehicles  Sensors  Roads  Trajectory  Data models  Motion measurement 
Abstract: Advanced driver assistance systems allow for increasing user comfort and safety by sensing the environment and anticipating upcoming hazards. Often, this requires to accurately predict how situations will change. Recent approaches make simplifying assumptions on the predictive model of the Ego-Vehicle motion or assume prior knowledge, such as road topologies, to be available. However, in many urban areas this assumption is not satisfied. Furthermore, temporary changes (e.g. construction areas, vehicles parked on the street) are not considered by such models. Since many cars observe the environment with several different sensors, predictive models can benefit from them by considering environmental properties. In this work, we present an approach for an Ego-Vehicle path prediction from such sensor measurements of the static vehicle environment. Besides proposing a learned model for predicting the driver's multi-modal future path as a grid-based prediction, we derive an approach for extracting paths from it. In driver assistance systems both can be used to solve varying assistance tasks. The proposed approach is evaluated on real driving data and outperforms several baseline approaches.


Title: Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning
Key Words: blood vessels  convolution  image recognition  image segmentation  learning (artificial intelligence)  medical image processing  medical robotics  recurrent neural nets  surgery  thread centerline reconstruction  multistage suture detection  robot assisted anastomosis  deep learning  robust suture detection  suture augmentation  robotic-assisted surgery  fully convolutional neural networks  trainee suturing skill evaluation  curvilinear structure detector  Yarn  Instruction sets  Surgery  Splines (mathematics)  Image reconstruction  Robots  Task analysis 
Abstract: The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.


Title: Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
Key Words: ecology  hydrological equipment  hydrological techniques  microorganisms  multi-robot systems  remotely operated vehicles  reservoirs  water quality  data-driven behavior  real geophysical data  MODIS measurements  water-sampling apparatus  water quality sensor  plankton-rich water samples  chlorophyll density  autonomous surface vehicles plan  water-sampling behavior  efficient measurement  fresh-water systems  measuring contamination levels  drinking water  physical sampling  strategic water sampling  heterogeneous multirobot system  water reservoir  explorer robot  water sampling apparatus  ASV  Pollution measurement  Geophysical measurements  Robot sensing systems  Real-time systems  Time measurement  Water pollution 
Abstract: Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.


Title: A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration
Key Words: image registration  image sensors  mobile robots  sensor fusion  flexible framework  general framework  explicit data association  flexible multicue photometric point cloud registration  mobile robots  mapping systems  recorded sensor data  photometric registration  multiple modalities  image data streams  pixel-wise difference  multichannel images  Three-dimensional displays  Robot sensing systems  Cameras  Iterative closest point algorithm  Minimization  Integrated circuit modeling  Laser radar 
Abstract: The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.


Title: Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping
Key Words: continuous time systems  entropy  graph theory  image registration  image resolution  laser ranging  optical radar  SLAM (robots)  solid modelling  stereo image processing  laser-range scanners  high data rate  3D laser scanner  surfel-based registration  recursive state estimation  multiresolution maps  continuous-time SLAM  3D lidar-based online mapping  online simultaneous localization and mapping  Three-dimensional displays  Measurement by laser beam  Optimization  Trajectory  Laser modes  Simultaneous localization and mapping 
Abstract: Modern 3D laser-range scanners have a high data rate, making online simultaneous localization and mapping (SLAM) computationally challenging. Recursive state estimation techniques are efficient but commit to a state estimate immediately after a new scan is made, which may lead to misalignments of measurements. We present a 3D SLAM approach that allows for refining alignments during online mapping. Our method is based on efficient local mapping and a hierarchical optimization back-end. Measurements of a 3D laser scanner are aggregated in local multiresolution maps by means of surfel-based registration. The local maps are used in a multi-level graph for allocentric mapping and localization. In order to incorporate corrections when refining the alignment, the individual 3D scans in the local map are modeled as a sub-graph and graph optimization is performed to account for drift and misalignments in the local maps. Furthermore, in each sub-graph, a continuous-time representation of the sensor trajectory allows to correct measurements between scan poses. We evaluate our approach in multiple experiments by showing qualitative results. Furthermore, we quantify the map quality by an entropy-based measure.


Title: A Scalable Multi-Robot Task Allocation Algorithm
Key Words: computational complexity  industrial robots  mobile robots  multi-robot systems  nearest neighbour methods  pattern clustering  vehicle routing  warehouse automation  CVRP instance  nCAR  scalable multirobot task allocation algorithm  modern warehouses  docking station  route planning  capacity-constrained vehicle routing problem  nearest-neighbor based clustering and routing  Task analysis  Heuristic algorithms  Clustering algorithms  Resource management  Routing  Service robots 
Abstract: In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.


Title: Distributed Intermittent Communication Control of Mobile Robot Networks Under Time-Critical Dynamic Tasks
Key Words: control engineering computing  distributed control  mobile robots  multi-robot systems  protocols  scheduling  time-critical dynamic tasks  offline schedules  mobile robot networks  distributed intermittent communication control  task accomplishment  task planning  communication events  distributed control framework  communication constraints  intermittent communication protocols  connected networks  reliable networks  robot communication capabilities  Task analysis  Robot sensing systems  Time factors  Schedules  Communication networks 
Abstract: In this paper, we develop a distributed intermittent communication framework for teams of mobile robots that are responsible for accomplishing time-critical dynamic tasks and sharing the collected information with all other robots and possibly also with a user. Specifically, we consider situations where the robot communication capabilities are not sufficient to maintain reliable and connected networks while the robots move to accomplish their tasks. In this case, intermittent communication protocols are necessary that allow the robots to temporarily disconnect from the network in order to accomplish their tasks free of communication constraints. We assume that the robots can only communicate with each other when they meet at common locations in space. Our proposed distributed control framework determines offline schedules of communication events and integrates them online with task planning. The resulting paths ensure task accomplishment and exchange of information among robots infinitely often at locations that minimize a user-specified metric. Simulation results corroborate the proposed distributed control framework.


Title: Landmark-based Exploration with Swarm of Resource Constrained Robots
Key Words: distance measurement  Global Positioning System  mobile robots  multi-robot systems  path planning  robot vision  sensor fusion  landmark-based exploration  resource constrained robots  autonomous exploration  topological representation  topological information  exploitation strategy  robot swarm  GPS-denied environment  sensing capabilities  range sensor  dense landmarks  bearing angles  metric information  local navigation  Robot kinematics  Robot sensing systems  Navigation  Dispersion  Measurement 
Abstract: In this paper we consider the problem of autonomous exploration of an unknown, GPS-denied environment using a swarm of robots with very limited resources and limited sensing capabilities. To that end we use a landmark complex, a simplicial complex utilizing an observation of landmarks, as a topological representation of the environment. Each robot is equipped with an omni-directional, limited-range sensor that can identify landmarks in the robot's neighborhood. The robots use the bearing angles to the landmarks for local navigation. Given a collection of identifiable landmarks, a landmark complex can then be cumulatively constructed to encapsulate the topological information of the environment. Under the assumption of sufficiently dense landmarks, we propose an exploration and exploitation strategy that guides the swarm of robots to explore an environment using only bearing measurements without any metric information. Lastly, we demonstrate the coordinate-free and localization-free navigation in the environment using the constructed landmark complex.


Title: Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis
Key Words: brakes  braking  mobile robots  motion control  multi-robot systems  wheels  braking control region analysis  passive mobile robot  wheel  formation control  control law  passive robot  fundamental control method  active leader  multiple mobile robots  external pulling force  servo brakes  multiple passive-follower type robots  Mobile robots  Force  Wheels  Robot kinematics  Brakes  Torque 
Abstract: Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.


Title: 2D SLAM Correction Prediction in Large Scale Urban Environments
Key Words: image representation  mobile robots  multilayer perceptrons  pose estimation  robot vision  SLAM (robots)  autonomous mobile robots  large scale urban environments  simultaneous location and mapping  hybrid correction module  likelihood distributions  2D likelihood SLAM approaches  successive estimated poses  Ensemble Multilayer Perceptron model  SLAM estimations  systematic errors  sensor measurement errors  SLAM map representation  observation model  motion model  probabilistic formulation  Simultaneous localization and mapping  Two dimensional displays  Estimation  Neural networks  Predictive models  Kalman filters 
Abstract: Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.


Title: Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition
Key Words: mobile robots  object recognition  robot vision  sensor fusion  SLAM (robots)  omnidirectional multisensory perception fusion  long-term place recognition  long-term autonomy  omnidirectional sensors  omnidirectional observation  multidirectional place recognition  omnidirectional multisensory data  appearance variations  Simultaneous Localization and Mapping  Feature extraction  Sensor phenomena and characterization  Simultaneous localization and mapping  Optimization 
Abstract: Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.


Title: Differential Flatness Transformations for Aggressive Quadrotor Flight
Key Words: helicopters  mobile robots  stability  trajectory control  flight envelope  hierarchical control  quadrotor flight  differential flatness transformation  trajectory control  stability issues  Trajectory  Attitude control  Standards  Acceleration  Aerospace electronics  Australia  Robustness 
Abstract: Aggressive maneuvering amongst obstacles could enable advanced capabilities for quadrotors in applications such as search and rescue, surveillance, inspection, and situations where rapid flight is required in cluttered environments. Previous works have treated quadrotors as differentially flat systems, and this property has been exploited widely to design simple algorithms that generate dynamically feasible trajectories and to enable hierarchical control. The differentially flat property allows the full state of the quadrotor to be extracted from the reduced dimensional space of x, y, z, yaw and their derivatives. This differential flatness transformation has a number of singularities, however, as well as stability issues when controlling near these singularities. Many methods have been described in the literature to address these; however, they all have limitations when exploring the full flight envelope of a quadrotor, including roll or pitch angles past 90°, and during inverted flight. In this paper, we review these existing methods and then introduce our method, which combines multiple methods to provide a highly-robust differential flatness transformation that addresses most of these issues. Our approach is demonstrated enabling highly-aggressive quadrotor flight in both simulations and real-world experiments.


Title: Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles
Key Words: aerospace robotics  collision avoidance  helicopters  mobile robots  predictive control  robot dynamics  vehicle dynamics  path planning  trajectory generation algorithms  MPC  sequential linear quadratic  SLQ  obstacle-avoidance algorithm  Model Predictive Control  dynamic environments  planning algorithms  multirotor  suspended load  Heuristic algorithms  Trajectory  Cost function  Mathematical model  Vehicle dynamics  Load modeling  Computational modeling 
Abstract: This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.


Title: EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots
Key Words: distance measurement  endoscopes  learning (artificial intelligence)  medical robotics  particle filtering (numerical methods)  pose estimation  recurrent neural nets  robot vision  sensor fusion  multisensor fusion  endoscopy robots  endoscopic capsule robot trajectories  recurrent neural network  nonlinear kinematic model  sensor reliability  online estimation  particle filter  gastrointestinal tract  therapeutic technology  switching state-space model  particle filtering-based multisensory data fusion  Robot sensing systems  Switches  Kalman filters  Proposals  Endoscopes  Magnetic resonance imaging 
Abstract: A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.


Title: A Projected Inverse Dynamics Approach for Multi-Arm Cartesian Impedance Control
Key Words: force control  friction  manipulator dynamics  motion control  unknown object dynamics  projected inverse dynamics approach  multiarm Cartesian impedance control  model-based control framework  multiarm manipulation  control law  constrained subspaces  unconstrained subspaces  unconstrained components  motion task  Cartesian impedance behaviour  constrained component enforces contact  friction constraints  contact forces  constrained subspace  contact points  dual-arm platform  Dynamics  Impedance  Force  Aerospace electronics  Robots  Task analysis  Jacobian matrices 
Abstract: We propose a model-based control framework for multi-arm manipulation of a rigid object subject to external disturbances. The control framework, based on projected inverse dynamics, decomposes the control law into constrained and unconstrained subspaces. Unconstrained components accomplish the motion task with a desired 6-DOF Cartesian impedance behaviour against external disturbances. Meanwhile, the constrained component enforces contact and friction constraints by optimising for contact forces within the constrained subspace. External disturbances are explicitly compensated for without using force/torque sensors at the contact points. The approach is evaluated on a dual-arm platform manipulating a rigid object while coping with unknown object dynamics and human interaction.


Title: Robust, Compliant Assembly via Optimal Belief Space Planning
Key Words: assembling  CAD  friction  geometry  mobile robots  optimal control  path planning  planning (artificial intelligence)  probability  robot dynamics  uncertain systems  compliant assembly  optimal belief space planning  automated manufacturing  robots  nonlinear contact-dynamics  model parameters  belief space planning problem  compliant system  asymptotically optimal belief space planner  kinodynamic motion planner  asymptotic optimality  multiple assembly tasks  CAD models  state spaces  object poses  geometry  friction  uncertainty  impedance-control  nondeterministic domains  probabilistic completeness  Planning  Robots  Trajectory  Uncertainty  Task analysis  Aerospace electronics  Dynamics 
Abstract: In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.


Title: First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle
Key Words: autonomous aerial vehicles  image colour analysis  mobile robots  path planning  robot vision  stereo image processing  multiroom exploration task  DelFly Explorer  autonomous indoor exploration mission  room exploration  stereo-vision based droplet algorithm  heading-based door passage algorithm  flapping wing vehicles  autonomous exploration tasks  autonomous multiroom exploration  wing vehicle  MAVs  autonomous indoor navigation  rotary wings  flapping wing MAV  stereo vision system  microair vehicles  monocular color based Snake-gate algorithm  Task analysis  Robot sensing systems  Navigation  Collision avoidance  Cameras  Image color analysis 
Abstract: One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.


Title: Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning
Key Words: collision avoidance  finite element analysis  learning (artificial intelligence)  mobile robots  motion control  neurocontrollers  path planning  position control  realtime planning  high-DOF deformable bodies  arbitrarily-shaped volumetric deformable bodies  complex environments  high-dimensional configuration spaces  dynamics constraints  two-stage learning method  multitask controller  dynamic movement primitives  neural-network controller  DMP task  finite element method  contact invariant optimization  gradient-based method  two-stage learning algorithm  trained DMP controller  different navigation tasks  learned motion planner  walking deformable robots  obstacle avoidance  Deep Q-Learning  Planning  Deformable models  Robots  Finite element analysis  Strain  Computational modeling  Task analysis 
Abstract: We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.


Title: Caging Loops in Shape Embedding Space: Theory and Computation
Key Words: geometry  grippers  object detection  robot vision  topology  shape embedding space  robot gripper  surface geometry  caging grasps  Caging Loops  target object  Grasping  Grippers  Robots  Shape  Geometry  Topology  Robustness 
Abstract: We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.


Title: Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning
Key Words: convolution  dexterous manipulators  end effectors  feedforward neural nets  grippers  industrial manipulators  learning (artificial intelligence)  manipulator dynamics  deep learning  vacuum-based end effectors  multifinger grippers  suction cup  external wrenches  pneumatic suction gripper  point clouds  grasp quality convolutional neural network  robust vacuum suction grasp targets  gravity wrench  parallel-jaw grippers  object pose  material properties  GQ-CNN  ABB YuMi  adversarial  Three-dimensional displays  Robustness  Robots  Analytical models  Seals  Computational modeling  Planning 
Abstract: Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.


Title: Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning
Key Words: collision avoidance  learning (artificial intelligence)  life testing  mobile robots  neurocontrollers  regression analysis  autonomous vehicle  imitation learning  surrogate agents  test scenario generation  performance modes  deep neural networks  imitator surrogates  mission performance  simulation-based testing  on-line imitation  complex mission  target vehicle  behavioral modes  dataset aggregation  collision avoidance  Testing  Training  Autonomous vehicles  Trajectory  Adaptation models  History 
Abstract: In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.


Title: Generalized Task-Parameterized Skill Learning
Key Words: Gaussian processes  humanoid robots  human-robot interaction  learning (artificial intelligence)  manipulators  mixture models  motion control  robot programming  generalized task-parameterized skill learning  human skills  task-parameterized Gaussian mixture model  TP-GMM  human-robot collaboration  dual-arm manipulation  learning framework  task parameters  robot joint limits  task-parameterized learning  learned skills  real robotic systems  task constraints  learning perspective  Programming by demonstration  Task analysis  Trajectory  Robot kinematics  Optimization  Feature extraction  Robot sensing systems 
Abstract: Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.


Title: Navigating Congested Environments with Risk Level Sets
Key Words: collision avoidance  mobile robots  multi-agent systems  road vehicles  risk level set  congested environment navigation  cluttered environment  congestion cost  occupancy risk  cost function  planning space  agent planning  autonomous vehicle driving  risk threshold  conservative behavior  aggressive behavior  Planning  Level set  Navigation  Vehicle dynamics  Autonomous vehicles  Collision avoidance  Cost function 
Abstract: In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.


Title: Topological Multi-Robot Belief Space Planning in Unknown Environments
Key Words: Bayes methods  graph theory  multi-robot systems  path planning  topology  graph pruning  topological properties  factor graphs  topological space  embedded state space  high-dimensional state spaces  announced path approach  topological multirobot belief space planning  BSP approaches  factor graph representation  posterior beliefs  Planning  Robot kinematics  Simultaneous localization and mapping  Linear programming  Aerospace electronics 
Abstract: In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.


Title: On Time Optimization of Centroidal Momentum Dynamics
Key Words: angular momentum  concave programming  convex programming  humanoid robots  minimisation  mobile robots  path planning  position control  robot dynamics  time optimal control  fixed timing  motion plans  timing optimization  nonconvex problem  time-optimized dynamically consistent trajectories  centroidal dynamics  time variables  nonconvexity  contact forces  momentum trajectories  convex relaxation  trajectory optimization techniques  multicontact scenarios  dynamically consistent motions  centroidal momentum dynamics  Optimization  Dynamics  Robots  Kinematics  Torque  Mathematical model  Trajectory 
Abstract: Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing ††Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.


Title: Human-guided Optical Manipulation of Multiple Microscopic Objects
Key Words: collision avoidance  decision making  manipulators  micromanipulators  multi-robot systems  radiation pressure  human-guided optical manipulation  multiple microscopic objects  control systems  multiple microobjects  robotic control technique  automated optical manipulation system  precise manipulation  productive manipulation  Robots  Microscopy  Optical microscopy  Potential energy  Biomedical optical imaging  Collision avoidance 
Abstract: Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.


Title: MergeNet: A Deep Net Architecture for Small Obstacle Discovery
Key Words: image colour analysis  learning (artificial intelligence)  neural net architecture  object tracking  traffic engineering computing  lost and found dataset  complementary features  RGBD input  high level features  low level features  weight-sharing  multistage training procedure  annotation process  autonomous driving  on-road scenes  novel network architecture  small obstacle discovery  deep net architecture  MergeNet  Roads  Image segmentation  Strips  Semantics  Training  Autonomous vehicles  Task analysis 
Abstract: We present here, a novel network architecture called MergeNet for discovering small obstacles for on-road scenes in the context of autonomous driving. The basis of the architecture rests on the central consideration of training with less amount of data since the physical setup and the annotation process for small obstacles is hard to scale. For making effective use of the limited data, we propose a multi-stage training procedure involving weight-sharing, separate learning of low and high level features from the RGBD input and a refining stage which learns to fuse the obtained complementary features. The model is trained and evaluated on the Lost and Found dataset and is able to achieve state-of-art results with just 135 images in comparison to the 1000 images used by the previous benchmark. Additionally, we also compare our results with recent methods trained on 6000 images and show that our method achieves comparable performance with only 1000 training samples.


Title: Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator
Key Words: control engineering computing  convolution  feature extraction  feedforward neural nets  image classification  image colour analysis  manipulators  mobile robots  object detection  object recognition  operating systems (computers)  robot programming  robot vision  scene classification  unified architecture  global scene features  regional object features  object recognition  continuous robot beliefs  robotics applications  Robot Operating System  mobile manipulator  object detection  object locations  network predictions  SUN RGBD dataset  3D space  unified convolutional neural network  Proposals  Robots  Object detection  Object recognition  Three-dimensional displays  Semantics  Feature extraction 
Abstract: Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.


Title: AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection
Key Words: image classification  learning (artificial intelligence)  object detection  multiple object detection  AffordanceNet  object localization  object classification  affordance label  robust resizing strategy  deconvolutional layer sequence  real-time robotic applications  testing environments  end-to-end architecture  multitask loss function  affordance mask  RGB images  object affordance detection  end-to-end deep learning approach  Feature extraction  Robots  Computer architecture  Object detection  Training  Image segmentation  Machine learning 
Abstract: We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net.


Title: Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction
Key Words: feature selection  human-robot interaction  image motion analysis  learning (artificial intelligence)  mobile robots  pose estimation  recurrent neural nets  stochastic processes  human robot cooperation scenario  prediction model  action prediction dataset  human motion data  human-robot cooperation  recurrent neural network approach  multiple action sequences prediction  assistive applications  nonverbal cues  neural networks  human action prediction problem  continuous spaces  discrete spaces  encoder-decoder recurrent neural network topology  discrete action prediction problem  action sequences  feature selection  stochastic reward  Predictive models  Decoding  Hidden Markov models  Recurrent neural networks  Robot kinematics  Trajectory 
Abstract: Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.


Title: Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization
Key Words: graph theory  intelligent transportation systems  optimisation  pose estimation  sensor fusion  stereo image processing  3D localization  factor graph-based optimization  autonomous driving  3D pose measurement  asynchronous multisensor fusion  asynchronous-measurement alignment  graph nodes  out-of-sequence measurement alignment  multiple navigation sensors  modular sensor-fusion system  autonomous vehicles  3D mapping  asynchronous sensors  multiple heterogeneous sensors  Sensors  Three-dimensional displays  Optimization  Atmospheric measurements  Particle measurements  Frequency measurement  Laser radar 
Abstract: In this paper, we address the problem of optimally fusing multiple heterogeneous and asynchronous sensors for use in 3D mapping and localization of autonomous vehicles. To this end, based on the factor graph-based optimization framework, we design a modular sensor-fusion system that allows for efficient and accurate incorporation of multiple navigation sensors operating at different sampling rates. In particular, we develop a general method of out-of-sequence (asynchronous) measurement alignment to incorporate heterogeneous sensors into a factor graph for mapping and localization in 3D, without requiring the addition of new graph nodes, thus allowing the graph to have an overall reduced complexity. The proposed sensor-fusion system is validated on a real-world experimental dataset, in which the asynchronous-measurement alignment is shown to have an improved performance when compared to a naive approach without alignment.


Title: Localization Under Topological Uncertainty for Lane Identification of Autonomous Vehicles
Key Words: hidden Markov models  mobile robots  position control  remotely operated vehicles  road traffic control  topology  VSM-HMM  topological uncertainty  lane membership  topological localization process  topological structure estimation  AV lane estimation  lane identification  autonomous vehicles  topological location  decision-making  public roads  variable structure multiple hidden Markov model  metric location  Earth mover distance  Hidden Markov models  Computational modeling  Topology  Roads  Uncertainty  Measurement  Vehicle dynamics 
Abstract: Autonomous vehicles (AVs) require accurate metric and topological location estimates for safe, effective navigation and decision-making. Although many high-definition (HD) roadmaps exist, they are not always accurate since public roads are dynamic, shaped unpredictably by both human activity and nature. Thus, AVs must be able to handle situations in which the topology specified by the map does not agree with reality. We present the Variable Structure Multiple Hidden Markov Model (VSM-HMM) as a framework for localizing in the presence of topological uncertainty, and demonstrate its effectiveness on an AV where lane membership is modeled as a topological localization process. VSM-HMMs use a dynamic set of HMMs to simultaneously reason about location within a set of most likely current topologies and therefore may also be applied to topological structure estimation as well as AV lane estimation. In addition, we present an extension to the Earth Mover's Distance which allows uncertainty to be taken into account when computing the distance between belief distributions on simplices of arbitrary relative sizes.


Title: Surface Edge Explorer (see): Planning Next Best Views Directly from 3D Observations
Key Words: computational geometry  feature extraction  image reconstruction  mesh generation  solid modelling  Surface Edge Explorer  Best View planning  NBV planning approaches  voxel grids  triangulated meshes  surface geometry  high-resolution models  Surface representations  multiple survey stages  scene-model-free NBV planning approach  density representation  current measurements  observed surface boundaries  surface coverage  evaluated state-of-the-art volumetric approaches  Next Best views  time 3.0 d  Planning  Computational modeling  Density measurement  Geometry  Surface treatment  Three-dimensional displays 
Abstract: Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.


Title: Active Image-Based Modeling with a Toy Drone
Key Words: autonomous aerial vehicles  data acquisition  image reconstruction  image sensors  solid modelling  stereo image processing  iterative linear method  multiview stereo problem  online model reconstruction  toy unmanned aerial vehicle  data acquisition  toy drone  image-based modeling techniques  photo-realistic 3D models  multi-view stereo algorithm  active image-based modeling  Three-dimensional displays  Image reconstruction  Solid modeling  Unmanned aerial vehicles  Planning  Pipelines  Cameras 
Abstract: Image-based modeling techniques [1]-[3] can now generate photo-realistic 3D models from images. But it is up to users to provide high quality images with good coverage and view overlap, which makes the data capturing process tedious and time consuming. We seek to automate data capturing for image-based modeling. The core of our system is an iterative linear method to solve the multi-view stereo (MVS) problem quickly and plan the Next-Best-View (NBV) effectively. Our fast MVS algorithm enables online model reconstruction and quality assessment to determine the NBVs on the fly. We test our system with a toy unmanned aerial vehicle (UAV) in simulated, indoor and outdoor experiments. Results show that our system improves the efficiency of data acquisition and ensures the completeness of the final model.


Title: Fusing Object Context to Detect Functional Area for Cognitive Robots
Key Words: feature extraction  image classification  image fusion  image recognition  learning (artificial intelligence)  object detection  object context  deep learning  object detection dataset  current object detection framework  functional area detection  functionality-related feature  object-related  potential image regions  deep-model-based classifier  functional area image dataset  area detection problem  image recognition  cognitive robot  Feature extraction  Object detection  Robots  Task analysis  Machine learning  Proposals  Image recognition 
Abstract: A cognitive robot usually needs to perform multiple tasks in practice and needs to locate the desired area for each task. Since deep learning has achieved substantial progress in image recognition, to solve this area detection problem, it is straightforward to label a functional area (affordance) image dataset and apply a well-trained deep-model-based classifier on all the potential image regions. However, annotating the functional area is time consuming and the requirement of large amount of training data limits the application scope. We observe that the functional area are usually related to the surrounding object context. In this work, we propose to use the existing object detection dataset and employ the object context as effective prior to improve the performance without additional annotated data. In particular, we formulate a two-stream network that fuses the object-related and functionality-related feature for functional area detection. The whole system is formulated in an end-to-end manner and easy to implement with current object detection framework. Experiments demonstrate that the proposed network outperforms current method by almost 20% in terms of precision and recall.


Title: When Regression Meets Manifold Learning for Object Recognition and Pose Estimation
Key Words: convolution  feedforward neural nets  image matching  nearest neighbour methods  object recognition  pose estimation  regression analysis  manifold learning  pose regression  NN descriptor matching  manifold descriptor learning  multitask learning framework  nearest neighbor search  convolutional neural networks  pose estimation  object recognition  Pose estimation  Manifolds  Task analysis  Training  Robustness  Object recognition  Three-dimensional displays 
Abstract: In this work, we propose a method for object recognition and pose estimation from depth images using convolutional neural networks. Previous methods addressing this problem rely on manifold learning to learn low dimensional viewpoint descriptors and employ them in a nearest neighbor search on an estimated descriptor space. In comparison we create an efficient multi-task learning framework combining manifold descriptor learning and pose regression. By combining the strengths of manifold learning using triplet loss and pose regression, we could either estimate the pose directly reducing the complexity compared to NN search, or use the learned descriptor for the NN descriptor matching. By in depth experimental evaluation of the novel loss function we observed that the view descriptors learned by the network are much more discriminative resulting in almost 30% increase regarding relative pose accuracy compared to related works. On the other hand, regarding directly regressed poses we obtained important improvement compared to simple pose regression. By leveraging the advantages of both manifold learning and regression tasks, we are able to improve the current state-of-the-art for object recognition and pose retrieval.


Title: Ultra-Fast Multi-Scale Shape Estimation of Light Transport Matrix for Complex Light Reflection Objects
Key Words: cameras  image reconstruction  image resolution  light reflection  optical projectors  shape measurement  sparse matrices  multiple light paths  complex light reflection objects  Light Transport Matrix estimation  LT Matrix estimation  high resolution measurement  sparse matrix representation  ultra-fast multiscale shape estimation  target objects  specular reflection  light path  memory efficiency  256 × 256 resolution projector  camera system  3D measurement methods  Cameras  Three-dimensional displays  Estimation  Sparse matrices  Shape  Shape measurement  Sensors 
Abstract: 3D measurement of target objects characterized by specular reflection or subsurface scatterings cannot be measured by traditional 3D measurement methods because these targets have multiple light paths that make it difficult to determine the unique surface. We define these objects as complex light reflection objects. In this case, 3D measurement methods based on Light Transport (LT) Matrix estimation may be a solution to measure these complex light reflection objects, because LT Matrix captures every light path, and we can identify all 3D points on the target shape by using LT Matrix. However, these methods either provide low resolution results, or they are too slow for use in robot vision in practice. In this paper, we suppress the computational cost of LT Matrix estimation by dividing LT Matrix estimation into multi-scale. The proposed method reduces the number of candidate combinations between camera pixels and projector pixels greatly by using the information given by low resolution observations. The proposed algorithm allows high resolution measurement of the LT Matrix very efficiently. Furthermore, careful implementation of our method by using a sparse matrix representation achieves memory efficiency. We evaluated our method by measuring 3D points for a 256 × 256 resolution projector and camera system, which is an LT matrix 4096 times larger than that developed in our previous study [1] and 100 times faster than our naïve implementation of [2].


Title: Intelligent Shipwreck Search Using Autonomous Underwater Vehicles
Key Words: archaeology  autonomous underwater vehicles  control engineering computing  image processing  intelligent control  marine control  mobile robots  path planning  sonar  archaeological survey  intelligent shipwreck search  autonomous underwater vehicles  autonomous robot system  multistep pipeline  high altitude scan  low-resolution side scan sonar data  image processing software  AUV path planner  archaeological sites  underwater archaeological sites  ranking algorithm  Sonar  Proposals  Clustering algorithms  Pipelines  Feature extraction  Software 
Abstract: This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.


Title: Reinforcement Learning of Depth Stabilization with a Micro Diving Agent
Key Words: embedded systems  learning (artificial intelligence)  microrobots  multi-agent systems  robot programming  underwater vehicles  model-based value-function RL algorithm  micro underwater agents  underwater robotics  underwater depth stabilization  light embedded systems  control tasks  microdiving agent  reinforcement learning  Computational modeling  Learning (artificial intelligence)  Task analysis  Robot kinematics  Heuristic algorithms  Force 
Abstract: Reinforcement learning (RL) allows robots to solve control tasks through interaction with their environment. In this paper we study a model-based value-function RL approach, which is suitable for computationally limited robots and light embedded systems. We develop a diving agent, which uses the RL algorithm for underwater depth stabilization. Simulations and experiments with the micro diving agent demonstrate its ability to learn the depth stabilization task.


Title: Gaussian Process Adaptive Sampling Using the Cross-Entropy Method for Environmental Sensing and Monitoring
Key Words: bathymetry  entropy  Gaussian processes  learning (artificial intelligence)  mobile robots  optimisation  path planning  sampling methods  single ROI  deepest region  coastal bathymetry mapping mission validate  efficient sampling strategy  latest sensory measurements  sampling density  CE trajectory optimization  higher spatial variability  exhibit extreme sensory measurements  exploring learning  initial stage  path planning  GP-UCB  GP upper confidence  receding-horizon Cross-Entropy trajectory optimization  environmental sensing  cross-entropy method  Gaussian process adaptive sampling  Robot sensing systems  Adaptation models  Optimization  Predictive models  Trajectory  Uncertainty 
Abstract: In this paper, we focus on adaptive sampling on a Gaussian Processes (GP) using the receding-horizon Cross-Entropy (CE) trajectory optimization. Specifically, we employ the GP upper confidence bound (GP-UCB) as the optimization criteria to adaptively plan sampling paths that balance the exploitation-exploration trade-off. Path planning at the initial stage focuses on exploring and learning a model of the environment, and later, on exploiting the learned model to focus sampling around regions that exhibit extreme sensory measurements and much higher spatial variability, denoted as the Region of Interest (ROI). The integration of the CE trajectory optimization allows the sampling density to be dynamically adjusted based on the latest sensory measurements, thus providing an efficient sampling strategy for sensing and localizing the ROI. We demonstrate the effectiveness of the proposed method in exploring simulated scalar fields with single or multiple ROIs. Field experiments with an Unmanned Surface Vehicle (USV) in a coastal bathymetry mapping mission validate the approach's capability in quickly exploring and mapping the given area, and then focusing and increasing the sampling density around the deepest region, as a surrogate for e.g. the extremal concentration of a pollutant in the environment.


Title: Composable Deep Reinforcement Learning for Robotic Manipulation
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  composable deep reinforcement  model-free deep reinforcement learning  simulated robotic manipulation  model-free methods  real-world robotic tasks  maximum entropy policies  soft Q-learning  real-world robotic manipulation  Entropy  Robots  Learning (artificial intelligence)  Neural networks  Machine learning  Task analysis  Training 
Abstract: Model-free deep reinforcement learning has been shown to exhibit good performance in domains ranging from video games to simulated robotic manipulation and locomotion. However, model-free methods are known to perform poorly when the interaction time with the environment is limited, as is the case for most real-world robotic tasks. In this paper, we study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation. The application of this method to real-world manipulation is facilitated by two important features of soft Q-learning. First, soft Q-learning can learn multimodal exploration strategies by learning policies represented by expressive energy-based models. Second, we show that policies learned with soft Q-learning can be composed to create new policies, and that the optimality of the resulting policy can be bounded in terms of the divergence between the composed policies. This compositionality provides an especially valuable tool for real-world manipulation, where constructing new policies by composing existing skills can provide a large gain in efficiency over training from scratch. Our experimental evaluation demonstrates that soft Q-learning is substantially more sample efficient than prior model-free deep reinforcement learning methods, and that compositionality can be performed for both simulated and real-world tasks.


Title: Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning
Key Words: collision avoidance  decentralised control  gradient methods  learning (artificial intelligence)  mobile robots  multi-robot systems  multiscenario multistage training framework  optimal policy  policy gradient  reinforcement learning algorithm  learned sensor-level collision avoidance policy  final learned policy  collision-free paths  large-scale robot system  deep reinforcement learning  safe collision avoidance policy  efficient collision avoidance policy  optimally decentralized multirobot collision avoidance  agent-level feature extraction  decentralized methods  maps raw sensor measurements  multirobot systems  decentralized sensor-level collision avoidance policy  local collision-free action  distributed multirobot collision avoidance systems  Collision avoidance  Robot sensing systems  Robot kinematics  Navigation  Robustness  Training 
Abstract: Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots on rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. We validate the learned sensor-level collision avoidance policy in a variety of simulated scenarios with thorough performance evaluations and show that the final learned policy is able to find time efficient, collision-free paths for a large-scale robot system. We also demonstrate that the learned policy can be well generalized to new scenarios that do not appear in the entire training period, including navigating a heterogeneous group of robots and a large-scale scenario with 100 robots. Videos are available at https://sites.google.com/view/drlmaca.


Title: Overcoming Exploration in Reinforcement Learning with Demonstrations
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  reinforcement learning  reward function  task horizon  RL methods  exploration problem  multistep robotics tasks  robot arm  deep deterministic policy gradients  hindsight experience replay  simulated robotics tasks  Task analysis  Robots  Learning (artificial intelligence)  Stacking  Training  Mathematical model  Games 
Abstract: Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.


Title: Fast Image-Based Geometric Change Detection Given a 3D Model
Key Words: image reconstruction  image sequences  object detection  solid modelling  stereo image processing  fast image-based geometric change detection  multiple images  self-recorded image sequences  robotic applications  3D model  3D location  Three-dimensional displays  Solid modeling  Computational modeling  Cameras  Robots  Two dimensional displays  Uncertainty 
Abstract: 3D models of the environment are used in numerous robotic applications and should reflect the current state of the world. In this paper, we address the problem of quickly finding structural changes between the current state of the world and a given 3D model using a small number of images. Our approach finds inconsistencies between pairs of images by re-projecting an image onto another one by passing through the given 3D model. This process leads to ambiguities, which we resolve by combining multiple images such that the 3D location of the change can be estimated. A focus of our approach is that it can be executed fast enough to allow the operation on a mobile system. We implemented our approach in C++ and released it as open source software. We tested it on existing datasets as well as on self-recorded image sequences and 3D models, which we publicly share. Our experiments show that our method quickly finds changes in the geometry of a scene.


Title: Multimodal 2D Image to 3D Model Registration via a Mutual Alignment of Sparse and Dense Visual Features
Key Words: geometry  image registration  solid modelling  multimodal 2D image  3D model registration  dense visual features  2D/3D registration methods  geometric features  feature type  hybrid registration framework  visual sensors  3D model  Mutual Alignment  geometric visual features  sparse visual features  2D/3D alignment  Three-dimensional displays  Cameras  Solid modeling  Visualization  Feature extraction  Two dimensional displays  Sensors 
Abstract: Many fields of application could benefit from an accurate registration of measurements of different modalities over a known 3D model. However, aligning a 2D image to a 3D model is a challenging task and is even more complex when the two have a different modality. Most of the 2D/3D registration methods are based on either geometric or dense visual features. Both have their own advantages and their own drawbacks. We propose, in this paper, to mutually exploit the advantages of one feature type to reduce the drawbacks of the other one. For this, an hybrid registration framework has been designed to mutually align geometrical and dense visual features in order to obtain an accurate final 2D/3D alignment. We evaluate and compare the proposed registration method on real data acquired by a robot equipped with several visual sensors. The results highlights the robustness of the method and its ability to produce wide convergence domain and a high registration accuracy.


Title: Adaptive Sampling and Online Learning in Multi-Robot Sensor Coverage with Mixture of Gaussian Processes
Key Words: Gaussian processes  learning (artificial intelligence)  multi-robot systems  optimisation  online learning  multirobot sensor coverage  online environmental sampling  multirobot coverage control  environmental phenomenon  robot team  Gaussian Process  locally learned Gaussian Processes  collective model learning  simultaneous adaptive sampling  density function  sensing performance optimization  Robot sensing systems  Adaptation models  Density functional theory  Temperature distribution  Data models 
Abstract: We consider the problem of online environmental sampling and modeling for multi-robot sensor coverage, where a team of robots spread out over the workspace in order to optimize the overall sensing performance. In contrast to most existing works on multi-robot coverage control that assume prior knowledge of the distribution of environmental phenomenon, also known as density function, we relax this assumption and enable the robot team to efficiently learn the model of the unknown density function Online using adaptive sampling and non-parametric inference such as Gaussian Process (GP). To capture significantly different components of the environmental phenomenon, we propose a new approach with mixture of locally learned Gaussian Processes for collective model learning and an information-theoretic criterion for simultaneous adaptive sampling in multi-robot coverage. Our approach demonstrates a better generalization of the environment modeling and thus the improved performance of coverage without assuming the density function is known a priori. We demonstrate the effectiveness of our algorithm via simulations of information gathering from indoor static sensors.


Title: Coordinated Dense Aerial Traffic with Self-Driving Drones
Key Words: air traffic control  autonomous aerial vehicles  collision avoidance  decentralised control  multi-robot systems  coordinated dense aerial traffic  general air traffic control solution  decentralized air traffic control solution  package-delivery scenarios  intelligent collective collision avoidance  motion planning  jam-free optimal traffic flow  force-based distributed multirobot control model  behaviour-driven velocity alignment  self-organized queueing  conflict-avoiding self-driving  Drones  Mathematical model  Atmospheric modeling  Oscillators  Acceleration  Task analysis  Roads 
Abstract: In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.


Title: Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems
Key Words: decision making  multi-agent systems  multi-robot systems  planning (artificial intelligence)  multirobot  small-scale synchronous decision-making scenarios  asynchronous agents  multiple strategic adversaries  adversary strategies  optimized stratagems  unified policy  near-optimality  optimal adversarial policy switching  decentralized asynchronous multiagent systems  communication capabilities  Switches  Planning  Task analysis  Robot kinematics  Probabilistic logic 
Abstract: A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.


Title: Data Ferrying with Swarming UAS in Tactical Defence Networks
Key Words: mobile robots  multi-robot systems  harsh communication environments  UAS  human-swarm interaction  data dissemination capabilities  indoor flight facilities  physical swarm robotic platforms  radio-frequency communications  swarm members  tactical defence networks  Emulation  Convergence  Australia  Radio frequency  Data models  Robot kinematics 
Abstract: In this paper we categorise swarming into four classes, depending on the manner in which swarm members communicate. We identify two of these classes as ready candidates for the provision of communications within tactical defence networks in which radio-frequency communications are highly contested or denied. We demonstrate the feasibility of a swarm-robotics approach to data ferrying from both of these classes using simulation, emulation, and physical swarm robotic platforms within indoor flight facilities. The results show strong alignment between data dissemination capabilities of the simulated and physical systems; we envisage these techniques providing communications between not only troops, but also other swarm robotic platforms, thereby enabling swarm robotics applications and human-swarm interaction within harsh communications environments.


Title: Distance-Based Multi-Robot Coordination on Pocket Drones
Key Words: learning (artificial intelligence)  particle filtering (numerical methods)  recurrent neural nets  remotely operated vehicles  Deep Q-Learning Network  recurrent network  UWB-distance information  neural networks  distance-based multirobot coordination  pocket drones  MicroAerial Vehicles  recurrent neural network  Drones  Robot kinematics  Recurrent neural networks  Hardware  Robot sensing systems  Distance measurement 
Abstract: We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.


Title: Cooperative Adaptive Control for Cloud-Based Robotics
Key Words: adaptive control  cloud computing  control engineering computing  control system synthesis  decentralised control  Lyapunov methods  manipulators  multi-robot systems  adaptive control  robot manipulators  synchronous centralized update laws  parameter convergence  time-varying network topologies  nonidealized networked conditions  planar manipulator  cloud-based robotics  inertial parameters  collective sufficient richness notion  decentralized update laws  Adaptive control  Manipulators  Convergence  Robot sensing systems  Cloud computing  Trajectory 
Abstract: This paper studies collaboration through the cloud in the context of cooperative adaptive control for robot manipulators. We first consider the case of multiple robots manipulating a common object through synchronous centralized update laws to identify unknown inertial parameters. Through this development, we introduce a notion of Collective Sufficient Richness, wherein parameter convergence can be enabled through teamwork in the group. The introduction of this property and the analysis of stable adaptive controllers that benefit from it constitute the main new contributions of this work. Building on this original example, we then consider decentralized update laws, time-varying network topologies, and the influence of communication delays on this process. Perhaps surprisingly, these nonidealized networked conditions inherit the same benefits of convergence being determined through collective effects for the group. Simple simulations of a planar manipulator identifying an unknown load are provided to illustrate the central idea and benefits of Collective Sufficient Richness.


Title: Put-in-Box Task Generated from Multiple Discrete Tasks by aHumanoid Robot Using Deep Learning
Key Words: feature extraction  humanoid robots  learning (artificial intelligence)  manipulators  recurrent neural nets  multiple discrete tasks  deep learning  deep neural networks  robot manipulation model  DNNs  long sequential dynamic tasks  multiple short sequential tasks  multiple timescale recurrent neural network  MTRNN  initial motion steps  final motion steps  initial image input  subtask  put-in-box task  Task analysis  Robots  Feature extraction  Switches  Neurons  Training  Convolution 
Abstract: For robots to have a wide range of applications, they must be able to execute numerous tasks. However, recent studies into robot manipulation using deep neural networks (DNN) have primarily focused on single tasks. Therefore, we investigate a robot manipulation model that uses DNNs and can execute long sequential dynamic tasks by performing multiple short sequential tasks at appropriate times. To generate compound tasks, we propose a model comprising two DNNs: a convolutional autoencoder that extracts image features and a multiple timescale recurrent neural network (MTRNN) to generate motion. The internal state of the MTRNN is constrained to have similar values at the initial and final motion steps; thus, motions can be differentiated based on the initial image input. As an example compound task, we demonstrate that the robot can generate a “Put-In-Box” task that is divided into three subtasks: open the box, grasp the object and put it into the box, and close the box. The subtasks were trained as discrete tasks, and the connections between each subtask were not trained. With the proposed model, the robot could perform the Put-In-Box task by switching among subtasks and could skip or repeat subtasks depending on the situation.


Title: CASSL: Curriculum Accelerated Self-Supervised Learning
Key Words: grippers  learning (artificial intelligence)  sensitivity analysis  adaptive-underactuated multifingered gripper  curriculum accelerated self-supervised learning  variance-based global sensitivity analysis  control parameters  control dimensions  training data  CASSL orders  higher-dimensional action  map visual information  clever sampling strategy  data collection efforts  higher-dimensional control  low-dimensional action  self-supervised learning approaches  complete end-to-end learning  staged curriculum learning  CASSL framework  Aerospace electronics  Grasping  Training  Task analysis  Robots  Sensitivity analysis 
Abstract: Recent self-supervised learning approaches focus on using a few thousand data points to learn policies for high-level, low-dimensional action spaces. However, scaling this framework for higher-dimensional control requires either scaling up the data collection efforts or using a clever sampling strategy for training. We present a novel approach - Curriculum Accelerated Self-Supervised Learning (CASSL) - to train policies that map visual information to high-level, higher-dimensional action spaces. CASSL orders the sampling of training data based on control dimensions: the learning and sampling are focused on few control parameters before other parameters. The right curriculum for learning is suggested by variance-based global sensitivity analysis of the control space. We apply our CASSL framework to learning how to grasp using an adaptive, underactuated multi-fingered gripper, a challenging system to control. Our experimental results indicate that CASSL provides significant improvement and generalization compared to baseline methods such as staged curriculum learning (8% increase) and complete end-to-end learning with random exploration (14% improvement) tested on a set of novel objects.


Title: Q-CP: Learning Action Values for Cooperative Planning
Key Words: iterative methods  learning (artificial intelligence)  learning systems  mobile robots  Monte Carlo methods  multi-robot systems  navigation  path planning  state-space methods  stochastic games  tree searching  uncertain systems  multirobot systems  manifold applications  unstructured scenarios  state dimensionality  model-based reinforcement learning algorithm  Q-learning  curse-of-dimensionality  cooperation scenario  mobile robots  robot behaviors  uncertainties  state space exploration  action values learning  stochastic cooperative games  cooperative navigation problem  cooperative planning  Monte-Carlo tree search iterations  general-sum games  KUKA YouBots  robot hand-overs  coordination task  Robot kinematics  Games  Monte Carlo methods  Task analysis  Planning  Stochastic processes 
Abstract: Research on multi-robot systems has demonstrated promising results in manifold applications and domains. Still, efficiently learning an effective robot behaviors is very difficult, due to unstructured scenarios, high uncertainties, and large state dimensionality (e.g, hyper-redundant and groups of robot). To alleviate this problem, we present Q-CP a cooperative model-based reinforcement learning algorithm, which exploits action values to both (1) guide the exploration of the state space and (2) generate effective policies. Specifically, we exploit Q-learning to attack the curse-of-dimensionality in the iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on different stochastic cooperative (general-sum) games: (1) a simple cooperative navigation problem among 3 robots, (2) a cooperation scenario between a pair of KUKA YouBots performing hand-overs, and (3) a coordination task between two mobile robots entering a door. The obtained results show the effectiveness of Q- CP in the chosen applications, where action values drive the exploration and reduce the computational demand of the planning process while achieving good performance.


Title: Radiation Source Localization in GPS-Denied Environments Using Aerial Robots
Key Words: gamma-ray detection  Global Positioning System  mobile robots  photomultipliers  radioactive sources  radioactivity measurement  solid scintillation detectors  radiation measurements  radioactive source localization  radiation mapping  thallium-doped cesium iodide scintillator  indoor GPS-denied environments  Cesium-137 radiation source  GPS-denied localization  visual-inertial localization  autonomous nuclear radiation source localization  aerial robot  Scintillators  Calibration  Robot sensing systems  Detectors  Unmanned aerial vehicles  Radiation detectors 
Abstract: This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.


Title: LineDrone Technology: Landing an Unmanned Aerial Vehicle on a Power Line
Key Words: aircraft landing guidance  autonomous aerial vehicles  cameras  electrical maintenance  helicopters  inspection  optical radar  power overhead lines  remotely operated vehicles  robot vision  sensor fusion  LineDrone Technology  unmanned aerial vehicle landing  semiautomatic landing  vehicle onboard vision system  monocular camera  lidar  nondestructive testing  multirotor unmanned aerial vehicle capable  power transmission lines  landing assistance  Cameras  Payloads  Unmanned aerial vehicles  Inspection  Laser radar  Task analysis  Machine vision 
Abstract: This paper presents the design of a multirotor unmanned aerial vehicle (UAV) capable of landing semiautomatically on a power line while carrying a payload. The vehicle then rolls along the line to perform an inspection. Special attention is given to the vehicle's onboard vision system, which consists of a monocular camera and LiDAR used together to compute the pose of the vehicle relative to the power line. Landing assistance is provided to the pilot by a position-based visual controller that aligns and keeps the vehicle centered along the power line. The pilot remains in control of vertical and longitudinal movement during descent. The proposed approach was tested on a full-scale test line and shows promise for future applications of high value to the electric industry such as non-destructive testing of power transmission lines.


Title: Direction Controlled Descent of Samara Autorotating Wings (SAW) with N-Wings * Research supported by the SUTD-MIT International Design Centre (IDC) and by the Temasek Laboratories Defence Innovation Research Programme (DIRP) IGDSP15020141.
Key Words: aerospace components  gyroscopes  mechanical stability  numerical analysis  position control  wind tunnels  direction controlled descent  spinning wing  direction controllability  control schemes  conical spiral autorotation trajectory  gyroscopic stability  maple trees  translational motion  numerical simulations  multiwing SAW prototype  wind-tunnel  samara autorotating wings  ball joint  Surface acoustic waves  Blades  Prototypes  Rotors  Mathematical model  Solid modeling  Stability analysis 
Abstract: The seeds of Maple trees (Samara) use autorotation as a unique mechanism to disperse their seeds. By exploiting gyroscopic stability of a spinning wing, the Samara is able to cover large horizontal distance despite having no form of propulsion. We applied and adapted this natural ability in our novel concept, the Samara Autorotating Wings (SAW), and extended its stability and direction controllability by generalizing the mechanism to incorporate designs with more than 1 wing. By conceiving cyclic control, the translational motion of autorotation is regulated. A nonlinear model of SAW with n wings is derived and control schemes developed to control the translational position during autorotation. Numerical simulations were performed to investigate the performance of the multi-wing SAW prototypes to track a conical spiral autorotation trajectory. Direct experiments were conducted in a vertical wind-tunnel through a special ball joint that allows z-axis translation and all three rotational degrees of freedom. Finally, free-fall drop tests are used to verify the directional controllability and performance of SAW.


Title: Pseudo-bearing Measurements for Improved Localization of Radio Sources with Multirotor UAVs
Key Words: autonomous aerial vehicles  directive antennas  helicopters  mobile radio  mobile robots  omnidirectional antennas  radionavigation  pseudobearing measurements  radio frequency sources  RF source  directional antenna  omnidirectional antenna  antenna theory  ground tests  multirotor UAVs  radio sources localization  bearing-like measurements  unmanned aerial vehicles  Antenna measurements  Directional antennas  Gain  Radio frequency  Extraterrestrial measurements  Rotation measurement 
Abstract: Localizing radio frequency (RF) sources is an important application for unmanned aerial vehicles (UAVs), Localization is often carried out by estimating bearing to an RF source, which can be achieved by rotating a directional antenna in place. Multirotor UAVs are well-suited for this sensing modality because they can efficiently rotate in place. However, a full rotation from a single location is needed to account for scale factors affecting the directional antenna's measurements. Although easy to perform, these rotations tend to be slow and delay localization. In this paper, we equip a multirotor UAV with a directional antenna and an omnidirectional antenna. The omnidirectional antenna serves to normalize measurements made by the directional antenna, yielding “pseudo-bearing” measurements. These bearing-like measurements are less informative than bearing measurements but do not require a full rotation, leading to more measurements and faster localization. We validate the normalization with antenna theory and ground tests. Claims of improved localization are validated with simulations and flight tests on a multirotor UAV. Our setup significantly reduces localization time compared to a multirotor UAV equipped with only a directional antenna.


Title: Onboard State Dependent LQR for Agile Quadrotors
Key Words: aircraft control  attitude control  autonomous aerial vehicles  control system synthesis  helicopters  linear quadratic control  mobile robots  state estimation  time-varying systems  trajectory control  onboard state dependent LQR  agile quadrotors  quadrotor control  multiple cascaded subproblems  rotational dynamics  translational dynamics  cascaded attitude controller  attitude dynamics  robustness  LQR controller  rotational states  translational states  time-varying system dynamics  control parameters  linearization  Vehicle dynamics  Acceleration  Trajectory  Quaternions  Attitude control  Visualization  Regulators 
Abstract: State-of-the-art approaches in quadrotor control split the problem into multiple cascaded subproblems, exploiting the different time scales of the rotational and translational dynamics. They calculate a desired acceleration as input for a cascaded attitude controller but omit the attitude dynamics. These approaches use limits on the desired acceleration to maintain feasibility and robustness through the control cascade. We propose an implementation of an LQR controller, which: (I) is linearized depending on the quadrotor's state; (II) unifies the control of rotational and translational states; (III) handles time-varying system dynamics and control parameters. Our implementation is efficient enough to compute the full linearization and solution of the LQR at a minimum of 10 Hz on the vehicle using a common ARM processor. We show four successful experiments: (I) controlling at hover state with large disturbances; (II) tracking along a trajectory; (III) tracking along an infeasible trajectory; (IV) tracking along a trajectory with disturbances. All the experiments were done using only onboard visual inertial state estimation and LQR computation. To the best of our knowledge, this is the first implementation and evaluation of a state-dependent LQR capable of onboard computation while providing this amount of versatility and performance.


Title: Towards X-Ray Medical Imaging with Robots in the Open: Safety Without Compromising Performances
Key Words: collision avoidance  control engineering computing  end effectors  linear quadratic control  manipulator dynamics  medical image processing  medical robotics  mobile robots  motion control  robot vision  control solution  robotic manipulator  generic safe controller  Linear Quadratic Problem formulation  unified energetic formulation  kinetic energy  redundant Kuka LWR4+ robot  X-ray medical imaging  end-effector  Robots  Task analysis  Torque  Safety  Collision avoidance  X-ray imaging  Aerospace electronics 
Abstract: In this paper, a control solution featuring an energetic constraint is developed to improve the safety of a robotic manipulator sharing its workspace with humans. This general control structure, exploits a generic safe controller that ensures the respect of multiple constraints thanks to a Linear Quadratic Problem formulation. With a unified energetic formulation, the controller allows to explicitly limit both the kinetic energy when moving and the wrench applied to the environment in case of contact with an unexpected obstacle. This control approach is experimented on a redundant Kuka LWR4+ robot which end-effector shall precisely point toward a given location while following a trajectory.


Title: Semi-Autonomous Laparoscopic Robotic Electro-Surgery with a Novel 3D Endoscope
Key Words: biomedical optical imaging  endoscopes  kidney  medical image processing  medical robotics  surgery  3D endoscope  robotic surgical system  cutting depth  freedom electro-surgical tool  robotic system  imaging system  laparoscopic camera  open loop control scheme  porcine cadaver kidney  robotic laparoscopic surgery system  semiautonomous laparoscopic robotic electro-surgery  Robots  Imaging  Surgery  Three-dimensional displays  Laparoscopes  Kidney  Task analysis 
Abstract: This paper reports a robotic laparoscopic surgery system performing electro-surgery on porcine cadaver kidney, and evaluates its accuracy in an open loop control scheme to conduct targeting and cutting tasks guided by a novel 3D endoscope. We describe the design and integration of the novel laparoscopic imaging system that is capable of reconstructing the surgical field using structured light. A targeting task is first performed to determine the average positioning error of the system as guided by the laparoscopic camera. The imaging system is then used to reconstruct the surface of a porcine cadaver kidney, and generate a cutting trajectory with consistent depth. The paper concludes by using the robotic system in open loop control to cut this trajectory using a multi degree of freedom electro-surgical tool. It is demonstrated that for a cutting depth of 3 mm, the robotic surgical system follows the trajectory with an average depth of 2.44 mm and standard deviation of 0.34 mm. The average positional accuracy of the system was 2.74±0.99 mm.


Title: An Ultrasonic Bone Cutting Tool for the da Vinci Research Kit
Key Words: biomedical transducers  biomedical ultrasonics  bone  finite element analysis  genetic algorithms  medical robotics  surgery  ultrasonic transducers  finite element software  cutting phantom  research kit system  ultrasonic system  multiobjective genetic algorithm  ultrasonic transducer  minimally invasive ultrasonic bone cutting tool  da Vinci research kit  Acoustics  Impedance  Finite element analysis  Transducers  Bones  Surgery  Cutting tools 
Abstract: This paper presents a minimally invasive ultrasonic bone cutting tool designed for the da Vinci® research kit (dVRK). An ultrasonic transducer is modelled using finite element software, and correlated with testing results using an impedance analyzer. A multi-objective genetic algorithm is then used to design and analyze the remaining components of the ultrasonic system, in order to maximize system performance. The system is fabricated and mounted to the da Vinci® research kit system and tested on a cutting phantom.


Title: Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
Key Words: aircraft control  autonomous aerial vehicles  game theory  helicopters  mobile robots  multi-robot systems  optimal control  path planning  trajectory control  multiple quadrotors  flag game  distributed trajectory planning algorithm  WiFi based communication infrastructure  autopilot modules  low power computing modules  suboptimal control action  adversarial game  Gazebo robot simulator  multiple UAVs  quadrotor platform  flight testing  robot operating system  ROS  Games  Software algorithms  Software  Hardware  Real-time systems  Testing  Computational modeling 
Abstract: We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.


Title: Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View
Key Words: aerospace computing  autonomous aerial vehicles  groupware  image fusion  Kalman filters  multi-robot systems  nonlinear filters  pose estimation  robot vision  stereo image processing  monocular-inertial odometry  Extended Kalman Filter  collaborative scene estimation  monocular camera  variable-baseline stereo rig  inertial sensor  Unmanned Aerial Vehicles  collaborative robot operation  collaborative 6DoF relative pose estimation  UAV  Cameras  Simultaneous localization and mapping  Collaboration  Estimation  Unmanned aerial vehicles 
Abstract: Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.


Title: Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots
Key Words: approximation theory  computational complexity  graph theory  multi-robot systems  optimisation  path planning  O(n3) time complexity  optimal assignments  multiple robots  fixed goal formations  standard assignment problem  transformed problem  formation parameters  linear sum assignment problem  variable goal formation problem  location parameters  Collision avoidance  Robot kinematics  Trajectory  Shape  Cost function 
Abstract: This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.


Title: Machine Learning for Placement-Insensitive Inertial Motion Capture
Key Words: calibration  image motion analysis  image sensors  multilayer perceptrons  sensor positions  body segments  standard deviation  calibration values  rotation matrices  inertial motion-capture systems  latency errors  motion data  sensor-displacement patterns  multilayer perceptrons  rotational transformations  kinematic algorithms  sensor movement  performance degradation  Euler angles  placement-insensitive inertial motion capture  machine learning  joint angles  sensor data  time 3.0 hour  Tracking  Robot sensing systems  Motion segmentation  Machine learning  Calibration  Kinematics  Neural networks 
Abstract: Although existing inertial motion-capture systems work reasonably well (≤10° error in Euler angles), their accuracy suffers when sensor positions change relative to the associated body segments (±60° mean error and 120° standard deviation). We attribute this performance degradation to undermined calibration values, sensor movement latency and displacement offsets. The latter specifically leads to incongruent rotation matrices in kinematic algorithms that rely on rotational transformations. To overcome these limitations, we propose to employ machine-learning techniques. In particular, we use multi-layer perceptrons to learn sensor-displacement patterns based on 3 hours of motion data collected from 12 test subjects in the lab over 215 trials. Furthermore, to compensate for calibration and latency errors, we directly process sensor data with deep neural networks and estimate the joint angles. Based on these approaches, we demonstrate up to 69% reduction in tracking errors.


Title: Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace
Key Words: actuators  biomechanics  feedback  medical robotics  optimisation  patient rehabilitation  robot dynamics  robot kinematics  wrist robots  analytical stiffness model  bounded nonlinear multiobjective optimization  parallel architecture  wearable hip  ankle  parallel-actuated robotic shoulder exoskeleton  sagittal plane  Shoulder  Actuators  Exoskeletons  Kinematics  End effectors 
Abstract: The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.


Title: Grasp Planning for Load Sharing in Collaborative Manipulation
Key Words: dexterous manipulators  force control  grippers  human-robot interaction  industrial manipulators  lifting  manipulators  collaborative manipulation  manipulation task  grasp location  human robot collaborative lifting task  grasp planning  grasp analysis approach  load sharing  partial observability  two-agent decentralized set-up  Task analysis  Robot kinematics  Planning  Collaboration  Force  Quadratic programming 
Abstract: In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.


Title: Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration
Key Words: feature extraction  learning (artificial intelligence)  pattern classification  robots  LfD scenarios  human feature selection  robot learner  informative features  multiclass classification task  computational feature selection  human selected features  informative task features  general-purpose robot  learning computation  robotic agent learning classification tasks  human-driven feature selection  Task analysis  Feature extraction  Robots  Training  Training data  Object recognition  Support vector machines 
Abstract: The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.


Title: Deep Auxiliary Learning for Visual Localization and Odometry
Key Words: distance measurement  feature extraction  learning (artificial intelligence)  neural nets  pose estimation  video signal processing  state-of-the-art SIFT-based approaches  deep learning technique  multitask learning  Geometric Consistency Loss  visual odometry estimation  global localization  parameter sharing  multitask model  consecutive monocular images  VLocNet  convolutional neural networks  action execution  robot  visual localization  Task analysis  Visual odometry  Estimation  Visualization  Training  Robustness 
Abstract: Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.


Title: Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
Key Words: aerospace control  autonomous aerial vehicles  closed loop systems  mobile robots  optimisation  position control  propellers  closed-loop aerial transformation  aerial grasping  shape adaptive transformation  aerial manipulation  HALO  horizontal plane transformable aerial robot  closed-loop multilinks structure  flight control  serial-link structure  propeller  optimization planning method  Unmanned aerial vehicles  Propellers  Shape  Grasping  Servomotors  Force  End effectors 
Abstract: In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.


Title: Towards a Flying Assistant Paradigm: the OTHex
Key Words: autonomous aerial vehicles  control system synthesis  estimation theory  geometry  manipulators  mobile robots  robust control  trajectory control  maintenance tasks  task-driven custom design  experimental validations  control framework  low-level geometric controller  external wrench estimator  admittance filter  trajectory generator  external force disturbances  Flying Assistant paradigm  OTHex platform  aerial manipulation  LAAS-CNRS  multidirectional thrust platform  human operators  long bars  assembly tasks  ground manipulators  Propellers  Bars  Trajectory  Robots  Task analysis  Admittance  Force 
Abstract: This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.


Title: LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation
Key Words: decentralised control  hydraulic actuators  machine control  rotors  valves  robotic system  LASDRA  valve turning  trajectory tracking  strong/sturdy base actuator/structure  actuators  hydraulic actuation  large-size aerial skeleton system  large-size dexterously-articulated robot  internal actuation  external actuation  distributed rotors  distributed rotor actuation  Rotors  Robots  Force  Loading  Torque  Hydraulic systems  Actuators 
Abstract: Electrical motor and hydraulic actuation widely-used in robotics are “internal actuation” with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as “external actuation”, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.


Title: A Flying Gripper Based on Cuboid Modular Robots
Key Words: autonomous aerial vehicles  grippers  helicopters  mobile robots  multi-robot systems  position control  degree of freedom  four-bar linkage  aperture angle  cuboid frame  docking mechanism  vertical edges  grasp object  cuboid modular robots  flying Gripper  hovering performance  DOF  Grippers  Apertures  Robots  Rotors  Grasping  Propellers  Shape 
Abstract: We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.


Title: Faster R-CNN with Classifier Fusion for Small Fruit Detection
Key Words: convolution  crops  feedforward neural nets  image classification  image fusion  object detection  probability  recurrent neural nets  robot vision  multiple classifiers  classifier correlation  small fruit detection  Faster R-CNN network  multiple classifier fusion  objectness classification  probabilities  agricultural robots  Proposals  Correlation  Feature extraction  Image segmentation  Machine learning  Robots  Adaptation models 
Abstract: The-state-of-the-art of fruit detection with Faster R-CNN shows lack of detection advantage on small fruits. One of reasons is only single level features is used for localization of proposal candidates. In this paper, we propose to incorporate a multiple classifier fusion strategy into a Faster R-CNN network for small fruit detection. We utilize features from three different levels to learn three classifiers for objectness classification in the stage of proposal localization. Probabilities from classifiers are combined by a simple convolutional layer to generate final objectness classification for proposal candidates. In order to keep diversity of multiple classifiers, a novel loss term of classifier correlation is introduced into original loss function. Experimental results show that our model is feasible for detecting small fruits.


Title: Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration
Key Words: humanoid robots  learning systems  manipulator kinematics  probability  trajectory control  joint space  motion constraints  probabilistic formulation  dynamic movement primitives  probabilistic treatment  trajectory constraints  hybrid space learning  motion smoothness  robot null-space  hybrid probabilistic trajectory optimization  null-space exploration  Cartesian space  learning from demonstration  Jacobian-based inverse kinematics  Probabilistic logic  Task analysis  Robot kinematics  Acceleration  Trajectory optimization 
Abstract: In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.


Title: Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion
Key Words: distance measurement  mobile robots  motion control  motion estimation  position control  robot vision  motion estimation process  positioning inaccuracy  structured environments  rotational motion  drift-free rotation  SO(3)-manifold constrained mean shift algorithm  multiple orthogonal planes  rotation estimate  structural regularities  drift-free rotational motion  low-drift visual odometry algorithm  translational motion  Cameras  Tracking  Three-dimensional displays  Estimation  Visual odometry  Feature extraction  Image segmentation 
Abstract: We present a low-drift visual odometry algorithm that separately estimates rotational and translational motion from lines, planes, and points found in RGB-D images. Previous methods estimate drift-free rotational motion from structural regularities to reduce drift in the rotation estimate, which is the primary source of positioning inaccuracy in visual odometry. However, multiple orthogonal planes are required to be visible throughout the entire motion estimation process; otherwise, these VO approaches fail. We propose a new approach to estimate drift-free rotational motion jointly from both lines and planes by exploiting environmental regularities. We track the spatial regularities with an efficient SO(3)-manifold constrained mean shift algorithm. Once the drift-free rotation is found, we recover the translational motion from all tracked points with and without depth by minimizing the de-rotated reprojection error. We compare the proposed algorithm to other state-of-the-art visual odometry methods on a variety of RGB-D datasets (including especially challenging pure rotations) and demonstrate improved accuracy and lower drift error.


Title: Selection and Compression of Local Binary Features for Remote Visual SLAM
Key Words: feature extraction  feature selection  mobile robots  multi-robot systems  robot vision  SLAM (robots)  feature selection stage  remote visual SLAM  autonomous robotics  collaborative SLAM approaches  multiple robots  feature coding scheme  simultaneous localization and mapping  visual sensors  embedded devices  local binary features extraction  centralized powerful processing node  Visualization  Encoding  Simultaneous localization and mapping  Feature extraction  Task analysis  Image coding 
Abstract: In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.


Title: Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand
Key Words: automobiles  collision avoidance  mobile robots  optimal control  optimisation  road traffic  scheduling  potential collision situations  road geometries  joint motion plans  multivehicle motion planning  road network  Vienna Convention  desired deadlines  integrated route  road traffic  motion planning problem  social optimal mobility-on-demand  self-driving cars  bubble spaces  queue scheduling  Roads  Planning  Delays  Task analysis  Sensors  Trajectory  Automobiles 
Abstract: In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.


Title: Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty
Key Words: control engineering computing  formal specification  mobile robots  multi-robot systems  operating systems (computers)  path planning  temporal logic  probabilistic options  temporal logic-based multirobot cooperation  temporal dependencies  task specification  robot team  temporal logic specifications  goal specification  ROS implementation  Robot kinematics  Task analysis  Uncertainty  Planning  Resource management  Probabilistic logic 
Abstract: Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.


Title: GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability
Key Words: actuators  belts  drives  grippers  legged locomotion  manipulator kinematics  motion control  springs (mechanical)  finger  synchronous belt drive  underactuated graspers  serial kinematic chain  scalable kinematic structure  kinematic analysis  prototype robot  multimodal locomotion  robotic platform  active gripping surface  underactuated fingers  multipurpose grasper  manipulation  grasping  GraspMan  Grasping  Belts  Actuators  Task analysis  Grippers  Manipulators 
Abstract: In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as “legs” or “wheels” of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.


Title: A Robust Robot Design for Item Picking
Key Words: calibration  cameras  grippers  industrial manipulators  learning (artificial intelligence)  path planning  robot vision  service robots  feature-based comparison  gripper system  grasping strategy  robust performance  target items  robot system  dual 6 degrees of freedom industrial arms  error recovery strategies  fixed calibrated frame  multiple stereo cameras  vision system  custom-designed top-open extendable shelf  calibrated table  fixed bases  module designs  component selection  motion planning  system requirements  Amazon Robotics Challenge  reliable system  stable system  item picking  robust robot design  Cameras  Manipulators  Task analysis  Planning  Service robots  Robot vision systems 
Abstract: In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.


Title: A Soft Robot for Random Exploration of Terrestrial Environments
Key Words: control engineering computing  industrial robots  mass production  microrobots  motion control  multi-robot systems  soft robot  random exploration  terrestrial environments  unknown terrains  adequate locomotion strategy  fast exploration  obstacles negotiation  mass manufacturing  minimalistic design  roll  soft cage  swarm operations  randomly moving miniature robots  Robots  Propellers  Aerodynamics  Shock absorbers  Batteries 
Abstract: A swarm of randomly moving miniature robots is an effective solution for the exploration of unknown terrains. However, the deployment of a swarm of miniature robots poses two challenges: finding an adequate locomotion strategy for fast exploration and obstacles negotiation; and implementing simple design and control solutions suited for mass manufacturing. Here, we tackle these challenges by developing a new soft robot with a minimalistic design and a simple control strategy that can randomly propel itself above obstacles and roll on the ground upon landing. The robot is equipped with two propellers that are periodically activated to jump, a soft cage that protects the robot from impacts and allows to passively roll on the ground, and a passive self-righting mechanism for repetitive jumps. The minimalistic control and design reduce the complexity of the mechanics and electronics and are instrumental to the production of a large number of robots. In the paper, the key design aspects of the robot are discussed, the locomotion of a single prototype is experimentally characterized, and improvements of the system for future swarm operations are discussed.


Title: Intent-Aware Multi-Agent Reinforcement Learning
Key Words: aerospace robotics  control engineering computing  decision theory  function approximation  learning (artificial intelligence)  Markov processes  multi-agent systems  planning (artificial intelligence)  robot dynamics  low-level planning algorithms  intent-aware multiagent reinforcement learning  learning algorithm  planning process  partially observable Markov decision process  linear function approximation  intent-aware multiagent planning  aerial robots  human interaction  dynamic process  POMDP  Planning  Prediction algorithms  Automata  Vehicles  History  Computational modeling 
Abstract: This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.


Title: Probabilistic Graph Security for Networked Multi-Robot Systems
Key Words: binary decision diagrams  Boolean functions  graph theory  mobile robots  multi-robot systems  probability  networked multirobot systems  robot interactions  existing control-theoretic notion  network attacks  left invertibility  dynamical system  probabilistic robot communication  adversarial influence  probabilistic graph security problem  system reliability  efficient graphical representation  binary decision diagrams  networked MRS  mobile multirobot teams  mobile MRS  reduced order BDD  Robot sensing systems  Probabilistic logic  Observers  Security  Boolean functions 
Abstract: In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time.


Title: Controlling the Interaction of a Multi-Robot System with External Entities
Key Words: force control  multi-robot systems  external entities  dynamic interaction model  multirobot system  interaction control  local deformations  coupling actions  passivity property  safety guarantees  Robots  Couplings  Multi-robot systems  Dynamics  Force  Damping  Collision avoidance 
Abstract: In this paper we consider a multi-robot system that shares the environment with external entities, and we propose a methodology for controlling the interaction with them. In particular, we consider the problem of achieving a desired dynamic interaction model, in such a way that the multi-robot system exchanges desired forces with external entities. This is obtained by introducing local deformations of the coupling actions among the robots. The proposed method ensures preservation of the passivity property, which provides safety guarantees in the interaction with the (possibly poorly known) external entities.


Title: Network Topology Inference in Swarm Robotics
Key Words: graph theory  inference mechanisms  multi-robot systems  network theory (graphs)  swarm intelligence  network topology inference  swarm robotics  topological graph  swarm intelligence  Trajectory  Robots  Network topology  Acceleration  Australia  Mathematical model  Atmospheric measurements 
Abstract: Swarm robotics refers to the implementation of swarm intelligence features like autonomy and self-organization to a collective of robots. This study focuses on the construction of a topological graph that represents both the magnitude and orientation of swarm interactions. Such structure is used for identifying global parameters like leadership and to derive a relationship between the distribution of interaction magnitudes and swarm parameters. Interaction magnitudes were derived from the trajectory distance between nearest neighbors and it was found that the distribution is able to differentiate between only a small subset of controllers, communication ranges and swarm sizes. Leader detection was based on the analysis of position vectors orientation in local neighborhoods. The method was successful at a 100% rate for 10 and 30 robots, while for 60 a minimum rate of 67% was obtained. Additionally, processing times never exceeded a simulation duration for swarms up to 30 robots, with the potential to parallelize for larger sizes.


Title: Using Hardware Specialization and Hierarchy to Simplify Robotic Swarms
Key Words: mobile robots  multi-robot systems  work distribution  hardware specialization  classical distributed robotics problem  robotic swarms  simulated environment  shape formation  Shape  Task analysis  Hardware  Robot sensing systems  Legged locomotion  Collision avoidance 
Abstract: Specialization has always been a tool for work distribution and simplification in nature and in distributed robotics. We present a novel approach to use hardware specialization hierarchically to enhance the capabilities of a swarm without increasing complexity, allowing a numerous group of robots to benefit from the extended features of a few to complete a task that was impossible for them before. We tested the concept under a simulated environment with a classical distributed robotics problem, shape formation, and validated the simulated results against a real experiment.


Title: From Swarms to Stars: Task Coverage in Robot Swarms with Connectivity Constraints
Key Words: distributed control  mobile robots  multi-robot systems  navigation  optimisation  scheduling  Task coverage  Robot swarms  connectivity constraints  swarm robotics  complex tasks  control algorithms  globally coordinated behaviours  spatial coverage  global connectivity  distributed Robot Navigation Controller  RNC  global Task Scheduling Controller  minimal computational load  connectivity assessment  real-life robot experiments  coverage optimality  Task analysis  Robot kinematics  Navigation  Eigenvalues and eigenfunctions  Computational modeling  Multi-robot systems 
Abstract: Swarm robotics carries the potential of solving complex tasks using simple devices. To do so, however, one must define distributed control algorithms capable of producing globally coordinated behaviours. We propose a methodology to address the problem of the spatial coverage of multiple tasks with a swarm of robots that must not lose global connectivity. Our methodology comprises two layers: (i) a distributed Robot Navigation Controller (RNC) is responsible for simultaneously guaranteeing connectivity and pursuit of multiple tasks; and (ii) a global Task Scheduling Controller approximates the optimal strategy for the RNC with minimal computational load. Our contributions include: (i) a qualitative analysis of the literature on connectivity assessment, (ii) our proposed methodology, (iii) simulations in a multi-physics environment, (iv) real-life robot experiments, and (v) the experimental validation of connectivity, coverage optimality, and fault-tolerance.


Title: Using Information Invariants to Compare Swarm Algorithms and General Multi-Robot Algorithms
Key Words: mobile robots  multi-robot systems  swarm intelligence  multirobot algorithms  proximal neighbors  emergent collective behaviors  all-to-all communication  deliberative collaboration  supervisory operator  mission constraints  application domains - navigation  dynamic area coverage  online algorithm selection decisions  offline system design decisions  robotic swarms  information invariants  Heuristic algorithms  Robot kinematics  Robot sensing systems  Collision avoidance  Multi-robot systems  Navigation 
Abstract: Robotic swarms are decentralized multi-robot systems whose members use local information from proximal neighbors to execute simple reactive control laws that result in emergent collective behaviors. In contrast, members of a general multi-robot system may have access to global information, all-to-all communication or sophisticated deliberative collaboration. Some algorithms in the literature are applicable to robotic swarms. Others require the extra complexity of general multi-robot systems. Given an application domain, a system designer or supervisory operator must choose an appropriate system or algorithm respectively that will enable them to achieve their goals while satisfying mission constraints (e.g, bandwidth, energy, time limits). In this paper, we compare representative swarm and general multi-robot algorithms in two application domains - navigation and dynamic area coverage - with respect to several metrics (e.g, completion time, distance travelled). Our objective is to characterize each class of algorithms to inform offline system design decisions by engineers or online algorithm selection decisions by supervisory operators. Our contributions are (a) an empirical performance comparison of representative swarm and general multi-robot algorithms in two application domains, (b) a comparative analysis of the algorithms based on the theory of information invariants, which provides a theoretical characterization supported by our emnirical results.


Title: Learning Robust Policies for Object Manipulation with Robot Swarms
Key Words: Hilbert spaces  learning systems  mobile robots  multi-robot systems  robotic assembly  robust control  search problems  swarm size  robust policies learning  Hilbert space embeddings  policy search methods  low-level object movement policy  high-level assembly plan  assembly process  policy search method  autonomous object assembly  swarm robotics  robot swarms  object manipulation  Robot sensing systems  Task analysis  Light sources  Robustness  Kernel  Trajectory 
Abstract: Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.


Title: Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning
Key Words: decision theory  graph theory  learning (artificial intelligence)  Markov processes  mobile robots  navigation  path planning  probability  search problems  control problem  single follower robot  visual contact  moving target  plausible predictions  predictive models  discrete hypotheses  combinatorial search  physical space  model target behavior  learned navigation reward function  semantic terrain features  search methods  predictive pursuit algorithm  multiple satellite maps  simulation scenarios  inverse reinforcement learning  long term behavior  short term behavior  planning pursuit paths  locations  graph representation  latent destination  position  POMDP solvers  domain specific knowledge  model based probabilistic pursuit  Navigation  Planning  Trajectory  Visualization  Entropy  Predictive models  Learning (artificial intelligence) 
Abstract: We address the integrated prediction, planning, and control problem that enables a single follower robot (the photographer) to quickly re-establish visual contact with a moving target (the subject) that has escaped the follower's field of view. We deal with this scenario, which reactive controllers are typically ill-equipped to handle, by making plausible predictions about the long- and short-term behavior of the target, and planning pursuit paths that will maximize the chance of seeing the target again. At the core of our pursuit method is the use of predictive models of target behavior, which help narrow down the set of possible future locations of the target to a few discrete hypotheses, as well as the use of combinatorial search in physical space to check those hypotheses efficiently. We model target behavior in terms of a learned navigation reward function, using Inverse Reinforcement Learning, based on semantic terrain features of satellite maps. Our pursuit algorithm continuously predicts the latent destination of the target and its position in the future, and relies on efficient graph representation and search methods in order to navigate to locations at which the target is most likely to be seen at an anticipated time. We perform extensive evaluation of our predictive pursuit algorithm over multiple satellite maps, thousands of simulation scenarios, against state-of-the art MDP and POMDP solvers. We show that our method significantly outperforms them by exploiting domain-specific knowledge, while being able to run in real-time.


Title: Safe Teleoperation of Dynamic UAVs Through Control Barrier Functions
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  helicopters  human-robot interaction  Lyapunov methods  quadratic programming  assistive training solution  safe human teleoperated flight  control approach  motion capture environment  safe teleoperation  control barrier functions  human operators  highly dynamic systems  constrained environment  quadrotor systems  potential obstacles  presented supervisory controller  safety constraints  dynamic UAV  exponential control barrier function  Safety  Trajectory  Collision avoidance  Vehicle dynamics  Dynamics  Robots  Task analysis 
Abstract: This paper presents a method for assisting human operators to teleoperate highly dynamic systems such as quadrotors inside a constrained environment with safety guarantees. Our method enables human operators to focus on manually operating and flying quadrotor systems without the need to focus on avoiding potential obstacles. This is achieved with the presented supervisory controller overriding human input to enforce safety constraints when necessary. This method can be used as an assistive training solution for novice pilots to begin flying quadrotors without crashing them. Our supervisory controller uses an Exponential control barrier function based quadratic program to achieve safe human teleoperated flight. We demonstrate and validate our control approach through several experiments with multiple users with varying skill levels for three different scenarios of a quadrotor flying in a motion capture environment with virtual and physical constraints.


