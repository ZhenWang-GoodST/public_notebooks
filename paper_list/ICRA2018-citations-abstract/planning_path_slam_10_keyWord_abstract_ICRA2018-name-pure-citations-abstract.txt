total paper: 10
Title: Relocalization, Global Optimization and Map Merging for Monocular Visual-Inertial SLAM
Key Words: cameras  distance measurement  graph theory  inertial navigation  mobile robots  optimisation  path planning  pose estimation  robot vision  SLAM (robots)  relocalization  global optimization  monocular visual-inertial SLAM  visual-inertial system  low-cost inertial measurement unit  state estimation  visual-inertial odometry  absolute pose estimation  visual-inertial SLAM system  global pose graph optimization  map merging ability  map reuse  pose graph optimization  Cameras  Optimization  Visualization  Feature extraction  Microsoft Windows  Simultaneous localization and mapping  Real-time systems 
Abstract: The monocular visual-inertial system (VINS), which consists one camera and one low-cost inertial measurement unit (IMU), is a popular approach to achieve accurate 6-DOF state estimation. However, such locally accurate visual-inertial odometry is prone to drift and cannot provide absolute pose estimation. Leveraging history information to relocalize and correct drift has become a hot topic. In this paper, we propose a monocular visual-inertial SLAM system, which can relocalize camera and get the absolute pose in a previous-built map. Then 4-DOF pose graph optimization is performed to correct drifts and achieve global consistent. The 4-DOF contains x, y, z, and yaw angle, which is the actual drifted direction in the visual-inertial system. Furthermore, the proposed system can reuse a map by saving and loading it in an efficient way. Current map and previous map can be merged together by the global pose graph optimization. We validate the accuracy of our system on public datasets and compare against other state-of-the-art algorithms. We also evaluate the map merging ability of our system in the large-scale outdoor environment. The source code of map reuse is integrated into our public code, VINS-Monol11https://github.com/HKUST-Aerial-Robotics/VINS-Mono.


Title: Robot Navigation in Complex Workspaces Using Harmonic Maps
Key Words: geometry  mobile robots  motion control  path planning  robot vision  SLAM (robots)  complex workspaces  harmonic maps  Artificial Potential Fields  autonomous robot navigation control schemes  local minima  APF based control scheme  goal configuration  multiply connected compact 2D workspaces  Harmonic analysis  Navigation  Robot kinematics  Convergence  Tuning  Trajectory 
Abstract: Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline “tuning” of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.


Title: Semantic Mapping with Omnidirectional Vision
Key Words: cameras  distortion  image classification  image fusion  image segmentation  image sensors  mobile robots  path planning  robot vision  SLAM (robots)  omnidirectional vision  omnidirectional images  robust segmentation  occupancy grid maps  inverse sensor model  nonlinear distortions  omnidirectional camera mirror  place category classifier  range-based occupancy grid  dense semantic map  bird eye view  visual semantic mapping framework  robot local free space  Semantics  Sensors  Cameras  Robots  Buildings  Mirrors  Visualization 
Abstract: This paper presents a purely visual semantic mapping framework using omnidirectional images. The approach rests upon the robust segmentation of the robot's local free space, replacing conventional range sensors for the generation of occupancy grid maps. The perceptions are mapped into a bird's eye view allowing an inverse sensor model directly by removing the non-linear distortions of the omnidirectional camera mirror. The system relies on a place category classifier to label the navigation relevant categories: room, corridor, doorway, and open room. Each place class maintains a separated grid map that are fused with the range-based occupancy grid for building a dense semantic map.


Title: Fast Nonlinear Approximation of Pose Graph Node Marginalization
Key Words: approximation theory  graph theory  mobile robots  optimisation  path planning  pose estimation  SLAM (robots)  pose graph node marginalization  longterm localization  longterm mapping  longterm navigation  pose graph structure  absolute-to relative-pose spaces  pose-composition approach scaled version  approximate subgraph  fast nonlinear approximation method  Topology  Jacobian matrices  Covariance matrices  Gaussian distribution  Simultaneous localization and mapping  Approximation methods 
Abstract: We present a fast nonlinear approximation method for marginalizing out nodes on pose graphs for longterm simultaneous localization, mapping, and navigation. Our approximation preserves the pose graph structure to leverage the rich literature of pose graphs and optimization schemes. By re-parameterizing from absolute-to relative-pose spaces, our method does not suffer from the choice of linearization points as in previous works. We then join our approximation process with a scaled version of the recently-demoted pose-composition approach. Our approach eschews the expenses of many state-of-the-art convex optimization schemes through our efficient and simple O(N2) implementation for a given known topology of the approximate subgraph. We demonstrate its speed and near optimality in practice by comparing against state-of-the-art techniques on popular datasets.


Title: Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition
Key Words: cameras  feature extraction  image matching  image representation  image sequences  mobile robots  neural nets  object recognition  path planning  robot vision  SLAM (robots)  semantics-aware higher-order layers  deep neural networks  pure appearance-based techniques  place categorization  place-centric characteristics  condition-invariant place recognition  rear view mirror  semantic visual understanding  visual places  Semantics  Visualization  Robustness  Databases  Image recognition  Cameras  Neural networks 
Abstract: When a human drives a car along a road for the first time, they later recognize where they are on the return journey typically without needing to look in their rear view mirror or turn around to look back, despite significant viewpoint and appearance change. Such navigation capabilities are typically attributed to our semantic visual understanding of the environment [1] beyond geometry to recognizing the types of places we are passing through such as “passing a shop on the left” or “moving through a forested area”. Humans are in effect using place categorization [2] to perform specific place recognition even when the viewpoint is 180 degrees reversed. Recent advances in deep neural networks have enabled high performance semantic understanding of visual places and scenes, opening up the possibility of emulating what humans do. In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM [3]. Using two different datasets - one road-based, one pedestrian-based, we evaluate the performance of the system in performing place recognition on reverse traversals of a route with a limited field of view camera and no turn-back-and-Iook behaviours, and compare to existing state-of-the-art techniques and vanilla off-the-shelf features. The results demonstrate significant improvements over the existing state of the art, especially for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change. We also provide experimental analyses of the contributions of the various system components: the use of spatio-temporal sequences, place categorization and place-centric characteristics as opposed to object-centric semantics.


Title: Towards Globally Consistent Visual-Inertial Collaborative SLAM
Key Words: autonomous aerial vehicles  mobile robots  path planning  robot vision  SLAM (robots)  globally consistent tracking  autonomous robot navigation  monocular-inertial odometry  vision-based perception  metric scale estimation  benchmarking datasets  UAVs  monocular-inertial sensor suite  unmanned aerial vehicles  visual-inertial collaborative SLAM  drift correction  Simultaneous localization and mapping  Collaboration  Unmanned aerial vehicles  Optimization  Measurement  Trajectory 
Abstract: Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.


Title: Topomap: Topological Mapping and Navigation Based on Visual SLAM Maps
Key Words: mobile robots  navigation  path planning  robot vision  SLAM (robots)  three-dimensional topological map  noisy sparse point cloud  convex free-space clusters  global planning  mobile robotic platform  Topomap  visual SLAM  visual robot navigation  navigation task  sparse feature-based map  path planning algorithms  visual simultaneous localization and mapping system  Navigation  Visualization  Simultaneous localization and mapping  Path planning  Three-dimensional displays  Planning 
Abstract: Visual robot navigation within large-scale, semistructured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many state-of-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages.


Title: Efficient Active SLAM Based on Submap Joining, Graph Topology and Convex Optimization
Key Words: computational complexity  convex programming  least squares approximations  minimisation  mobile robots  path planning  predictive control  quadratic programming  robot vision  SLAM (robots)  graph topology  active SLAM problem  robot trajectory  area coverage task  model predictive control framework  uncertainty minimization MPC problem  graphical structure  2D feature-based SLAM  variable substitutions  convex optimization method  MPC framework  sequential quadratic programming method  linear SLAM  submap joining approach  planning  simultaneous localization and mapping  nonconvex constrained least-squares problem  Optimized production technology  Simultaneous localization and mapping  Uncertainty  Task analysis  Robot kinematics 
Abstract: The active SLAM problem considered in this paper aims to plan a robot trajectory for simultaneous localization and mapping (SLAM) as well as for an area coverage task with robot pose uncertainty. Based on a model predictive control (MPC) framework, these two problems are solved respectively by different methods. For the uncertainty minimization MPC problem, based on the graphical structure of the 2D feature-based SLAM, a non-convex constrained least-squares problem is presented to approximate the original problem. Then, using variable substitutions, it is further transformed into a convex problem, and then solved by a convex optimization method. For the coverage task considering robot pose uncertainty, it is formulated and solved by the MPC framework and the sequential quadratic programming (SQP) method. In the whole process, considering the computation complexity, we use linear SLAM, which is a submap joining approach, to reduce the time for planning and estimation. Finally, various simulations are presented to validate the effectiveness of the proposed approach.


Title: Ruling the Control Authority of a Service Robot Based on Information Precision
Key Words: geriatrics  handicapped aids  mobile robots  path planning  position control  service robots  SLAM (robots)  active sensing system  control law  senior user guidance  path following problem  landmarks  actuator control  accurate localisation  exact localisation  robotic walking assistant  information precision  service robot  control authority  design strategy  massive data collection  SLAM approaches  Robot sensing systems  Estimation error  Uncertainty  Probabilistic logic  Service robots  Automobiles 
Abstract: We consider the problem of guiding a senior user along a path using a robotic walking assistant. This is a particular type of path following problem, for which most of the solutions available in the literature require an exact localisation of the robot in the environment. An accurate localisation is obtained either with a heavy infrastructure (e.g., an active sensing system deployed in the environment or deploying landmarks in known positions) or using SLAM approaches with a massive data collection. Our key observation is that the intervention of the system (and a good level of accuracy) is only required in proximity of difficult decision points, while we can rely on the user in an environment where the only possibility is just to maintain a course (e.g., a corridor). The direct implication is that we can instrument the environment with a heavy infrastructure only in certain areas. This design strategy has to be complemented by an adequate control law that shifts the authority (i.e., the control of the actuators) between the robot and the user according to the accuracy of the information available to the robot. Such a control law is exactly the contribution of this paper.


Title: Feature-constrained Active Visual SLAM for Mobile Robot Navigation
Key Words: collision avoidance  mobile robots  navigation  path planning  robot vision  SLAM (robots)  sensory constraints  iterative motion planning framework  collision avoidance  online mapping  associated map points  distance-optimal path planner  data-driven approach  continuous identification  feature-based Visual Simultaneous Localization  vision-based navigation  failure avoidance  mobile robot navigation  feature-constrained active Visual SLAM  Cameras  Navigation  Collision avoidance  Simultaneous localization and mapping  Planning 
Abstract: This paper focuses on tracking failure avoidance during vision-based navigation to a desired goal in unknown environments. While using feature-based Visual Simultaneous Localization and Mapping (VSLAM), continuous identification and association of map points are required during motion. Thus, we discuss a motion planning framework that takes into account sensory constraints for a reliable navigation. We use information available in the SLAM and propose a data-driven approach to predict the number of map points associated in a given pose. Then, a distance-optimal path planner utilizes the model to constrain paths such that the number of associated map points in each pose is above a threshold. We also include an online mapping of the environment for collision avoidance. Overall, we propose an iterative motion planning framework that enables real-time replanning after the acquisition of more information. Experiments in two environments demonstrate the performance of the proposed framework.


