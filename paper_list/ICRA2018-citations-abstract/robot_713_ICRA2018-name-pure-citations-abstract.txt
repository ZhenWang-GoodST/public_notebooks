total paper: 713
Title: Welcome Message from the General Chair
Title: Welcome Message from the General Chair
Abstract: On behalf of the ICRA 2018 Organising Committee we extend a warm welcome to the world's foremost conference in robotics & automation, where you will be in the company of the best and brightest researchers and engineers from around our planet! ICRA started in 1984 and has become the leading international conference attended by thousands. The conference has played a leading role in shaping the future of robotics and automation. There has never been a better time than now to be working in robotics and automation field. Today we are witnessing explosive growth in the field with significant opportunities for both research and industry. ICRA is the meeting place where science, technology, innovation comes together to understand the latest advances in order to push for the next frontiers of development. As our technology matures and takes its place amongst the everyday lives of people it is important that this is done in a considered, safe and ethical manner.


Title: Workshops & Tutorials
Key Words: Conferences  Tutorials  Service robots  Machine learning  Soft robotics  Estimation 
Abstract: Full Day Workshops & Tutorials


Title: Sponsors and Exhibitors
Key Words: Conferences  Tutorials  Service robots  Machine learning  Soft robotics  Estimation 
Abstract: We thank all sponsors for their generous support and contribution.


Title: Automatic Optimized 3D Path Planner for Steerable Catheters with Heuristic Search and Uncertainty Tolerance
Key Words: catheters  drugs  medical robotics  needles  path planning  surgery  RRT-Connect  sample-based algorithms  obstacle occupancy  insertion procedure  catheter modeling  asymptotically-optimal solution  BIT* algorithm  sample-based heuristic search  drug delivery  multisegment steerable probe  programmable bevel-tip needle  EDEN2020  neurosurgeon  minimally invasive neurosurgery  automatic planner  steerable catheters  Neurosurgery  Catheters  Three-dimensional displays  Kinematics  Needles  Planning  Uncertainty 
Abstract: In this paper, an automatic planner for minimally invasive neurosurgery is presented. The solution provides the neurosurgeon with the best path to connect a user-defined entry point with a target in accordance with a specific cost function. The approach guarantees the avoidance of obstacles which can be found along the insertion pathway. The method is tailored to the EDEN2020* programmable bevel-tip needle, a multisegment steerable probe intended to be used to perform drug delivery for the treatment of glioblastomas. A sample-based heuristic search inspired by the BIT* algorithm is used to define the asymptotically-optimal solution in terms of path length, followed by a smoothing phase to meet the required kinematic constraints of the needle. To account for inaccuracies in catheter modeling, which could determine unexpected control errors over the insertion procedure, an uncertainty margin is defined in order to increase the algorithm's safety. The feasibility of the proposed solution was demonstrated by testing the method in simulated neurosurgical scenarios with different degrees of obstacle occupancy and against other sample-based algorithms present in literature: RRT, RRT* and an enhanced version of the RRT-Connect.


Title: Design and kinematics characterization of a laser-profiled continuum manipulator for the guidance of bronchoscopic instruments
Key Words: dexterous manipulators  diseases  lung  manipulator kinematics  medical robotics  patient treatment  kinematics characterization  laser-profiled continuum manipulator  bronchoscopic instruments  bronchoscopic intervention  minimally invasive method  lung diseases  endobronchial instruments  peripheral airways  precision laser profiling  commercial bronchoscopes  distal airways  kinematic models  manipulator configuration  actuation wires  manipulator joints  instrument guidance robot  wire-driven dexterous manipulator  Manipulators  Wires  Instruments  Electron tubes  Surgery  Kinematics 
Abstract: Bronchoscopic intervention, as a minimally invasive method for the diagnosis and treatment of lung diseases, has attracted more and more attention in recent years. However, existing endobronchial instruments lack the steerability accessing the peripheral airways with difficult bifurcations. This paper presents a novel wire-driven dexterous manipulator for the guidance of such instruments. Precision laser profiling is used to cut a stainless steel tube into multiple interlocked segments with revolute joints. The outer diameter of the manipulator is 2.20 mm which is small enough to be inserted into the working channels of most commercial bronchoscopes and distal airways, while keeping a large inner lumen with a diameter of 1.44 mm for passing various bronchoscopic instruments. The small bending radius provides enough flexibility to navigate inside the complex bronchial tree. Two kinematic models are proposed to predict the manipulator configuration from the translation of actuation wires. The former model is geometrically derived with the assumption of constant curvature bending and the latter one is statistically driven by capturing the motion trajectories of manipulator joints. A prototype of our low-cost add-on instrument guidance robot for bronchoscopic intervention is presented which can be easily integrated into current clinical routine.


Title: Design, Modeling and Control of a 2-DoF Robotic Guidewire
Key Words: actuators  blood vessels  catheters  diseases  medical robotics  surgery  two-degree-of-freedom robotic guidewire  joints laser micromachining  Nitinol tube  catheters  arteries  tendon force  shape sensing mechanism  peripheral arterial disease  size 0.78 mm  Tendons  Electron tubes  Arteries  Catheters  Robot kinematics  Kinematics 
Abstract: In most cases of peripheral arterial disease (PAD), the operating surgeon must use a variety of catheters riding on a thin wire known as a `guidewire'. This guidewire must be manually navigated through a tortuous pathway of arteries to arrive at the diseased area. Automation of the guidewire therefore reduces surgeon effort and minimizes the time required for a PAD procedure, but is restricted by the size constraints of a standard guidewire. This work presents the design of a robotically actuated 2 degree-of-freedom (DoF) guidewire tip comprised of joints laser micro-machined into a 0.78 mm (<; 2.4 Fr) Nitinol tube. We present an analysis of the notch joint used as a building block in the robot and a control strategy for this type of a joint. The experimental results show that tendon force is an important observable quantity that can be used as a shape sensing mechanism for this type of a joint in practical control applications.


Title: An Observer-Based Fusion Method Using Multicore Optical Shape Sensors and Ultrasound Images for Magnetically-Actuated Catheters
Key Words: biomedical ultrasonics  catheters  endoscopes  feedforward neural nets  image fusion  Kalman filters  medical image processing  medical robotics  observers  state estimation  surgery  multicore optical shape sensors  ultrasound images  magnetically-actuated catheters  minimally invasive surgery  flexible medical instruments  endoscopes  magnetically actuated catheters  steering precision  conventional catheters  actuation method  accurate tip position  precise control  robust sensor fusion algorithm  template-based tracker  convolutional neural network based tracker  observer-based fusion  Euclidean error  Luenberger observer  Kalman filter  Catheters  Fiber gratings  Optical sensors  Shape  Multicore processing 
Abstract: Minimally invasive surgery involves using flexible medical instruments such as endoscopes and catheters. Magnetically actuated catheters can provide improved steering precision over conventional catheters. However, besides the actuation method, an accurate tip position is required for precise control of the medical instruments. In this study, the tip position obtained from transverse 2D ultrasound images and multicore optical shape sensors are combined using a robust sensor fusion algorithm. The tip position is tracked in the ultrasound images using a template-based tracker and a convolutional neural network based tracker, respectively. Experimental results for a rhombus path are presented, where data obtained from both tracking sources are fused using Luenberger and Kalman state estimators. The mean and standard deviation of the Euclidean error for the Luenberger observer is 0.2 ± 0.11 [mm] whereas for the Kalman filter it is 0.18 ± 0.13 [mm], respectively.


Title: Reflection-Aware Sound Source Localization
Key Words: acoustic signal processing  array signal processing  microphone arrays  mobile robots  Monte Carlo methods  ray tracing  direct acoustic paths  direct sound signal  3D sound localization  single frame  reflected acoustic paths  3D sound source position  nonline-of-sight sound source  mobile sound source  localization accuracy  mobile source  intermittent sound signals  cube-shaped microphone array  Monte Carlo localization  inverse acoustic ray tracing  indirect sound signals  stationary source  continuous sound signals  indoor environments  reflection-aware method  reflection-aware sound source localization  direct acoustic rays  time 3.0 d  size 0.8 m  size 7.0 m  size 3.0 m  Acoustics  Ray tracing  Microphone arrays  Three-dimensional displays  Robots  Indoor environments 
Abstract: We present a novel, reflection-aware method for 3D sound localization in indoor environments. Unlike prior approaches, which are mainly based on continuous sound signals from a stationary source, our formulation is designed to localize the position instantaneously from signals within a single frame. We consider direct sound and indirect sound signals that reach the microphones after reflecting off surfaces such as ceilings or walls. We then generate and trace direct and reflected acoustic paths using inverse acoustic ray tracing and utilize these paths with Monte Carlo localization to estimate a 3D sound source position. We have implemented our method on a robot with a cube-shaped microphone array and tested it against different settings with continuous and intermittent sound signals with a stationary or a mobile source. Across different settings, our approach can localize the sound with an average distance error of 0.8 m tested in a room of 7 m by 7 m area with 3 m height, including a mobile and non-line-of-sight sound source. We also reveal that the modeling of indirect rays increases the localization accuracy by 40% compared to only using direct acoustic rays.


Title: Deep Neural Networks for Multiple Speaker Detection and Localization
Key Words: acoustic generators  encoding  human-robot interaction  microphone arrays  neural nets  speaker recognition  deep neural networks  multiple speaker detection  simultaneous detection  multiple sound sources  human-robot interaction  neural network-based sound source localization methods  single sound source  likelihood-based encoding  network output  sound mixtures  spatial spectrum-based approaches  Encoding  Delays  Robots  Artificial neural networks  Microphones  Estimation 
Abstract: We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.


Title: DroneEARS: Robust Acoustic Source Localization with Aerial Drones
Key Words: acoustic signal processing  array signal processing  autonomous aerial vehicles  sensor arrays  DroneEARS  robust acoustic source localization  aerial drones  microaerial vehicles  high value mobile sensing assets  external sensing scene  acoustic clues  MAV auditory system  robust acoustic localization system  MAV propeller units  sensor arrays  binaural sensing system  geo-locating sound sources  sparse sensor array design  platform constraints  severe ego-noise  received signal-to-noise ratio  source localization accuracy  physical space-of-interest  mobility-aided beamforming  Acoustics  Robot sensing systems  Sensor arrays  Signal to noise ratio  Array signal processing  Propellers 
Abstract: Micro aerial vehicles (MAVs), an emerging class of aerial drones, are fast turning into high value mobile sensing assets. While MAVs have a large sensory gamut at their disposal; vision continues to dominate the external sensing scene, with limited usability in scenarios that offer acoustic clues. Therefore, we endeavor to provision a MAV auditory system (i.e., ears); and as part of this goal, our preliminary aim is to develop a robust acoustic localization system for detecting sound sources in the physical space-of-interest. However, devising this capability is extremely challenging due to strong ego-noise from the MAV propeller units, which is both wideband and non-stationary. It is well known that beamformers with large sensor arrays can overcome high noise levels; but in an attempt to cater to the platform (i.e., space, payload and computation) constraints of a MAV, we propose DroneEARS: a binaural sensing system for geo-locating sound sources. It combines the benefits of sparse (two elements) sensor array design (for meeting the platform constraints), and our proposed mobility-aided beamforming (for overcoming the severe ego-noise and its other complex characteristics) to significantly enhance the received signal-to-noise ratio (SNR). We demonstrate the efficacy of DroneEARS by empirical evaluations, and show that it provides a SNR improvement of 15-18 dB compared to many conventional and widely used techniques. This SNR gain translates to a source localization accuracy of approximately 40 cm within a scan region of 6m × 3m , that is, one order of magnitude better than competing methodologies.


Title: Inertial Machine Monitoring System for Automated Failure Detection
Key Words: condition monitoring  failure analysis  neural nets  production engineering computing  productivity  sensors  support vector machines  support vector machines  combine industrial equipment failure  inertial machine monitoring system  manufacturing productivity  3D printer  neural networks  smart manufacturing technologies  automated failure detection  Internet-of-Things sensors  Feature extraction  Robot sensing systems  Vibrations  Monitoring  Accelerometers  Databases  Three-dimensional displays 
Abstract: Smart manufacturing technologies are emerging which combine industrial equipment with Internet-of-Things (IoT) sensors to monitor and improve productivity of manufacturing. This allows for new opportunities to explore algorithms for predicting machine failures from attached sensor data. This paper presents a solution to non-invasively upgrade an existing machine with an Inertial Machine Monitoring System (IMMS) to detect and classify equipment failure or degraded state. We also provide a strategy to optimize the amount, placement locations, and efficiency of the sensors. In experiments, the system collected data from 36 inertial sensors placed at multiple locations on a 3D printer. Normal operation vs. 10 types of realworld abnormal equipment behavior (loose belt, failures of machine components) were detected and classified by Support Vector Machines and Neural Networks. Using under 1 minute of recording while running a test print, a recursively discovered best subset of 4 to 9 sensors yielded 11-way classification accuracy over 99%. Our results suggest that even a small sensor network and short test program can yield effective detection of machine degraded state and can facilitate early remediation.


Title: iMag: Accurate and Rapidly Deployable Inertial Magneto-Inductive Localisation
Key Words: Global Positioning System  sensor placement  SLAM (robots)  wireless sensor networks  inertial magneto-inductive localisation  short-term construction work  iMag  robust simultaneous localisation  inertial measurement units  Transmitters  Robustness  Simultaneous localization and mapping  Magnetic resonance imaging  Distortion  Trajectory  Magneto-inductive device  Inertial measurements  Localisation  SLAM 
Abstract: Localisation is of importance for many applications. Our motivating scenarios are short-term construction work and emergency rescue. Not only is accuracy necessary, these scenarios also require rapid setup and robustness to environmental conditions. These requirements preclude the use of many traditional methods e.g. vision-based, laser-based, Ultra-wide band (UWB) and Global Positioning System (GPS)-based localisation systems. To solve these challenges, we introduce iMag, an accurate and rapidly deployable inertial magneto-inductive (MI) localisation system. It localises monitored workers using a single MI transmitter and inertial measurement units with minimal setup effort. However, MI location estimates can be distorted and ambiguous. To solve this problem, we suggest a novel method to use MI devices for sensing environmental distortions, and use these to correctly close inertial loops. By applying robust simultaneous localisation and mapping (SLAM), our proposed localisation method achieves excellent tracking accuracy, and can improve performance significantly compared with only using an inertial measurement unit (IMU) and MI device for localisation.


Title: Parallel Pick and Place Using Two Independent Untethered Mobile Magnetic Microgrippers
Key Words: end effectors  freight handling  grippers  industrial robots  micromanipulators  microrobots  mobile robots  position control  independent untethered mobile magnetic microgrippers  parallel targeted cargo delivery  two-microgripper pair  local magnetic interactions  global magnetic field  end effectors  parallel pick and place  3D microgrippers configuration  Grippers  Magnetic separation  Barium  Magnetic hysteresis  Magnetoelasticity  Micromagnetics  Task analysis  magnetic microgripper  multi-agent control at microscales  soft robotics  targeted cargo delivery 
Abstract: Untethered mobile microgrippers exhibit flexibility and agility in small and constrained environments as precise and accurate robotic end-effectors, with promising potential applications in cell manipulation and microassembly. Here, we propose the first scheme to independently and simultaneously position two microgrippers on a horizontal plane for parallel targeted cargo delivery using a single global input. The separation and orientation of the two-microgripper pair are modulated by the local magnetic interactions between the two microgrippers, which are governed by a global magnetic field. The microgripper action of grasping or releasing cargoes is fully controlled by the global magnetic field without requiring additional thermal, chemical, or other stimuli. Thus, the proposed strategy only requires a single input, i.e., a global magnetic field, to control two microgrippers and therefore is simple to implement and fast-acting. As a demonstration, two microgrippers are maneuvered by a global magnetic field to pick up two cargoes and deliver them to their respective destinations. The parallel operation of two microgrippers can potentially double the overall throughput and enable the tasks that require team cooperations. The two 3D microgrippers configuration is intuitive in teleoperations, since it imitates the two-hand case of human beings.


Title: Development and Experimental Validation of a Combined FBG Force and OCT Distance Sensing Needle for Robot-Assisted Retinal Vein Cannulation
Key Words: biomedical optical imaging  blood vessels  Bragg gratings  calibration  coagulation  distance measurement  eye  fibre optic sensors  force sensors  manipulators  medical disorders  medical robotics  needles  optical tomography  surgery  vision defects  real-time distance estimation algorithm  calibration method  manufacturing process  Fiber Bragg grating  Fiber Bragg grating  depth estimation  anticoagulant  robot-assisted procedure  retinal vascular disorder  FBG force  Optical Coherence Tomography A-scan technology  distance sensing cannulation needle  instrument-tissue interaction forces  Retinal Vein Occlusion  robot-assisted retinal Vein cannulation  OCT distance sensing needle  Retina  Robot sensing systems  Force  Needles  Instruments  Veins 
Abstract: Retinal Vein Occlusion is a common retinal vascular disorder which can cause severe loss of vision. Retinal vein cannulation followed by injection of an anti-coagulant into the affected vein is a promising treatment. However, given the scale and fragility of the surgical workfield, this procedure is considered too high-risk to perform manually. A first successful robot-assisted procedure has been demonstrated. Even though successful, the procedure remains extremely challenging. This paper aims at providing a solution for the limited perception of instrument-tissue interaction forces as well as depth estimation during retinal vein cannulation. The development of a novel combined force and distance sensing cannulation needle relying on Fiber Bragg grating (FBG) and Optical Coherence Tomography (OCT) A-scan technology is reported. The design, the manufacturing process, the calibration method, and the experimental characterization of the produced sensor are discussed. The functionality of the combined sensing modalities and the real-time distance estimation algorithm are validated respectively on in-vitro and ex-vivo models.


Title: Requirements Based Design and End-to-End Dynamic Modeling of a Robotic Tool for Vitreoretinal Surgery
Key Words: manipulator dynamics  manipulator kinematics  medical robotics  motion control  surgery  end-to-end dynamic modeling  robotic tool  vitreoretinal surgery  sub-optimal motor selection  microprecise surgery  surgical tool  3-link surgical manipulator  anti-backlash lead screw assembly  multi-Degree of Freedom robotic system  dynamics analysis  rigorous kinematics analysis  Euler-Lagrange equations of motion  Surgery  Manipulator dynamics  Tools  Mathematical model  Dynamics 
Abstract: Despite several robots having been proposed for vitreoretinal surgery, there is limited information on their dynamic modeling. This gap leads to sub-optimal motor selection and hinders the application of advanced control schemes that would fulfill the goal of micro-precise surgery. This paper presents the design process and a dynamics study of a multi-Degree of Freedom (DoF) robotic system, which is inspired by established co-manipulation architectures. A rigorous kinematics and dynamics analysis of the robot's part that is responsible for manipulating the surgical tool during the retinal surgery phase is provided. In particular, the Euler-Lagrange equations of motion, which describe the dynamics of the 3-link surgical manipulator, are combined with novel analytical models of each link's corresponding transmission mechanism, including an anti-backlash lead screw assembly and a worm drive. The resulting models, transferable to existing manipulators, provide a meticulous analysis of the robot's performance that can be used both for mechanical design and control purposes.


Title: ESD CYCLOPS: A New Robotic Surgical System for GI Surgery
Key Words: biomedical optical imaging  cancer  endoscopes  laser applications in medicine  medical robotics  surgery  tumours  endoscopic submucosal dissection  robotic surgical system  therapeutic endoscopy technique  GI surgery  GI surgeon  bimanual surgical robotic attachment  ESD CYCLOPS system  surgical systems  gastrointestinal cancers  Instruments  Endoscopes  Electrostatic discharges  Surgery  Tendons  Robots  Cancer 
Abstract: Gastrointestinal (GI) cancers account for 1.5 million deaths worldwide. Endoscopic Submucosal Dissection (ESD) is an advanced therapeutic endoscopy technique with superior clinical outcome due to the minimally invasive and en bloc removal of tumours. In the western world, ESD is seldom carried out, due to its complex and challenging nature. Various surgical systems are being developed to make this therapy accessible, however, these solutions have shown limited operational workspace, dexterity, or low force exertion capabilities. The current paper shows the ESD CYCLOPS system, a bimanual surgical robotic attachment that can be mounted at the end of any flexible endoscope. The system is able to achieve forces of up to 46N, and showed a mean error of 0.217mm during an elliptical tracing task. The workspace and instrument dexterity is shown by pre-clinical ex vivo trials, in which ESD is successfully performed by a GI surgeon. The system is currently undergoing pre-clinical in vivo validation.


Title: Differentiation of C2C12 Myoblasts and Characterization of Electro-Responsive Beating Behavior of Myotubes Using Circularly Distributed Multiple Electrodes for Bio-Syncretic Robot
Key Words: biomechanics  cellular biophysics  electromechanical actuators  medical robotics  microrobots  muscle  physiological models  tissue engineering  ultrasonic therapy  electrical stimulation  myotubes  bio-syncretic robot  circularly distributed multiple electrodes  C2C12 myoblasts  electro-responsive beating behavior  biomedical field  C2C12 differentiation  muscle tissue engineering  Electrodes  Electrical stimulation  Muscles  Robots  Electric fields  Biological materials  Force 
Abstract: Micro-robots have a great application prospect in the biomedical field due to the feature of small size. To solve the issues of energy supply and bio-compatibility of micro-robots, bio-syncretic micro-robots composed of biological materials and electromechanical systems have been studied widely. The skeletal muscle is a potential material to develop bio-actuator for the bio-syncretic robots on account of the great contraction force and the controllability. However, the low differentiation quality of C2C12s and the control of the bio-syncretic robots are the two of the main challenges for the development of the bio-syncretic robots based on the skeleton muscle. In this paper, an approach based on circularly distributed multiple electrodes (CDMEs) was proposed to improve the differentiation of C2C12 myoblast cells and characterize the electro-responsive beating behavior of myotubes for the development of bio-syncretic robots. Three groups of C2C12 blasts were used to fulfill the differentiation experiments without electrical stimulation and with electrical stimulation using parallel electrodes and CDMEs respectively, for evaluating the effect of CDMEs on C2C12 differentiation. It was demonstrated that electrical field through CDMEs can improve the differentiation quality of C2C12 blasts into myotubes in terms of intensity, length, and widths. Then, the effect of electrical stimulation on the beating behaviors of myotubes was also investigated with CDMEs, and it was shown that the beating amplitudes of myotubes were significantly affected by the frequencies, amplitude and direction of electrical stimulation with respect to the myotubes, which is fundamental for the control of the micro-robot based on skeletal muscle cells. The proposed approach is useful for not only the development of the bio-syncretic robots, but also the study of muscle tissue engineering.


Title: String Untying Planning Based on Knot Theory and Proposal of Algorithms to Generate the Motion of a Manipulator
Key Words: manipulators  path planning  deformable object manipulation  string untying planning method  motion generation  optimal string shape operation  knot theory  Shape  Planning  Manipulators  Robot motion  Three-dimensional displays  Task analysis 
Abstract: Recently, the demand to manipulate deformable objects such as a string and cloth by robots is growing. The reason is that it has the possibility of making our lives more convenient in many domains. The manipulation of deformable objects, however, is more difficult than that of rigid objects, because deformable objects have diversity of shape and behavior. Therefore, our research group has been focusing on the string shape operation. This paper describes planning method of string untying operation based on knot theory and algorithms to generate the motion of a manipulator. The novel contribution of our planning method is automatic selection of optimal shape operation based on cost function. At final, the results of string untying experiments are reported.


Title: Compliant Low Profile Multi-Axis Force Sensors
Key Words: carbon fibre reinforced composites  compliant mechanisms  deformation  elastomers  force sensors  strain sensors  multiaxis force sensors  soft force sensors  compliant force sensors  microscale meanders  elastomers layers  sensor contact mechanics  differential measurement  laser-machined carbon fiber composite micro-structures  mechanical compliance  Robot sensing systems  Resistance  Fabrication  Geometry  Force sensors  Contacts  Carbon  Soft Material Robotics  Wearable Robots 
Abstract: The development of soft, compliant force sensors is greatly sought after in areas such as soft robotics and prosthetics. Nevertheless, solutions for measuring forces in multiple axes, while being mechanically compliant, have been few and far between. Here we present a compliant sensor able to detect forces tangential and normal to the sensor surface. The transduction mechanism is based on the deformation of laser-machined carbon fiber composite (CFC) micro-scale meanders, encapsulated within elastomers layers. Strains in the elastomer are transmitted to the meanders, causing changes in the electrical resistance of the sensor contact mechanics. Configuring the meanders in a radial pattern, segmenting them into quadrants (two antagonist pairs) and biasing the center of the sensor out-of-plane enables detection of forces in multiple axis via differential measurement. Sensors were manufactured using a custom fabrication process and exhibited high mechanical compliance with a very low form factor. The sensors were experimentally characterized and demonstrated large differential changes in resistance (up to 26 kΩ for tangential forces applied to the sensor surface). We integrated our sensor onto a soft robotic gripper finger and demonstrated the ability to detect changes in friction at the actuator surface, thus demonstrating their potential for real world applications.


Title: A Novel Approach to Under-Actuated Control of Fluidic Systems
Key Words: actuators  flow control  fluidics  under-actuated control  fluidic actuation  Fluidic Systems  Robots  Pneumatic systems  Valves  Pistons  Damping  Task analysis  Inspection 
Abstract: Thanks to the growing interest in soft robotics, hydropneumatics and inflatable system dynamics are attracting renewed attention from the scientific community. Typical fluidic systems are composed of several chambers and require a complex and bulky network of active components for their control. This paper presents a novel approach to fluidic actuation, which consists in the co-design of both the mechanical parameters of the system and of custom input signals, to enable the elicitation of different behaviors of the system with fewer control components. The principle is presented in theory and simulation and then experimentally validated through the application to a case study, an in-pipe inchworm-like robot. It is shown that it is possible to obtain forward and backward movements by modulating a unique input.


Title: Introducing PneuAct: Parametrically-Designed MRI-Compatible Pneumatic Stepper Actuator
Key Words: biomedical MRI  electromagnetic actuators  medical robotics  motion control  pneumatic actuators  stepping motors  MR compatible robotics  proof-of-concept-prototypes  rotational pneumatic stepper motors  parametrically-designed MRI-compatible pneumatic stepper actuator  motion control  general purpose nonelectromagnetic actuation  PneuAct  Pistons  Synchronous motors  Electron tubes  Pneumatic systems  Force  Actuators  Robots 
Abstract: Pneumatic stepper motors are one of the promising alternative actuation methods for motion control in environments where electromagnetic (EM) motors cannot be used. Due to the lack of commercial off-the-shelf products, researchers working on MR compatible robotics have to develop their own pneumatic actuators. This imposes extensive costs and delays on the development process. Additionally, the current solutions are limited in their range of specifications and are difficult to manufacture. In this paper, proof-of-concept-prototypes for a family of parametrically designed, electromagnetically stealth, rotational pneumatic stepper motors are presented. The main objective of the paper is to demonstrate a general purpose non-electromagnetic actuation method, which can be customized and integrated into any design. Customizability, miniaturization, safety and affordability are some of the key features of the presented work. The developed prototypes are entirely 3D-printed and contain no sealing, bearing or lubrication. Thanks to the low production cost, the motor can be used as a disposable part in surgical applications. Experiments demonstrate effectiveness of the design in terms of cost-efficiency, versatility, MRI-compatibility, speed and performance. In order to optimize the design and control algorithm, empirical equations are presented describing response time of a pneumatic system to sequential pressure signals. A rotational speed of 800 rpm, total volume of 4.6 cm3 and resolution of 3° are some of the design attributes. The effects of clearance on stick-slip effect and leakage in a 3D printed cylinder-piston are also presented.


Title: Efficient Planning for Near-Optimal Compliant Manipulation Leveraging Environmental Contact
Key Words: large-scale systems  manipulators  optimisation  path planning  robot kinematics  path planning  assembly tasks  action uncertainty  optimal manipulation  leverage environmental contact  complex kinematics  action space  contact manifold  problem complexity  near-optimal compliant manipulation  environmental contact  discretization  Aerospace electronics  Uncertainty  Kinematics  Mathematical model  Manifolds  Task analysis  Complexity theory 
Abstract: Path planning classically focuses on avoiding environmental contact. However, some assembly tasks permit contact through compliance, and such contact may allow for more efficient and reliable solutions under action uncertainty. But, optimal manipulation plans that leverage environmental contact are difficult to compute. Environmental contact produces complex kinematics that create difficulties for planning. This complexity is usually addressed by discretization over state and action space, but discretization quickly becomes computationally intractable. To overcome the challenge, we use the insight that only actions on configurations near the contact manifold are likely to involve complex kinematics, while segments of the plan through free space do not. Leveraging this structure can greatly reduce the number of states considered and scales much better with problem complexity. We develop an algorithm based on this idea and show that it performs comparably to full MDP solutions at a fraction of the computational cost.


Title: Constrained Sampling-Based Planning for Grasping and Manipulation
Key Words: manipulator dynamics  motion control  path planning  position control  redundant manipulators  sampling methods  sensors  trees (mathematics)  constrained sampling-based planning  sampling-based motion  transport tasks  redundant robotic manipulator  planning margin  grasp configuration  approach direction  sensor uncertainty  execution errors  soft constraints  computational efficiency  studied approaches  target position  grasp tasks  optimal grasp pose  Rapidly-exploring Random Tree algorithm  RRT algorithm  Planning  Grasping  Task analysis  Manipulators  Jacobian matrices  Robustness  Manifolds 
Abstract: This paper presents a novel constrained, sampling-based motion planning method for grasp and transport tasks with a redundant robotic manipulator. We utilize a planning margin for grasping with constraints that allow the best grasp configuration and approach direction to be determined automatically. For manipulators with many degrees of freedom, our method efficiently chooses the optimal grasp pose when there are many redundant solutions. The method also introduces a parameterized intermediate pose that is optimized to determine the approach direction, increasing robustness under sensor uncertainty and execution errors. Our method also considers transporting the grasped object to the desired target position using a Rapidly-exploring Random Tree (RRT) algorithm that incorporates soft constraints via appropriate cost penalties. We demonstrate the effectiveness and efficiency of our algorithms on a number of simulated and experimental applications. Our experimental results show a marked improvement in computational efficiency in comparison to previously studied approaches.


Title: Geometric In-Hand Regrasp Planning: Alternating Optimization of Finger Gaits and In-Grasp Manipulation
Key Words: dexterous manipulators  gait analysis  manipulator kinematics  mesh generation  mobile robots  optimisation  path planning  finger gaiting  in-grasp manipulation  contact location  finger gaits  object reposing actions  optimization  geometric in-hand regrasp planning  robots fingers  objects geometry  hands kinematic structure  kinematic feasibility  collision free  Planning  Robots  Optimization  Task analysis  Thumb  Collision avoidance 
Abstract: This paper explores the problem of autonomous, in-hand regrasping-the problem of moving from an initial grasp on an object to a desired grasp using the dexterity of a robot's fingers. We propose a planner for this problem which alternates between finger gaiting, and in-grasp manipulation. Finger gaiting enables the robot to move a single finger to a new contact location on the object, while the remaining fingers stably hold the object. In-grasp manipulation moves the object to a new pose relative to the robot's palm, while maintaining the contact locations between the hand and object. Given the object's geometry (as a mesh), the hand's kinematic structure, and the initial and desired grasps, we plan a sequence of finger gaits and object reposing actions to reach the desired grasp without dropping the object. We propose an optimization based approach and report in-hand regrasping plans for 5 objects over 5 in-hand regrasp goals each. The plans generated by our planner are collision free and guarantee kinematic feasibility.


Title: Manipulating Highly Deformable Materials Using a Visual Feedback Dictionary
Key Words: feature extraction  manipulators  mobile robots  robot vision  visual servoing  complex physical properties  autonomous robotic manipulation systems  visual feedback dictionary-based method  deformable objects  visual servoing  RGB sensor stream  deformable model features  histogram features  high-level representations  deformable material  manipulation data  robotic end-effectors  complex manipulation tasks  human-robot manipulation tasks  material characteristics  deformable materials  Visualization  Dictionaries  Feature extraction  Task analysis  Visual servoing  Deformable models 
Abstract: The complex physical properties of highly deformable materials such as clothes pose significant challenges for autonomous robotic manipulation systems. We present a novel visual feedback dictionary-based method for manipulating deformable objects towards a desired configuration. Our approach is based on visual servoing and we use an efficient technique to extract key features from the RGB sensor stream in the form of a histogram of deformable model features. These histogram features serve as high-level representations of the state of the deformable material. Next, we collect manipulation data and use a visual feedback dictionary that maps the velocity in the high-dimensional feature space to the velocity of the robotic end-effectors for manipulation. We have evaluated our approach on a set of complex manipulation tasks and human-robot manipulation tasks on different cloth pieces with varying material characteristics.


Title: Reactive Planar Manipulation with Convex Hybrid MPC
Key Words: closed loop systems  learning (artificial intelligence)  manipulators  optimal control  optimisation  predictive control  Model Predictive Control formulation  optimal sequence  robot motions  desired object motion  multiple contact modes  frictional interactions  combinatorial complexity  optimal mode sequences offline  optimal control inputs  convex hybrid MPC program  planar manipulation experimental setup  convex hybrid MPC formulation  closed-loop performance  reactive planar manipulation  reactive controller  planar manipulation tasks  optimization program  machine learning  Task analysis  Force  Schedules  Friction  Predictive control  Manipulators  Optimization 
Abstract: This paper presents a reactive controller for planar manipulation tasks that leverages machine learning to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes. To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from machine learning, this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem.


Title: Stable Prehensile Pushing: In-Hand Manipulation with Alternating Sticking Contacts
Key Words: dexterous manipulators  friction  manipulator dynamics  mechanical contact  motion control  path planning  frictional coefficients  pushing strategy  in-hand manipulation planning  dynamics formulation  object grasping  alternating sticking contacts  prehensile pushing stability  Planning  Dynamics  Grippers  Friction  Robots  Geometry  Force 
Abstract: This paper presents an approach to in-hand manipulation planning that exploits the mechanics of alternating sticking contact. Particularly, we consider the problem of manipulating a grasped object using external pushes for which the pusher sticks to the object. Given the physical properties of the object, frictional coefficients at contacts and a desired regrasp on the object, we propose a sampling-based planning framework that builds a pushing strategy concatenating different feasible stable pushes to achieve the desired regrasp. An efficient dynamics formulation allows us to plan in-hand manipulations 100-1000 times faster than our previous work which builds upon a complementarity formulation. Experimental observations for the generated plans show that the object precisely moves in the grasp as expected by the planner.


Title: Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement Learning
Key Words: learning (artificial intelligence)  manipulators  mobile robots  path planning  potential field-based heuristic exploration strategy  deep Q-network  nonprehensile rearrangement strategy  physical environment  physical world  skillful interaction  tabletop surface  rearranging objects  deep reinforcement learning  nonprehensile manipulation  quicker learning  training process  Planning  Task analysis  Robots  Tools  Cameras  Visualization  Training 
Abstract: Rearranging objects on a tabletop surface by means of nonprehensile manipulation is a task which requires skillful interaction with the physical world. Usually, this is achieved by precisely modeling physical properties of the objects, robot, and the environment for explicit planning. In contrast, as explicitly modeling the physical environment is not always feasible and involves various uncertainties, we learn a nonprehensile rearrangement strategy with deep reinforcement learning based on only visual feedback. For this, we model the task with rewards and train a deep Q-network. Our potential field-based heuristic exploration strategy reduces the amount of collisions which lead to suboptimal outcomes and we actively balance the training set to avoid bias towards poor examples. Our training process leads to quicker learning and better performance on the task as compared to uniform exploration and standard experience replay. We demonstrate empirical evidence from simulation that our method leads to a success rate of 85%, show that our system can cope with sudden changes of the environment, and compare our performance with human level performance.


Title: Decentralized Adaptive Control for Collaborative Manipulation
Key Words: adaptive control  decentralised control  Lyapunov methods  manipulators  multi-robot systems  stability  center-of-mass measurements  angular velocity  local measurements  collaborative manipulation  decentralized adaptive controller  common payload  agent positions  payload properties  Lyapunov-style analysis  stability  convergence  Payloads  Robots  Collaboration  Angular velocity  Velocity measurement  Task analysis  Stability analysis 
Abstract: This paper presents a design for a decentralized adaptive controller that allows a team of agents to manipulate a common payload in $\mathbb{R}^{2}$ or $\mathbb{R}^{3}$. The controller requires no communication between agents and requires no a priori knowledge of agent positions or payload properties. The agents can control the payload to track a reference trajectory in linear and angular velocity with center-of-mass measurements, in angular velocity using only local measurements and a common frame, and can stabilize its rotation with only local measurements. The controller is designed via a Lyapunov-style analysis and has proven stability and convergence. The controller is validated in simulation and experimentally with four robots manipulating an object in the plane.


Title: Trajectory Generation for Minimum Closed-Loop State Sensitivity
Key Words: autonomous aerial vehicles  closed loop systems  mobile robots  Monte Carlo methods  optimisation  controller dynamics  reference trajectory  system trajectories  trajectory optimization problems  closed-loop sensitivity  trajectory generation  minimum closed-loop state sensitivity  dynamical system fulfil  nominal parameters  closed-loop trajectory  system/controller pair  control inputs  system states  robotic systems  Monte Carlo simulations  unicycle  quadrotor UAV  Trajectory  Sensitivity  Task analysis  Optimization  Uncertainty  Robots  Robustness 
Abstract: In this paper we propose a novel general method to let a dynamical system fulfil at best a control task when the nominal parameters are not perfectly known. The approach is based on the introduction of the novel concept of closed-loop sensitivity, a quantity that relates parameter variations to deviations of the closed-loop trajectory of the system/controller pair. This new definition takes into account the dependency of the control inputs from the system states and nominal parameters as well as from the controller dynamics. The reference trajectory to be tracked is taken as optimization variable, and the dynamics of both the sensitivity and of its gradient are computed analytically along the system trajectories. We then show how this computation can be effectively exploited for solving trajectory optimization problems aimed at generating a reference trajectory that minimizes a norm of the closed-loop sensitivity. The theoretical results are validated via an extensive campaign of Monte Carlo simulations for two relevant robotic systems: a unicycle and a quadrotor UAV.


Title: Modeling and Control of Multi-Arm and Multi-Leg Robots: Compensating for Object Dynamics During Grasping
Key Words: actuators  dexterous manipulators  humanoid robots  legged locomotion  manipulator dynamics  manipulator kinematics  mobile robots  motion control  object dynamics compensation  ANYmal  free-floating robot link  KUKA LWR IV+ representing fingers  contact wrenches control  floating-base multileg robots control  virtual DOF  enormous robot hand  underactuated robots  contact consistent motion generation  Projected Inverse Dynamics Control approach  underactuated system  multiarm robot  modeling approach  grasping scenarios  virtual manipulator  mass 9.0 kg  Grasping  Dynamics  Task analysis  Jacobian matrices  Manipulator dynamics 
Abstract: We consider a virtual manipulator in grasping scenarios which allows us to capture the effect of the object dynamics. This modeling approach turns a multi-arm robot into an underactuated system. We observe that controlling floating-base multi-leg robots is fundamentally similar. The Projected Inverse Dynamics Control approach is employed for decoupling contact consistent motion generation and controlling contact wrenches. The proposed framework for underactuated robots has been evaluated on an enormous robot hand composed of four KUKA LWR IV+ representing fingers cooperatively manipulating a 9kg box with total 28 actuated DOF and six virtual DOF representing the object as additional free-floating robot link. Finally, we validate the same approach on ANYmal, a floating-base quadruped with 12 actuated DOF. Experiments are performed both in simulation and real world.


Title: Multi-Priority Cartesian Impedance Control Based on Quadratic Programming Optimization
Key Words: collision avoidance  humanoid robots  human-robot interaction  motion control  quadratic programming  robot dynamics  service robots  torque control  prioritized Cartesian impedance control  inverse dynamics  matrix pseudoinversion  inverse kinematics computation  QP optimization  QP implementation  classical Cartesian impedance controller  humanoid upper-body torque controlled robot  quadratic programming optimization  inequality constraints  multipriority Cartesian impedance control  algebraic implementation  joint torque limits  virtual model control  Task analysis  Impedance  Robots  Force  Torque  Optimization  Acceleration 
Abstract: In this work we introduced a prioritized Cartesian impedance control under the framework of the Quadratic Programming (QP) optimization. In particular, we present a formulation which is simpler than full inverse dynamics, avoids any matrix pseudo-inversion, inverse kinematics computation and considers strict priorities among tasks. Our formulation is based on QP optimization permitting to take into account also explicit inequality constraints. We compare in simulation the tracking results obtained with a classical algebraic implementation against those derived from the proposed QP implementation taking into account joint torque limits. We consider the classical Cartesian impedance controller and a simplified version, also known as Virtual Model Control. Finally the proposed method was implemented and validated on a humanoid upper-body torque controlled robot. Experimental trials involving various physical interaction conditions were executed to demonstrate the performance of the proposed method.


Title: Responsive and Reactive Dual-Arm Robot Coordination
Key Words: collision avoidance  control engineering computing  industrial robots  manipulators  mobile robots  motion control  multi-robot systems  path planning  dual-arm robot coordination  temporal coordination  spatial coordination  shared workspace  industrial service-oriented robotics  user experience  execution performance  independently planned motions  dual-arm manipulator  motion commands  robot motion  ABB YuMi robot  Robot kinematics  Trajectory  Collision avoidance  Task analysis  Service robots  Manipulators 
Abstract: The need for temporal and spatial coordination of two robot arms moving independently in a shared workspace frequently arises in industrial and service-oriented robotics alike. Today, this problem is often solved manually, leading to a negative impact on user experience as well as on execution performance. In this paper, we present an algorithm that is able to automatically coordinate independently planned motions of a dual-arm manipulator during execution. In addition, the algorithm is capable of refining the plan upon receiving new motion commands during the robot motion. We demonstrate the effectiveness and efficiency of the proposed approach on an ABB YuMi robot working on an industrial palletizing task.


Title: Contact Point Localization for Articulated Manipulators with Proprioceptive Sensors and Machine Learning
Key Words: control engineering computing  learning (artificial intelligence)  manipulator dynamics  manipulator kinematics  multilayer perceptrons  optimisation  position control  contact point localization  articulated manipulators  proprioceptive sensors  machine learning  joint positions  one-dimensional joint torques  robot arm  RFs  contact link  contact points  Kinova Jaco 2 manipulator  optimization based approach  ML approach  serial manipulator  random forests  multilayer perceptrons  MLP  Force  Torque  Three-dimensional displays  Robot sensing systems  Manipulator dynamics 
Abstract: A model-based Machine Learning (ML) approach is presented to detect and localize external contacts on a 6 degree of freedom (DoF) serial manipulator. This approach only requires the use of proprioceptive sensors (joint positions, velocities and one-dimensional (ID) joint torques already available in the robot arm). Good results are obtained with Random Forests (RFs) and Multi-Layer-Perceptrons (MLPs) leading to a precise localization of the contact link and its orientation. Apart from the link in contact and the orientation of the force, RFs and MLPs are also able to differentiate between contact points on the same link and orientation but with different distances to the joint axis. We experimentally verify this approach on simulated and real data obtained from the Kinova Jaco 2 manipulator and compare it to an optimization based approach.


Title: $L_{1}$ Robustness of Computed Torque Method for Robot Manipulators
Key Words: continuous time systems  linear systems  manipulators  robust control  stability  time-varying systems  torque control  uncertain systems  robot manipulator  L1 robustness  L1 robust stability condition  performance measure  induced norm bounded model uncertainty  continuous-time linear time-invariant nominal plant  multiplicative model uncertainty  exogenous disturbance  modelling errors  computed torque controller  model uncertainties  computed torque method  Torque  Manipulator dynamics  Computational modeling  Uncertainty  Robustness 
Abstract: This paper revisits computed torque method for robot manipulators and aims at developing its new framework based on the L1 robustness, in which the L∞ norm together with its induced norm is employed to characterize model uncertainties and a performance measure. More precisely, we consider the L1 robust stability and performance for a given robot manipulator with a computed torque controller. We first show that the modelling errors in the computed torque method can be divided into an exogenous disturbance and a multiplicative model uncertainty, which are bounded in terms of the L∞ norm and its induced norm, respectively. It is next shown that the robot manipulator with the computed torque controller can be equivalently represented by an interconnection of a continuous-time linear time-invariant (LTI) nominal plant and a stabilizing controller together with the L∞-induced norm bounded model uncertainty. Based on the interconnected representation, the L1 robust stability condition and an upper bound of the L1 performance against the exogenous disturbance with respect to all model uncertainties in a class of a bounded L∞-induced norm are dealt with by using the small-gain theorem. Finally, the effectiveness of the theoretical results is demonstrated through some experiment results.


Title: Online Safe Trajectory Generation for Quadrotors Using Fast Marching Method and Bernstein Basis Polynomial
Key Words: autonomous aerial vehicles  clutter  computational geometry  convex programming  helicopters  indoor environment  mobile robots  path planning  polynomials  search problems  state estimation  trajectory control  online safe trajectory generation  Bernstein basis polynomial  onboard state estimation  velocity field  Euclidean signed distance field  time allocation  flight corridor  piecewise Bézier curves  outdoor environments  convex programs  autonomous navigation  marching-based path searching method  light-weight quadrotor platform  online quadrotor motion planning  cluttered indoor environments  ESDF  open-source package  Resource management  Planning  Trajectory optimization  Safety  Autonomous robots 
Abstract: In this paper, we propose a framework for online quadrotor motion planning for autonomous navigation in unknown environments. Based on the onboard state estimation and environment perception, we adopt a fast marching-based path searching method to find a path on a velocity field induced by the Euclidean signed distance field (ESDF) of the map, to achieve better time allocation. We generate a flight corridor for the quadrotor to travel through by inflating the path against the environment. We represent the trajectory as piecewise Bézier curves by using Bernstein polynomial basis and formulate the trajectory generation problem as typical convex programs. By using Bézier curves, we are able to bound positions and higher order dynamics of the trajectory entirely within safe regions. The proposed motion planning method is integrated into a customized light-weight quadrotor platform and is validated by presenting fully autonomous navigation in unknown cluttered indoor and outdoor environments. We also release our code for trajectory generation as an open-source package.


Title: Coverage Path Planning Under the Energy Constraint
Key Words: approximation theory  geometry  mobile robots  path planning  energy constraint  coverage path planning problem  battery limitations  working environment  geometric version  polygonal grid  single charging station  energy consumption  constant-factor approximation algorithm  contour-connected environments  aerial robot  mobile robot systems  Robots  Charging stations  Approximation algorithms  Path planning  Batteries  Partitioning algorithms  Energy consumption 
Abstract: In the coverage path planning problem, a common assumption is that the robot can fully cover the environment without recharging. However, in reality most mobile robot systems operate under battery limitations. To incorporate this constraint, we consider the problem when the working environment is large and the robot needs to recharge multiple times to fully cover the environment. We focus on a geometric version where the environment is represented as a polygonal grid with a single charging station. Energy consumption throughout the environment is assumed to be uniform and proportional to the distance traveled. We first present a constant-factor approximation algorithm for contour-connected environments. We then extend the algorithm for general environments. We also validate the results in experiments performed with an aerial robot.


Title: The Dubins Car and Other Arm-Like Mobile Robots
Key Words: force control  Jacobian matrices  mobile robots  optimal control  path planning  robot kinematics  torque control  Dubins car  lagrange multipliers  external force  equal torques  arm Jacobian yields  optimal paths  arm-like mobile robots  robots arm kinematics  geometric interpretations  rotation center locations  Kinematics  Mobile robots  Trajectory  Automobiles  Manipulators  Mathematical model 
Abstract: This paper investigates the connection between the kinematics of robots arms and the shortest paths for mobile robots. Lagrange multipliers are used to show that the shortest paths are equivalent to arms in configurations that balance an external force, while applying equal torques and forces at each joint. Analysis of the arm Jacobian yields a further geometric interpretations of optimal paths, constraining the locations of rotation centers and the directions of translations that may occur along optimal paths.


Title: Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  path planning  trajectory control  motion planning  robotics community  FaSTrack  sensor measurements  meta-planning notion  Crazyflie 2.0 quadrotor  adaptive realtime safe trajectory planning  safety guarantee  online planner  offline computation  motion plans  modular safety guarantee  Planning  Trajectory  Safety  Real-time systems  Robustness  Navigation  Computational modeling 
Abstract: Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of “meta-planning” in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.


Title: Reactive Bipedal Walking Method for Torque Controlled Robot
Key Words: collision avoidance  humanoid robots  legged locomotion  motion control  robot dynamics  stability  torque control  walking algorithm  whole-body control algorithm  operational space control framework  compliant task behavior  robust walking  unexpected obstacle  reactive bipedal walking method  torque controlled robot  unexpected situations  reactive biped robot walking method  time plan  trajectory tracking control  reactive behavior  unexpected contact  12-DoF torque controlled biped robot  Legged locomotion  Foot  Acceleration  Trajectory tracking  Humanoid robots  Robot kinematics 
Abstract: Reactivity to unexpected situations is one of the most important characteristics of walking for real world applications. In this study, we introduce a reactive biped robot walking method that reflects only the current state of the robot. Therefore, time plan and trajectory tracking control are not required for robot walking, and this enables reactive behavior to unexpected contact or disturbance. The walking algorithm is realized through a whole-body control algorithm based on the operational space control framework, that possesses the capability to command the required force for tasks and also implement compliant task behavior by adjusting corresponding task gains. The performance of the proposed method is verified by experiments with a 12-DoF torque controlled biped robot. Robust walking is demonstrated when the foot is stopped by an unexpected obstacle or when the lateral motion is unexpectedly blocked and released by a human.


Title: Disturbance Observer Based Linear Feedback Controller for Compliant Motion of Humanoid Robot
Key Words: actuators  control system synthesis  elasticity  feedback  humanoid robots  legged locomotion  motion control  observers  position control  robot dynamics  stability  linear feedback controller  humanoid robot  industrial robots  position-controlled humanoid robots  disturbance observer based estimator  flexible joint model  joint elasticity  DYROS-JET robot  compliant motion  Elasticity  Legged locomotion  Humanoid robots  Gravity  Vibrations  Torque 
Abstract: Actuator modules of humanoid robots have relatively higher joint elasticity than those of industrial robots. Such joint elasticity could lead to negative effects on both the tracking performance and stability for walking. Especially, unstable contact between the foot and ground caused by joint elasticity is a critical problem, as it decreases the stability of position-controlled humanoid robots. To address this problem, this paper introduces a novel control scheme for position-controlled humanoid robots by which we can obtain not only enhance compliance capability for unknown contact but also suppress the vibration caused by joint elasticity. To estimate the disturbance caused by external forces and modeling errors between the actual system and nominal system, a disturbance observer based estimator is designed at each joint. Furthermore, a linear feedback controller for the flexible joint model and a gravity compensator is considered to reduce vibration and deflection due to the joint elasticity. The proposed control scheme was implemented on our humanoid robot, DYROS-JET, and its performance was demonstrated by improved stability during dynamic walking and stepping on objects.


Title: Unsupervised Contact Learning for Humanoid Estimation and Control
Key Words: end effectors  friction  humanoid robots  legged locomotion  pattern clustering  probability  robot kinematics  state estimation  unsupervised learning  humanoid estimation  contact state estimation  fuzzy clustering  six-dimensional humanoid contacts  proprioceptive sensors - endeffector contact wrench sensors  inertial measurement units  clustering-based contact probability estimator  kinematics-based base state estimator  sensor noise  unsupervised contact learning  IMUs  DoFs  Friction  Sensors  Force  Foot  State estimation  Computational modeling 
Abstract: This work presents a method for contact state estimation using fuzzy clustering to learn contact probability for full, six-dimensional humanoid contacts. The data required for training is solely from proprioceptive sensors - endeffector contact wrench sensors and inertial measurement units (IMUs) - and the method is completely unsupervised. The resulting cluster means are used to efficiently compute the probability of contact in each of the six endeffector degrees of freedom (DoFs) independently. This clustering-based contact probability estimator is validated in a kinematics-based base state estimator in a simulation environment with realistic added sensor noise for locomotion over rough, low-friction terrain on which the robot is subject to foot slip and rotation. The proposed base state estimator which utilizes these six DoF contact probability estimates is shown to perform considerably better than that which determines kinematic contact constraints purely based on measured normal force.


Title: Robust Control of Dynamic Walking Robots Using Transverse H∞
Key Words: control system synthesis  gait analysis  legged locomotion  linear quadratic control  motion control  robot dynamics  robust control  H∞ control  LQR controllers  compass gait walker  gait sensitivity norm  disturbance rejection  transverse coordinates  robust controllers  dynamic walkers  unstructured environments  dynamic walking robots  robust control  Legged locomotion  Robot kinematics  Robustness  Sensitivity  Robot sensing systems  Trajectory 
Abstract: The control of walking robots has been a long-studied problem as researchers attempt to bring robots out of the lab and into unstructured environments. In particular, there is significant interest in dynamic walkers: a class of walking robots that exhibit highly efficient gaits, but are sensitive to disturbances. This paper develops robust controllers for dynamic walkers in transverse coordinates using H∞ control, with a focus on rejecting disturbances at foot impact. The optimization objective is a measure of disturbance rejection known as the gait sensitivity norm. The controller was used to stabilise a compass gait walker in simulation for various disturbances. Simulation results demonstrate the advantages of phase-tracking and H∞ control for robustness compared to time-varying and LQR controllers.


Title: Investigation of a Bipedal Platform for Rapid Acceleration and Braking Manoeuvres
Key Words: braking  legged locomotion  optimisation  time optimal control  rapid acceleration manoeuvres  optimal control  time optimal sprint  realistic linkage morphology  pre-specified actuator  nominal leg length  optimisation problem  brute force approach  unique motion trajectories  time optimal behaviour  steady state motion  braking manoeuvres  physical bipedal robotic platform  bipedal platform  Legged locomotion  Couplings  Mathematical model  Actuators  Acceleration  Force 
Abstract: Rapid acceleration manoeuvres have been avoided by researchers due to the aperiodicity and complexities of this motion. With the recent improvements in optimal control, this paper presents the first examination of a biped completing a time optimal sprint, starting and ending in rest, to provide insight for parameter choices of a robotic platform. In particular, a realistic linkage morphology is used with the limitation of a pre-specified actuator to choose the nominal leg length and gear ratio. Due to the size of the optimisation problem, a brute force approach is used rather than including these parameters as free variables. The results provided unique motion trajectories for time optimal behaviour with the models reaching near steady state motion and performing manoeuvres that are seen in a biped's biological counterpart. We then show that access to a higher mass-specific force does not improve the rapid acceleration manoeuvres, rather the friction coefficient and keeping the feet near the ground act as the limiting factor given sufficiently powerful actuators. A parabolic relationship emerged for sprint time versus linkage lengths providing valuable insight into the parameters to use for the platform design. To the authors knowledge, no prior research has focused on rapid acceleration and braking manoeuvres of a biped in one optimisation problem, let alone providing insight for the physical bipedal robotic platform.


Title: Comparison Study of Nonlinear Optimization of Step Durations and Foot Placement for Dynamic Walking
Key Words: humanoid robots  legged locomotion  nonlinear control systems  optimisation  pendulums  robot dynamics  dynamic walking  nonlinear optimization problem  continuous dynamics  discrete dynamics  remaining step duration  foot location  motion model captures  mass dynamics  low-dimensionality  holistic approach  three-dimensional parametric space  computational efficiency  sequential approach  customized optimization  current step duration  optimal solutions  bipedal locomotion  Optimization  Foot  Legged locomotion  Robustness  Lips  Dynamics  Computational modeling 
Abstract: This paper studies bipedal locomotion as a nonlinear optimization problem based on continuous and discrete dynamics, by simultaneously optimizing the remaining step duration, the next step duration and the foot location to achieve robustness. The linear inverted pendulum as the motion model captures the center of mass dynamics and its low-dimensionality makes the problem more tractable. We first formulate a holistic approach to search for optimality in the three-dimensional parametric space and use these results as baseline. To further improve computational efficiency, our study investigates a sequential approach with two stages of customized optimization that first optimizes the current step duration, and subsequently the duration and location of the next step. The effectiveness of both approaches is successfully demonstrated in simulation by applying different perturbations. The comparison study shows that these two approaches find mostly the same optimal solutions, but the latter requires considerably less computational time, which suggests that the proposed sequential approach is well suited for real-time implementation with a minor trade-off in optimality.


Title: Torque-Based Dynamic Walking - A Long Way from Simulation to Experiment
Key Words: gait analysis  legged locomotion  motion control  robot dynamics  torque control  torque-based dynamic walking - a long way  torque-controlled robots  trajectory generation  DCM controller  whole-body controller  WBC  full-body walking behavior  sophisticated walking gaits  original control framework  divergent component  Legged locomotion  Task analysis  Foot  Trajectory  Force  Torque 
Abstract: This paper presents methods that facilitate the implementation of dynamic walking on torque-controlled robots in real world experiments. The work uses the Divergent Component of Motion (DCM) for walking trajectory generation and control. The DCM controller is embedded into a whole-body controller (WBC) that produces a full-body walking behavior. While in simulation the combination of DCM and WBC is sufficient for achieving sophisticated walking gaits, during our initial experiments several real-world issues, detailed in this paper, prevented the original control framework from functioning. This work presents the improvements to the original control framework that enabled a breakthrough on the way to achieving torque-based dynamic walking on a real robot.


Title: Online Falling-Over Control of Humanoids Exploiting Energy Shaping and Distribution Methods
Key Words: end effectors  humanoid robots  nonlinear control systems  position control  energy distribution polygons  humanoid robot  lateral falls  sagittal falls  EDP concepts  total energy  impact forces  online falling-over control  fall control technique  energy concepts  orientation control  energy shaping  nonlinear control  ES concepts  humanoids  end effectors  Force  Numerical models  Energy conversion  Robot kinematics  Position control  Dynamics 
Abstract: This paper proposes a novel fall control technique based on energy concepts, which can be applied online to mitigate the impact forces incurred during the falling over of humanoids. The technique reduces the total energy using a nonlinear control tool, called energy shaping (ES), and further distributes the reduced energy over multiple contacts by means of energy distribution polygons (EDP). We also include an effective orientation control to safeguard the end-effectors in the event of ground impacts. The performance of the proposed method is numerically evaluated by dynamic simulations under the sudden falling over scenario of the humanoid robot for both lateral and sagittal falls. The effectiveness of the proposed ES and EDP concepts are verified by diverse comparative simulations with total energy, distribution, and impact forces.


Title: High Stiffness in Teleoperated Comanipulation: Necessity or Luxury?
Key Words: decision making  elastic constants  human-robot interaction  manipulators  telerobotics  teleoperated comanipulation  high stiffness controllers  human dyads  comanipulative tasks  low-level interactions  high-level interactions  decision-making  teleoperated control  physical human-human interaction  Task analysis  Force  Haptic interfaces  Visualization  Impedance  Measurement  Robots 
Abstract: The present paper investigates if and in which conditions does the implementation of high stiffness controllers increase the performances of human dyads during comanipulative tasks in physical Human-Human Interaction (pHHI) settings. Two experiments are conducted which cover two fundamental aspects of pHHI: low-level interactions allowing interpersonal coordination, and high-level interactions allowing common decision-making and negotiation of strategies. The results of these experiments show that high stiffness is not necessary for good performances when the task only requires low-level interactions. On the contrary, when dealing with high-level interactions, higher stiffness increases task performance. The results presented highlight the importance of the quality of teleoperated control in setups used for the study of pHHI.


Title: Effects of Latency and Refresh Rate on Force Perception via Sensory Substitution by Force-Controlled Skin Deformation Feedback
Key Words: control engineering computing  damping  force feedback  haptic interfaces  medical robotics  robot kinematics  skin  telerobotics  sensory substitution  force-controlled skin deformation feedback device  3-degree-of-freedom kinesthetic force feedback device  damping  reference object  human force perception  latency  refresh rate  Skin  Strain  Force  Force feedback  Damping  Delay effects 
Abstract: Latency and refresh rate are known to adversely affect human force perception in bilateral teleoperators and virtual environments using kinesthetic force feedback, motivating the use of sensory substitution of force. The purpose of this study is to quantify the effects of latency and refresh rate on force perception using sensory substitution by skin deformation feedback. A force-controlled skin deformation feedback device was attached to a 3-degree-of-freedom kinesthetic force feedback device used for position tracking and gravity support. A human participant study was conducted to determine the effects of latency and refresh rate on perceived stiffness and damping with skin deformation feedback. Participants compared two virtual objects: a comparison object with stiffness or damping that could be tuned by the participant, and a reference object with either added latency or reduced refresh rate. Participants modified the stiffness or damping of the tunable object until it resembled the stiffness or damping of the reference object. We found that added latency and reduced refresh rate both increased perceived stiffness but had no effect on perceived damping. Specifically, participants felt significantly different stiffness when the latency exceeded 300 ms and the refresh rate dropped below 16.6 Hz. The impact of latency and refresh rate on force perception via skin deformation feedback was significantly less than what has been previously shown for kinesthetic force feedback.


Title: Know Rob 2.0 — A 2nd Generation Knowledge Processing Framework for Cognition-Enabled Robotic Agents
Key Words: knowledge based systems  knowledge representation  manipulator kinematics  manipulators  service robots  complex manipulation tasks  chemical experiments  first-order time interval logic knowledge base  logical expressions  robotics algorithms  motion planning  open-ended manipulation skills  commonsense knowledge  2nd generation knowledge processing framework  cognition-enabled robotic agents  generation knowledge representation  advanced knowledge  inverse kinematic problem solving  KnowRob2.0  Robots  Cognition  Data structures  Ontologies  Task analysis  Knowledge based systems  Physics 
Abstract: In this paper we present KnowRob2, a second generation knowledge representation and reasoning framework for robotic agents. KnowRob2 is an extension and partial redesign of KnowRob, currently one of the most advanced knowledge processing systems for robots that has enabled them to successfully perform complex manipulation tasks such as making pizza, conducting chemical experiments, and setting tables. The knowledge base appears to be a conventional first-order time interval logic knowledge base, but it exists to a large part only virtually: many logical expressions are constructed on demand from data structures of the control program, computed through robotics algorithms including ones for motion planning and solving inverse kinematics problems, and log data stored in noSQL databases. Novel features and extensions of KnowRob2 substantially increase the capabilities of robotic agents of acquiring open-ended manipulation skills and competence, reasoning about how to perform manipulation actions more realistically, and acquiring commonsense knowledge.


Title: Intuitive Constraint-Based Robot Programming for Robotic Assembly Tasks* The research leading to these results has received funding from the European Unions Seventh Framework Programme FP7/2013-2017 under grant agreement n 608604 (LIAA: Lean Intelligent Assembly Automation) and Horizon 2020 Research and Innovation Programme under grant agreement n 688642 (RAMPup).
Key Words: assembling  manipulators  mobile robots  robot programming  robotic assembly  intuitive constraint-based robot programming  robotic assembly tasks  recent intuitive robot programming approaches  encapsulating robot capabilities  general guidelines  assembly process descriptions  German Engineers VDI  particular addressing assembly applications  constraint-based approach iTaSC  elementary processes  exemplarily assembly tasks  instantaneous task specification  Task analysis  Robot sensing systems  Robot programming  Guidelines  Robotic assembly 
Abstract: Recent intuitive robot programming approaches operate on task level, enabling programmers to intuitively arrange or compose encapsulating robot capabilities (skills). This paper presents an approach to intuitively create (sub-)skills. General guidelines for assembly process descriptions #2860 provided by the Association of German Engineers VDI are applied to robot programming, in particular addressing assembly applications. The guidelines are exemplarily applied to the constraint-based approach iTaSC (instantaneous Task Specification using Constraints), presenting a procedure to hierarchically combine elementary processes to (sub-)skills. Six elementary processes are identified to be sufficient to implement a wide variety of assembly tasks. An iTaSC implementation was developed and two exemplarily assembly tasks were realized to evaluate the approach.


Title: MaestROB: A Robotics Framework for Integrated Orchestration of Low-Level Control and High-Level Reasoning
Key Words: humanoid robots  human-robot interaction  industrial robots  inference mechanisms  intelligent robots  middleware  multi-robot systems  ontologies (artificial intelligence)  robot programming  service robots  MaestROB  integrated orchestration  low-level control  high-level reasoning  MaestROBe  complex tasks  simple high-level instructions  hierarchical structure  ontology  actuation control  symbolic planner  Watson APIs  cognitive capabilities  semantic understanding  open source robot middleware  complex scenario  communication robot  industrial robot  common industrial task  assembly task  humanoid robot  SoftBank Robotics  natural language conversation  human demonstration  collaborative robot arm  Universal Robots  robotic framework  Task analysis  Service robots  Natural languages  Robot kinematics  Middleware  Robot sensing systems 
Abstract: This paper describes a framework called MaestROBe It is designed to make the robots perform complex tasks with high precision by simple high-level instructions given by natural language or demonstration. To realize this, it handles a hierarchical structure by using the knowledge stored in the forms of ontology and rules for bridging among different levels of instructions. Accordingly, the framework has multiple layers of processing components; perception and actuation control at the low level, symbolic planner and Watson APIs for cognitive capabilities and semantic understanding, and orchestration of these components by a new open source robot middleware called Project Intu at its core. We show how this framework can be used in a complex scenario where multiple actors (human, a communication robot, and an industrial robot) collaborate to perform a common industrial task. Human teaches an assembly task to Pepper (a humanoid robot from SoftBank Robotics) using natural language conversation and demonstration. Our framework helps Pepper perceive the human demonstration and generate a sequence of actions for UR5 (collaborative robot arm from Universal Robots), which ultimately performs the assembly (e.g. insertion) task.


Title: Ctrl-MORE: A Framework to Integrate Controllers of Multi-DoF Robot for Developers and Users
Key Words: control system synthesis  feedback  mobile robots  multi-robot systems  path planning  robust control  software architecture  trajectory control  multiDoF robot  robotic applications  modular framework  software architecture  control developers  feedback controllers  coupling  software modules  Ctrl-MORE  manipulation  locomotion  vision  stabilizers  trajectory planners  robustness  Robots  Documentation  Software  Task analysis  Computer architecture  Hardware  Tools 
Abstract: In recent years, many different feedback controllers for robotic applications have been proposed and implemented. However, the high coupling between the different software modules made their integration into one common architecture difficult. Consequently, this has hindered the ability of a user to employ the different controllers into a single, general and modular framework. To address this problem, we present Ctrl-MORE, a software architecture developed to fill the gap between control developers and other users in robotic applications. On one hand, Ctrl-MORE aims to provide developers with an opportunity to integrate easily and share their controllers with other roboticists working in different areas. For example, manipulation, locomotion, vision and so on. On the other hand, it provides to end-users a tool to apply the additional control strategies that guarantee the execution of desired behaviors in a transparent, yet efficient way. The proposed control architecture allows an easier integration of general purpose feedback controllers, such as stabilizers, with higher control layers such as trajectory planners, increasing the robustness of the overall system.


Title: A Prototype-Based Skill Model for Specifying Robotic Assembly Tasks
Key Words: robot programming  robotic assembly  specification languages  industrial assembly applications  Task Function Approach  Task Frame Formalism  model robot task description  robot tasks  model-based manipulation skills  robotic assembly tasks  prototype-based skill model  prototype-based inheritance  reuse  domain-specific languages  model coordination mechanisms  Task analysis  Robot kinematics  Kinematics  DSL  Libraries  Robot sensing systems 
Abstract: In recent years, a number of publications described approaches for model-based manipulation skills and their applicability to a variety of robot tasks-be it assembly, industrial robotics in general, or service robotics. These approaches roughly follow the same pattern: They model robot task description based on the Task Frame Formalism, the Task Function Approach, or iTaSC. They model coordination mechanisms in form of statecharts or Petri nets. And almost all models are accompanied by domain-specific languages (DSLs) that facilitate creating applications based on those models. While one advantage of using models is their reusability across applications, how to explicitly model the reuse itself has not been fully addressed by these publications. Our paper contributes to this field of research by investigating how reuse can be explicitly modeled using prototype-based inheritance. We base our model on iTaSC and provide a simple yet effective DSL for populating the model and creating applications. We demonstrate our approach by creating a comprehensive library of skills, and by showing the use, reuse and incremental refinement of skills for diverse industrial assembly applications.


Title: Facilitating Model-Based Control Through Software-Hardware Co-Design
Key Words: actuators  control engineering computing  force control  hardware-software codesign  legged locomotion  mobile robots  motion control  robot dynamics  model-based control  design process  legged machines  dynamic behaviors  high performance robots  design requirements  control algorithm  physical robot  actuation  natural dynamic behavior  physical machine  legged robots  high bandwidth force control  software-hardware codesign processes  robotic control  robotic platforms  hardware design choices  model-based balance controller  Legged locomotion  Robot sensing systems  Actuators  Hardware  Torque 
Abstract: This paper exemplifies the design process for legged machines capable of dynamic behaviors. In order to achieve high performance robots, it is crucial to guarantee harmonious integration between software and hardware. Hence, the development of such capable robotic platforms must address design requirements that meet the assumptions of typical model-based controllers but also respect the physical limitations of a real system. First, we show that proper hardware design choices can greatly aid the control algorithm by approximating the physical robot to the template assumptions. We include actuation and sensing design examples that allows a simple model to capture a major portion of the natural dynamic behavior of the physical machine. Results are applied to a real robot (Figure 1) and we show that the adopted methodology is able to address typical problems in legged robots such as high bandwidth force control and robustness to impact. Finally, a simple model-based balance controller that takes advantage of the fidelity of the template model to the real machine is implemented. These are examples of software-hardware codesign processes that vastly facilitate robotic control.


Title: Inference of User Qualities in Shared Control
Key Words: groupware  human-robot interaction  telerobotics  Human-Robot Interaction  shared control  telepresence robot  locus of control  teleoperation controllers  collaborative performance  robotic systems  Robots  Telepresence  Collision avoidance  Task analysis  Force  Human-robot interaction  System performance 
Abstract: Users play an integral role in the performance of many robotic systems, and robotic systems must account for differences in users to improve collaborative performance. Much of the work in adapting to users has focused on designing teleoperation controllers that adjust to extrinsic user indicators such as force, or intent, but do not adjust to intrinsic user qualities. In contrast, the Human-Robot Interaction community has extensively studied intrinsic user qualities, but results may not rapidly be fed back into autonomy design. Here we provide foundational evidence for a new strategy that augments current shared control, and provide a mechanism to directly feed back results from the HRI community into autonomy design. Our evidence is based on a study examining the impact of the user quality “locus of control” on telepresence robot performance. Our results support our hypothesis that key user qualities can be inferred from human-robot interactions (such as through path deviation or time to completion) and that switching or adaptive autonomies might improve shared control performance.


Title: Sample and Feedback Efficient Hierarchical Reinforcement Learning from Human Preferences
Key Words: human-robot interaction  learning (artificial intelligence)  human feedback  reward function  bi-perspective reward learning  simulated robot grasping task  general hierarchical reinforcement learning framework  robot perspective  feedback efficiency  physical robot  informative reward function  human preferences  Robots  Grasping  Task analysis  Trajectory  Learning (artificial intelligence)  Context modeling  Customer relationship management 
Abstract: While reinforcement learning has led to promising results in robotics, defining an informative reward function is challenging. Prior work considered including the human in the loop to jointly learn the reward function and the optimal policy. Generating samples from a physical robot and requesting human feedback are both taxing efforts for which efficiency is critical. We propose to learn reward functions from both the robot and the human perspectives to improve on both efficiency metrics. Learning a reward function from the human perspective increases feedback efficiency by assuming that humans rank trajectories according to a low-dimensional outcome space. Learning a reward function from the robot perspective circumvents the need for a dynamics model while retaining the sample efficiency of model-based approaches. We provide an algorithm that incorporates bi-perspective reward learning into a general hierarchical reinforcement learning framework and demonstrate the merits of our approach on a toy task and a simulated robot grasping task.


Title: Investigation of Communicative Flight Paths for Small Unmanned Aerial Systems * This work was supported by NSF NRI 1638099
Key Words: aircraft control  autonomous aerial vehicles  humanoid robots  human-robot interaction  human-humanoid robot interactions  avian flight paths  sUAS manufacturers  sUAS flight paths  human-robot interaction  small Unmanned Aerial System flight paths  human-human interactions  Biology  Humanoid robots  Stakeholders  Batteries  Aerospace electronics  Service robots 
Abstract: This project seeks to generate small Unmanned Aerial System (sUAS) flight paths that are broadly understood by the general population and can communicate states about both the sUAS and its understanding of the world. Previous work in sUAS flight paths has sought to communicate intent, destination, or emotion of the system without focusing on concrete states (e.g., low battery, landing, etc.). This work leverages biologically-based flight paths and experimental methodologies from human-human and human-humanoid robot interactions to assess the understanding of avian flight paths to communicate sUAS states to novice users. If successful, this work should inform: the human-robot interaction community about the perception of flight paths, sUAS manufacturers on how their systems could communicate with both operators and bystanders, and end users on ways to communicate with others when flying systems in public spaces. General design implications and future directions of work are suggested to build on the results here, which suggest that novice users gravitate towards labels they understand (draw attention and landing) while avoiding more technical labels (lost sensor).


Title: Inverse Reinforcement Learning via Function Approximation for Clinical Motion Analysis
Key Words: function approximation  image motion analysis  injuries  learning (artificial intelligence)  medical image processing  neurophysiology  Bellman Optimality Equation  reward learning  inverse reinforcement learning  learned reward function  computationally expensive reinforcement learning problems  function approximation method  clinical motion analysis  Learning (artificial intelligence)  Mathematical model  Trajectory  Function approximation  Spinal cord injury  Markov processes  Estimation 
Abstract: This paper introduces a new method for inverse reinforcement learning in large state spaces, where the learned reward function can be used to control high-dimensional robot systems and analyze complex human movement. To avoid solving the computationally expensive reinforcement learning problems in reward learning, we propose a function approximation method to ensure that the Bellman Optimality Equation always holds, and then estimate a function to maximize the likelihood of the observed motion. The time complexity of the proposed method is linearly proportional to the cardinality of the action set, thus it can handle large state spaces efficiently. We test the proposed method in a simulated environment on reward learning, and show that it is more accurate than existing methods and significantly better in scalability. We also show that the proposed method can extend many existing methods to large state spaces. We then apply the method to evaluating the effect of rehabilitative stimulations on patients with spinal cord injuries based on the observed patient motions.


Title: Learning User Preferences in Robot Motion Planning Through Interaction
Key Words: human-robot interaction  mobile robots  optimal control  path planning  user preferences  robot motion planning  complex task specifications  human-robot interaction  temporal constraints  complex robot tasks  user constraint  user-optimal path  spatial constraints  Task analysis  Service robots  Roads  Robot motion  Planning  Shortest path problem 
Abstract: In this paper we develop an approach for learning user preferences for complex task specifications through human-robot interaction. We consider the problem of planning robot motion in a known environment, but where a user has specified additional spatial and temporal constraints on allowable robot motions. To illustrate the impact of the user's constraints on performance, we iteratively present users with alternative solutions on an interface. The user provides a ranking of alternate paths, and from this we learn about the importance of different constraints. This allows for an accessible method for specifying complex robot tasks. We present an algorithm that iteratively builds a set of constraints on the relative importance of each user constraint, and prove that with sufficient interaction, the algorithm determines a user-optimal path. We demonstrate the practical performance by simulating realistic material transport scenarios in industrial facilities.


Title: Visual Articulated Tracking in the Presence of Occlusions
Key Words: image colour analysis  iterative methods  manipulators  object tracking  robot vision  RGB-D camera  manipulated object  per-pixel data-to-model associations  tracked object  Iterative Closest Point  visual articulated tracking  robotic manipulator  Manipulators  Data models  Visualization  Robot sensing systems  Training  Radio frequency 
Abstract: This paper focuses on visual tracking of a robotic manipulator during manipulation. In this situation, tracking is prone to failure when visual distractions are created by the object being manipulated and the clutter in the environment. Current state-of-the-art approaches, which typically rely on model-fitting using Iterative Closest Point (ICP), fail in the presence of distracting data points and are unable to recover. Meanwhile, discriminative methods which are trained only to distinguish parts of the tracked object can also fail in these scenarios as data points from the occlusions are incorrectly classified as being from the manipulator. We instead propose to use the per-pixel data-to-model associations provided from a random forest to avoid local minima during model fitting. By training the random forest with artificial occlusions we can achieve increased robustness to occlusion and clutter present in the scene. We do this without specific knowledge about the type or location of the manipulated object. Our approach is demonstrated by using dense depth data from an RGB-D camera to track a robotic manipulator during manipulation and in presence of occlusions.


Title: Planar Object Tracking in the Wild: A Benchmark
Key Words: image motion analysis  image sequences  object detection  object tracking  robot vision  video signal processing  vision-based robotic applications  evaluating state-of-the-art algorithms  carefully designed planar object tracking benchmark  planar objects  Object tracking  Benchmark testing  Cameras  Target tracking  Robots 
Abstract: Planar object tracking is an actively studied problem in vision-based robotic applications. While several benchmarks have been constructed for evaluating state-of-the-art algorithms, there is a lack of video sequences captured in the wild rather than in constrained laboratory environment. In this paper, we present a carefully designed planar object tracking benchmark containing 210 videos of 30 planar objects sampled in the natural environment. In particular, for each object, we shoot seven videos involving various challenging factors, namely scale change, rotation, perspective distortion, motion blur, occlusion, out-of-view, and unconstrained. The ground truth is carefully annotated semi-manually to ensure the quality. Moreover, eleven state-of-the-art algorithms are evaluated on the benchmark using two evaluation metrics, with detailed analysis provided for the evaluation results. We expect the proposed benchmark to benefit future studies on planar object tracking.


Title: Constrained Confidence Matching for Planar Object Tracking
Key Words: image matching  image motion analysis  Kalman filters  motion estimation  object detection  object tracking  tracking  template tracking algorithms  occlusion detector  motion estimation  state-of-the-art planar object trackers  robust Kalman filter  planar object tracking  heavy motion blur  Robustness  Lighting  Perturbation methods  Object tracking  Kalman filters  Visualization 
Abstract: Tracking planar objects has a wide range of applications in robotics. Conventional template tracking algorithms, however, often fail to observe fast object motion or drift significantly after a period of time, due to drastic object appearance change. To address such challenges, we propose a novel constrained confidence matching algorithm for motion estimation and a robust Kalman filter for template updating. Integrated with an accurate occlusion detector, our approach achieves accurate motion estimation in presence of partial occlusion, by excluding occluded pixels from computation of motion parameters. Furthermore, the proposed Kalman filter employs a novel control-input model to handle the object appearance change, which brings our tracker high robustness against sudden illumination change and heavy motion blur. For evaluation, we compare the proposed tracker with several state-of-the-art planar object trackers on two public benchmark datasets. Experimental results show that our algorithm achieves robust tracking results against various environmental variations, and outperforms baseline algorithms remarkably on both datasets.


Title: Deep Forward and Inverse Perceptual Models for Tracking and Prediction
Key Words: deconvolution  feedforward neural nets  image sensors  Kalman filters  learning (artificial intelligence)  mobile robots  nonlinear filters  state estimation  high-dimensional images  deconvolutional methods  robotic system  robot trajectories  convolutional neural network model  photo-realistic images  image generation  video frames  perceptual model  robotics  inverse models  inverse perceptual models  Predictive models  Inverse problems  Robot sensing systems  Kinematics  Training 
Abstract: We consider the problems of learning forward models that map state to high-dimensional images and inverse models that map high-dimensional images to state in robotics. Specifically, we present a perceptual model for generating video frames from state with deep networks, and provide a framework for its use in tracking and prediction tasks. We show that our proposed model greatly outperforms standard deconvolutional methods and GANs for image generation, producing clear, photo-realistic images. We also develop a convolutional neural network model for state estimation and compare the result to an Extended Kalman Filter to estimate robot trajectories. We validate all models on a real robotic system.


Title: ModQuad: The Flying Modular Structure that Self-Assembles in Midair
Key Words: attitude control  autonomous aerial vehicles  mobile robots  multi-robot systems  robot dynamics  self-assembly  midair  modular robotic structure  self-assemble  agile flying modules  quadrotor platform  ModQuad swarm  modular flying structures  decentralized modular attitude controller  docking method  flying modular structure  flying structure assembling  cooperative flying method  Robot kinematics  Rotors  Buildings  Payloads  Shape  Task analysis 
Abstract: We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.


Title: Autonomous Battery Exchange of UAVs with a Mobile Ground Base
Key Words: autonomous aerial vehicles  control engineering computing  mobile robots  multi-robot systems  planetary rovers  small scale UAV  autonomous battery exchange operation  autonomous operations  landed UAV  ground rover  autonomous outdoor experiments  collaborative software framework  robotic systems  persistence  battery exchange mechanism  service station  robotic arm  mobile ground base  Batteries  Task analysis  Actuators  Robot kinematics  Planning  Manipulators 
Abstract: This paper presents the autonomous battery exchange operation for small scale UAVs, using a mobile ground base that carries a robotic arm and a service station containing the battery exchange mechanism. The goal of this work is to demonstrate the means to increase the autonomy and persistence of robotic systems without requiring human intervention. The design and control of the system and its components are presented in detail, as well as the collaborative software framework used to plan and execute complex missions. Finally, the results of autonomous outdoor experiments are presented, in which the ground rover successfully localizes, retrieves, services, and deploys the landed UAV, proving its capacity to extend and enhance autonomous operations.


Title: A Whole Body Attitude Stabilizer for Hybrid Wheeled-Legged Quadruped Robots
Key Words: attitude control  legged locomotion  motion control  quadratic programming  robot kinematics  stability  wheels  motion capabilities  Centauro robot  body attitude stabilizer  attitude balancing strategy  quadrupedal robot  inverse kinematics solution scheme  stable reaction response  smooth reaction response  robot hybrid wheeled-legged mobility system  quadratic programming optimization  Wheels  Legged locomotion  Task analysis  Stability analysis  Kinematics 
Abstract: This work presents a new attitude balancing strategy implemented and validated on a quadrupedal robot equipped with a custom hybrid wheel-legged mobility system. The proposed method uses an inverse kinematics solution scheme based on Quadratic Programming optimization to generate full body motions that ensure the desired balancing performances. The strategy generates a compliant behaviour to cope with the applied external forces resulting in a stable and smooth reaction response. Furthermore, the method takes advantage of the robot hybrid wheeled-legged mobility system to provide new motion capabilities and balancing reactions as it will be shown through the paper. Extensive simulation studies on the Centauro robot are presented. Results show the efficiency of the propose method demonstrating significant contribution in the rejection of the applied external disturbances.


Title: Learning Motion Predictors for Smart Wheelchair Using Autoregressive Sparse Gaussian Process
Key Words: adaptive control  autoregressive processes  distance measurement  Gaussian processes  handicapped aids  image capture  interactive devices  learning (artificial intelligence)  mobile robots  motion control  path planning  robot vision  wheelchairs  motion predictors  smart wheelchair  robotics  analog joystick inputs  black-box transformations  intuitive motion control  adaptable motion control  human operators  commercial PWC platform  physical modification  electronic modification  industry standard auxiliary input port  visual odometry  joystick signals  autoregressive sparse Gaussian process model  short-term path prediction experiments  powered wheelchair platform  RGB-D camera  Arduino interface board  motion data capture  standard axle mounted odometers  Cameras  Gaussian processes  Robot sensing systems  Wheelchairs  Mobile robots  Hardware 
Abstract: Constructing a smart wheelchair on a commercially available powered wheelchair (PWC) platform avoids a host of seating, mechanical design and reliability issues but requires methods of predicting and controlling the motion of a device never intended for robotics. Analog joystick inputs are subject to black-box transformations which may produce intuitive and adaptable motion control for human operators, but complicate robotic control approaches; furthermore, installation of standard axle mounted odometers on a commercial PWC is difficult. In this work, we present an integrated hardware and software system for predicting the motion of a commercial PWC platform that does not require any physical or electronic modification of the chair beyond plugging into an industry standard auxiliary input port. This system uses an RGB-D camera and an Arduino interface board to capture motion data, including visual odometry and joystick signals, via ROS communication. Future motion is predicted using an autoregressive sparse Gaussian process model. We evaluate the proposed system on real-world short-term path prediction experiments. Experimental results demonstrate the system's efficacy when compared to a baseline neural network model.


Title: Local Behavior-Based Navigation in Rough Off-Road Scenarios Based on Vehicle Kinematics
Key Words: mobile robots  off-road vehicles  path planning  robot dynamics  robot kinematics  trajectory control  elevation grid map  robot orientation  behavior-based control paradigm  rough terrains  traversability  occupancy maps  on-road local navigation approaches  trajectory candidates  behavior-based local navigation approach  vehicle kinematics  rough off-road scenarios  Wheels  Navigation  Trajectory  Robot sensing systems  Axles  Three-dimensional displays  robotics  off-road navigation  behavior-based control  tentacles 
Abstract: This paper describes a novel behavior-based local navigation approach for rough off-road scenarios. Trajectory candidates are generated based on vehicle kinematics and dynamics as well as the desired global trajectory. In contrast to on-road local navigation approaches, the work at hand proposes the use of a shiftable elevation grid map instead of occupancy maps since traversability in rough terrains does not only depend on location, but also on the robot's orientation. The traversability is evaluated by determining tire contact points with the terrain to take various different safety and efficiency aspects like underbody collisions and rollover risk into account. By exploiting the behavior-based control paradigm, the navigation approach can be easily extended and its robustness is shown in experimental evaluations using an Unimog U5023.


Title: Controlling a Non-Holonomic Mobile Manipulator in a Constrained Floor Space
Key Words: collision avoidance  end effectors  mobile robots  motion control  redundant manipulators  constrained floor space  robotic manipulators  mobile platforms  warehouse shelf stacking  assistive robots  critical time  continuous operation  experienced operator  end-effector workspace  floor obstacles  straightforward control method  time-dependent constraints  time constraints  mobile base trajectory  sensor-assisted obstacle avoidance  freedom mobility  safe obstacle-free time-independent path  5-DoF redundant Planar Mobile Manipulator  9-DoF redundant mobile manipulator  mobile platform motion  allowed obstacle-free path  task completion  nonholonomic mobile manipulator  Manipulators  Task analysis  Trajectory  Hardware  Kinematics  Robot kinematics 
Abstract: Robotic manipulators that are attached to mobile platforms are often used in workspaces that require the end-effector to mobilize beyond the manipulator's limited reach, such as in warehouse shelf stacking and similar applications. However, such assistive robots fall short of completing tasks that require the end-effector to be situated in a specific configuration at a critical time during the task. Traditionally, users control the mobile base to situate the arm such that the task can be completed through continuous operation. This requires an experienced operator who can predict the needed end-effector workspace, and can operate the base accordingly to maximize the likelihood of a successful task while avoiding any floor obstacles. In this work, we propose a straightforward control method that provides sufficient freedom to the end-effector to complete a task that is bound by time-dependent constraints. This is achieved by relaxing the time constraints on the mobile base trajectory in a floor space obstructed by obstacles. The trajectory of the platform is determined by sensor-assisted obstacle avoidance algorithm such that a single degree of freedom mobility can be represented through a safe obstacle-free time-independent path. The proposed control method is implemented in simulation and on physical hardware built in our labs. The simulation included a 5-DoF redundant Planar Mobile Manipulator (PMM). The hardware implementation and testing utilized a 9-DoF redundant mobile manipulator. The implementation results demonstrate the effectiveness of the control method in adjusting the mobile platform motion along its allowed obstacle-free path to enable the end-effector to follow its trajectory for task completion that would otherwise fail to complete when conventional control methods are used.


Title: A Parametric MPC Approach to Balancing the Cost of Abstraction for Differential-Drive Mobile Robots
Key Words: mobile robots  motion control  predictive control  Parametric MPC approach  differential-drive mobile robots  three-state unicycle model  two-state single-integrator model  maneuverability costs  control signal  Parametric Model Predictive Control method  Mobile robots  Wheels  Robot kinematics  Predictive control  Measurement  Parametric statistics 
Abstract: When designing control strategies for differential-drive mobile robots, one standard tool is the consideration of a point at a fixed distance along a line orthogonal to the wheel axis instead of the full pose of the vehicle. This abstraction supports replacing the non-holonomic, three-state unicycle model with a much simpler two-state single-integrator model (i.e., a velocity-controlled point). Yet this transformation comes at a performance cost, through the robot's precision and maneuverability. This work contains derivations for expressions of these precision and maneuverability costs in terms of the transformation's parameters. Furthermore, these costs show that only selecting the parameter once over the course of an application may cause an undue loss of precision. Model Predictive Control (MPC) represents one such method to ameliorate this condition. However, MPC typically realizes a control signal, rather than a parameter, so this work also proposes a Parametric Model Predictive Control (PMPC) method for parameter and sampling horizon optimization. Experimental results are presented that demonstrate the effects of the parameterization on the deployment of algorithms developed for the single-integrator model on actual differential-drive mobile robots.


Title: Dynamic Simulation of Planetary Rovers with Terrain Property Mapping * Research supported by National Natural Science Foundation of China (Grant No. 61370033), National Basic Research Program of China (Grant No. 2013CB035502), Foundation for Innovative Research Groups of the Natural Science Foundation of China (Grant No. 51521003), Foundation of Chinese State Key Laboratory of Robotics and Systems (Grant No. SKLRS201501B, SKLRS20164B), Harbin Applied Technology Project of Research and Development (2015RQQXJ081), and the “111 Project” (Grant No. B07018).
Key Words: cartography  control engineering computing  geometry  Mars  mobile robots  planetary rovers  soil  wheels  digital elevation map  terrain physical properties  terrain pressure-sinkage property  contact model  soil  terramechanics model  shearing property  friction angle  Mars exploration  complex terrains  terrain property mapping  planetary rovers  dynamic simulation  three-wheel-rover  Soil  Mathematical model  Wheels  Stress  Computational modeling  Shearing  Force 
Abstract: Simulation of planetary rovers moving on complex terrains is critical for Mars exploration. Equivalent stiffness is proposed and used to characterize the pressure-sinkage property of terrain, while friction angle to characterize the shearing property. Terramechanics model for calculating forces between rigid wheel and soil is proved to be the same with that contact model for calculating forces between rigid wheel and rock. A Digital Elevation Map with Physical Properties is developed and applied to simulate terrain physical properties along with its geometry information. The established methods are validated using simulation and experimental tests with a three-wheel-rover.


Title: Design Considerations and Redundancy Resolution for Variable Geometry Continuum Robots
Key Words: Jacobian matrices  manipulator kinematics  mobile robots  redundant manipulators  design alternative  kinematic redundancy  kinematic parameter adaptation  continuum robot design  admissible design parameter values  joint forces  gradient descent redundancy resolution problem  variable geometry continuum  joint limits  multibackbone continuum robots  continuum robot segment  situational awareness  task execution performance  Couplings  Kinematics  Elbow  Robot sensing systems  Redundancy  Fasteners  Continuum robots  variable geometry robots  redundancy  angulated scissor mechanism  kinematics 
Abstract: Current multi-backbone continuum robots are limited to a constant cross-sectional diameter. This paper proposes a design alternative that overcomes this limitation. The ability to change the diameter of a continuum robot expands the repertoire of kinematic redundancy and enables kinematic parameter adaptation to optimize performance. A continuum robot design based on the angulated scissor mechanism is presented along with its position analysis. An exploration of admissible design parameter values for a given continuum robot segment with a desired maximum curvature while maintaining an open bore along its center is also carried out. A design presenting how this mechanism can be incorporated into a continuum robot is shown and a strategy for minimizing joint forces and avoiding joint limits is formulated as a gradient descent redundancy resolution problem in a simulation case study. The simulation results show that varying the diameter can significantly reduce joint forces while preserving the workspace and avoiding joint limits. This work is a first step towards continuum robots with situational awareness that will use their sensing capabilities to adapt their structure in order to optimize task execution performance.


Title: Extending a Dynamic Friction Model with Nonlinear Viscous and Thermal Dependency for a Motor and Harmonic Drive Gear
Key Words: brushless DC motors  compensation  electric drives  friction  humanoid robots  manipulator dynamics  dynamic friction model  thermal dependency  robotic actuation  friction behavior  actuator components  friction compensation  output torque estimation  dynamic simulations  brush-less DC motor  harmonic drive gear  humanoid David  DLR Floating Spring Joint  friction models  nonlinear viscous dependency  temperature 24 degC to 50 degC  Friction  Mathematical model  Torque  Gears  Robots  Harmonic analysis  Springs 
Abstract: In robotic actuation a well identified and modeled friction behavior of the actuator components helps to significantly improve friction compensation, output torque estimation, and dynamic simulations. The friction of two components, i.e. a brush-less DC motor and a harmonic drive gear (HD) is investigated in order to build an accurate dynamic model of the main actuator of the arms of the humanoid David namely the DLR Floating Spring Joint (FSJ). A dedicated testbed is built to precisely identify input and output torques, temperatures, positions, and elasticities of the investigated components at a controlled environment temperature. Extensive test series are performed in the full velocity operating range in a temperature interval from 24 to 50 °C. The nonlinear influences of velocity and temperature are identified to be dominant effects. It is proposed how to include these nonlinear velocity and temperature dependencies into a static and a dynamic friction model, e.g. LuGre. Dynamic models of the motor and HD are built with the proposed method and experimentally evaluated. The new models are compared to friction models with linear dependencies and show a significant improvement of correspondence with reality.


Title: Eddy Current Damper Design for Vibration Suppression in Robotic Milling Process
Key Words: damping  design engineering  eddy currents  finite element analysis  frequency response  industrial robots  machine tool spindles  machining chatter  magnetic flux  magnetic forces  mechanical stability  milling  vibration control  robotic milling process  vibration attenuation method  vibration suppression process  tool tip frequency response function  milling spindle tool  chatter stability  magnetic force  magnetic flux density  finite element method  eddy current damper design  Robots  Milling  Damping  Tools  Force  Copper  Vibrations  Robotic milling  eddy current damper  vibration suppression  chatter 
Abstract: This paper presents a novel eddy current damper design for chatter suppression in robotic milling process. The designed eddy current dampers are installed on a milling spindle to damp the tool tip vibrations. The structural design of the eddy current dampers and the working principle of the proposed vibration attenuation method are explained. Finite element method is used to analyze the magnetic flux density and the magnetic force generated by the designed eddy current. The dynamics of the robotic milling system without and with eddy current dampers are modeled, and the damping performance of the proposed method is verified through simulations in both frequency and time domains. The results show that the peaks of the tool tip frequency response function caused by the spindle and milling tool modes are damped by 3.2 dB and 5.3 dB, respectively, and the chatter stability is improved by about 43% in the high spindle speed zone, compared to the case without eddy current dampers.


Title: Learning-Based Image Enhancement for Visual Odometry in Challenging HDR Environments
Key Words: convolution  distance measurement  feedforward neural nets  image enhancement  image representation  image sequences  learning (artificial intelligence)  object tracking  robot vision  SLAM (robots)  visual odometry  high dynamic range environments  interest points  bold assumptions  brightness constancy  deep learning perspective  deep neural network  long short term memory  deep networks  VO framework  convolutional neural network  image enhancement  illumination conditions  HDR environments  Robustness  Cameras  Brightness  Lighting  Training  Decoding  Estimation 
Abstract: One of the main open challenges in visual odometry (VO) is the robustness to difficult illumination conditions or high dynamic range (HDR) environments. The main difficulties in these situations come from both the limitations of the sensors and the inability to perform a successful tracking of interest points because of the bold assumptions in VO, such as brightness constancy. We address this problem from a deep learning perspective, for which we first fine-tune a deep neural network with the purpose of obtaining enhanced representations of the sequences for VO. Then, we demonstrate how the insertion of long short term memory allows us to obtain temporally consistent sequences, as the estimation depends on previous states. However, the use of very deep networks enlarges the computational burden of the VO framework; therefore, we also propose a convolutional neural network of reduced size capable of performing faster. Finally, we validate the enhanced representations by evaluating the sequences produced by the two architectures in several state-of-art VO algorithms, such as ORB-SLAM and DSO.


Title: Spherical Visual Gyroscope for Autonomous Robots Using the Mixture of Photometric Potentials
Key Words: aerospace components  attitude control  autonomous aerial vehicles  cameras  end effectors  gyroscopes  image sensors  image sequences  least squares approximations  mobile robots  nonlinear programming  robot vision  robust control  spherical visual gyroscope  autonomous robots  direct omnidirectional visual gyroscope  mobile robotic platforms  camera-robot  pixel intensities  extended convergence domain  spherical image sequences  robot arm  3D orientation  Mixture of Photometric Potentials  image-similarity measure  nonlinear least-squares optimization scheme  twin-fisheye camera  end-effector  fixed-wing UAV  robust attitude estimates  Cameras  Visualization  Gyroscopes  Robot vision systems  Three-dimensional displays  Convergence 
Abstract: In this paper, we present a new direct omnidirectional visual gyroscope for mobile robotic platforms. The gyroscope estimates the 3D orientation of a camera-robot by comparing the current spherical image with that acquired at a reference pose. By transforming pixel intensities into a Mixture of Photometric Potentials, we introduce a novel image-similarity measure which can be seamlessly integrated into a classical nonlinear least-squares optimization scheme, offering an extended convergence domain. Our method provides accurate and robust attitude estimates, and it is easy-to-use since it involves a single tuning parameter, the width of the photometric potentials (Gaussian functions, in this work) controlling the power of attraction of each pixel. The visual gyroscope has been successfully tested on spherical image sequences generated by a twin-fisheye camera mounted on the end-effector of a robot arm and on a fixed-wing UAV.


Title: Correlation Flow: Robust Optical Flow Using Kernel Cross-Correlators
Key Words: aircraft control  aircraft navigation  autonomous aerial vehicles  cameras  helicopters  mobile robots  position control  correlation flow  reliable velocity estimation  robust trajectory estimation  robust optical flow  kernel cross-correlators  position estimation  autonomous robot navigation  autonomous navigation  kernel cross-correlator based algorithm  monocular camera  ROS framework  yaw rate  Kernel  Optical sensors  Optical imaging  Correlation  Correlators  Robustness  Estimation 
Abstract: Robust velocity and position estimation is crucial for autonomous robot navigation. The optical flow based methods for autonomous navigation have been receiving increasing attentions in tandem with the development of micro unmanned aerial vehicles. This paper proposes a kernel cross-correlator (KCC) based algorithm to determine optical flow using a monocular camera, which is named as correlation flow (CF). Correlation flow is able to provide reliable and accurate velocity estimation and is robust to motion blur. In addition, it can also estimate the altitude velocity and yaw rate, which are not available by traditional methods. Autonomous flight tests on a quadcopter show that correlation flow can provide robust trajectory estimation with very low processing power. The source codes are released based on the ROS framework.


Title: Cubic Range Error Model for Stereo Vision with Illuminators
Key Words: cameras  image sensors  robot vision  stereo image processing  telecommunication scheduling  cubic range error model  stereo vision  low-cost depth sensors  stereo camera setup  robotics  augmented reality  map generation  sensor scheduling policy  multisensor setup  range error models  uncertainty estimates  range measurements  integrated illuminators  off-the-shelf structured light stereo system  Cameras  Robot sensing systems  Uncertainty  Lighting  Geometry 
Abstract: Use of low-cost depth sensors, such as a stereo camera setup with illuminators, is of particular interest for numerous applications ranging from robotics and transportation to mixed and augmented reality. The ability to quantify noise is crucial for these applications, e.g., when the sensor is used for map generation or to develop a sensor scheduling policy in a multi-sensor setup. Range error models provide uncertainty estimates and help weigh the data correctly in instances where range measurements are taken from different vantage points or with different sensors. Such a model is derived in this work. We show that the range error for stereo systems with integrated illuminators is cubic and validate the proposed model experimentally with an off-the-shelf structured light stereo system. The experiments confirm the validity of the model and simplify the application of this type of sensor in robotics.


Title: Fusion of Stereo and Still Monocular Depth Estimates in a Self-Supervised Learning Context
Key Words: feedforward neural nets  image colour analysis  intelligent robots  learning (artificial intelligence)  mobile robots  robot vision  SLAM (robots)  monocular depth estimates  autonomous robots  self-supervised learning setup  stereo vision depth  convolutional neural network  fusion method  CNN estimates  autonomous navigation  depth estimation  self-supervised learning  Estimation  Stereo vision  Robot sensing systems  Cameras  Training  Self-supervised learning  monocular depth estimation  stereo vision  convolutional neural networks 
Abstract: We study how autonomous robots can learn by themselves to improve their depth estimation capability. In particular, we investigate a self-supervised learning setup in which stereo vision depth estimates serve as targets for a convolutional neural network (CNN) that transforms a single still image to a dense depth map. After training, the stereo and mono estimates are fused with a novel fusion method that preserves high confidence stereo estimates, while leveraging the CNN estimates in the low-confidence regions. The main contribution of the article is that it is shown that the fused estimates lead to a higher performance than the stereo vision estimates alone. Experiments are performed on the KITTI dataset, and on board of a Parrot SLAMDunk, showing that even rather limited CNNs can help provide stereo vision equipped robots with more reliable depth maps for autonomous navigation.


Title: Exposure Control Using Bayesian Optimization Based on Entropy Weighted Image Gradient
Key Words: cameras  entropy  gradient methods  optimisation  robot vision  image degradation  exposure control scheme  image frame grab  light conditions  vision-based approaches  optimal exposure value  image information measure  dynamic lighting conditions  camera exposure  vision-based robotic applications  entropy weighted image gradient  Bayesian optimization  Entropy  Measurement  Cameras  Optimization  Bayes methods  Robot vision systems 
Abstract: Under- and oversaturation can cause severe image degradation in many vision-based robotic applications. To control camera exposure in dynamic lighting conditions, we introduce a novel metric for image information measure. Measuring an image gradient is typical when evaluating its level of image detail. However, emphasizing more informative pixels substantially improves the measure within an image. By using this entropy weighted image gradient, we introduce an optimal exposure value for vision-based approaches. Using this newly invented metric, we also propose an effective exposure control scheme that covers a wide range of light conditions. When evaluating the function (e.g., image frame grab) is expensive, the next best estimation needs to be carefully considered. Through Bayesian optimization, the algorithm can estimate the optimal exposure value with minimal cost. We validated the proposed image information measure and exposure control scheme via a series of thorough experiments using various exposure conditions.


Title: Compliant Manipulation of Free-Floating Objects
Key Words: force control  force sensors  manipulators  minimisation  motion control  position control  interaction forces  direct force control  implicit force control algorithms  compliant manipulation  free-floating objects  compliant motions  reaction forces  constant force  manipulator inertia  KUKA LWR4+ manipulator arm  Manipulators  Force  Force control  Impedance  Damping  Aerospace electronics 
Abstract: Compliant motions allow alignment of workpieces using naturally occurring interaction forces. However, free-floating objects do not have a fixed base to absorb the reaction forces caused by the interactions. Consequently, if the interaction forces are too high, objects can gain momentum and move away after contact. This paper proposes an approach based on direct force control for compliant manipulation of free-floating objects. The objective of the controller is to minimize the interaction forces while maintaining the contact. The proposed approach achieves this by maintaining small constant force along the motion direction and an apparent reduction of manipulator inertia along remaining Degrees of Freedom (DOF). Simulation results emphasize the importance of relative inertia of the robotic manipulator with respect to the free-floating object. The experiments were performed with KUKA LWR4+ manipulator arm and a two-dimensional micro-gravity emulator (object floating on an air bed), which was developed in-house. It was verified that the proposed control law is capable of controlling the interaction forces and aligning the tools without pushing the object away. We conclude that direct force control works better with a free-floating object than implicit force control algorithms, such as impedance control.


Title: Validation of the Robot Rendezvous and Grasping Manoeuvre Using Microgravity Simulators
Key Words: aerospace robotics  artificial satellites  control system synthesis  end effectors  industrial robots  multi-robot systems  path planning  space debris  space vehicles  robot rendezvous  grasping manoeuvre  unmanned chaser satellite  performing rendezvous  grasping manoeuvres  space debris  manoeuvres high disturbances  manipulator arm end-effector  robotic subsystem  chaser rendezvous  planar air-bearing microgravity simulators  industrial robots  specified test-bed system  Manipulators  Satellites  Orbits  Space vehicles  Service robots  Control systems 
Abstract: Robots mounted on an unmanned chaser satellite could be used for performing rendezvous and grasping manoeuvres in order to repair satellites or remove space debris from orbit. Use of manipulators for such purposes is challenging, since the performed task need to be done autonomously, accurately and with high level of robustness. During manoeuvres high disturbances might appear e.g. due to contact between the manipulator arm end-effector and the target spacecraft. In this paper an approach for validation of the robotic subsystem during chaser rendezvous and grasping manoeuvre has been shown. Two type of testbed systems were used: planar air-bearing microgravity simulators and a test-bed system with industrial robots. The proposed approach took advantage of possible replacement of particular subsystem in reference model or reference hardware in specified test-bed system. The list of tests performed are included in the paper.


Title: Collision-Based Contact Mode Estimation for Dynamic Rigid Body Capture
Key Words: aerospace robotics  collision avoidance  manipulator dynamics  mobile robots  motion estimation  multi-robot systems  particle filtering (numerical methods)  robot vision  space debris  vehicle dynamics  space debris  Brach collision model  collision-based contact mode estimation  particle filter  pre-capture phase  motion estimation error  reasonable computation resources  collision-triggered filter  moving rigid body  force-torque sensor  dynamic rigid body capture  Estimation  Robot sensing systems  Computational modeling  Collision avoidance  Predictive models  Bayes methods 
Abstract: This paper proposes real-time collision-based contact mode estimation with only a force-torque sensor for capturing a moving rigid body. The contact modes are defined for determining when to generate the signal to close the robotic hand for establishing object closure. In our particle filter approach, collision-triggered filter is used to determine the contact mode with the least amount of computation. Brach's collision model is used for our collision model-based approach for a rigid body because it is computationally light-weighted and enables the sampling of three collision properties for the particle filter. The validity of our method is experimentally demonstrated by achieving the highest success rate using the reasonable computation resources required (average of 3.9 milliseconds and worst of 6.1 milliseconds with our setup), and verifying each computation resource (or number of particles) based on the size of motion estimation error in the pre-capture phase.


Title: Workspace Fixation for Free-Floating Space Robot Operations
Key Words: aerospace robotics  end effectors  mobile robots  CoM  degree-of-freedom  free-floating space robot operations  workspace fixation  6DOF moving base  center-of-mass regulation  end-effector  Manipulators  Symmetric matrices  Fuels  Robot kinematics  Satellites 
Abstract: When a space robot accidentally or voluntarily comes in contact with a target object, a workspace shift happens due to exchange of momentum between the objects. The problem of workspace adjustment is addressed herein. A novel controller is derived to simultaneously adjust the workspace and control the end-effector pose. The controller is based on a center-of-mass (CoM) regulation which fixes the workspace in the inertial space while leaving the base free to move, resulting in fuel efficiency. The control is validated on hardware using a robotic simulator composed of a seven degree-of-freedom (DOF) arm mounted on a 6DOF moving base.


Title: Robust Visual Localization for Hopping Rovers on Small Bodies
Key Words: cameras  planetary rovers  pose estimation  robot vision  SLAM (robots)  space vehicles  visual SLAM algorithms  ORB-SLAM2  orbiting primary spacecraft  onboard visual simultaneous localization and mapping  visual SLAM implementation  wide field of view camera  off-nadir camera pointing angles  narrow FOV camera  orbiting spacecraft  visual appearance  high-contrast shadows  hopping rover  illumination angles  Solar System bodies  collaborative visual localization method  robust visual localization  time 1.0 hour to 12.0 hour  Cameras  Space vehicles  Visualization  Simultaneous localization and mapping  Optimization  Lighting  Solar system 
Abstract: We present a collaborative visual localization method for rovers designed to hop and tumble across the surface of small Solar System bodies, such as comets and asteroids. In a two-phase approach, an orbiting primary spacecraft first maps the surface of a body by capturing images from various poses and illumination angles; these images are processed to create a prior map of 3D landmarks. In the second phase, a hopping rover is deployed to the surface where it uses a camera to relocalize to the prior map and to perform onboard visual simultaneous localization and mapping (SLAM). Small bodies present several unique challenges to existing visual SLAM algorithms, such as high-contrast shadows that move quickly over the surface due to the short (e.g. 1-12 hour) rotational periods, and large changes in visual appearance between orbit and the surface, where image scale varies by many orders of magnitude (kilometers to centimeters). In this work, we describe how to augment ORB-SLAM2-a state of the art visual SLAM implementation-to handle large variations in illumination by fusing prior images with varying illumination angles. We demonstrate how a hopping rover can use a wide field of view (FOV) camera to relocalize to prior maps captured by an orbiting spacecraft with a narrow FOV camera, and how the growth of pose and scale errors can be bounded by periodic loop closures during large hops. The proposed method is evaluated with sequences of images captured around a mock asteroid; it is shown to be robust to varying illumination angles, scene scale changes, and off-nadir camera pointing angles.


Title: Wheel Design Methodology for a Lunar Exploration Rover in Order to Improve Trafficability Considering Operation Environment
Key Words: mobile robots  planetary rovers  wheels  wheel design methodology  lunar exploration rover  operation environment  successful mission  rover wheel  power consumption  conceptual design stage  power acquisition  terrain characteristics  lunar simulant  wheel-terrain interaction model  optimal wheel dimension  maximal trafficability  single wheel test bed  tractive performance maximization  Wheels  Moon  Mathematical model  Stress  Design methodology  Power demand  Azimuth 
Abstract: For achieving a successful mission in lunar exploration, not only traversability of exploration rover should be predicted but also operation environment should be considered under the limited power condition. Therefore, an optimal design of rover wheel for minimizing power consumption and maximizing tractive performance is required by conducting conceptual design stage. This paper describes settlement of requirements at system level and modeling of operation environment such as power acquisition and terrain characteristics in the lunar simulant. Using the wheel-terrain interaction model, a wheel design methodology was proposed to obtain an optimal wheel dimension, which meet the limited power condition along with maximal trafficability according to the each landing site. In addition, the results from the above approach have been validated with the experimental results using a single wheel test bed on the lunar simulant.


Title: Whole-Body Impedance Control for a Planetary Rover with Robotic Arm: Theory, Control Design, and Experimental Validation
Key Words: aerospace robotics  control system synthesis  controllability  manipulators  mechanical variables control  motion control  optimisation  planetary rovers  position control  rescue robots  robot kinematics  wheels  planetary rover  robotic arm  control framework  versatile manipulation  planetary exploration  control design  experimental validation  planetary rovers  contact interaction  terrestrial applications  terrestrial whole-body controllers  wheel force distribution  whole-body impedance control  maneuverability  whole-body Cartesian impedance controller  global optimization  overactuation redundancy  mobile base  kinematic redundancy handling  serial kinematic subchain  DLR Lightweight Rover Unit  rough terrain  terrestrial search-and-rescue scenario  Wheels  Manipulators  Impedance  Mobile robots  Robot kinematics  Null space 
Abstract: Future planetary rovers will gain the ability to manipulate their environment in addition to the maneuverability of current systems. For dedicated contact interaction, Cartesian impedance control is a well-established approach from numerous terrestrial applications. In this paper we will present a whole-body Cartesian impedance controller for a planetary rover equipped with a robotic arm. In contrast to classical terrestrial whole-body controllers, the issue of proper wheel force distribution will be addressed within the control framework. A global optimization solves this redundancy in the over-actuation of the mobile base while additionally handling the kinematic redundancy in the serial kinematic sub-chain of the robot. The approach is experimentally validated on the DLR Lightweight Rover Unit. It can be used for versatile manipulation in rough terrain such as encountered in planetary exploration or terrestrial search-and-rescue scenarios.


Title: Kinematic Design Optimization of a Parallel Surgical Robot to Maximize Anatomical Visibility via Motion Planning
Key Words: biological tissues  manipulator kinematics  medical robotics  motion control  needles  optimisation  path planning  simulated annealing  surgery  tissue surface  CRISP robot  parallel structure connection points  global stochastic optimization algorithm  kinematic design optimization  parallel surgical robot  Continuum Reconfigurable Incisionless Surgical Parallel robot  needle-diameter medical robot  minimally invasive procedures  motion planning  anatomical visibility  adaptive simulated annealing  ASA  Electron tubes  Kinematics  Collision avoidance  Robot kinematics  Cameras  Robot vision systems 
Abstract: We introduce a method to optimize on a patient-specific basis the kinematic design of the Continuum Reconfigurable Incisionless Surgical Parallel (CRISP) robot, a needle-diameter medical robot based on a parallel structure that is capable of performing minimally invasive procedures. Our objective is to maximize the ability of the robot's tip camera to view tissue surfaces in constrained spaces. The kinematic design of the CRISP robot, which greatly influences its ability to perform a task, includes parameters that are fixed before the procedure begins, such as entry points into the body and parallel structure connection points. We combine a global stochastic optimization algorithm, Adaptive Simulated Annealing (ASA), with a motion planner designed specifically for the CRISP robot. ASA facilitates exploration of the robot's design space while the motion planner enables evaluation of candidate designs based on their ability to successfully view target regions on a tissue surface. By leveraging motion planning, we ensure that the evaluation of a design only considers motions which do not collide with the patient's anatomy. We analytically show that the method asymptotically converges to a globally optimal solution and demonstrate our algorithm's ability to optimize kinematic designs of the CRISP robot on a patient-specific basis.


Title: Workspace, Transmissibility and Dynamics of a New 3T3R Parallel Pick-and-place Robot with High Rotational Capability
Key Words: actuators  end effectors  manipulator dynamics  manipulator kinematics  3-axis translations  rotations  robot end-effector  orientational workspace  gearbox  workspace volume  commercial Delta-type robots  high-speed parallel robot  6-axis Delta-type robot  structural complexity  rotational capability  3T3R parallel pick-and-place robot  commercial actuation combination  Robot kinematics  Manipulators  Actuators  Kinematics  Service robots  Dynamics 
Abstract: This paper presents a six-limb high-speed parallel robot for pick-and-place operations that is based on two Delta robots, where the two sub-platforms are connected by a gearbox. Unlike the current 6-axis Delta-type robot, all the actuators of the robot are mounted on a base platform, allowing to reduce the inertia for high dynamic performance. Besides the 3-axis translations, the three rotations of the robot end-effector are realized by the differential motions of the two sub-platforms in three directions for large orientational workspace, but without significantly increased structural complexity of gearbox, compared to the existing one. The kinematic problems are studied to reveal that the workspace volume of the robot is similar to the commercial Delta-type robots. The simplified dynamic model is established and the simulation results show that the robot can reach up to a 20G acceleration subject to the commercial actuation combination.


Title: Dynamic Control of Cable Driven Parallel Robots with Unknown Cable Stiffness: a Joint Space Approach
Key Words: cables (mechanical)  closed loop systems  control nonlinearities  control system synthesis  end effectors  feedback  linearisation techniques  manipulator dynamics  manipulator kinematics  motion control  position control  velocity control  closed-loop controllers  redundant dynamics  end effector  dynamic control  joint space approach  dynamic controller  joint variables  cable driven parallel robots  cable stiffness  observer linearization  three-tendon planar platform  backstepping technique  quasivelocity method  Observers  Kinematics  Position measurement  Velocity measurement  Jacobian matrices  Parallel robots 
Abstract: In the present paper we discuss a novel dynamic controller for Cable Driven Parallel Robots, based on the Backstepping technique. The main challenge in controlling these robots, is expressing the dynamic equilibrium with respect to the joint variables. This drawback makes the definition of closed-loop controllers more challenging, in comparison with their serial counterparts. The problem is tackled by considering redundant dynamics, expressed in both task and joints space and solved through the method of quasi-velocity. We propose the usage of the observer linearization to estimate the end effector pose and stiffness, by just measuring the motor position, velocity and torque. These variables are used in the feedback loop to control the pose of the end effector. A 3-tendon planar platform is used for the experimental analysis.


Title: Available Wrench Set for Planar Mobile Cable-Driven Parallel Robots
Key Words: cables (mechanical)  end effectors  manipulator kinematics  mobile robots  robot dynamics  geometric architecture  parallel manipulators  convex hull methods  hyperplane shifting methods  point-mass end-effector  static equilibrium  mobile cable-driven parallel robots  available wrench set  Task analysis  Parallel robots  Power cables  Collision avoidance  Prototypes  Wheels 
Abstract: Cable-Driven Parallel Robots (CDPRs) have several advantages over conventional parallel manipulators most notably a large workspace. CDPRs whose workspace can be further increased by modification of the geometric architecture are known as Reconfigurable Cable Driven Parallel Robots(RCDPRs). A novel concept of RCDPRs, known as Mobile CDPR (MCDPR) that consists of a CDPR carried by multiple mobile bases, is studied in this paper. The system is capable of autonomously navigating to a desired location then deploying to a standard CDPR. In this paper, we analyze the Static equilibrium (SE) of the mobile bases when the system is fully deployed. In contrast to classical CDPRs we show that the workspace of the MCDPR depends, not only on the tension limits, but on the SE constraints as well. We demonstrate how to construct the Available Wrench Set (AWS) for a planar MCDPR wih a point-mass end-effector using both the convex hull and Hyperplane shifting methods. The obtained results are validated in simulation and on an experimental platform consisting of two mobile bases and a CDPR with four cables.


Title: Closed-form Solution for the Direct Kinematics Problem of the Planar 3-RPR Parallel Mechanism
Key Words: manipulator dynamics  manipulator kinematics  pose estimation  robot vision  closed-form solution  direct kinematics problem  planar 3-RPR parallel mechanism  active prismatic joints  manipulator platform  pose estimations  reference drives  workspace limitations  Manipulators  Kinematics  Actuators  Sensors  Closed-form solutions  Legged locomotion  Conferences 
Abstract: In general, it is not possible to determine the actual manipulator platform's pose of a parallel mechanism from its active joints' coordinates. This problem is usually solved by using additional numerical procedures or by additional system information from auxiliary sensors, providing several weaknesses including initial pose estimations, reference drives, or workspace limitations. In this paper, we therefore introduce a closed-form solution for the direct kinematics problem of the planar 3-RPR parallel mechanism by using only the orientations of two active joints and the manipulator platform, where P denotes active prismatic joints and R passive revolute joints.


Title: Bounding Drift in Cooperative Localisation Through the Sharing of Local Loop Closures
Key Words: graph theory  mobile robots  robot vision  SLAM (robots)  direct intervehicle observations  fuses single vehicle SLAM  cooperative localisation  data association  map data  local subgraphs  shared states  localisation accuracy  bounding drift  local loop closures  robotic scenarios  data consistency  bandwidth limitations  single vehicle visual SLAM framework  Information matrix  Simultaneous localization and mapping  Bandwidth  Jacobian matrices  Visualization  Message systems 
Abstract: Handling loop closures and intervehicle observations in cooperative robotic scenarios remains a challenging problem due to data consistency, bandwidth limitations and increased computation requirements. This paper develops a general cooperative localisation and single vehicle Visual SLAM framework that includes direct intervehicle observations and pose to pose loop closures on each vehicle with states shared as required. This fuses single vehicle SLAM with cooperative localisation and avoids data association of map data across limited communication networks. The base problem is developed as a factor graph with each vehicle solving local subgraphs that are split based on intervehicle observations. We modify the order of variable elimination in subgraphs through manipulation of the square-root of the Information matrix to extract updates that include the historic states involved in the loop closures and do not require transmission of other states not involved in the measurement or retransmission of previously shared states. We demonstrate the effect on localisation accuracy and bandwidth using data captured from a set of five robots observing each other and landmarks compared to both single vehicle SLAM, pure cooperative localisation and a centralised solution.


Title: Monocular Visual Odometry Scale Recovery Using Geometrical Constraint
Key Words: cameras  feature extraction  geometry  image colour analysis  image matching  image segmentation  image sequences  mesh generation  object detection  roads  stereo image processing  road detection  road geometrical model calculation  road region detection  road geometrical model estimation  visual odometry scale recovery method  geometrical constraint  monocular visual odometry scale recovery methods  color information  Delaunay Triangulation method  Roads  Cameras  Visual odometry  Three-dimensional displays  Robot vision systems  Robustness 
Abstract: Scale recovery is one of the essential problems for monocular visual odometry. The camera height is usually used as an absolute reference to recover the scale. In this case, the precision of scale recovery depends on the accuracy of the road region detection and road geometrical model calculation. In previous works, road detection and road geometrical model calculation are solved sequentially: the road geometrical model calculation is based on the road detection and the road region detection is based on the color information. However, the color information of a road is not stable enough. In the proposed method, the estimated road geometrical model is taken into consideration to detect the road region as a feedback. Therefore, the road region detection and road geometrical model estimation can benefit each other. Delaunay Triangulation method is used to segment an input image to many triangles with the matched feature points as vertices. Every triangle region is classified as a road region or not by comparing their geometrical model with that of the road and the road geometrical model is updated online. We evaluate our visual odometry scale recovery method on the KITTI dataset and the results show that our method is achieving the best performance among all existing monocular visual odometry scale recovery methods without additional sensors.


Title: Predicting Alignment Risk to Prevent Localization Failure
Key Words: feature extraction  image registration  SLAM (robots)  cluttered man-made environments  geometric constraints  spatial overlap  failed alignment  point cloud content  laser-based localization failure  geometric features  point cloud registration  alignment risk  Three-dimensional displays  Cloud computing  Robot sensing systems  Measurement  Iterative closest point algorithm  Octrees 
Abstract: During localization and mapping the success of point cloud registration can be compromised when there is an absence of geometric features or constraints in corridors or across doorways, or when the volumes scanned only partly overlap, due to occlusions or constrictions between subsequent observations. This work proposes a strategy to predict and prevent laser-based localization failure. Our solution relies on explicit analysis of the point cloud content prior to registration. A model predicting the risk of a failed alignment is learned by analysing the degree of spatial overlap between two input point clouds and the geometric constraints available within the region of overlap. We define a novel measure of alignability for these constraints. The method is evaluated against three real-world datasets and compared to baseline approaches. The experiments demonstrate how our approach can help improve the reliability of laser-based localization during exploration of unknown and cluttered man-made environments.


Title: Adversarial Training for Adverse Conditions: Robust Metric Localisation Using Appearance Transfer
Key Words: feature extraction  image filtering  image recognition  adversarial training  adverse conditions  robust metric localisation  appearance transfer  visual place recognition  invertable generator  image transforming filter  feature-matching  dense descriptor maps  output synthetic images  input RGB image  generated images  multiple traversals  reliable localisation  Generators  Detectors  Measurement  Feature extraction  Computer architecture  Training  Pipelines 
Abstract: We present a method of improving visual place recognition and metric localisation under very strong appearance change. We learn an invertable generator that can transform the conditions of images, e.g. from day to night, summer to winter etc. This image transforming filter is explicitly designed to aid and abet feature-matching using a new loss based on SURF detector and dense descriptor maps. A network is trained to output synthetic images optimised for feature matching given only an input RGB image, and these generated images are used to localize the robot against a previously built map using traditional sparse matching approaches. We benchmark our results using multiple traversals of the Oxford RobotCar Dataset over a year-long period, using one traversal as a map and the other to localise. We show that this method significantly improves place recognition and localisation under changing and adverse conditions, while reducing the number of mapping runs needed to successfully achieve reliable localisation.


Title: Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming
Key Words: autonomous aerial vehicles  concave programming  knapsack problems  mobile robots  multi-robot systems  stochastic programming  chance-constrained 0-1 knapsack problem  variance-mean plane  deterministic knapsack problems  multirobot team selection problem  optimal chance constrained knapsack problem  2D discrete optimization problem  risk-averse knapsack problem  Robots  Optimization  Random variables  Task analysis  Batteries  Linear programming  Approximation algorithms 
Abstract: Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.


Title: Planning-Aware Communication for Decentralised Multi-Robot Coordination
Key Words: control engineering computing  mobile robots  Monte Carlo methods  multi-robot systems  path planning  planning (artificial intelligence)  statistical distributions  tree searching  decentralised multirobot coordination  coordinated multirobot missions  polynomial-time belief-space planning algorithm  informative communication planning  planning-aware communication  multirobot information gathering  robot simulation  decentralised Monte Carlo tree search  Planning  Robot kinematics  Prediction algorithms  Probability distribution  Australia  Cognition 
Abstract: We present an algorithm for selecting when to communicate during online planning phases of coordinated multi-robot missions. The key idea is that a robot decides to request communication from another robot by reasoning over the predicted information value of communication messages over a sliding time-horizon, where communication messages are probability distributions over action sequences. We formulate this problem in the context of the recently proposed decentralised Monte Carlo tree search (Dec-MCTS) algorithm for online, decentralised multi-robot coordination. We propose a particle filter for predicting the information value, and a polynomial-time belief-space planning algorithm for finding the optimal communication schedules in an online and decentralised manner. We evaluate the benefit of informative communication planning for a multi-robot information gathering scenario with 8 simulated robots. Our results show reductions in channel utilisation of up to four-fifths with surprisingly little impact on coordination performance.


Title: Multi-Robot Realization Based on Goal Adjacency Constraints
Key Words: closed loop systems  matrix algebra  mobile robots  multi-robot systems  navigation  path planning  position control  velocity control  pairwise distances  velocity-controlled robot  multirobot realization  goal adjacency constraints  robot positions  exact goal positions  relative distances  pairwise adjacency constraints  multirobots  adjacency matrix  adjacency threshold  robot pairs  coordinated navigation  closed-loop dynamics  Conferences  Automation  Australia 
Abstract: This paper considers the problem of multi-robot realization. A realization is a set of robot positions where pairwise distances are either bounded from above or from below by a given adjacency threshold - depending on whether the respective robot pairs are to be adjacent or not. In the realization problem, unlike the related coordinated navigation or formation control problems, exact goal positions or relative distances need not be specified. Rather, only pairwise adjacency constraints are given and the robots' positions are required to satisfy these constraints. Applications of realization problem include multi-robots involved in team games (playing soccer, etc), patrolling and area coverage. We present a novel solution to this problem in which the robots simultaneously navigate to find a realization of a given adjacency matrix without colliding with each other along the way. In this solution, complete information about pairwise distances and free configuration space are encoded using an artificial potential function over the cross product space of the robots' simultaneous positions and proximity variables. The closed-loop dynamics governing the motion of each velocity-controlled robot take the form of the appropriate projection of the gradient of this function while pairwise distances are adjusted accordingly. Our extensive simulations demonstrate that the proposed approach has considerably higher realization percentage and shorter movement distances in comparison to a standard 2-stage approach.


Title: Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication
Key Words: aerospace robotics  asymptotic stability  compensation  controllability  distributed control  helicopters  mobile robots  trajectory optimisation (aerospace)  exponential stability  distributed compensation scheme  controllability  local optimization problem  entire assembly  distributed wrench controller  rigidly attached quadrotor aerial robots  multiple quadrotors  subsequent trajectory optimization  output wrench space  control wrench  group control authority  Robot kinematics  Trajectory  Torque  Three-dimensional displays  Payloads  Unmanned aerial vehicles 
Abstract: We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.


Title: An Energy-Based Approach for the Multi-Rate Control of a Manipulator on an Actuated Base
Key Words: aerospace robotics  damping  manipulators  observers  stability  vibration control  energy-based approach  multirate control  robotic system  actuated floating base  space applications  stability issues  time domain passivity approach  base-manipulator multibody simulation  passivity-based stabilizing controller  energy observer design  Manipulators  Satellites  Jacobian matrices  Stability analysis  Delays  Time-domain analysis 
Abstract: In this paper we address the problem of controlling a robotic system mounted on an actuated floating base for space applications. In particular, we investigate the stability issues due to the low rate of the base control unit. We propose a passivity-based stabilizing controller based on the time domain passivity approach. The controller uses a variable damper regulated by a designed energy observer. The effectiveness of the proposed strategy is validated on a base-manipulator multibody simulation.


Title: Optimal Intermittent Deployment and Sensor Selection for Environmental Sensing with Multi-Robot Teams
Key Words: decision theory  Markov processes  multi-robot systems  partial environmental information  optimal policy  optimal intermittent deployment  multirobot team  environmental sensing problem  team composition  environmental process  heterogeneous robots  heterogeneous robot teams  sensor types  sensor selection policy  Robot sensing systems  Robot kinematics  Markov processes  Computational modeling  Delays 
Abstract: In this paper, we formulate an environmental sensing problem for multi-robot teams that couples intermittent deployments with the selection of team composition and sensor type over time. We suppose that a multi-robot team needs to autonomously sense an environmental process and find the optimal policy for deploying heterogeneous robots. In addition, heterogeneous robot teams can be composed in various ways by selecting different mobility and sensor types which have varying accuracies and costs, resulting in a more complex problem. The question is then how to find an optimal intermittent deployment and sensor selection policy that captures both cost and estimation accuracy based on partial environmental information. By utilizing structural results from partially observable Markov decision processes (POMDP) and exploiting submodularity, an optimal policy, which minimizes cost while maintaining a high accuracy, can be achieved in this paper. The effectiveness of this method is demonstrated by simulation results and comparisons with naive policies.


Title: Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning
Key Words: cables (mechanical)  dynamic programming  mobile robots  multi-robot systems  optimal control  path planning  planning problems  aerial robots  transportation task  ground robots  nonrigid inextensible cables  heterogeneous multirobot system  multiple aerial vehicles  general constrained optimal planning problem  multiple ground vehicles  cooperative object transportation  modeling problems  dynamic programming  Vehicle dynamics  Manipulators  Load modeling  Unmanned aerial vehicles  Dynamics 
Abstract: In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.


Title: Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints
Key Words: autonomous aerial vehicles  delays  distributed control  mobile robots  multi-robot systems  intermittent communications  high-level decision skills  distributed decision architecture  hybrid planner  distributed execution algorithm  delays  surveillance missions  ground robots  heterogeneous robots  field multirobot missions  autonomous aerial robot  unavoidable disturbances  integrating planning and execution  communication constrains  time constraints  decentralized repairs  Maintenance engineering  Planning  Computer architecture  Robot kinematics  Surveillance  Delays 
Abstract: Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.


Title: Data-Driven Approach to Simulating Realistic Human Joint Constraints
Key Words: backpropagation  human-robot interaction  neural nets  optimisation  physical human-robot interaction  physics simulation  implicit equation  human data  physics engine  data-driven approach  human joint limits  joint motion  realistic human joint limits  human joint configurations  realistic human joint constraints  backpropagation  optimization problem  fully connected neural network  Joints  Mathematical model  Physics  Robots  Neural networks  Elbow  Computational modeling 
Abstract: Modeling realistic human joint limits is important for applications involving physical human-robot interaction. However, setting appropriate human joint limits is challenging because it is pose-dependent: the range of joint motion varies depending on the positions of other bones. The paper introduces a new technique to accurately simulate human joint limits in physics simulation. We propose to learn an implicit equation to represent the boundary of valid human joint configurations from real human data. The function in the implicit equation is represented by a fully connected neural network whose gradients can be efficiently computed via back-propagation. Using gradients, we can efficiently enforce realistic human joint limits through constraint forces in a physics engine or as constraints in an optimization problem.


Title: Generative Adversarial Nets in Robotic Chinese Calligraphy
Key Words: character sets  control engineering computing  learning (artificial intelligence)  robot programming  robotic chinese calligraphy  robotic writing  Chinese character strokes  font generation methods  generative adversarial nets-based calligraphic robotic framework  interactive modules  stroke generation module  stroke discriminative module  stroke generative module  calligraphic robot  human-level stroke  robotic autonomous creation ability  reinforcement learning  Writing  Trajectory  Training  Gallium nitride  Manipulators  Probability distribution 
Abstract: Conventional approaches of robotic writing of Chinese character strokes often suffer from limited font generation methods, and thus the writing results often lack of diversity. This has seriously restricted the high quality writing ability of robots. This paper proposes a generative adversarial nets-based calligraphic robotic framework, which enables a robot to learn writing fundamental Chinese strokes with rich diversity and good originality. In particular, the framework considers the learning process of robotic writing as an adversarial procedure which is implemented by three interactive modules including a stroke generation module, a stroke discriminative module and a training module. Noting that the stroke generative module included in the conventional generative adversarial nets cannot solve the non-differentiable problem, the policy gradient commonly used in reinforcement learning is thus adapted in this work to train the generative module by regarding the outputs from the discriminative module as rewards. Experimental results demonstrate that the proposed framework allows a calligraphic robot to successfully write fundamental Chinese strokes with good quality in various styles. The experiment also suggests the proposed approach can achieve human-level stroke writing quality without the requirement of a performance evaluation system. This approach therefore significantly boosts the robotic autonomous creation ability.


Title: Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning
Key Words: learning (artificial intelligence)  mobile robots  path planning  socially compliant navigation  raw depth inputs  mobile robots  socially compliant manner  generative adversarial imitation learning strategy  raw sensory input  GAIL-based approach  behavior cloning policy  social force model  Force  Navigation  Cloning  Sensors  Mobile robots  Learning (artificial intelligence)  Visualization 
Abstract: We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.


Title: Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation
Key Words: learning by example  robot programming  video signal processing  context translation  observation-action tuples  supervised learning algorithm  imitation-from-observation  deep reinforcement learning  video prediction  raw video  robotic skills learning  imitation learning  Task analysis  Robots  Context modeling  Learning (artificial intelligence)  Visualization  Tools  Cloning 
Abstract: Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, object positions and types, and other factors. We term this kind of imitation learning “imitation-from-observation,” and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in imitation learning that the demonstration should consist of observations in the same environment configuration, and enables a variety of interesting applications, including learning robotic skills that involve tool use simply by observing videos of human tool use. Our experimental results show the effectiveness of our approach in learning a wide range of real-world robotic tasks modeled after common household chores from videos of a human demonstrator, including sweeping, ladling almonds, pushing objects as well as a number of tasks in simulation.


Title: Incremental Task Modification via Corrective Demonstrations
Key Words: autoregressive processes  Bayes methods  finite state machines  hidden Markov models  intelligent robots  manipulators  Incremental Task Modification via Corrective Demonstrations  state transition auto-regressive hidden Markov model  probabilistic properties  simulated block sorting domain  real-world pouring task  ITMCD Model Selection  approximate Bayesian model selection  FSA  finite state automaton representation  Hidden Markov models  Task analysis  Robots  Computational modeling  Adaptation models  Probabilistic logic  Bayes methods 
Abstract: In realistic environments, fully specifying a task model such that a robot can perform a task in all situations is impractical. In this work, we present Incremental Task Modification via Corrective Demonstrations (ITMCD), a novel algorithm that allows a robot to update a learned model by making use of corrective demonstrations from an end-user in its environment. We propose three different types of model updates that make structural changes to a finite state automaton (FSA) representation of the task by first converting the FSA into a state transition auto-regressive hidden Markov model (STARHMM). The STARHMM's probabilistic properties are then used to perform approximate Bayesian model selection to choose the best model update, if any. We evaluate ITMCD Model Selection in a simulated block sorting domain and the full algorithm on a real-world pouring task. The simulation results show our approach can choose new task models that sufficiently incorporate new demonstrations while remaining as simple as possible. The results from the pouring task show that ITMCD performs well when the modeled segments of the corrective demonstrations closely comply with the original task model.


Title: Time-Contrastive Networks: Self-Supervised Learning from Video
Key Words: image representation  learning (artificial intelligence)  pose estimation  robot programming  robot vision  video signal processing  time-contrastive networks  robotic behaviors  robotic imitation settings  human poses  viewpoint-invariant representation  end-effectors  reinforcement learning algorithm  self-supervised learning  robotic systems  Robots  Task analysis  Visualization  Learning (artificial intelligence)  Training  Liquids  Lighting 
Abstract: We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.


Title: Learning Sensor Feedback Models from Demonstrations via Phase-Modulated Neural Networks
Key Words: adaptive control  feedback  humanoid robots  learning (artificial intelligence)  mobile robots  path planning  radial basis function networks  tactile sensors  phase-modulated neural networks  feedback model maps  motion plan adaptation  radial basis function network structure  tactile sensor traces  data-driven framework  anthropomorphic robot  Robot sensing systems  Adaptation models  Task analysis  Mathematical model  Neural networks  Quaternions 
Abstract: In order to robustly execute a task under environmental uncertainty, a robot needs to be able to reactively adapt to changes arising in its environment. The environment changes are usually reflected in deviation from expected sensory traces. These deviations in sensory traces can be used to drive the motion adaptation, and for this purpose, a feedback model is required. The feedback model maps the deviations in sensory traces to the motion plan adaptation. In this paper, we develop a general data-driven framework for learning a feedback model from demonstrations. We utilize a variant of a radial basis function network structure -with movement phases as kernel centers- which can generally be applied to represent any feedback models for movement primitives. To demonstrate the effectiveness of our framework, we test it on the task of scraping on a tilt board. In this task, we are learning a reactive policy in the form of orientation adaptation, based on deviations of tactile sensor traces. As a proof of concept of our method, we provide evaluations on an anthropomorphic robot.


Title: Robot Navigation from Human Demonstration: Learning Control Behaviors
Key Words: learning (artificial intelligence)  mobile robots  optimal control  robot navigation  human collaborators  dynamic environments  disaster recovery  unmanned ground vehicle  UGV  fast field adaptation  minimal human supervision  visual perception  inverse optimal control  minimal human supervisory examples  navigation behavior  real-world environment  minimal human demonstration  Navigation  Robots  Trajectory  Entropy  Training  Collision avoidance  Task analysis 
Abstract: When working alongside human collaborators in dynamic environments such as a disaster recovery, an unmanned ground vehicle (UGV) may require fast field adaptation to perform its duties or learn novel tasks. In disaster recovery situations, personnel and equipment are constrained, so training must be accomplished with minimal human supervision. In this paper, we introduce a novel framework which uses learned visual perception and inverse optimal control trained with minimal human supervisory examples. This approach is used to learn to mimic navigation behavior and is demonstrated through extensive evaluation in a real-world environment. Finally, we demonstrate the ability to learn an additional behavior with minimal human demonstration in the field.


Title: Relocalization, Global Optimization and Map Merging for Monocular Visual-Inertial SLAM
Key Words: cameras  distance measurement  graph theory  inertial navigation  mobile robots  optimisation  path planning  pose estimation  robot vision  SLAM (robots)  relocalization  global optimization  monocular visual-inertial SLAM  visual-inertial system  low-cost inertial measurement unit  state estimation  visual-inertial odometry  absolute pose estimation  visual-inertial SLAM system  global pose graph optimization  map merging ability  map reuse  pose graph optimization  Cameras  Optimization  Visualization  Feature extraction  Microsoft Windows  Simultaneous localization and mapping  Real-time systems 
Abstract: The monocular visual-inertial system (VINS), which consists one camera and one low-cost inertial measurement unit (IMU), is a popular approach to achieve accurate 6-DOF state estimation. However, such locally accurate visual-inertial odometry is prone to drift and cannot provide absolute pose estimation. Leveraging history information to relocalize and correct drift has become a hot topic. In this paper, we propose a monocular visual-inertial SLAM system, which can relocalize camera and get the absolute pose in a previous-built map. Then 4-DOF pose graph optimization is performed to correct drifts and achieve global consistent. The 4-DOF contains x, y, z, and yaw angle, which is the actual drifted direction in the visual-inertial system. Furthermore, the proposed system can reuse a map by saving and loading it in an efficient way. Current map and previous map can be merged together by the global pose graph optimization. We validate the accuracy of our system on public datasets and compare against other state-of-the-art algorithms. We also evaluate the map merging ability of our system in the large-scale outdoor environment. The source code of map reuse is integrated into our public code, VINS-Monol11https://github.com/HKUST-Aerial-Robotics/VINS-Mono.


Title: Elastic LiDAR Fusion: Dense Map-Centric Continuous-Time SLAM
Key Words: image reconstruction  mobile robots  optical radar  optimisation  probability  radar imaging  robot vision  sensor fusion  SLAM (robots)  dense map-centric continuous-time SLAM  CT-SLAM  computational complexity  surfel fusion  global batch trajectory optimization  probabilistic surface element fusion  map deformation  global trajectory optimization  Continuous-Time SLAM  global batch optimization  multimodal sensor fusion  continuous-time trajectory representation  elastic LiDAR fusion  Laser radar  Trajectory optimization  Simultaneous localization and mapping  Strain  Interpolation 
Abstract: The concept of continuous-time trajectory representation has brought increased accuracy and efficiency to multi-modal sensor fusion in modern SLAM. However, regardless of these advantages, its offline property caused by the requirement of global batch optimization is critically hindering its relevance for real-time and life-long applications. In this paper, we present a dense map-centric SLAM method based on a continuous-time trajectory to cope with this problem. The proposed system locally functions in a similar fashion to conventional Continuous-Time SLAM (CT-SLAM). However, it removes the need for global trajectory optimization by introducing map deformation. The computational complexity of the proposed approach for loop closure does not depend on the operation time, but only on the size of the space it explored before the loop closure. It is therefore more suitable for long term operation compared to the conventional CT-SLAM. Furthermore, the proposed method reduces uncertainty in the reconstructed dense map by using probabilistic surface element (surfel) fusion. We demonstrate that the proposed method produces globally consistent maps without global batch trajectory optimization, and effectively reduces LiDAR noise by surfel fusion.


Title: Design and Analysis of a Fixed-Wing Unmanned Aerial-Aquatic Vehicle
Key Words: aerospace components  autonomous aerial vehicles  autonomous underwater vehicles  closed loop systems  mobile robots  optimisation  fixed-wing unmanned aerial-aquatic vehicle  fixed-wing vehicle  aerobatic post-stall maneuvers  water-to-air transition execution  direct hybrid trajectory optimization  closed-loop control  Propellers  Vehicle dynamics  Prototypes  Unmanned aerial vehicles  Design tools 
Abstract: In this paper, we describe the design and analysis of a fixed-wing unmanned aerial-aquatic vehicle. Inspired by prior work in aerobatic post-stall maneuvers for fixed-wing vehicles [1], we explore the feasibility of executing a water-to-air transition with a fixed-wing vehicle using almost entirely commercial off-the-shelf components (excluding the fuselage). To do this, we first propose a conceptual design based on observations about the dominant forces and dimensionless analysis. We then further refine this concept by building a design tool based on simplified models to explore the design space. To verify the results of the design tool, we use a higher fidelity model along with a direct hybrid trajectory optimization approach to show via numerical simulation that the water-to-air transition is feasible. Finally, we successfully test our design experimentally by hand-piloting a prototype vehicle through the water-to-air transition and discuss our approach for replacing the human-pilot with closed-loop control.


Title: Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints
Key Words: cooperative systems  decision making  distributed control  Gaussian processes  multi-robot systems  path planning  Gaussian processes  path planning  path clustering  multi-robot exploration  inter-robot communication constraints  information-theoretic utility function  Max-sum algorithm  distributed decision-making algorithm  multirobot information gathering  inter-robot restrictions  distributed multirobot cooperation  Clustering algorithms  Robot kinematics  Robot sensing systems  Heuristic algorithms  Linear programming 
Abstract: Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.


Title: Automated Pick-Up of Suturing Needles for Robotic Surgical Assistance
Key Words: cancer  endoscopes  medical image processing  medical robotics  needles  robot vision  surgery  surgical tool  RALP  urethrovesical anastomosis  robotic surgical assistance  robot-assisted laparoscopic prostatectomy  prostate cancer  nerve sparing removal prostate tissue  bladder neck  dexterity demanding tasks  suturing instruments  robotic instruments  vision-guided needle grasping method  suturing needle  grasping process  needle detection algorithm  Needles  Grasping  Robots  Tools  Instruments  Surgery  Task analysis 
Abstract: Robot-assisted laparoscopic prostatectomy (RALP) is a treatment for prostate cancer that involves complete or nerve sparing removal prostate tissue that contains cancer. After removal the bladder neck is successively sutured directly with the urethra. The procedure is called urethrovesical anastomosis and is one of the most dexterity demanding tasks during RALP. Two suturing instruments and a pair of needles are used in combination to perform a running stitch during urethrovesical anastomosis. While robotic instruments provide enhanced dexterity to perform the anastomosis, it is still highly challenging and difficult to learn. In this paper, we presents a vision-guided needle grasping method for automatically grasping the needle that has been inserted into the patient prior to anastomosis. We aim to automatically grasp the suturing needle in a position that avoids hand-offs and immediately enables the start of suturing. The full grasping process can be broken down into: a needle detection algorithm; an approach phase where the surgical tool moves closer to the needle based on visual feedback; and a grasping phase through path planning based on observed surgical practice. Our experimental results show examples of successful autonomous grasping that has the potential to simplify and decrease the operational time in RALP by assisting a small component of urethrovesical anastomosis.


Title: A Hybrid Actuated Robotic Prototype for Minimally Invasive Surgery
Key Words: actuators  end effectors  graphical user interfaces  haptic interfaces  medical computing  medical robotics  motion control  shape memory effects  surgery  telerobotics  hybrid actuated robotic prototype  prototype robotic platform  minimally invasive surgical procedures  extra-operative motion  pivoting motion  4 DoF shape memory alloy actuated probe  intra-operative dexterity  end-effector  Robot Operating System framework  interaction forces  graphical user interface  servo-actuated manipulator  operation mode switching  stereo imaging  teleoperation  haptic device  Probes  Manipulators  Actuators  Wires  Kinematics  Minimally Invasive Surgery  Robot Assisted Surgery  Shape Memory Alloy actuation  Visual Servoing  Medical Imaging 
Abstract: This article presents the design and experimental evaluation of a prototype robotic platform for minimally invasive surgical procedures. The platform utilizes a hybrid actuation scheme, consisting of a 5 Degree-of-Freedom (DoF) servo-actuated manipulator for extra-operative and pivoting motion and a 4 DoF shape memory alloy actuated probe at the distal end, for intra-operative dexterity. The architecture targets thoracic and abdominal operations, with low interaction forces at the probe's end-effector. The system, runs under the Robot Operating System framework for easier deployment and development. Additional accompanying software is developed to aid the surgeon during deployment. Specifically, a Graphical User Interface employing modules controls for online parameter reconfiguration, operation mode switching while custom viewports for stereo imaging are implemented. Teleoperation is feasible with the integration of a haptic device. In-vitro evaluation of the robot is presented, to assess the maneuvering efficiency and further potential exploitation of the design.


Title: Design and Test of an In-Vivo Robotic Camera Integrated with Optimized Illumination System for Single-port Laparoscopic Surgery
Key Words: biomedical optical imaging  cameras  image sensors  lenses  light emitting diodes  medical robotics  optical design techniques  surgery  in-vivo robotic laparoscopic camera design  optical efficiency  LED  miniature optical lenses  illuminance  illumination uniformity  freeform optical lens design method  single-port laparoscopic surgery  optimized illumination system  distance 100.0 mm  Cameras  Robot vision systems  Lighting  Lenses  Laparoscopes 
Abstract: This paper proposes a novel in-vivo robotic laparo-scopic camera design with an optimized illumination system, which is a crucial component for achieving high imaging quality. The robotic camera design with three extendable wings can reserve sufficient on-board space to harbor the optimized illumination system without affecting the compactness of the camera. We contribute a freeform optical lens design method and develop three miniature optical lenses for the LEDs to achieve greater than 95% illumination uniformity, greater than 14, 000 lx illuminance on a target plane with a distance of 100 mm, and greater than 89% optical efficiency. The prototype is implemented and experimentally tested, which demonstrates great performance of the in-vivo robotic laparoscopic camera and the significance of the optimized illumination system.


Title: A Novel Magnetic Anchored and Steered Camera Robot for Single Port Access Surgery
Key Words: cameras  finite element analysis  medical robotics  robot vision  surgery  single port access surgery  minimally invasive surgery  planar pan/tilt workspace  lower robot footprint  vertical space  internal permanent magnets  IPMs  cylindrical capsule  camera module  camera view orientation  planar workspace  anchoring  intra-abdominal surface  steering  tilting panning  camera robot prototype  minimal footprint  magnetic anchored steered camera robot  size 6.0 mm  size 4.0 cm  size 7.0 mm  mass 3.6 g  Cameras  Robot vision systems  Magnetic separation  Soft magnetic materials  Surgery  Instruments 
Abstract: This paper presents a novel magnetic anchored and steered camera robot intended for minimally invasive surgery (MIS), particularly for single port access (SPA) surgery. The design aims to achieve both compactness and a planar pan/tilt workspace (instead of hemispheric) to lower robot footprint in vertical space. Robot comprises two 6mm×6mm diametrically magnetized internal permanent magnets (IPMs) fixed at either ends of a small cylindrical capsule, with camera module and a 45°mirror capped inside capsule. As such, camera view orientation can be steered in 2-DOF across range of 180° tilt and 360° panning, all within a planar workspace close to surface of anchor. Using only two small IPMs for all necessary functions (anchoring, translation along intra-abdominal surface, and steering) reduces bulk and length of robot. The robot is investigated first by finite element methods. Theoretical models for both tilting and panning were then built based on FEM results. The models are evaluated and verified by checking its predictions in benchtop experiments. Ex vivo evaluations was also utilized to prove feasibility of device in environment similar to human anatomy. Overall, the camera robot prototype is compact (4cm length; 7mm diameter), lightweight (3.6g), motor-free, and allow view orientation control (tilting and panning) in a planar workspace. Minimal footprint in vertical space is ideal for many MIS applications, where vertical space is extremely limited.


Title: Vehicle Detection, Tracking and Behavior Analysis in Urban Driving Environments Using Road Context
Key Words: driver information systems  learning (artificial intelligence)  object detection  object tracking  optical radar  real-time systems  road traffic  road vehicles  sensor fusion  traffic engineering computing  2D Lidar  deep learning  vehicle tracking  Lidar sensor fusion  global map coordinate system  track management  data association  high precision range estimation  monocular camera  robust fusion system  tracking system  real-time vehicle detection  road context  urban driving environments  behavior analysis  Roads  Laser radar  Sensor fusion  Robot sensing systems  Vehicle detection  Estimation  Autonomous vehicles 
Abstract: We present a real-time vehicle detection and tracking system to accomplish the complex task of driving behavior analysis in urban environments. We propose a robust fusion system that combines a monocular camera and a 2D Lidar. This system takes advantage of three key components: robust vehicle detection using deep learning techniques, high precision range estimation from Lidar, and road context from the prior map knowledge. The camera and Lidar sensor fusion, data association and track management are all performed in the global map coordinate system by taking into account the sensors' characteristics. Lastly, behavior reasoning is performed by examining the tracked vehicle states in the lane coordinate system in which the road context is encoded. We validated our approach by tracking a leading vehicle while it performed usual urban driving behaviors such as lane keeping, stop-and-go at intersections, lane changing, overtaking and turning. The leading vehicle was tracked consistently throughout the 2.3 km route and its behavior was classified reliably.


Title: GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation
Key Words: autonomous aerial vehicles  distance measurement  graph theory  Kalman filters  mobile robots  nonlinear filters  optimisation  pose estimation  robot vision  sensor fusion  SLAM (robots)  GOMSF  proprioceptive measurements  exteroceptive measurements  navigation algorithms  agile mobile robots  Unmanned Aerial Vehicles  UAV pose estimation  graph optimization based multisensor fusion  6 Degree-of-Freedom visual-inertial odometry poses  extended Kalman filter  Robot sensing systems  Robot kinematics  Optimization  Pose estimation  Global Positioning System  Time measurement 
Abstract: Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.


Title: Attitude, Linear Velocity and Depth Estimation of a Camera Observing a Planar Target Using Continuous Homography and Inertial Data
Key Words: accelerometers  cameras  image sequences  inertial navigation  Kalman filters  motion estimation  stability  state estimation  motion excitation conditions  deterministic observer  accelerometer measurements  gyrometer  optical flow  linear velocity  inertial data  continuous homography  planar target  attitude  testbed IMU-Camera system  estimation errors  observability analysis  Observers  Observability  Robot sensing systems  Accelerometers  Magnetometers  Cameras 
Abstract: This paper revisits the problem of estimating the attitude, linear velocity and depth of an IMU-Camera with respect to a planar target. The considered solution relies on the measurement of the optical flow (extracted from the continuous homography) complemented with gyrometer and accelerometer measurements. The proposed deterministic observer is accompanied with an observability analysis that points out camera's motion excitation conditions whose satisfaction grants stability of the observer and convergence of the estimation errors to zero. The performance of the observer is illustrated by performing experiments on a testbed IMU-Camera system.


Title: Deep Inference for Covariance Estimation: Learning Gaussian Noise Models for State Estimation
Key Words: covariance analysis  Gaussian noise  image representation  learning (artificial intelligence)  measurement errors  measurement uncertainty  neural nets  regression analysis  state estimation  raw sensor data  raw sensor measurement  ground-truth measurement error  measurement model  prediction performance  covariance prediction  state Estimation  measurement covariance estimation  deep neural network  Gaussian noise models  measurement uncertainty  deep inference for covariance estimation  predictive sensor modeling  hand-coded features  Robot sensing systems  Measurement uncertainty  Measurement errors  Covariance matrices  Predictive models  Estimation  Neural networks 
Abstract: We present a novel method of measurement covariance estimation that models measurement uncertainty as a function of the measurement itself. Existing work in predictive sensor modeling outperforms conventional fixed models, but requires domain knowledge of the sensors that heavily influences the accuracy and the computational cost of the models. In this work, we introduce Deep Inference for Covariance Estimation (DICE), which utilizes a deep neural network to predict the covariance of a sensor measurement from raw sensor data. We show that given pairs of raw sensor measurement and ground-truth measurement error, we can learn a representation of the measurement model via supervised regression on the prediction performance of the model, eliminating the need for hand-coded features and parametric forms. Our approach is sensor-agnostic, and we demonstrate improved covariance prediction on both simulated and real data.


Title: A Study on Optimal Placement of Accelerometers for Pose Estimation of a Robot Arm
Key Words: accelerometers  end effectors  legged locomotion  mobile robots  Monte Carlo methods  pose estimation  position control  prosthetics  sensors  optimal placement  accelerometers  inertial sensor placement  noise characteristics  joint angle encoders  end-effector positioning  legged locomotion  dual arm  prosthetic limbs  inertial measurement units  artificial skin patches  noise properties  signal-to-noise Ratio  micromachined sensors  two-link robot arm  expected estimation error metric values  accelerometer configurations  optimal number  arm pose estimation error  SNR  Monte-Carlo simulations  robot arm pose estimation  IMU  Robot sensing systems  Accelerometers  Manipulators  Pose estimation  Robot kinematics 
Abstract: This study investigates the effects of inertial sensor placement and noise characteristics on the accuracy of robot pose estimation. Of course, most robots are equipped with joint angle encoders for pose estimation and end-effector positioning. However, in some situations, it's not possible or not desirable to introduce encoders on all joints. Such common examples include legged locomotion, dual arm co-manipulation, and prosthetic limbs. To tackle such situations, one solution is to embed inertial measurement units (IMUs) into artificial skin patches placed on robots' limbs and body. This work analyzes the effects of design parameters such as the number of sensors, their placement on the robot, and noise properties on the quality of robot pose estimation and its signal-to-noise Ratio (SNR). We study the benefits of using a large number of IMUs, which is possible due to the proliferation of inexpensive micro-machined sensors. We use Monte-Carlo simulations and experiments with a two-link robot arm to obtain the distributions of expected estimation error metric values for several accelerometer configurations, which are then compared to determine the optimal number and placement for the IMUs. Results show that the placement of at least two accelerometers on each link has the most significant impact on the pose estimation error, while using a larger number of accelerometers plays a less significant role in reducing the arm pose estimation error and resultant SNR.


Title: Encoder-Camera-Ground Penetrating Radar Tri-Sensor Mapping for Surface and Subsurface Transportation Infrastructure Inspection
Key Words: automatic optical inspection  cameras  graph theory  ground penetrating radar  image fusion  image reconstruction  optimisation  pose estimation  structural engineering computing  transportation  GPR  wheel encoder  sensing suite  data collection scheme  ALs  types data streams  camera images  data fusion  sensory data  sensor fusion approach  encoder-camera-ground penetrating radar tri-sensor mapping  subsurface transportation infrastructure inspection  algorithmic development  multiple sensors  multimodal mapping  Ground penetrating radar  Cameras  Inspection  Synchronization  Robot sensing systems  Three-dimensional displays 
Abstract: We report system and algorithmic development for a sensing suite comprising multiple sensors for both surface and subsurface transportation infrastructure inspection focusing on multi-modal mapping for inspection. The sensing suite contains a camera, a ground penetrating radar (GPR), and a wheel encoder. We design the sensing suite and propose a data collection scheme using customized artificial landmarks (ALs). We use ALs to synchronize two types data streams: camera images that are temporally evenly-spaced and GPR/encoder data that are spatially evenly-spaced. We also employ pose graph optimization with synchronization as penalty functions to further refine synchronization and perform data fusion for 3D reconstruction. We have implemented the system and tested it in physical experiments. The results show that our system successfully fuses three sensory data and product metric 3D reconstruction. The sensor fusion approach reduces the end-to-end distance error from 7.45cm to 3.10cm.


Title: Angle Estimation for Robotic Arms on Floating Base Using Low-Cost IMUS
Key Words: hydraulic systems  inertial navigation  Kalman filters  mobile robots  nonlinear filters  sensor fusion  wheels  commercial mobile working machine  extended Kalman filter  complementary filter  sensors data fusion  low-cost IMUs  six degrees-of-freedom wheeled base platform  3-DOF hydraulic anthropomorphic arm  floating base hydraulic arm  vibrational disturbances  machines diesel engine  deformation  EKF  CF  root mean square error  RMS error  floating base robotic platforms  link angles  low-cost inertial measurement units  robotic arms  angle estimation  Accelerometers  Estimation  Force  Manipulators  Hydraulic systems  Gyroscopes 
Abstract: An algorithm that uses low-cost inertial measurement units (IMUs) for estimating link angles for floating base robotic platforms is proposed. Each link has four IMUs attached on its surfaces, and an Extended Kalman Filter (EKF) and a Complementary Filter (CF) are used for fusing the sensors' data. The algorithm is validated with a commercial mobile working machine, which consist of six degrees-of-freedom (DOF) wheeled base platform, and a 3-DOF hydraulic anthropomorphic arm. Although there are vibrational disturbances from the machine's diesel engine and deformation of the links themselves, the measured results from the planar motion of a floating base hydraulic arm show that the accuracy of the angle estimation is impressively less than 1 degree in the root mean square (RMS) error.


Title: IntuBot: Design and Prototyping of a Robotic Intubation Device
Key Words: biomedical equipment  computerised tomography  medical image processing  medical robotics  mobile robots  robot vision  servomechanisms  steering systems  robotic intubation device  endotracheal intubation  robotic prototype  hardware system  stepper motor  servo motors  stylet tip  vocal cords  pre-clinical testing  IntuBot  vision-based navigation algorithm  CT scan images  Gears  Prototypes  Servomotors  Electron tubes  Mouth  Training  Testing 
Abstract: Endotracheal intubation is one of the most common procedures performed worldwide in emergency departments and operating rooms. It is a highly complicated procedure susceptible to failure. This paper presents a robotic prototype, called IntuBot, designed to automate this procedure. The hardware system consists of a stepper motor to steer the stylet in forward and backward motions and two servo motors to generate bending at the stylet tip to navigate through a patient's airway. A real-time vision-based navigation algorithm is also presented to guide the stylet to localize the vocal cords, which is the tubes ultimate target. For pre-clinical testing, we 3D printed and then molded a silicone model of the airway from the mouth to the vocal cords based on a series of actual CT scan images. The prototype was tested for its steering capabilities.


Title: Locomotion Envelopes for Adaptive Control of Powered Ankle Prostheses
Key Words: adaptive control  gait analysis  Gaussian processes  medical robotics  prosthetics  regression analysis  Gaussian process regression  human subjects walking  locomotion variables  nonlinear manifolds  anthropomorphic control  impedance control  adaptive control  powered ankle foot prosthesis  locomotion envelope  gait-cycle duration  temporal evolution  velocity range  Legged locomotion  Prosthetics  Impedance  Manifolds  Kernel  Gaussian processes  Robustness 
Abstract: In this paper we combine Gaussian process regression and impedance control, to illicit robust, anthropomorphic, adaptive control of a powered ankle prosthesis. We learn the non-linear manifolds which guide how locomotion variables temporally evolve, and regress that surface over a velocity range to create a manifold. The joint set of manifolds, as well as the temporal evolution of the gait-cycle duration is what we term a locomotion envelope. Current powered prostheses have problems adapting across speeds. It is likely that humans rely upon a control strategy which is adaptable, can become more robust and accurate with more data and provides a nonparametric approach which allows the strategy to grow with the number of observations. We demonstrate such a strategy in this study and successfully simulate locomotion well beyond our training data. The method we propose is based on common physical features observed in numerous human subjects walking at different speeds. Based on the derived locomotion envelopes we show that ankle power increases monotonically with speed among all subjects. We demonstrate our methods in simulation and human experiments, on a powered ankle foot prosthesis to demonstrate the effectiveness of the method.


Title: Modeling and Characterization of a Potential Bladder Based Orthotic Device to Mitigate Shoe Slip
Key Words: accident prevention  footwear  friction  orthotics  physiological models  wearable robots  friction force  valves  slip event  impact force  bladder walls  contact forces  slip-mitigating potential  orthotic device  intelligent orthotic shoe  longitudinal slip  shoe slip  bladder based orthotic device  rubberized shoe sole  robotic shoes  slip-fall accidents  Bladder  Atmospheric modeling  Conferences  Automation  Australia  Friction 
Abstract: The exploration of an “intelligent” orthotic shoe sole to negate, or minimize, longitudinal slip by momentarily increasing friction force is presented. The conceptual device takes the form of a rubberized shoe sole containing pockets of air that can be released via valves controlled by a microprocessor. During a slip event, the valves would be opened and the bladders would be collapsed by the weight of the user, which modulates contact and friction forces. The goal is to increase friction forces in this process, by creating an impact force between the user and ground surface, with the potential to increase friction and mitigate slip. Simulations of bladder walls, air flow through valves, contact forces, and friction forces are modeled and combined into a lumped parameter model to predict device behavior. Prototypes of the device are created and evaluated to validate models and slip-mitigating potential.


Title: Programmable Medicine: Autonomous, Ingestible, Deployable Hydrogel Patch and Plug for Stomach Ulcer Therapy
Key Words: biological organs  biomechanics  biomedical materials  diseases  drug delivery systems  drugs  hydrogels  remotely navigatable hydrogel patch  deployable ingestible hydrogel patch  stomach ulcer therapy  remotely navigatable hydrogel plug  deployable ingestible hydrogel plug  magnetic field  deployable origami design  folded configuration  dehydration  hydration  agarose hydrogel  gastric ulcer treatment  catastrophic situation  inflammatory process  stomach wall  programmable medicine  Plugs  Stomach  Navigation  Shape  Fabrication  Robot sensing systems 
Abstract: Gastric ulcer is a chronic and complex (and often complete) erosion of the stomach wall that happens as a complication of a previous chronic, inflammatory process. It represents a catastrophic situation in which the patient is critical and its conditions need to be treated fast. This study presents a remotely navigatable and deployable ingestible patch and plug for gastric ulcer treatment. The patch/plug structure is made of agarose hydrogel that can change rigidity through hydration and dehydration. When dehydrated, it is rigid and can maintain a folded configuration so it can be ingested as a “pill”. This can be guided to the targeted location by a magnetic field, and be deployed instantly by hydration, namely by supplying water from the mouth. Due to the deployable origami design, it exhibits an expansion of 10 times its initial surface area, making the device suitable for the use of dressing a surface as a patch, and filling a hole as a plug.


Title: Open-Loop Drug Delivery Strategy to the Cochlea Using a Permanent Magnetic Actuator
Key Words: actuators  bioMEMS  diseases  drug delivery systems  drugs  electromagnetic actuators  magnetic actuators  manipulators  medical robotics  microrobots  disease locations  magnetics fields  reliable solution  innovative solution  human body  use ofrobotic devices  permanent magnetic actuator  open-loop drug delivery strategy  reliable drug administration  precise drug administration  human phantom cochlea  navigation proposed strategy  human cochlea  magnetic microparticle  freedom robotic manipulator  robotic drug delivery strategy  open-loop control way  magnetic actuator axis  pushing pulling forces  end-effector  permanent magnets  micronanorobots  Actuators  Robots  Ear  Magnetic separation  Drug delivery  Drugs  Permanent magnets 
Abstract: The use ofrobotic devices for drug delivery in sensitive area of the human body is an innovative and reliable solution. Most of them use magnetics fields, to steer micro-nano-robots into diseases locations. In this study, we use a magnetic actuator based on two permanent magnets as an end-effector of a robotic manipulator. The actuator offers the possibility to generate both pushing and pulling forces on the magnetic actuator axis in an open-loop control way. We describe in this paper the robotic drug delivery strategy that we implemented in a 6 degree of freedom robotic manipulator to push and to steer a magnetic microparticle from the round window to the apex of the human cochlea. Different experiments have been conducted in order to demonstrate the effectiveness and robustness of the navigation proposed strategy on a human phantom cochlea. The results demonstrate clearly that precise and reliable drug administration is rendered possible.


Title: Augmented Joint Stiffness and Actuation Using Architectures of Soft Pneumatic Actuators
Key Words: elastomers  pneumatic actuators  robots  helical actuators  parallel actuators  augmented joint stiffness  soft pneumatic actuators  soft robotic actuators  wearable soft robotic sleeve  fiber reinforced elastomeric enclosures  helical actuator architectures  linear actuators  linear-helical actuator configuration  FREE  Conferences  Automation  Australia 
Abstract: Soft robotic actuators are well suited for use in exoskeleton applications due to their innate compliance and low weight. We have developed a wearable soft robotic sleeve that uses fiber reinforced elastomeric enclosures (FREEs) to provide actuation and stiffness at the elbow for augmented lifting and carrying ability. The sleeve includes novel linear and helical actuator architectures to induce and resist joint movement respectively, and is intended to be comfortable, lightweight, and low profile. We developed test protocols to measure actuation and stiffness performance of different helical and linear architectures, and to compare helical and linear actuator groups when used individually and together. Our findings indicate that nested linear actuators have superior contraction ratios compared to parallel linear actuators, resulting in greater angular displacement. Stiffness from helical actuators increased with pressure and number of parallel actuators. A combined linear-helical actuator configuration considerably outperformed helical and linear actuator groups when used on their own.


Title: APAM: Antagonistic Pneumatic Artificial Muscle
Key Words: electroactive polymer actuators  medical robotics  motion control  muscle  pneumatic actuators  supports  internal chambers  tetrahedron apex  compliant truss robot  independent control  external chambers  pneumatic actuator  antagonistic pneumatic artificial muscle  APAM  Actuators  Shape  Electron tubes  Force  Muscles  Robots  Geometry 
Abstract: We present a pneumatic actuator capable of changing length by 1000%, applying both pushing and pulling forces, and independently modulating its length and stiffness. These characteristics are enabled by individually addressable internal and external chambers that work antagonistically against one another. The high deformation with low hysteresis is achieved by wrinkling of thin materials that are assumed to be inextensible but flexible, as opposed to stretchable. A model for the actuator is presented and validated with experimental results, showing capabilities of high strain, pushing and pulling, and independent control of length and stiffness. These characteristics are motivated by the application of a compliant truss robot. Accordingly, we show a simple grounded tetrahedron with three actuator elements and three static elements. We demonstrate motion of the tetrahedron apex against external loads and the ability of the structure to vary its stiffness. The actuator offers a unique set of characteristics that could increase the capabilities of soft robotic devices.


Title: Passive and Active Particle Damping in Soft Robotic Actuators *This work is funded by a Basic Research Grant from the University of Hong Kong.
Key Words: damping  design engineering  elasticity  industrial robots  pneumatic actuators  vibration control  passive particle damping  vibration damping method  University of Hong Kong  elastic bodies  energy source  soft actuator design  soft robotic actuators  active particle damping  Actuators  Damping  Vibrations  Robots  Friction  Shock absorbers  Force 
Abstract: Soft robotic actuators are highly elastic bodies that oscillate drastically once excited. This oscillation is undesirable in many applications. So far, very little studies on soft actuator damping have been reported. In this paper, we report a simple and effective vibration damping method based on passive and active particle damping. Experimental studies on the effectiveness of particle damping have been conducted. It is found that active particle damping is more effective than passive damping, nevertheless, active particle damping demands a more complicated design with extra energy source and control. Since particles are discrete matters, they can be seamless integrated into soft actuator design with only minor influence of soft actuator's compliance and softness.


Title: A Fluid-Filled Tubular Dielectric Elastomer Variable Stiffness Structure Inspired by the Hydrostatic Skeleton Principle *Research supported by the National Natural Science Foundation of China (No.51675413).
Key Words: dielectric materials  elastic constants  elastomers  elongation  oils  pre-stretch  tensile stiffness  fluid-filled tubular dielectric elastomer variable stiffness structure  insulating oil  fiber-constrained dielectric elastomer tube  hydrostatic skeleton principle  Electron tubes  Strain  Oils  Muscles  Hydraulic systems  Force  Soft robotics 
Abstract: This work presents a novel variable stiffness structure consisting of a fiber-constrained dielectric elastomer tube filled with insulating oil. The tensile stiffness of the structure can be adjusted by voltages and its initial value can be customized according to the initial pre-stretch of the material. The structure has a dimension of ~30 mm diameter × 50 mm length. A mathematical analysis is established to predict the initial tensile stiffness of the structure. The changes of the tensile stiffness of the structure under voltages are verified experimentally. The results show a decrease of the tensile stiffness of the device by 25% at 4 kV and the decrement is also related to the elongation of the structure. With different pre-stretches and dimensions of the dielectric elastomer, one can obtain devices with different variation ranges of tensile stiffness.


Title: Stiffness Variability in Jamming of Compliant Granules and a Case Study Application in Climbing Vertical Shafts
Key Words: bending  biomechanics  elastic constants  elasticity  end effectors  force measurement  friction  granular materials  legged locomotion  pressure sensors  shafts  cubic shaped granules  gradual stiffness change  jamming membranes  end effectors  bending stiffness  climbing task  shaft walls  compressive stiffness variation  multimodal properties  granular material  stiffness variability  quasisolid state  packing density  compliant granules jamming  granular media jamming  bioinspired robotic platform  straight vertical shafts climbing  friction force measurement  pressure sensor  force dissipators  Jamming  Biomembranes  End effectors  Shape  Shafts  Legged locomotion  Soft robotics  variable stiffness joints  vacuum jamming  universal gripper  climbing 
Abstract: Jamming of granular media has been shown to possess the property of stiffness variation, transitioning from a soft to a quasi-solid state depending on the packing density of the granules. Recently, a gradual stiffness change for bending has been reported by using compliant, cubic shaped granules. Here we demonstrate that the same method and material also exhibits a gradual stiffness change for compression. As a potential application of “compliant jamming”, a bio-inspired robotic platform with jamming membranes as end effectors is designed and tasked with climbing straight vertical shafts. First, the benefit of varying the bending stiffness is investigated in the climbing task by measuring the friction force that the end effectors are applying to the shaft walls, especially if the walls are irregularly shaped. Then the role of compressive stiffness variation is explored by analyzing the performance of the robot in the climbing task, showing multi-modal properties of jamming membranes: (i) enabling a pressure sensor to detect the shaft walls, acting (ii) as grippers that actively use the irregularities of the walls to climb up by state-switching the granular material and (iii) as force dissipators that can dissipate internal forces caused by closed kinematic chains.


Title: A Geometric and Unified Approach for Modeling Soft-Rigid Multi-Body Systems with Lumped and Distributed Degrees of Freedom
Key Words: elasticity  geometry  inverse problems  Newton method  robot dynamics  discrete Cosserat approach  soft-body dynamics  geometric theory  recursive Newton-Euler algorithm  forward dynamic problems  soft robots  soft-rigid multibody systems  inverse problems  linear complexity  Kinematics  Fasteners  Strain  Heuristic algorithms  Algebra  Soft robotics 
Abstract: In this paper, a geometric and unified model of soft-rigid multi-body systems is presented, based on a discrete Cosserat approach of the soft-body dynamics. The model is in fact a generalization to soft and hybrid systems of the geometric theory of rigid robotics characterized by the exponential map. A generalization of the recursive Newton-Euler algorithm is also presented, able to solve inverse and forward dynamic problems with linear O(N) complexity. The proposed model provides several improvements with respect to the existing flexible multi-body models, which make it particularly suitable to study the dynamics of modern soft robots as shown for a multi-body system inspired by motile bacteria.


Title: Morphological Adaptation in an Energy Efficient Vibration-Based Robot
Key Words: beams (structures)  elasticity  energy conservation  legged locomotion  vibrations  adaptation ability  robot locomotion  morphological adaptation  energy efficient vibration-based robot  morphological computation  soft materials  elastic materials  low-cost robot  elastic curved beam  robots rich dynamics  robots shape  rotating frequency  Legged locomotion  DC motors  Springs  Resonant frequency  Foot  Shape 
Abstract: Morphological computation is a concept relevant to robots made of soft and elastic materials. It states that robot's rich dynamics can be exploited to generate desirable behaviors, which can be altered when their morphology is adapted accordingly. This paper presents a low-cost robot made of elastic curved beam driven by a motor, with morphological computation and adaptation ability. Simply by changing robot's shape and the rotating frequency of the motor that vibrates the robot's body, the robot is able to shift its behavior from showing a tendency to slide when it needs to perform tasks like going under confined space, to have more tendency to hop diagonally forward when the robot stands upright. It will also be shown that based on the proposed mechanism, the energy efficiency of the robot locomotion can be maximized.


Title: Bio-Inspired Octopus Robot Based on Novel Soft Fluidic Actuator
Key Words: actuators  biomechanics  biomimetics  legged locomotion  mobile robots  motion control  pneumatic actuators  robot dynamics  bio-inspired octopus robot  novel soft fluidic actuator  modern roboticists  novel robotic structures  soft robots  complex motion patterns  octopus tentacles  bio-mimetic approach  soft material  Actuators  Manipulators  Force  Robot sensing systems  Soft robotics  Fabrication 
Abstract: Many modern roboticists take inspiration from biology to create novel robotic structures, including those that are modeled after the octopus. This paper advances this trend by creating soft robots modeling the complex motion patterns of octopus tentacles employing a bio-mimetic approach. The proposed octopus robot is entirely made from soft material and uses a novel fluidic actuation mechanism that allows the robot to advance forward, change directions and rotate around its primary axis. The paper presents the robot's design and fabrication process. An experimental study is conducted showing the feasibility of the proposed robot and actuation mechanism.


Title: Completion Time Analysis for Automated Manufacturing Systems with Parallel Processing Modules
Key Words: cluster tools  etching  hoists  industrial robots  lithography  lot sizing  manufacturing systems  materials testing  parallel processing  scheduling  semiconductor device manufacture  semiconductor industry  storage  semiconductor manufacturing processes  lithography  etching  materials testing  scheduling  lot finish processing  stockers  overhead hoist transports  wafer lots  transport robot  dual-armed cluster tool  parallel processing modules  automated manufacturing systems  completion time analysis  Tools  Robots  Task analysis  Switches  Optimal scheduling  Job shop scheduling  Time factors 
Abstract: This paper analyzes the completion time of automated manufacturing systems, especially a dual-armed cluster tool, equipped with parallel processing modules (PMs). Cluster tools, which consist of multiple PMs, a transport robot, and loadlocks where wafer lots are loaded and unloaded, perform semiconductor manufacturing processes, such as lithography, etching, deposition, and testing. Wafer lots are transported by overhead hoist transports (OHTs) between tools or stockers where wafer lots are stored. To reduce the idle time of OHTs or cluster tools, it is essential to estimate the time when all wafers of a lot finish processing in a tool. Hence, we derive closed-form expressions for the completion time of wafer lots, especially in dual-armed cluster tools with parallel PMs to reflect real circumstances of fabs. We finally show that the formulas derived can be used even when there are small processing time variations with numerical experiments.


Title: Reliably Arranging Objects in Uncertain Domains
Key Words: learning (artificial intelligence)  manipulators  mobile robots  multi-robot systems  path planning  control uncertainty  conformant planning approach  robot manipulation  multiple planar objects  specified arrangement  external sensing  belief-state planning problem  initial belief state  forward belief-state planning  deterministic belief-state transition model  off-line physics simulations  on-line physics-based manipulation approach  physical robot experiments  uncertain domains  Planning  Robot sensing systems  Task analysis  Reliability  Computational modeling  Uncertainty 
Abstract: A crucial challenge in robotics is achieving reliable results in spite of sensing and control uncertainty. In this work, we explore the conformant planning approach to robot manipulation. In particular, we tackle the problem of pushing multiple planar objects simultaneously to achieve a specified arrangement without external sensing. Conformant planning is a belief-state planning problem. A belief state is the set of all possible states of the world, and the goal is to find a sequence of actions that will bring an initial belief state to a goal belief state. To do forward belief-state planning, we created a deterministic belief-state transition model from supervised learning based on off-line physics simulations. We compare our method with an on-line physics-based manipulation approach and show significantly reduced planning times and increased robustness in simulated experiments. Finally, we demonstrate the success of this approach in simulations and physical robot experiments.


Title: RoboTSP – A Fast Solution to the Robotic Task Sequencing Problem
Key Words: industrial robots  travelling salesman problems  Robotic Task Sequencing Problem  industrial robotics applications  spray-painting  robot travel time  execution time  robot configurations  task space  configuration space  RTSP literature  Generalized Traveling Salesman Problem  Task analysis  Measurement  Collision avoidance  Service robots  Planning  Space exploration 
Abstract: In many industrial robotics applications, such as spot-welding, spray-painting or drilling, the robot is required to visit successively multiple targets. The robot travel time among the targets is a significant component of the overall execution time. This travel time is in turn greatly affected by the order of visit of the targets, and by the robot configurations used to reach each target. Therefore, it is crucial to optimize these two elements, a problem known in the literature as the Robotic Task Sequencing Problem (RTSP). Our contribution in this paper is two-fold. First, we propose a fast, near-optimal, algorithm to solve RTSP. The key to our approach is to exploit the classical distinction between task space and configuration space, which, surprisingly, has been so far overlooked in the RTSP literature. Second, we provide an open-source implementation of the above algorithm, which has been carefully benchmarked to yield an efficient, ready-to-use, software solution. We discuss the relationship between RTSP and other Traveling Salesman Problem (TSP) variants, such as the Generalized Traveling Salesman Problem (GTSP), and show experimentally that our method finds motion sequences of the same quality but using several orders of magnitude less computation time than existing approaches.


Title: An Automated Reactive Approach to Single Robot Exogeneous Planar Assembly
Key Words: collision avoidance  motion control  robotic assembly  unactuated disk-shaped parts  automated reactive approach  single robot exogeneous planar assembly  assembly task  Conferences  Automation  Australia 
Abstract: In this paper, we are concerned with the automation of single robot exogeneous assembly in simple planar settings. Here, a set of of unactuated disk-shaped parts needs to be serviced by a single robot that resides outside the workspace and is capable of moving the parts one at a time through sliding or lifting slightly. The task is to have the parts end up in their respective goal positions without any collisions whilst moving. We present an automated reactive approach through the composition of one-part movements. The movement of each part is achieved by a controller obtained through the projection of a carefully constructed vector field on the respective configuration subspace. Such a scheme is known to accommodate positional variations naturally. Once the movement terminates, the robot chooses the next part to move in a cyclic manner. The contribution of this paper is to show for the first time that with certain restrictions on the allowed goal configurations, the assembly task is either successfully completed or terminated (rather than useless cycling of a part or from part to part) while the generated sequence of motions never causes collisions among the parts.


Title: Robotic Cleaning Through Dirt Rearrangement Planning with Learned Transition Models
Key Words: cleaning  learning (artificial intelligence)  manipulators  mobile robots  path planning  sampling methods  service robots  PR2 robots  Fetch robots  primitive dirt-oriented tool actions  heuristic search  cleaning tool  arbitrary amounts  manipulator  learned transition models  dirt rearrangement planning  robotic cleaning  Tools  Planning  Surface cleaning  Manipulators  Task analysis 
Abstract: We address the problem of enabling a manipulator to move arbitrary amounts and configurations of dirt on a surface to a goal region using a cleaning tool. We represent this problem as heuristic search with a set of primitive dirt-oriented tool actions. We present dirt and action representations that allow efficient learning and prediction of future dirt states, given the current dirt state and applied action. We also present a method for sampling promising actions based on a clustering of dirt states and heuristics for planning. We demonstrate the effectiveness of our approach on challenging cleaning tasks through implementations on PR2 and Fetch robots.


Title: Fast Planning for 3D Any-Pose-Reorienting Using Pivoting
Key Words: dexterous manipulators  geometry  grippers  mesh generation  solid modelling  fast planning  two-finger pinch gripper  3D mesh model  gripper motions  arbitrary object  grasping positions  gripper poses  motion primitives  compliant rolling  planning problem  object shapes  nontrivial geometry  gripper workspace  3D Any-pose-reorienting  mesh models approximation  pivoting  Grippers  Planning  Gravity  Robots  Three-dimensional displays  Friction 
Abstract: In this paper, we consider reorienting 3D objects on a table using a two-finger pinch gripper. Given the 3D mesh model of the object, our algorithm solves for the gripper motions that are required to transit between arbitrary object poses, grasping positions and gripper poses. The two motion primitives we used, pivoting and compliant rolling, enable us to decompose the planning problem and solve it more efficiently. Our algorithm can work with approximated (simplified) mesh models while being robust to approximation errors, thereby allowing us to efficiently handle object shapes with originally thousands of facets. We show the effectiveness of the proposed method by testing on objects with non-trivial geometry in both simulations and experiments. Results show that our algorithm can solve a larger range of reorienting problems with less number of making and breaking contacts when compared to traditional pick-and-place based methods, especially when the gripper workspace is highly constrained.


Title: Modeling and Control of Brachiating Robots Traversing Flexible Cables
Key Words: cables (mechanical)  legged locomotion  manipulator dynamics  motion control  optimal control  torque control  trajectory control  vibration control  brachiating robots  coupling soft junctions  multiple-shooting  parametric trajectory approaches  catenary cable  energy-efficient continuous brachiation  optimal torque profiles  control torque profiles  optimized trajectories  robot locomotion  cable vibration  energy-minimizing optimal control strategy  two-link robot  multibody system  flexible cable  two-link underactuated brachiating robot  locomotion control  dynamic modeling  Junctions  Mathematical model  Grippers  Legged locomotion  Trajectory  Robot kinematics 
Abstract: This paper describes the dynamic modeling and locomotion control of a two-link underactuated brachiating robot traversing a flexible cable. A multi-body system comprised of a two-link robot, a flexible cable, and coupling soft junctions is modeled dynamically. This model is used to formulate an energy-minimizing optimal control strategy that includes the effects of cable vibration induced by robot locomotion. Optimized trajectories and control torque profiles are obtained via multiple-shooting and parametric trajectory approaches. Simulation results show that these optimal torque profiles result in energy-efficient continuous brachiation over a flexible cable. Additional studies examine how the optimal torque profiles change depending on the robot's initial position along a catenary cable.


Title: Performance Indicator for Benchmarking Force-Controlled Robots
Key Words: force control  force feedback  mobile robots  position control  robotic assembly  performance indicator  force control  impedance control  robot-based sensitive assembly  robotics  force feedback information  direct force control  force-controlled robot benchmarking  Force  Robot sensing systems  Service robots  Task analysis  Tools  Benchmark testing 
Abstract: Robot-based sensitive assembly is a recent and growing trend in robotics. Force-controlled robots are expected to interact with an unknown environment using solely force feedback information. In general, the exact contact is difficult to predict due to various impact factors, such as the dynamics of the interaction, work-piece stiffness and geometry, the robot's configuration, and the efficiency of the control algorithm. Currently, there is no general indicator for evaluating the performance of a force-controlled robot. This work presents a concept of such a performance indicator. In order to test the proposed concept for comparison, an experimental setup is presented that simulates a contour-following task under force control. This setup is used to test two robots with different force-controllers and control principles, namely direct force and impedance control. The results indicate good applicability of the proposed performance indicator to benchmark force-controlled robots, and this is extensively discussed.


Title: A Failure-Tolerant Approach to Synchronous Formation Control of Mobile Robots Under Communication Delays
Key Words: delays  mobile robots  motion control  multi-robot systems  switching systems (control)  topology  failure-tolerant approach  mobile robots  communication delays  robot malfunction  robot formation control  system malfunction  synchronous formation control problem  network connectivity  motion synchronism  robot replacements  synchronous formation control method  recursive switched topology control strategy  neighboring robots  Topology  Switches  Robot kinematics  Network topology  Synchronization 
Abstract: Robot malfunction is inevitable in practical applications of the robot formation control due to uncontrolled crashing, system malfunction or communication loss. In this paper, we study the synchronous formation control problem in the presence of robot malfunctions. Our main idea is to improve the network connectivity and motion synchronism of the robot formation through a series of topology switchings and robot replacements. Firstly, the synchronous formation control method is introduced which enables the robots to tracking their desired trajectories while keeping predefined formation shapes. Secondly, a recursive switched topology control strategy is proposed to restore the formation shape as well as to improve the network connectivity and motion synchronism in the presence of robot malfunctions. Thirdly, the convergence analysis of the proposed control system is presented and a sufficient condition is obtained under an average dwell time scheme. What's more, the proposed approach is fully distributed and the communication delays between neighboring robots also have been taken into consideration. Simulation results demonstrate the effectiveness of the proposed approach.


Title: Perceived Stiffness Estimation for Robot Force Control
Key Words: adaptive control  force control  manipulators  position control  environment stiffness  perceived stiffness estimation  positive force feedback loop  contact dynamics  force measurements  force signals  low pass filters  environment dynamics  force control performance  force control perspective  robot effective mass  force based stiffness estimation strategy  control gains  control optimization parameter  force control  robot dynamics  Robots  Force  Estimation  Dynamics  Force control  Effective mass  Adaptation models 
Abstract: Typical robot force control architectures have a positive force feedback loop to decouple robot dynamics from contact dynamics. Due to the noisy profile of force measurements, it is common to filter force signals by low pass filters. This paper shows that, when force feedback is filtered, robot and environment dynamics are no longer decoupled, affecting force control performance. Additionally, the perceived stiffness from the force control perspective, is correlated with the robot effective mass. To cope with this issue, a force based stiffness estimation strategy that also includes the inertial properties (effective mass) in the estimation algorithm is proposed, allowing to adapt control gains based on the robot effective mass. In this way, the perceived stiffness can be seen as a control optimization parameter, rather than a well defined physical property. Simulation and experimental results with a 1-DoF robot and 7-DoF manipulator, respectively, validate the estimation strategy, showing better force control results with the perceived stiffness in the control loop, as compared to the real environment stiffness.


Title: Grasp a Moving Target from the Air: System & Control of an Aerial Manipulator
Key Words: autonomous aerial vehicles  force control  manipulator dynamics  mobile robots  motion control  robot vision  rotors  visual servoing  CoM offset motion  center of mass  aerial grasping experiments  aerial vehicle  aerial manipulator control system  independent control structure  hex-rotor  fixed-base manipulator  Manipulator dynamics  Grasping  Control systems  Kinematics  Vehicle dynamics 
Abstract: Grasping a moving target has been investigated extensively for fixed-base manipulator. However, such a task becomes much more challenging when the manipulator is free flying in the air with an UAV. Towards moving target grasping, this paper presents an aerial manipulator system composed of a hex-rotor and a 7-DoF (Degree of Freedom) manipulator. An independent control structure is used in the aerial manipulator control system, i.e., the hex-rotor and the manipulator are controlled separately. In the hex-rotor's controller, the system CoM (Center of Mass) offset motion is used to compensate disturbance of the robotic arm. In the manipulator's controller, the relative kinematics between the target and the aerial vehicle is taken into consideration to grasp the target. At last aerial grasping experiments are conducted to validate the feasibility of the proposed control scheme and the reliability of our aerial manipulator system.


Title: Task Space Motion Planning Decomposition
Key Words: manipulators  mobile robots  path planning  autonomous robotics  T-Space parameters  maze navigation  path planning  motion planning  Task Space Motion Planning Decomposition  TSMPD  manipulator  Planning  Task analysis  Manipulators  Manifolds  Kinematics  Robot kinematics 
Abstract: In autonomous robotics there are many situations that require solving a motion planning problem to complete a task. A Task Space (T-Space), composed of parameters that define the task being performed, can be a more effective planning space for these problems, however, planning within a T-Space is often computationally challenging. In this paper, we present a novel method to analyse the relationship between T-Space parameters and the pose of manipulator bodies to create a dependency matrix. We then use this information to decompose the motion planning problem into sequential lower complexity sub-problems. We call this approach Task Space Motion Planning Decomposition (TSMPD). This paper introduces TSMPD and quantifies the improvement to planning efficiency on a challenging maze navigation problem and weld path planning problem.


Title: Planning Hybrid Driving-Stepping Locomotion on Multiple Levels of Abstraction
Key Words: legged locomotion  path planning  navigating  rescue environments  locomotion methods  navigation planning method  hybrid driving-stepping locomotion planning  Momaro robot  robot state dimensionality  Planning  Robot sensing systems  Legged locomotion  Semantics  Motion segmentation 
Abstract: Navigating in search and rescue environments is challenging, since a variety of terrains has to be considered. Hybrid driving-stepping locomotion, as provided by our robot Momaro, is a promising approach. Similar to other locomotion methods, it incorporates many degrees of freedom - offering high flexibility but making planning computationally expensive for larger environments. We propose a navigation planning method, which unifies different levels of representation in a single planner. In the vicinity of the robot, it provides plans with a fine resolution and a high robot state dimensionality. With increasing distance from the robot, plans become coarser and the robot state dimensionality decreases. We compensate this loss of information by enriching coarser representations with additional semantics. Experiments show that the proposed planner provides plans for large, challenging scenarios in feasible time.


Title: Design and Evaluation of Skating Motions for a Dexterous Quadruped
Key Words: control system synthesis  legged locomotion  mobile robots  motion control  robot dynamics  wheels  Dexterous Quadruped  contact force distribution  wheel slip  three-wheeled skating maneuvers  omnidirectional motion primitives  dexterous limbs  quadruped robot  skating motions  locomotion  continuous ground contact  Wheels  Mobile robots  Planning  Force  Trajectory  Acceleration 
Abstract: This paper describes skating locomotion for a quadruped robot with dexterous limbs. The emphasis is on design of omnidirectional motion primitives and quantification of resulting speed and accuracy when traversing different types of smooth but potentially non-flat terrain. In particular, we study trade-offs between using four-wheeled versus three-wheeled skating maneuvers. In four-wheeled skating, motions have the benefit of symmetry, so that errors due to wheel slip should theoretically cancel out on average. Three-wheeled skating, by contrast, introduces significantly more asymmetry in configuration and contact force distribution over time; however, it has the advantage of guaranteeing continuous ground contact for all skates when terrain has bumps or other curvature. We present simulation results quantifying errors for each approach, for various terrains. Our results allow us to tune motions to reduce biases and variability in motion, which are primarily due to accelerations as locomotion begins.


Title: Gradient-Informed Path Smoothing for Wheeled Mobile Robots
Key Words: gradient methods  mobile robots  motion control  optimal control  optimisation  path planning  robot dynamics  robot kinematics  smoothing methods  trajectory control  wheels  wheeled mobile robots  crowded environments  optimal sampling-based motion planners  nonoptimal motion planners  post-smoothing step  gradient-informed post-smoothing algorithm  gradient-informed path smoothing  smooth trajectories planning  GRIPS  kinodynamic constraints  Trajectory  Smoothing methods  Shape  Mobile robots  Interpolation  Strain 
Abstract: Planning smooth trajectories is important for the safe, efficient and comfortable operation of mobile robots, such as wheeled robots moving in crowded environments or cars moving at high speed. Asymptotically optimal sampling-based motion planners can be used to generate such trajectories. However, to achieve the necessary efficiency for the realtime operation of robots, one often uses their initial feasible trajectories or the trajectories of non-optimal motion planners instead, typically after a post-smoothing step. We propose a gradient-informed post-smoothing algorithm, called GRIPS, that deforms given trajectories by locally optimizing the placement of vertices while satisfying the system's kinodynamic constraints. We show experimentally that GRIPS typically produces trajectories of significantly smaller length and higher smoothness than several existing post-smoothing algorithms.


Title: Indoor Coverage Path Planning: Survey, Implementation, Analysis
Key Words: mobile robots  path planning  service robots  trajectory control  indoor coverage path planning  robot trajectories  mobile cleaning robots  lawn mowing robots  harvesting machines  Path planning  Cleaning  Robot sensing systems  Planning  Traveling salesman problems 
Abstract: Coverage Path Planning (CPP) describes the process of generating robot trajectories that fully cover an area or volume. Applications are, amongst many others, mobile cleaning robots, lawn mowing robots or harvesting machines in agriculture. Many approaches and facets of this problem have been discussed in literature but despite the availability of several surveys on the topic there is little work on quantitative assessment and comparison of different coverage path planning algorithms. This paper analyzes six popular off-line coverage path planning methods, applicable to previously recorded maps, in the setting of indoor coverage path planning on room-sized units. The implemented algorithms are thoroughly compared on a large dataset of over 550 rooms with and without furniture.


Title: Robot Navigation in Complex Workspaces Using Harmonic Maps
Key Words: geometry  mobile robots  motion control  path planning  robot vision  SLAM (robots)  complex workspaces  harmonic maps  Artificial Potential Fields  autonomous robot navigation control schemes  local minima  APF based control scheme  goal configuration  multiply connected compact 2D workspaces  Harmonic analysis  Navigation  Robot kinematics  Convergence  Tuning  Trajectory 
Abstract: Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline “tuning” of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.


Title: Backprop-MPDM: Faster Risk-Aware Policy Evaluation Through Efficient Gradient Optimization
Key Words: decision making  gradient methods  learning (artificial intelligence)  Markov processes  optimisation  stochastic processes  multipolicy decision-making  gradient optimization  risk-aware policy evaluation  backprop-MPDM policy  robot platform  easily-differentiable heuristic function  random sampling  stochastic gradient optimization algorithms  decision making process  risk-aware formulations  Robots  Computational modeling  Trajectory  Navigation  Decision making  Cost function 
Abstract: In Multi-Policy Decision-Making (MPDM), many computationally-expensive forward simulations are performed in order to predict the performance of a set of candidate policies. In risk-aware formulations of MPDM, only the worst outcomes affect the decision making process, and efficiently finding these influential outcomes becomes the core challenge. Recently, stochastic gradient optimization algorithms, using a heuristic function, were shown to be significantly superior to random sampling. In this paper, we show that accurate gradients can be computed - even through a complex forward simulation - using approaches similar to those in deep networks. We show that our proposed approach finds influential outcomes more reliably, and is faster than earlier methods, allowing us to evaluate more policies while simultaneously eliminating the need to design an easily-differentiable heuristic function. We demonstrate significant performance improvements in simulation as well as on a real robot platform navigating a highly dynamic environment.


Title: Spherical Foot Placement Estimator for Humanoid Balance Control and Recovery
Key Words: feedback  humanoid robots  legged locomotion  motion control  optimal control  robot dynamics  stepping  SFPE-based feedback  SFPE point  control reference  balance criteria  recovery step location prediction  momentum objectives  Spherical Foot Placement Estimator  bipedal gait  unknown disturbances  momentum-based leaning  smooth dynamics  Three-dimensional displays  Foot  Integrated circuit modeling  Mathematical model  Legged locomotion  Solid modeling  Iterative closest point algorithm 
Abstract: One of the main challenges of bipedal gait is to avoid falling due to unknown disturbances. Compensating for these disturbances in bipeds is often achieved by leaning or stepping. In this work, the Spherical Foot Placement Estimator (SFPE) is introduced, which uses the biped's current kinematics and dynamics to predict if a step is needed, and if so where to step, to restore balance in 3D. An example of a controller using the SFPE is shown, which augments an existing optimal controller with both leaning and stepping: SFPE-based feedback is used to generate a desired momentum for momentum-based leaning while the SFPE point is used as a control reference for stepping. The new estimator outperforms existing balance criteria by providing both recovery step location prediction and momentum objectives with smooth dynamics.


Title: Bayesian Optimization Using Domain Knowledge on the ATRIAS Biped
Key Words: Bayes methods  control engineering computing  gait analysis  learning (artificial intelligence)  legged locomotion  motion control  optimisation  Bayesian optimization  1-dimensional space  feature transformation  different walking controllers  ATRIAS bipedal robot  nonhumanoid robot morphologies  human-inspired neuromuscular controller  human walking  16-dimensional locomotion controller  bipedal locomotion  black-box data-efficient optimization scheme  data-efficient learning techniques  legged locomotion  simulation transfer  expert-designed heuristics  robotics controllers  domain knowledge  Hardware  Legged locomotion  Optimization  Kernel  Transforms  Measurement 
Abstract: Robotics controllers often consist of expert-designed heuristics, which can be hard to tune in higher dimensions. Simulation can aid in optimizing these controllers if parameters learned in simulation transfer to hardware. Unfortunately, this is often not the case in legged locomotion, necessitating learning directly on hardware. This motivates using data-efficient learning techniques like Bayesian Optimization (BO) to minimize collecting expensive data samples. BO is a black-box data-efficient optimization scheme, though its performance typically degrades in higher dimensions. We aim to overcome this problem by incorporating domain knowledge, with a focus on bipedal locomotion. In our previous work, we proposed a feature transformation that projected a 16-dimensional locomotion controller to a 1-dimensional space using knowledge of human walking. When optimizing a human-inspired neuromuscular controller in simulation, this feature transformation enhanced sample efficiency of BO over traditional BO with a Squared Exponential kernel. In this paper, we present a generalized feature transform applicable to non-humanoid robot morphologies and evaluate it on the ATRIAS bipedal robot, in both simulation and hardware. We present three different walking controllers and two are evaluated on the real robot. Our results show that this feature transform captures important aspects of walking and accelerates learning on hardware and simulation, as compared to traditional BO.


Title: Balance Control Using Both ZMP and COM Height Variations: A Convex Boundedness Approach
Key Words: convex programming  humanoid robots  legged locomotion  mechanical stability  mechanical variables control  convex boundedness approach  biped robots  CoM height variations  nonconvex direct transcriptions  centroidal dynamics  boundedness condition  balance control  ZMP  sagittal plane  CoM trajectories  Trajectory  Mathematical model  Three-dimensional displays  Two dimensional displays  Robots  Radio frequency  Differential equations 
Abstract: Developments for 3D control of the center of mass (CoM) of biped robots are currently located in two local minima: on the one hand, methods that allow CoM height variations but only work in the 2D sagittal plane; on the other hand, nonconvex direct transcriptions of centroidal dynamics that are delicate to handle. This paper presents an alternative that controls the CoM in 3D via an indirect transcription that is both low-dimensional and solvable fast enough for real-time control. The key to this development is the notion of boundedness condition, which quantifies the capturability of 3D CoM trajectories.


Title: An MPC Walking Framework with External Contact Forces
Key Words: compensation  integer programming  legged locomotion  linear systems  predictive control  quadratic programming  hand contact  MPC walking framework  external contact forces  two-step optimization problem  Zero Moment Point  ZMP tracking error  friction cone  walking control scheme  linear model predictive control scheme  multiple contact locations  center of mass trajectory  mixed integer quadratic program  frequency 100.0 Hz to 300.0 Hz  Optimization  Force  Legged locomotion  Trajectory  Friction  Dynamics 
Abstract: In this work, we present an extension to a linear Model Predictive Control (MPC) scheme that plans external contact forces for the robot when given multiple contact locations and their corresponding friction cone. To this end, we set up a two-step optimization problem. In the first optimization, we compute the Center of Mass (CoM) trajectory, foot step locations, and introduce slack variables to account for violating the imposed constraints on the Zero Moment Point (ZMP). We then use the slack variables to trigger the second optimization, in which we calculate the optimal external force that compensates for the ZMP tracking error. This optimization considers multiple contacts positions within the environment by formulating the problem as a Mixed Integer Quadratic Program (MIQP) that can be solved at a speed between 100-300 Hz. Once contact is created, the MIQP reduces to a single Quadratic Program (QP) that can be solved in real-time (<; 1kHz). Simulations show that the presented walking control scheme can withstand disturbances 2-3× larger with the additional force provided by a hand contact.


Title: Inclusion of Angular Momentum During Planning for Capture Point Based Walking
Key Words: angular momentum  gait analysis  humanoid robots  legged locomotion  motion control  trajectory control  smooth trajectories  continuous trajectories  leg swing  nonnegligible angular momentum rate  reference trajectory generator  bipedal walking  centroidal angular momentum  planning stage  closed-form trajectory solutions  centroidal moment pivot  instantaneous capture point  CMP  ICP  center of mass  Legged locomotion  Trajectory  Iterative closest point algorithm  Planning  Dynamics  Lips 
Abstract: When walking at high speeds, the swing legs of robots produce a non-negligible angular momentum rate. To accommodate this, we provide a reference trajectory generator for bipedal walking that incorporates predicted centroidal angular momentum at the planning stage. This can be done efficiently as the Centroidal Moment Pivot (CMP), Instantaneous Capture Point (ICP) and the center of mass (CoM) all have closed-form trajectory solutions due to their linear dynamics. This is then used to produce smooth, continuous trajectories. We furthermore provide a lightweight model to estimate angular momentum as induced during leg swing of the gait cycle. Our proposed trajectory generator is tested thoroughly in simulation and has been shown to successfully operate on the real hardware.


Title: Subject-Independent Data Pooling in Classification of Gait Intent Using Mechanomyography on a Transtibial Amputee
Key Words: artificial limbs  electromyography  gait analysis  learning (artificial intelligence)  medical signal processing  neurophysiology  signal classification  support vector machines  support vector machine classifier  movement delay classification  controller response  training pool  subject specific classifiers  prosthetic legs  subject-specific amputee data sets  supervised training  real-time monitoring  EMG  neuromuscular interfaces  patient activities  inertial measurement units  prosthetic measurement units  gait mode  active lower limb prosthetics  transtibial amputee  mechanomyography  gait intent  subject-independent data pooling  prosthetic control  subject-specific training  MMG gait classifier  user-specific data  pooled training data  Electromyography  Training  Legged locomotion  Muscles  Sensors  Prosthetics  Support vector machines 
Abstract: Active lower limb prosthetics rely on the detection of gait mode to direct controller response. The majority of systems require feedback from the prosthetic and/or inertial measurement units (IMUs). Reliance on movement delays classification, reducing the range of patient activities and terrain traversed. Neuromuscular interfaces using electromyography (EMG) enable real-time monitoring by registering user intent, however EMG has known robustness issues out-of-clinic that have impeded its translation. Furthermore, supervised training of gait classifiers can require large subject-specific amputee data sets which are difficult to obtain. Mechanomyography (MMG) has shown less dependence on environmental conditions than EMG yet has seen limited use in this realm. In this investigation we introduce an MMG gait classifier targeting improved control of prosthetic (robotic) legs. We compare the accuracy of subject specific classifiers to those trained using subject-independent pooling. Additionally, we quantify the effect of introducing a small amount of data from individual test subjects to the training pool. Experiments were performed on 12 participants and 5 gait modes. A support vector machine (SVM) classifier achieved 65% accuracy with subject-specific data, 92% with pooled training data, and 94% with pooled plus limited user-specific data. The results show the promise of MMG gait classifiers with increased robustness and reduced subject-specific training in prosthetic control.


Title: Empirical Quantification and Modeling of Muscle Deformation: Toward Ultrasound-Driven Assistive Device Control
Key Words: biomechanics  biomedical ultrasonics  electromyography  medical image processing  medical robotics  medical signal processing  muscle  assistive device sensor locations  real-time ultrasound scanning  muscle cross-sectional area  force-associated deformation signals  motion capture  ultrasound scanner  high-DoF assistive devices  B-mode ultrasound  exoskeletons  biosignal-driven prostheses  surface electromyography  toward ultrasound-driven assistive device control  empirical quantification  muscle deformation models  Muscles  Strain  Ultrasonic imaging  Elbow  Assistive devices  Deformable models  Ultrasonic variables measurement 
Abstract: Surface electromyography is currently the sensing modality of choice for control of biosignal-driven prostheses and exoskeletons; however, the sensor's noisy and aggregate nature inhibits collection of distinguishable signal streams to robustly manipulate multiple device degrees of freedom (DoF). We here explore 2D B-mode ultrasound as an alternative source of muscle activation data (namely, muscle deformation) that can be more precisely localized, allowing for the theoretical collection of multiple naturally-varying signals that could be used to control high-DoF assistive devices. We here present a proof-of-concept study showing a) the observability of muscle deformation via ultrasound, and b) novel descriptions of the spatially-varying nature of the signal. These analyses are accomplished through the study of nine volumetric scans of the biceps brachii under varied elbow angle and loading conditions, collected and spatially localized using an ultrasound scanner and motion capture. We here establish the feasibility of measuring several force-associated deformation signals (including muscle cross-sectional area and thickness) via real-time ultrasound scanning and quantify the spatial variation of these signals. Additionally, we propose future applications for both our signal characterizations and the generated muscle volume data set, including better design of assistive device sensor locations and validation of existing muscle deformation models.


Title: Grasp-training Robot to Activate Neural Control Loop for Reflex and Experimental Verification
Key Words: electromyography  handicapped aids  medical robotics  neurocontrollers  neurophysiology  patient rehabilitation  grasp rehabilitation  robot design  grasping movements  mechanical motions  reflex response  motion intention  rehabilitation robot  activate neural control loop  grasp-training robot  paralyzed hand  grasp reflex  elastic bar  Robots  Grasping  Shafts  Bars  Force  Electromyography  Rubber 
Abstract: Using a rehabilitation robot to activate motion intention and reflex response simultaneously is an effective approach to aiding recovery from paralysis caused by neurological disorders. Mechanical motions supported by conventional robots are, however, not enough to activate reflex. In this paper, we propose a grasp-training robot that can stimulate the grasp reflex of a paralyzed hand by pushing the hand onto an elastic bar while supporting the grasping movements. In addition to this feature, we discuss the robot design in relation to its usability and wearability for ease of use in clinical practice. Experimental results obtained from healthy subjects show that the proposed robot can support grasping in a way similar to the traditional range-of-motion exercise used by therapists for grasp rehabilitation. Combining this appropriate grasping-motion support and the mechanism for pushing the hand onto an elastic bar succeeds in activating the grasp reflex of a completely paralyzed patient in a clinical test that involves monitoring electromyography signals from the paralyzed hand.


Title: Mark Yourself: Road Marking Segmentation via Weakly-Supervised Annotations from Multimodal Data
Key Words: feature extraction  image segmentation  object detection  object recognition  traffic engineering computing  unsupervised learning  video signal processing  visual databases  road marking segmentation  weakly-supervised annotations  multimodal data  weakly-supervised learning system  complex urban environments  monocular camera  expensive manual labelling  annotated images  deep semantic segmentation network  road markings  traffic situations  weather conditions  sensor modalities  lighting  qualitative performance  real-time road marking detection  labelling effort  Oxford RobotCar dataset  CamVid dataset  Roads  Laser radar  Cameras  Image segmentation  Real-time systems  Labeling  Semantics 
Abstract: This paper presents a weakly-supervised learning system for real-time road marking detection using images of complex urban environments obtained from a monocular camera. We avoid expensive manual labelling by exploiting additional sensor modalities to generate large quantities of annotated images in a weakly-supervised way, which are then used to train a deep semantic segmentation network. At run time, the road markings in the scene are detected in real time in a variety of traffic situations and under different lighting and weather conditions without relying on any preprocessing steps or predefined models. We achieve reliable qualitative performance on the Oxford RobotCar dataset, and demonstrate quantitatively on the CamVid dataset that exploiting these annotations significantly reduces the required labelling effort and improves performance.


Title: Semantic Labeling of Indoor Environments from 3D RGB Maps
Key Words: data mining  feature extraction  geometry  image classification  image colour analysis  image reconstruction  image sensors  indoor navigation  learning (artificial intelligence)  mobile robots  object detection  object recognition  robot vision  SLAM (robots)  stereo image processing  semantic labels assignment  rooms reconstruction  deep-learning techniques  virtual RGB views  geometric analysis  object detection  scene classification  room types  3D RGB maps  indoor environments  semantic labeling  Semantics  Labeling  Three-dimensional displays  Robots  Training  Task analysis  Solid modeling 
Abstract: We present an approach to automatically assign semantic labels to rooms reconstructed from 3D RGB maps of apartments. Evidence for the room types is generated using state-of-the-art deep-learning techniques for scene classification and object detection based on automatically generated virtual RGB views, as well as from a geometric analysis of the map's 3D structure. The evidence is merged in a conditional random field, using statistics mined from different datasets of indoor environments. We evaluate our approach qualitatively and quantitatively and compare it to related methods.


Title: Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments
Key Words: cameras  distance measurement  feature extraction  image classification  image sensors  learning (artificial intelligence)  mobile robots  motion estimation  object detection  pose estimation  robot vision  SLAM (robots)  stereo image processing  self-supervised distractor learning  robust monocular visual odometry  self-supervised approach  distractors  camera images  cluttered urban environments  per-pixel ephemerality mask  depth map  deep convolutional network  monocular visual odometry pipeline  sparse features  dense photometric matching  metric-scale VO  single camera  robust VO methods  odometry drift  egomotion estimation  moving vehicles  urban traffic  vehicle motion  ephemerality  offline multisession mapping approaches  Three-dimensional displays  Cameras  Robustness  Visual odometry  Motion estimation  Entropy  Training data 
Abstract: We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.


Title: Semantic Mapping with Omnidirectional Vision
Key Words: cameras  distortion  image classification  image fusion  image segmentation  image sensors  mobile robots  path planning  robot vision  SLAM (robots)  omnidirectional vision  omnidirectional images  robust segmentation  occupancy grid maps  inverse sensor model  nonlinear distortions  omnidirectional camera mirror  place category classifier  range-based occupancy grid  dense semantic map  bird eye view  visual semantic mapping framework  robot local free space  Semantics  Sensors  Cameras  Robots  Buildings  Mirrors  Visualization 
Abstract: This paper presents a purely visual semantic mapping framework using omnidirectional images. The approach rests upon the robust segmentation of the robot's local free space, replacing conventional range sensors for the generation of occupancy grid maps. The perceptions are mapped into a bird's eye view allowing an inverse sensor model directly by removing the non-linear distortions of the omnidirectional camera mirror. The system relies on a place category classifier to label the navigation relevant categories: room, corridor, doorway, and open room. Each place class maintains a separated grid map that are fused with the range-based occupancy grid for building a dense semantic map.


Title: Semantic Segmentation from Limited Training Data
Key Words: convolution  image classification  image segmentation  learning (artificial intelligence)  neural nets  object detection  object recognition  recurrent neural nets  robot vision  limited training data  robotic perception  cluttered scenes  shiny surfaces  transparent surfaces  robust perception pipeline  data acquisition  deep metric learning approach  semantic-agnostic boundary detection  pixel-wise voting  fully-supervised semantic segmentation approach  ARC 2017 dataset  Amazon Robotics Challenge 2017  dataset collection  deep convolutional neural networks  Task analysis  Image segmentation  Training  Semantics  Robots  Measurement  Three-dimensional displays 
Abstract: We present our approach for robotic perception in cluttered scenes that led to winning the recent Amazon Robotics Challenge (ARC) 2017. Next to small objects with shiny and transparent surfaces, the biggest challenge of the 2017 competition was the introduction of unseen categories. In contrast to traditional approaches which require large collections of annotated data and many hours of training, the task here was to obtain a robust perception pipeline with only few minutes of data acquisition and training time. To that end, we present two strategies that we explored. One is a deep metric learning approach that works in three separate steps: semantic-agnostic boundary detection, patch classification and pixel-wise voting. The other is a fully-supervised semantic segmentation approach with efficient dataset collection. We conduct an extensive analysis of the two methods on our ARC 2017 dataset. Interestingly, only few examples of each class are sufficient to fine-tune even very deep convolutional neural networks for this specific task.


Title: Planning Ergonomic Sequences of Actions in Human-Robot Interaction
Key Words: ergonomics  human-robot interaction  multi-agent systems  multi-robot systems  path planning  optimization formulation  ergonomic situations  human-robot interaction  human-robot collaboration  motion planning problem  multiagent case  human robot  Ergonomics  Task analysis  Robot kinematics  Planning  Cost function 
Abstract: In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.


Title: Proposal of Collaboration Safety in a Coexistence Environment of Human and Robots
Key Words: Big Data  factory automation  human-robot interaction  industrial robots  Internet of Things  manufacturing systems  production engineering computing  safety  solution-oriented industrial society  high technological capabilities  next-generation manufacturing systems  flexible productivity  human-robot collaboration  robot revolution  collaboration safety  safety level  IoT technology  optimization  big data  progressing digitalization  4th industrial revolution  manufacturing sites  Collaboration  Service robots  Production  Hazards  Optimization  Robot Safety  Industrial Robots  Factory Automation 
Abstract: Whereas various things are connected via networks thanks to IoT technology, and the era of the 4th industrial revolution which realizes optimization and efficiency by utilizing AI and big data is emerging, manufacturing systems are also significantly transforming globally. In addition to the robot revolution, along with progressing digitalization, manufacturing sites in Japan are changing, aiming at establishment of “Connected Industries” that is a solution-oriented industrial society, based on the high technological capabilities. In order to respond timely to diversifying demands of customers, it is necessary to build a next-generation manufacturing systems that realizes flexible and high productivity, such as human-robot collaboration, and it is becoming difficult to respond to the necessity by conventional safety concept. Therefore, in order to realize the 4th industrial revolution, the robot revolution, and “Connected Industries,” it is essential to establish a new safety concept corresponding to the next-generation manufacturing systems to ensure safety. This paper introduces the safety concept to be changed along with the evolution of manufacturing sites, and proposes a new safety concept, which realizes collaboration safety of humans and robots, and an outline of its safety level, for the first time in the world.


Title: A Robust Method to Predict Temporal Aspects of Actions by Observation
Key Words: human-robot interaction  manipulators  robust method  temporal properties  ground truth data  temporal aspec prediction  time-constrained tasks  wiping  table  vegetable chopping  floor cleaning  Task analysis  Frequency modulation  Motion segmentation  Predictive models  Process control 
Abstract: The ability to predict the duration of an activity can enable a robot to plan its behaviors ahead, interact seamlessly with other humans, by coordinating its actions, and allocate effort and resources to tasks that are time-constrained or critical. Despite its usefulness, models that examine the temporal properties of an activity remain relatively unexplored. In the current paper we present, to the best of our knowledge, the first method that can estimate temporal properties of an activity by observation. We evaluate it on three use-cases (i) wiping a table, (ii) chopping vegetables and (iii) cleaning the floor, using ground truth data from real demonstrations, and show that it can make predictions with high accuracy and little training. In addition, we investigate different methods to approximate the progress of each task, and demonstrate how a model can generalize, by reusing part of it in different activities.


Title: Augmented Reality for Feedback in a Shared Control Spraying Task
Key Words: augmented reality  calibration  control engineering computing  feedback  industrial robots  mobile robots  spraying  handheld spraying robot  industrial robots  task awareness  Microsoft Hololens system  motion capture system  augmented reality spraying task  calibration routine  augmented reality interfaces  feedback  logical approach  target regions  shared control methods  shared control spraying task  time 4.0 s  Task analysis  Robots  Spraying  Augmented reality  Calibration  Paints  Headphones 
Abstract: Using industrial robots to spray structures has been investigated extensively, however interesting challenges emerge when using handheld spraying robots. In previous work we have demonstrated the use of shared control of a handheld spraying robot to assist a user in a 3D spraying task. In this paper we demonstrate the use of Augmented Reality Interfaces to increase the user's progress and task awareness. We describe our solutions to challenging calibration issues between the Microsoft Hololens system and a motion capture system without the need for well defined markers or careful alignment on the part of the user. Error relative to the motion capture system was shown to be 10mm after only a 4 second calibration routine. Secondly we outline a logical approach for visualising liquid density for an augmented reality spraying task, this system allows the user to see target regions to complete, areas that are complete and areas that have been overdosed clearly. Finally we produced a user study to investigate the level of assistance that a handheld robot utilising shared control methods should provide during a spraying task. Using a handheld spraying robot with a moving spray head did not aid the user much over simply actuating spray nozzle for them. Compared to manual control the automatic modes significantly reduced the task load experienced by the user and significantly increased the quality of the result of the spraying task, reducing the error by 33-45%.


Title: Interactive Robot Knowledge Patching Using Augmented Reality
Key Words: augmented reality  data visualisation  decision making  human-robot interaction  knowledge representation  learning (artificial intelligence)  robot programming  Augmented Reality  Temporal And-Or graph  robot program  interactive robot teaching  AR interface  knowledge representation  comprehensive visualizations  decision making process  Microsoft HoloLens  interactive robot knowledge patching  Task analysis  Decision making  Knowledge representation  Visualization  Robot sensing systems  Grammar 
Abstract: We present a novel Augmented Reality (AR) approach, through Microsoft HoloLens, to address the challenging problems of diagnosing, teaching, and patching interpretable knowledge of a robot. A Temporal And-Or graph (T-AOG) of opening bottles is learned from human demonstration and programmed to the robot. This representation yields a hierarchical structure that captures the compositional nature of the given task, which is highly interpretable for the users. By visualizing the knowledge structure represented by a T-AOG and the decision making process by parsing the T-AOG, the user can intuitively understand what the robot knows, supervise the robot's action planner, and monitor visually latent robot states (e.g., the force exerted during interactions). Given a new task, through such comprehensive visualizations of robot's inner functioning, users can quickly identify the reasons of failures, interactively teach the robot with a new action, and patch it to the current knowledge structure. In this way, the robot is capable of solving similar but new tasks only through minor modifications provided by the users interactively. This process demonstrates the interpretability of our knowledge representation and the effectiveness of the AR interface.


Title: Using Constrained Optimization for Real-Time Synchronization of Verbal and Nonverbal Robot Behavior
Key Words: computer animation  humanoid robots  image motion analysis  mobile robots  motion control  optimisation  robot vision  constrained optimization  real-time synchronization  motion re-targeting techniques  virtual character animation research  joint angular velocities  robot motion  re-targeted motion sequences  humanoid robot  joint motion trajectories  verbal behavior synchronization  nonverbal behavior synchronization  verbal robot behavior  nonverbal robot behavior  Optimization  Trajectory  Angular velocity  Synchronization  Dynamics  Robot motion 
Abstract: Most of the motion re-targeting techniques are grounded on virtual character animation research, which means that they typically assume that the target embodiment has unconstrained joint angular velocities. However, because robots often do have such constraints, traditional re-targeting approaches can originate irregular delays in the robot motion. With the goal of ensuring synchronization between verbal and nonverbal behavior, this paper proposes an optimization framework for processing re-targeted motion sequences that addresses constraints such as joint angle and angular velocities. The proposed framework was evaluated on a humanoid robot using both objective and subjective metrics. While the analysis of the joint motion trajectories provides evidence that our framework successfully performs the desired modifications to ensure verbal and nonverbal behavior synchronization, results from a perceptual study showed that participants found the robot motion generated by our method more natural, elegant and lifelike than a control condition.


Title: Learning Task-Based Instructional Policy for Excavator-Like Robots
Key Words: excavators  learning by example  mobile robots  learning from demonstration  demonstration trajectories automatic segmentation  hydraulic actuated scaled excavator robot  complex truck loading task  nongeneric policy model  mapping continuous state action trajectories  expert demonstration  task-based instructional policy  Task analysis  Robots  Trajectory  Hidden Markov models  Load modeling  Actuators  Loading 
Abstract: We explore beyond existing work in learning from demonstration by asking the question: “Can robots learn to guide?”, that is, can a robot autonomously learn an instructional policy from expert demonstration and use it to instruct humans in executing complex task? As a solution, we propose learning of instructional policy (πI) that maps the state to an instruction for a human. To learn πI, we define action primitives that addresses the challenge of mapping continuous state action trajectories to human parse-able instructions. Action primitives are demonstrated to be very effective in automatic segmentation of demonstration trajectories into fewer repetitive and reusable segments, and a highly scalable approach in comparison to the existing state-of-the art. Finally, we construct a non-generic policy model as a generative model for instructional policies to generate instruction for an entire task. With few modifications, the proposed model is demonstrated to perform autonomous execution of complex truck loading task on hydraulic actuated scaled excavator robot. Guidance approach is tested based on a controlled group study involving 75 participants, who learn to perform the same task.


Title: Playdough to Roombots: Towards a Novel Tangible User Interface for Self-reconfigurable Modular Robots
Key Words: control engineering computing  furniture  mobile robots  robot dynamics  user interfaces  self-reconfigurable modular robots  shape-shift  self-reconfigurable furniture  intuitive user interface  tangible user interface  Roombots shape  3D shape scanning  SRMR system  Shape  Three-dimensional displays  User interfaces  Solid modeling  Robots  Planning  Buildings  tangible user interface  self-reconfigurable modular robots  deformable material  shape formation 
Abstract: One of the main strengths of self-reconfigurable modular robots (SRMR) is their ability to shape-shift and dynamically change their morphology. In the case of our SRMR system “Roombots”, these shapes can be quite arbitrary for a great variety of tasks while the major utility is envisioned to be self-reconfigurable furniture. As such, the ideas and inspirations from users quickly need to be translated into the final Roombots shape. This involves a multitude of separate processes and - most importantly - requires an intuitive user interface. Our current approach led to the development of a tangible user interface (TUI) which involves 3D-scanning of a shape formed by modeling clay and the necessary steps to prepare the digitized model to be formed by Roombots. The system is able to generate a solution in less than two minutes for our target use as demonstrated with various examples.


Title: 3D Human Pose Estimation in RGBD Images for Robotic Task Learning
Key Words: image colour analysis  image sensors  learning (artificial intelligence)  pose estimation  service robots  monocular 3D pose estimation  service robot  color images  robust human keypoint detectors  robotic task learning  RGBD images  3D human pose estimation  human teacher  PR2 robot  Three-dimensional displays  Two dimensional displays  Color  Pose estimation  Robot sensing systems  Task analysis 
Abstract: We propose an approach to estimate 3D human pose in real world units from a single RGBD image and show that it exceeds performance of monocular 3D pose estimation approaches from color as well as pose estimation exclusively from depth. Our approach builds on robust human keypoint detectors for color images and incorporates depth for lifting into 3D. We combine the system with our learning from demonstration framework to instruct a service robot without the need of markers. Experiments in real world settings demonstrate that our approach enables a PR2 robot to imitate manipulation actions observed from a human teacher.


Title: Safe and Efficient Human-Robot Collaboration Part I: Estimation of Human Arm Motions
Key Words: human-robot interaction  manipulator dynamics  motion control  path planning  human arm motions  fenceless robot cells  safety requirements  robot motions  control-oriented dynamic model  human-robot collaboration  cycle times  admissible path velocity  Collision avoidance  Manipulators  Kinematics  Collaboration  Safety  Task analysis 
Abstract: A significant barrier regarding a successful implementation of fenceless robot cells into manufacturing areas with humans is given by the inefficiency due to safety requirements. Robot motions have to be slowed down so that an unexpected collision with a human does not result in human injuries. This velocity reduction leads to longer cycle times and, hence, fenceless robot cells turn out as uneconomic. In this paper, a new approach for human-robot collaboration in assembly tasks is presented. For a better performance of the robot, methods are investigated on how the robot can exploit a maximum performance while maintaining the safety of collaborating humans. For this purpose, the kinematics and dynamics of a human arm are described by a control-oriented dynamic model to determine its capability and reachability. Successful experiments validate the dynamic model as well as a corresponding projection approach for calculating possible movements of the human arm that may lead to a collision with the robot. Finally, this information is used to calculate an admissible path velocity that minimizes the danger of human injuries.


Title: Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications
Key Words: graphics processing units  human computer interaction  mobile robots  object detection  robot vision  stereo image processing  mobile robotics  3D sensor types  indoor applications  outdoor applications  outdoor scenarios  indoor scenarios  smaller robotic systems  single CPU thread  multiple CPU cores  human interaction  robotic applications  robust person detection  robust real-time 3D person detection  Three-dimensional displays  Robot sensing systems  Feature extraction  Visualization  Pipelines  Real-time systems 
Abstract: Fast and robust person detection is one of the most important tasks for robotic applications involving human interaction. Particularly in mobile robotics this task is still challenging. Though there are already reliable and real-time capable approaches, they are usually computationally expensive. They either require GPUs or multiple CPU cores in order to work properly. Furthermore, some of the approaches are designed for special environments and sensor types, which reduces general applicability. In this work, we present a robust, generic and lightweight solution for real-time 3D person detection. Since our approach requires only a single CPU thread, it can be run as a background process and is suitable for smaller robotic systems. We demonstrate applicability to indoor and outdoor scenarios using different 3D sensor types separately. Moreover, we are able to show that the proposed method outperforms other state-of-the-art approaches, including a DCNN.


Title: Eye on You: Fusing Gesture Data from Depth Camera and Inertial Sensors for Person Identification
Key Words: biometrics (access control)  cameras  gesture recognition  image fusion  EOY  asynchronous timing  coordinate calibration  environmental constraints  IoT applications  person identification  gesture data  fusion algorithms  inertial measurement unit  wearable sensors  3D depth camera  data fusion approach  Eye On You  remote PID  reliable PID  recognition rate  Skeleton  Cameras  Sensors  Correlation  Iris recognition  Feature extraction  Motion segmentation 
Abstract: Person identification (PID) is a key issue in many IoT applications. It has long been studied and achieved by technologies such as RFID and face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition rates highly depend on use scenarios. To enable reliable and remote PID, in this work, we present EOY (Eye On You)1, a data fusion approach that combines two kinds of sensors, a 3D depth camera and wearable sensors embedded with inertial measurement unit (IMU). Since these two kinds of data share common features, we are able to fuse them to conduct PID. Further, the result can be transferred to a mobile platform (such as robot) since we have less constraints on devices. To realize EOY, we develop fusion algorithms to address practical challenges, such as asynchronous timing and coordinate calibration. The experimental evaluation shows that EOY can achieve the recognition rate of 95% and is very robust even in crowded areas.


Title: Human Motion Capture Using a Drone
Key Words: calibration  cameras  image motion analysis  image reconstruction  image sensors  mobile robots  robot vision  motion capture systems  calibrated cameras  indoor environments  on-board RGB camera  autonomously flying drone  3D human MoCap  drone-based system  human motion capture  consumer drone  motion reconstruction  reconstruction algorithm  Cameras  Drones  Two dimensional displays  Three-dimensional displays  Image reconstruction  Tracking  Joints 
Abstract: Current motion capture (MoCap) systems generally require markers and multiple calibrated cameras, which can be used only in constrained environments. In this work we introduce a drone-based system for 3D human MoCap. The system only needs an autonomously flying drone with an on-board RGB camera and is usable in various indoor and outdoor environments. A reconstruction algorithm is developed to recover full-body motion from the video recorded by the drone. We argue that, besides the capability of tracking a moving subject, a flying drone also provides fast varying viewpoints, which is beneficial for motion reconstruction. We evaluate the accuracy of the proposed system using our new DroCap dataset and also demonstrate its applicability for MoCap in the wild using a consumer drone.


Title: Navigating Occluded Intersections with Autonomous Vehicles Using Deep Reinforcement Learning
Key Words: learning systems  mobile robots  navigation  path planning  road vehicles  autonomous vehicles  unsignaled intersections  Deep RL  intersection handling problem  deep reinforcement learning system  occluded intersections  active sensing behaviors  Autonomous vehicles  Automobiles  Machine learning  Safety  Navigation  Learning (artificial intelligence) 
Abstract: Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of Deep Reinforcement Learning to handle intersection problems. Using recent advances in Deep RL, we are able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. We then explore a system's ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. Our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule-based methods, and the failures of our current deep reinforcement learning system point to future research directions.


Title: Autonomous Vehicle Navigation in Rural Environments Without Detailed Prior Maps
Key Words: collision avoidance  least squares approximations  mobile robots  recursive filters  robot vision  sensors  prior maps  positive societal impact  autonomous vehicle navigating  recursive filtering approach  navigate road networks  least-squares residual approach  vehicle frame  sensor-based perception system  global navigation  sparse topological maps  mapless driving framework  autonomous navigation  autonomous driving technology  transmit detailed maps  urban areas  rural environments  autonomous vehicle navigation  Roads  Navigation  Autonomous vehicles  Trajectory  Robot sensing systems  Reliability 
Abstract: State-of-the-art autonomous driving systems rely heavily on detailed and highly accurate prior maps. However, outside of small urban areas, it is very challenging to build, store, and transmit detailed maps since the spatial scales are so large. Furthermore, maintaining detailed maps of large rural areas can be impracticable due to the rapid rate at which these environments can change. This is a significant limitation for the widespread applicability of autonomous driving technology, which has the potential for an incredibly positive societal impact. In this paper, we address the problem of autonomous navigation in rural environments through a novel mapless driving framework that combines sparse topological maps for global navigation with a sensor-based perception system for local navigation. First, a local navigation goal within the sensor view of the vehicle is chosen as a waypoint leading towards the global goal. Next, the local perception system generates a feasible trajectory in the vehicle frame to reach the waypoint while abiding by the rules of the road for the segment being traversed. These trajectories are updated to remain in the local frame using the vehicle's odometry and the associated uncertainty based on the least-squares residual and a recursive filtering approach, which allows the vehicle to navigate road networks reliably, and at high speed, without detailed prior maps. We demonstrate the performance of the system on a full-scale autonomous vehicle navigating in a challenging rural environment and benchmark the system on a large amount of collected data.


Title: Design of an Autonomous Racecar: Perception, State Estimation and System Integration
Key Words: mobile robots  road vehicles  state estimation  modular redundant sub-systems  lateral accelerations  longitudinal accelerations  flüela driverless  onboard sensing  Formula Student Driverless competition  system integration  autonomous racecar  Automobiles  State estimation  Robot sensing systems  Current measurement  Laser radar  Wheels  Global Positioning System 
Abstract: This paper introduces jlüela driverless: the first autonomous racecar to win a Formula Student Driverless competition. In this competition, among other challenges, an autonomous racecar is tasked to complete 10 laps of a previously unknown racetrack as fast as possible and using only onboard sensing and computing. The key components of flüela's design are its modular redundant sub-systems that allow robust performance despite challenging perceptual conditions or partial system failures. The paper presents the integration of key components of our autonomous racecar, i.e., system design, EKF-based state estimation, LiDAR-based perception, and particle filter-based SLAM. We perform an extensive experimental evaluation on real-world data, demonstrating the system's effectiveness by outperforming the next-best ranking team by almost half the time required to finish a lap. The autonomous racecar reaches lateral and longitudinal accelerations comparable to those achieved by experienced human drivers.


Title: Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling
Key Words: Bayes methods  convolution  feedforward neural nets  filtering theory  intelligent transportation systems  mobile robots  Monte Carlo methods  road traffic  time series  traffic engineering computing  unsupervised learning  complex interactions  dynamic occupancy grid prediction  urban autonomous driving  deep learning approach  long-term situation prediction  intelligent vehicles  complex downtown scenarios  multiple road users  motor vehicles  Bayesian filtering technique  environment representation  machine learning  deep convolutional neural network  spatially distributed velocity estimates  raw data sequence  input time series  multiple sensors  convolutional neural networks  road user interaction  pixel-wise balancing  static cells  dynamic cells  unsupervised learning character  pedestrians  bikes  distributed velocity estimation  Monte-Carlo simulation  Vehicle dynamics  Machine learning  Sensor fusion  Roads  Time series analysis  Laser radar 
Abstract: Long-term situation prediction plays a crucial role for intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation. Experiments show the ability to model complex interactions.


Title: Scalable Decision Making with Sensor Occlusions for Autonomous Driving
Key Words: collision avoidance  decision making  Markov processes  mobile robots  optimisation  path planning  road safety  road vehicles  road users  scalable decision making  sensor occlusions  POMDP solution techniques  optimal avoidance strategy  decomposition method  computational cost  partially observable Markov decision process  robust navigation  autonomous driving  Automobiles  Uncertainty  Roads  Acceleration  Autonomous vehicles  Approximation algorithms  Robot sensing systems 
Abstract: Autonomous driving in urban areas requires avoiding other road users with only partial observability of the environment. Observations are only partial because obstacles can occlude the field of view of the sensors. The problem of robust and efficient navigation under uncertainty can be framed as a partially observable Markov decision process (POMDP). In order to bypass the computational cost of scaling the formulation to avoiding multiple road users, this paper demonstrates a decomposition method that leverages the optimal avoidance strategy for a single user. We evaluate the performance of two POMDP solution techniques augmented with the decomposition method for scenarios involving a pedestrian crosswalk and an intersection.


Title: Situation Assessment for Planning Lane Changes: Combining Recurrent Models and Prediction
Key Words: automobiles  driver information systems  intelligent transportation systems  learning (artificial intelligence)  mobile robots  prediction theory  recurrent neural nets  road safety  road traffic  road traffic control  fully autonomous cars  complex scenes  dynamic scenes  car following scenarios  situation assessment algorithm  lane changing  recurrent models  driver-assistance systems  bidirectional recurrent neural network  intelligent driver model  lane changes planning  maneuvers planning  driving situations classification  deep learning architecture  long short-term memory units  Automobiles  Planning  Machine learning  Predictive models  Prediction algorithms  Autonomous automobiles 
Abstract: One of the greatest challenges towards fully autonomous cars is the understanding of complex and dynamic scenes. Such understanding is needed for planning of maneuvers, especially those that are particularly frequent such as lane changes. While in recent years advanced driver-assistance systems have made driving safer and more comfortable, these have mostly focused on car following scenarios, and less on maneuvers involving lane changes. In this work we propose a situation assessment algorithm for classifying driving situations with respect to their suitability for lane changing. For this, we propose a deep learning architecture based on a Bidirectional Recurrent Neural Network, which uses Long Short-Term Memory units, and integrates a prediction component in the form of the Intelligent Driver Model. We prove the feasibility of our algorithm on the publicly available NGSIM datasets, where we outperform existing methods.


Title: Design and Analysis of a Novel Underwater Glider - RoBuoy
Key Words: autonomous underwater vehicles  design engineering  mathematical analysis  mechatronics  mobile robots  oceanographic equipment  variable buoyancy method  autonomous underwater vehicles  underwater robots  mechatronic system  underwater gliders RoBuoy  metallic bellows  integrated mathematical model  wings  open loop performance  power efficient  actuated metallic bellows  parts fouling  optimized dimensions  Actuators  Buoyancy  Bellows  Surges  Pistons  Unmanned underwater vehicles  Prototypes 
Abstract: Underwater gliders are special class of autonomous underwater vehicles (AUVs) proven to be power efficient with better range and endurance compared to the conventional underwater robots. Most of the existing underwater gliders use `change of mass' based variable buoyancy (VB) method in which the overall system architecture and construction are complex. A novel underwater glider RoBuoy based on the `change of volume' concept of variable buoyancy method is presented here. RoBuoy uses actuated metallic bellows to change the volume which makes the system simple and modular in construction without any compromise in the performance. It uses minimal number of parts compared to the existing gliders which reduces the overall complexity of the system. Also, most of the conventional gliders use the external fluid for its working which may result in corrosion or fouling of parts and requires frequent maintenance. In the proposed glider, all the vital parts required for its working, apart from the sensing payloads are enclosed inside the hull, thereby increasing the durability. In this paper, a detailed design of RoBuoy is discussed with its possible modes of operation. An integrated mathematical model considering the individual dynamics of the actuator, hull/fuselage, and the wings has been developed and the open loop performance of the glider is studied at different input conditions. An experimental prototype has been designed and fabricated based on optimized dimensions, with the required mechatronic system. Experiments have been conducted and the results prove the feasibility of the concept.


Title: Modeling Speed-, Load-, and Position-Dependent Friction Effects in Strain Wave Gears
Key Words: force control  friction  gears  industrial robots  position control  velocity control  strain wave gears  robotic joint  position-dependent friction effects  industrial robots  load-dependent friction effects  sensorless force control  speed-dependent friction effects  Friction  Load modeling  Torque  Gravity  Strain  Gears  Robots 
Abstract: Strain wave gears are frequently used in small and medium size industrial robots. In order to describe and quantify friction effects in gearboxes of such type, a structurally simple, yet powerful model is proposed taking into account both speed-and load-dependent friction effects. Moreover, position-dependent disturbances in a robotic joint are considered. An identification procedure is presented that allows to separate the individual components of the model and identify them subsequently. The effectiveness of the model and identification procedure is validated using experimental data gathered from four different robotic joints of varying size. Furthermore, the benefits of improved friction modeling are shown by means of different applications, including smooth lead-through programming and sensorless force control.


Title: Real-Time Identification of Robot Payload Using a Multirate Quaternion-Based Kalman Filter and Recursive Total Least-Squares
Key Words: end effectors  industrial manipulators  Kalman filters  least squares approximations  recursive estimation  robot kinematics  least-squares process  multirate quaternion-based Kalman filter  recursive total least-squares  inertial parameters  rigid load  robot kinematics  inertial sensors  robot payload real-time identification  end-effector  industrial manipulator  Kalman filters  Quaternions  Robot kinematics  Service robots  Robot sensing systems  Estimation 
Abstract: The paper describes an estimation and identification procedure that allows to reconstruct the inertial parameters of a rigid load attached to the end-effector of an industrial manipulator. In particular, the proposed method adopts a multirate quaternion-based Kalman filter, fusing measurements obtained from robot kinematics and inertial sensors at possibly different sampling frequencies, to estimate linear accelerations and angular velocities/accelerations of the load. Then, a recursive total least-squares (RTLS) process is executed to identify the load parameters. Both steps of the estimation and identification procedure are performed in real-time, without the need for offline post-processing of measured data.


Title: Optimal Active Sensing with Process and Measurement Noise
Key Words: covariance matrices  eigenvalues and eigenfunctions  gradient methods  Kalman filters  mobile robots  noise measurement  nonlinear filters  observability  optimisation  path planning  Riccati equations  trajectory control  estimation algorithm  OG  nonnegligible process noise  largest eigenvalue  optimal active sensing  measurement noise  nonlinear differentially flat system  online gradient descent method  optimal trajectories  maximum estimation uncertainty  Kalman Filter  onboard sensors  observability gramian  inversely proportional  posteriori covariance matrix  continuous Riccati equation  unicycle robot  Robot sensing systems  Estimation  Trajectory  Eigenvalues and eigenfunctions  Observability 
Abstract: The goal of this paper is to increase the estimation performance of an Extended Kalman Filter for a nonlinear differentially flat system by planning trajectories able to maximize the amount of information gathered by onboard sensors in presence of both process and measurement noises. In a previous work, we presented an online gradient descent method for planning optimal trajectories along which the smallest eigenvalue of the Observability Gramian (OG) is maximized. As the smallest eigenvalue of the OG is inversely proportional to the maximum estimation uncertainty, its maximization reduces the maximum estimation uncertainty of any estimation algorithm employed during motion. However, the OG does not consider the process noise that, instead, in several applications is far from being negligible. For this reason, this paper proposes a novel solution able to cope with non-negligible process noise: this is achieved by minimizing the largest eigenvalue of the a posteriori covariance matrix obtained by solving the Continuous Riccati Equation as a measure of the total available information. This minimization is expected to maximize the information gathered by the outputs while, at the same time, limiting as much as possible the negative effects of the process noise. We apply our method to a unicycle robot. The comparison between the novel method and the one of our previous work (which did not consider process noise) shows significant improvements in the obtained estimation accuracy.


Title: Encoderless Gimbal Calibration of Dynamic Multi-Camera Clusters
Key Words: angular measurement  calibration  cameras  encoderless gimbal calibration  dynamic multiCamera Clusters  Dynamic Camera Clusters  multicamera systems  cameras  joint angle measurements  time-varying transformation  static camera  motor encoders  transformation chain  encoderless gimbal mechanism  online estimation  Cameras  Calibration  Robot vision systems  Estimation  Reluctance motors  Kinematics  Vehicle dynamics 
Abstract: Dynamic Camera Clusters (DCCs) are multi-camera systems where one or more cameras are mounted on actuated mechanisms such as a gimbal. Existing methods for DCC calibration rely on joint angle measurements to resolve the time-varying transformation between the dynamic and static camera. This information is usually provided by motor encoders, however, joint angle measurements are not always readily available on off-the-shelf mechanisms. In this paper, we present an encoderless approach for DCC calibration which simultaneously estimates the kinematic parameters of the transformation chain as well as the unknown joint angles. We also demonstrate the integration of an encoderless gimbal mechanism with a state-of-the art VIO algorithm, and show the extensions required in order to perform simultaneous online estimation of the joint angles and vehicle localization state. The proposed calibration approach is validated both in simulation and on a physical DCC composed of a 2-DOF gimbal mounted on a UAV. Finally, we show the experimental results of the calibrated mechanism integrated into the OKVIS VIO package, and demonstrate successful online joint angle estimation while maintaining localization accuracy that is comparable to a standard static multi-camera configuration.


Title: Stickman: Towards a Human Scale Acrobatic Robot
Key Words: humanoid robots  laser ranging  mobile robots  motion control  pendulums  gravity-driven pendulum launch  two degree of freedom robot  autonomous robot  mobile robot  acrobatic techniques  acrobatic capability  laser range-finder  somersaulting stunts  gymnastic arts  human scale acrobatic robot  stickman  Robot sensing systems  Angular velocity  Mathematical model  Aerodynamics 
Abstract: Human performers have developed impressive acrobatic techniques over thousands of years of practicing the gymnastic arts. At the same time, robots have started to become more mobile and autonomous, and can begin to imitate these stunts in dramatic and informative ways. We present a simple two degree of freedom robot that uses a gravity-driven pendulum launch and produces a variety of somersaulting stunts. The robot uses an IMU and a laser range-finder to estimate its state mid-flight and actuates to change its motion both on and and off the pendulum. We discuss the dynamics of this behavior in a framework of acrobatic capability and present experimental results.


Title: 3D Lidar-IMU Calibration Based on Upsampled Preintegrated Measurements for Motion Distortion Correction
Key Words: calibration  cameras  image motion analysis  optical radar  optimisation  probability  sampling methods  stereo image processing  interpolated inertial measurements  lidar scan  lidar point-to-plane distances  upsampled preintegrated measurements  motion distortion correction  probabilistic framework  lidar-IMU sensing system  motion distortion  on-manifold optimisation  3D lidar-IMU calibration  Laser radar  Calibration  Distortion  Robot sensing systems  Three-dimensional displays  Distortion measurement  Motion measurement 
Abstract: In this paper, we present a probabilistic framework to recover the extrinsic calibration parameters of a lidar-IMU sensing system. Unlike global-shutter cameras, lidars do not take single snapshots of the environment. Instead, lidars collect a succession of 3D-points generally grouped in scans. If these points are assumed to be expressed in a common frame, this becomes an issue when the sensor moves rapidly in the environment causing motion distortion. The fundamental idea of our proposed framework is to use preintegration over interpolated inertial measurements to characterise the motion distortion in each lidar scan. Moreover, by using a set of planes as a calibration target, the proposed method makes use of lidar point-to-plane distances to jointly calibrate and localise the system using on-manifold optimisation. The calibration does not rely on a predefined target as arbitrary planes are detected and modelled in the first lidar scan. Simulated and real data are used to show the effectiveness of the proposed method.


Title: Sampled-Point Network for Classification of Deformed Building Element Point Clouds
Key Words: disasters  feature extraction  image classification  learning (artificial intelligence)  object recognition  robot vision  object recognition  post-disaster urban areas  search-and-rescue robots  deformed building element point clouds  point network  synthetically-deformed object datasets  point sorting  point coordinates  classification network  deformed building elements  3D class recognition  point cloud input  disaster relief operations  potentially-deformed objects  unstructured environments  point cloud data  3D point cloud  physical site information  Three-dimensional displays  Strain  Object recognition  Deformable models  Machine learning  Feature extraction  Buildings 
Abstract: Search-and-rescue (SAR) robots operating in post-disaster urban areas need to accurately identify physical site information to perform navigation, mapping and manipulation tasks. This can be achieved by acquiring a 3D point cloud of the environment and performing object recognition from the point cloud data. However, this task is complicated by the unstructured environments and potentially-deformed objects encountered during disaster relief operations. Current 3D object recognition methods rely on point cloud input acquired under suitable conditions and do not consider deformations such as outlier noise, bending and truncation. This work introduces a deep learning architecture for 3D class recognition from point clouds of deformed building elements. The classification network, consisting of stacked convolution and average pooling layers applied directly to point coordinates, was trained using point clouds sampled from a database of mesh models. The proposed method achieves robustness to input variability using point sorting, resampling, and rotation normalization techniques. Experimental results on synthetically-deformed object datasets show that the proposed method outperforms the conventional deep learning methods in terms of classification accuracy and computational efficiency.


Title: Recognizing Objects in-the-Wild: Where do we Stand?
Key Words: cameras  image classification  image colour analysis  image representation  learning (artificial intelligence)  mobile robots  neural nets  object recognition  robot vision  multiview object dataset  RGB-D camera  deep convolutional networks  Web images  robotic system  autonomous agents  good visual perceptual systems  robotic vision research communities  human-populated environments  robot vision  real-life robotic data  object classification  deep representations  object recognition algorithms  real-life application  mobile robot  Task analysis  Clutter  Visualization  Mobile robots  Cameras  Robot vision systems 
Abstract: The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for realworld applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance.


Title: A Controlled-Delay Event Camera Framework for On-Line Robotics
Key Words: cameras  humanoid robots  image sensors  mobile robots  robot vision  controlled-delay event camera framework  dynamic robotics  low latency response  high dynamic range  inherent compression  visual signal  real-time performance  off-line datasets  camera resolution  latency-free operation  event-driven framework  iCub robot  algorithm processing rate  actual event-rate  algorithm performance  Cameras  Robot vision systems  Delays  Corner detection  Visualization 
Abstract: Event cameras offer many advantages for dynamic robotics due to their low latency response to motion, high dynamic range, and inherent compression of the visual signal. Many algorithms easily achieve real-time performance when testing on off-line datasets, however with an increase in camera resolution and applications on fast-moving robots, latency-free operation is not guaranteed. The event-rate is not constant, but is proportional to the amount of movement in the scene, or the velocity of the camera itself. Recently, algorithms have instead reported a maximum event-rate that can be achieved in real-time. In this paper we present the event-driven framework used on the iCub robot, which closes the loop between algorithm processing rate and the actual event-rate of the camera in order to smoothly control and limit the latency, while allowing the algorithm to degrade gracefully when large bursts of events occur. We show two algorithms that process events differently from each other and demonstrate the trade-off between latency and algorithm performance that the framework provides.


Title: Where can i do this? Geometric Affordances from a Single Example with the Interaction Tensor
Key Words: computational geometry  feature extraction  image capture  image colour analysis  image representation  tensors  geometric affordance  interaction tensor  tensor field representation  bisector surface representation  surface points  directional vectors  cognitive robots  autonomous robots  RGB-D sensors  Tensile stress  Robots  Three-dimensional displays  Solid modeling  Task analysis  Shape  Tools 
Abstract: This paper introduces and evaluates a new tensor field representation to express the geometric affordance of one object relative to another, a key competence for Cognitive and Autonomous robots. We expand the bisector surface representation to one that is weight-driven and that retains the provenance of surface points with directional vectors. We also incorporate the notion of affordance keypoints which allow for faster decisions at a point of query and with a compact and straightforward descriptor. Using a single interaction example, we are able to generalize to previously-unseen scenarios; both synthetic and also real scenes captured with RGB-D sensors. Evaluations also include crowdsourcing comparisons that confirm the validity of our affordance proposals, which agree on average 84 % of the time with human judgments, that is 20-40 % better than the baseline methods.


Title: A Low-Cost Navigation Strategy for Yield Estimation in Vineyards
Key Words: agriculture  image colour analysis  image resolution  object detection  yield estimation  grape varieties  vineyard management  low-cost navigation strategy  navigation algorithm  grape pictures  low-cost autonomous system  RGB camera  RGB image processing  Navigation  Pipelines  Yield estimation  Cameras  Robot vision systems  Lasers 
Abstract: Accurate yield estimation is very important for improving the vineyard management, the quality of the grapes and the health of the vines. The most common systems use RGB image processing for achieving a good estimation. In order to collect images, robots or farming vehicles can be equipped with a RGB camera. In this paper, we propose a low-cost autonomous system which can navigate through a vineyard while collecting grape pictures in order to provide a yield estimation. Our system uses only a laser scanner to detect the row and follows it until its end, then it navigates towards the next one, exploiting the knowledge of the vineyard. The navigation algorithm was tested both in simulation and in a real environment with good results. Furthermore, a yield estimation of two different grape varieties is presented.


Title: Object Detection for Cattle Gait Tracking
Key Words: convolution  dairy products  dairying  feature extraction  feedforward neural nets  gait analysis  image sampling  object detection  veterinary medicine  kinematic gait features  object detection  cattle gait tracking  health issue  locomotion score  widespread commercial adoption  sensor configuration  flight sensors  rotary milking dairy  lameness detection systems  cattle kinematics  CNN  cartesian space  Cows  Feature extraction  Kinematics  Laser radar  Robot sensing systems  Three-dimensional displays  Australia 
Abstract: Lameness in cattle is a health issue where gait is modified to minimise pain. Cattle are currently visually assessed for locomotion score, which provides the degree of lameness for individual animals. This subjective method is costly in terms of labour, and its level of accuracy and ability to detect small changes in locomotion that is critical for early detection of lameness and associated intervention. Current automatic lameness detection systems found in literature have not yet met the ultimate goal of widespread commercial adoption. We present a sensor configuration to record cattle kinematics towards automatic lameness detection. This configuration features four Time of Flight sensors to view cattle from above and from one side as they exit an automatic rotary milking dairy. Two dimensional near infrared images sampled from 223 cows passing through the system were used to train a Faster R-CNN to detect hooves (F1-score = 0.90) and carpal/tarsal joints (Fl-score = 0.85). The depth images were used to project these detected key points into Cartesian space where they were tracked to obtain individual trajectories per limb. The results show that kinematic gait features can be successfully obtained as a first and important step towards objective, accurate, automatic lameness detection.


Title: Routing Algorithms for Robot Assisted Precision Irrigation
Key Words: computational complexity  graph theory  greedy algorithms  irrigation  mobile robots  orienteering problem  NP-hard  routing algorithms  robot assisted precision irrigation  temporal budget  possible motions  spatially distributed sites  battery charge  optimization problem  irrigation adjustments  robots navigate  commercial vineyard  Irrigation  Routing  Approximation algorithms  Robot sensing systems  Navigation 
Abstract: When robots navigate through vineyards to perform irrigation adjustments, an optimization problem emerges whereby robots are tasked with performing adjustments having the highest cumulative outcome within a given temporal budget due to limited battery charge. To this end, the robot needs to reach a set of spatially distributed sites, and the specific structure of the vineyard imposes various constraints on possible motions. In this paper we first demonstrate that this type of orienteering problem remains NP-hard even for the restricted class of graphs associated with precision irrigation. Then, we devise and analyze two greedy heuristics informed by the problem we consider. Finally, these algorithms are evaluated on settings associated with a commercial vineyard and we show that our methods favorably compare to solutions proposed in the past.


Title: Real-Time Semantic Segmentation of Crop and Weed for Precision Agriculture Robots Leveraging Background Knowledge in CNNs
Key Words: agricultural machinery  agrochemicals  convolution  crops  feedforward neural nets  image colour analysis  image segmentation  industrial robots  robot vision  precision agriculture robots leveraging background knowledge  precision farming robots  CNN-based semantic segmentation  crop fields  sugar beet plants  RGB data  vegetation indexes  real-time semantic segmentation  trigger weeding actions  agricultural robot operator  Agriculture  Vegetation mapping  Semantics  Real-time systems  Soil  Indexes  Task analysis 
Abstract: Precision farming robots, which target to reduce the amount of herbicides that need to be brought out in the fields, must have the ability to identify crops and weeds in real time to trigger weeding actions. In this paper, we address the problem of CNN-based semantic segmentation of crop fields separating sugar beet plants, weeds, and background solely based on RGB data. We propose a CNN that exploits existing vegetation indexes and provides a classification in real time. Furthermore, it can be effectively re-trained to so far unseen fields with a comparably small amount of training data. We implemented and thoroughly evaluated our system on a real agricultural robot operating in different fields in Germany and Switzerland. The results show that our system generalizes well, can operate at around 20 Hz, and is suitable for online operation in the fields.


Title: Robustly Adjusting Indoor Drip Irrigation Emitters with the Toyota HSR Robot
Key Words: computer vision  grippers  irrigation  manipulators  mobile robots  computer vision  build-in hand camera  modular Emitter Localization Device  lightweight Emitter Localization Device  Toyota HSR mobile manipulator robot  commercial buildings  indoor plants  Toyota HSR robot  indoor drip irrigation emitters  emitter axis  gripper axis  Cameras  Irrigation  Robot vision systems  Manipulators  Grippers 
Abstract: Indoor plants in homes and commercial buildings such as malls, offices, airports, and hotels, can benefit from precision irrigation to maintain healthy growth and reduce water consumption. As active valves are too costly, and ongoing precise manual adjustment of drip emitters is impractical, we explore how the Toyota HSR mobile manipulator robot can autonomously adjust low-cost passive emitters. To provide sufficient accuracy for gripper alignment, we designed a lightweight, modular Emitter Localization Device (ELD) with cameras and LEDs that can be non-invasively mounted on the arm. This paper presents details of the design, algorithms, and experiments with adjusting emitters using a two-phase procedure: (1) aligning the robot base using the build-in hand camera, and (2) aligning the gripper axis with the emitter axis using the ELD. We report success rates and sensitivity analysis to tune computer vision parameters and joint motor gains. Experiments suggest that emitters can be adjusted with 95 % success rate in approximately 20 seconds.


Title: Preliminary Study of Twisted String Actuation Through a Conduit Toward Soft and Wearable Actuation
Key Words: actuators  cables (mechanical)  friction  lubrication  mobile robots  wearable robots  twisted string actuation  conduit  wearable actuation  TSAs  modern engineering  robotic applications  conventional cable sliding transmission  lubricated twisting  friction  mobile robots  Friction  Force  Mathematical model  Cable shielding  DC motors  Power cables  Robots 
Abstract: Twisted string actuators (TSAs) are gaining popularity in modern engineering and robotic applications. However, in conventional actuators of this type, the twisted part of the string should not be in contact with any surfaces or objects because this may interfere with the propagation of twisting. This imposes significant constraint on potential applications of TSAs. In this paper, we investigated the feasibility of using TSAs inside conduit and demonstrated that the twists of the string can be fully propagated through the sheath and that consistent periodic behavior of the twisted string can be achieved. In addition, we investigated input-output position and force characteristics of TSAs for various deflection angles of the conduit, effect of lubrication on transmission efficiency, and compared it with conventional cable sliding transmission. We found that TSA has higher transmission efficiency than sliding due to decreased friction between the string and conduit, which is further improved by lubrication. We have managed to achieve 85 % of force transmission efficiency for the case of lubricated twisting, as opposed to the 71.74% for lubricated sliding.


Title: Stiffness Decomposition and Design Optimization of Under-Actuated Tendon-Driven Robotic Systems
Key Words: compliant mechanisms  design engineering  elasticity  manipulator dynamics  motion control  stiffness decomposition  design optimization  systematic design framework  under-actuated tendon-driven robotic systems  free motion  contact task  configuration space  UATD robotic systems  actuation  active tendons  un-actuated space  passive compliance  UATD robotic finger  contact wrench  Robots  Tendons  Pulleys  Routing  Springs  Grasping  Actuators 
Abstract: We present a novel systematic design framework for general under-actuated tendon-driven (UATD) robotic systems to exhibit desired behaviors both during the free motion and the contact task. For this, we propose stiffness decomposition, which enables us to completely decompose the configuration space of the UATD robotic systems into the actuated space (with full actuation via active tendons) and the un-actuated space (with no actuation, only with passive compliance and contact wrench). The behavior in the actuated space is then fully-controllable, thus, the attainment of the desired behaviors, particularly those during the contact task, hinges upon that in the un-actuated space. For this, relying on the stiffness decomposition, we optimize the design parameters (e.g., tendon routing, pulley radius, passive compliance, etc.) to ensure the deformation in the un-actuated space as directional (e.g., for adaptive grasping) and minimized (e.g., pushing with posture maintained) for different contact wrench sets as possible, while also rendering the free motion to be as compliant and backdrivable as possible. The presented framework is then applied to design a UATD robotic finger and experimentally verified with the robot able to mimic the behavior of human index finger both during the free motion and pinch-pushing.


Title: Design and Development of Effective Transmission Mechanisms on a Tendon Driven Hand Orthosis for Stroke Patients
Key Words: biomechanics  fatigue  orthotics  patient rehabilitation  three-dimensional printing  3D-printed artificial finger  moment arms  fatigue  spasticity  wearable tendon-driven hand orthosis  exoskeletons  transmission efficiency  low-profile design  effective transmission mechanisms  stroke patients  joint angle characteristics  finger joints  effective force transmission  Tendons  Force  Exoskeletons  Robots  Electron tubes  Task analysis  Thumb 
Abstract: Tendon-driven hand orthoses have advantages over exoskeletons with respect to wearability and safety because of their low-profile design and ability to fit a range of patients without requiring custom joint alignment. However, no existing study on a wearable tendon-driven hand orthosis for stroke patients presents evidence that such devices can overcome spasticity given repeated use and fatigue, or discusses transmission efficiency. In this study, we propose two designs that provide effective force transmission by increasing moment arms around finger joints. We evaluate the designs with geometric models and experiment using a 3D-printed artificial finger to find force and joint angle characteristics of the suggested structures. We also perform clinical tests with stroke patients to demonstrate the feasibility of the designs. The testing supports the hypothesis that the proposed designs efficiently elicit extension of the digits in patients with spasticity as compared to existing baselines.


Title: Discovering a Library of Rhythmic Gaits for Spherical Tensegrity Locomotion
Key Words: Bayes methods  gait analysis  Gaussian processes  legged locomotion  Monte Carlo methods  motion control  pattern classification  regression analysis  significant control challenges  high-dimensionality  nonlinear nature  effective parameterization  rhythmic gaits  periodic control signals  rhythmic control signals  gait parameters  parameter space  Bayesian Optimization  parameter sample  gait discovery process  spherical tensegrity locomotion  tensegrity robots  rigid elements  soft elements  locomotion capabilities  central pattern generators  Gaussian Process regression model  Robots  Optimization  Aerospace electronics  Bayes methods  Shape  Angular velocity  Libraries 
Abstract: Tensegrity robots, which combine both rigid and soft elements, provide exciting new locomotion capabilities but introduce significant control challenges given their high-dimensionality and non-linear nature. This work first defines an effective parameterization of a spherical tensegrity for generating rhythmic gaits based on Central Pattern Generators (cp G). This allows the definition of periodic and rhythmic control signals, while exposing only five gait parameters. Then, this work proposes a framework for optimizing such gaits by exploring the parameter space through Bayesian Optimization on an underlying Gaussian Process regression model. The objective is to provide gaits that allow the platform to move along different directions with high velocity. Additionally, kNN binary classifiers are trained to estimate whether a parameter sample will result in an effective gait. The classification biases the sampling toward subspaces likely to yield effective gaits. An asynchronous communication layer is defined between the optimization and classification processes. The proposed gait discovery process is shown to efficiently optimize the parameters of gaits defined given the novel CPG architecture and outperforms less holistic approaches and Monte Carlo sampling.


Title: Line-Based Global Localization of a Spherical Camera in Manhattan Worlds
Key Words: cameras  feature extraction  gradient methods  Hough transforms  SLAM (robots)  3D line map  complicated six degrees of freedom search  2D line information  line-based global localization  spherical Hough representation  6 DoF localization process  Manhattan world assumption  3D-2D line correspondences  spherical-gradient filtering  spherical image  indoor environment  camera position  global environmental information  spherical camera  indoor localization  indoor spaces  Cameras  Three-dimensional displays  Image edge detection  Robustness  Robot vision systems  Solid modeling  Estimation 
Abstract: Localization is an important task for mobile service robots in indoor spaces. In this research, we propose a novel technique for indoor localization using a spherical camera. Spherical cameras can obtain a complete view of the surroundings allowing the use of global environmental information. We take advantage of this in order to estimate camera position and the orientation with respect to a known 3D line map of an indoor environment, using a single image. We robustly extract 2D line information from the spherical image via spherical-gradient filtering and match it to 3D line information in the line map. Our method requires no information about the 3D-2D line correspondences. In order to avoid a complicated six degrees of freedom (6 DoF) search for position and orientation, we use a Manhattan world assumption to decompose the line information in the image. The 6 DoF localization process is divided into two phases. First, we estimate the orientation by extracting the three principle directions from the image. Then, the position is estimated by robustly matching the distribution of lines between the image and the 3D model via a spherical Hough representation. This decoupled search can robustly localize a spherical camera using a single image, as we demonstrate experimentally.


Title: Robust Target-Relative Localization with Ultra-Wideband Ranging and Communication
Key Words: aircraft communication  aircraft navigation  altimeters  autonomous aerial vehicles  helicopters  Kalman filters  nonlinear filters  position control  sensors  target tracking  ultra wideband communication  quadcopter  autonomous flight  Extended Kalman Filter  UWB ranging measurements  onboard sensors  altimeters  optical flow  UWB based communication capability  robust target-relative localization  ultra-wideband ranging communication  Ultra-wideband ranging sensors  Distance measurement  Sensors  Antenna measurements  Robustness  Iron  Robots  Kalman filters 
Abstract: In this paper we propose a method to achieve relative positioning and tracking of a target by a quadcopter using Ultra-wideband (UWB) ranging sensors, which are strategically installed to help retrieve both relative position and bearing between the quadcopter and target. To achieve robust localization for autonomous flight even with uncertainty in the speed of the target, two main features are developed. First, an estimator based on Extended Kalman Filter (EKF) is developed to fuse UWB ranging measurements with data from onboard sensors including inertial measurement unit (IMU), altimeters and optical flow. Second, to properly handle the coupling of the target's orientation with the range measurements, UWB based communication capability is utilized to transfer the target's orientation to the quadcopter. Experiments results demonstrate the ability of the quadcopter to control its position relative to the target autonomously in both cases when the target is static and moving.


Title: Visual Odometry Using a Homography Formulation with Decoupled Rotation and Translation Estimation Using Minimal Solutions
Key Words: distance measurement  estimation theory  image matching  matrix algebra  motion estimation  pose estimation  robot vision  motion estimation  decoupled rotation  optimal inlier set  histogram voting  RANSAC step  KITTI data set  road driving scenarios  homography formulation  visual odometry  exhaustive search  motion hypothesis  translation estimation  dominant ground plane  Estimation  Visual odometry  Mathematical model  Cameras  Histograms  Gravity  Motion estimation 
Abstract: In this paper we present minimal solutions for two-view relative motion estimation based on a homography formulation. By assuming a known vertical direction (e.g. from an IMU) and assuming a dominant ground plane we demonstrate that rotation and translation estimation can be decoupled. This result allows us to reduce the number of point matches needed to compute a motion hypothesis. We then derive different algorithms based on this decoupling that allow an efficient estimation. We also demonstrate how these algorithms can be used efficiently to compute an optimal inlier set using exhaustive search or histogram voting instead of a traditional RANSAC step. Our methods are evaluated on synthetic data and on the KITTI data set, demonstrating that our methods are well suited for visual odometry in road driving scenarios.


Title: Local Nearest Neighbor Integrity Risk Evaluation for Robot Navigation
Key Words: computational complexity  feature extraction  mobile robots  nearest neighbour methods  risk analysis  sensor fusion  association faults  nearest neighbor data association algorithm  upper bound  nearest neighbor integrity risk evaluation  robot localization  integrity risk prediction  robot navigation  data association algorithms  feature extraction  Feature extraction  Technological innovation  Covariance matrices  Robots  Upper bound  Safety  Noise measurement 
Abstract: This paper describes the design of a new integrity risk prediction/monitoring methodology for robot localization that uses feature extraction and data association algorithms. The work specifically addresses incorrect association faults when employing a local nearest neighbor data association algorithm. This approach is more efficient and easier to implement than previous work. The methodology is tested in simulation, showing that the computed upper bound on integrity risk is a performance metric capable of providing warnings when the safety of the system cannot be guaranteed.


Title: Omnidirectional CNN for Visual Place Recognition and Navigation
Key Words: cameras  feature extraction  feedforward neural nets  image matching  image retrieval  learning (artificial intelligence)  mobile robots  object recognition  pose estimation  robot vision  visual place recognition  place exemplars  recognition method  omnidirectional cameras  visual input  matched place exemplar  closest place exemplar  relative distance  retrieved closest place  omnidirectional view  powerful O-CNN  Omnidirectional CNN  virtual world datasets  real-world datasets  omnidirectional convolutional neural network  camera pose variation  Visualization  Navigation  Robots  Measurement  Cameras  Feature extraction  Task analysis 
Abstract: Visual place recognition is challenging, especially when only a few place exemplars are given. To mitigate the challenge, we consider place recognition method using omnidirectional cameras and propose a novel Omnidirectional Convolutional Neural Network (O-CNN) to handle severe camera pose variation. Given a visual input, the task of the O-CNN is not to retrieve the matched place exemplar, but to retrieve the closest place exemplar and estimate the relative distance between the input and the closest place. With the ability to estimate relative distance, a heuristic policy is proposed to navigate a robot to the retrieved closest place. Note that the network is designed to take advantage of the omnidirectional view by incorporating circular padding and rotation invariance. To train a powerful O-CNN, we build a virtual world for training on a large scale. We also propose a continuous lifted structured feature embedding loss to learn the concept of distance efficiently. Finally, our experimental results confirm that our method achieves state-of-the-art accuracy and speed with both the virtual world and real-world datasets.


Title: Addressing Challenging Place Recognition Tasks Using Generative Adversarial Networks
Key Words: feature extraction  image recognition  learning (artificial intelligence)  mobile robots  robot vision  SLAM (robots)  visual perception  perception task  place recognition tasks  simultaneous localization and mapping  SLAM  coupled Generative Adversarial Networks  domain translation task  Task analysis  Gallium nitride  Lighting  Generators  Image recognition  Feature extraction  Visualization 
Abstract: Place recognition is an essential component of Simultaneous Localization And Mapping (SLAM). Under severe appearance change, reliable place recognition is a difficult perception task since the same place is perceptually very different in the morning, at night, or over different seasons. This work addresses place recognition as a domain translation task. Using a pair of coupled Generative Adversarial Networks (GANs), we show that it is possible to generate the appearance of one domain (such as summer) from another (such as winter) without requiring image-to-image correspondences across the domains. Mapping between domains is learned from sets of images in each domain without knowing the instance-to-instance correspondence by enforcing a cyclic consistency constraint. In the process, meaningful feature spaces are learned for each domain, the distances in which can be used for the task of place recognition. Experiments show that learned features correspond to visual similarity and can be effectively used for place recognition across seasons.


Title: Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response
Key Words: approximation theory  computational complexity  greedy algorithms  mobile robots  multi-robot systems  optimisation  service robots  N task arrivals  service tasks  redeployment cost  one-stage greedy algorithm  constant-factor approximation algorithm  service cost  multiple service robots  autonomous robots  re-deployment algorithms  task response optimization  NP-hard  Robots  Task analysis  Time factors  Approximation algorithms  Probability distribution  Measurement  Vehicle dynamics 
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.


Title: Multi-Agent Time-Based Decision-Making for the Search and Action Problem
Key Words: computational complexity  control engineering computing  decision making  multi-agent systems  multi-robot systems  probability  rescue robots  search-and-rescue  task allocation  probabilistic reasoning  Gazebo-based environmenT  multiagent time-based decision-making  Mohamed Bin Zayed International Robotics Challenge  near-optimal decisions  agent action  allocated budget  time constraints  decentralized multiagent decision-making framework  computational complexity  task selection  missions present several challenges  robotic applications  action problem  Task analysis  Search problems  Decision making  Planning  Time factors  Robots  Probabilistic logic 
Abstract: Many robotic applications, such as search-and-rescue, require multiple agents to search for and perform actions on targets. However, such missions present several challenges, including cooperative exploration, task selection and allocation, time limitations, and computational complexity. To address this, we propose a decentralized multi-agent decision-making framework for the search and action problem with time constraints. The main idea is to treat time as an allocated budget in a setting where each agent action incurs a time cost and yields a certain reward. Our approach leverages probabilistic reasoning to make near-optimal decisions leading to maximized reward. We evaluate our method in the search, pick, and place scenario of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), by using a probability density map and reward prediction function to assess actions. Extensive simulations show that our algorithm outperforms benchmark strategies, and we demonstrate system integration in a Gazebo-based environment, validating the framework's readiness for field application.


Title: Multi-robot Dubins Coverage with Autonomous Surface Vehicles
Key Words: computational complexity  mobile robots  multi-robot systems  path planning  remotely operated vehicles  travelling salesman problems  multirobot Dubins coverage  aerial monitoring  single robot approaches  multirobot approaches  Dubins vehicle kinematics  environmental monitoring  multirobot team  Dubins vehicles  NP-complete problems  salesman problem-k-TSP-formulation  autonomous surface vehicles  large scale coverage operations  marine exploration  Robot sensing systems  Clustering algorithms  Task analysis  Lakes  Multi-robot systems  Kinematics 
Abstract: In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.


Title: How Many Robots are Enough: A Multi-Objective Genetic Algorithm for the Single-Objective Time-Limited Complete Coverage Problem
Key Words: computational complexity  genetic algorithms  multi-robot systems  trees (mathematics)  multiobjective genetic algorithm  multirobot complete coverage problem  task-allocation  number-fixed problem  multiobjective GA  Mofint  single-objective time-limited complete coverage problem  Robots  Vegetation  Task analysis  Genetic algorithms  Resource management  Optimization  Approximation algorithms 
Abstract: Complete coverage, which is the foundation of many robotic applications, aims to cover an area as quickly as possible. This study investigates the time-limited version of multi-robot complete coverage problem, that is, to find the least number of robots and allocate tasks properly to them such that they can finish a known mission within the time limit. This version of problem can be tackled straightforwardly based on optimizing the task-allocation to a fixed number of robots and enumerating the number. However, the number-fixed problem is NP-hard and the existing algorithm for the number-fixed problem allows intersecting tasks (possibly causing robots' interference) and endures high approximation factor. In this study, the time-limited complete coverage problem is tackled with a multi-objective approach, instead of enumerating robots' number and optimizing each number-fixed problem one by one. The multi-objective GA, Mofint, at first estimates the lower and upper bounds of the number of robots. It abstracts each task as a weighted node of a graph. Then, Mofint evolves individuals, each individual being a forest containing a certain number (within the bounds) of non-intersecting trees. Mofint can finally obtain higher precision than existing work with less time: the approximation factor for Mofint is 1.1 to 1.5 times the ideal allocation when robots' number is fixed, while for existing work is 1.5 to 2. Due to its higher precision, the least number of robots obtained in the experiments by Mofint is 0.6 times of existing work.


Title: Joint Multi-Policy Behavior Estimation and Receding-Horizon Trajectory Planning for Automated Urban Driving
Key Words: collision avoidance  Markov processes  mobile robots  multi-robot systems  path planning  road vehicles  multipolicy decision-making  traffic participants  planned trajectory  ego-vehicle  safe trajectories  multiple motion policies  receding-horizon planner  simulated multivehicle intersection scenarios  joint multipolicy behavior  automated urban driving  urban environments  autonomous vehicle  multiple motion hypothesis  joint behavior estimation  observable Markov decision processes  receding-horizon control  receding-horizon trajectory planning  Trajectory  Planning  Estimation  Space vehicles  Uncertainty  Roads  Computational modeling 
Abstract: When driving in urban environments, an autonomous vehicle must account for the interaction with other traffic participants. It must reason about their future behavior, how its actions affect their future behavior, and potentially consider multiple motion hypothesis. In this paper we introduce a method for joint behavior estimation and trajectory planning that models interaction and multi-policy decision-making. The method leverages Partially Observable Markov Decision Processes to estimate the behavior of other traffic participants given the planned trajectory for the ego-vehicle, and Receding-Horizon Control for generating safe trajectories for the ego-vehicle. To achieve safe navigation we introduce chance constraints over multiple motion policies in the receding-horizon planner. These constraints account for uncertainty over the behavior of other traffic participants. The method is capable of running in real-time and we show its performance and good scalability in simulated multi-vehicle intersection scenarios.


Title: Robust Environmental Mapping by Mobile Sensor Networks
Key Words: Bayes methods  computational geometry  environmental factors  fires  mobile radio  mobile robots  wireless sensor networks  environmental mapping  ground truth distribution  Voronoi diagram  ad-hoc communication  human safety  satisfactory convergence  autonomous agents  mapping tasks  terrain elevation  physical quantities  forest fires  hazardous chemical leakages  spatial map  mobile sensor networks  decentralized manner  disjoint regions  hardware failures  short-range sensors  mobile robots  environmental parameters  robust spatial mapping  Bayesian approach  Robot sensing systems  Robustness  Mutual information  Computational modeling  Mobile robots  Task analysis 
Abstract: Constructing a spatial map of environmental parameters is a crucial step to preventing hazardous chemical leakages, forest fires, or while estimating a spatially distributed physical quantities such as terrain elevation. Although prior methods can do such mapping tasks efficiently via dispatching a group of autonomous agents, they are unable to ensure satisfactory convergence to the underlying ground truth distribution in a decentralized manner when any of the agents fail. Since the types of agents utilized to perform such mapping are typically inexpensive and prone to failure, this results in poor overall mapping performance in real-world applications, which can in certain cases endanger human safety. This paper presents a Bayesian approach for robust spatial mapping of environmental parameters by deploying a group of mobile robots capable of ad-hoc communication equipped with short-range sensors in the presence of hardware failures. Our approach first utilizes a variant of the Voronoi diagram to partition the region to be mapped into disjoint regions that are each associated with at least one robot. These robots are then deployed in a decentralized manner to maximize the likelihood that at least one robot detects every target in their associated region despite a non-zero probability of failure. A suite of simulation results is presented to demonstrate the effectiveness and robustness of the proposed method when compared to existing techniques.


Title: Best Response Model Predictive Control for Agile Interactions Between Autonomous Ground Vehicles
Key Words: game theory  information theory  mobile robots  nonlinear control systems  predictive control  remotely operated vehicles  stochastic systems  best response model predictive control  AutoRally platforms  nonlinear stochastic systems  information theoretic model predictive control algorithm  iterated best response  game theoretic notion  autonomous control  autonomous ground vehicles  Games  Stochastic processes  Predictive control  Nash equilibrium  Optimization  Vehicle dynamics  Prediction algorithms 
Abstract: We introduce an algorithm for autonomous control of multiple fast ground vehicles operating in close proximity to each other. The algorithm is based on a combination of the game theoretic notion of iterated best response, and an information theoretic model predictive control algorithm designed for non-linear stochastic systems. We test the algorithm on two one-fifth scale AutoRally platforms traveling at speeds upwards of 8 meters per second, while maintaining a following distance of under two meters from bumper-to-bumper.


Title: A Deep Incremental Boltzmann Machine for Modeling Context in Robots
Key Words: Boltzmann machines  learning (artificial intelligence)  pattern classification  contextual model  context layer  scene classification benchmark  nonincremental models  deep incremental Boltzmann machine  robots  context modeling efforts  fixed structure  incremental deep model  Neurons  Context modeling  Hidden Markov models  Robots  Computational modeling  Adaptation models  Data models 
Abstract: Context is an essential capability for robots that are to be as adaptive as possible in challenging environments. Although there are many context modeling efforts, they assume a fixed structure and number of contexts. In this paper, we propose an incremental deep model that extends Restricted Boltzmann Machines. Our model gets one scene at a time, and gradually extends the contextual model when necessary, either by adding a new context or a new context layer to form a hierarchy. We show on a scene classification benchmark that our method converges to a good estimate of the contexts of the scenes, and performs better or on-par on several tasks compared to other incremental models or non-incremental models.


Title: Accelerating Model Learning with Inter-Robot Knowledge Transfer
Key Words: learning (artificial intelligence)  manipulator dynamics  multi-robot systems  robot programming  training transfer models  online learning  inverse dynamics model  model learning  inter-robot knowledge transfer  multirobot setting  trajectory tracking tasks  robot inverse dynamics model  tabula rasa learning  robot learning  Interbotix PhantomX Pincher arm  Kuka youBot arm  Adaptation models  Manipulator dynamics  Data models  Acceleration  Task analysis 
Abstract: Online learning of a robot's inverse dynamics model for trajectory tracking necessitates an interaction between the robot and its environment to collect training data. This is challenging for physical robots in the real world, especially for humanoids and manipulators due to their large and high dimensional state and action spaces, as a large amount of data must be collected over time. This can put the robot in danger when learning tabula rasa and can also be a time-intensive process especially in a multi-robot setting, where each robot is learning its model from scratch. We propose accelerating learning of the inverse dynamics model for trajectory tracking tasks in this multi-robot setting using knowledge transfer, where robots share and re-use data collected by preexisting robots, in order to speed up learning for new robots. We propose a scheme for collecting a sample of correspondences from the robots for training transfer models, and demonstrate, in simulations, the benefit of knowledge transfer in accelerating online learning of the inverse dynamics model between several robots, including between a low-cost Interbotix PhantomX Pincher arm, and a more expensive and relatively heavier Kuka youBot arm. We show that knowledge transfer can save up to 63% of training time of the youBot arm compared to learning from scratch, and about 58% for the lighter Pincher arm.


Title: Online Learning of a Memory for Learning Rates
Key Words: gradient methods  learning (artificial intelligence)  optimisation  pattern classification  learning rates  learning process  memory model  optimal learning rate landscape  task specific optimization  meta-learner  internal memory  optimization tasks  meta-learning algorithm speeds  learning control tasks  online learning settings  gradient behaviors  gradient-based optimizer  MNIST classification  Task analysis  Optimization  Prediction algorithms  Robots  Transforms  Computational modeling  Predictive models 
Abstract: The promise of learning to learn for robotics rests on the hope that by extracting some information about the learning process itself we can speed up subsequent similar learning tasks. Here, we introduce a computationally efficient online meta-learning algorithm that builds and optimizes a memory model of the optimal learning rate landscape from previously observed gradient behaviors. While performing task specific optimization, this memory of learning rates predicts how to scale currently observed gradients. After applying the gradient scaling our meta-learner updates its internal memory based on the observed effect its prediction had. Our meta-learner can be combined with any gradient-based optimizer, learns on the fly and can be transferred to new optimization tasks. In our evaluations we show that our meta-learning algorithm speeds up learning of MNIST classification and a variety of learning control tasks, either in batch or online learning settings.


Title: Learning Coupled Forward-Inverse Models with Combined Prediction Errors
Key Words: learning (artificial intelligence)  robots  multiple solutions  inverse space  forward models  paired forward-inverse models  multiple modules  local minima  training multiple models-that  monolithic complex network  efficient alternative  multiple simple models  complex models  unstructured environments  combined prediction errors  coupled forward-inverse models  Inverse problems  Computational modeling  Data models  Predictive models  Adaptation models  Robots  Context modeling 
Abstract: Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models-that is, learning their parameters and their responsibilities-has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously. In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions.


Title: DEFO-NET: Learning Body Deformation Using Generative Adversarial Networks
Key Words: finite element analysis  image colour analysis  image reconstruction  mobile robots  robot vision  RGB-D image  finite element methods  mobile robots  single depth view  physical finite element model simulator  autonomous robots  Generative Adversarial networks  body deformation  DEFO-NET  Strain  Gallium nitride  Force  Deformable models  Robots  Training  Generators 
Abstract: Modelling the physical properties of everyday objects is a fundamental prerequisite for autonomous robots. We present a novel generative adversarial network (DEFO-NET), able to predict body deformations under external forces from a single RGB-D image. The network is based on an invertible conditional Generative Adversarial Network (IcGAN) and is trained on a collection of different objects of interest generated by a physical finite element model simulator. Defo-netinherits the generalisation properties of GANs. This means that the network is able to reconstruct the whole 3-D appearance of the object given a single depth view of the object and to generalise to unseen object configurations. Contrary to traditional finite element methods, our approach is fast enough to be used in real-time applications. We apply the network to the problem of safe and fast navigation of mobile robots carrying payloads over different obstacles and floor materials. Experimental results in real scenarios show how a robot equipped with an RGB-D camera can use the network to predict terrain deformations under different payload configurations and use this to avoid unsafe areas.


Title: Bodily Aware Soft Robots: Integration of Proprioceptive and Exteroceptive Sensors
Key Words: cameras  convolution  dexterous manipulators  mobile robots  object tracking  path planning  recurrent neural nets  sensors  bodily aware soft robots  exteroceptive sensors  proprioceptive sensors  bend sensors  visual sensor  nonlinearity  octopus-inspired arm  camera record  arm capturing  internal sensory signals  stacked convolutional autoencoder  CAE  recurrent neural network  RNN  motion  Convolution  Soft robotics  Robot sensing systems  Visualization  Recurrent neural networks 
Abstract: Being aware of our body has great importance in our everyday life. It helps us to complete difficult tasks, such as movement in a dark room or grasping a complex object. These skills are important for robots as well, however, robotic bodily awareness is still an open question, and the nonlinearity of soft robots adds even more complexity. In this paper, we address this problem and present a novel method to implement bodily awareness into a real soft robot by the integration of its exteroceptive and proprioceptive sensors. We use an octopus-inspired arm as an example where the proprioceptive representation is approximated by four bend sensors integrated into the soft body, while a camera records the movement of the arm capturing its exteroceptive representation. The internal sensory signals are mapped to the visual information using a combination of a stacked convolutional autoencoder (CAE) and a recurrent neural network (RNN). As a result, the soft robot can learn to estimate and, therefore, to imagine its motion even when its visual sensor is not available.


Title: Deep Learning a Quadrotor Dynamic Model for Multi-Step Prediction
Key Words: aircraft control  autonomous aerial vehicles  control engineering computing  helicopters  learning (artificial intelligence)  mobile robots  motion control  predictive control  recurrent neural nets  robot dynamics  robot kinematics  trajectory control  quadrotor dynamic model  motion prediction  dynamic systems  long horizons  deep learning  deep recurrent neural networks  quadrotor motion model  initial system state  motor speeds  prediction horizon  recurrent neural network state initialization  quadrotor vehicle flights  indoor flight arena  hybrid network architecture  system identification methods  robust state predictions  time 2.0 s  frequency 100.0 Hz  Mathematical model  Predictive models  Vehicle dynamics  Aerodynamics  Recurrent neural networks  Training 
Abstract: We develop a multi-step motion prediction modeling method for dynamic systems over long horizons using deep learning. Building on previous work, we propose a novel hybrid network architecture, by combining deep recurrent neural networks with a quadrotor motion model created using classic system identification methods. The proposed model takes only the initial system state and motor speeds over the prediction horizon as inputs and returns robust state predictions for up to two seconds of motion at 100 Hz. We employ recurrent neural network state initialization during training, to exploit real-world dataset collected from quadrotor vehicle flights in an indoor flight arena. Our experiments demonstrate that the proposed hybrid network model consistently outperforms both black box and rigid body dynamics predictions over single and multi-step prediction scenarios, with an order of magnitude improvements in velocity estimates in particular.


Title: Safe Learning of Quadrotor Dynamics Using Barrier Certificates
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  Gaussian processes  helicopters  learning systems  mobile robots  nonlinear control systems  probability  uncertain systems  complex dynamical systems  accurate nonlinear models  data-driven approach  Gaussian processes  learning process  barrier certificates  safe learning  learning controller  quadrotor dynamics  Safety  Control systems  Computational modeling  Gaussian processes  Adaptation models  Lyapunov methods  System dynamics 
Abstract: To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. Simulation results are provided to demonstrate the effectiveness of the proposed approach.


Title: Data-Efficient Decentralized Visual SLAM
Key Words: cameras  data mining  graph theory  image sensors  multi-robot systems  optimisation  pose estimation  robot vision  SLAM (robots)  decentralized visual SLAM system  decentralized SLAM components  data-efficient decentralized visual SLAM  pose-graph optimization method  data association scales  robot count  data transfers  robots  map data  visual SLAM systems exchange  versatile cameras  lightweight cameras  cheap cameras  multirobot applications  mapping  Supplementary Material Data  Simultaneous localization and mapping  Visualization  Optimization  Pose estimation  Trajectory  Bandwidth 
Abstract: Decentralized visual simultaneous localization and mapping (SLAM) is a powerful tool for multi-robot applications in environments where absolute positioning is not available. Being visual, it relies on cheap, lightweight and versatile cameras, and, being decentralized, it does not rely on communication to a central entity. In this work, we integrate state-of-the-art decentralized SLAM components into a new, complete decentralized visual SLAM system. To allow for data association and optimization, existing decentralized visual SLAM systems exchange the full map data among all robots, incurring large data transfers at a complexity that scales quadratically with the robot count. In contrast, our method performs efficient data association in two stages: first, a compact full-image descriptor is deterministically sent to only one robot. Then, only if the first stage succeeded, the data required for relative pose estimation is sent, again to only one robot. Thus, data association scales linearly with the robot count and uses highly compact place representations. For optimization, a state-of-the-art decentralized pose-graph optimization method is used. It exchanges a minimum amount of data which is linear with trajectory overlap. We characterize the resulting system and identify bottlenecks in its components. The system is evaluated on publicly available datasets and we provide open access to the code. Supplementary Material Data and code are at: https://github.com/uzh-rpg/dslam_open.


Title: A Linear Least Square Initialization Method for 3D Pose Graph Optimization Problem
Key Words: approximation theory  computer vision  graph theory  image reconstruction  iterative methods  least squares approximations  optimisation  pose estimation  SLAM (robots)  important optimization problem  machine vision applications  3D SLAM  graph corresponds  PGO problem  relative noisy observation  PGO solvers  state-of-the-art initialization methods  low noise problems  measurement noise  iterative methods  high noise problems  PGO optimization problem  iterative least-squares method  linear least square initialization method  pose graph optimization  least-square problem  Robots  Integrated circuits  Cost function  Iterative methods  Three-dimensional displays  Estimation  Pose Graph Optimization  Least square  3D SLAM  Initialization method 
Abstract: Pose Graph Optimization (PGO) is an important optimization problem arising in robotics and machine vision applications like 3D reconstruction and 3D SLAM. Each node of pose graph corresponds to an orientation and a location. The PGO problem finds orientations and locations of the nodes from relative noisy observation between nodes. Recent investigations show that well-known iterative PGO solvers need good initialization to converge to good solutions. However, we observed that state-of-the-art initialization methods obtain good initialization only in low noise problems, and they fail in challenging problems having more measurement noise. Consequently, iterative methods may converge to bad solutions in high noise problems. In this paper, a new method for obtaining orientations in the PGO optimization problem is presented. Like other well-known methods the initial locations are obtained from the result of a least-squares problem. The proposed method iteratively approximates the problem around current estimation and converts it to a least-squares problem. Therefore, the method can be seen as an iterative least-squares method which is computationally efficient. Simulation results show that the proposed initialization method helps the most well-known iterative solver to obtain better optima and significantly outperform other solvers in some cases.


Title: IMLS-SLAM: Scan-to-Model Matching Based on 3D Data
Key Words: collision avoidance  mobile robots  optical radar  remotely operated vehicles  road traffic control  robot vision  SLAM (robots)  stereo image processing  robotics community  stereo cameras  depth sensors  Velodyne LiDAR  autonomous driving  low-drift SLAM algorithm  3D LiDAR data  scan-to-model matching framework  specific sampling strategy  LiDAR scans  Velodyne HDL32  Velodyne HDL64  global drift  IMLS-SLAM  3D data  simultaneous localization and mapping  localized LiDAR sweeps  IMLS surface representation  implicit moving least squares  size 4.0 km  size 16.0 m  time 10.0 year  Three-dimensional displays  Laser radar  Simultaneous localization and mapping  Two dimensional displays  Iterative closest point algorithm  Observability 
Abstract: The Simultaneous Localization And Mapping (SLAM) problem has been well studied in the robotics community, especially using mono, stereo cameras or depth sensors. 3D depth sensors, such as Velodyne LiDAR, have proved in the last 10 years to be very useful to perceive the environment in autonomous driving, but few methods exist that directly use these 3D data for odometry. We present a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method relies on a scan-to-model matching framework. We first have a specific sampling strategy based on the LiDAR scans. We then define our model as the previous localized LiDAR sweeps and use the Implicit Moving Least Squares (IMLS) surface representation. We show experiments with the Velodyne HDL32 with only 0.40% drift over a 4 km acquisition without any loop closure (i.e., 16 m drift after 4 km). We tested our solution on the KITTI benchmark with a Velodyne HDL64 and ranked among the best methods (against mono, stereo and LiDAR methods) with a global drift of only 0.69%.


Title: ApriISAM: Real-Time Smoothing and Mapping
Key Words: error analysis  matrix decomposition  mobile robots  SLAM (robots)  sparse matrices  fixed computational budget  dynamic variable reordering algorithm  ApriISAM  real-time smoothing  online robots  incremental SLAM algorithms  batch algorithms  absolute error  incremental Cholesky factorizations  marginalization order  iSAM  re-linearize  Simultaneous localization and mapping  Heuristic algorithms  Smoothing methods  Sparse matrices  Clustering algorithms  Real-time systems 
Abstract: For online robots, incremental SLAM algorithms offer huge potential computational savings over batch algorithms. The dominant incremental algorithms are iSAM and iSAM2 which offer radically different approaches to computing incremental updates, balancing issues like 1) the need to re-linearize, 2) changes in the desirable variable marginalization order, and 3) the underlying conceptual approach (i.e. the “matrix” story versus the “factor graph” story). In this paper, we propose a new incremental algorithm that computes solutions with lower absolute error and generally provides lower error solutions for a fixed computational budget than either iSAM or iSAM2. Key to AprilSAM's performance are a new dynamic variable reordering algorithm for fast incremental Cholesky factorizations, a method for reducing the work involved in backsubstitutions, and a new algorithm for deciding between incremental and batch updates.


Title: Fast Nonlinear Approximation of Pose Graph Node Marginalization
Key Words: approximation theory  graph theory  mobile robots  optimisation  path planning  pose estimation  SLAM (robots)  pose graph node marginalization  longterm localization  longterm mapping  longterm navigation  pose graph structure  absolute-to relative-pose spaces  pose-composition approach scaled version  approximate subgraph  fast nonlinear approximation method  Topology  Jacobian matrices  Covariance matrices  Gaussian distribution  Simultaneous localization and mapping  Approximation methods 
Abstract: We present a fast nonlinear approximation method for marginalizing out nodes on pose graphs for longterm simultaneous localization, mapping, and navigation. Our approximation preserves the pose graph structure to leverage the rich literature of pose graphs and optimization schemes. By re-parameterizing from absolute-to relative-pose spaces, our method does not suffer from the choice of linearization points as in previous works. We then join our approximation process with a scaled version of the recently-demoted pose-composition approach. Our approach eschews the expenses of many state-of-the-art convex optimization schemes through our efficient and simple O(N2) implementation for a given known topology of the approximate subgraph. We demonstrate its speed and near optimality in practice by comparing against state-of-the-art techniques on popular datasets.


Title: A Benchmark Comparison of Monocular Visual-Inertial Odometry Algorithms for Flying Robots
Key Words: aerospace robotics  cameras  Global Positioning System  image capture  mobile robots  pose estimation  robot vision  state estimation  monocular visual-inertial odometry algorithms  state estimation algorithms  computational constraints  inertial measurement units  VIO algorithms  single-board computer systems  flying robots  pose estimation  cameras  IMUs  motion capture  global positioning systems  MSCKF  OKVIS  ROVIO  VINS-Mono  SVO-MSF  SVO-GTSAM  hardware configurations  EuRoC datasets  six degree of freedom  6 DoF  State estimation  Visualization  Optimization  Pipelines  Hardware  Robot sensing systems 
Abstract: Flying robots require a combination of accuracy and low latency in their state estimation in order to achieve stable and robust flight. However, due to the power and payload constraints of aerial platforms, state estimation algorithms must provide these qualities under the computational constraints of embedded hardware. Cameras and inertial measurement units (IMUs) satisfy these power and payload constraints, so visual-inertial odometry (VIO) algorithms are popular choices for state estimation in these scenarios, in addition to their ability to operate without external localization from motion capture or global positioning systems. It is not clear from existing results in the literature, however, which VIO algorithms perform well under the accuracy, latency, and computational constraints of a flying robot with onboard state estimation. This paper evaluates an array of publicly-available VIO pipelines (MSCKF, OKVIS, ROVIO, VINS-Mono, SVO+MSF, and SVO+GTSAM) on different hardware configurations, including several single-board computer systems that are typically found on flying robots. The evaluation considers the pose estimation accuracy, per-frame processing time, and CPU and memory load while processing the EuRoC datasets, which contain six degree of freedom (6DoF) trajectories typical of flying robots. We present our complete results as a benchmark for the research community.


Title: A Monocular SLAM System Leveraging Structural Regularity in Manhattan World
Key Words: cameras  feature extraction  mobile robots  optimisation  pose estimation  robot vision  SLAM (robots)  rotation optimization strategy  parallelism  global binding method  absolute rotation  relative rotation  translation optimization strategy leveraging coplanarity  coplanar features  relative translation  optimal absolute translation  3D line optimization strategy  structural line segments  structural features  structural feature-based optimization module  3D map  structural regularity  optimization strategies  monocular SLAM systems  Manhattan World  camera poses  Three-dimensional displays  Cameras  Optimization  Parallel processing  Simultaneous localization and mapping  Robustness  Estimation 
Abstract: The structural features in Manhattan world encode useful geometric information of parallelism, orthogonality and/or coplanarity in the scene. By fully exploiting these structural features, we propose a novel monocular SLAM system which provides accurate estimation of camera poses and 3D map. The foremost contribution of the proposed system is a structural feature-based optimization module which contains three novel optimization strategies. First, a rotation optimization strategy using the parallelism and orthogonality of 3D lines is presented. We propose a global binding method to compute an accurate estimation of the absolute rotation of the camera. Then we propose an approach for calculating the relative rotation to further refine the absolute rotation. Second, a translation optimization strategy leveraging coplanarity is proposed. Coplanar features are effectively identified, and we leverage them by a unified model handling both points and lines to calculate the relative translation, and then the optimal absolute translation. Third, a 3D line optimization strategy utilizing parallelism, orthogonality and coplanarity simultaneously is proposed to obtain an accurate 3D map consisting of structural line segments with low computational complexity. Experiments in man-made environments have demonstrated that the proposed system outperforms existing state-of-the-art monocular SLAM systems in terms of accuracy and robustness.


Title: Visual Saliency-Aware Receding Horizon Autonomous Exploration with Application to Aerial Robotics
Key Words: mobile robots  optimisation  path planning  robot vision  trees (mathematics)  visual saliency-aware receding horizon autonomous exploration  reobserving salient regions  environment exploration rate  robot endurance  random tree  two-step optimization paradigm  salient objects  path planner  visual attention  aerial robotics  Visualization  Robot sensing systems  Planning  Computational modeling  Path planning 
Abstract: This paper presents a novel strategy for autonomous visual saliency-aware receding horizon exploration of unknown environments using aerial robots. Through a model of visual attention, incrementally built maps are annotated regarding the visual importance and saliency of different objects and entities in the environment. Provided this information, a path planner that simultaneously optimizes for exploration of unknown space, and also directs the robot's attention to focus on the most salient objects, is developed. Following a two-step optimization paradigm, the algorithm first samples a random tree and identifies the branch maximizing for new volume to be explored. The first viewpoint of this path is then provided as a reference to the second planning step. Within that, a new tree is spanned, admissible branches arriving at the reference viewpoint while respecting a time budget dependent on the robot endurance and its environment exploration rate are found and evaluated in terms of reobserving salient regions at sufficient resolution. The best branch is then selected and executed by the robot, and the whole process is iteratively repeated. The proposed method is evaluated regarding its ability to provide increased attention toward salient objects, is verified to run onboard a small aerial robot, and is demonstrated in a set of challenging experimental studies.


Title: Perception-aware Receding Horizon Navigation for MAVs
Key Words: aircraft control  collision avoidance  mobile robots  navigation  path planning  robot vision  state estimation  perception-aware receding horizon navigation  microaerial vehicle  state estimation uncertainty  perception-aware receding horizon approach  monocular state estimation  candidate trajectories  perception quality  collision probability  receding horizon navigation framework  improved state estimation accuracy  goal-reaching task  purely-reactive navigation system  MAV  Trajectory  State estimation  Planning  Navigation  Cameras  Measurement  Task analysis 
Abstract: To reach a given destination safely and accurately, a micro aerial vehicle needs to be able to avoid obstacles and minimize its state estimation uncertainty at the same time. To achieve this goal, we propose a perception-aware receding horizon approach. In our method, a single forward-looking camera is used for state estimation and mapping. Using the information from the monocular state estimation and mapping system, we generate a library of candidate trajectories and evaluate them in terms of perception quality, collision probability, and distance to the goal. The best trajectory to execute is then selected as the one that maximizes a reward function based on these three metrics. To the best of our knowledge, this is the first work that integrates active vision within a receding horizon navigation framework for a goal reaching task. We demonstrate by simulation and real-world experiments on an actual quadrotor that our active approach leads to improved state estimation accuracy in a goal-reaching task when compared to a purely-reactive navigation system, especially in difficult scenes (e.g., weak texture).


Title: Viewpoint-Tolerant Place Recognition Combining 2D and 3D Information for UAV Navigation
Key Words: autonomous aerial vehicles  distance measurement  geometry  mobile robots  path planning  robot vision  stereo image processing  3D information  UAV navigation  Unmanned Aerial Vehicles  vision-based odometry  loop-closure detection  place recognition framework  local 3D geometry  viewpoint-tolerant place recognition  2D Information  hand-held datasets  perceptual aliasing  binary features  Simultaneous localization and mapping  Three-dimensional displays  Visualization  Vocabulary  Image recognition  Navigation 
Abstract: The booming interest in Unmanned Aerial Vehicles (UAV s) is fed by their potentially great impact, however progress is hindered by their limited perception capabilities. While vision-based odometry was shown to run successfully onboard UAV s, loop-closure detection to correct for drift or to recover from tracking failures, has so far, proven particularly challenging for UAVs. At the heart of this is the problem of viewpoint-tolerant place recognition; in stark difference to ground robots, UAVs can revisit a scene from very different viewpoints. As a result, existing approaches struggle greatly as the task at hand violates underlying assumptions in assessing scene similarity. In this paper, we propose a place recognition framework, which exploits both efficient binary features and noisy estimates of the local 3D geometry, which are anyway computed for visual-inertial odometry onboard the UAV. Attaching both an appearance and a geometry signature to each `location', the proposed approach demonstrates unprecedented recall for perfect precision as well as high quality loop-closing transformations on both flying and hand-held datasets exhibiting large viewpoint and appearance changes as well as perceptual aliasing.


Title: Flexible Stereo: Constrained, Non-Rigid, Wide-Baseline Stereo Vision for Fixed-Wing Aerial Platforms
Key Words: aerospace components  angular velocity measurement  autonomous aerial vehicles  cameras  collision avoidance  Kalman filters  nonlinear filters  pose estimation  robot vision  stereo image processing  landing maneuvers  wing model  probability density function  measured deviations  nominal relative baseline transformation  relative pose measurements  relative perspective N-point problem  inertial measurement units  highly accurate baseline transformations  flexible stereo  wide-baseline stereo vision  fixed-wing aerial platforms  computationally efficient method  visual-inertial sensor rigs  fixed-wing unmanned aerial vehicle  estimated relative poses  highly accurate depth maps  obstacle avoidance  low-altitude flights  extended Kalman filter  Cameras  Visualization  Mathematical model  Quaternions  Unmanned aerial vehicles  Real-time systems  Accelerometers 
Abstract: This paper proposes a computationally efficient method to estimate the time-varying relative pose between two visual-inertial sensor rigs mounted on the flexible wings of a fixed-wing unmanned aerial vehicle (UAV). The estimated relative poses are used to generate highly accurate depth maps in real-time and can be employed for obstacle avoidance in low-altitude flights or landing maneuvers. The approach is structured as follows: Initially, a wing model is identified by fitting a probability density function to measured deviations from the nominal relative baseline transformation. At runtime, the prior knowledge about the wing model is fused in an Extended Kalman filter (EKF) together with relative pose measurements obtained from solving a relative perspective N-point problem (PNP), and the linear accelerations and angular velocities measured by the two inertial measurement units (IMU) which are rigidly attached to the cameras. Results obtained from extensive synthetic experiments demonstrate that our proposed framework is able to estimate highly accurate baseline transformations and depth maps.


Title: Development and Implementation of High Power Hexapole Magnetic Tweezer System for Micromanipulations
Key Words: coils  collision avoidance  electromagnetic actuators  magnetic devices  micromanipulators  microrobots  mobile robots  non-Newtonian fluids  radiation pressure  three-dimensional printing  electromagnetic coil  3D printed magnetic yokes  double layer structure  power source  microscale robotic swimmer manipulations  high power hexapole magnetic tweezer system  tapering-tipped magnetic poles  Cartesian coordinate system  3D micromanipulations  Newtonian fluid  nonNewtonian fluid  obstacle avoidance  Magnetic flux  Magnetic resonance imaging  Magnetic fields  Saturation magnetization  Magnetic hysteresis  Force  Power supplies 
Abstract: This paper presents the design, development and implementation of a novel, high power hexapole magnetic tweezer system for 3D micromanipulations. Six tapering-tipped magnetic poles are deployed in a tilted Cartesian coordinate system, with an electromagnetic coil on each for actuation, connected by two 3D printed magnetic yokes to form a double layer structure. The power source is integrated to the magnetic tweezer system through a control algorithm on the software level; image processing was used for experiment analysis. Because of the high magnetic field that the magnetic coils can generate, the working space in the system is relatively larger than other similar designs, which provides better performance on microscale robotic swimmer manipulations. Simulations and experiments performed in this paper demonstrate the agile and powerful manipulation of microswimmers with desired control input to follow complex trajectories, avoid obstacles and move against micro-flow in the samples. We prove that the developed hexapole magnetic tweezer has enough power and controllability to guide microswimmers in Newtonian and Non-Newtonian fluid environments. The system will be optimized continuously and implemented into cell penetration experiments. Finally, the application will be deployed into in vivo based environments.


Title: Robotic Immobilization of Motile Sperm
Key Words: cell motility  cellular biophysics  manipulators  medical robotics  microorganisms  position control  servomechanisms  visual servoing  robotic sperm immobilization  visual servo control  sperm velocity  sperm orientation  sperm tail positions  robotic system  proximal sperms  sperm head  motile cells  motile sperm  robotic immobilization  Robots  Head  Visualization  Target tracking  Servosystems  Glass 
Abstract: Manipulation of motile cells such as bacteria and sperm is required in both cell biology and clinical applications. For immobilizing a motile sperm, the sperm head and tail positions must be accurately tracked, interference of proximal sperms on the target sperm must be tackled, and the orientation of the sperm must be properly aligned with the manipulation tool in order not to damage the sperm head where DNA is contained. Manual operation of sperm immobilization has stringent skill requirements, and both manual operation and existing robotic sperm immobilization suffer from inconsistent success rates and incapability of manipulating sperms swimming in all directions. This paper presents a robotic system for fully automated tracking, orientation control, and immobilization of motile sperms. Algorithms were developed for robustly tracking the sperm head and estimating the sperm tail positions under interfering conditions. A new visual servo control strategy was developed to enable the robotic system to actively adjust sperm orientation for immobilizing a sperm swimming in any direction. Experimental results from robotic immobilization of 400 sperms confirmed that the robotic system achieved a consistent success rate of 94.5 %, independent of sperm velocity or swimming direction.


Title: Automated Non-Invasive Measurement of Sperm Motility and Morphology Parameters
Key Words: biological techniques  biomedical measurement  cell motility  filtering theory  image reconstruction  image segmentation  medical image processing  probability  target tracking  motile cells  automation techniques  noninvasive measurement  adapted joint probabilistic data association filter  multisperm tracking  inherent inhomogeneous image intensity  quadratic cost function method  DIC image reconstruction  sperm motility measurement  differential interference contrast imaging method  sperm morphology measurement  image intensity  sperm subcellular structures  single sperm motility  sperm morphology parameters  illumination effect  Morphology  Switches  Head  Target tracking  Microscopy  Robots 
Abstract: Measuring the motility and morphology parameters of motile cells is important for revealing their functional characteristics. This paper presents automation techniques that, for the first time, enable automated, non-invasive measurement of motility and morphology parameters of individual sperms. Compared to the status quo of qualitative estimation of single sperm's motility and morphology based on embryologists' empirical experience, the automation techniques provide quantitative data in nearly real time. An adapted joint probabilistic data association filter (JPDAF) was used for multi-sperm tracking and tackled challenges of identifying sperms that intersect or have small spatial distances. Since the standard differential interference contrast (DIC) imaging method has side illumination effect which causes inherent inhomogeneous image intensity and poses difficulties for accurate sperm morphology measurement, we integrated total variation norm into the quadratic cost function method, which together effectively removed inhomogeneous image intensity and retained sperm's subcellular structures after DIC image reconstruction. In order to relocate the same sperm of interest identified under low magnification after switching to high magnification, coordinate transformation was conducted to handle the changes in the field of view caused by magnification switch. Experimental results demonstrated an accuracy of 95.6% in sperm motility measurement and errors <;10% in morphology measurement.


Title: A Framework for Sensorless Tissue Motion Tracking in Robotic Endomicroscopy Scanning
Key Words: biological tissues  biomedical optical imaging  endoscopes  image resolution  image segmentation  laser applications in medicine  medical image processing  medical robotics  optical microscopy  probe-based confocal laser endomicroscopy  robotic endomicroscopy scanning  image-quality metric  sensorless tissue motion tracking  ex vivo porcine tissue validate  autonomous endomicroscopy scanning  pCLE robotic tool  novel sensorless framework  sensorless approaches  endomicroscopy probe  robotic manipulation  tissue deformation  probe-tissue contact force  Probes  Tools  Force  Robot sensing systems  Strain 
Abstract: Recent advances in probe-based Confocal Laser Endomicroscopy (pCLE) enable real-time, in situ and in vivo tissue assessment at the micro scale. The limited field-of-view offered by pCLE necessitates the use of mosaicking to allow for accurate tissue characterization from the incoming image stream. However, mosaicking requires a series of contiguous good-quality images, which is particularly challenging because probe-tissue distance must be maintained within a very narrow working range at all times and probe-tissue contact force must be kept to a minimum so that tissue deformation is avoided. Robotic manipulation of the endomicroscopy probe has provided partial solution to these challenges, but sensorless approaches have not been thoroughly investigated up to date. This paper proposes a novel sensorless framework that uses a single non-reference image-quality metric to learn an approximation of tissue motion and subsequently track it. Moreover, a pCLE robotic tool for autonomous endomicroscopy scanning is designed and used for testing and validation purposes. Experiments on lens paper and ex vivo porcine tissue validate the philosophy of the framework.


Title: SAT-C: An Efficient Control Strategy for Assembly of Heterogeneous Stress-Engineered MEMS Microrobots
Key Words: controllability  microrobots  mobile robots  motion control  multi-robot systems  position control  control primitives  control pulses  microrobotic systems  control policy  planar assembly  efficient control strategy  heterogeneous stress-engineered MEMS microrobots  efficient control framework  controllable microrobots  theoretical control strategy  multiple-shapes microassembly  arbitrary initial configuration  power delivery waveform  nonholonomic unicycles  multiple macroscale robots  direct drive wheels  Robots  Hysteresis  Microassembly  Micromechanical devices  Voltage control  Bandwidth  Actuators 
Abstract: We present a new efficient control framework for controlling groups of heterogeneous stress-engineered MEMS microrobots for accomplishing micro-assembly. The objective is to maximize the number of controllable microrobots in the system while keeping the number of external global signals as low as possible. This work proposes a theoretical control strategy that could complete multiple-shapes microassembly from arbitrary initial configuration where all the control primitives can be accompanied with a constant number (O(1)) of control pulses of the power delivery waveform. We focus on microrobotic systems that can be modeled as nonholonomic unicycles. We validate the control policy with hardware experiments for implementing planar assembly using multiple macroscale robots with direct drive wheels. These results lay the foundation for developing new methods to control of a large number of MEMS microrobots.


Title: Robotic Intracellular Manipulation: 3D Navigation and Measurement Inside a Single Cell
Key Words: biomagnetism  biomechanics  bioMEMS  Brownian motion  cancer  cellular biophysics  force control  medical robotics  micromanipulators  optical microscopy  patient treatment  position control  predictive control  magnetic bead  cell nucleus minor axes  cell nucleus major axes  stiffness polarity  sub-micrometer object  tissue level  untethered technique  3D navigation  robotic intracellular manipulation  force-displacement data  Brownian motion-imposed constraint  high-resolution confocal microscopy  slow visual feedback  generalized predictive controller  single human bladder cancer cell  piconewton force control  sub-micrometer position control  magnetic micromanipulation task  size 0.7 mum  frequency 1.0 Hz  distance 0.43 mum  Magnetic resonance imaging  Magnetic levitation  Force  Magnetic noise  Magnetic shielding  Magnetic devices  Magnetic separation 
Abstract: Magnetic micromanipulation is an untethered technique and has enabled numerous applications in the scale of millimeters to micrometers from the tissue level to cell level. However, existing systems are not capable of maneuvering a sub-micrometer object for precise force control, preventing the realization of intracellular manipulation or `fantastic voyage' inside a single cell. The magnetic micromanipulation task achieved in this work is sub-micrometer position control and piconewton force control of a sub-micron (0.7 μm) magnetic bead inside a single human bladder cancer cell (RT4). The magnetic bead was 3D positioned in the cell using a generalized predictive controller that effectively tackled the control challenge caused by the slow visual feedback (1 Hz) from high-resolution confocal microscopy. The average positioning error was quantified to be 0.43 μm, which is slightly larger than Brownian motion-imposed constraint (0.31 μm). The system is capable of three-dimensionally applying a maximum force of 60 pN with a resolution of 4 pN. In experiments, a 0.7 μm magnetic bead was controlled to move from an initial position in a cell to target positions on the cell nucleus. Force-displacement data were obtained from multiple locations along the cell nucleus' major and minor axes. The results revealed, for the first time, significantly higher stiffness exists in the cell nucleus' major axis than the minor axis. This stiffness polarity was likely attributed to the aligned stress fibers of actin filament inside the cells.


Title: ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition
Key Words: covariance analysis  feature extraction  image recognition  image texture  neural nets  touch (physiological)  tactile data  cloth textures  good recognition performance  perception performance  tactile sensing  shared representation space  feature sharing  cloth texture recognition  multimodal sensing ability  tactile images  Deep Maximum Covariance Analysis  learned features  DMCA framework  unimodal data  joint latent space  Gelsight sensor  deep neural networks  sensing modalities  Visualization  Tactile sensors  Cameras  Task analysis  Surface topography 
Abstract: Vision and touch are two of the important sensing modalities for humans and they offer complementary information for sensing the environment. Robots could also benefit from such multi-modal sensing ability. In this paper, addressing for the first time (to the best of our knowledge) texture recognition from tactile images and vision, we propose a new fusion method named Deep Maximum Covariance Analysis (DMCA) to learn a joint latent space for sharing features through vision and tactile sensing. The features of camera images and tactile data acquired from a GelSight sensor are learned by deep neural networks. But the learned features are of a high dimensionality and are redundant due to the differences between the two sensing modalities, which deteriorates the perception performance. To address this, the learned features are paired using maximum covariance analysis. Results of the algorithm on a newly collected dataset of paired visual and tactile data relating to cloth textures show that a good recognition performance of greater than 90% can be achieved by using the proposed DMCA framework. In addition, we find that the perception performance of either vision or tactile sensing can be improved by employing the shared representation space, compared to learning from unimodal data.


Title: Voronoi Features for Tactile Sensing: Direct Inference of Pressure, Shear, and Contact Locations
Key Words: calibration  computational geometry  computerised instrumentation  inference mechanisms  optical sensors  pressure measurement  pressure sensors  tactile sensors  transducers  Voronoi tessellation  visualisation mode  optical tactile sensor  shear magnitude  tactile contact  object grasping  manipulation  perception  contact location inference  pressure location inference  shear location inference  transducing method  local shear measurement  TacTip  calibration  complex systems  robot hands  Pins  Tactile sensors  Optical sensors  Data visualization  Biomedical optical imaging  Strain 
Abstract: There are a wide range of features that tactile contact provides, each with different aspects of information that can be used for object grasping, manipulation, and perception. In this paper inference of some key tactile features, tip displacement, contact location, shear direction and magnitude, is demonstrated by introducing a novel method of transducing a third dimension to the sensor data via Voronoi tessellation. The inferred features are displayed throughout the work in a new visualisation mode derived from the Voronoi tessellation; these visualisations create easier interpretation of data from an optical tactile sensor that measures local shear from displacement of internal pins (the TacTip). The output values of tip displacement and shear magnitude are calibrated to appropriate mechanical units and validate the direction of shear inferred from the sensor. We show that these methods can infer the direction of shear to ~2.3° without the need for training a classifier or regressor. The approach demonstrated here will increase the versatility and generality of the sensors and thus allow sensor to be used in more unstructured and unknown environments, as well as improve the use of these tactile sensors in more complex systems such as robot hands.


Title: Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals
Key Words: dexterous manipulators  graph theory  learning (artificial intelligence)  mobile robots  tactile sensors  erroneous contact states  manipulation demonstrations  motor primitive  manipulation task  insertion tasks  learned manipulation graphs  robust manipulation executions  sensory goals  multimodal sensory signals  complex contact manipulation tasks  contact state  contact state information  Barrett arm  BioTacs  contact changes  Robot sensing systems  Task analysis  Fasteners  Trajectory  Motion segmentation  Vibrations 
Abstract: Complex contact manipulation tasks can be decomposed into sequences of motor primitives. Individual primitives often end with a distinct contact state, such as inserting a screwdriver tip into a screw head or loosening it through twisting. To achieve robust execution, the robot should be able to verify that the primitive's goal has been reached as well as disambiguate it from erroneous contact states. In this paper, we introduce and evaluate a framework to autonomously construct manipulation graphs from manipulation demonstrations. Our manipulation graphs include sequences of motor primitives for performing a manipulation task as well as corresponding contact state information. The sensory models for the contact states allow the robot to verify the goal of each motor primitive as well as detect erroneous contact changes. The proposed framework was experimentally evaluated on grasping, unscrewing, and insertion tasks on a Barrett arm and hand equipped with two BioTacs. The results of our experiments indicate that the learned manipulation graphs achieve more robust manipulation executions by confirming sensory goals as well as discovering and detecting novel failure modes.


Title: ExoSense: Measuring Manipulation in a Wearable Manner
Key Words: design engineering  dexterous manipulators  end effectors  force control  force measurement  force sensors  grippers  manipulator dynamics  medical robotics  position control  tactile sensors  torque  end-effector posture measurements  human internal grasp force variations  robotic hand  passive hand exoskeleton  wearable manner  design engineering  forces measurement  exosense  robotic manipulators control  fingertip wearable force  torque sensing system  position control  Kinematics  Exoskeletons  Robot sensing systems  Force  Calibration 
Abstract: Grasp and manipulation is a complex task, deceivingly simple to accomplish for humans in everyday life, yet challenging to implement in a robotic hand. There is a trend in literature to use information obtained from studies on human grasp for the design and control of robotic manipulators. However, the effectiveness of such approach is dependent on the measurement tools that are available for use with human hands. While there are many sensing solutions that are designed for this purpose, obtaining a complete set of measurements of forces during grasp interaction is still challenging. In this work we aim to bridge this gap by introducing ExoSense, a passive hand exoskeleton. This device can provide position and orientation of the fingertips and, when integrated with the fingertip wearable force/torque sensing system ThimbleSense, a complete characterization of manipulation in terms of generalized forces and position of contacts on each fingertip in a completely wearable and unconstrained manner. After validating the device in terms of end-effector posture measurements and overall accuracy of grasp measurements, we report on a preliminary experiment aiming to show the potentialities of the system to study human internal grasp force variations and for neuroscientific investigation in general.


Title: Robotizing Double-Bar Ankle-Foot Orthosis
Key Words: actuators  cables (mechanical)  gait analysis  iterative learning control  medical robotics  muscle  orthotics  patient rehabilitation  pneumatic actuators  position control  pulleys  shafts  springs (mechanical)  double-bar ankle-foot orthosis  post-stroke gait rehabilitation  double-bar AFO  rehabilitation facilities  pneumatic actuator  Bowden cable force-transmission system  modular joint system  Modular Exoskeletal Joint  MEJ  hollow shaft  AFO's pivot  Bowden cables  contraction forces  actuation scheme  Nested-cylinder Pneumatic Artificial Muscle system  PAM  ideal actuation system  exoskeletal robots  NcPAM houses  cable-tensioning spring  cable tension  cable stopper  ankle-joint trajectory tracking performances  integrated system  iterative learning control  Robots  Force  Actuators  Mechanical cables  Exoskeletons  Torque  Springs 
Abstract: This paper introduces an approach that robotizes an ankle-foot orthosis (AFO). In particular, toward post-stroke gait rehabilitation, we robotize a double-bar AFO, which is widely used in rehabilitation facilities, by newly designing a modular joint, a pneumatic actuator, and a Bowden cable force-transmission system. Our modular joint system, called the Modular Exoskeletal Joint (MEJ), has a hollow shaft for simple attachment to an AFO's pivot. We designed MEJ to compactly house an encoder that is built in a bearing in a pulley. We adopted Bowden cables to transmit contraction forces from an actuator to the MEJ. As an actuation scheme, we developed the Nested-cylinder Pneumatic Artificial Muscle (NcPAM) system. Even though PAMs are mechanically compliant and lightweight, they can still generate a large force. Therefore, they can provide an ideal actuation system for exoskeletal robots. The nested-cylinder in NcPAM houses a cable-tensioning spring to properly maintain small cable tension for passive movements and a cable stopper to connect the PAM and the cable for properly transmitting the large force generated by PAM. We show the ankle-joint trajectory tracking performances of this integrated system using iterative learning control.


Title: Design and Benchtop Validation of a Powered Knee-Ankle Prosthesis with High-Torque, Low-Impedance Actuators
Key Words: actuators  artificial limbs  gait analysis  motion control  open loop systems  torque control  powered knee-ankle prosthesis  low-impedance actuators  high torque density actuators  low-reduction transmissions  low-speed motor  low mechanical impedance  high backdrivability  robotic prosthetic legs  negligible unmodeled actuator dynamics  power regeneration  free-swinging knee tests  open-loop impedance control tests  intrinsic impedance  joint impedance  torque feedback  powered knee-and-ankle transfemoral prosthetic leg  actuation styles  free-swinging knee motion  size 3.0 nm  Actuators  Gears  Legged locomotion  Knee  Torque  Brushless DC motors 
Abstract: This paper describes the design of a powered knee-and-ankle transfemoral prosthetic leg, which implements high torque density actuators with low-reduction transmissions. The low reduction of the transmission coupled with a high-torque and low-speed motor creates an actuator with low mechanical impedance and high backdrivability. This style of actuation presents several possible benefits over modern actuation styles implemented in emerging robotic prosthetic legs. Such benefits include free-swinging knee motion, compliance with the ground, negligible unmodeled actuator dynamics, and greater potential for power regeneration. Benchtop validation experiments were conducted to verify some of these benefits. Backdrive and free-swinging knee tests confirm that both joints can be backdriven by small torques (~3 Nm). Bandwidth tests reveal that the actuator is capable of achieving frequencies required for walking and running. Lastly, open-loop impedance control tests prove that the intrinsic impedance and unmodeled dynamics of the actuator are sufficiently small to control joint impedance without torque feedback.


Title: Variable Transmission Series Elastic Actuator for Robotic Prosthesis
Key Words: actuators  artificial limbs  biomechanics  elasticity  legged locomotion  medical robotics  motion control  prosthetics  robot dynamics  torque control  robotic prosthetic knee  passive mode test  passive prosthesis  rotary motion  linear motion  slider crank mechanism  knee angle  variable transmission mechanism  SuKnee  robotic prosthesis  variable transmission series elastic actuator  Knee  Prosthetics  Legged locomotion  Springs  Batteries  Force 
Abstract: In this paper, we introduce a novel robotic prosthetic knee as shown in Fig. 1 (named as SuKnee) with variable transmission mechanism that could vary transmission ratio while knee angle varies during ambulation activities. A slider crank mechanism is utilized to transform linear motion of series elastic actuator to rotary motion of knee joint. And it contributes to variable transmission ratio with knee angle, which help obtain desired speed variation and torque output in different activities in one mechanism. This feature could uniquely give the SuKnee both: the torque necessary to assist with standing up from a chair and the speed necessary to swing the leg forward during walking. The knee has an active mode, where it operates with batteries and is capable of providing external power, and a passive mode, behaving like a passive prosthesis. Preliminary tests have been performed by a transfemoral amputee and SuKnee could provide user with power to assist walking on level ground and standing up from a chair. And a passive mode test shows it could work like passive prosthesis after battery exhaustion.


Title: Towards Restoring Locomotion for Paraplegics: Realizing Dynamically Stable Walking on Exoskeletons
Key Words: gait analysis  legged locomotion  medical robotics  optimisation  robot dynamics  stable walking gaits  direct collocation optimization formulation  paraplegics  crutch-less dynamic walking  lower-body exoskeleton  French start-up company Wandercraft  partial hybrid zero dynamics framework  PHZD  legged locomotion  Exoskeletons  Legged locomotion  Foot  Companies  Optimization  Kinematics 
Abstract: This paper presents the first experimental results of crutch-less dynamic walking with paraplegics on a lower-body exoskeleton: ATALANTE, designed by the French start-up company Wandercraft. The methodology used to achieve these results is based on the partial hybrid zero dynamics (PHZD) framework for formally generating stable walking gaits. A direct collocation optimization formulation is used to provide fast and efficient generation of gaits tailored to each patient. These gaits are then implemented on the exoskeleton for three paraplegics. The end result is dynamically stable walking in an exoskeleton without the need for crutches. After a short period of tuning by the engineers and practice by the subjects, each subject was able to dynamically walk across a room of about 10 m up to a speed of 0.15 m/s (0.5 km/h) without the need for crutches or any other kind of assistance.


Title: Autonomous Multi-Joint Soft Exosuit for Assistance with Walking Overground
Key Words: actuators  biomechanics  force control  gait analysis  medical robotics  motion control  autonomous multijoint soft exosuit  human locomotion  assistive torques  gait assistance  overground walking  soft exosuit assists  ankle plantarflexion  hip flexion  hip extension  mobile actuation system  high assistive forces  force profiles  walking cycle  control adaptation method  force consistency  peak force  target force  country-course walking  RMS error  human energy economy  Legged locomotion  Hip  Belts  Force  Actuators  Thigh 
Abstract: Soft exosuits are a new approach for assisting with human locomotion, which applies assistive torques to the wearer through functional apparel. In this paper, we present a new version of autonomous multi-joint soft exosuit for gait assistance, particularly designed for overground walking. The soft exosuit assists with ankle plantarflexion, hip flexion, and hip extension, equally distributing the forces between ankle plantarflexion and hip flexion. A mobile actuation system was developed to generate high assistive forces, and Bowden cables are used to transmit the forces to the exosuit. A sensor harness connects two load cells and three IMU s per leg that are used to measure real-time data for a controller that commands desired force profiles as a function of the walking cycle. In addition, a control adaptation method was developed which adjusts control parameters while walking on irregular surfaces. In preliminary studies, the proposed method substantially improved the force consistency while walking over uneven terrain. Specifically, the number of steps where the peak force deviated from the target force decreased from 100 to 57 out of 250 steps, and RMS error on the peak force decreased from 90.0 N to 76.6 N with respect to 300 N target force. Also, a two-subject case study on country-course walking demonstrated the potential of this soft exosuit to improve human energy economy while walking overground.


Title: A Lightweight and Efficient Portable Soft Exosuit for Paretic Ankle Assistance in Walking After Stroke
Key Words: gait analysis  medical robotics  patient rehabilitation  hemiparetic gait  paretic ankle assistance  overground walking  heterogeneous gait patterns  mechanical assistance  clinical gait training  optimized soft exosuit  poststroke patients  soft exosuits  soft wearable robots  paretic ankle dorsiflexion  forward propulsion symmetry  impaired paretic ankle plantarflexion  paretic ankle function  walking deficits  Legged locomotion  Prototypes  Foot  Actuators  Force  Mechanical cables 
Abstract: Hemiparetic gait after stroke is typically asymmetric and energetically inefficient. A major contributor to walking deficits is impaired paretic ankle function. Impaired paretic ankle plantarflexion (PF) reduces forward propulsion symmetry and impaired paretic ankle dorsiflexion (DF) diminishes ground clearance during swing. We have developed soft wearable robots (soft exosuits) to assist paretic PF and DF during walking after stroke. Through experimental studies with poststroke patients, we have demonstrated that exosuits can improve forward propulsion symmetry and ground clearance in walking, ultimately reducing the metabolic cost of walking. This paper presents an optimized soft exosuit aimed at use in clinical gait training for patients poststroke. The optimized exosuit is lightweight, easy to don and doff, and capable of efficiently delivering mechanical assistance to the paretic ankle. This paper focuses on the optimized controller that can deliver well-timed consistent ankle assistance to patients. A preliminary study was performed using this exosuit with three poststroke patients with heterogeneous gait patterns. Results showed that compared to a previously published controller, more consistent assistive force profiles could be delivered to individuals poststroke while consuming 50% less electrical power. Additionally, a preliminary biomechanical assessment was performed during overground walking.


Title: Comparing Assistive Admittance Control Algorithms for a Trunk Supporting Exoskeleton
Key Words: diseases  feedforward  handicapped aids  human-robot interaction  medical robotics  muscle  assistive admittance control algorithms  trunk supporting exoskeleton  duchenne muscular dystrophy  health care  active exoskeletons  daily living  trunk supporting robot  constant parameters  variable parameters  control laws  feedforward  variable admittance controllers  standard admittance  feed-forward force  Fitts-like experiment  Force  Admittance  Robots  Trajectory  Force measurement  Exoskeletons  Task analysis 
Abstract: Duchenne muscular dystrophy leaves patients with severe dependency on health care. In an effort to increase independence and quality of life, active exoskeletons are developed to support activities of daily living. This study is dedicated to the development and assessment of three different admittance control algorithms for a trunk supporting robot; a law with constant parameters, a law with added feed-forward force, and a law with variable parameters. A Fitts'-like experiment with 12 healthy subjects was performed to compare the control laws. The results show decreased movement times for the feedforward and variable admittance controllers with respect to the standard admittance.


Title: Dynamic Actuator Selection and Robust State-Feedback Control of Networked Soft Actuators
Key Words: control system synthesis  electroactive polymer actuators  pneumatic actuators  robots  robust control  state feedback  Electromagnetic Soft Actuator  logistic constraints  dynamic actuator selection  networked soft actuators  soft robotic systems  dynamic environments  robust state-feedback control  control input bounds  minimal actuator selection problem  physical network  artificial muscle fiber  soft actuator matrix  networked ESAs  robust control  soft-body actuators  actuator selection algorithms  realtime control  lightweight power sources  external stimuli  Actuators  Muscles  Force  Coils  Robust control  Magnetic cores  Springs 
Abstract: The design of robots that are light, soft, powerful is a grand challenge. Since they can easily adapt to dynamic environments, soft robotic systems have the potential of changing the status-quo of bulky robotics. A crucial component of soft robotics is a soft actuator that is activated by external stimuli to generate desired motions. Unfortunately, there is a lack of powerful soft actuators that operate through lightweight power sources. To that end, we recently designed a highly scalable, flexible, biocompatible Electromagnetic Soft Actuator (ESA). With ESAs, artificial muscles can be designed by integrating a network of ESAs. The main research gap addressed in this work is in the absence of system-theoretic understanding of the impact of the realtime control and actuator selection algorithms on the performance of networked soft-body actuators and ESAs. The objective of this paper is to establish a framework that guides the analysis and robust control of networked ESAs. A novel ESA is described, and a configuration of soft actuator matrix to resemble artificial muscle fiber is presented. A mathematical model which depicts the physical network is derived, considering the disturbances due to external forces and linearization errors as an integral part of this model. Then, a robust control and minimal actuator selection problem with logistic constraints and control input bounds is formulated, and tractable computational routines are proposed with numerical case studies.


Title: Safety and Guaranteed Stability Through Embedded Energy-Aware Actuators
Key Words: actuators  human-robot interaction  stability  embedded energy-aware actuators  robots  control algorithm  discrete-time computer  communication delays  model-free passivity  safety layer  complex robotic systems  physical human-robot interaction  safety mechanism  Actuators  Robots  Safety  Force  Springs  Shock absorbers 
Abstract: Safety is essential for robots in unknown environments, especially when there is physical Human-Robot Interaction (pHRI). Control over energy, or passivity, is an effective safety mechanism. However, when the control algorithm is implemented in a discrete-time computer, computation and communication delays readily lead to loss of passivity and to instability. In this paper, a way to make the actuators aware of the energy that they inject into the system is presented. Passivity and stability are then always guaranteed, even in situations of total communication loss. These Embedded Energy-Aware Actuators are a model-free passivity and safety layer that make complex robotic systems dependable, well-behaved and safe. The proposed method is validated in simulation and experiments.


Title: High-Level MLN-Based Approach for Spatial Context Disambiguation
Key Words: control engineering computing  inference mechanisms  learning (artificial intelligence)  Markov processes  mobile robots  probability  robot dynamics  sensor fusion  spatial context disambiguation  probabilistic MLN-based model  incomplete knowledge  High-level task planning  semantic spatial relations  robot dynamic  High-level MLN  MLN probabilistic reasoning  Robot sensing systems  Context modeling  Semantics  Probabilistic logic  Object recognition 
Abstract: In this paper, we propose a probabilistic MLN-based model for spatial context disambiguation. This model serves as a solution for the problem of incomplete knowledge in High-level task planning. By applying the state of the art MLN probabilistic reasoning such as MCSAT, we determine the concept class of the current spatial context of the robot and contribute by combining semantic spatial relations with observed data at different timesteps. The inherent uncertainty of robot dynamic environments makes the proposed approach suitable to deal with partial observability and sensing limitations of robots. Simulation experiments and evaluation results are presented to validate our model.


Title: Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging
Key Words: expectation-maximisation algorithm  graph theory  mobile robots  multi-robot systems  optimisation  robot vision  SLAM (robots)  PCM  robust multirobot map  robust selection  robust SLAM methods  multirobot case  simultaneous localization and mapping  pairwise consistency set maximization  pairwise consistent measurement set maximization  odometry backbone  Simultaneous localization and mapping  Robot kinematics  Phase change materials  Trajectory  Robustness  Merging 
Abstract: This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an “odometry backbone” to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.


Title: Task-Specific Sensor Planning for Robotic Assembly Tasks
Key Words: feedback  multi-robot systems  open loop systems  path planning  robotic assembly  sensors  task-specific sensor planning  robotic assembly tasks  sensory feedback  task planning  open-loop simulation  task-specific uncertainty approximants  multirobot planner  multirobot tasks  Robot sensing systems  Task analysis  Uncertainty  Planning  Robotic assembly  Estimation 
Abstract: When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.


Title: Map-Aware Particle Filter for Localization
Key Words: distance measurement  Global Positioning System  optical radar  particle filtering (numerical methods)  SLAM (robots)  map-aware particle filter  2D LiDAR localization  GPS localization  map information  localization sensors  particle filter framework  map-matching  prior occupancy grid  vehicle localization  Trajectory  Roads  Atmospheric measurements  Particle measurements  Sensors  Particle filters  Two dimensional displays 
Abstract: This work presents a method to improve vehicle localization by using the information from a prior occupancy grid to bound the possible poses. The method, named Map-Aware Particle Filter, uses a nonlinear approach to map-matching that can be integrated into a particle filter framework for localization. Each particle is re-weighted based on the validity of its current position in the map. In addition, we buffer the trajectory followed by the vehicle and then append it to each particle's pose. We then quantify the overlap between the trajectory and the map's free space. This serves as a measure of each particle's validity given the trajectory and the shape of the map. We evaluated the method by performing experiments with different types of localization sensors: First, (i) we significantly reduced the drift inherent to dead reckoning. By only using wheel odometry and map information we achieved loop closure over a distance of approximately 3 km. We also (ii) increased the accuracy of GPS localization. Finally, (iii) we fused a fragile 2D LiDAR localization with the map information. The resulting system had a higher robustness and managed to close the loop in an outdated map where it had failed before.


Title: Active Motion-Based Communication for Robots with Monocular Vision
Key Words: Bayes methods  decoding  estimation theory  image classification  Kalman filters  Monte Carlo methods  robot vision  online Bayesian estimation algorithm  monocular camera  receiver robot  sending robot  active motion-based communication  accurate trajectory classification  trajectory class distribution  active vision-based control policy  message decoding  trajectory identification  monocular vision model  receiving robot  Trajectory  Receivers  Cameras  Robot vision systems  Bayes methods  Estimation 
Abstract: In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.


Title: A Novel Recurrent Neural Network for Improving Redundant Manipulator Motion Planning Completeness
Key Words: collision avoidance  neurocontrollers  recurrent neural nets  redundant manipulators  Recurrent Neural Networks  manipulator control optimization  obstacle avoidance  RNN control  redundant manipulator motion planning  Planning  Manipulators  Task analysis  Recurrent neural networks  Collision avoidance  Robustness  Aerospace electronics  Motion Planning  Kinematic Control  Recurrent Neural Networks  Redundant Manipulator  Robot 
Abstract: Recurrent Neural Networks (RNNs) demonstrated advantages on control precision, system robustness and computational efficiency, and have been widely applied to redundant manipulator control optimization. Existing RNN control schemes locally optimize trajectories and are efficient and reliable on obstacle avoidance. However, for motion planning, they suffer from local minimum and do not have planning completeness. This work explained the cause of the planning incompleteness and addressed the problem with a novel RNN control scheme. The paper presented the proposed method in detail and analyzed the global stability and the planning completeness in theory. The proposed method was compared with other three control schemes on the precision, the robustness and the planning completeness in software simulation and the results shows the proposed method has improved precision and robustness, and planning completeness.


Title: Robust Collision Avoidance via Sliding Control
Key Words: adaptive control  collision avoidance  mobile robots  navigation  nonlinear control systems  parameter estimation  robust control  trajectory control  uncertain systems  variable structure systems  robust collision avoidance  planning algorithms  robots  unknown environments  cluttered environments  model uncertainty  external disturbances  nonlinear control theory  CASC  safe trajectory  parameter estimation  composite adaptive sliding controller  quadrotor navigation  Trajectory  Electron tubes  Uncertainty  Robustness  Optimization  Adaptation models 
Abstract: Recent advances in perception and planning algorithms have enabled robots to navigate autonomously through unknown, cluttered environments at high-speeds. A key component of these systems is the ability to identify, select, and execute a safe trajectory around obstacles. Many of these systems, however, lack performance guarantees because model uncertainty and external disturbances are ignored when a trajectory is selected for execution. This work leverages results from nonlinear control theory to establish a bound on tracking performance that can be used to select a provably safe trajectory. The Composite Adaptive Sliding Controller (CASC) provides robustness to disturbances and reduces model uncertainty through high-rate parameter estimation. CASC is demonstrated in simulation and hardware to significantly improve the performance of a quadrotor navigating through unknown environments with external disturbances and unknown model parameters.


Title: Optimizing Simulations with Noise-Tolerant Structured Exploration
Key Words: digital simulation  fast Fourier transforms  finite difference methods  gradient methods  Hadamard transforms  Jacobian matrices  legged locomotion  Newton method  optimisation  rendering (computer graphics)  Walsh functions  trajectory optimizers  noisy dynamics  quasiNewton optimizer  turning policies  noise-tolerant structured exploration  blackbox optimization  parameter perturbation directions  structured orthogonal matrices  structured finite differences  continuous control tasks  agile walking learning  Fast Walsh-Hadamard Fourier Transform  FWHT FFT  drop-in noise-tolerant replacement  quadruped locomotion  deep reinforcement learning  Mujoco simulator  3D renderers  Perturbation methods  Optimization  Standards  Smoothing methods  Robots  Jacobian matrices  Task analysis 
Abstract: We propose a simple drop-in noise-tolerant replacement for the standard finite difference procedure used ubiquitously in blackbox optimization. In our approach, parameter perturbation directions are defined by a family of structured orthogonal matrices. We show that at the small cost of computing a Fast Walsh-Hadamard/Fourier Transform (FWHT/FFT), such structured finite differences consistently give higher quality approximation of gradients and Jacobians in comparison to vanilla approaches that use coordinate directions or random Gaussian perturbations. We find that trajectory optimizers like Iterative LQR and Differential Dynamic Programming require fewer iterations to solve several classic continuous control tasks when our methods are used to linearize noisy, blackbox dynamics instead of standard finite differences. By embedding structured exploration in a quasi-Newton optimizer (LBFGS), we are able to learn agile walking and turning policies for quadruped locomotion, that successfully transfer from simulation to actual hardware. We theoretically justify our methods via bounds on the quality of gradient reconstruction and provide a basis for applying them also to nonsmooth problems.


Title: Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller
Key Words: autonomous aerial vehicles  iterative methods  learning (artificial intelligence)  nonlinear control systems  optimal control  optimisation  path planning  predictive control  sampling methods  trajectory optimisation (aerospace)  direct optimal control  control policy  optimal state-control trajectories  nonlinear predictive controller  nonlinear optimization problem  model-based methodology  control cycle  kinodynamic probabilistic roadmap  nonlinear solver  unmanned aerial vehicle  UAV  complex dynamical systems  sampling-based planning  policy learning  Computational modeling  Approximation algorithms  Optimal control  Planning  Robots  Trajectory optimization 
Abstract: Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.


Title: Goal Directed Dynamics
Key Words: control engineering computing  end effectors  humanoid robots  learning (artificial intelligence)  manipulator dynamics  motion control  quadratic programming  robot dynamics  telerobotics  forward dynamics  greedy optimization  feature-based control  control policies  trajectory optimization  goal directed dynamics  general control framework  low-level optimizer  robot dynamics  dynamical system  high level command  cost function  end-effector poses  soft-constraint physics model  quadratic programming framework  teleoperation  MuJoCo simulator  Acceleration  Robots  Force  Cost function  Dynamics 
Abstract: We develop a general control framework where a low-level optimizer is built into the robot dynamics. This optimizer together with the robot constitute a goal directed dynamical system, controlled on a higher level. The high level command is a cost function. It can encode desired accelerations, end-effector poses, center of pressure, and other intuitive features that have been studied before. Unlike the currently popular quadratic programming framework, which comes with performance guarantees at the expense of modeling flexibility, the optimization problem we solve at each time step is non-convex and non-smooth. Nevertheless, by exploiting the unique properties of the soft-constraint physics model we have recently developed, we are able to design an efficient solver for goal directed dynamics. It is only two times slower than the forward dynamics solver, and is much faster than real time. The simulation results reveal that complex movements can be generated via greedy optimization of simple costs. This new computational infrastructure can facilitate teleoperation, feature-based control, deep learning of control policies, and trajectory optimization. It will become a standard feature in future releases of the MuJoCo simulator.


Title: Regression-Based Linear Quadratic Regulator
Key Words: control system synthesis  feedback  linear quadratic control  mobile robots  optimisation  regression analysis  search problems  nonlinear dynamics  nonquadratic cost functions  free-derivative algorithm  local quadratic regressions  robot motion policy  locally-optimal control feedback policies  regression-based linear quadratic regulator  R-LQR  search space  optimization  Cost function  Approximation algorithms  Heuristic algorithms  Regulators  Optimal control  Robots  Aerospace electronics 
Abstract: We present the Regression-based Linear Quadratic Regulator (R-LQR), a new approach for determining locally-optimal control feedback policies for robots with non-linear dynamics and non-quadratic cost functions. Our proposal uses a free-derivative algorithm based on local quadratic regressions to obtain the robot motion policy. In addition, our methodology allows to define a notion of scale that translates into the definition of neighborhoods of valid policy and into the exploration of larger areas of the search space to find the optimal policies. The results show that our formulation allows to reach policies with lower costs than existing algorithms and to avoid problems when the behavior of the cost function makes the optimization difficult.


Title: Time-Optimal Path Tracking via Reachability Analysis
Key Words: control system analysis  mobile robots  path planning  perturbation techniques  reachability analysis  time optimal control  torque control  trajectory control  geometric path  control strategy  tracking controller  path parameterization problems  reachability analysis  time-optimal path tracking problem  tracking error regulation  reference trajectory  tracking performance degradation  path controller parameterization  joint torques  torque bounds  perturbations  Trajectory  Torque  Robustness  Perturbation methods  Acceleration  Manipulator dynamics 
Abstract: Given a geometric path, the Time-Optimal Path Tracking problem consists in finding the control strategy to traverse the path time-optimally while regulating tracking errors. A simple yet effective approach to this problem is to decompose the controller into two components: (i) a path controller, which modulates the parameterization of the desired path in an online manner, yielding a reference trajectory; and (ii) a tracking controller, which takes the reference trajectory and outputs joint torques for tracking. However, there is one major difficulty: the path controller might not find any feasible reference trajectory that can be tracked by the tracking controller because of torque bounds. In turn, this results in degraded tracking performances. Here, we propose a new path controller that is guaranteed to find feasible reference trajectories by accounting for possible future perturbations. The main technical tool underlying the proposed controller is Reachability Analysis, a new method for analyzing path parameterization problems. Simulations show that the proposed controller outperforms existing methods.


Title: Charging Station Placement for Indoor Robotic Applications
Key Words: computability  mobile robots  path planning  indoor robotic application  battery  satisfiability modulo theory  charging station placement problem  autonomous mobile robot  Charging stations  Trajectory  Batteries  Planning  Mobile robots  Task analysis 
Abstract: For an autonomous mobile robot, when the available power goes below a certain threshold, the robot needs to abort its current task and move towards a charging station to recharge its battery. The efficiency of an autonomous mobile robot depends significantly on the location of the charging stations. In this paper, we address the charging station placement problem for mobile robots in a controlled workspace. We propose two algorithms to place a number of charging stations so that a robot is always capable of reaching one of the charging stations from any obstacle-free location in the workspace without aborting its task too early. We reduce the charging-station placement problem to a series of Satisfiability Modulo Theory (SMT) problems and use the off-the-shelf SMT solver Z3 to implement our algorithm. The algorithm produces as output the locations of the charging stations in the workspace and the trajectories from any obstacle-free locations to one of the charging stations. Our experimental results show how our algorithm can efficiently find the locations of the charging stations and robot trajectories to reach the charging stations. We demonstrate through simulation how the generated trajectories can be effectively used by a robot to reach a charging stations autonomously without getting depleted with power.


Title: Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy
Key Words: control nonlinearities  mobile robots  observers  robot kinematics  robust control  steering systems  wheels  robust multi-model off-road steering strategy  path tracking algorithms  backstepping control strategy  two-wheel steering mobile robot  control law  dynamic models  kinematic models  observer  Mobile robots  Kinematics  Mathematical model  Trajectory  Observers  Dynamics 
Abstract: In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.


Title: Annotating Traversable Gaps in Walkable Environments
Key Words: computational geometry  mesh generation  mobile robots  navigation  path planning  solid modelling  virtual reality  navigation mesh generation  walkable areas  3D virtual environment  walkable environment  annotating traversable gaps  Navigation  Three-dimensional displays  Maintenance engineering  Image edge detection  Geometry  Surface morphology  Path planning 
Abstract: Autonomous agents typically need a navigation mesh of a 3D virtual environment to allow efficient path planning. This mesh needs as input a continuous representation of the walkable areas. However, the walkable environment (WE), i.e. the parts of the 3D environment that an agent can walk on, may contain gaps. These may be due to the filtering steps performed to compute the WE, because of modelling errors in the 3D model, or simply be part of the geometry of the environment. We provide an algorithm that identifies and fills these gaps. We detect gaps, up to a given distance, between pairs of boundary edges of the walkable environment, and fill them with polygons. We employ a heuristic for choosing which pairs of edges should be connected. We compare our algorithm to Recast [10], a voxel-based method for navigation mesh generation. We find that our method gives more accurate results in many environments: it retains the exact representation of the walkable environment, semantically separates the gaps from the walkable areas, and requires no tweaking of parameters to obtain good results. However, our method is currently slower than Recast, and requires more memory.


Title: Topological Nearest-Neighbor Filtering for Sampling-Based Planners
Key Words: filtering theory  mobile robots  nearest neighbour methods  path planning  sampling methods  trees (mathematics)  topological nearest-neighbor filtering  computational techniques  locality-sensitive hashing  workspace connectivity  nearest-neighbor time  nearest-neighbor algorithm  candidate neighbor configurations  topologically relevant set  sampling-based motion planning algorithms  Nearest-neighbor finding  sampling-based planners 
Abstract: Nearest-neighbor finding is a major bottleneck for sampling-based motion planning algorithms. The cost of finding nearest neighbors grows with the size of the roadmap, leading to significant slowdowns for problems which require many configurations to find a solution. Prior work has investigated relieving this pressure with quicker computational techniques, such as kd-trees or locality-sensitive hashing. In this work, we investigate an alternative direction for expediting this process based on workspace connectivity. We present an algorithm called Topological Nearest-Neighbor Filtering, which employs a workspace decomposition to select a topologically relevant set of candidate neighbor configurations as a pre-processing step for a nearest-neighbor algorithm. We investigate the application of this filter to several varieties of RRT and demonstrate that the filter improves both nearest-neighbor time and overall planning performance.


Title: Integration of Local Geometry and Metric Information in Sampling-Based Motion Planning
Key Words: geometry  linear quadratic control  linear systems  linearisation techniques  matrix algebra  mobile robots  path planning  robot dynamics  robot kinematics  sampling methods  sampling-based motion planning algorithms  steering procedure  configuration space geometry  sample configurations  local system dynamics  convex subsets  free space  local behavior  LQR cost-to-go function  system linearization  linear-Gaussian system  second-order linear system  Gram matrix  Mahalanobis distance  kinematic unicycle  local geometry  metric information  Measurement  Heuristic algorithms  Trajectory  Geometry  Robots  System dynamics  Planning 
Abstract: The efficiency of sampling-based motion planning algorithms is dependent on how well a steering procedure is capable of capturing both system dynamics and configuration space geometry to connect sample configurations. This paper considers how metrics describing local system dynamics may be combined with convex subsets of the free space to describe the local behavior of a steering function for sampling-based planners. Subsequently, a framework for using these subsets to extend the steering procedure to incorporate this information is introduced. To demonstrate our framework, three specific metrics are considered: the LQR cost-to-go function, a Gram matrix derived from system linearization, and the Mahalanobis distance of a linear-Gaussian system. Finally, numerical tests are conducted for a second-order linear system, a kinematic unicycle, and a linear-Gaussian system to demonstrate that our framework increases the connectivity of sampling-based planners and allows them to better explore the free space.


Title: Realization of a Real-Time Optimal Control Strategy to Stabilize a Falling Humanoid Robot with Hand Contact
Key Words: collision avoidance  friction  humanoid robots  mobile robots  motion control  optimal control  robot dynamics  stability  falling humanoid robot  environmental obstacles  obstacle geometry  contact point  planar dynamic model  optimal control approach  three-link robot model  hand contact optimization  Darwin-Mini robot  realtime optimal control strategy  realtime falling robot stabilization system  Real-time systems  Legged locomotion  Computational modeling  Humanoid robots  Robot sensing systems  Kinetic energy 
Abstract: In this paper, we present a real-time falling robot stabilization system for a humanoid robot in which the robot can prevent falling using hand contact with walls and other surfaces in the environment. Instead of ignoring or avoiding interaction with environmental obstacles, our system uses obstacle geometry to determine a contact point that reduces impact and necessary friction. It uses a planar dynamic model that is appropriate for falling stabilization in the robot's sagittal plane and frontal plane. The hand contact is determined with an optimal control approach, and to make the algorithm run in realtime, a simplified three-link robot model and a pre-computed database of subproblems for the hand contact optimization are adopted. Moreover, if the robot is not leaning too far after stabilization, we employ a heuristic push-up strategy to recover the robot to a standing posture. System integration is performed on the Darwin-Mini robot and validation is conducted in several environments and falling scenarios.


Title: Markerless Visual Servoing on Unknown Objects for Humanoid Robot Platforms
Key Words: Bayes methods  end effectors  humanoid robots  least squares approximations  Monte Carlo methods  recursive filters  stereo image processing  visual perception  visual servoing  least squares minimization problem  stereo vision  image-based visual servo control  nonlinear constrained optimization problem  Sequential Monte Carlo filtering  recursive Bayesian filtering technique  markerless visual servoing  iCub humanoid robot platform  Visual servoing  Grasping  Solid modeling  Three-dimensional displays  Mathematical model  Humanoid robots 
Abstract: To precisely reach for an object with a humanoid robot, it is of central importance to have good knowledge of both end-effector, object pose and shape. In this work we propose a framework for markerless visual servoing on unknown objects, which is divided in four main parts: I) a leastsquares minimization problem is formulated to find the volume of the object graspable by the robot's hand using its stereo vision; II) a recursive Bayesian filtering technique, based on Sequential Monte Carlo (SMC) filtering, estimates the 6D pose (position and orientation) of the robot's end-effector without the use of markers; III) a nonlinear constrained optimization problem is formulated to compute the desired graspable pose about the object; IV) an image-based visual servo control commands the robot's end-effector toward the desired pose. We demonstrate effectiveness and robustness of our approach with extensive experiments on the iCub humanoid robot platform, achieving real-time computation, smooth trajectories and subpixel precisions.


Title: Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller
Key Words: humanoid robots  mobile robots  motion control  multi-robot systems  optimal control  quadratic programming  human-humanoid collaborative tasks  multirobot quadratic program controller  human dynamics reconstruction  optimal robot controls  interaction motions  interaction forces  humanoid controller  co-manipulation tasks  robot platform simulation  optimization problem  Task analysis  Dynamics  Robot sensing systems  Mathematical model  Optimization  Humanoid robots 
Abstract: Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.


Title: Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments
Key Words: end effectors  humanoid robots  manipulators  mobile robots  motion control  stability  end-effectors  multicontact contact pose sequence planning  humanoid robot ARMAR-4  loco-manipulation tasks  contacts  loco-manipulation affordances  vision-based detection  whole-body multicontact tasks  motion planning  multicontact pose sequences  goal-directed planning  end-effector contact opportunities  autonomous detection  whole-body loco-manipulation actions  autonomous planning  humanoid robotics  humanoid robots  whole-body pose sequence planning  affordance-based multicontact  Planning  Humanoid robots  Task analysis  Motion segmentation  Robot sensing systems  Complexity theory 
Abstract: Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.


Title: Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement
Key Words: biomechanics  force measurement  force sensors  humanoid robots  humanoid robot  torque measurement  external forces  direct force measurements  regular force sensors  model-based estimator  floating-base kinematics  filtered measurement  contact force  additional estimation external force  model-based external force-moment estimation  Dynamics  Robot sensing systems  Kinematics  Force  Mathematical model 
Abstract: The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.


Title: Nonintuitive Optima for Dynamic Locomotion: The Acrollbot
Key Words: legged locomotion  motion control  optimal control  robot dynamics  velocity control  wheels  nonintuitive optima  dynamic locomotion  acrollbot  locally-optimal locomotion  two-link planar robot  unactuated wheel  passive wheel  ground reaction forces  net accelerations  decelerations  bipedal robot locomotion  toy system  locomotion speed  actuation  forward velocity  optimization techniques  direct collocation optimization framework  nonintuitive dynamic robot models  physical robot parameterizations  locomotion efficiency  data-driven optimization  dynamically-stable locomotion  legged rolling locomotion solutions  Wheels  Optimization  Damping  Trajectory  Controllability  Mobile robots 
Abstract: This paper explores locally-optimal, efficient locomotion of a two-link planar robot balancing on a single, unactuated wheel. Because this model is essentially an acrobot mounted on a passive wheel, we name this model the acrollbot. By actuating an internal degree of freedom, the model can indirectly produce ground reaction forces yielding net accelerations and decelerations, to achieve locomotion. As with bipedal robot locomotion, this toy system is particularly challenging to control due to the need to balance continuously while controlling forward locomotion speed. However, unlike typical legged or rolling locomotion solutions, it is not immediately obvious how best to exploit actuation, internal reconfigurations, and motions to produce and control forward velocity along the ground, providing a useful benchmarking system for exploring optimization techniques. We use a direct collocation optimization framework to study this toy system, both to achieve a range of feasible locomotion solutions for nonintuitive dynamic robot models, and to investigate optimization of physical robot parameterizations, in the sense of improving locomotion efficiency. The framework and example presented throughout are designed with an aim toward bridging the gap between non-intuitive, data-driven optimization and model-based methods for design and control of underactuated and dynamically-stable locomotion.


Title: Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation
Key Words: manipulators  multi-robot systems  path planning  physics reasoning  robot manipulation  manipulation planning  human-robot cooperation  multi-robot cooperation  Planning  Cognition  Estimation  Force  Robot sensing systems 
Abstract: For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as “physics reasoning”) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.


Title: Learning Modes of Within-Hand Manipulation
Key Words: actuators  control engineering computing  feature extraction  image classification  learning (artificial intelligence)  manipulators  motion control  robot vision  tactile sensors  learning modes  prehensile fingertip-based within-hand manipulation  tactile sensors  actuator states  visual data  supervised learning techniques  classification performance  Extra Trees  Gradient Boosting  visual features  classification rate  actuator loads  within-hand manipulation movements  hand/object system  Actuators  Visualization  Task analysis  Robot sensing systems  Grippers  Feature extraction 
Abstract: In this work, we investigate methods to detect four phenomena (modes) that occur during prehensile fingertip-based within-hand manipulation without the use of tactile sensors. By using actuator states and visual data, we aim to recognize different modes of operation such as interpreting if the hand is about to drop the object, if the object will begin to slide on the fingers, or if the system is at or near a singularity. For this purpose, we utilize supervised learning techniques, which allow us to detect the modes without the use of a mechanical model of the system. We analyze the individual roles of specific features available through both the actuator and visual data, and identify the ones that have the most significance for detecting the operation modes. Our results show classification performance of 96% (using either Extra Trees, Gradient Boosting, or SVM) when using combined actuator and visual features. Interestingly, we were able to achieve a 94% classification rate using only actuator information, and 93 % using only visual information. Overall, the classifiers identified actuator positions, actuator loads, and commanded velocities as the most important features for detecting a mode. These results have implications for enabling the control of within-hand manipulation movements utilizing a minimal amount of sensory information without a model of the hand/object system.


Title: Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks
Key Words: control engineering computing  evolutionary computation  gradient methods  humanoid robots  learning (artificial intelligence)  manipulator kinematics  motion control  operating systems (computers)  particle swarm optimisation  public domain software  robot programming  trees (mathematics)  full-body motion generation  open-source software package  inverse kinematics  arbitrary kinematic trees  evolutionary optimization  particle swarm optimization  cost functions  multigoal manipulation tasks  serial kinematic chains  dual-arm manipulation  multifinger hands  memetic algorithm  full-body motion specification  ROS  MoveIt!  Kinematics  Task analysis  Cost function  Robot kinematics  End effectors  Quaternions 
Abstract: While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.


Title: Robot Composite Learning and the Nunchaku Flipping Challenge
Key Words: humanoid robots  human-robot interaction  learning (artificial intelligence)  mobile robots  robot dynamics  heavily case-specific engineering  ubiquitous manner  human demonstration  LfD  dynamic skills  composite learning scheme  human definition  advanced motor skills  dynamic time-critical maneuver  complex contact control  partly soft partly rigid objects  nunchaku flipping challenge  physical success  robot composite learning  robot dynamics  hyper robot motor capabilities  robot learning  Petri nets  Robot learning  Mobile robots  Compounds  Dynamics  Real-time systems 
Abstract: Advanced motor skills are essential for robots to physically coexist with humans. Much research on robot dynamics and control has achieved success on hyper robot motor capabilities, but mostly through heavily case-specific engineering. Meanwhile, in terms of robot acquiring skills in a ubiquitous manner, robot learning from human demonstration (LfD) has achieved great progress, but still has limitations handling dynamic skills and compound actions. We present a composite learning scheme which goes beyond LfD and integrates robot learning from human definition, demonstration, and evaluation. The method tackles advanced motor skills that require dynamic time-critical maneuver, complex contact control, and handling partly soft partly rigid objects. We also introduce the “nunchaku flipping challenge”, an extreme test that puts hard requirements to all these three aspects. Continued from our previous presentations, this paper introduces the latest update of the composite learning scheme and the physical success of the nunchaku flipping challenge.


Title: Iterative Learning Scheme for Dexterous In-Hand Manipulation with Stochastic Uncertainty
Key Words: dexterous manipulators  gradient methods  iterative learning control  stochastic processes  stochastic systems  uncertain systems  dexterous manipulation tasks  model-based approaches  stochastic uncertainty  iterative learning scheme  adaptive learning rate methods  dexterous in-hand manipulation  gradient descent-based iterative learning control  Uncertainty  Stochastic processes  Robots  Torque  Cost function  Noise measurement  Robustness 
Abstract: In-hand manipulation has attracted attention because of its potential for performing dexterous manipulation tasks. Few successful examples using real robotic fingers have been reported because model-based approaches have been assumed. A gradient descent-based iterative learning control is one of the typical methods for improving the control performance without the need for a precise model. However, the learning performances deteriorate greatly owing to the stochastic uncertainties, and the learning rates have to be determined manually. We propose a novel iterative learning scheme with adaptive learning rate methods for dexterous in-hand manipulation. The proposed scheme not only eliminates the need for a precise model and manual tuning of a learning rate but also is robust to stochastic uncertainties and insensitive to hyperparameters. The validity of the proposed iterative learning scheme is demonstrated through several experiments.


Title: Dexterous Manipulation by Two Fingers with Coupled Joints
Key Words: dexterous manipulators  humanoid robots  manipulator kinematics  mechanical contact  finger  links  coupled joints  Lagrangian mechanics  independent joint angles  contact kinematics  slip modes  angular accelerations  joint accelerations  joint torques  proportional-derivative law  dexterous manipulation  stick modes  Acceleration  Kinematics  Task analysis  Thumb  Service robots 
Abstract: This paper studies dexterous manipulation in the plane by a two-fingered hand in the plane. The dynamics of each finger, which consists of two links with coupled joints, are derived based on Lagrangian mechanics. As an object is being manipulated, its orientation and the two independent joint angles of the hand constitute the state of the entire system. Contact kinematics, accounting for both stick and slip modes, are combined with dynamics to establish a dependence of the object's linear and angular accelerations on joint accelerations. This allows control of joint torques, under a proportional-derivative (PD) law, to move the object to a target position in a desired orientation.


Title: Extrinsic Dexterity Through Active Slip Control Using Deep Predictive Models
Key Words: dexterous manipulators  end effectors  grippers  learning (artificial intelligence)  slip  tactile sensors  extrinsic dexterity  active slip control  machine learning methodology  robot dexterity  recent insights  deep learning  tactile sensor information  manipulated object  robot end-effector  deep predictive models  Grippers  Training  Robot sensing systems  Predictive models  Acceleration 
Abstract: We present a machine learning methodology for actively controlling slip, in order to increase robot dexterity. Leveraging recent insights in deep learning, we propose a Deep Predictive Model that uses tactile sensor information to reason about slip and its future influence on the manipulated object. The obtained information is then used to precisely manipulate objects within a robot end-effector using external perturbations imposed by gravity or acceleration. We show in a set of experiments that this approach can be used to increase a robot's repertoire of motor skills.


Title: A General Pipeline for 3D Detection of Vehicles
Key Words: automobiles  convolution  feature extraction  feedforward neural nets  mobile robots  robot vision  traffic engineering computing  2D detection network  generalised car models  two-stage convolutional neural network  3D detection algorithms  general pipeline  autonomous driving  flexible pipeline  3D point cloud  model fitting algorithm  3D box detection  2D vehicle detection  Three-dimensional displays  Two dimensional displays  Automobiles  Pipelines  Solid modeling  Proposals  Laser radar 
Abstract: Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection.


Title: SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes
Key Words: geometry  image colour analysis  image representation  image segmentation  learning (artificial intelligence)  object detection  joint geometric  object segmentation  indoor scenes  unseen objects  nonobject surfaces  scene semantics  scene surfaces  unified energy function  hierarchical segmentation trees  RGB-D image  deep learning-based methods  SceneCut  convolutional oriented boundary network  Image segmentation  Semantics  Silicon  Object segmentation  Robots  Training  Three-dimensional displays 
Abstract: This paper presents SceneCut, a novel approach to jointly discover previously unseen objects and non-object surfaces using a single RGB-D image. SceneCut's joint reasoning over scene semantics and geometry allows a robot to detect and segment object instances in complex scenes where modern deep learning-based methods either fail to separate object instances, or fail to detect objects that were not seen during training. SceneCut automatically decomposes a scene into meaningful regions which either represent objects or scene surfaces. The decomposition is qualified by an unified energy function over objectness and geometric fitting. We show how this energy function can be optimized efficiently by utilizing hierarchical segmentation trees. Moreover, we leverage a pre-trained convolutional oriented boundary network to predict accurate boundaries from images, which are used to construct high-quality region hierarchies. We evaluate SceneCut on several different indoor environments, and the results show that SceneCut significantly outperforms all the existing methods.


Title: Bayesian Viewpoint-Dependent Robust Classification Under Model and Localization Uncertainty
Key Words: Bayes methods  image classification  pattern classification  Bayesian viewpoint-dependent robust classification  localization uncertainty  robust visual classification  black-box Bayesian classifier  localization error  spatial correlation  Uncertainty  Measurement uncertainty  Robots  Correlation  Bayes methods  Robustness  Training data 
Abstract: We propose an algorithm for robust visual classification of an object of interest observed from multiple views using a black-box Bayesian classifier which provides a measure of uncertainty, in the presence of significant ambiguity and classifier noise, and of localization error. The fusion of classifier outputs takes into account viewpoint dependency and spatial correlation among observations, as well as pose uncertainty when these observations are taken and a measure of confidence provided by the classifier itself. Our experiments confirm an improvement in robustness over state-of-the-art.


Title: Signature of Topologically Persistent Points for 3D Point Cloud Description
Key Words: computer graphics  image resolution  solid modelling  object classification  object detection  3D point cloud processing tasks  RGB-D dataset  spatial resolutions  topological invariant encoding  global descriptor  topologically persistent point signature  homology groups  competitive 3D point cloud descriptor  topological space  3D point cloud data  STPP  time 3.0 d  Three-dimensional displays  Shape  Robot sensing systems  Generators  Histograms  Topology  Face 
Abstract: We present the Signature of Topologically Persistent Points (STPP), a global descriptor that encodes topological invariants of 3D point cloud data. These topological invariants include the zeroth and first homology groups and are computed using persistent homology, a method for finding the features of a topological space at different spatial resolutions. STPP is a competitive 3D point cloud descriptor when compared to the state of art and is resilient to noisy sensor data. We demonstrate experimentally on a publicly available RGB-D dataset that STPP can be used as a distinctive signature, thus allowing for 3D point cloud processing tasks such as object detection and classification.


Title: Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes
Key Words: image colour analysis  image fusion  image reconstruction  image representation  image segmentation  learning (artificial intelligence)  neural net architecture  object detection  object tracking  pose estimation  robot vision  video cameras  video signal processing  reconstruction techniques  ground truth label generation  labeled object instances  object pose  video scene collection  annotation pipeline  DNN architecture  RGBD image  object meshes  human assisted ICP-fitting  3D dense reconstruction  RGBD camera  pixelwise labels  specific robotic manipulation task  training data  DNN pipelines  object segmentation  deep neural network architectures  cluttered scenes  real RGBD data  label fusion  Pipelines  Three-dimensional displays  Robot sensing systems  Image segmentation  Cameras  Image reconstruction 
Abstract: Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.


Title: Dropout Sampling for Robust Object Detection in Open-Set Conditions
Key Words: approximation theory  Bayes methods  image classification  inference mechanisms  learning (artificial intelligence)  mobile robots  object detection  regression analysis  robot vision  sampling methods  dropout sampling network  dropout variational inference  approximation technique  Bayesian deep learning  mobile robot  versatile campus environment  robotic vision  regression tasks  image classification  open-set conditions  robust object detection  Object detection  Uncertainty  Training  Bayes methods  Entropy  Task analysis  Robots 
Abstract: Dropout Variational Inference, or Dropout Sampling, has been recently proposed as an approximation technique for Bayesian Deep Learning and evaluated for image classification and regression tasks. This paper investigates the utility of Dropout Sampling for object detection for the first time. We demonstrate how label uncertainty can be extracted from a state-of-the-art object detection system via Dropout Sampling. We evaluate this approach on a large synthetic dataset of 30,000 images, and a real-world dataset captured by a mobile robot in a versatile campus environment. We show that this uncertainty can be utilized to increase object detection performance under the open-set conditions that are typically encountered in robotic vision. A Dropout Sampling network is shown to achieve a 12.3 % increase in recall (for the same precision score as a standard network) and a 15.1 % increase in precision (for the same recall score as the standard network).


Title: Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration
Key Words: cognition  control engineering computing  groupware  human computer interaction  human-robot interaction  medical computing  medical robotics  neural nets  surgery  team working  user interfaces  early prediction capability  turn-taking actions  early turn-taking prediction  Spiking Neural networks  human robot collaboration  human teamwork  Cognitive Turn-taking Model  turn-taking prediction algorithms  CTTM  robotic scrub nurse  human turn-taking intentions  multimodal human communication cues  Neurons  Robot kinematics  Task analysis  Training  Teamwork 
Abstract: Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.


Title: Learning Human Ergonomic Preferences for Handovers
Key Words: ergonomics  human-robot interaction  manipulators  human ergonomic preferences  handovers  robots  ergonomic human grasping configurations  ergonomic cost function  online estimation problem  in-person user study  Ergonomics  Handover  Cost function  Training  Manipulators 
Abstract: Our goal is for people to be physically comfortable when taking objects from robots. This puts a burden on the robot to hand over the object in such a way that a person can easily reach it, without needing to strain or twist their arm - a way that is conducive to ergonomic human grasping configurations. To achieve this, the robot needs to understand what makes a configuration more or less ergonomic to the person, i.e. their ergonomic cost function. In this work, we formulate learning a person's ergonomic cost as an online estimation problem. The robot can implicitly make queries to the person by handing them objects in different configurations, and gets observations in response about the way they choose to take the object. We compare the performance of both passive and active approaches for solving this problem in simulation, as well as in an in-person user study.


Title: Joining High-Level Symbolic Planning with Low-Level Motion Primitives in Adaptive HRI: Application to Dressing Assistance
Key Words: control engineering computing  footwear  human-robot interaction  learning (artificial intelligence)  mobile robots  planning (artificial intelligence)  robot programming  service robots  daily living assistance  robot motion encoding  programming  shoe-dressing scenario  robot verbosity  robot speed  safe living assistance  dressing assistance  adaptive HRI  low-level motion primitives  high-level symbolic planning  user preferences  human-robot interaction  Task analysis  Planning  Robot sensing systems  Footwear  Foot  Computational modeling 
Abstract: For a safe and successful daily living assistance, far from the highly controlled environment of a factory, robots should be able to adapt to ever-changing situations. Programming such a robot is a tedious process that requires expert knowledge. An alternative is to rely on a high-level planner, but the generic symbolic representations used are not well suited to particular robot executions. Contrarily, motion primitives encode robot motions in a way that can be easily adapted to different situations. This paper presents a combined framework that exploits the advantages of both approaches. The number of required symbolic states is reduced, as motion primitives provide “smart actions” that take the current state and cope online with variations. Symbolic actions can include interactions (e.g., ask and inform) that are difficult to demonstrate. We show that the proposed framework can adapt to the user preferences (in terms of robot speed and robot verbosity), can readjust the trajectories based on the user movements, and can handle unforeseen situations. Experiments are performed in a shoe-dressing scenario. This scenario is particularly interesting because it involves a sufficient number of actions, and the human-robot interaction requires the handling of user preferences and unexpected reactions.


Title: A Passivity-Based Strategy for Coaching in Human-Robot Interaction
Key Words: control engineering computing  end effectors  human-robot interaction  mobile robots  motion control  robot programming  end-effector  initial trajectory  path tracking  admittance parameters  passivity-based strategy  coaching  human-robot interaction  robot programming  programming techniques  passivity-based framework  Dynamical Movement Primitives  admittance control  human operator grabs  Trajectory  Admittance  Service robots  Robot sensing systems  Hidden Markov models  Task analysis 
Abstract: In order to make robot programming more easy and immediate, walk-through programming techniques can be exploited. However, a modification of a portion of the trajectory usually means to execute the path from the beginning. In this paper we propose a passivity-based framework to modify the trajectory online, manually driving the robot throughout the desired correction. The system follows the initial trajectory, encoded with Dynamical Movement Primitives, by setting high gains in the admittance control. When the human operator grabs the end-effector, the robot becomes compliant and the user can easily teach the desired correction, until he/she releases it at the end of the modification. Finally, the correction is optimally joined to the initial trajectory, restarting the path tracking. To avoid unsafe behaviors, the variation of the admittance parameters is performed exploiting energy tanks, in order to preserve the passivity of the interaction.


Title: A Tensegrity-Inspired Compliant 3-DOF Compliant Joint
Key Words: actuators  design engineering  geometry  mechatronics  motion control  optimisation  position control  robot dynamics  velocity control  tensegrity-inspired compliant three degree-of-freedom robotic joint  continuously soft materials  embedded sensing  position information  velocity information  geometry selection  optimization  theoretical configuration space  mechatronic design solutions  hardware prototype  low order dynamic systems  soft robotic systems  robotic limb  omnidirectional compliance  Tensegrity-Inspired Compliant 3-DOF Compliant joint  Robot kinematics  Robot sensing systems  Geometry  Force  Topology 
Abstract: Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.


Title: Training Deep Neural Networks for Visual Servoing
Key Words: feedforward neural nets  learning (artificial intelligence)  pose estimation  position control  robot vision  servomechanisms  visual servoing  6 DOF robot  deep neural network-based method  convolutional neural network  robust handling  scene-agnostic network  deep neural network training  real-time 6 DOF positioning  pose-based visual servoing control law  occlusions  lighting variations  Training  Robots  Feature extraction  Task analysis  Cameras  Voltage control  Robustness 
Abstract: We present a deep neural network-based method to perform high-precision, robust and real-time 6 DOF positioning tasks by visual servoing. A convolutional neural network is fine-tuned to estimate the relative pose between the current and desired images and a pose-based visual servoing control law is considered to reach the desired pose. The paper describes how to efficiently and automatically create a dataset used to train the network. We show that this enables the robust handling of various perturbations (occlusions and lighting variations). We then propose the training of a scene-agnostic network by feeding in both the desired and current images into a deep network. The method is validated on a 6 DOF robot.


Title: SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control
Key Words: cameras  closed loop systems  control engineering computing  gradient methods  image colour analysis  image segmentation  industrial robots  learning (artificial intelligence)  minimisation  neural nets  pose estimation  robot dynamics  robot vision  SE3-pose-Nets  deep visuomotor control  SE3-Nets  encoder-decoder structure  pose embedding  point-wise data associations  closed-loop control  scene dynamics  structred deep dynamics models  pose error minimization  gradient-based methods  Baxter robot  Three-dimensional displays  Predictive models  Transforms  Computational modeling  Data models  Aerospace electronics  Training 
Abstract: In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.


Title: Fast Object Learning and Dual-arm Coordination for Cluttered Stowing, Picking, and Packing
Key Words: grippers  humanoid robots  human-robot interaction  industrial manipulators  learning (artificial intelligence)  mobile robots  multi-robot systems  object detection  path planning  robot vision  service robots  robotic picking  cluttered bins  2017 Amazon Robotics Challenge  ARC  storage system  deep object perception pipeline  custom turntable capture system  transfer learning  robot arms  NimbRo Picking  stow-and-pick task  Task analysis  Training  Robot kinematics  Pipelines  Robot sensing systems  Semantics 
Abstract: Robotic picking from cluttered bins is a demanding task, for which Amazon Robotics holds challenges. The 2017 Amazon Robotics Challenge (ARC) required stowing items into a storage system, picking specific items, and packing them into boxes. In this paper, we describe the entry of team NimbRo Picking. Our deep object perception pipeline can be quickly and efficiently adapted to new items using a custom turntable capture system and transfer learning. It produces high-quality item segments, on which grasp poses are found. A planning component coordinates manipulation actions between two robot arms, minimizing execution time. The system has been demonstrated successfully at ARC, where our team reached second places in both the picking task and the final stow-and-pick task. We also evaluate individual components.


Title: Optical Sensing and Control Methods for Soft Pneumatically Actuated Robotic Manipulators
Key Words: elastomers  manipulators  mean square error methods  optical sensors  pneumatic actuators  regression analysis  strain data  chamber pressures  gravitational tip loading conditions  soft continuum robot  pressure data  base orientation  combined optical sensor  control methods  soft pneumatically actuated robotic  soft pneumatic manipulator motion  optically-diffuse elastomer sensors  strain mode  optical sensors measure local strains  axial center  optical sensing method  soft pneumatically actuated robotic manipulators  regression analyses  end-effector  Robot sensing systems  Optical fiber sensors  Optical fibers  Pneumatic systems 
Abstract: A low-cost optical sensing method for improved measurement and control of soft pneumatic manipulator motion is presented. The core of a soft continuum robot is embedded with several optically-diffuse elastomer sensors which attenuate light depending on their strain mode and degree. The optical sensors measure local strains at the robot's axial center, and these strain data are combined with measured actuator chamber pressures to determine the pose of the robot under various gravitational and tip loading conditions. Regression analyses using neural networks (NNs) demonstrate that when the soft continuum robot's base orientation is fixed, the position of its end-effector can be estimated with 3.42 times more accuracy (71 % smaller root mean squared error) when using both optical sensor and pressure data (~2.44mm) than when using only pressure data (~8.3mm). When the robot's base orientation was varied, the combined optical sensor and pressure data provide position estimates which are as much as 37.8 times more accurate (~2.76mm) than pressure data alone (~104mm).


Title: Modeling Driver Behavior from Demonstrations in Dynamic Environments Using Spatiotemporal Lattices
Key Words: collision avoidance  driver information systems  learning (artificial intelligence)  mobile robots  road vehicles  spatiotemporal lattices  path planners  intelligent vehicles  cost function  model parameters  demonstrated driving data  Inverse Reinforcement  IRL methods  forward control problem  traditional path-planning techniques  conformal spatiotemporal state lattice  dynamic obstacles  model assessment  IRL framework  highly dynamic environments  highway tactical driving task  instrumented vehicle  driver behavior modeling  Trajectory  Lattices  Task analysis  Spatiotemporal phenomena  Vehicle dynamics  Learning (artificial intelligence)  Cost function 
Abstract: One of the most challenging tasks in the development of path planners for intelligent vehicles is the design of the cost function that models the desired behavior of the vehicle. While this task has been traditionally accomplished by hand-tuning the model parameters, recent approaches propose to learn the model automatically from demonstrated driving data using Inverse Reinforcement Learning (IRL). To determine if the model has correctly captured the demonstrated behavior, most IRL methods require obtaining a policy by solving the forward control problem repetitively. Calculating the full policy is a costly task in continuous or large domains and thus often approximated by finding a single trajectory using traditional path-planning techniques. In this work, we propose to find such a trajectory using a conformal spatiotemporal state lattice, which offers two main advantages. First, by conforming the lattice to the environment, the search is focused only on feasible motions for the robot, saving computational power. And second, by considering time as part of the state, the trajectory is optimized with respect to the motion of the dynamic obstacles in the scene. As a consequence, the resulting trajectory can be used for the model assessment. We show how the proposed IRL framework can successfully handle highly dynamic environments by modeling the highway tactical driving task from demonstrated driving data gathered with an instrumented vehicle.


Title: Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
Key Words: decision making  human-robot interaction  intelligent transportation systems  learning (artificial intelligence)  probability  highway on-ramp-off-ramps  human-robot interaction policies  multimodal probabilistic model-based planning  traffic weaving scenario  human-in-the-loop simulation  candidate future robot actions  interaction history  action distributions  direct learning  candidate robot action sequences  human responses  massively parallel sampling  real-time robot policy construction  human-human exemplars  future human actions  multimodal probability distributions  inherent multimodal uncertainty  experienced drivers  entering exiting cars  decision making  Robots  Vehicles  Predictive models  History  Cognition  Probabilistic logic  Weaving 
Abstract: This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.


Title: AA-ICP: Iterative Closest Point with Anderson Acceleration
Key Words: iterative methods  PCL  Point Cloud Library  fixed point problem  ICP implementations  standard Picard iteration  iterative procedure  registration  scan-matching  Anderson acceleration  iterative closest point  AA-ICP  Iterative closest point algorithm  Acceleration  History  Convergence  Three-dimensional displays  Robots  Two dimensional displays 
Abstract: Iterative Closest Point (ICP) is a widely used method for performing scan-matching and registration. Being simple and robust, this method is still computationally expensive and may be challenging to use in real-time applications with limited resources on mobile platforms. In this paper we propose a novel effective method for acceleration of ICP which does not require substantial modifications to the existing code. This method is based on an idea of Anderson acceleration which is an iterative procedure for finding a fixed point of contractive mapping. The latter is often faster than a standard Picard iteration, usually used in ICP implementations. We show that ICP, being a fixed point problem, can be significantly accelerated by this method enhanced by heuristics to improve overall robustness. We implement proposed approach into Point Cloud Library (PCL) and make it available online. Benchmarking on the real-world data fully supports our claims.


Title: A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  biomimetics  control system synthesis  elastomers  electroactive polymer actuators  force control  mobile robots  motion control  remotely operated vehicles  velocity control  thrust force  actuation layers  fin-like dielectric elastomer actuator  DEA design  fish fins undulatory motions  tunable DEAs  soft actuators  autonomous planar swimming  actuator designs  swimming speed  vertical swimming  underwater operation  elastomers  autonomous mobility  AUV  miniature autonomous underwater vehicle  modular dielectric elastomer actuator  Aquatic robots  Power supplies  Propulsion  Dielectric elastomer actuators 
Abstract: In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.


Title: Proprioceptive-Inertial Autonomous Locomotion for Articulated Robots
Key Words: collision avoidance  feedback  force control  legged locomotion  motion control  parallel controller  bi-stable dynamical system  snake robot  unevenly-spaced obstacles  proprioceptive controller  legged locomotion  hexaprint robot  proprioceptive-inertial autonomous locomotion  articulated robots  proprioception  vestibular feedback  gait  force sensing  force feedback  Shape  Robot sensing systems  Snake robots  Legged locomotion  Force feedback  Robot motion 
Abstract: Inspired by the ability of animals to rely on proprioception and vestibular feedback to adapt their gait, we propose a modular framework for autonomous locomotion that relies on force sensing and inertial information. A first controller exploits anti-compliance, a new application of positive force feedback, to quickly react against obstacles upon impact. We hypothesize that, in situations where a robot experiences occasional impacts with the environment, anti-compliance can help negotiate unknown obstacles, similar to biological systems where positive feedback enables fast responses to external stimuli. A novel parallel controller, based on a bi-stable dynamical system, continuously adjusts the robot's direction of locomotion, and reverts it in reaction to major swerves. We present experimental results, demonstrating how our framework allows a snake robot to autonomously locomote through a row of unevenly-spaced obstacles. Finally, we extend our proprioceptive controller to legged locomotion, showing how a hexaprint robot can adapt its motion to climb over obstacles.


Title: Autonomous Bio-Inspired Small-Object Detection and Avoidance
Key Words: collision avoidance  Fourier analysis  helicopters  image sequences  mobile robots  navigation  object detection  robot vision  small-field motion-sensitive interneurons  insect visuomotor system  small-field object detection  artificial potential function-based low-order steering control law  small-field clutter  bio-inspired approach  autonomous robots  autonomous vehicles  bio-inspired navigation technique  Fourier residual analysis  instantaneous optic flow  Optical sensors  Optical imaging  Navigation  Biomedical optical imaging  Insects  Neurons 
Abstract: Small-object detection and avoidance in unknown environments is a significant challenge to overcome for small autonomous vehicles that are generally highly agile and restricted in payload and computational processing power. Typical machine-vision and range measurement based solutions suffer either from restricted fields-of-view or significant computational complexity and are not easily portable to small platforms. In this paper, a novel bio-inspired navigation technique is introduced that is modeled using analogues of the small-field motion-sensitive interneurons of the insect visuomotor system. The proposed technique achieves small-field object detection based on Fourier residual analysis of instantaneous optic flow. The small field signal is used to extract relative range and bearing of the nearest obstacle, which is then combined with an artificial potential function-based low-order steering control law. The proposed sensing and control scheme is experimentally validated with a quadrotor vehicle that is able to effectively navigate an unknown environment laden with small-field clutter. This bio-inspired approach is computationally efficient and serves as a robust, reflexive solution to the problem of small-object detection and avoidance for autonomous robots.


Title: PISRob: A Pneumatic Soft Robot for Locomoting Like an Inchworm
Key Words: actuators  bending  mobile robots  pneumatic actuators  pneumatic systems  inchworm-like locomotion  PISRob  pneumatic soft robot  pneumatic actuation  pneumatic system  soft climbing robots  soft parts  system development  Legged locomotion  Soft robotics  Pneumatic systems  Strain  Fabrication  Glass 
Abstract: Climbing or crawling robots may be widely applied in agriculture, forestry, military, construction industry, disaster searching and rescuing, and so on. Soft robots possess better safety, flexibility, dexterity, portability, and adaption to complex environments than traditional robots. However, there are big challenges in system development, modeling and control of soft climbing robots. To address system development of a soft robot as a new type climbing robot, we present a pneumatic soft robot capable of inchworm-like locomotion, PISRob. The presented robot is composed of three soft parts in H-shaped configuration. Each part is able to perform 2D bending. While the middle part, as the main body, can bend in Ω -shape for actuation, the two end parts as legs can conduct simple bending motion for grasping or anchoring during locomotion. The system design and fabrication process of the soft robot is presented in details in this paper. A control system is developed for pneumatic actuation of the robot. Tests are carried out to get the relationship between the actuating air pressure and the step length in locomotion. Experiments of crawling on a floor and climbing on a pole are performed to verify the feasibility of development of the new soft robot and the effectiveness of the control method for the pneumatic system.


Title: Continuous Growth in Plant-Inspired Robots Through 3D Additive Manufacturing
Key Words: agriculture  bending  bio-inspired materials  position control  rapid prototyping (industrial)  robots  three-dimensional printing  three-term control  plant-inspired robots  3D additive manufacturing  plant growth  3D printer-like mechanism  tubular body  material deposition process  turning behavior  filament height  position PID control algorithm  homogeneous structures  robust structures  continuous growth  plotting velocity  bending  Magnetic heads  Force  Robot sensing systems  Soil  Wires  Fingers 
Abstract: This paper presents a new material deposition strategy for developing a growing robot capable of building its own body. The growing robot is inspired by plant growth and is based on a 3D printer-like mechanism. The plotting of a filament near the tip allows the forward movement of the robot and results in building a tubular body. A material deposition process is introduced to perform a straight continuous growth as well as a turning behavior in order to permit the navigation of the robot in the environment. Bending is achieved by controlling the filament height in each position of the plotting, lowering or increasing plotting velocity with a position PID control algorithm. We demonstrate that the continuous deposition of the filament allows to obtain homogeneous and robust structures, with a significant improvement of the robot's performance compared to our previous version of the system (i.e., more than 100 N pulling force and 200 N shear force). The current version of the robot can sustain its weight, move efficiently by growing in the environment - both air and soil - and penetrate hard medium (up to 60kPa).


Title: Investigation of Scaling Effect of Copper Microwire Based on in-Situ Nanorobotic Twisting Inside SEM
Key Words: copper  deformation  fracture  manipulators  nanomechanics  nanostructured materials  plastic deformation  scanning electron microscopy  twinning  deformation intertwine  deformation twin  plastic deformation  assembly method  positioning method  scanning electron microscope  copper microwire in situ twisting test  micromaterial  scaling effects  nanomaterial  copper microwire sample fracture morphology  copper microwire specimen  degree-of-freedoms nanorobotic manipulator  nanorobotics manipulation system  copper microwire mechanical properties  scaling effect  microelectron mechanical systems  SEM  in-situ nanorobotic twisting  Cu  Copper  Scanning electron microscopy  Manipulators  Mechanical factors  Calibration 
Abstract: Copper microwire is an essential metal widely used in micro-electron mechanical systems. Since micro/nano material usually demonstrates unique mechanical properties due to scaling effect, copper microwire mechanical properties need to be investigated for better adhibition. Herein, we propose a nanorobotics manipulation system for copper microwire insitu twisting test. Firstly, a system with six degree-of-freedoms (DOFs) nanorobotic manipulator integrated inside scanning electron microscope (SEM) is introduced. Secondly, a positioning and assembly method for copper microwire specimen are proposed to solve the mismatching problem. Finally, the copper microwire is twisted in-situ and its properties are investigated and analyzed. The copper microwire sample fracture morphology shows a severe plastic deformation and being along with the emergence of deformation twin and intertwine, which exhibit strong scaling effects. This system provides a new method for in-situ twisting test, which paves the way for mechanical characterization inside SEM and benefits the fundamental nanomaterial research immensely.


Title: Teach-and-Replay of Mobile Robot with Particle Filter on Episode
Key Words: learning (artificial intelligence)  mobile robots  particle filtering (numerical methods)  robust control  mobile robot  reinforcement learning method  task teaching  micromouse type robot  Teach-and-Replay  PFoE  particle filter on episode  Robot sensing systems  Robot kinematics  Education  Hidden Markov models  Mobile robots  Task analysis 
Abstract: A novel method for replaying behavior of a mobile robot from its memory of past experiences is presented in this paper. The method is a version of a particle filter on episode (PFoE), which applies a particle filter on the memory so as to efficiently find some similar situations with the current one. Though the original PFoE was proposed as a reinforcement learning method, we once removed the reward system from the original one so as to apply it to task teaching. In the experiment, we gave several kinds of motion to a micromouse type robot with the proposed method through a gamepad. The robot replayed the behaviors robustly with sensor feedback after several number of repetitive teaching.


Title: Vision-Based Robotic Grasping and Manipulation of USB Wires
Key Words: closed loop systems  grippers  industrial manipulators  Lyapunov methods  peripheral interfaces  robot vision  stability  USB cables  vision-based controller  wire alignment  USB color code  vision-based robotic grasping  USB wires  two-level structure  dynamic stability  closed-loop system  Lyapunov methods  Wires  Universal Serial Bus  Robots  Grasping  Grippers  Strain  Image color analysis 
Abstract: The fast expanding 3C (Computer, Communication, and Consumer electronics) manufacturing leads to a high demand on the fabrication of USB cables. While several commercial machines have been developed to automate the process of stripping and soldering of USB cables, the operation of manipulating USB wires according to the color code is heavily dependent on manual works because of the deformation property of wires, probably resulting in the falling-off or the escape of wires during manipulation. In this paper, a new vision-based controller is proposed for robotic grasping and manipulation of USB wires. A novel two-level structure is developed and embedded into the controller, where Level-I is referred to as the grasping and manipulation of wires, and Level-II is referred to as the wire alignment by following the USB color code. The proposed formulation allows the robot to automatically grasp, manipulate, and align the wires in a sequential, simultaneous, and smooth manner, and hence to deal with the deformation of wires. The dynamic stability of the closed-loop system is rigorously proved with Lyapunov methods, and experiments are performed to validate the proposed controller.


Title: Vision-Based Global Localization Using Ceiling Space Density
Key Words: cameras  mobile robots  robot vision  service robots  home environments  free space density  available blueprint information  ceiling vision  robust localization information  robotic vacuum  superior localization results  vision-based global localization  ceiling space density  service robots  homes  self-localize  man-made constructions  documented blueprint  robot localization  smart home applications  movable objects  complicated task  horizontal range-finders  effective global localization approach  Cameras  Kernel  Three-dimensional displays  Robot vision systems  Simultaneous localization and mapping 
Abstract: Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.


Title: Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
Key Words: feature extraction  image segmentation  learning (artificial intelligence)  manipulators  neural nets  robot vision  multitask domain adaptation  deep learning  successful grasping probability  transfer learning framework  domain-adversarial loss  candidate motor command  specified target object  instance segmentation mask  monocular RGB images  neural network  cluttered scenes  instance grasping  robotic manipulation  Grasping  Robots  Adaptation models  Data models  Feature extraction  Image segmentation  Neural networks 
Abstract: Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.


Title: Learning Robotic Assembly from CAD
Key Words: CAD  industrial manipulators  learning (artificial intelligence)  mobile robots  path planning  production engineering computing  robotic assembly  suboptimal control  autonomous robotic assembly  industrial assembly tasks  contact-rich manipulation skills  motion planning approaches  robot controllers  reinforcement learning  robot skills  contact-rich dynamics  control policy  robot executions  locally suboptimal solutions  RL performance  CAD design files  geometric motion plan  CAD data  assembly controller  manufacturing trends  Task analysis  Planning  Robots  Trajectory  Tracking  Robotic assembly  Dynamics 
Abstract: In this work, motivated by recent manufacturing trends, we investigate autonomous robotic assembly. Industrial assembly tasks require contact-rich manipulation skills, which are challenging to acquire using classical control and motion planning approaches. Consequently, robot controllers for assembly domains are presently engineered to solve a particular task, and cannot easily handle variations in the product or environment. Reinforcement learning (RL) is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics. However, RL relies on random exploration for learning a control policy, which requires many robot executions, and often gets trapped in locally suboptimal solutions. Instead, we posit that prior knowledge, when available, can improve RL performance. We exploit the fact that in modern assembly domains, geometric information about the task is readily available via the CAD design files. We propose to leverage this prior knowledge by guiding RL along a geometric motion plan, calculated using the CAD data. We show that our approach effectively improves over traditional control approaches for tracking the motion plan, and can solve assembly tasks that require high precision, even without accurate state estimation. In addition, we propose a neural network architecture that can learn to track the motion plan, thereby generalizing the assembly controller to changes in the object positions.


Title: Accurate and Adaptive in Situ Fabrication of an Undulated Wall Using an on-Board Visual Sensing System
Key Words: buildings (structures)  CAD  geometry  mobile robots  reinforced concrete  robot vision  steel  structural engineering computing  walls  wires  in situ fabrication  visual sensing system  curved steel reinforced concrete wall  steel wire mesh  building construction  digital building process  CAD model  material deformations  geometry  mobile robot  vision-based sensing  load-bearing  building plan  Buildings  Robot sensing systems  Wires  Fabrication  Steel 
Abstract: In this paper we present a system for the in situ33In the context of building construction, “in situ” means that fabrication takes place at the structure's final location directly on the building site. fabrication of a full-scale, load-bearing, and doubly-curved steel reinforced concrete wall. Two complementary vision-based sensing systems provide the feedback necessary to build a 12 meter long steel wire mesh as part of a novel digital building process. The sensing systems provide estimates of the robot pose, referenced to the CAD model of the building site, as well as feedback on the accuracy of the built structure over the course of construction. This second piece of information is used to adapt the building plan to compensate for system inaccuracies and material deformations which occur during buildup. In this way, the structure was successfully built with 98% of the total geometry within 2 centimeters of the designed position. To the best of our knowledge, this is the largest structure which has been built by a mobile robot using solely vision-based sensing.


Title: Robot Assisted Carpentry for Mass Customization
Key Words: design engineering  furniture  mass production  mobile robots  product customisation  production engineering computing  mass customization  laymen editable templates  CNC fabrication  template based system  robotic fabrication system  mobile robots  standard carpentry tools  end-to-end design  template design  laymen users  robotics system  design tools  robot assisted carpentered items  Fabrication  Robots  Solid modeling  Tools  Standards  Face  Connectors 
Abstract: Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.


Title: A Fish-Like Magnetically Propelled Microswimmer Fabricated by 3D Laser Lithography
Key Words: bioMEMS  biomimetics  cell motility  hydrodynamics  laser materials processing  magnetic actuators  medical robotics  microfabrication  microorganisms  microrobots  nickel  permanent magnets  fish-like magnetically propelled microswimmer fabrication  glass substrate  detoxification tools  biosensing tools  fabricated microswimmers  permanent magnets  magnetic control system  external magnetic field  oscillating uniform magnetic field  magnetic actuation  caudal fin  3D laser lithography  size 50.0 nm  Ni  Magnetic fields  Magnetic domains  Magnetic heads  Magnetic flux  Magnetic resonance imaging  Propulsion 
Abstract: This paper presents the development of a fish-like magnetically propelled microswimmer fabricated by 3D laser lithography. The microswimmer consists of a head and a caudal fin, just like a natural fish. There is a joint between the head and the fin so that the caudal fin can oscillate around the head to generate thrust, and the oscillation of the fin hardly transfers to the head, which benefits the stable motion of the microswimmer. The caudal fin of the microswimmer is deposited with a layer of 50 nm nickel (Ni) for magnetic actuation. Through applying an oscillating uniform magnetic field, the microswimmer can move along with the direction guided by the external magnetic field. A magnetic control system with permanent magnets is designed to provide such an oscillating uniform magnetic field, where the oscillating frequency and amplitude are controllable. A micro probe operation platform is used to detach the fabricated microswimmers from glass substrate in manufacturing. The proposed magnetically propelled microswimmer can be potentially used as powerful detoxification and biosensing tools for medical diagnosis and treatment in precision medicine.


Title: Liftoff of a 190 mg Laser-Powered Aerial Vehicle: The Lightest Wireless Robot to Fly
Key Words: aerospace robotics  autonomous aerial vehicles  avionics  electronics packaging  feedback  microcontrollers  microrobots  mobile robots  power convertors  robot dynamics  wire tethers  high-voltage power electronics  severely constrained weight budgets  wireless liftoff  fast-turnaround laser based circuit fabrication technique  onboard electronics  high voltage bias  drive signals  insect scale aerial robots  aerial vehicle  power electronics package  wireless robot  laser-powered aerial vehicle  microcontroller  feedback control  mass 190.0 mg  mass 104.0 mg  wavelength 976.0 nm  Actuators  Insects  Microcontrollers  High-voltage techniques  Capacitors  Robot sensing systems 
Abstract: To date, insect scale aerial robots have required wire tethers for providing power due to the challenges of integrating the required high-voltage power electronics within their severely constrained weight budgets. In this paper we present a significant milestone in the achievement of flight autonomy: the first wireless liftoff of a 190 mg aerial vehicle. Our robot is remotely powered using a 976 nm laser and integrates a complete power electronics package weighing a total of 104 mg, using commercially available components and fabricated using a fast-turnaround laser based circuit fabrication technique. The onboard electronics include a lightweight boost converter capable of producing high voltage bias and drive signals of over 200 V at up to 170 Hz and regulated by a microcontroller performing feedback control. We present our system design and analysis, detailed description of our fabrication method, and results from flight experiments.


Title: Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms
Key Words: magnetic fields  medical robotics  microfluidics  microrobots  motion control  microscale devices  microrobotic devices  independent motions  magnetic elements  independent actuation  homogeneous magnetic field input  magnetic field signals  field generation source  magnetic microrobots  complex mechanism motions  multiagent mechanism motions  stationary devices  mobile devices  microfactories  microfluidic tools  medical procedures  remote applications  millimeter-scale robotic devices  magnetic mechanisms  degrees-of-freedom remote actuation  size 500.0 mum  size 0.6 mm  Magnetic resonance imaging  Magnetic devices  Magnetic moments  Torque  Mathematical model  Force  Wireless communication 
Abstract: Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 μm magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.


Title: Feature-Based SLAM for Imaging Sonar with Under-Constrained Landmarks
Key Words: feature extraction  image reconstruction  image sensors  reliability  SLAM (robots)  sonar imaging  sonar imaging  point landmark identification  feature-point extraction  general-purpose method  planar scene assumption  underwater feature-based SLAM  under-constrained landmarks  Feature extraction  Imaging  Sonar measurements  Simultaneous localization and mapping  Three-dimensional displays  Image reconstruction 
Abstract: Recent algorithms have demonstrated the feasibility of underwater feature-based SLAM using imaging sonar. But previous methods have either relied on manual feature extraction and correspondence or used prior knowledge of the scene, such as the planar scene assumption. Our proposed system provides a general-purpose method for feature-point extraction and correspondence in arbitrary scenes. Additionally, we develop a method of identifying point landmarks that are likely to be well-constrained and reliably reconstructed. Finally, we demonstrate that while under-constrained landmarks cannot be accurately reconstructed themselves, they can still be used to constrain and correct the sensor motion. These advances represent a large step towards general-purpose, feature-based SLAM with imaging sonar.


Title: SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
Key Words: augmented reality  autonomous aerial vehicles  mobile computing  mobile robots  navigation  robot vision  SLAM (robots)  visual SLAM  augmented reality systems  nonfunctional requirements  mobile phone-based AR application  tight energy budget  UAV navigation system  SLAMBench2  benchmarking framework  open source  close source  performance metrics  ORB-SLAM2  publicly-available software framework  SLAM applications  SLAM systems  SLAM algorithms  multiobjective head-to-head benchmarking  functional requirements  Simultaneous localization and mapping  Measurement  Trajectory  Benchmark testing  User interfaces  C++ languages 
Abstract: SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.


Title: Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition
Key Words: cameras  feature extraction  image matching  image representation  image sequences  mobile robots  neural nets  object recognition  path planning  robot vision  SLAM (robots)  semantics-aware higher-order layers  deep neural networks  pure appearance-based techniques  place categorization  place-centric characteristics  condition-invariant place recognition  rear view mirror  semantic visual understanding  visual places  Semantics  Visualization  Robustness  Databases  Image recognition  Cameras  Neural networks 
Abstract: When a human drives a car along a road for the first time, they later recognize where they are on the return journey typically without needing to look in their rear view mirror or turn around to look back, despite significant viewpoint and appearance change. Such navigation capabilities are typically attributed to our semantic visual understanding of the environment [1] beyond geometry to recognizing the types of places we are passing through such as “passing a shop on the left” or “moving through a forested area”. Humans are in effect using place categorization [2] to perform specific place recognition even when the viewpoint is 180 degrees reversed. Recent advances in deep neural networks have enabled high performance semantic understanding of visual places and scenes, opening up the possibility of emulating what humans do. In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM [3]. Using two different datasets - one road-based, one pedestrian-based, we evaluate the performance of the system in performing place recognition on reverse traversals of a route with a limited field of view camera and no turn-back-and-Iook behaviours, and compare to existing state-of-the-art techniques and vanilla off-the-shelf features. The results demonstrate significant improvements over the existing state of the art, especially for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change. We also provide experimental analyses of the contributions of the various system components: the use of spatio-temporal sequences, place categorization and place-centric characteristics as opposed to object-centric semantics.


Title: Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities
Key Words: mobile robots  navigation  optical information processing  optical radar  path planning  robot vision  intensity information  DELIGHT  distributed histograms  chi-squared tests  two-stage solution  geometry-based verification  range information  GPS-denied areas  robot position  kidnapped robot problems  mobile robotics  place recognition  global localisation  intensity-based prior estimation  LiDAR intensities  Laser radar  Histograms  Three-dimensional displays  Simultaneous localization and mapping 
Abstract: Place recognition is a key element of mobile robotics. It can assist with the “wake-up” and “kidnapped robot” problems, where the robot position needs to be estimated without prior information. Among the different sensors that can be used for the task (e.g., camera, GPS, LiDAR), LiDAR has the advantage of operating in the dark and in GPS-denied areas. We propose a new method that uses solely the LiDAR data and that can be performed without robot motion. In contrast to other methods, our system leverages intensity information (as opposed to only range information) which is encoded into a novel descriptor of LiDAR intensities as a group of histograms, named DELIGHT. The descriptor encodes the distributed histograms of intensity of the surroundings which are compared using chi-squared tests. Our pipeline is a two-stage solution consisting of an intensity-based prior estimation and a geometry-based verification. For a map of 220k square meters, the method achieves localisation in around 3s with a success rate of 97%, illustrating the applicability of the method in real environments.


Title: The Dynamic Bearing Observability Matrix Nonlinear Observability and Estimation for Multi-Agent Systems
Key Words: geometry  group theory  Kalman filters  Lie groups  matrix algebra  multi-agent systems  multi-robot systems  nonlinear filters  multiagent formations  dynamic agents  algebraic properties  first-order derivatives  nonlinear observability theory  higher order derivatives  localization problem  dynamic bearing observability matrix nonlinear observability  multiagent systems  rigidity matrix  Observability  Robot sensing systems  Geometry  Manifolds  Cameras  Estimation 
Abstract: We consider the problem of localization in multiagent formations with bearing only measurements, and analyze the fundamental observability properties for dynamic agents. The current well-established approach is based on the socalled rigidity matrix, and its algebraic properties (e.g., its rank and nullspace). This method is typically motivated using first-order derivatives, and shows, among other facts, that the global scale of the formation is not observable. This work shows that current results represent an incomplete view of the problem. In particular, we show that 1) current methods are a particular instantiation of nonlinear observability theory, 2) we can introduce the concept of the dynamic bearing observability matrix from higher order derivatives to study the observability of dynamic formations, and 3) the global scale is, in fact, generally observable when the agents move according to known inputs. We use tools from Riemannian geometry and Lie group theory to tackle, in a general and principled way, the general formulation of the localization problem with states that include both rotations and translations. Finally, we verify our theoretical results by deriving and applying, in both simulations and real experiments on UAVs, a centralized Extended Kalman Filter on Lie groups that is able to estimate the global scale of a moving formation.


Title: CDDT: Fast Approximate 2D Ray Casting for Accelerated Localization
Key Words: data structures  mobile robots  particle filtering (numerical methods)  ray tracing  table lookup  constant time ray casting performance  particle filter algorithm  resource-constrained mobile robots  localization approach  approximate 2D ray casting  mobile robot  compressed directional distance transform  two dimensional occupancy grid maps  autonomous robots  three dimensional lookup table  frequency 40.0 Hz  Casting  Table lookup  Robot sensing systems  Transforms  Approximation algorithms  Memory management  Acceleration 
Abstract: Localization is an essential component for autonomous robots. A well-established localization approach combines ray casting with a particle filter, leading to a computationally expensive algorithm that is difficult to run on resource-constrained mobile robots. We present a novel data structure called the Compressed Directional Distance Transform for accelerating ray casting in two dimensional occupancy grid maps. Our approach allows online map updates, and near constant time ray casting performance for a fixed size map, in contrast with other methods exhibit poor worst case performance. Our experimental results show that the proposed algorithm approximates the performance characteristics of reading from a three dimensional lookup table of ray cast solutions while requiring two orders of magnitude less memory and precomputation. This results in a particle filter algorithm which can maintain 2500 particles with 61 ray casts per particle at 40Hz, using a single CPU thread onboard a mobile robot.


Title: Towards Globally Consistent Visual-Inertial Collaborative SLAM
Key Words: autonomous aerial vehicles  mobile robots  path planning  robot vision  SLAM (robots)  globally consistent tracking  autonomous robot navigation  monocular-inertial odometry  vision-based perception  metric scale estimation  benchmarking datasets  UAVs  monocular-inertial sensor suite  unmanned aerial vehicles  visual-inertial collaborative SLAM  drift correction  Simultaneous localization and mapping  Collaboration  Unmanned aerial vehicles  Optimization  Measurement  Trajectory 
Abstract: Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.


Title: Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing
Key Words: approximation theory  Monte Carlo methods  multi-robot systems  normal distribution  optimisation  probability  independent normally distributed random events  conditional probability distributions  multirobot task allocation problems  deterministic method  optimisation method  travel times  task durations  approximation methods  resource contention modelling  Robots  Task analysis  Uncertainty  Probability distribution  Random variables  Resource management 
Abstract: This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.


Title: Constrained-Action POMDPs for Multi-Agent Intelligent Knowledge Distribution
Key Words: decision theory  intelligent control  Markov processes  Monte Carlo methods  multi-agent systems  multi-robot systems  optimal control  optimisation  multiagent intelligent knowledge distribution  infinite-horizon policy  minimal constraint guarantees  constraint analysis  information content  Markov chain Monte Carlo analysis  probabilistic constraint satisfaction  partially observable Markov decision processes  action-based constraints  multiagent coordination  multiagent systems  communication requirements  constrained-action POMDPs  Markov processes  Collaboration  Monte Carlo methods  Bandwidth  Proposals  Entropy  Power capacitors 
Abstract: This paper addresses a fundamental question of multi-agent knowledge distribution: what information should be sent to whom and when, with the limited resources available to each agent? Intelligent Knowledge Distribution is a framework that answers these questions. Communication requirements for multi-agent systems can be rather high when an accurate picture of the environment and the state of other agents must be maintained. To reduce the impact of multi-agent coordination on systems, including communications, this paper introduces the concept of action-based constraints on partially observable Markov decision processes, rewards based upon the value of information driven by Kullback-Leibler Divergence, and probabilistic constraint satisfaction through discrete optimization and Markov chain Monte Carlo analysis. Intelligent Knowledge Distribution is driven by determining the information content an agent believes another agent will obtain by receiving certain information, along with the importance or relevance of that information to the system objective. To perform constraint analysis on an infinite-horizon policy, policies are represented as a Finite State Controller allowing Markov chain Monte Carlo analysis to determine a probabilistic level of guarantee that the constraints will be satisfied. The analysis of performance for an example mission presented in this paper shows the constrained controllers, during the highest constraint seen in simulations, can be constructed to meet minimal constraint guarantees (80%) while impacting the optimal value less than 50%, where the unconstrained optimal controller only satisfied the constraint 10% of the time.


Title: Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
Key Words: mobile robots  multi-robot systems  path planning  probability  potential contingency task  multirobot mission planning  expected mission completion time  probability  Task analysis  Robot kinematics  Uncertainty  Schedules  Marine vehicles  Resource management 
Abstract: In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.


Title: Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking
Key Words: computational complexity  distributed control  multi-robot systems  target tracking  O(hlog1/ε) communication rounds  distributed simultaneous action  multirobot multitarget tracking  multirobot assignment problems  Robot sensing systems  Target tracking  Approximation algorithms  Partitioning algorithms 
Abstract: We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/ε) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.


Title: How to Make Fat Autonomous Robots See all Others Fast?
Key Words: collision avoidance  computational complexity  deterministic algorithms  distributed algorithms  mobile robots  multi-robot systems  scheduling  fat autonomous robots  coordination problems  autonomous mobile robots  distributed robotics community  convex hull  nontransparent fat robots  deterministic distributed algorithm  semisynchronous scheduler  Robot kinematics  Fats  Cogeneration  Collision avoidance  Runtime  Computational modeling 
Abstract: The coordination problems arising in a team of autonomous mobile robots have received a lot of attention in the distributed robotics community. Along those lines, we study in this paper the problem of coordinating autonomous mobile robots to reposition on a convex hull so that each robot sees all others. In particular, we consider non-transparent fat robots operating in the 2-dimensional plane. They are abstracted as unit discs and they make local decisions with vision being the only mean of coordination among them. We develop a (deterministic) distributed algorithm that solves the problem for a team of N ≥ 3 fat robots in O(N) time avoiding collisions under the semi-synchronous scheduler. The main idea is to enforce the robots to reach a configuration in which (i) the robots' centers form a convex hull; (ii) all robots are on the convex hull's boundary; and (iii) each robot can see all other robots. The result is achieved assuming some reasonable conditions on the input configuration and showing that starting from any input configuration that satisfies our conditions, robots reach such a configuration in linear time and terminate.


Title: A Synchronization Scheme for Position Control of Multiple Rope-Climbing Robots
Key Words: actuators  asymptotic stability  manipulators  mobile robots  multi-robot systems  position control  robot dynamics  singularly perturbed systems  single rope-climbing robot  multiple rope-climbing robots  position control  Robot kinematics  Synchronization  Task analysis  Actuators  Mathematical model  Position control  multiple Rope-Climbing Robots  climbing robots  motion control 
Abstract: The ability of rope-climbing robots in aloft operation is limited by its self-supporting and locomotion ability. In many applications, a given task is also too complex to be achieved by a single rope-climbing robot acting alone. The solution of multiple rope-climbing robots can overcome the limitations. However, existing control methods for rope-climbing robots are limited to single robot, and the open issue of coordination between multiple rope-climbing robots has not been systematically addressed. This paper presents a new synchronization scheme for position control of multiple rope-climbing robots, such that each robot moves to the corresponding desired position while synchronizing the heights between each other. Maintaining the same height is very important to guarantee the stability of the task-oriented manipulator installed among multiple robots, when it is performing the manipulation task. The development of the proposed controller is based on the singular perturbation approach, by treating the fast actuator dynamics as a perturbation of the slow robot dynamics, such that the lowest control complexity is achieved. The exponential stability of the overall system that consists of the fast and slow subsystems is proved by using Tikhonov' s theorem. Experimental results are presented to illustrate the performance of the proposed controller.


Title: Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching
Key Words: grippers  image classification  image matching  object recognition  robot vision  robotic pick-and-place  image classification framework  2017 Amazon Robotics Challenge  MIT-Princeton Team system  category-agnostic affordance prediction algorithm  cross-domain image matching  Grasping  Robots  Clutter  Grippers  Robustness  Proposals  Task analysis 
Abstract: This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select and execute among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu.


Title: Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration
Key Words: learning (artificial intelligence)  manipulators  recurrent neural nets  robot vision  nonprehensile manipulation  recurrent neural network  raw images  VAE-GAN-based reconstruction  autoregressive multimodal action prediction  complex manipulation tasks  towel  weight  reconstruction-based regularization  vision-based multitask manipulation  end-to-end learning  multitask learning  low-cost robotic arm  robot arm trajectories  complex picking and placing tasks  Task analysis  Robots  Feature extraction  Neural networks  Image reconstruction  Training  Visualization 
Abstract: We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.


Title: Learning 6-DOF Grasping Interaction via Deep Geometry-Aware 3D Representations
Key Words: convolution  dexterous manipulators  geometry  grippers  image reconstruction  image representation  intelligent robots  learning (artificial intelligence)  optimisation  recurrent neural nets  virtual reality  outcome prediction model  3D shape modeling  DGGN  analysis-by-synthesis optimization  6-DOF grasping net  virtual reality  sensory annotations  data augmentation strategy  CNN  3D occupancy grid  mental geometry-aware representation  deep geometry-aware grasping network  3D geometry prediction  grasping interaction learning  parallel jaw gripper  RGBD input  internal geometry-aware representation  Grasping  Three-dimensional displays  Shape  Geometry  Solid modeling  Two dimensional displays  Robots 
Abstract: This paper focuses on the problem of learning 6- DOF grasping with a parallel jaw gripper in simulation. Our key idea is constraining and regularizing grasping interaction learning through 3D geometry prediction. We introduce a deep geometry-aware grasping network (DGGN) that decomposes the learning into two steps. First, we learn to build mental geometry-aware representation by reconstructing the scene (i.e., 3D occupancy grid) from RGBD input via generative 3D shape modeling. Second, we learn to predict grasping outcome with its internal geometry-aware representation. The learned outcome prediction model is used to sequentially propose grasping solutions via analysis-by-synthesis optimization. Our contributions are fourfold: (1) To best of our knowledge, we are presenting for the first time a method to learn a 6-DOF grasping net from RGBD input; (2) We build a grasping dataset from demonstrations in virtual reality with rich sensory and interaction annotations. This dataset includes 101 everyday objects spread across 7 categories, additionally, we propose a data augmentation strategy for effective learning; (3) We demonstrate that the learned geometry-aware representation leads to about 10% relative performance improvement over the baseline CNN on grasping objects from our dataset. (4) We further demonstrate that the model generalizes to novel viewpoints and object instances.


Title: Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions
Key Words: industrial robots  interactive systems  learning (artificial intelligence)  manipulators  natural language interfaces  natural language processing  object detection  robot vision  natural language processing technologies  unconstrained spoken instructions  instruction ambiguity  physical industrial robot arm  natural instructions  object picking task  real-world objects  unconstrained spoken language instructions  spoken natural language  human instructions  comprehensive system  Task analysis  Object recognition  Natural languages  Object detection  Feature extraction  Service robots 
Abstract: Comprehension of spoken natural language is an essential skill for robots to communicate with humans effectively. However, handling unconstrained spoken instructions is challenging due to (1) complex structures and the wide variety of expressions used in spoken language, and (2) inherent ambiguity of human instructions. In this paper, we propose the first comprehensive system for controlling robots with unconstrained spoken language, which is able to effectively resolve ambiguity in spoken instructions. Specifically, we integrate deep learning-based object detection together with natural language processing technologies to handle unconstrained spoken instructions, and propose a method for robots to resolve instruction ambiguity through dialogue. Through our experiments on both a simulated environment as well as a physical industrial robot arm, we demonstrate the ability of our system to understand natural instructions from human operators effectively, and show how higher success rates of the object picking task can be achieved through an interactive clarification process.


Title: Translating Videos to Commands for Robotic Manipulation with Deep Recurrent Neural Networks
Key Words: control engineering computing  convolution  feature extraction  feedforward neural nets  humanoid robots  mobile robots  recurrent neural nets  video signal processing  feature extraction  video translation  CNN  RNN  full-size humanoid robot WALK-MAN  manipulation tasks  translation module  visual features  encoder-decoder architecture  RNN layers  deep Convolutional Neural Networks  input video frames  deep features  command  Deep Recurrent Neural Networks  robotic manipulation  Videos  Robots  Feature extraction  Task analysis  Visualization  Recurrent neural networks  Logic gates 
Abstract: We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks (RNN). Our framework first extracts deep features from the input video frames with a deep Convolutional Neural Networks (CNN). Two RNN layers with an encoder-decoder architecture are then used to encode the visual features and sequentially generate the output words as the command. We demonstrate that the translation accuracy can be improved by allowing a smooth transaction between two RNN layers and using the state-of-the-art feature extractor. The experimental results on our new challenging dataset show that our approach outperforms recent methods by a fair margin. Furthermore, we combine the proposed translation module with the vision and planning system to let a robot perform various manipulation tasks. Finally, we demonstrate the effectiveness of our framework on a full-size humanoid robot WALK-MAN.


Title: Distributed Learning for the Decentralized Control of Articulated Mobile Robots
Key Words: decentralised control  distributed control  learning systems  mobile robots  multi-agent systems  highly cluttered evaluation environments  decentralized control architectures  central pattern generators  spatially distributed portions  articulated bodies  system-level objectives  reinforcement learning  independent agents  parallel environments  meta-level agent  homogeneous decentralized control  articulated locomotion  distributed learning  asynchronous advantage actor-critic algorithm  A3C  decentralized control policies  independently controlled portion  autonomous decentralized compliant control framework  compliant control baseline  articulated mobile robots  Shape  Decentralized control  Aerospace electronics  Robot kinematics  Admittance  Hardware 
Abstract: Decentralized control architectures, such as those conventionally defined by central pattern generators, independently coordinate spatially distributed portions of articulated bodies to achieve system-level objectives. State of the art distributed algorithms for reinforcement learning employ a different but conceptually related idea; independent agents simultaneously coordinating their own behaviors in parallel environments while asynchronously updating the policy of a system-or, rather, meta-level agent. This work, to the best of the authors' knowledge, is the first to explicitly explore the potential relationship between the underlying concepts in homogeneous decentralized control for articulated locomotion and distributed learning. We present an approach that leverages the structure of the asynchronous advantage actor-critic (A3C) algorithm to provide a natural framework for learning decentralized control policies on a single platform. Our primary contribution shows an individual agent in the A3C algorithm can be defined by an independently controlled portion of the robot's body, thus enabling distributed learning on a single platform for efficient hardware implementation. To this end, we show how the system is trained offline using hardware experiments implementing an autonomous decentralized compliant control framework. Our experimental results show that the trained agent outperforms the compliant control baseline by more than 40% in terms of steady progression through a series of randomized, highly cluttered evaluation environments.


Title: Neural Task Programming: Learning to Generalize Across Hierarchical Tasks
Key Words: learning (artificial intelligence)  manipulators  neural nets  neural task programming  unseen tasks  sequential tasks  robot manipulation tasks  bottom-level programs  hierarchical neural program  finer sub-task specifications  task specification  neural program induction  few-shot learning  NTP  novel robot learning framework  hierarchical tasks  Task analysis  Programming  Robots  Sorting  Semantics  Topology  Data models 
Abstract: In this work, we propose a novel robot learning framework called Neural Task Programming (NTP), which bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well towards unseen tasks with increasing lengths, variable topologies, and changing objectives.stanfordvl.github.io/ntp/.


Title: Sim-to-Real Transfer of Robotic Control with Dynamics Randomization
Key Words: calibration  mobile robots  multi-agent systems  multi-robot systems  robot dynamics  sim-to-real transfer  robotic control  dynamics randomization  training agents  training process  robotic arm  calibration error  Robots  Training  Adaptation models  Task analysis  Trajectory  Data models  Robustness 
Abstract: Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.


Title: Topomap: Topological Mapping and Navigation Based on Visual SLAM Maps
Key Words: mobile robots  navigation  path planning  robot vision  SLAM (robots)  three-dimensional topological map  noisy sparse point cloud  convex free-space clusters  global planning  mobile robotic platform  Topomap  visual SLAM  visual robot navigation  navigation task  sparse feature-based map  path planning algorithms  visual simultaneous localization and mapping system  Navigation  Visualization  Simultaneous localization and mapping  Path planning  Three-dimensional displays  Planning 
Abstract: Visual robot navigation within large-scale, semistructured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many state-of-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages.


Title: PIRVS: An Advanced Visual-Inertial SLAM System with Flexible Sensor Fusion and Hardware Co-Design
Key Words: cameras  image fusion  robot vision  SLAM (robots)  stereo image processing  synchronisation  embedded simultaneous localization and mapping algorithm  multi-core processor  public visual-inertial datasets  PerceptIn Robotics Vision System  Hardware Co-Design  advanced visual-inertial SLAM System  state-of-the-art visual-inertial algorithms  additional sensor modalities  inertial measurements  visual measurements  flexible sensor fusion approach  PIRVS software features  precise hardware synchronization  global-shutter stereo camera  PIRVS hardware  visual-inertial computing hardware  Simultaneous localization and mapping  Hardware  Cameras  Feature extraction  Synchronization  Visualization 
Abstract: In this paper, we present the PerceptIn Robotics Vision System (PIRVS), a visual-inertial computing hardware with embedded simultaneous localization and mapping (SLAM) algorithm. The PIRVS hardware is equipped with a multi-core processor, a global-shutter stereo camera, and an IMU with precise hardware synchronization. The PIRVS software features a flexible sensor fusion approach to not only tightly integrate visual measurements with inertial measurements and also to loosely couple with additional sensor modalities. It runs in real-time on both PC and the PIRVS hardware. We perform a thorough evaluation of the proposed system using multiple public visual-inertial datasets. Experimental results demonstrate that our system reaches comparable accuracy of state-of-the-art visual-inertial algorithms on PC, while being more efficient on the PIRVS hardware.


Title: ProSLAM: Graph SLAM from a Programmer's Perspective
Key Words: C++ language  data structures  graph theory  public domain software  robot vision  SLAM (robots)  stereo image processing  Graph SLAM  data structures  C++ programming language  standard libraries  lightweight open-source stereo visual SLAM system  programmer  ProSLAM  algorithmic aspects  mathematical aspects  highly modular system  Simultaneous localization and mapping  Visualization  Three-dimensional displays  Cameras  Data structures  Benchmark testing 
Abstract: In this paper we present ProSLAM, a lightweight open-source stereo visual SLAM system designed with simplicity in mind. This work stems from the experience gathered by the authors while teaching SLAM and aims at providing a highly modular system that can be easily implemented and understood. Rather than focusing on the well known mathematical aspects of stereo visual SLAM, we highlight the data structures and the algorithmic aspects required to realize such a system. We implemented ProSLAM using the C++ programming language in combination with a minimal set of standard libraries. The results of a thorough validation performed on several standard benchmark datasets show that ProSLAM achieves precision comparable to state-of-the-art approaches, while requiring substantially less computation.


Title: Talk Resource-Efficiently to Me: Optimal Communication Planning for Distributed Loop Closure Detection
Key Words: mobile robots  multi-robot systems  robot vision  SLAM (robots)  cooperative simultaneous localization and mapping  inter-robot loop closures  general resource-efficiency communication planning  sensory data sharing  distributed loop closure detection  optimal communication planning  CSLAM  Robot sensing systems  Distributed databases  Planning  Trajectory  Visualization  Metadata 
Abstract: Due to the distributed nature of cooperative simultaneous localization and mapping (CSLAM), detecting inter-robot loop closures necessitates sharing sensory data with other robots. A naïve approach to data sharing can easily lead to a waste of mission-critical resources. This paper investigates the logistical aspects of CSLAM. Particularly, we present a general resource-efficient communication planning framework that takes into account both the total amount of exchanged data and the induced division of labor between the participating robots. Compared to other state-of-the-art approaches, our framework is able to verify the same set of potential inter-robot loop closures while exchanging considerably less data and influencing the induced workloads. We develop a fast algorithm for finding globally optimal communication policies, and present theoretical analysis to characterize the necessary and sufficient conditions under which simpler strategies are optimal. The proposed framework is extensively evaluated with data from the KITTI odometry benchmark datasets.


Title: StaticFusion: Background Reconstruction for Dense RGB-D SLAM in Dynamic Environments
Key Words: cameras  image colour analysis  image filtering  image motion analysis  image reconstruction  image segmentation  image sensors  image sequences  motion estimation  object detection  object tracking  pose estimation  probability  robot vision  SLAM (robots)  frame-to-model alignment  3D model estimation  outlier filtering techniques  moving object detection  camera pose tracking  probabilistic static-dynamic segmentation  background structure reconstruction  dynamic scenes  static environments  dynamic sequences  static sequences  camera motion estimation  weighted dense RGB-D fusion  current RGB-D image pair  implicit robust penalisers  background structure  robust dense RGB-D SLAM  visual SLAM  dynamic environments  Cameras  Robustness  Image segmentation  Motion segmentation  Dynamics  Three-dimensional displays  Image reconstruction 
Abstract: Dynamic environments are challenging for visual SLAM as moving objects can impair camera pose tracking and cause corruptions to be integrated into the map. In this paper, we propose a method for robust dense RGB-D SLAM in dynamic environments which detects moving objects and simultaneously reconstructs the background structure. While most methods employ implicit robust penalisers or outlier filtering techniques in order to handle moving objects, our approach is to simultaneously estimate the camera motion as well as a probabilistic static/dynamic segmentation of the current RGB-D image pair. This segmentation is then used for weighted dense RGB-D fusion to estimate a 3D model of only the static parts of the environment. By leveraging the 3D model for frame-to-model alignment, as well as static/dynamic segmentation, camera motion estimation has reduced overall drift - as well as being more robust to the presence of dynamics in the scene. Demonstrations are presented which compare the proposed method to related state-of-the-art approaches using both static and dynamic sequences. The proposed method achieves similar performance in static environments and improved accuracy and robustness in dynamic scenes.


Title: Vision Based Collaborative Path Planning for Micro Aerial Vehicles
Key Words: cameras  collision avoidance  covariance matrices  mobile robots  optimisation  path planning  robot vision  trees (mathematics)  microaerial vehicles  collaborative path-planning framework  localization uncertainty  two-step planning framework  visual-fidelity aerial vehicle simulator  Planning  Uncertainty  Cameras  Three-dimensional displays  Collaboration  Optimization  Path planning 
Abstract: In this paper, we present a collaborative path-planning framework for a group of micro aerial vehicles that are capable of localizing through vision. Each of the micro aerial vehicles is assumed to be equipped with a forward facing monocular camera. The vehicles initially use their captured images to build 3D maps through common features; and subsequently track these features to localize through 3D-2D correspondences. The planning algorithm, while connecting start locations to provided goal locations, also aims to reduce the localization uncertainty of the vehicles in the group. To achieve this, we develop a two-step planning framework: the first step attempts to build an improved map of the environment by solving the next-best-view problem for multiple cameras. We express this as a black-box optimization problem and solve it using the Covariance Matrix Adaption evolution strategy (CMA-ES). Once an improved map is available, the second stage of the planning framework performs belief space planning for the vehicles individually using the rapidly exploring random belief tree (RRBT) algorithm. Through the RRBT approach, the planner generates paths that ensure feature visibility while attempting to optimize path cost and reduce localization uncertainty. We validate our approach using experiments conducted in a high visual-fidelity aerial vehicle simulator, Microsoft AirSim.


Title: Semi-Dense Visual-Inertial Odometry and Mapping for Quadrotors with SWAP Constraints
Key Words: helicopters  inertial navigation  mobile robots  path planning  robot vision  state estimation  stereo image processing  semidense visual-inertial odometry  quadrotors  SWAP constraints  autonomous navigation capabilities  dense 3D maps  indoor environments  visual inertial state estimation  microaerial vehicles  size, weight, and power constraints  stereo camera  Cameras  Three-dimensional displays  Visual odometry  Optimization  Navigation  Robot vision systems 
Abstract: Micro Aerial Vehicles have the potential to assist humans in real life tasks involving applications such as smart homes, search and rescue, and architecture construction. To enhance autonomous navigation capabilities these vehicles need to be able to create dense 3D maps of the environment, while concurrently estimating their own motion. In this paper, we are particularly interested in small vehicles that can navigate cluttered indoor environments. We address the problem of visual inertial state estimation, control and 3D mapping on platforms with Size, Weight, And Power (SWAP) constraints. The proposed approach is validated through experimental results on a 250 g, 22 cm diameter quadrotor equipped only with a stereo camera and an IMU with a computationally-limited CPU showing the ability to autonomously navigate, while concurrently creating a 3D map of the environment.


Title: Real-Time Image-Guided Cooperative Robotic Assist Device for Deep Anterior Lamellar Keratoplasty
Key Words: biomechanics  biomedical equipment  biomedical optical imaging  eye  manipulators  medical robotics  optical tomography  surgery  robot arm  graft rejection risk  chronic immunosuppression comorbidities  corneal transplantation  promising technique  deep anterior lamellar keratoplasty  time image-guided cooperative robotic  perforation-free needle depth  DALK needle insertions  real-time OCT segmentation  posterior corneal boundary virtual fixture  optical coherence tomography imaging  robot-assisted solution  inadequate needle depth  Needles  Surgery  Robot sensing systems  Visualization  Tools  Cornea  Cooperative control  medical robotics 
Abstract: Deep anterior lamellar keratoplasty (DALK) is a promising technique for corneal transplantation that avoids the chronic immunosuppression comorbidities and graft rejection risk associated with penetrating keratoplasty (PKP), the standard procedure. In DALK, surgeons must insert a needle 90% through the 500 μm cornea without penetrating its underlying membrane. This pushes surgeons to their manipulation and visualization limits such that 59% of DALK attempts fail due to corneal perforation or inadequate needle depth. We propose a robot-assisted solution to jointly solve the manipulation and visualization challenges using a cooperatively-controlled, precise robot arm and live optical coherence tomography (OCT) imaging, respectively. Our system features an interface handle, with which the surgeon and robot cooperatively hold the tool, and a posterior corneal boundary virtual fixture driven by real-time OCT segmentation. A study in which three operators performed DALK needle insertions manually and cooperatively in ex vivo human corneas demonstrated an 84% improvement in perforation-free needle depth without an increased perforation rate.


Title: Hall Effect Sensing Workspace Estimation with Non-Permanent Magnetic Needle for Eye Anesthesia Training System via Robotic Experiments
Key Words: eye  Hall effect devices  Kalman filters  manipulators  medical robotics  needles  position control  sensor arrays  sensors  surgery  Hall effect sensing workspace  nonpermanent magnetic needle  eye anesthesia training system  robotic experiments  eye surgery  needle tip tracking system  ophthalmic anesthesia training  anesthesia needle  magnetized needle tip  Hall-effect sensor array  orbital structure model  Hall-effect sensors  ophthalmic anesthesia pathway  needle tip position  commercial robotic manipulator  developed system  Needles  Robot sensing systems  Magnetic flux  Anesthesia  Orbits 
Abstract: Ophthalmic anesthesia is an important preparation for eye surgery. The conventional practice is performed blind in a cadaver under the supervision of an experienced surgeon. This paper introduces a needle tip tracking system for ophthalmic anesthesia training without major modification of an anesthesia needle. The study presents a prototyped system to track a magnetized needle tip using Hall-effect sensor array. The orbital structure model was embedded with Hall-effect sensors after considering the sensing workspace and ophthalmic anesthesia pathway. The extended Kalman filter was used to calculate needle tip position. A commercial robotic manipulator was used to model the characteristics of sensor and accuracy of the developed system. A prototype can detect needle tip position with a root-mean-square deviation around 1.80 mm. As a result, the system is capable of providing needle tip positions for training purposes.


Title: Precision Needle Tip Localization Using Optical Coherence Tomography Images for Subretinal Injection
Key Words: biological tissues  biomedical equipment  biomedical optical imaging  eye  medical image processing  medical robotics  needles  optical tomography  surgery  robot-assisted subretinal injection  needle tip localization  microsurgery  microscope-integrated intraoperative optical coherence tomography  insertion depth  subretinal visual feedback  optical coherence tomography images  Needles  Retina  Surgery  Microscopy  Robots  Probes 
Abstract: Subretinal injection is a delicate and complex microsurgery, which requires surgeons to inject the therapeutic substance in a pre-operatively defined and intra-operatively updated subretinal target area. Due to the lack of subretinal visual feedback, it is hard to sense the insertion depth during the procedure, thus affecting the results of surgical outcome and hindering the widespread use of this treatment. This paper presents a novel approach to estimate the 3D position of the needle under the retina using the information from microscope-integrated Intraoperative Optical Coherence Tomography (iOCT). We evaluated our approach on both tissue phantom and ex-vivo porcine eyes. Evaluation results show that the average error in distance measurement is 4.7 μm (maximum of 16.5 μm). We furthermore, verified the feasibility of the proposed method to track the insertion depth of needle in robot-assisted subretinal injection.


Title: Proprioceptive Inference for Dual-Arm Grasping of Bulky Objects Using RoboSimian
Key Words: Bayes methods  dexterous manipulators  humanoid robots  inference mechanisms  learning (artificial intelligence)  mobile robots  position control  robot kinematics  sensors  torque measurement  nasa jet propulsion laboratorys  robosimian  JPL  supporting manipulator  cumbersome objects  data-driven Bayesian models  inferred object properties  dual-arm lifting  bulky object  dual-arm grasping  proprioceptive inference  Manipulators  Probabilistic logic  Rotation measurement  Grasping  Shape  Task analysis 
Abstract: This work demonstrates dual-arm lifting of bulky objects based on inferred object properties (center of mass (COM) location, weight, and shape) using proprioception (i.e. force torque measurements). Data-driven Bayesian models describe these quantities, which enables subsequent behaviors to depend on confidence of the learned models. Experiments were conducted using the NASA Jet Propulsion Laboratory's (JPL) RoboSimian to lift a variety of cumbersome objects ranging in mass from 7kg to 25kg. The position of a supporting second manipulator was determined using a particle set and heuristics that were derived from inferred object properties. The supporting manipulator decreased the initial manipulator's load and distributed the wrench load more equitably across each manipulator, for each bulky object. Knowledge of the objects came from pure proprioception (i.e. without reliance on vision or other exteroceptive sensors) throughout the experiments.


Title: Compact and High Performance Torque-Controlled Actuators and its Implementation to Disaster Response Robot
Key Words: actuators  disasters  electromagnetic interference  gears  legged locomotion  rescue robots  strain gauges  torque control  high performance torque-controlled actuators  disaster response robot  scattered debris  axial compactness  torque sensors  torque control  analog digital converter board  differential control  joint torque  torque ripple  torque-controlled legged robot  disaster environments  harmonic drive gear  electromagnetic interference  strain gauges  Torque  Actuators  Robot sensing systems  Torque measurement  Strain measurement 
Abstract: Applying robots in narrow and cluttered disaster environments such as oil refineries requires a slim body and a wide range of motion. It is also necessary to have abilities to absorb unexpected contact with the environment and to walk on scattered debris. In this paper we propose new compact and high performance torque-controlled actuators for legged robots to satisfy the above mentioned requirements. For axial compactness, torque sensors are designed as ring-shaped thin cylinders surrounding motors or gears with strain gauges for sensing. To achieve broad bandwidth of torque control, we introduced an analog differentiator circuit into an analog digital converter (ADC) board in order to suppress noise in the differential control of joint torque. We also propose methods to reduce torque ripple caused by the deformation of the harmonic drive gear and electromagnetic interference (EMI) from a motor and a motor driver. Finally, experiments of a collision with objects and movement on scattered debris were executed with a fully torque-controlled legged robot built with the proposed actuators.


Title: High Dynamic Range Sensing by a Multistage Six-Axis Force Sensor with Stopper Mechanism
Key Words: force measurement  force sensors  seals (stoppers)  torque measurement  high dynamic range six-axis force-torque sensor  HDR six-axis force-torque sensor  force measurement  stopper mechanism  multistage six-axis force sensor  high dynamic range sensing  HDR measurement  overload protection mechanism  low-rigidity flexure element  high-rigidity flexure element  Robot sensing systems  Force sensors  Force  Strain  Force measurement  Mathematical model 
Abstract: This paper describes the design of a high dynamic range (HDR) six-axis force/torque sensor. The sensor is composed of a high-rigidity flexure element detecting large force and a low-rigidity flexure element detecting small force. The overload on the low-rigidity flexure element is prevented by an overload protection mechanism. An HDR measurement is achieved by combining the outputs of the two flexure elements. A loading test for the designed sensor is performed, and the results indicate that the six-axis sensor measures force with a dynamic range from 0.01N to 1000 N.


Title: Principal Components of Touch
Key Words: biology computing  data visualisation  principal component analysis  sensor arrays  tactile sensors  touch (physiological)  vibrissal arrays  PCA  touch  complex robotic manipulation  tactile sensor arrays  principal component analysis  visualisation approach  k-NN  Euclidean distance  Principal component analysis  Tactile sensors  Data visualization  Sensor arrays  Pins 
Abstract: Our human sense of touch enables us to manipulate our surroundings; therefore, complex robotic manipulation will require artificial tactile sensing. Typically tactile sensor arrays are used in robotics, implying that a straightforward way of interpreting multidimensional data is required. In this paper we present a simple visualisation approach based on applying principal component analysis (PCA) to systematically collected sets of tactile data. We apply the visualisation approach to 4 different types of tactile sensor, encompassing fingertips and vibrissal arrays. The results show that PCA can reveal structure and regularities in the tactile data, which also permits the use of simple classifiers such as k-NN to achieve good inference. Additionally, the Euclidean distance in principal component space gives a measure of sensitivity, which can aid visualisation and also be used to find regions in the tactile input space where the sensor is able to perceive with higher accuracy. We expect that these observations will generalise, and thus offer the potential for novel control methods based on touch.


Title: Artistic Pen Drawing on an Arbitrary Surface Using an Impedance-Controlled Robot
Key Words: art  computational geometry  curve fitting  manipulators  position control  splines (mathematics)  vectors  surface-reconstruction  position control  vector-graphics engine  Bézier spline curves  artistic pen drawing  impedance control  seven-degree-of-freedom manipulator  pen strokes  pen art  semiautonomous robotic pen-drawing system  impedance-controlled robot  arbitrary surface  Surface impedance  Robot sensing systems  Service robots  Surface reconstruction  Rendering (computer graphics)  Art 
Abstract: We present a semi-autonomous robotic pen-drawing system that is capable of creating pen art on an arbitrary surface with varying thickness of pen strokes but without reconstructing the surface explicitly. Our robotic system relies on an industrial, seven-degree-of-freedom (7DoF) manipulator that can be both position- and impedance-controlled. We use a vector-graphics engine to take an artist's pen drawing as input and generate Bézier spline curves with varying offsets. In order to estimate geometric details of the target, unknown surface, during drawing, we rely on incremental and adaptive sampling on the surface using a combination of position and impedance control. Then, our control algorithm physically replicates this drawing on any arbitrary, continuous surface by impedance-controlling the manipulator. We demonstrate that our system can create visually-pleasing and complicated artistic pen drawings on general surfaces without explicit surface-reconstruction nor visual feedback.


Title: Detection and Control of Contact Force Transients in Robotic Manipulation Without a Force Sensor
Key Words: force sensors  industrial robots  manipulators  recurrent neural nets  torque  recurrent neural network  RNN  industrial robot  force transient detection  robot joint torques  force sensor  robotic manipulation  contact force transients  Robot sensing systems  Transient analysis  Training  Switches  Task analysis  Data models 
Abstract: In this research, it is shown that robot joint torques can be used to recognize contact force transients induced during robotic manipulation, thus detecting when a task is completed. The approach does not assume any external sensor, which is a benefit compared to the state of the art. The joint torque data are used as input to a recurrent neural network (RNN), and the output of the RNN indicates whether the task is completed. A real-time application for force transient detection is developed, and verified experimentally on an industrial robot.


Title: Unsupervised Learning of Hierarchical Models for Hand-Object Interactions
Key Words: image segmentation  pose estimation  support vector machines  tactile sensors  unsupervised learning  force vectors  unsupervised manner  event labeling sequences  manipulation event segmentation  hierarchical models  hand-object interactions  contact forces  unsupervised learning approach  manipulation event parsing  low-cost easy-to-replicate tactile glove  temporal grammar model  Force  Grammar  Robot sensing systems  Task analysis  Motion segmentation  Unsupervised learning 
Abstract: Contact forces of the hand are visually unobservable, but play a crucial role in understanding hand-object interactions. In this paper, we propose an unsupervised learning approach for manipulation event segmentation and manipulation event parsing. The proposed framework incorporates hand pose kinematics and contact forces using a low-cost easy-to-replicate tactile glove. We use a temporal grammar model to capture the hierarchical structure of events, integrating extracted force vectors from the raw sensory input of poses and forces. The temporal grammar is represented as a temporal And-Or graph (T-AOG), which can be induced in an unsupervised manner. We obtain the event labeling sequences by measuring the similarity between segments using the Dynamic Time Alignment Kernel (DTAK). Experimental results show that our method achieves high accuracy in manipulation event segmentation, recognition and parsing by utilizing both pose and force data.


Title: Decoupled Motion Control of Wearable Robot for Rejecting Human Induced Disturbances
Key Words: artificial limbs  dexterous manipulators  medical robotics  mobile robots  motion control  position control  wearable robots  human arm  human induced disturbances  data-driven latent space impedance control method  latent space impedance controller  wearable robotic fingers  decoupled motion control  wearable extra limbs  human movement  self-standing robots  single-handed object manipulation  5G mobile communication  Conferences  Automation  Australia 
Abstract: When a human performs a task with the assistance of wearable extra limbs, the human movement for performing the task may inadvertently disturb the position and orientation of the robot base, making it difficult for the robot to properly carry out its objective. Therefore, unlike self-standing robots, a wearable robot must not only assist the user without interfering or prohibiting the natural human movement, but also have the capability to detect and reject disturbances caused by the wearer's motion. This paper examines such a situation, where the human attempts to twist open a bottle while a pair of robotic fingers mounted on the same arm holds the bottle in place. As the human arm rotates to twist the cap, the robot and consequently the bottle would rotate in that same direction, which makes separation of the cap from the bottle almost impossible. To compensate for the human induced disturbances, a data-driven latent space impedance control method is developed such that the robot can secure the bottle and at the same time allow natural human movement to be carried out during manipulation. Simulation and experiments have demonstrated the efficacy of the latent space impedance controller to enable single-handed object manipulation with the assistance of wearable robotic fingers.


Title: Estimation of Object Orientation Using Conductive Ink and Fabric Based Multilayered Tactile Sensor
Key Words: accelerometers  dexterous manipulators  force sensors  grippers  manipulator kinematics  tactile sensors  fabric based multilayered tactile sensor  hard materials  soft materials  robotic hand gripper  kinesthetic sensation  grasped object orientation  tactile sensing  rigid inertial measurement units  object orientation estimation  conductive silver ink  conductive fabric  fabric based sensors  hard surfaces  soft surfaces  manipulator kinematics  object manipulation tasks  Ink  Fabrics  Tactile sensors  Piezoresistance  Silver  Fabric Tactile sensor  Multilayered sensor  Tilt sensing  Conductive silver ink 
Abstract: Robots, either made from hard or soft materials, are being used increasingly for unknown object manipulation tasks in unstructured environments. To hold an object firmly and do the required task, the orientation of the object with respect to the robotic hand gripper is one of the necessary key information. Humans can sense the orientation of an object based on vision, kinesthetic sensation, or touch sensation. Similarly, robots shall also be able to estimate grasped object orientation just based on tactile sensing without knowing manipulator kinesthetic or kinematics. Existing sensors are mostly based on vision or rigid inertial measurement units (such as accelerometers, gyroscopes, magnetometers), which require additional setup and are typically not compliant with the arbitrary surfaces of the unknown obj ects. This paper discusses a new approach for object orientation estimation from a multilayered tactile sensor based on conductive silver ink and conductive fabric. Fabric based sensors are flexible and can confer to both hard and soft surfaces. Experimental results show that the tactile sensor developed is able to estimate the tilt angle without any information about manipulator kinematics.


Title: Magnified Force Sensory Substitution for Telemanipulation via Force-Controlled Skin Deformation
Key Words: force control  force feedback  force sensors  haptic interfaces  medical robotics  skin  surgery  tactile sensors  telerobotics  magnified force sensory substitution  teleoperation systems  kinesthetic force feedback systems  force-controlled tactile skin deformation  tangential force  normal force  sensory substitution device  skin deformation force feedback  maximum stable kinesthetic force feedback  da Vinci Research Kit teleoperation system  force magnification  interaction force  magnified force feedback  force feedback maximized performance  force-controlled skin deformation feedback  magnified kinesthetic force feedback  Force  Force feedback  Manipulators  Robot sensing systems  Skin  Strain  Force sensors  Haptics and Haptic Interfaces  Surgical Robotics  Laparoscopy  Force Control  Telerobotics and Teleoperation 
Abstract: Teleoperation systems could benefit from force sensory substitution when kinesthetic force feedback systems are too bulky or expensive, and when they cause instability by magnifying force feedback. We aim to magnify force feedback using sensory substitution via force-controlled tactile skin deformation, using a device with the ability to provide tangential and normal force directly to the fingerpads. The sensory substitution device is able to provide skin deformation force feedback over ten times the maximum stable kinesthetic force feedback on a da Vinci Research Kit teleoperation system. We evaluated the effect of this force magnification in two experimental tasks where the goal was to minimize interaction force with the environment. In a peg transfer task, magnified force feedback using sensory substitution improved participants' performance for force magnifications up to ten times, but decreased performance for higher force magnifications. In a tube connection task, sensory substitution that doubled the force feedback maximized performance; there was no improvement at the larger magnifications. These experiments demonstrate that magnified force feedback using sensory substitution via force-controlled skin deformation feedback can decrease applied forces similarly to magnified kinesthetic force feedback during teleoperation.


Title: Obstacle-Aided Navigation of a Soft Growing Robot
Key Words: collision avoidance  mobile robots  path planning  obstacle-aided navigation  soft growing robot  obstacle avoidance  robot path planning  soft robots  intentional obstacle collisions  soft robot navigation  robot-obstacle interaction  tip-extending soft robot  obstacle interaction model  account obstacle collisions  Collision avoidance  Computational modeling  Kinematics  Pneumatic systems  Soft robotics  Navigation 
Abstract: For many types of robots, avoiding obstacles is necessary to prevent damage to the robot and environment. As a result, obstacle avoidance has historically been an important problem in robot path planning and control. Soft robots represent a paradigm shift with respect to obstacle avoidance because their low mass and compliant bodies can make collisions with obstacles inherently safe. Here we consider the benefits of intentional obstacle collisions for soft robot navigation. We develop and experimentally verify a model of robot-obstacle interaction for a tip-extending soft robot. Building on the obstacle interaction model, we develop an algorithm to determine the path of a growing robot that takes into account obstacle collisions. We find that obstacle collisions can be beneficial for open-loop navigation of growing robots because the obstacles passively steer the robot, both reducing the uncertainty of the location of the robot and directing the robot to targets that do not lie on a straight path from the starting point. Our work shows that for a robot with predictable and safe interactions with obstacles, target locations in a cluttered, mapped environment can be reached reliably by simply setting the initial trajectory. This has implications for the control and design of robots with minimal active steering.


Title: Color-Based Sensing of Bending Deformation on Soft Robots
Key Words: image colour analysis  pneumatic actuators  robots  signal generators  three-dimensional printing  signal generator  color sensors  soft pneumatic actuators  soft actuators  multicolor 3D printing  soft robots  bending deformation  color-based sensing  Color  Strain  Actuators  Robot sensing systems  Signal generators  Soft robotics 
Abstract: This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The working principle of our approach is based on using compact color sensors to detect deformation that is visualized by the change of color ratios. Two novel designs are presented to generate color signals on 3D printed objects, which we call an external signal generator and an internal signal generator. Signal processing and calibration methods are developed to transform the raw RGB-data into a meaningful deformation metric. Our experimental tests taken on soft pneumatic actuators verify that color signals can be stably generated and captured to indicate the bending deformation. The results also demonstrate the usability of this sensing approach in deformation control.


Title: Modelling and Control of a Novel Soft Crawling Robot Based on a Dielectric Elastomer Actuator
Key Words: elastomers  electric actuators  electroactive polymer actuators  feedback  feedforward  mobile robots  motion control  viscoelasticity  dielectric elastomer actuator  soft crawling robot  inchworms  viscoelasticity  feedforward plus feedback control scheme  motion control  Force  Actuators  Soft robotics  Friction  Steady-state  Electrodes 
Abstract: Soft robots have recently evoked extensive attention due to their abilities to work effectively in unstructured environments. As an actuation technology of soft robots, dielectric elastomers exhibit many intriguing attributes such as large strain and high energy density. This work presents a novel dielectric elastomer based soft crawling robot inspired by inchworms. To fill the need of control of the soft robot, a model describing the interaction between the dielectric elastomer actuator and the environment is proposed, which takes inertia, viscoelasticity and friction into consideration. The model can well describe the robot's dynamic performances and the modelling approach used here can be extended to other dielectric elastomer actuators with complicated geometries for control purposes. The obtained model allows us to design a feedforward plus feedback control scheme for the robot to achieve desired motion. Simulation shows fast response and good tracking performances which are further confirmed by the experiments.


Title: Geometry-based Direct Simulation for Multi-Material Soft Robots
Key Words: calibration  deformation  design engineering  elasticity  geometry  manipulators  motion control  optimisation  pneumatic actuators  shapes (structures)  three-dimensional printing  material properties  deformation simulation  deformed shape  geometry-based direct simulation  multimaterial soft robots  soft materials  motion simulation  robots fabrication  numerical optimization  pneumatic actuators  cable-driven  calibration  design engineering  manipulators  3D-printing  elasticity  Shape  Soft robotics  Strain  Computational modeling  Optimization  Numerical models  Deformable models 
Abstract: Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.


Title: Incorporate Oblique Muscle Contractions to Strengthen Soft Robots
Key Words: actuators  biomechanics  muscle  robot kinematics  shear strength  wearable robots  soft robotics  shear forces  muscle arrangements  incompressible property  biological hydrostatic skeletons  longitudinal muscles  transverse muscles  oblique arrangement  shape-independent load-carrying capability  actuation mechanisms  oblique muscle contractions  flexibility  Muscles  Skeleton  Strain  Shape  Soft robotics  Force  Frequency modulation 
Abstract: For the state-of-the-art of soft robotics, the current actuation mechanisms cannot produce shear forces, neither are the current stiffening mechanisms adaptive to various deformations. Consequently, the soft robots gain strength at the price of losing flexibility. To fill this gap, we proposed a new mechanism based on the muscle arrangements and incompressible property identified in biological hydrostatic skeletons. Beside longitudinal and transverse muscles, the proposed mechanism includes the oblique arrangement which is proved to play an indispensable role of producing shear forces. The effectiveness of the new mechanism is demonstrated through a benchmark problem - carrying a distributed load at the initial horizontal configuration, thus indicating an improved direction to realise shape-independent load-carrying capability of soft robotics. Furthermore, the proposed mechanism may explain how elephants coordinate the two contradicting properties, strength and flexibility, during their trunk manipulations.


Title: Efficient FEM-Based Simulation of Soft Robots Modeled as Kinematic Chains
Key Words: dexterous manipulators  finite element analysis  pneumatic actuators  soft manipulation  soft hands  environmental constraints  object surfaces  simulation technologies  triple-layered simulation framework  dynamic properties  lumped parameter model  fast simulate soft fingers  soft pneumatic fingers  soft robots modeled  kinematic chains  robotic manipulation  grasping  force closure  single posture  contact-rich  FEM-based simulation  FEM simulation data  Computational modeling  Actuators  Deformable models  Finite element analysis  Data models  Object oriented modeling  Robots 
Abstract: In the context of robotic manipulation and grasping, the shift from a view that is static (force closure of a single posture) and contact-deprived (only contact for force closure is allowed, everything else is obstacle) towards a view that is dynamic and contact-rich (soft manipulation) has led to an increased interest in soft hands. These hands can easily exploit environmental constraints and object surfaces without risk, and safely interact with humans, but present also some challenges. Designing them is difficult, as well as predicting, modelling, and “programming” their interactions with the objects and the environment. This paper tackles the problem of simulating them in a fast and effective way, leveraging on novel and existing simulation technologies. We present a triple-layered simulation framework where dynamic properties such as stiffness are determined from slow but accurate FEM simulation data once, and then condensed into a lumped parameter model that can be used to fast simulate soft fingers and soft hands. We apply our approach to the simulation of soft pneumatic fingers.


Title: Evaluating the Quality of Non-Prehensile Balancing Grasps
Key Words: dexterous manipulators  grippers  manipulator dynamics  mobile robots  nonprehensile balancing grasps  wrench-based quality metric  force-closure grasps  autonomous robotic applications  manipulation  prediction capability  dexterity  Task analysis  Measurement  Force  Robots  Grasping  Friction  Predictive models 
Abstract: Assessing grasp quality and, subsequently, predicting grasp success is useful for avoiding failures in many autonomous robotic applications. In addition, interest in nonprehensile grasping and manipulation has been growing as it offers the potential for a large increase in dexterity. However, while force-closure grasping has been the subject of intense study for many years, few existing works have considered quality metrics for non-prehensile grasps. Furthermore, no studies exist to validate them in practice. In this work we use a real-world data set of non-prehensile balancing grasps and use it to experimentally validate a wrench-based quality metric by means of its grasp success prediction capability. The overall accuracy of up to 84 % is encouraging and in line with existing results for force-closure grasps.


Title: Transferring Grasping Skills to Novel Instances by Latent Space Non-Rigid Registration
Key Words: image registration  inference mechanisms  intelligent robots  shape recognition  latent space nonrigid transformation  coherent point drift approach  class-level knowledge  grasping motions  shape parameters  low-dimensional latent space  subspace methods  nonrigid registration method  grasping skills  Shape  Grasping  Strain  Aerospace electronics  Three-dimensional displays  Robots  Coherence 
Abstract: Robots acting in open environments need to be able to handle novel objects. Based on the observation that objects within a category are often similar in their shapes and usage, we propose an approach for transferring grasping skills from known instances to novel instances of an object category. Correspondences between the instances are established by means of a non-rigid registration method that combines the Coherent Point Drift approach with subspace methods. The known object instances are modeled using a canonical shape and a transformation which deforms it to match the instance shape. The principle axes of variation of these deformations define a low-dimensional latent space. New instances can be generated through interpolation and extrapolation in this shape space. For inferring the shape parameters of an unknown instance, an energy function expressed in terms of the latent variables is minimized. Due to the class-level knowledge of the object, our method is able to complete novel shapes from partial views. Control poses for generating grasping motions are transferred efficiently to novel instances by the estimated non-rigid transformation.


Title: Grasping Objects Big and Small: Human Heuristics Relating Grasp-Type and Object Size
Key Words: biomechanics  dexterous manipulators  motion control  human heuristics  grasp-type  object size  online data collection method  human intuition  survey questions  adopted taxonomy  wrist orientation  common grasps  object height  robot hand size  confidence-interval based polytope  object shape space  potential pre-grasps  grasping objects  fundamental object shapes  Shape  Taxonomy  Robots  Grasping  Planning  Videos  Data collection 
Abstract: This paper presents an online data collection method that captures human intuition about what grasp types are preferred for different fundamental object shapes and sizes. Survey questions are based on an adopted taxonomy that combines grasp pre-shape, approach, wrist orientation, object shape, orientation and size which covers a large swathe of common grasps. For example, the survey identifies at what object height or width dimension (normalized by robot hand size) the human prefers to use a two finger precision grasp versus a three-finger power grasp. This information is represented as a confidence-interval based polytope in the object shape space. The result is a database that can be used to quickly find potential pre-grasps that are likely to work, given an estimate of the object shape and size.


Title: Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping
Key Words: image colour analysis  manipulators  neurocontrollers  robot vision  deep robotic grasping  off-the-shelf simulators  ground-truth annotations  randomized simulated environments  domain adaptation methods  grasping system  raw monocular RGB images  pixel-level domain adaptation  real-world grasping performance  annotated visual grasping datasets  GraspGAN  generative adversial network  Grasping  Robots  Training  Feature extraction  Adaptation models  Cameras  Task analysis 
Abstract: Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.


Title: Coordination of Intrinsic and Extrinsic Degrees of Freedom in Soft Robotic Grasping
Key Words: adaptive control  grippers  manipulators  motion control  hand capabilities  soft RBO Hand 2  predefined motion  finger movements  compliant robot  soft robotic grasping  human grasping  movement patterns  adaptive intrinsic/extrinsic motion  Robot kinematics  Grasping  Wrist  Manipulators  Protocols  Kinematics 
Abstract: We demonstrate that moving the wrist while the fingers perform a grasp increases performance. The coordination shapes the interactions between the fingers, the object and its environment to extend the hand capabilities (e.g. higher payload and precision). We evaluated our hypothesis with a human grasping study where the volunteers grasped objects by moving the soft RBO Hand 2 while its fingers closed in a predefined motion. We limited their ability to coordinate their motion with the finger movements using a compliant robot attached to the hand, and observed that their grasp success decreases with increased constraints. We also successfully transferred one of the observed movement patterns to the robot, indicating that adaptive intrinsic/extrinsic motion increases robotic grasp performance as well.


Title: Reinforcement Learning for 4-Finger-Gripper Manipulation
Key Words: grippers  intelligent robots  learning (artificial intelligence)  manipulator dynamics  motion control  path planning  high-level discrete actions  Q-learning  rhythmic Dynamic Movement Primitives  4-finger-gripper manipulator  hierarchical planning  Reinforcement Learning  4-finger-gripper manipulation  hierarchical-planning approach  Robots  Trajectory  Task analysis  Planning  Heuristic algorithms  Learning (artificial intelligence)  Approximation algorithms 
Abstract: In the framework of robotics, Reinforcement Learning (RL) deals with the learning of a task by the robot itself. This paper presents a hierarchical-planning approach in which the robot learns the optimal behavior for different levels in a decoupled way. For high-level discrete actions, Q-learning was chosen, whereas for the low level we utilize Policy Improvement with Path Integrals (PI2) algorithm to learn the parameters of policies, represented by rhythmic Dynamic Movement Primitives (DMPs). The paper studies the case of a 4-finger-gripper manipulator, which performs the task of continuously spinning a ball around a desired axis. The results demonstrate the efficacy of the hierarchical planning and the increased performance of the task when PI2 is used in conjunction with rhythmic DMPs in a real environment.


Title: Popcorn-Driven Robotic Actuators
Key Words: actuators  compressive strength  friction  granular flow  granular materials  grippers  ignition  mixtures  robot dynamics  inter-granular friction  granular fluids  jamming actuators  popcorn-driven actuation  robotics  popcorn-driven robotic actuators  popcorn kernels  expansion ratio  transition temperature  compression strength  hot oil  hot air  direct contact  heated Nichrome wire  popping force  biodegradability  Kernel  Heating systems  Robots  Jamming  Actuators  Force  Wires 
Abstract: Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat. Although this transition is irreversible, it carries potential for several robotic applications. Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability. We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire. As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump. Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers. Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.


Title: A Hybrid Dynamic-Regenerative Damping Scheme for Energy Regeneration in Variable Impedance Actuators
Key Words: actuators  damping  electromagnetic devices  energy conservation  regenerative braking  vibration control  VIA  variable damping module design  numerical simulations  energy consumption  energy efficiency  variable impedance actuators  dynamic-regenerative damping scheme  dynamic braking  regenerative braking effect  energy regeneration  dissipated energy  Damping  Resistance  Actuators  DC motors  Task analysis  Robots 
Abstract: Increasing research efforts have been made to improve the energy efficiency of variable impedance actuators (VIAs) through reduction of energy consumption. However, the harvesting of dissipated energy in such systems remains under-explored. This study proposes a novel variable damping module design enabling energy regeneration in VIAs by exploiting the regenerative braking effect of DC motors. The proposed damping module uses four switches to combine regenerative and dynamic braking, in a hybrid approach that enables energy regeneration without reduction in the range of damping achievable. Numerical simulations and a physical experiment are presented in which the proposed module shows an optimal trade-off between task-performance and energy efficiency.


Title: Axially and Radially Expandable Modular Helical Soft Actuator for Robotic Implantables
Key Words: biological tissues  biomedical materials  cellular biophysics  elastomers  medical robotics  pneumatic actuators  prosthetics  surgery  radially expandable modular helical soft actuator  axially expandable modular helical soft actuator  elastomeric strands  elongation  tissue regeneration  long-gap esophageal atresia condition  soft pneumatic actuator  soft robots  modular soft basic constituents  human body  biomedical engineering  robotic implantables  soft medical robots  pressure 19.0 kPa  Actuators  Implants  Soft robotics  Esophagus  Surgery  Mathematical model 
Abstract: Soft robotics has advanced the field of biomedical engineering by creating safer technologies for interfacing with the human body. One of the challenges in this field is the realization of modular soft basic constituents and accessible assembly methods to increase the versatility of soft robots. We present a soft pneumatic actuator composed of two elastomeric strands that provide interdependent axial and radial expansion due to the modularity of the components and their helical arrangement. The actuator reaches 35% of elongation with respect to its initial height and both chambers achieve forces of 1N at about 19kPa. We describe the design, fabrication, modeling and benchtop testing of the soft actuator towards realizing 3D functional structures with potential medical applications. An example of application for soft medical robots is tissue regenerative for the long-gap esophageal atresia condition.


Title: Clothoid-Based Global Path Planning for Autonomous Vehicles in Urban Scenarios
Key Words: curve fitting  mobile robots  path planning  road traffic  road vehicles  roads  autonomous vehicles  urban scenario  intelligent vehicles  kinematic constraints  continuous-curvature paths  low curvature derivatives  clothoid-based global path planning  road network representation  Roads  Path planning  Geometry  Autonomous vehicles  Wheels  Kinematics  Computational modeling 
Abstract: Intelligent vehicles require an efficient way to compute a feasible path that connects its current localization to a destination point. To achieve that, the knowledge about the road network, including its geometry, is important since connections between roads can be used in the path planning. This work consists on computing a feasible global path for autonomous vehicles with kinematic constraints. Piecewise linear continuous-curvature paths composed of clothoids, circular arcs, and straight lines are used for this purpose. Low curvature derivatives provide comfort to passengers. This approach provides a compact road network representation as only the parameters of the curves are stored. A real urban scenario with straight and curved roads, multiple lanes, intersections, and roundabouts is modeled and the proposed approach is validated. As a result of the proposed approaches, door-to-door global continuous-curvature paths are generated considering the shortest traveled distance.


Title: Surface-Based Exploration for Autonomous 3D Modeling
Key Words: mobile robots  path planning  solid modelling  surface reconstruction  3D models  exploration algorithm  autonomous 3D modeling  path planning problem  exploration path  low-confidence surfaces  reconstructed surfaces  volumetric model  volumetric map  mobile robot  Surface reconstruction  Computational modeling  Three-dimensional displays  Robot sensing systems  Inspection  Mobile robots  Solid modeling 
Abstract: In this study, we addressed a path planning problem of a mobile robot to construct highly accurate 3D models of an unknown environment. Most studies have focused on exploration approaches, which find the most informative viewpoint or trajectories by analyzing a volumetric map. However, the completion of a volumetric map does not necessarily describe the completion of a 3D model. A highly complicated structure sometimes cannot be represented as a volumetric model. We propose a novel exploration algorithm that considers not only a volumetric map but also reconstructed surfaces. Unlike previous approaches, we evaluate the model completeness according to the quality of the reconstructed surfaces and extract low-confidence surfaces. The surface information is used to guide the computation of the exploration path. Experimental results showed that the proposed algorithm performed better than other state-of-the-art exploration methods and especially improved the completeness and confidence of the 3D models.


Title: Departure and Conflict Management in Multi-Robot Path Coordination
Key Words: aircraft control  airports  mobile robots  multi-robot systems  path planning  automatic aircraft taxiing coordination  driver-less cars coordination  no-backward-movement constraint  complex conflict situations  Charles de Gaulle airport  multirobot path coordination  Robot kinematics  Planning  Aircraft  Collision avoidance  Airports  Automobiles 
Abstract: This paper addresses the problem of multi-robot path coordination, considering specific features that arise in applications such as automatic aircraft taxiing or driver-less cars coordination. The first feature is departure events: when robots arrive at their destinations (e.g. the runway for takeoff), they can be removed from the coordination diagram. The second feature is the “no-backward-movement” constraint: the robots can only move forward on their assigned paths. These features can interact to give rise to complex conflict situations, which existing planners are unable to solve in practical time. We propose a set of algorithms to efficiently account for these features and validate these algorithms on a realistic model of Charles de Gaulle airport.


Title: A Single-Planner Approach to Multi-Modal Humanoid Mobility
Key Words: humanoid robots  legged locomotion  path planning  planning (artificial intelligence)  search problems  planning efforts  planning process  single-planner approach  multimodal humanoid mobility  configuration space  humanoid robot  single search process  search spaces  adaptive dimensionality  Planning  Task analysis  Aerospace electronics  Legged locomotion  Superluminescent diodes  Humanoid robots 
Abstract: In this work, we present an approach to planning for humanoid mobility. Humanoid mobility is a challenging problem, as the configuration space for a humanoid robot is intractably large, especially if the robot is capable of performing many types of locomotion. For example, a humanoid robot may be able to perform such tasks as bipedal walking, crawling, and climbing. Our approach is to plan for all these tasks within a single search process. This allows the search to reason about all the capabilities of the robot at any point, and to derive the complete solution such that the plan is guaranteed to be feasible. A key observation is that we often can roughly decompose a mobility task into a sequence of smaller tasks, and focus planning efforts to reason over much smaller search spaces. To this end, we leverage the results of a recently developed framework for planning with adaptive dimensionality, and incorporate the capabilities of available controllers directly into the planning process. The resulting planner can also be run in an interleaved fashion alongside execution so that time spent idle is much reduced.


Title: Information Based Mobile Sensor Planning for Source Term Estimation of a Non-Continuous Atmospheric Release
Key Words: air pollution  atmospheric chemistry  atmospheric techniques  Bayes methods  chemical sensors  disperse systems  hazardous materials  inverse problems  mobile sensor planning  Bayes' theorem  static sensors  single mobile sensor  chemical sensor  dispersion parameters  Gaussian puff dispersion model  meteorological information  inverse problem  hazardous material  noncontinuous atmospheric release  source term estimation  Robot sensing systems  Dispersion  Atmospheric modeling  Unmanned aerial vehicles  Position measurement  Wind speed  Mathematical model 
Abstract: Ahstract- This paper presents a method to estimate the original location and the mass of an instantaneous release of hazardous material into the atmosphere. It is formulated as an inverse problem, where concentration observations from a mobile sensor are fused with meteorological information and a Gaussian puff dispersion model to characterise the source. Bayes' theorem is used to estimate the parameters of the release taking into account the uncertainty that exists in the dispersion parameters and meteorological variables. An information based reward is used to guide an unmanned aerial vehicle equipped with a chemical sensor to the expected most informative measurement locations. Simulation results compare the performance between a single mobile sensor with various amounts of static sensors.


Title: Collision-Free Motion Planning for Human-Robot Collaborative Safety Under Cartesian Constraint
Key Words: collision avoidance  control system synthesis  end effectors  human-robot interaction  image segmentation  Kalman filters  nearest neighbour methods  robot vision  human-robot collaborative safety  Cartesian constraint  real-time motion planning  control design  robotic arm  multiple KinectV2 depth cameras  robot workspace  collision avoidance  robot end effector  collision-free motion planning method  6-DOF robot arm  Kalman filter  K-nearest neighbor searching algorithm  K-nearest neighbor searching algorithm  Robots  Collision avoidance  Force  Planning  Three-dimensional displays  Collaboration  Task analysis 
Abstract: This paper presents a real-time motion planning and control design of a robotic arm for human-robot collaborative safety. A novel collision-free motion planning method is proposed not only to keep robot body from colliding with objects but also preserve the execution of robot's original task under the Cartesian constraint of the environment. Multiple KinectV2 depth cameras are utilized to model and track dynamic obstacles (e.g. Humans and objects) inside the robot workspace. Depth images are applied to generate point cloud of segmented objects in the environment. A K-nearest neighbor (KNN) searching algorithm is used to cluster and find the closest point from the obstacle to the robot. Then a Kalman filter is applied to estimate the obstacle position and velocity. For the collision avoidance in collaborative operation, attractive and repulsive potential is generated for robot end effector based on the task specification and obstacle observation. Practical experiments show that the 6-DOF robot arm can effectively avoid an obstacle in a constrained environment and complete the original task.


Title: Generating Vibration Free Rest-to-Rest Trajectories for Configuration Dependent Dynamic Systems via 3-Segmented Input Shaping
Key Words: bang-bang control  path planning  position control  configuration dependent dynamics  vibration-free RTR trajectory generation  bang-coast-bang trajectory  system dynamics  piece wise shaping  trajectory segmentation strategy  3-Segmented Input Shaping  configuration dependent dynamic systems  free rest-to-rest trajectories  Trajectory  Vibrations  Acceleration  Motion segmentation  System dynamics  Numerical simulation 
Abstract: This paper presents a new method to generate vibration free rest-to-rest (RTR) trajectories for configuration dependent dynamic systems, such as robots, cranes or machine tools. The new method named 3-Segmented Input Shaping is based on a combination of the widely known Input Shaping method and a new trajectory segmentation strategy for piece wise shaping of the trajectory. The new segmentation strategy facilitates the capability of accounting for variations in system dynamics during motion by shaping acceleration and deceleration profiles with individual frequencies. In this paper the new segmentation strategy is used in combination with the bang-coast-bang (BCB) trajectory. The generated trajectories are described in closed form, hence requires no optimization and thereby provides strong computational performance. The new method is verified by numerical simulations and detailed analysis and shows great potential in vibration-free RTR trajectory generation for systems with configuration dependent dynamics.


Title: A Model-Based Hierarchical Controller for Legged Systems Subject to External Disturbances
Key Words: control system synthesis  force control  legged locomotion  motion control  position control  robot dynamics  robot kinematics  robust control  model-based hierarchical controller  model-based controller  projected inverse dynamics controller  control law  constrained space controller  unknown external disturbances  impedance controller  legged systems  unconstrained component  contact forces  force sensors  torque sensors  ANYmal quadruped platform  contact locations  legged robots  Task analysis  Force  Legged locomotion  Aerospace electronics  Dynamics  Jacobian matrices 
Abstract: Legged robots have many potential applications in real-world scenarios where the tasks are too dangerous for humans, and compliance is needed to protect the system against external disturbances and impacts. In this paper, we propose a model-based controller for hierarchical tasks of legged systems subject to external disturbance. The control framework is based on projected inverse dynamics controller, such that the control law is decomposed into two orthogonal subspaces, i.e., the constrained and the unconstrained subspaces. The unconstrained component controls multiple desired tasks with impedance responses. The constrained space controller maintains the contact subject to unknown external disturbances, without the use of any force/torque sensing at the contact points. By explicitly modelling the external force, our controller is robust to external disturbances and errors arising from incorrect dynamic model information. The main contributions of this paper include (1) incorporating an impedance controller to control external disturbances and allow impedance shaping to adjust the behaviour of the motion under external disturbances, (2) optimising contact forces within the constrained subspace that also takes into account the external disturbances without using force/torque sensors at the contact locations. The techniques are evaluated on the ANYmal quadruped platform under a variety of scenarios.


Title: Fore-Aft Leg Specialization Controller for a Dynamic Quadruped
Key Words: legged locomotion  robot dynamics  trajectory control  fore-aft leg specialization controller  running animals  robotic counterparts  functional dynamic decomposition  Dynamic Quadruped  trajectory-based controller  Legged locomotion  Trajectory  Force  Springs  Vehicle dynamics  Robot kinematics 
Abstract: Many running animals, unlike their robotic counterparts, have distinct morphologies and functional roles for their front and rear legs. In this paper we present a new control approach for a 5kg autonomous dynamic quadruped that explicitly encodes separate roles for each contralateral pair of legs. This controller utilizes a functional dynamic decomposition similar to Raibert's three part control law, but focuses on fore-aft leg specialization to regulate the robot's performance. The velocity of this controller, which exceeds 5 body lengths per sec, is compared with an improved trajectory-based controller and shown to be significantly more robust to changes in environment.


Title: Contact Model Fusion for Event-Based Locomotion in Unstructured Terrains
Key Words: discrete time systems  finite state machines  force control  Kalman filters  legged locomotion  motion control  observers  robot dynamics  robot kinematics  robust control  contact detection  contact state estimation  MIT Cheetah 3 robot  dynamic modeling  kinematic  Event-Based Finite State Machine  Kalman Filtering  contact priors  proprioceptive force control estimates  generalized-momentum disturbance observer  discrete-time extension  contact initiation  terrain geometry  contact models  contact transitions  unstructured environments  legged robots  unstructured terrains  event-based locomotion  contact model fusion  time 4.0 ms to 5.0 ms  Legged locomotion  Robot sensing systems  Force  Disturbance observers  Robustness 
Abstract: As legged robots are sent into unstructured environments, the ability to robustly manage contact transitions will be a critical skill. This paper introduces an approach to probabilistically fuse contact models, managing uncertainty in terrain geometry, dynamic modeling, and kinematics to improve the robustness of contact initiation at touchdown. A discrete-time extension of the generalized-momentum disturbance observer is presented to increase the accuracy of proprioceptive force control estimates. This information is fused with other contact priors under a framework of Kalman Filtering to increase robustness of the method. This approach results in accurate contact detection with 99.3 % accuracy and a small 4-5ms delay. Using this new detector, an Event-Based Finite State Machine is implemented to deal with unexpected early and late contacts. This allows the robot to traverse cluttered environments by modifying the control actions for each individual leg based on the estimated contact state rather than adhering to a rigid time schedule regardless of actual contact state. Experiments with the MIT Cheetah 3 robot show the success of both the detection algorithm, as well as the Event-Based FSM while making unexpected contacts during trotting.


Title: Single-Image Footstep Prediction for Versatile Legged Locomotion
Key Words: convolution  feedforward neural nets  image colour analysis  intelligent robots  learning (artificial intelligence)  legged locomotion  path planning  prediction theory  robot kinematics  sensors  versatile legged locomotion  robots  longterm routes  horizontal terrain  vertical terrain  onboard sensors  vantage points  strongly foreshortened images  terrain features  viewing angle  convolutional neural network method  arbitrary tilt angles  route planner  plausible plans  rock climbing gyms  walking robots  climbing robots  single image footstep prediction  distance angle  valid handhold prediction  foothold locations prediction  single RGB+D images  learning techniques  flat ground  stairs  walls  Cameras  Legged locomotion  Planning  Robot kinematics  Three-dimensional displays  Rocks 
Abstract: Walking and climbing robots need to plan longterm routes on both horizontal and vertical terrain, but onboard sensors take images from vantage points that provide strongly foreshortened images that cause the appearance of terrain features to vary greatly by distance and viewing angle. This paper presents a convolutional neural network (CNN) method for predicting valid handhold and foothold locations from single RGB+D images taken at arbitrary tilt angles. Experiments show that the method predicts holds more accurately than comparable learning techniques, and that a route planner based on these predictions generates plausible plans for flat ground, stairs, and walls in rock climbing gyms.


Title: Legged Robot State-Estimation Through Combined Forward Kinematic and Preintegrated Contact Factors
Key Words: graph theory  legged locomotion  object tracking  optimisation  robot kinematics  robot vision  state estimation  robotic perception systems  robot state-estimation  Agility Robotics  Cassie-series robot  forward kinematic factor  factor graph framework  preintegrated contact factor  kinematic factors  legged robots  state-estimation technique  visual tracking  Robot sensing systems  Legged locomotion  Kinematics  Optimization  Foot  Cameras 
Abstract: State-of-the-art robotic perception systems have achieved sufficiently good performance using Inertial Measurement Units (IMUs), cameras, and nonlinear optimization techniques, that they are now being deployed as technologies. However, many of these methods rely significantly on vision and often fail when visual tracking is lost due to lighting or scarcity of features. This paper presents a state-estimation technique for legged robots that takes into account the robot's kinematic model as well as its contact with the environment. We introduce forward kinematic factors and preintegrated contact factors into a factor graph framework that can be incrementally solved in real-time. The forward kinematic factor relates the robot's base pose to a contact frame through noisy encoder measurements. The preintegrated contact factor provides odometry measurements of this contact frame while accounting for possible foot slippage. Together, the two developed factors constrain the graph optimization problem allowing the robot's trajectory to be estimated. The paper evaluates the method using simulated and real sensory IMU and kinematic data from experiments with a Cassie-series robot designed by Agility Robotics. These preliminary experiments show that using the proposed method in addition to IMU decreases drift and improves localization accuracy, suggesting that its use can enable successful recovery from a loss of visual tracking.


Title: Learning to Parse Natural Language to Grounded Reward Functions with Weak Supervision
Key Words: grammars  lambda calculus  learning (artificial intelligence)  natural language processing  robots  trees (mathematics)  parse weights  validation-driven perceptron weight updates  goal-condition learning approach  grounded reward functions  language representations  weighted linear Combinatory Categorial Grammar semantic parser  CCG lexicon  parse trees  robot behaviors  Cleanup World domain  natural language parsing  goal-state reward functions  lambda calculus  Natural languages  Semantics  Task analysis  Planning  Robots  Trajectory  Navigation 
Abstract: In order to intuitively and efficiently collaborate with humans, robots must learn to complete tasks specified using natural language. We represent natural language instructions as goal-state reward functions specified using lambda calculus. Using reward functions as language representations allows robots to plan efficiently in stochastic environments. To map sentences to such reward functions, we learn a weighted linear Combinatory Categorial Grammar (CCG) semantic parser. The parser, including both parameters and the CCG lexicon, is learned from a validation procedure that does not require execution of a planner, annotating reward functions, or labeling parse trees, unlike prior approaches. To learn a CCG lexicon and parse weights, we use coarse lexical generation and validation-driven perceptron weight updates using the approach of Artzi and Zettlemoyer [4]. We present results on the Cleanup World domain [18] to demonstrate the potential of our approach. We report an F1 score of 0.82 on a collected corpus of 23 tasks containing combinations of nested referential expressions, comparators and object properties with 2037 corresponding sentences. Our goal-condition learning approach enables an improvement of orders of magnitude in computation time over a baseline that performs planning during learning, while achieving comparable results. Further, we conduct an experiment with just 6 labeled demonstrations to show the ease of teaching a robot behaviors using our method. We show that parsing models learned from small data sets can generalize to commands not seen during training.


Title: Deep Haptic Model Predictive Control for Robot-Assisted Dressing
Key Words: assisted living  clothing  control engineering computing  end effectors  handicapped aids  haptic interfaces  human-robot interaction  learning (artificial intelligence)  optimal control  predictive control  service robots  physical human-robot interaction  people with disabilities  controller objective function  deep predictive model  prediction horizon  PR2 robot  physics-based simulation  dressing assistance  garment  deep recurrent model  nonrigid garments  physical implications  robot-assisted dressing  deep haptic model predictive control  Robot sensing systems  Haptic interfaces  End effectors  Clothing  Predictive models 
Abstract: Robot-assisted dressing offers an opportunity to benefit the lives of many people with disabilities, such as some older adults. However, robots currently lack common sense about the physical implications of their actions on people. The physical implications of dressing are complicated by non-rigid garments, which can result in a robot indirectly applying high forces to a person's body. We present a deep recurrent model that, when given a proposed action by the robot, predicts the forces a garment will apply to a person's body. We also show that a robot can provide better dressing assistance by using this model with model predictive control. The predictions made by our model only use haptic and kinematic observations from the robot's end effector, which are readily attainable. Collecting training data from real world physical human-robot interaction can be time consuming, costly, and put people at risk. Instead, we train our predictive model using data collected in an entirely self-supervised fashion from a physics-based simulation. We evaluated our approach with a PR2 robot that attempted to pull a hospital gown onto the arms of 10 human participants. With a 0.2s prediction horizon, our controller succeeded at high rates and lowered applied force while navigating the garment around a persons fist and elbow without getting caught. Shorter prediction horizons resulted in significantly reduced performance with the sleeve catching on the participants' fists and elbows, demonstrating the value of our model's predictions. These behaviors of mitigating catches emerged from our deep predictive model and the controller objective function, which primarily penalizes high forces.


Title: EmoRL: Continuous Acoustic Emotion Classification Using Deep Reinforcement Learning
Key Words: acoustic signal processing  emotion recognition  human-robot interaction  learning (artificial intelligence)  neural nets  EmoRL model  audio signal  continuous acoustic emotion classification  deep reinforcement learning  acoustically expressed emotions  deep neural network-based models  affective state evaluation  real-time communication scenario  human-robot interaction  Acoustics  Robots  Adaptation models  Logic gates  Feature extraction  Predictive models  Recurrent neural networks 
Abstract: Acoustically expressed emotions can make communication with a robot more efficient. Detecting emotions like anger could provide a clue for the robot indicating unsafe/undesired situations. Recently, several deep neural network-based models have been proposed which establish new state-of-the-art results in affective state evaluation. These models typically start processing at the end of each utterance, which not only requires a mechanism to detect the end of an utterance but also makes it difficult to use them in a real-time communication scenario, e.g. human-robot interaction. We propose the EmoRL model that triggers an emotion classification as soon as it gains enough confidence while listening to a person speaking. As a result, we minimize the need for segmenting the audio signal for classification and achieve lower latency as the audio signal is processed incrementally. The method is competitive with the accuracy of a strong baseline model, while allowing much earlier prediction.


Title: Temporal Spatial Inverse Semantics for Robots Communicating with Humans
Key Words: control engineering computing  human-robot interaction  natural language processing  Amazon MTurk  TeSIS  natural language sentences  extended sentence structure  spatial context information  human listeners  temporal spatial inverse semantics  temporal context  Semantics  Grounding  Pallets  Natural languages  Tires  Service robots 
Abstract: Effective communication between humans often embeds both temporal and spatial context. While spatial context captures the geographic settings of objects in the environment, temporal context describes their changes over time. In this paper, we propose temporal spatial inverse semantics (TeSIS) to extend the inverse semantics approach to also consider the temporal context for robots communicating with humans. Inverse semantics generates natural language requests while taking into account how well the human listeners would interpret those requests given the current spatial context. Compared to inverse semantics, our approach incorporates also temporal context by referring to spatial context information in the past. To achieve this, we extend the sentence structure in inverse semantics to generate sentences that can refer to not only the current but also previous states of the environment. A new metric based on the extended sentence structure is developed by breaking a single sentence into multiple independent sentences that refer to environment states at different times. Using this approach, we are able to generate sentences such as “Please pick up the cup beside the oven that was on the dining table”. To evaluate our approach, we randomly generate scenarios in an experimental domain. Each scenario includes the description of the current and several immediate previous states. Natural language sentences are then generated for these scenarios using both inverse semantics that uses only the spatial context and our approach. Amazon MTurk is used to compare the sentences generated and results show that TeSIS achieves better accuracy, sometimes by a significant margin, than the baseline.


Title: Brain-Computer Interface Meets ROS: A Robotic Approach to Mentally Drive Telepresence Robots
Key Words: brain  brain-computer interfaces  collision avoidance  control engineering computing  geriatrics  handicapped aids  learning (artificial intelligence)  medical robotics  medical signal processing  mobile robots  operating systems (computers)  patient rehabilitation  position control  robot programming  telerobotics  video streaming  noninvasive Brain-Computer Interface  Robot Operating System  telepresence robot  mobile device  human brain signals  severe physical disabilities  elderly people  BCI user  robot position control  obstacle avoidance  video streaming  Navigation  Robot sensing systems  Task analysis  Telepresence  Brain-computer interfaces 
Abstract: This paper shows and evaluates a novel approach to integrate a non-invasive Brain-Computer Interface (BCI) with the Robot Operating System (ROS) to mentally drive a telepresence robot. Controlling a mobile device by using human brain signals might improve the quality of life of people suffering from severe physical disabilities or elderly people who cannot move anymore. Thus, the BCI user can actively interact with relatives and friends located in different rooms thanks to a video streaming connection to the robot. To facilitate the control of the robot via BCI, we explore new ROS-based algorithms for navigation and obstacle avoidance in order to make the system safer and more reliable. In this regard, the robot exploits two maps of the environment, one for localization and one for navigation, and both are used as additional visual feedback for the BCI user to control the robot position. Experimental results show a decrease of the number of commands needed to complete the navigation task, suggesting a reduction user's cognitive workload. The novelty of this work is to provide a first evidence of an integration between BCI and ROS that can simplify and foster the development of software for BCI driven robotics devices.


Title: FaNeuRobot: A Framework for Robot and Prosthetics Control Using the NeuCube Spiking Neural Network Architecture and Finite Automata Theory
Key Words: brain  brain-computer interfaces  electroencephalography  finite automata  handicapped aids  learning (artificial intelligence)  medical robotics  medical signal processing  muscle  neural nets  neurophysiology  brain-machine interface  central nervous system  biomedical signal  finite automata theory  NeuCube evolving spiking neural network architecture  robust prosthetic control  anthropomorphic mechanical design  noninvasive BMI  muscle atrophy  motor control framework  anthropomorphic design  prosthetic limbs  limb amputation  prosthetics control  Prosthetics  Muscles  Electroencephalography  DC motors  Grasping  Bones  Thumb 
Abstract: Limb amputation is a global problem. Prosthetic limbs can enhance the quality of life of amputees. To this end, anthropomorphic design and intuitive manipulation are two essential requirements. This paper presents a motor control framework for prosthetic control through Brain-Machine Interface (BMI) using Finite Automata Theory, and NeuCube Evolving Spiking Neural Network (SNN) architecture. Voluntary control of prosthetics requires decoding motor commands from the Central Nervous System of the amputee. Selection of the most suitable biomedical signal depends on many parameters such as level of amputation and muscle atrophy. Non-invasive BMI's have the possibility of supporting a wider range of amputees as it extracts the motor commands from the brain. In this paper, we present a proof of concept study on whether a cognitive computational model that is inspired by the motor control of the human body through muscle synergies combined with an anthropomorphic mechanical design, can result in accurate and robust prosthetic control through a noninvasive BMI. In future, learning of a complex Finite Automata that reflects complex upper limb motor behaviours will be investigated.


Title: Human in the Loop of Robot Learning: EEG-Based Reward Signal for Target Identification and Reaching Task
Key Words: brain  control engineering computing  electroencephalography  human-robot interaction  intelligent robots  learning (artificial intelligence)  robot programming  target reaching task  assistive technologies  shared control  intelligent robotic device  electrophysiological measures  error detection  Error-related Potentials  semiautonomous system  online robot learning task  detected ErrP  robot learning loop  optimal policy learning  shared autonomy  reinforcement learning framework  Electroencephalography  Training  Graphical user interfaces  Microsoft Windows  Testing  Robot learning 
Abstract: Shared control and shared autonomy play an important role in assistive technologies, allowing the offloading of the cognitive burden required for control from the user to the intelligent robotic device. In this context, electrophysiological measures of error detection, directly measured from a person's brain activity as Error-related Potentials (ErrPs), can be exploited to provide passive adaptation of an external semi-autonomous system to the human. This concept was implemented in an online robot learning task, where user's evaluation of the robot's actions, in terms of detected ErrP, was exploited to update a reward function in a Reinforcement Learning (RL) framework. Results from both simulated and experimental studies show that the introduction of human evaluation in the robot learning loop allows for: (1) the acceleration of optimal policy learning in a target reaching task, (2) the introduction of a further degree of control in robot learning, namely identification of one among multiple targets, according to the user's will. Overall, presented results support the potential of human-robot co-adaptive and co-operative strategies to develop human-centered assistive technologies.


Title: Incremental Adversarial Domain Adaptation for Continually Changing Environments
Key Words: feature extraction  image segmentation  unsupervised learning  machine learning models  robotics applications  alignment step  feature distribution  GAN training  continuous appearance shifts  continually changing environments  incremental adversarial domain adaptation  generative adversarial network  traversable-path segmentation task  unsupervised domain adaptation  Training  Task analysis  Adaptation models  Robots  Gallium nitride  Mathematical model  Lighting 
Abstract: Continuous appearance shifts such as changes in weather and lighting conditions can impact the performance of deployed machine learning models. While unsupervised domain adaptation aims to address this challenge, current approaches do not utilise the continuity of the occurring shifts. In particular, many robotics applications exhibit these conditions and thus facilitate the potential to incrementally adapt a learnt model over minor shifts which integrate to massive differences over time. Our work presents an adversarial approach for lifelong, incremental domain adaptation which benefits from unsupervised alignment to a series of intermediate domains which successively diverge from the labelled source domain. We empirically demonstrate that our incremental approach improves handling of large appearance changes, e.g. day to night, on a traversable-path segmentation task compared with a direct, single alignment step approach. Furthermore, by approximating the feature distribution for the source domain with a generative adversarial network, the deployment module can be rendered fully independent of retaining potentially large amounts of the related source training data for only a minor reduction in performance.


Title: Optimization Beyond the Convolution: Generalizing Spatial Relations with End-to-End Metric Learning
Key Words: convolution  distance learning  feedforward neural nets  gradient methods  learning (artificial intelligence)  mobile robots  optimisation  pose estimation  solid modelling  robots  arbitrary spatial relations  sizes  shapes  distance metric learning  3D point clouds  metric space  object poses  arbitrary target relation  domestic environments  convolution  gradient based optimization  neural network  geometric models  continuous spectrum  end to end metric learning  Measurement  Three-dimensional displays  Robots  Optimization  Transforms  Shape  Convolution 
Abstract: To operate intelligently in domestic environments, robots require the ability to understand arbitrary spatial relations between objects and to generalize them to objects of varying sizes and shapes. In this work, we present a novel end-to-end approach to generalize spatial relations based on distance metric learning. We train a neural network to transform 3D point clouds of objects to a metric space that captures the similarity of the depicted spatial relations, using only geometric models of the objects. Our approach employs gradient-based optimization to compute object poses in order to imitate an arbitrary target relation by reducing the distance to it under the learned metric. Our results based on simulated and real-world experiments show that the proposed method enables robots to generalize spatial relations to unknown objects over a continuous spectrum.


Title: Constructing Category-Specific Models for Monocular Object-SLAM
Key Words: cameras  feature extraction  mobile robots  object detection  pose estimation  robot vision  SLAM (robots)  category-specific models  real-time object-oriented SLAM  monocular camera  object-level models  category-level models  object deformations  discriminative object features  category models  object landmark observations  generic monocular SLAM framework  2D object features  sparse feature-based monocular SLAM  object instance retrieval  instance-independent monocular object-SLAM system  feature-based SLAM methods  time 2.0 d  time 3.0 d  Solid modeling  Simultaneous localization and mapping  Three-dimensional displays  Object oriented modeling  Pipelines  Two dimensional displays  Shape 
Abstract: We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category-level models from CAD collections which are now widely available. To alleviate the need for huge amounts of labeled data, we develop a rendering pipeline that enables synthesis of large datasets from a limited amount of manually labeled data. Using data thus synthesized, we learn category-level models for object deformations in 3D, as well as discriminative object features in 2D. These category models are instance-independent and aid in the design of object landmark observations that can be incorporated into a generic monocular SLAM framework. Where typical object-SLAM approaches usually solve only for object and camera poses, we also estimate object shape on-the-fty, allowing for a wide range of objects from the category to be present in the scene. Moreover, since our 2D object features are learned discriminatively, the proposed object-SLAM system succeeds in several scenarios where sparse feature-based monocular SLAM fails due to insufficient features or parallax. Also, the proposed category-models help in object instance retrieval, useful for Augmented Reality (AR) applications. We evaluate the proposed framework on multiple challenging real-world scenes and show - to the best of our knowledge - first results of an instance-independent monocular object-SLAM system and the benefits it enjoys over feature-based SLAM methods.


Title: The Hands-Free Push-Cart: Autonomous Following in Front by Predicting User Trajectory Around Obstacles
Key Words: collision avoidance  mobile robots  motion control  object detection  trajectory control  autonomous mobile robot  walking user  autonomous push-carts  multimodal person detection  human-motion model  obstacle mapper  human tracker  human motion model  robot motion planner  robot motion controller  industrial entertainment applications  domestic entertainment applications  hands-free push-cart  predicting user trajectory  Robot sensing systems  Legged locomotion  Cameras  Tracking  Trajectory  Predictive models 
Abstract: This paper demonstrates an autonomous mobile robot that follows a walking user while staying ahead of them. Despite several useful applications for autonomous push-carts, this problem has received much less attention than the easier problem of following from behind. In contrast to previous work, we use multi-modal person detection and a human-motion model that considers obstacles to predict the future path of the user. We implement the system with a modular architecture of obstacle mapper, human tracker, human motion model, robot motion planner and robot motion controller. We report on the performance of the robot in real-world experiments. We believe that approaches to this largely overlooked problem could be useful in real industrial, domestic and entertainment applications in the near future.


Title: Socially Constrained Tracking in Crowded Environments Using Shoulder Pose Estimates
Key Words: object detection  object tracking  pose estimation  robot vision  inner city train station  robotic technologies  2D pose  motion capture system  person tracking framework  human environments  shoulder pose estimates  crowded environments  pose errors  lab environment  Target tracking  Sensors  Cameras  Robustness  Task analysis  Head 
Abstract: Detecting and tracking people is a key requirement in the development of robotic technologies intended to operate in human environments. In crowded environments such as train stations this task is particularly challenging due the high numbers of targets and frequent occlusions. In this paper we present a framework for detecting and tracking humans in such crowded environments in terms of 2D pose ( x, y, θ). The main contributions are a method for extracting pose from the most visible parts of the body in a crowd, the head and shoulders, and a tracker which leverages social constraints regarding peoples orientation, movement and proximity to one another, to improve robustness in this challenging environment. The framework is evaluated on two datasets: one captured in a lab environment with ground truth obtained using a motion capture system, and the other captured in a busy inner city train station. Pose errors are reported against the ground truth and the tracking results are then compared with a state-of-the-art person tracking framework.


Title: Anticipating Many Futures: Online Human Motion Prediction and Generation for Human-Robot Interaction
Key Words: human-robot interaction  image coding  image colour analysis  image motion analysis  image representation  probability  robot vision  motion patterns  kinematic cues  natural human motion  human-robot interaction  online human motion prediction  target prediction  RGB depth images  skeletal data  conditional variational autoencoder  time 300.0 ms to 500.0 ms  Trajectory  Task analysis  Robot kinematics  Predictive models  Computational modeling  Training data 
Abstract: Fluent and safe interactions of humans and robots require both partners to anticipate the others' actions. The bottleneck of most methods is the lack of an accurate model of natural human motion. In this work, we present a conditional variational autoencoder that is trained to predict a window of future human motion given a window of past frames. Using skeletal data obtained from RGB depth images, we show how this unsupervised approach can be used for online motion prediction for up to 1660 ms. Additionally, we demonstrate online target prediction within the first 300-500 ms after motion onset without the use of target specific training data. The advantage of our probabilistic approach is the possibility to draw samples of possible future motion patterns. Finally, we investigate how movements and kinematic cues are represented on the learned low dimensional manifold.


Title: Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach
Key Words: collision avoidance  Markov processes  mobile robots  motion control  multi-agent systems  multi-robot systems  random processes  stochastic processes  motion trajectories  planning-based approach  dynamic objects  planning-based social force approach  joint long-term prediction  individual agent velocities  social forces  weighted random walk algorithm  stochastic motion policies  long-term predictions  multiple agents  joint motion  local interactions  long-term human motion prediction  dynamic environments  intelligent vehicles  mobile robots  Trajectory  Prediction algorithms  Force  Predictive models  Planning  Stochastic processes  Robots 
Abstract: The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.


Title: Negotiating with a Robot: Analysis of Regulatory Focus Behavior
Key Words: control engineering computing  geriatrics  man-machine systems  psychology  robots  user interfaces  persuasive communication skills  social psychology theory  promotion behavior  prevention behavior  neutral behavior  companion robots  caregivers  elderly people  decisions taking  regulatory focus behavior  prevention focus  body gestures  negotiation scenario  Robots  Senior citizens  Psychology  Games  Speech recognition  Tracking  Human-robot interaction 
Abstract: Companion robots are more and more taking the role of caregivers for elderly people. Elderly people sometimes take the advice given by their family members or caregivers as a criticism. In this context, persuasive communication skills could be helpful. A social psychology theory called Regulatory Focus states that people have one of two inclinations when taking decisions: Promotion or Prevention Focus. Also, based on these inclinations, people can be influenced by the way the message is sent, including the speed of the speech and the amplitude of body gestures. In this paper, we analyze the influence of Regulatory Focus on a negotiation scenario, using 3 conditions: (1) a robot with a promotion behavior, (2) a robot with a prevention behavior, and (3) a robot with a neutral behavior. Our results support the results found in the psychology literature related to Regulatory Focus, suggesting that Promotion participants were more influenced by the robot showing a Promotion based behavior. Moreover, Prevention participants were more relaxed on the condition with the robot showing a Prevention based behavior, and accepted the biggest concession between the initial and final offer.


Title: Multi3: Multi-Sensory Perception System for Multi-Modal Child Interaction with Multiple Robots
Key Words: computer games  control engineering computing  educational robots  gesture recognition  human-robot interaction  mobile robots  multi-robot systems  robot vision  speech recognition  robotic platforms  child-robot interaction scenarios  Multi3  robotic sensory  perception capabilities  speech recognition modules  gesture recognition modules  modular multirobot architecture  action recognition modules  indoors interaction scenarios  child-robot interaction scene  multiple Kinect-based system  multiple robots  Multimodal child interaction  Multisensory perception system  Speech recognition  Trajectory  Robot sensing systems  Microphone arrays 
Abstract: Child-robot interaction is an interdisciplinary research area that has been attracting growing interest, primarily focusing on edutainment applications. A crucial factor to the successful deployment and wide adoption of such applications remains the robust perception of the child's multi-modal actions, when interacting with the robot in a natural and untethered fashion. Since robotic sensory and perception capabilities are platform-dependent and most often rather limited, we propose a multiple Kinect-based system to perceive the child-robot interaction scene that is robot-independent and suitable for indoors interaction scenarios. The audio-visual input from the Kinect sensors is fed into speech, gesture, and action recognition modules, appropriately developed in this paper to address the challenging nature of child-robot interaction. For this purpose, data from multiple children are collected and used for module training or adaptation. Further, information from the multiple sensors is fused to enhance module performance. The perception system is integrated in a modular multi-robot architecture demonstrating its flexibility and scalability with different robotic platforms. The whole system, called Multi3, is evaluated, both objectively at the module level and subjectively in its entirety, under appropriate child-robot interaction scenarios containing several carefully designed games between children and robots.


Title: Multi-Robot Coordination in Dynamic Environments Shared with Humans
Key Words: human-robot interaction  mobile robots  multi-robot systems  navigation  path planning  market-based framework  coordination mechanism  social costs  bid evaluations  realistic environment  human-aware navigation  human-agnostic planning  social constraints  multirobot coordination  dynamic environments  social human-populated environments  multirobot task allocation problem  static humans  moving humans  high-fidelity simulator  localization noise  static people  blocked passages  human-aware planning  human-agnostic navigation  robot experiments  MRTA metrics  Robot kinematics  Task analysis  Navigation  Planning  Resource management  Measurement 
Abstract: This work addresses multi-robot coordination in social human-populated environments using a market-based framework for solving the Multi-Robot Task Allocation (MRTA) problem. Humans are considered in the proposed coordination mechanism by means of accounting for social costs in bid evaluations and requesting collaboration in socially blocking situations. Initially, the effect of a realistic environment with varying number of static/moving humans on the behavior and performance of our method is studied through an extensive suite of experiments in a high-fidelity simulator. Results show that the total traveled distance and time are increased when humans are present in the environments. Localization noise is also increased particularly in the case of static people. In the second series of experiments, a number of problematic cases resulting in longer modified paths, blocked passages, and long waits have been investigated. A comparative study targeting human-agnostic navigation and planning, human-aware navigation and human-agnostic planning, and human-aware navigation and planning has been conducted. Both simulated and real robot experiments confirm the effectiveness of accounting for humans at both team and individual levels. This leads to respecting social constraints as well as achieving a better performance based on MRTA metrics.


Title: Social Attention: Modeling Attention in Human Crowds
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  path planning  publicly available crowd datasets  trained attention model  Social Attention  human crowds  robots  human predictable trajectories  human trajectory prediction  Trajectory  Navigation  Predictive models  Robots  Collision avoidance  Dynamics  Task analysis 
Abstract: Robots that navigate through human crowds need to be able to plan safe, efficient, and human predictable trajectories. This is a particularly challenging problem as it requires the robot to predict future human trajectories within a crowd where everyone implicitly cooperates with each other to avoid collisions. Previous approaches to human trajectory prediction have modeled the interactions between humans as a function of proximity. However, that is not necessarily true as some people in our immediate vicinity moving in the same direction might not be as important as other people that are further away, but that might collide with us in the future. In this work, we propose Social Attention, a novel trajectory prediction model that captures the relative importance of each person when navigating in the crowd, irrespective of their proximity. We demonstrate the performance of our method against a state-of-the-art approach on two publicly available crowd datasets and analyze the trained attention model to gain a better understanding of which surrounding agents humans attend to, when navigating in a crowd.


Title: Fully Convolutional Neural Networks for Road Detection with Multiple Cues Integration
Key Words: convergence  convolution  feature extraction  feedforward neural nets  gradient methods  image colour analysis  learning (artificial intelligence)  mobile robots  optical radar  position control  convolutional neural networks  multiple cues integration  autonomous driving  deep learning  road detection algorithms  pre-trained Resnet-lOl  RGB images  CNN  feature maps extraction  Lidar scanner  position map  image gradient  convergence  KITTI benchmark  Roads  Feature extraction  Laser radar  Three-dimensional displays  Task analysis  Fuses  Network architecture 
Abstract: Road detection from images is a key task in autonomous driving. The recent advent of deep learning (and in particular, CNN or convolutional neural networks) has greatly improved the performance of road detection algorithms. In this paper, we show how to fuse multiple different cues under the same convolutional network framework. Specifically, we adopt a pre-trained Resnet-lOl to extract feature maps from RGB images; we then connect it with three extra deconvolution layers. These deconvolution layers is trained conditioning on appropriate image cues, and in our case they are a height image (i.e. elevation map obtained by e.g. Lidar scanner), image gradient, and position map. We also design two skip layers to speed up the convergence. Experiments on KITTI benchmark show competitive performance of our new networks.


Title: A Deep Learning Based Behavioral Approach to Indoor Autonomous Navigation
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  navigational behaviors  deep learning architectures  semantic abstraction  navigation tasks  navigational missions  behavioral approach  indoor autonomous navigation  semantically rich graph representation  indoor robotic navigation  semantic locations  Navigation  Semantics  Visualization  Simultaneous localization and mapping  Robustness  Measurement 
Abstract: We present a semantically rich graph representation for indoor robotic navigation. Our graph representation encodes: semantic locations such as offices or corridors as nodes, and navigational behaviors such as enter office or cross a corridor as edges. In particular, our navigational behaviors operate directly from visual inputs to produce motor controls and are implemented with deep learning architectures. This enables the robot to avoid explicit computation of its precise location or the geometry of the environment, and enables navigation at a higher level of semantic abstraction. We evaluate the effectiveness of our representation by simulating navigation tasks in a large number of virtual environments. Our results show that using a simple sets of perceptual and navigational behaviors, the proposed approach can successfully guide the way of the robot as it completes navigational missions such as going to a specific office. Furthermore, our implementation shows to be effective to control the selection and switching of behaviors.


Title: Footstep Planning in Rough Terrain for Bipedal Robots Using Curved Contact Patches
Key Words: humanoid robots  legged locomotion  off-road vehicles  path planning  robot vision  rough terrain  rough terrain stepping  WALK-MAN humanoid robot  flat foothold contact analysis  rough local terrain surfaces  curved patch modeling system  6DoF footstep sequences  black box walking controller  proper environment modeling  visual perception  foothold placements  exteroceptive perception  curved contact patches  bipedal robots  footstep planning  Planning  Three-dimensional displays  Rough surfaces  Surface roughness  Robot sensing systems  Navigation 
Abstract: Bipedal robots have gained a lot of locomotion capabilities the past few years, especially in the control level. Navigation over complex and unstructured environments using exteroceptive perception, is still an active research topic. In this paper, we present a footstep planning system to produce foothold placements, using visual perception and proper environment modeling, given a black box walking controller. In particular, we extend a state-of-the-art search-based planning approach (ARA*) that produces 6DoF footstep sequences in 3D space for flat uneven terrain, to also handle rough curved surfaces, e.g. rocks. This is achieved by integrating both a curved patch modeling system for rough local terrain surfaces and a flat foothold contact analysis based on visual range input data, into the existing planning framework. The system is experimentally validated using real-world point clouds, while rough terrain stepping demonstrations are presented on the WALK-MAN humanoid robot, in simulation.


Title: Safe Distributed Lane Change Maneuvers for Multiple Autonomous Vehicles Using Buffered Input Cells
Key Words: collision avoidance  computational geometry  decision making  feedback  mobile robots  position control  road safety  road vehicles  safe distributed lane change maneuvers  multiple autonomous vehicles  reciprocal collision avoidance method  autonomous cars  linear dynamics  buffered input cell  Voronoi cell  Voronoi diagrams  vehicles control input  control stack  freeway driving scenario  decision-making layer  trajectory planning layer  feedback controller  BIC method  human-driven car  Collision avoidance  Robots  Vehicle dynamics  Aerospace electronics  Traffic control  Autonomous vehicles  Planning 
Abstract: This paper introduces the Buffered Input Cell as a reciprocal collision avoidance method for multiple vehicles with high-order linear dynamics, extending recently proposed methods based on the Buffered Voronoi Cell [1] and generalized Voronoi diagrams [2]. We prove that if each vehicle's control input remains in its Buffered Input Cell at each time step, collisions will be avoided indefinitely. The method is fast, reactive, and only requires that each vehicle measures the relative position of neighboring vehicles. We incorporate this collision avoidance method as one layer of a complete lane change control stack for autonomous cars in a freeway driving scenario. The lane change control stack comprises a decision-making layer, a trajectory planning layer, a trajectory following feedback controller, and the Buffered Input Cell for collision avoidance. We show in simulations that collisions are avoided with multiple vehicles simultaneously changing lanes on a freeway. We also show in simulations that autonomous cars using the BIC method effectively avoid collisions with an aggressive human-driven car.


Title: End-to-End Driving Via Conditional Imitation Learning
Key Words: collision avoidance  learning systems  mobile robots  road traffic control  driving policy functions  conditional imitation learning  sensorimotor coordination  vision-based driving  robotic truck  driving policies  deep networks  high-level navigational commands  urban driving  high-level command input  condition imitation  Robot sensing systems  Task analysis  Vehicles  Cameras  Roads  Navigation 
Abstract: Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.


Title: Learning Steering Bounds for Parallel Autonomous Systems
Key Words: Bayes methods  cameras  control engineering computing  Gaussian processes  learning (artificial intelligence)  mixture models  mobile robots  neural nets  path planning  road vehicles  robot vision  steering systems  parallel autonomous systems  deep learning  autonomous driving task  camera data input  autonomous navigation  vehicle control  continuous control probability distribution  deep neural network based algorithm  steering angles  parallel autonomy setting  driving conditions  variational Bayesian methods  steering bounds learning  end-to-end learning  steering control options  Gaussian mixture models  Autonomous vehicles  Navigation  Neural networks  Probability distribution  Decision making  Machine learning  Bayes methods 
Abstract: Deep learning has been successfully applied to “end-to-end” learning of the autonomous driving task, where a deep neural network learns to predict steering control commands from camera data input. However, the learned representations do not support higher-level decision making required for autonomous navigation, nor the uncertainty estimates required for parallel autonomy, where vehicle control is shared between human and robot. This paper tackles the problem of learning a representation to predict a continuous control probability distribution, and thus steering control options and bounds for those options, which can be used for autonomous navigation. Each mode of the distribution encodes a possible macro-action that the system could execute at that instant, and the covariances of the modes place bounds on safe steering control values. Our approach has the added advantage of being trained on unlabeled data collected from inexpensive cameras. The deep neural network based algorithm generates a probability distribution over the space of steering angles, from which we leverage Variational Bayesian methods to extract a mixture model and compute the different possible actions in the environment. A bound, which the autonomous vehicle must respect in our parallel autonomy setting, is then computed for each of these actions. We evaluate our approach on a challenging dataset containing a wide variety of driving conditions, and show that our algorithm is capable of parameterizing Gaussian Mixture Models for possible actions, and extract steering bounds with a mean error of only 2 degrees. Additionally, we demonstrate our system working on a full scale autonomous vehicle and evaluate its ability to successful handle various different parallel autonomy situations.


Title: End to End Learning of Spiking Neural Network Based on R-STDP for a Lane Keeping Vehicle
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  neural nets  road vehicles  robot vision  SLAM (robots)  spiking neural network  lane keeping vehicle  mobile applications  mobile robot applications  reward-modulated spike-timing-dependent-plasticity  reinforcement learning  Pioneer robot  lane information  robot tasks control  end to end learning approach  R-STDP  SNNs training  neuromorphic vision sensor  lateral localization accuracy  Voltage control  Task analysis  Robot sensing systems  Training  Synapses  Neurons 
Abstract: Learning-based methods have demonstrated clear advantages in controlling robot tasks, such as the information fusion abilities, strong robustness, and high accuracy. Meanwhile, the on-board systems of robots have limited computation and energy resources, which are contradictory with state-of-the-art learning approaches. They are either too lightweight to solve complex problems or too heavyweight to be used for mobile applications. On the other hand, training spiking neural networks (SNNs) with biological plausibility has great potentials of performing fast computation and energy efficiency. However, the lack of effective learning rules for SNNs impedes their wide usage in mobile robot applications. This paper addresses the problem by introducing an end to end learning approach of spiking neural networks for a lane keeping vehicle. We consider the reward-modulated spike-timing-dependent-plasticity (R-STDP) as a promising solution in training SNNs, since it combines the advantages of both reinforcement learning and the well-known STDP. We test our approach in three scenarios that a Pioneer robot is controlled to keep lanes based on an SNN. Specifically, the lane information is encoded by the event data from a neuromorphic vision sensor. The SNN is constructed using R-STDP synapses in an all-to-all fashion. We demonstrate the advantages of our approach in terms of the lateral localization accuracy by comparing with other state-of-the-art learning algorithms based on SNNs.


Title: A Dual-Modal Vision-Based Tactile Sensor for Robotic Hand Grasping
Key Words: backpropagation  CCD image sensors  elastomers  force measurement  image texture  neural nets  robots  shape recognition  tactile sensors  robotic hand grasping  force vector distribution  transparent elastomer  transparent acrylic board  CCD camera  reflective membrane  markers array  object contact surface  backpropagation neural network  local binary pattern algorith  force magnitude  force direction  surface texture sensing  dual-modal vision-based tactile sensor  texture recognition rate  texture information  Force  Tactile sensors  Neurons  Cameras  Light emitting diodes 
Abstract: Humans' fingertips can perceive not only the magnitude and the direction of force but also the texture of object. When we grasp an object, the surface texture sensing of the fingertip helps us recognize the object and the force feeling that is parallel to the skin helps us grasp stably. Focusing on these points, we have developed a dual-modal vision-based tactile sensor that can measure the texture of object and a distribution of force vectors. The tactile sensor consists of a transparent elastomer, a camera, a piece of transparent acrylic board, LEDs and supporting structures. A reflective membrane and markers array are on the surface of the elastomer. An applied force on the elastic body results in movements of the markers, which are acquired by the CCD camera. In addition, the shape and texture of the object's contact surface can be reflected by the membrane deformations. The distribution of force vectors is determined by the BP neural network. The local binary pattern algorithm using captured images calculates the texture information. This paper reports experimental evaluation results concerning accuracy of determination of magnitude, direction of force, and texture recognition rate.


Title: Adapting the Goals/Questions/Metrics (GQM) Method for Applications in Robot Design
Key Words: grippers  service robots  Goals/Questions/Metrics method  robot design  advanced robots  resource-intensive activity  research teams  complex robot systems  design metrics  design tool  design-orientated GQM method  bespoke robotic gripper  service robot  GQM principles  robotics applications  Measurement  Prototypes  Grippers  Service robots  Robot sensing systems  Planning 
Abstract: Developing advanced robots can be a resource-intensive activity that creates many challenges for research teams. There is a need to formulate new techniques for systematically designing complex robot systems, especially in cases where high adaptability is needed and design metrics cannot be explicitly specified in advance. This research explores how the Goals/Questions/Metrics (GQM) method, a well-established technique for process measurement, can be modified for use as a design tool in robotics. To illustrate how a design-orientated GQM method may be used in practice, a sample use-case is given detailing how the approach was applied to the task of developing a bespoke robotic gripper for a service robot. The study provides an early indication that the adoption of GQM principles by designers can have significant benefits in robotics applications. However, further investigation is needed to better understand the magnitude and scope of any improvements.


Title: The Exchange of Knowledge Using Cloud Robotics
Key Words: cloud computing  ontologies (artificial intelligence)  robots  ontologies  OPENEASE cloud engine  web-based user interface  Fetch robot  PR2 robots  execution logs  knowledge exchange  encyclopedic knowledge  cloud application  crowd-sourcing  cloud robotics  Robots  Ontologies  Semantics  Task analysis  Containers  Cloud computing  Cognition 
Abstract: To enable robots to perform human-level tasks flexibly in varying conditions, we need a mechanism that allows them to exchange knowledge between themselves for crowd-sourcing the knowledge gap problem. One approach to achieve this is to equip a cloud application with a range of encyclopedic knowledge (i.e. ontologies) and execution logs of different robots performing the same tasks in different environments. In this paper, we show how knowledge exchange between robots can be done using OPENEASE as the cloud application. We equipped OPENEASE with ontologies about the kitchen domain, execution logs of three robots operating in two different kitchens, and semantic descriptions of both environments. By addressing two different use cases, we show that two PR2 robots and one Fetch robot can successfully adapt each other's plan parameters and sub symbolic data to the experiments that they are conducting.


Title: Dry Stacking for Automated Construction with Irregular Objects
Key Words: assembly planning  brick  building management systems  buildings (structures)  construction industry  disasters  heuristic programming  mechanical stability  robotic assembly  statistical analysis  structural engineering  automated construction  irregular objects  dry stacked structures  disaster areas  remote environments  assembly planning process  bricks  heuristics programming  Shape  Stacking  Planning  Stability analysis  Two dimensional displays  Building materials 
Abstract: We describe a method for automatically building structures from stacked, irregularly shaped objects. This is a simplified model for the problem of building dry stacked structures (i.e. no mortar) from found stones. Although automating such construction methods would be ideally suited for disaster areas or remote environments, currently such structures need to be built by skilled masons. No practical methods for automating the assembly planning process are known. The problem is challenging since each assembly action can be drawn from a continuous space poses for an object and several local geometric and physical considerations strongly affect the overall stability. We show that structures that are built following a stacking order for perfect bricks can accommodate a limited amount of irregularity, however, their performance degrades quickly when objects deviate from their ideal shape. We present a strategy for stacking irregular shapes that first considers geometric and physical constraints to find a small set of feasible actions and then further refines this set by using heuristics gathered from instructional literature for masons. The proposed method of choosing assembly actions allows construction with objects that contain a significant amount of variation.


Title: Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image
Key Words: image colour analysis  image reconstruction  image resolution  image sampling  image segmentation  image sensors  learning (artificial intelligence)  mean square error methods  optical radar  random processes  regression analysis  SLAM (robots)  sparse matrices  prediction root-mean-square error  sparse maps  dense maps  sparse-to-dense  dense depth prediction  sparse set  depth measurements  single RGB image  depth estimation  monocular images  low-resolution depth sensor  single deep regression network  RGB-D raw data  sparse depth samples  visual simultaneous localization and mapping algorithms  plug-in module  NYU-depth-v2 indoor dataset  LiDARs  Training  Laser radar  Image reconstruction  Estimation  Prediction algorithms  Simultaneous localization and mapping 
Abstract: We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software2 and video demonstration3 are publicly available.


Title: Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning
Key Words: blood vessels  convolution  image recognition  image segmentation  learning (artificial intelligence)  medical image processing  medical robotics  recurrent neural nets  surgery  thread centerline reconstruction  multistage suture detection  robot assisted anastomosis  deep learning  robust suture detection  suture augmentation  robotic-assisted surgery  fully convolutional neural networks  trainee suturing skill evaluation  curvilinear structure detector  Yarn  Instruction sets  Surgery  Splines (mathematics)  Image reconstruction  Robots  Task analysis 
Abstract: The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.


Title: Active Clothing Material Perception Using Tactile Sensing and Deep Learning
Key Words: clothing  control engineering computing  convolution  feedforward neural nets  image sensors  intelligent robots  learning (artificial intelligence)  mobile robots  robot vision  tactile sensors  active clothing material perception  tactile sensing  deep learning  intelligent robot  robot system  object properties  common object category  external Kinect sensor  GelSight tactile sensor  tactile data  physical properties  durability  semantic properties  clothing properties  active tactile perception system  vision-touch system  robots  varied clothing related housework  convolutional neural networks  Clothing  Tactile sensors  Shape  Grippers 
Abstract: Humans represent and discriminate the objects in the same category using their properties, and an intelligent robot should be able to do the same. In this paper, we build a robot system that can autonomously perceive the object properties through touch. We work on the common object category of clothing. The robot moves under the guidance of an external Kinect sensor, and squeezes the clothes with a GelSight tactile sensor, then it recognizes the 11 properties of the clothing according to the tactile data. Those properties include the physical properties, like thickness, fuzziness, softness and durability, and semantic properties, like wearing season and preferred washing methods. We collect a dataset of 153 varied pieces of clothes, and conduct 6616 robot exploring iterations on them. To extract the useful information from the high-dimensional sensory output, we applied Convolutional Neural Networks (CNN) on the tactile data for recognizing the clothing properties, and on the Kinect depth images for selecting exploration locations. Experiments show that using the trained neural networks, the robot can autonomously explore the unknown clothes and learn their properties. This work proposes a new framework for active tactile perception system with vision-touch system, and has potential to enable robots to help humans with varied clothing related housework.


Title: Topological Hotspot Identification for Informative Path Planning with a Marine Robot
Key Words: computational geometry  graph theory  greedy algorithms  image segmentation  marine control  mobile robots  path planning  robot vision  topological graph  greedy-coverage algorithm  informative path planning problem  topological hotspot identification  marine robot  topological map  biological hotspots  aquatic environment  Fast Marching-based Voronoi segmentation  scheduling problem  Path planning  Monitoring  Oceans  Robot sensing systems  Task analysis  Frequency modulation 
Abstract: In this work, we present a novel method for constructing a topological map of biological hotspots in an aquatic environment using a Fast Marching-based Voronoi segmentation. Using this topological map, we develop a closed form solution to the scheduling problem for any single path through the graph. Searching over the space of all paths allows us to compute a maximally informative path that traverses a subset of the hotspots, given some budget. Using a greedy-coverage algorithm we can then compute an informative path. We evaluate our method in a set of simulated trials, both with randomly generated environments and a real-world environment. In these trials, we show that our method produces a topological graph which more accurately captures features in the environment than standard thresholding techniques. Additionally, We show that our method can improve the performance of a greedy-coverage algorithm in the informative path planning problem by guiding it to different informative areas to help it escape from local maxima.


Title: Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
Key Words: ecology  hydrological equipment  hydrological techniques  microorganisms  multi-robot systems  remotely operated vehicles  reservoirs  water quality  data-driven behavior  real geophysical data  MODIS measurements  water-sampling apparatus  water quality sensor  plankton-rich water samples  chlorophyll density  autonomous surface vehicles plan  water-sampling behavior  efficient measurement  fresh-water systems  measuring contamination levels  drinking water  physical sampling  strategic water sampling  heterogeneous multirobot system  water reservoir  explorer robot  water sampling apparatus  ASV  Pollution measurement  Geophysical measurements  Robot sensing systems  Real-time systems  Time measurement  Water pollution 
Abstract: Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.


Title: Extended Kalman Filter-Based 3D Active-Alignment Control for LED Communication
Key Words: Kalman filters  light emitting diodes  mobile robots  optical communication  extended Kalman filter  proportional-integral controller  receiver-transmitter line  active alignment control system  transmitting device  active alignment system  mobile robots  Line-Of-Sight  underwater communication  optical communication  LED communication  active-alignment control  Receivers  Transmitters  Light emitting diodes  Robots  Three-dimensional displays  Estimation  Optical fiber communication 
Abstract: LED-based optical communication is emerging as a low-cost, high-data-rate alternative to the traditional acoustics mode of underwater communication. However, it is challenging to establish and maintain Line-Of-Sight (LOS) between the receiver and the transmitter, especially when such systems are used by mobile robots. Hence, there is a need for an active alignment system that enables the receiver to constantly align itself towards the direction of the transmitting device. In this paper, we propose and implement an active alignment control system capable of tracking a transmitting source moving in the three-dimensional (3D) space. An extended Kalman filter is used to estimate the components of the angle between the receiver orientation and the receiver-transmitter line. Using the estimate, a proportional-integral (PI) controller is implemented to adjust the receiver orientation. The algorithm uses one measurement of the light intensity from a single photo-diode, where successive measurements are obtained via a circular scanning technique. The amplitude of the scanning is adapted to the alignment performance, to achieve a sound trade-off between estimation accuracy, signal strength, and energy consumption. Simulation and experimental results are presented to illustrate the effectiveness of the proposed approach.


Title: Preliminary Evaluation of Cooperative Navigation of Underwater Vehicles without a DVL Utilizing a Dynamic Process Model
Key Words: attitude control  autonomous underwater vehicles  Global Positioning System  marine control  mobile robots  path planning  robot dynamics  robot kinematics  sensors  velocity measurement  preliminary evaluation  dynamic process model  fully dynamic vehicle process model  acoustic modem  surface vehicle  at-sea experimental trials  JHU Iver3 autonomous underwater vehicle  underwater vehicle navigation  DVL acoustic bottom-lock range  kinematic process model  dynamical process model  submerged vehicle  underwater communication  velocity measurements  attitude sensor  Acoustics  Underwater vehicles  Kinematics  Global Positioning System  Sensors 
Abstract: This paper reports a preliminary study for use of a fully dynamic vehicle process model in combined underwater communication and navigation (cooperative navigation) of underwater vehicles equipped with an acoustic modem, attitude, and depth sensors, but lacking a Doppler velocity log (DVL), and a surface vehicle equipped with an acoustic modem and GPS. We report both simulation and at-sea experimental trials with the JHU Iver3 autonomous underwater vehicle (AUV). The case of underwater vehicle navigation without a DVL is of interest in several use-cases including (a) small and low-cost underwater vehicles for which DVLs may be impractical or infeasible due to their size and cost and (b) for missions in which the vehicle's altitude above the sea floor (or depth beneath overhead ice) exceeds the DVL acoustic bottom-lock range. To the best of our knowledge, all previous studies on cooperative navigation have reported use of a kinematic process model, which works well in the presence of frequent, high-accuracy velocity measurements, as is the case when the vehicle is equipped with a DVL. This preliminary study suggests that the dynamical process model may offer a significant advantage over the purely kinematic model in the absence of frequent, high-accuracy velocity measurements, as is the case when the submerged vehicle is not equipped with a DVL.


Title: Self-Calibration of Mobile Manipulator Kinematic and Sensor Extrinsic Parameters Through Contact-Based Interaction
Key Words: calibration  computer graphics  end effectors  image registration  image sensors  manipulator kinematics  mobile robots  robot vision  mobile manipulator platform  mobile manipulator kinematic parameters  calibration rigs  centimetre-level post-calibration accuracy  end effector  registration algorithm  sensor extrinsic parameters  contact-based interaction  mobile manipulator self-calibration  point cloud registration  fixed vision sensor  mobile base  sensor calibration  manipulator kinematic model parameters  nonrigid registration process  on-board sensing  external measurement devices  Robot sensing systems  Three-dimensional displays  Manipulators  Calibration  Cameras  Kinematics  Transforms 
Abstract: We present a novel approach for mobile manipulator self-calibration using contact information. Our method, based on point cloud registration, is applied to estimate the extrinsic transform between a fixed vision sensor mounted on a mobile base and an end effector. Beyond sensor calibration, we demonstrate that the method can be extended to include manipulator kinematic model parameters, which involves a nonrigid registration process. Our procedure uses on-board sensing exclusively and does not rely on any external measurement devices, fiducial markers, or calibration rigs. Further, it is fully automatic in the general case. We experimentally validate the proposed method on a custom mobile manipulator platform, and demonstrate centimetre-level post-calibration accuracy in positioning of the end effector using visual guidance only. We also discuss the stability properties of the registration algorithm, in order to determine the conditions under which calibration is possible.


Title: Geometry Based Self Kinematic Calibration Method for Industrial Robots
Key Words: calibration  coordinate measuring machines  geometry  industrial robots  particle swarm optimisation  robot kinematics  industrial setting  kinematic calibration methodology  external metrology device  kinematic calibration model  optimal parameters/characteristics  Particle Swarm Optimization technique  Coordinate Measurement Machine  PSO  CMM  Yaskawa Motoman MHS-Hi robot  Yaskawa Motoman MHS-Hi robot  industrial robots  geometry based self kinematic calibration method  anthropomorphic robots  Robot kinematics  Calibration  Probes  Metrology  Bars  Data acquisition 
Abstract: Accuracy of robots is an important facet in an industrial setting. In this paper, we present a novel kinematic calibration methodology. Traditional calibration techniques require an external metrology device. Unlike those, the presented product here is highly practical in that it does not require a metrology device. The kinematic calibration model is formulated by making use of the robot itself as a metrology device to measure the geometry of a known artifact. The optimal parameters/characteristics of the model are identified using a Particle Swarm Optimization (PSO) technique. Our experimental results show that this new approach provides results comparable to those generated using spatial information provided by a Coordinate Measurement Machine (CMM). Using this new approach (GageCAL), the Yaskawa Motoman “MHS-Hi” robot is calibrated. Our experimental testing also indicates that this methodology can be extended to a wide variety of anthropomorphic robots.


Title: Inertial Parameters Identification of a Humanoid Robot Hanged to a Fix Force Sensor
Key Words: CAD  force sensors  humanoid robots  legged locomotion  motion control  parameter estimation  path planning  robot dynamics  fix force sensor  model-based controller  motion planning  dynamic identification  dynamic motions  safe fix base tree structure robot  optimal exciting motions  HOAP3 humanoid robot  6-axis force sensor  computer aided design data  inertial parameter identification  Humanoid robots  Force sensors  Dynamics  Robot sensing systems  Mathematical model  Optimization 
Abstract: Knowledge of the mass and inertial parameters of a humanoid robot is crucial for the development of model-based controller and motion planning in dynamics situation. Parameters are usually provided from Computer Aided Design (CAD) data and thus inaccurate specially if the robot is modified over time. In this paper, a practical method consisting of hanging a humanoid robot to a fix force sensor to perform its dynamic identification is proposed. This allows, contrary to the literature, to generate very exciting and dynamic motions to identify most of the elements of the inertia tensors in a reduced amount of time. This procedure transforms an instable floating base legged humanoid robot to a safe fix base tree structure robot which makes easier to generate optimal exciting motions. Because of a better excitation the overall trajectory lasts for less than a minute. The method was experimentally validated with a HOAP3 humanoid robot and using a 6-axis force sensor. A reduction of 3 times in average of the RMS difference between measured external reaction forces and moments and their estimates from CAD data was obtained with a single minute of optimal exciting motions.


Title: Online System Identification and Calibration of Dynamic Models for Autonomous Ground Vehicles
Key Words: calibration  mobile robots  vehicles  wheels  high-fidelity dynamical model  constant time algorithm  autonomous ground vehicles  dynamic models  online system identification  scale four wheel drive vehicle  estimated parameter  model parameters  informative motion segments  robotic platform  Calibration  Vehicle dynamics  Motion segmentation  Dynamics  Wheels  Friction 
Abstract: This paper is concerned with system identification and the calibration of parameters of dynamic models used in different robotic platforms. A constant time algorithm has been developed in order to automatically calibrate the parameters of a high-fidelity dynamical model for a robotic platform. The presented method is capable of choosing informative motion segments in order to calibrate model parameters in constant time while also calculating a confidence level on each estimated parameter. Simulations and experiments with a ⅛ th scale four wheel drive vehicle are performed to calibrate two of the parameters of test vehicle which demonstrate the accuracy and efficiency of the approach.


Title: On Geometric Models and Their Accuracy for Extrinsic Sensor Calibration
Key Words: calibration  geometry  numerical analysis  sensors  extrinsic sensor calibration methods  robotics  numerical simulation  abstract geometric model  Calibration  Cameras  Estimation  Task analysis  Simultaneous localization and mapping 
Abstract: Extrinsic sensor calibration is an important task in robotics. There are various ways to perform the calibration task, but it often remains unclear which methods are better than the others. In this paper, we provide a systematic study about the calibration accuracy of three types of calibration methods, each represented by an abstract geometric model based on the sensor configuration and the calibration setup. We discuss the advantages and disadvantages of each model and perform a rigorous study on their noise sensitivity from a geometric perspective. As a result, we can reveal and quantify the relative calibration accuracies of the three models, thus answering the question of “which model is better and why?”. Beside our analytical analysis, we also provide numerical simulation experiments that validate our findings.


Title: Dynamic Modeling and Identification of an Heterogeneously Actuated Underwater Manipulator Arm
Key Words: actuators  autonomous underwater vehicles  gears  manipulators  mobile robots  position control  telerobotics  arms parameters  linear actuators  identification procedure  manipulator arms  dynamic modeling  heterogeneously actuated underwater manipulator arm  electrically driven underwater robot manipulator  Ifremer's HROV Ariane underwater vehicle  hybrid remotely operated vehicle  Manipulator dynamics  Actuators  Vehicle dynamics  Gears  Friction  Mathematical model 
Abstract: This paper deals with the dynamic modeling and identification of an electrically driven underwater robot manipulator. The proposed study includes the dynamic modeling of the actuators of the arm as well as the identification of the parameters of the model. The proposed method deals with the specific case of heterogeneously actuated arms, namely arms with actuators behaving differently for each joint, being considered at the kinematic level. Indeed, we show how to estimate the arms parameters when some of their revolute joints are directly actuated by geared motors, while the others are actuated by linear actuators. A minimum set of identifiable parameters is determined, and adequate excitation trajectories are generated and used in the identification procedure. Realtime experimental validation on the manipulator arms of Ifremer's HROV (Hybrid Remotely Operated Vehicle) Ariane underwater vehicle demonstrates that the proposed method improves the estimation of the dynamic model.


Title: A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration
Key Words: image registration  image sensors  mobile robots  sensor fusion  flexible framework  general framework  explicit data association  flexible multicue photometric point cloud registration  mobile robots  mapping systems  recorded sensor data  photometric registration  multiple modalities  image data streams  pixel-wise difference  multichannel images  Three-dimensional displays  Robot sensing systems  Cameras  Iterative closest point algorithm  Minimization  Integrated circuit modeling  Laser radar 
Abstract: The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.


Title: Just-in-Time Reconstruction: Inpainting Sparse Maps Using Single View Depth Predictors as Priors
Key Words: convolution  feature extraction  image colour analysis  image fusion  image reconstruction  image sensors  iterative methods  neural nets  pose estimation  recurrent neural nets  robot vision  SLAM (robots)  stereo image processing  CRF model  RGB image  confidence-based fusion  realtime inpainting  convolutional neural networks  CNN  ORB-SLAM  Kinect  conditional depth error distributions  pixel-wise confidence weights  input depth map  fused depth map  virtual depth sensor  single-view depth prediction network  sparse sensor  monocular visual SLAM system  fully dense depth map  realtime image-guided inpainting  just-in-time reconstruction  single view depth predictors  scale-invariant depth error  outlier input depth  LIDAR depth maps  arbitrary scale  sparse map  Image reconstruction  Simultaneous localization and mapping  Visualization  Three-dimensional displays  Real-time systems  Uncertainty 
Abstract: We present “just-in-time reconstruction” as realtime image-guided inpainting of a map with arbitrary scale and sparsity to generate a fully dense depth map for the image. In particular, our goal is to inpaint a sparse map - obtained from either a monocular visual SLAM system or a sparse sensor - using a single-view depth prediction network as a virtual depth sensor. We adopt a fairly standard approach to data fusion, to produce a fused depth map by performing inference over a novel fully-connected Conditional Random Field (CRF) which is parameterized by the input depth maps and their pixel-wise confidence weights. Crucially, we obtain the confidence weights that parameterize the CRF model in a data-dependent manner via Convolutional Neural Networks (CNNs) which are trained to model the conditional depth error distributions given each source of input depth map and the associated RGB image. Our CRF model penalises absolute depth error in its nodes and pairwise scale-invariant depth error in its edges, and the confidence-based fusion minimizes the impact of outlier input depth values on the fused result. We demonstrate the flexibility of our method by real-time inpainting of ORB-SLAM, Kinect, and LIDAR depth maps acquired both indoors and outdoors at arbitrary scale and varied amount of irregular sparsity.


Title: A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS: Map of Ripples Segmentation
Key Words: computational geometry  convolution  image segmentation  robot vision  hand-drawn sketch maps  segmentation evaluation metric  ground-truth segmentations  Voronoi-based segmentation method  DuDe segmentation method  ground truth segmentations  segment maps  free space layout MAORIS  navigation maps  semantic representations  convolution  circular kernel  ripple-like patterns  Matthews correlation coefficient  map of ripples segmentation  Image segmentation  Merging  Robot kinematics  Robot sensing systems  Measurement  Two dimensional displays 
Abstract: How to divide floor plans or navigation maps into semantic representations, such as rooms and corridors, is an important research question in fields such as human-robot interaction, place categorization, or semantic mapping. While most works focus on segmenting robot built maps, those are not the only types of map a robot, or its user, can use. We present a method for segmenting maps from different modalities, focusing on robot built maps and hand-drawn sketch maps, and show better results than state of the art for both types. Our method segments the map by doing a convolution between the distance image of the map and a circular kernel, and grouping pixels of the same value. Segmentation is done by detecting ripple-like patterns where pixel values vary quickly, and merging neighboring regions with similar values. We identify a flaw in the segmentation evaluation metric used in recent works and propose a metric based on Matthews correlation coefficient (MCC). We compare our results to ground-truth segmentations of maps from a publicly available dataset, on which we obtain a better MCC than the state of the art with 0.98 compared to 0.65 for a recent Voronoi-based segmentation method and 0.70 for the DuDe segmentation method. We also provide a dataset of sketches of an indoor environment, with two possible sets of ground truth segmentations, on which our method obtains an MCC of 0.56 against 0.28 for the Voronoi-based segmentation method and 0.30 for DuDe.


Title: Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping
Key Words: continuous time systems  entropy  graph theory  image registration  image resolution  laser ranging  optical radar  SLAM (robots)  solid modelling  stereo image processing  laser-range scanners  high data rate  3D laser scanner  surfel-based registration  recursive state estimation  multiresolution maps  continuous-time SLAM  3D lidar-based online mapping  online simultaneous localization and mapping  Three-dimensional displays  Measurement by laser beam  Optimization  Trajectory  Laser modes  Simultaneous localization and mapping 
Abstract: Modern 3D laser-range scanners have a high data rate, making online simultaneous localization and mapping (SLAM) computationally challenging. Recursive state estimation techniques are efficient but commit to a state estimate immediately after a new scan is made, which may lead to misalignments of measurements. We present a 3D SLAM approach that allows for refining alignments during online mapping. Our method is based on efficient local mapping and a hierarchical optimization back-end. Measurements of a 3D laser scanner are aggregated in local multiresolution maps by means of surfel-based registration. The local maps are used in a multi-level graph for allocentric mapping and localization. In order to incorporate corrections when refining the alignment, the individual 3D scans in the local map are modeled as a sub-graph and graph optimization is performed to account for drift and misalignments in the local maps. Furthermore, in each sub-graph, a continuous-time representation of the sensor trajectory allows to correct measurements between scan poses. We evaluate our approach in multiple experiments by showing qualitative results. Furthermore, we quantify the map quality by an entropy-based measure.


Title: Efficient Mobile Robot Exploration with Gaussian Markov Random Fields in 3D Environments
Key Words: computer graphics  Gaussian processes  indoor environment  Markov processes  mobile robots  sampling methods  efficient computation algorithm  GMRF model hyperparameters  information gain  efficient mobile robot exploration  autonomous exploration  unknown indoor environments  mutual information  MI  informative sensing location  sampling method  random sensing patches  sensing patch  informative locations  training sample patches  established GMRF model  Gaussian Markov random fields  Gaussian process model  Robot sensing systems  Computational modeling  Mathematical model  Training  Mutual information 
Abstract: In this paper, we study the problem of autonomous exploration in unknown indoor environments using mobile robot. We use mutual information (MI) to evaluate the information the robot would get at a certain location. In order to get the most informative sensing location, we first propose a sampling method that can get random sensing patches in free space. Each sensing patch is extended to informative locations to collect information with true values. Then we use Gaussian Markov Random Fields (GMRF) to model the distribution of MI in environment. Compared with the traditional methods that employ Gaussian Process (GP) model, GMRF is more efficient. MI of every sensing location can be estimated using the training sample patches and the established GMRF model. We utilize an efficient computation algorithm to estimate the GMRF model hyperparameters so as to speed up the computation. Besides the information gain of the candidates regions, the path cost is also considered in this work. We propose a utility function that can balance the path cost and the information gain the robot would collect. We tested our algorithm in both simulated and real experiment. The experiment results demonstrate that our proposed method can explore the environment efficiently with relatively shorter path length.


Title: A Scalable Multi-Robot Task Allocation Algorithm
Key Words: computational complexity  industrial robots  mobile robots  multi-robot systems  nearest neighbour methods  pattern clustering  vehicle routing  warehouse automation  CVRP instance  nCAR  scalable multirobot task allocation algorithm  modern warehouses  docking station  route planning  capacity-constrained vehicle routing problem  nearest-neighbor based clustering and routing  Task analysis  Heuristic algorithms  Clustering algorithms  Resource management  Routing  Service robots 
Abstract: In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.


Title: Distributed Intermittent Communication Control of Mobile Robot Networks Under Time-Critical Dynamic Tasks
Key Words: control engineering computing  distributed control  mobile robots  multi-robot systems  protocols  scheduling  time-critical dynamic tasks  offline schedules  mobile robot networks  distributed intermittent communication control  task accomplishment  task planning  communication events  distributed control framework  communication constraints  intermittent communication protocols  connected networks  reliable networks  robot communication capabilities  Task analysis  Robot sensing systems  Time factors  Schedules  Communication networks 
Abstract: In this paper, we develop a distributed intermittent communication framework for teams of mobile robots that are responsible for accomplishing time-critical dynamic tasks and sharing the collected information with all other robots and possibly also with a user. Specifically, we consider situations where the robot communication capabilities are not sufficient to maintain reliable and connected networks while the robots move to accomplish their tasks. In this case, intermittent communication protocols are necessary that allow the robots to temporarily disconnect from the network in order to accomplish their tasks free of communication constraints. We assume that the robots can only communicate with each other when they meet at common locations in space. Our proposed distributed control framework determines offline schedules of communication events and integrates them online with task planning. The resulting paths ensure task accomplishment and exchange of information among robots infinitely often at locations that minimize a user-specified metric. Simulation results corroborate the proposed distributed control framework.


Title: Landmark-based Exploration with Swarm of Resource Constrained Robots
Key Words: distance measurement  Global Positioning System  mobile robots  multi-robot systems  path planning  robot vision  sensor fusion  landmark-based exploration  resource constrained robots  autonomous exploration  topological representation  topological information  exploitation strategy  robot swarm  GPS-denied environment  sensing capabilities  range sensor  dense landmarks  bearing angles  metric information  local navigation  Robot kinematics  Robot sensing systems  Navigation  Dispersion  Measurement 
Abstract: In this paper we consider the problem of autonomous exploration of an unknown, GPS-denied environment using a swarm of robots with very limited resources and limited sensing capabilities. To that end we use a landmark complex, a simplicial complex utilizing an observation of landmarks, as a topological representation of the environment. Each robot is equipped with an omni-directional, limited-range sensor that can identify landmarks in the robot's neighborhood. The robots use the bearing angles to the landmarks for local navigation. Given a collection of identifiable landmarks, a landmark complex can then be cumulatively constructed to encapsulate the topological information of the environment. Under the assumption of sufficiently dense landmarks, we propose an exploration and exploitation strategy that guides the swarm of robots to explore an environment using only bearing measurements without any metric information. Lastly, we demonstrate the coordinate-free and localization-free navigation in the environment using the constructed landmark complex.


Title: Coverage Control for Wire-Traversing Robots
Key Words: gradient methods  minimisation  mobile robots  motion control  path planning  continuous constrained coverage control problem  mobile robots  COW map  Continuous Onto Wires map  constrained locational cost minimization  final projection step  Lloyd descent algorithm  planar environment  continuous motion  one-dimensional manifolds  two-dimensional motion  wire-traversing robots  Wires  Minimization  Robot sensing systems  Optimization  Motion control  Power transmission lines 
Abstract: In this paper we consider the coverage control problem for a team of wire-traversing robots. The two-dimensional motion of robots moving in a planar environment has to be projected to one-dimensional manifolds representing the wires. Starting from Lloyd's descent algorithm for coverage control, a solution that generates continuous motion of the robots on the wires is proposed. This is realized by means of a Continuous Onto Wires (COW) map: the robots' workspace is mapped onto the wires on which the motion of the robots is constrained to be. A final projection step is introduced to ensure that the configuration of the robots on the wires is a local minimizer of the constrained locational cost. An algorithm for the continuous constrained coverage control problem is proposed and it is tested both in simulation and on a team of mobile robots.


Title: Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis
Key Words: brakes  braking  mobile robots  motion control  multi-robot systems  wheels  braking control region analysis  passive mobile robot  wheel  formation control  control law  passive robot  fundamental control method  active leader  multiple mobile robots  external pulling force  servo brakes  multiple passive-follower type robots  Mobile robots  Force  Wheels  Robot kinematics  Brakes  Torque 
Abstract: Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.


Title: Shaping in Practice: Training Wheels to Learn Fast Hopping Directly in Hardware
Key Words: control engineering computing  learning (artificial intelligence)  legged locomotion  robust control  temporary modifications  physical hardware  robot leg  reward landscape  fast hopping  robot controllers  engineering effort  potentially unstable parameters  training wheels  video synopsis  boom learning  robustness  Legged locomotion  Training  Wheels  Hardware  Hip 
Abstract: Learning instead of designing robot controllers can greatly reduce engineering effort required, while also emphasizing robustness. Despite considerable progress in simulation, applying learning directly in hardware is still challenging, in part due to the necessity to explore potentially unstable parameters. We explore the concept of shaping the reward landscape with training wheels; temporary modifications of the physical hardware that facilitate learning. We demonstrate the concept with a robot leg mounted on a boom learning to hop fast. This proof of concept embodies typical challenges such as instability and contact, while being simple enough to empirically map out and visualize the reward landscape. Based on our results we propose three criteria for designing effective training wheels for learning in robotics. A video synopsis can be found at https://youtu.be/6iH5E3LrYh8.


Title: Eager and Memory-Based Non-Parametric Stochastic Search Methods for Learning Control
Key Words: learning systems  nonparametric statistics  optimisation  robots  search problems  stochastic processes  learning control  direct policy search  complex problems  nonparametric methods  robot skill learning  memory-based learner  hybrid controller  memory-based non-parametric stochastic search methods  computing schedules  robot controller parameter optimisation  Stochastic processes  Robots  Search methods  Task analysis  Entropy  Computational modeling  Kernel 
Abstract: Direct policy search has shown to be a successful method to optimize robot controller parameters. However, defining a good parametric form for the controller can be challenging for complex problems. Non-parametric methods provide a flexible alternative and are thus a promising tool in robot skill learning. In this paper, we investigate two nonparametric methods based on similar principles but utilizing differing computing schedules: an eager learner and a memory-based learner. We compare the methods experimentally on two different control problems. Furthermore, we define and evaluate a new `hybrid' controller that combines the strong points of both of these methods.


Title: Data-driven Construction of Symbolic Process Models for Reinforcement Learning
Key Words: genetic algorithms  Internet  learning (artificial intelligence)  mobile robots  pendulums  time-varying systems  time varying dynamics  controlling systems  data driven construction  online  single node genetic programming  SNGP  pendulum swing up problem  training data  accurate models  real-time experiments  simulated mobile robot  realtime robot control  analytic equations  parsimonious models  symbolic regression  acceptable policy  RL  reinforcement learning  symbolic process models  Mathematical model  Data models  Learning (artificial intelligence)  Computational modeling  Mobile robots  Genetic programming  Model learning for control  AI-based methods  symbolic regression  reinforcement learning  optimal control 
Abstract: Reinforcement learning (RL) is a suitable approach for controlling systems with unknown or time-varying dynamics. RL in principle does not require a model of the system, but before it learns an acceptable policy, it needs many unsuccessful trials, which real robots usually cannot withstand. It is well known that RL can be sped up and made safer by using models learned online. In this paper, we propose to use symbolic regression to construct compact, parsimonious models described by analytic equations, which are suitable for realtime robot control. Single node genetic programming (SNGP) is employed as a tool to automatically search for equations fitting the available data. We demonstrate the approach on two benchmark examples: a simulated mobile robot and the pendulum swing-up problem; the latter both in simulations and real-time experiments. The results show that through this approach we can find accurate models even for small batches of training data. Based on the symbolic model found, RL can control the system well.


Title: PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-Based Planning
Key Words: learning (artificial intelligence)  mobile robots  navigation  neural nets  path planning  probability  robot dynamics  robot vision  sampling methods  sampling based planner  hierarchical method  sampling based path planning  large scale topology  probabilistic roadmaps  feature based deep neural net policies  continuous state  action spaces  simulation  office environments  aerial cargo delivery  urban environments  load displacement constraints  trajectories  noisy sensor conditions  flights  training  PRM RL  long range robotic navigation tasks  point to point navigation policies  end to end differential drive indoor navigation  nontrivial robot dynamics  robot configurations  task constraints  capture robot dynamics  RL agent  reinforcement learning  Task analysis  Robot sensing systems  Indoor navigation  Aerospace electronics  Learning (artificial intelligence) 
Abstract: We present PRM-RL, a hierarchical method for long-range navigation task completion that combines sampling-based path planning with reinforcement learning (RL). The RL agents learn short-range, point-to-point navigation policies that capture robot dynamics and task constraints without knowledge of the large-scale topology. Next, the sampling-based planners provide roadmaps which connect robot configurations that can be successfully navigated by the RL agent. The same RL agents are used to control the robot under the direction of the planning, enabling long-range navigation. We use the Probabilistic Roadmaps (PRMs) for the sampling-based planner. The RL agents are constructed using feature-based and deep neural net policies in continuous state and action spaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation tasks with non-trivial robot dynamics: end-to-end differential drive indoor navigation in office environments, and aerial cargo delivery in urban environments with load displacement constraints. Our results show improvement in task completion over both RL agents on their own and traditional sampling-based planners. In the indoor navigation task, PRM-RL successfully completes up to 215 m long trajectories under noisy sensor conditions, and the aerial cargo delivery completes flights over 1000 m without violating the task constraints in an environment 63 million times larger than used in training.


Title: Using Parameterized Black-Box Priors to Scale Up Model-Based Policy Search for Robotics
Key Words: control engineering computing  learning (artificial intelligence)  legged locomotion  optimisation  search problems  parameterized black-box priors  robotics  data-efficient algorithms  reinforcement learning  dynamical model  black-box optimization algorithm  model-based policy search approaches  model learning procedure  high-dimensional systems  physical hexapod robot  Black-DROPS algorithm  Robots  Data models  Mathematical model  Computational modeling  Heuristic algorithms  Analytical models  Task analysis 
Abstract: The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. Among the few proposed approaches, the recently introduced Black-DROPS algorithm exploits a black-box optimization algorithm to achieve both high data-efficiency and good computation times when several cores are used; nevertheless, like all model-based policy search approaches, Black-DROPS does not scale to high dimensional state/action spaces. In this paper, we introduce a new model learning procedure in Black-DROPS that leverages parameterized black-box priors to (1) scale up to high-dimensional systems, and (2) be robust to large inaccuracies of the prior information. We demonstrate the effectiveness of our approach with the “pendubot” swing-up task in simulation and with a physical hexapod robot (48D state space, 18D action space) that has to walk forward as fast as possible. The results show that our new algorithm is more data-efficient than previous model-based policy search algorithms (with and without priors) and that it can allow a physical 6-legged robot to learn new gaits in only 16 to 30 seconds of interaction time.


Title: Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation
Key Words: learning (artificial intelligence)  mobile robots  path planning  robot vision  double Q-learning  self-supervised deep reinforcement learning  self-supervised training  model-based methods  value-based model-free methods  learning-based methods  planning method  internal map  robot navigation  generalized computation graph  Computational modeling  Navigation  Learning (artificial intelligence)  Robots  Task analysis  Prediction algorithms  Planning 
Abstract: Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.


Title: Direct Line Guidance Odometry
Key Words: distance measurement  feature extraction  robot vision  SLAM (robots)  direct line guidance odometry  pixel intensities  line-based features  point-based direct monocular visual odometry method  visual odometry algorithms  feature extraction  keypoint selection  Feature extraction  IP networks  Cameras  Optimization  Visual odometry  Simultaneous localization and mapping  Computational efficiency 
Abstract: Modern visual odometry algorithms utilize sparse point-based features for tracking due to their low computational cost. Current state-of-the-art methods are split between indirect methods that process features extracted from the image, and indirect methods that deal directly on pixel intensities. In recent years, line-based features have been used in SLAM and have shown an increase in performance albeit with an increase in computational cost. In this paper, we propose an extension to a point-based direct monocular visual odometry method. Here we that uses lines to guide keypoint selection rather than acting as features. Points on a line are treated as stronger keypoints than those in other parts of the image, steering point-selection away from less distinctive points and thereby increasing efficiency. By combining intensity and geometry information from a set of points on a line, accuracy may also be increased.


Title: Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System
Key Words: cameras  image matching  motion estimation  motion measurement  optical radar  optical sensors  optical tracking  optical windows  portable instruments  SLAM (robots)  sparse depth information  motion estimation  pose-graph SLAM  KITTI odometry benchmark datasets  direct visual SLAM  monocular camera  light detection and ranging  portable camera-LiDAR mapping system  direct visual simultaneous localization and mapping  sliding window-based tracking method  depth-integrated frame matching  feature-based visual LiDAR mapping  sensors  Cameras  Laser radar  Three-dimensional displays  Visualization  Simultaneous localization and mapping  Optimization 
Abstract: This paper describes a framework for direct visual simultaneous localization and mapping (SLAM) combining a monocular camera with sparse depth information from Light Detection and Ranging (LiDAR). To ensure realtime performance while maintaining high accuracy in motion estimation, we present (i) a sliding window-based tracking method, (ii) strict pose marginalization for accurate pose-graph SLAM and (iii) depth-integrated frame matching for large-scale mapping. Unlike conventional feature-based visual and LiDAR mapping, the proposed approach is direct, eliminating the visual feature in the objective function. We evaluated results using our portable camera-LiDAR system as well as KITTI odometry benchmark datasets. The experimental results prove that the characteristics of two complementary sensors are very effective in improving real-time performance and accuracy. Via validation, we achieved low drift error of 0.98 % in the KITTI benchmark including various environments such as a highway and residential areas.


Title: Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift
Key Words: Bayes methods  learning (artificial intelligence)  object detection  robot vision  SLAM (robots)  monocular SLAM system  Bayesian framework  deep-learning based generic object detector  detection region  scale drift  monocular systems  Bayesian scale estimation  generic object detection  local scale correction  object class detection  KITTI dataset  quantitative evaluations  Simultaneous localization and mapping  Cameras  Three-dimensional displays  Trajectory  Bayes methods  Object detection  Image reconstruction 
Abstract: We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory. Within a Bayesian framework, it integrates observations from a deep-learning based generic object detector and landmarks from the map whose projection lie inside a detection region, to produce scale correction estimates from single frames. For each observation, a prior distribution on the height of the detected object class is used to define the observation's likelihood. Due to the scale drift inherent to monocular SLAM systems, we also incorporate a rough model on the dynamics of scale drift. Quantitative evaluations are presented on the KITTI dataset, and compared with different approaches. The results show a superior performance of our proposal in terms of relative translational error when compared to other monocular systems based on object detection.


Title: Efficient Active SLAM Based on Submap Joining, Graph Topology and Convex Optimization
Key Words: computational complexity  convex programming  least squares approximations  minimisation  mobile robots  path planning  predictive control  quadratic programming  robot vision  SLAM (robots)  graph topology  active SLAM problem  robot trajectory  area coverage task  model predictive control framework  uncertainty minimization MPC problem  graphical structure  2D feature-based SLAM  variable substitutions  convex optimization method  MPC framework  sequential quadratic programming method  linear SLAM  submap joining approach  planning  simultaneous localization and mapping  nonconvex constrained least-squares problem  Optimized production technology  Simultaneous localization and mapping  Uncertainty  Task analysis  Robot kinematics 
Abstract: The active SLAM problem considered in this paper aims to plan a robot trajectory for simultaneous localization and mapping (SLAM) as well as for an area coverage task with robot pose uncertainty. Based on a model predictive control (MPC) framework, these two problems are solved respectively by different methods. For the uncertainty minimization MPC problem, based on the graphical structure of the 2D feature-based SLAM, a non-convex constrained least-squares problem is presented to approximate the original problem. Then, using variable substitutions, it is further transformed into a convex problem, and then solved by a convex optimization method. For the coverage task considering robot pose uncertainty, it is formulated and solved by the MPC framework and the sequential quadratic programming (SQP) method. In the whole process, considering the computation complexity, we use linear SLAM, which is a submap joining approach, to reduce the time for planning and estimation. Finally, various simulations are presented to validate the effectiveness of the proposed approach.


Title: 2D SLAM Correction Prediction in Large Scale Urban Environments
Key Words: image representation  mobile robots  multilayer perceptrons  pose estimation  robot vision  SLAM (robots)  autonomous mobile robots  large scale urban environments  simultaneous location and mapping  hybrid correction module  likelihood distributions  2D likelihood SLAM approaches  successive estimated poses  Ensemble Multilayer Perceptron model  SLAM estimations  systematic errors  sensor measurement errors  SLAM map representation  observation model  motion model  probabilistic formulation  Simultaneous localization and mapping  Two dimensional displays  Estimation  Neural networks  Predictive models  Kalman filters 
Abstract: Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.


Title: Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition
Key Words: mobile robots  object recognition  robot vision  sensor fusion  SLAM (robots)  omnidirectional multisensory perception fusion  long-term place recognition  long-term autonomy  omnidirectional sensors  omnidirectional observation  multidirectional place recognition  omnidirectional multisensory data  appearance variations  Simultaneous Localization and Mapping  Feature extraction  Sensor phenomena and characterization  Simultaneous localization and mapping  Optimization 
Abstract: Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.


Title: Online Initialization and Automatic Camera-IMU Extrinsic Calibration for Monocular Visual-Inertial SLAM
Key Words: accelerometers  calibration  cameras  gyroscopes  inertial navigation  iterative methods  mobile robots  optimisation  robot vision  SLAM (robots)  extrinsic orientation  extrinsic translation  accelerometer bias  camera-IMU extrinsic parameters  initial values  visual scale  initialization stage  mechanical configuration  sensor suite changes  online initialization method  translation calibration  initialization procedure  gyroscope bias  monocular visual-inertial SLAM techniques  gyroscope  gravitational magnitude  Gyroscopes  Cameras  Quaternions  Accelerometers  Calibration  Simultaneous localization and mapping  Gravity 
Abstract: Most of the existing monocular visual-inertial SLAM techniques assume that the camera-IMU extrinsic parameters are known, therefore these methods merely estimate the initial values of velocity, visual scale, gravity, biases of gyroscope and accelerometer in the initialization stage. However, it's usually a professional work to carefully calibrate the extrinsic parameters, and it is required to repeat this work once the mechanical configuration of the sensor suite changes slightly. To tackle this problem, we propose an online initialization method to automatically estimate the initial values and the extrinsic parameters without knowing the mechanical configuration. The biases of gyroscope and accelerometer are considered in our method, and a convergence criteria for both orientation and translation calibration is introduced to identify the convergence and to terminate the initialization procedure. In the three processes of our method, an iterative strategy is firstly introduced to iteratively estimate the gyroscope bias and the extrinsic orientation. Secondly, the scale factor, gravity, and extrinsic translation are approximately estimated without considering the accelerometer bias. Finally, these values are further optimized by a refinement algorithm in which the accelerometer bias and the gravitational magnitude are taken into account. Extensive experimental results show that our method achieves competitive accuracy compared with the state-of-the-art with less calculation.


Title: Sonar Visual Inertial SLAM of Underwater Structures
Key Words: oceanographic techniques  SLAM (robots)  sonar  underwater sound  underwater vehicles  underwater structures  acoustic range data  sonar visual inertial SLAM  visual-inertial state estimation package  resource management  marine archaeology  underwater acoustic sensor  underwater cave  underwater wrecks  underwater domain  Sonar  Cameras  Visualization  Sonar navigation  Simultaneous localization and mapping  Underwater structures 
Abstract: This paper presents an extension to a state of the art Visual-Inertial state estimation package (OKVIS) in order to accommodate data from an underwater acoustic sensor. Mapping underwater structures is important in several fields, such as marine archaeology, search and rescue, resource management, hydrogeology, and speleology. Collecting the data, however, is a challenging, dangerous, and exhausting task. The underwater domain presents unique challenges in the quality of the visual data available; as such, augmenting the exteroceptive sensing with acoustic range data results in improved reconstructions of the underwater structures. Experimental results from underwater wrecks, an underwater cave, and a submerged bus demonstrate the performance of our approach.


Title: Differential Flatness Transformations for Aggressive Quadrotor Flight
Key Words: helicopters  mobile robots  stability  trajectory control  flight envelope  hierarchical control  quadrotor flight  differential flatness transformation  trajectory control  stability issues  Trajectory  Attitude control  Standards  Acceleration  Aerospace electronics  Australia  Robustness 
Abstract: Aggressive maneuvering amongst obstacles could enable advanced capabilities for quadrotors in applications such as search and rescue, surveillance, inspection, and situations where rapid flight is required in cluttered environments. Previous works have treated quadrotors as differentially flat systems, and this property has been exploited widely to design simple algorithms that generate dynamically feasible trajectories and to enable hierarchical control. The differentially flat property allows the full state of the quadrotor to be extracted from the reduced dimensional space of x, y, z, yaw and their derivatives. This differential flatness transformation has a number of singularities, however, as well as stability issues when controlling near these singularities. Many methods have been described in the literature to address these; however, they all have limitations when exploring the full flight envelope of a quadrotor, including roll or pitch angles past 90°, and during inverted flight. In this paper, we review these existing methods and then introduce our method, which combines multiple methods to provide a highly-robust differential flatness transformation that addresses most of these issues. Our approach is demonstrated enabling highly-aggressive quadrotor flight in both simulations and real-world experiments.


Title: Autonomous Control of the Interacting-BoomCopter UAV for Remote Sensor Mounting
Key Words: aircraft control  autonomous aerial vehicles  finite state machines  mobile robots  propellers  robot vision  target tracking  Interacting-BoomCopter UAV  remote sensor mounting  sensor package  vertical surface  unmanned aerial vehicle  on-board webcam  reversible propeller  aerial manipulation task  vehicle design  image processing algorithms  target tracking  extended finite state machine  high-level autonomous control  autonomous control strategy  I-BC platform  autonomous sensor  Task analysis  Propellers  Webcams  Unmanned aerial vehicles  Inspection  Force  Control systems 
Abstract: This paper presents a novel approach for autonomously mounting a sensor package on a vertical surface with an unmanned aerial vehicle (UAV). The Interacting-BoomCopter (I-BC) UAV uses an on-board webcam and computer along with a horizontally-mounted reversible propeller on its front boom to autonomously perform the aerial manipulation task. An overview of the vehicle design is presented along with the image processing algorithms used for target tracking, and the implementation of an extended finite state machine (EFSM) for carrying out the high-level autonomous control. The effectiveness of the autonomous control strategy and I-BC platform are examined through the performance of several autonomous sensor mounting flight tests.


Title: Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles
Key Words: aerospace robotics  collision avoidance  helicopters  mobile robots  predictive control  robot dynamics  vehicle dynamics  path planning  trajectory generation algorithms  MPC  sequential linear quadratic  SLQ  obstacle-avoidance algorithm  Model Predictive Control  dynamic environments  planning algorithms  multirotor  suspended load  Heuristic algorithms  Trajectory  Cost function  Mathematical model  Vehicle dynamics  Load modeling  Computational modeling 
Abstract: This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.


Title: Distal End Force Sensing with Optical Fiber Bragg Gratings for Tendon-Sheath Mechanisms in Flexible Endoscopic Robots
Key Words: Bragg gratings  end effectors  endoscopes  feedback  fibre optic sensors  force sensors  friction  haptic interfaces  medical robotics  surgery  distal end haptic sensing  compression force  tension force  surgical end-effectors  mechanics analysis  verification tests  tendon-sheath driven grasper  TSMs-driven systems  distal end force sensing  optical fiber Bragg gratings  tendon-sheath mechanisms  haptic feedback  endoscopic surgical robots  transmission systems  nonlinear friction profiles  nitinol tube  FBG fiber  robotic fingers-hands  wearable devices  rehabilitation devices  Force  Robot sensing systems  Tendons  Fiber gratings  Haptic Sensing  Fiber Bragg Gratings  Flexible Surgical Endoscopic Robot  Tendon-Sheath Mechanisms 
Abstract: Accurate haptic feedback is a critical challenge for surgical robots, especially for flexible endoscopic surgical robots whose transmission systems are Tendon-Sheath Mechanisms (TSMs) with highly nonlinear friction profiles and force hysteresis. For distal end haptic sensing of TSMs, this paper, for the first time, proposes to measure the compression force on the sheath at the distal end so that the tension force on the tendon, which equals the compression force on the sheath, can be obtained. A new force sensor, i.e., a nitinol tube attached with an optical Fiber Bragg Grating (FBG) fiber, is proposed to measure the compression force on the sheath. This sensor, with similar diameter and configuration (hollow) as the sheath, can be compactly integrated with TSMs and surgical end-effectors. In this paper, mechanics analysis and verification tests are presented to reveal the relationship between the tension force on the tendon and the compression force on the sheath. The proposed force sensor was calibrated in tests with a sensitivity of 24.28 pm/N and integrated with a tendon-sheath driven grasper to demonstrate the effectiveness of the proposed approach and sensor. The proposed approach and sensor can also be applied for a variety of TSMs-driven systems, such as robotic fingers/hands, wearable devices, and rehabilitation devices.


Title: Trajectory-Optimized Sensing for Active Search of Tissue Abnormalities in Robotic Surgery
Key Words: end effectors  Gaussian processes  knowledge acquisition  learning (artificial intelligence)  medical robotics  mobile robots  position control  robot kinematics  surgery  trajectory optimisation (aerospace)  tumours  uncertain systems  tumors  Gaussian processes  stiffness distribution  palpation path  acquisition function  active learning algorithm  incorporate uncertainties  robot position  sensor measurements  robot-kinematics  trajectory-optimized sensing  tissue abnormalities  da Vinci research kit  insertable robotic effector platform  robotic surgery  6-DoF industrial arm  dVRK  IREP  Trajectory  Robot sensing systems  Optimization  Uncertainty  Bayes methods  Tumors 
Abstract: In this work, we develop an approach for guiding robots to automatically localize and find the shapes of tumors and other stiff inclusions present in the anatomy. Our approach uses Gaussian processes to model the stiffness distribution and active learning to direct the palpation path of the robot. The palpation paths are chosen such that they maximize an acquisition function provided by an active learning algorithm. Our approach provides the flexibility to avoid obstacles in the robot's path, incorporate uncertainties in robot position and sensor measurements, include prior information about location of stiff inclusions while respecting the robot-kinematics. To the best of our knowledge this is the first work in literature that considers all the above conditions while localizing tumors. The proposed framework is evaluated via simulation and experimentation on three different robot platforms: 6-DoF industrial arm, da Vinci Research Kit (dVRK), and the Insertable Robotic Effector Platform (IREP). Results show that our approach can accurately estimate the locations and boundaries of the stiff inclusions while reducing exploration time.


Title: Active Constraints Using Vector Field Inequalities for Surgical Robots
Key Words: brain  collision avoidance  manipulators  medical robotics  neurophysiology  surgery  vectors  deep brain neurosurgery  tremor-free procedures  robotic assistance  surgical robots  manipulator-boundary collisions  vector field inequality  active constraints  surgical tool tips  endonasal surgery  Quaternions  Surgery  Tools  Task analysis  Kinematics  Manipulators 
Abstract: Robotic assistance allows surgeons to perform dexterous and tremor-free procedures, but is still underrepresented in deep brain neurosurgery and endonasal surgery where the workspace is constrained. In these conditions, the vision of surgeons is restricted to areas near the surgical tool tips, which increases the risk of unexpected collisions between the shafts of the instruments and their surroundings, in particular in areas outside the surgical field-of-view. Active constraints can be used to prevent the tools from entering restricted zones and thus avoid collisions. In this paper, a vector field inequality is proposed that guarantees that tools do not enter restricted zones. Moreover, in contrast with early techniques, the proposed method limits the tool approach velocity in the direction of the forbidden zone boundary, guaranteeing a smooth behavior and that tangential velocities will not be disturbed. The proposed method is evaluated in simulations featuring two eight degrees-of-freedom manipulators that were custom-designed for deep neurosurgery. The results show that both manipulator-manipulator and manipulator-boundary collisions can be avoided using the vector field inequalities.


Title: A Method for Online Optimization of Lower Limb Assistive Devices with High Dimensional Parameter Spaces
Key Words: gait analysis  handicapped aids  medical robotics  advanced prosthesis controls  control parameters  optimization method  offline portion  intact subject gait data  neuromuscular control policy  ankle prosthesis  high-dimensional parameter spaces  parameter selection process  offline optimization procedure  dueling bandits problem  assistive lower-limb devices  control policies  lower limb assistive devices  online optimization  Knee  Prosthetics  Optimization  Torque  Neuromuscular  Trajectory 
Abstract: We propose a method for optimizing control policies for assistive lower-limb devices. The method frames parameter selection as a dueling bandits problem in which a user indicates his or her qualitative preferences between pairs of parameter sets chosen from a library. We generate the library through an offline optimization procedure that seeks to reproduce the varied gaits of healthy human subjects. By separating the parameter selection process into online and offline portions, the method can handle high-dimensional parameter spaces and produces policies that can generalize to different gait scenarios such as speed variation. We evaluate the method on five subjects walking on a powered knee and ankle prosthesis governed by a neuromuscular control policy that has 43 parameters. We find the five subjects preferred four different parameter sets from the library and that the resulting optima resemble intact subject gait data. This result suggests the offline portion of the optimization method indeed produces control parameters that can adapt to different gaits. Moreover, we find that for three out of the four parameter sets we tested, the procedure also generates parameters that improve the ability of the prosthesis to adapt to increasing gait speed by increasing ankle net work production. The results encourage further research and exploration in clinical settings toward advanced prosthesis controls that employ online learning.


Title: Endo-VMFuseNet: A Deep Visual-Magnetic Sensor Fusion Approach for Endoscopic Capsule Robots
Key Words: endoscopes  learning (artificial intelligence)  magnetic sensors  medical robotics  sensor fusion  sensor fusion techniques  endo-VMFuseNet  asymmetric sensor data  asynchronous sensor data  deep learning  active medical robots  passive capsule endoscopes  medical device companies  endoscopic capsule robots  deep visual-magnetic sensor fusion approach  Robot sensing systems  Magnetic separation  Magnetic levitation  Sensor fusion  Magnetic cores  Magnetic resonance imaging 
Abstract: In the last decade, researchers and medical device companies have made major advances towards transforming passive capsule endoscopes into active medical robots. One of the major challenges is to endow capsule robots with accurate perception of the environment inside the human body, which will provide necessary information and enable improved medical procedures. We extend the success of deep learning approaches from various research fields to the problem of sensor fusion for endoscopic capsule robots in the case of asynchronous and asymmetric sensor data without any need of calibration between sensors. The results performed on real pig stomach datasets show that our method achieves high precision for both translational and rotational movements and contains various advantages over traditional sensor fusion techniques.


Title: EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots
Key Words: distance measurement  endoscopes  learning (artificial intelligence)  medical robotics  particle filtering (numerical methods)  pose estimation  recurrent neural nets  robot vision  sensor fusion  multisensor fusion  endoscopy robots  endoscopic capsule robot trajectories  recurrent neural network  nonlinear kinematic model  sensor reliability  online estimation  particle filter  gastrointestinal tract  therapeutic technology  switching state-space model  particle filtering-based multisensory data fusion  Robot sensing systems  Switches  Kalman filters  Proposals  Endoscopes  Magnetic resonance imaging 
Abstract: A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.


Title: Force Control of Series Elastic Actuators-Driven Parallel Robot
Key Words: actuators  control system synthesis  force control  motion control  robot kinematics  torque control  Spatial Force control algorithm  Series Elastic Actuators-driven parallel Robot  Virtual Ground Robot  RFSEAs  Reaction Force-sensing Series Elastic Actuator  torque generation  force generation  Kinematics  VGR motions  Legged locomotion  Force control  Parallel robots  Force  Aerospace electronics  Actuators 
Abstract: This paper proposes a novel parallel robot - Virtual Ground Robot (VGR) - that is driven by three Series Elastic Actuators (SEAs) to interact with a human. The proposed Virtual Ground Robot provides a virtual ground on which a human can stand on and interact in three directions: the pitch, the roll and the height directions. The most significant features of the proposed VGR are that 1) it is driven by RFSEAs (Reaction Force-sensing Series Elastic Actuator), and thus it can provide precise forces and torques, 2) the size of the VGR is small enough for a human to stand on with ease, and 3) it can generate torque/force large to support a weight of a human. Taking advantage of RFSEAs utilized in the proposed VGR, Spatial Force control algorithm is proposed in this paper. In order to design this controller, the motions of VGR are defined in the task space, the joint space and the RFSEA level. Based on the Kinematics, force control of VGR in the task level, which is named Spatial Force Control is designed and verified using experiments.


Title: Analyzing and Improving Cartesian Stiffness Control Stability of Series Elastic Tendon-Driven Robotic Hands
Key Words: actuators  control system synthesis  dexterous manipulators  elasticity  force control  manipulator kinematics  position control  stability  stability criteria  series elastic tendon-driven robotic hands  dexterous manipulation  robotic hand design  fingertip force directions  Cartesian stiffness control  position dependent fingertip forces  stability conditions  Cartesian stiffness controllers  passive joint coupling  generalized passivity based stability boundary  Cartesian stiffness controlled series elastic tendon-driven robotic fingers  stability criteria  Stability criteria  Robots  Tendons  Force  Loading  Actuators 
Abstract: Robust and dexterous manipulation is identified as one of the critical challenges in the field of robotic hand design and control. A key requirement of dexterous manipulation is the ability to modulate fingertip force directions and magnitudes. Cartesian stiffness control is a strategy to generate position dependent fingertip forces. However the stability conditions for the Cartesian stiffness controllers vary nonlinearly because of dependency on the manipulator's configuration and loading forces. The challenge is enhanced in case of tendon-driven robotic hands due to passive joint coupling. In this work, we derive a generalized passivity based stability boundary for Cartesian stiffness. We then present a methodology to analyze the stability boundaries of Cartesian stiffness controlled series elastic tendon-driven robotic fingers. We also present a solution to improve stability by optimizing the arrangement of optimized passive compliance in parallel to the actuators based on the stability criteria. Our analysis not only allows for informed design of new robotic hands but also applies to improving performance of existing robotic hands.


Title: A Projected Inverse Dynamics Approach for Multi-Arm Cartesian Impedance Control
Key Words: force control  friction  manipulator dynamics  motion control  unknown object dynamics  projected inverse dynamics approach  multiarm Cartesian impedance control  model-based control framework  multiarm manipulation  control law  constrained subspaces  unconstrained subspaces  unconstrained components  motion task  Cartesian impedance behaviour  constrained component enforces contact  friction constraints  contact forces  constrained subspace  contact points  dual-arm platform  Dynamics  Impedance  Force  Aerospace electronics  Robots  Task analysis  Jacobian matrices 
Abstract: We propose a model-based control framework for multi-arm manipulation of a rigid object subject to external disturbances. The control framework, based on projected inverse dynamics, decomposes the control law into constrained and unconstrained subspaces. Unconstrained components accomplish the motion task with a desired 6-DOF Cartesian impedance behaviour against external disturbances. Meanwhile, the constrained component enforces contact and friction constraints by optimising for contact forces within the constrained subspace. External disturbances are explicitly compensated for without using force/torque sensors at the contact points. The approach is evaluated on a dual-arm platform manipulating a rigid object while coping with unknown object dynamics and human interaction.


Title: Whole-Body Sensory Concept for Compliant Mobile Robots
Key Words: compliance control  filtering theory  force sensors  human-robot interaction  mobile robots  motion control  navigation  neurocontrollers  path planning  torque control  compliant mobile robots  mobile robot navigation  direct physical contact  intuitive communication  physical interaction  disturbance forces  mobile platform  neural network approach  distance sensors  mobile robot applications  whole-body sensory  model-free filtering approach  6-DoF force-torque sensor  robot-human interaction  Robot sensing systems  Force  Mobile robots  Collision avoidance  Oscillators 
Abstract: Most of the conventional approaches to mobile robot navigation avoid any kind of contact with the environment or with humans. As nowadays distance sensors typically have a limited - and often only two-dimensional - field of view, collisions with the environment or contacts with humans cannot be fully avoided in practical mobile robot applications. On the other hand, direct physical contact can be used for intuitive communication between a robot and humans. In this paper, we present a whole-body sensory concept based on a 6-DoF force-torque sensor to perceive physical interaction between the robot and humans. To distinguish between external contact and disturbance forces that result from the motion of the mobile platform or oscillations, we present a novel model-free filtering approach based on a neural network. In extensive experiments carried out with our robot Canny we demonstrate the effectiveness and advantages of the neural network approach, which clearly outperforms a classical model-based one.


Title: Robust, Compliant Assembly via Optimal Belief Space Planning
Key Words: assembling  CAD  friction  geometry  mobile robots  optimal control  path planning  planning (artificial intelligence)  probability  robot dynamics  uncertain systems  compliant assembly  optimal belief space planning  automated manufacturing  robots  nonlinear contact-dynamics  model parameters  belief space planning problem  compliant system  asymptotically optimal belief space planner  kinodynamic motion planner  asymptotic optimality  multiple assembly tasks  CAD models  state spaces  object poses  geometry  friction  uncertainty  impedance-control  nondeterministic domains  probabilistic completeness  Planning  Robots  Trajectory  Uncertainty  Task analysis  Aerospace electronics  Dynamics 
Abstract: In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.


Title: Cooperative Manipulation and Identification of a 2-DOF Articulated Object by a Dual-Arm Robot
Key Words: manipulators  dual-arm robot  dual-arm manipulation  motion directions  motion constraints  coordinated task space frameworks  redundancy exploitation  robot arms  two degrees-of-freedom articulated object  Task analysis  Robot kinematics  Manipulators  Uncertainty  Kinematics  Estimation 
Abstract: In this work, we address the dual-arm manipulation of a two degrees-of-freedom articulated object that consists of two rigid links. This can include a linkage constrained along two motion directions, or two objects in contact, where the contact imposes motion constraints. We formulate the problem as a cooperative task, which allows the employment of coordinated task space frameworks, thus enabling redundancy exploitation by adjusting how the task is shared by the robot arms. In addition, we propose a method that can estimate the joint location and the direction of the degrees-of-freedom, based on the contact forces and the motion constraints imposed by the object. Experimental results demonstrate the performance of the system in its ability to estimate the two degrees of freedom independently or simultaneously.


Title: A Soft Pneumatic Fabric-Polymer Actuator for Wearable Biomedical Devices: Proof of Concept for Lymphedema Treatment
Key Words: bending  control system synthesis  elasticity  force control  medical robotics  motion control  patient monitoring  pneumatic actuators  polymers  manual lymphatic drainage  human arm  lateral force  polymer element  hyperelastic polymer  mechanical elements  robotic device  soft pneumatic fabric-polymer bending actuator  rigid actuators  soft actuators  wearable biomedical devices  soft pneumatic fabric-polymer actuator  lymphedema treatment  actuator motion  hyperelastic beam  polymer beam  fabric element  Iron  Actuators  Skin  Fabrics  Force  Shape  Strain 
Abstract: Soft actuators are ideal candidates for wearable biomedical devices, their inherent compliance, robustness, lightweight and the possibility to be washable take advantage over rigid actuators. Thus, a soft pneumatic fabric-polymer bending actuator as a base component for a robotic device for lymphedema treatment is reported in this work. The actuator is composed of two mechanical elements, one made of fabric and the other one made of a hyperelastic polymer which is stuck on the fabric element. The fabric element is designed and fabricated with a curved shape longer than the polymer element, that is a hyperelastic beam. To assemble both elements, the fabric element was folded before sticking in order to match the length of the polymer beam. Once the air is pumped into the fabric, it bends towards its original curved shape. Once the air is removed, the hyperelastic beam allows the actuator to recover its initial position. This actuator is capable of exerting compression and lateral force on a human arm mimicking manual lymphatic drainage. A mathematical model is presented which is in good agreement with the experimental data, it could serve to predict the actuator motion. An end-tip free bending displacement of about 2.2 cm and a bending force of about 0.35 N were achieved at 12.5 kPa. A proof-of-concept system for lymphedema treatment is presented as well.


Title: Force Control of Textile-Based Soft Wearable Robots for Mechanotherapy
Key Words: actuators  biomechanics  closed loop systems  force control  medical robotics  patient treatment  force tracking variability  force-controlled actuation patterns  soft robotic system  open-loop pressure-based control  soft robotic force control device  sinusoidal force profiles  closed-loop force control methodology  manual mechanotherapy practices  massage-magnitude forces  closed-loop force control system  fully soft sensors  muscular tissue  tissue regeneration  judicious force application  soft tissues  mechanotherapeutic applications  soft robotic wearable devices  biomedical applications  soft robotic devices  textile-based soft wearable robots  Sensors  Soft robotics  Force  Muscles  Biological tissues  Actuators 
Abstract: Soft robotic devices have been utilized in a number of biomedical applications involving human interaction. An emerging opportunity for soft robotic wearable devices is in mechanotherapeutic applications for the recovery and regeneration of soft tissues. Previous studies have implied that judicious force application during mechanotherapy plays an important role in the functional outcome of tissue regeneration. In this paper, we propose soft robotic devices with closed-loop force control to precisely manipulate muscular tissue. The developed devices incorporate fully soft sensors and actuators using textile-based materials and fabrication methods. The closed-loop force control system is demonstrated in bench studies to regulate massage-magnitude forces at frequencies akin to those expected in manual mechanotherapy practices. Testing of the device on human limbs demonstrates the precision and accuracy of the closed-loop force control methodology across different body shapes and types. When commanded to regulate sinusoidal force profiles (with amplitudes of 30N, 45N and 60N), the soft robotic force control device could regulate peak compressive loads to within 0.7N of the desired force. Conversely, open-loop pressure-based control resulted in up to +/-6.6N force tracking variability between participants. A soft robotic system with independently actuatable modules was also fabricated to demonstrate force-controlled actuation patterns to mimic manual massage techniques.


Title: HapWRAP: Soft Growing Wearable Haptic Device
Key Words: force feedback  haptic interfaces  pneumatic actuators  polymers  HapWRAP  soft growing wearable haptic device  soft robotics  lightweight wearable haptic devices  flexible low density polyethylene  directional force feedback  haptic feedback device  mechanoreceptors  air flow control  distributed touch feedback  pneumatic actuators  Actuators  Haptic interfaces  Soft robotics  Skin  Electron tubes  Pneumatic systems 
Abstract: Soft robotics and pneumatic actuation present opportunities for lightweight wearable haptic devices that provide distributed touch feedback to the skin. Ideally, such devices would be easily donned and doffed, since permanent coverage of a large area of the skin is undesirable. Here we present the design and evaluation of a concept device called HapWRAP: a growing haptic device constructed from flexible low density polyethylene. Controlled air flow through tubes and pouches allows HapWRAP to grow out of a compact housing unit and provide a combination of directional and force feedback to a user. When activated, HapWRAP grows up and around the forearm; its loops form a temporary sleeve. After growth, pneumatic actuators inflate and deflate to stimulate mechanoreceptors in the skin at distinguishable locations. This paper describes the design and manufacturing of HapWRAP, reports its performance metrics, and tests its suitability as a haptic feedback device. Participants were able to interpret force and direction cues from HapWRAP with 92.5% accuracy. These findings suggest that HapWRAP can be successfully used for applications where both force and direction cues are necessary.


Title: Autonomous and Portable Soft Exosuit for Hip Extension Assistance with Online Walking and Running Detection Algorithm
Key Words: actuators  biomechanics  gait analysis  medical robotics  patient rehabilitation  portable hip-only  augmenting human walking  different fixed assistance profiles  online classification algorithm  mass potential energy fluctuations  abdomen-mounted IMU  maximum hip extension  autonomous wearable robot  assistance profile individualization  hip extension assistance  online walking  autonomous hip-only  Legged locomotion  Hip  Thigh  Exoskeletons  Acceleration  Force 
Abstract: We present an autonomous and portable hip-only soft exosuit, for augmenting human walking and running that assists hip extension by delivering peak forces of 300N to the user. Different fixed assistance profiles for walking and running were applied based on an online classification algorithm. The approach is based on the biomechanical understanding that the center of mass potential energy fluctuations during walking and running are out of phase. Specifically, we monitor the vertical acceleration with an abdomen-mounted IMU at the moment of maximum hip extension. Validation is demonstrated with six subjects on the treadmill and with eight subjects outdoors. Our results demonstrated a 99.99% accuracy on average over the fourteen participants for various speeds (0.5 - 4m/s), slopes (-10 -20%), treadmill and overground terrain, loaded (13.6 kg) and unloaded, Exo On and Exo Off conditions, and different shoe types. Results from an evaluation outdoors overground on the energetics of eight subjects demonstrated a significant reduction for running when comparing Exo On to No Exo (3.9%) and for walking and running when comparing Exo On to Exo Off (12.2% and 8.2% respectively). This study represents the first demonstration of an autonomous wearable robot reducing the energy cost of running. Significant variation in response across subjects was observed, highlighting further improvements may be possible via assistance profile individualization with human-in-the-Ioop optimization.


Title: Design and Analysis of a Wearable Robotic Forearm
Key Words: ergonomics  groupware  human computer interaction  human-robot interaction  manipulator kinematics  medical robotics  service robots  user interfaces  collaborative tool  human-human collaboration  human ergonomic wear limits  robot autonomy  lightweight wearable robotic augmentation device  human-wearable collaboration  wearable robotic forearm  close-range human-robot collaboration  lightweight supernumerary third arm  shared workspace activities  functional prototype  iterative design process  reachable workspace  natural human reach  human-robot interaction  Solid modeling  Collaboration  Manipulators  Elbow  Load modeling  Prototypes 
Abstract: This paper presents the design of a wearable robotic forearm for close-range human-robot collaboration. The robot's function is to serve as a lightweight supernumerary third arm for shared workspace activities. We present a functional prototype resulting from an iterative design process including several user studies. An analysis of the robot's kinematics shows an increase in reachable workspace by 246 % compared to the natural human reach. The robot's degrees of freedom and range of motion support a variety of usage scenarios with the robot as a collaborative tool, including self-handovers, fetching objects while the human's hands are occupied, assisting human-human collaboration, and stabilizing an object. We analyze the bio-mechanical loads for these scenarios and find that the design is able to operate within human ergonomic wear limits. We then report on a pilot human-robot interaction study that indicates robot autonomy is more task-time efficient and preferred by users when compared to direct voice-control. These results suggest that the design presented here is a promising configuration for a lightweight wearable robotic augmentation device, and can serve as a basis for further research into human-wearable collaboration.


Title: Real-Time Learning of Efficient Lift Generation on a Dynamically Scaled Flapping Wing Using Policy Search
Key Words: aerodynamics  aerospace components  aerospace robotics  learning (artificial intelligence)  search problems  efficient lift generation  policy search algorithm  real-time robotic learning problem  dynamically scaled flapping robotic wing  degrees-of-freedom  mineral oil  Reynolds number  optimal wing pitching amplitude  stroke-pitch phase difference  aerodynamic efficiency  quasisteady aerodynamic mechanism  wing rotation  stroke reversal  unsteady lift generation mechanisms  stroke amplitude range  Trajectory  Heuristic algorithms  Servomotors  Real-time systems  Aerodynamics  Robot sensing systems 
Abstract: In this work, we present a successful application of a policy search algorithm to a real-time robotic learning problem, where the goal is to maximize the efficiency of lift generation on a dynamically scaled flapping robotic wing. The robotic wing has two degrees-of-freedom, i.e., stroke and pitch, and operates in a tank filled with mineral oil. For all experiments, the Reynolds number is maintained constant at 1000, where learning is performed for different prescribed stroke amplitudes to find the optimal wing pitching amplitude and the stroke-pitch phase difference that maximize the power loading (PL) of lift generation, a measure of aerodynamic efficiency. For the investigated stroke amplitude range (30°-90°), the efficiency is observed to increase with the stroke amplitude and the lift is mainly generated through the delayed stall, a quasi-steady aerodynamic mechanism. Furthermore, the wing rotation becomes more asymmetric with respect to stroke reversal as the stroke amplitude decreases, indicating an increased use of unsteady lift generation mechanisms at lower stroke amplitudes.


Title: Exploration and Inspection with Vine-Inspired Continuum Robots
Key Words: inspection  mobile robots  motion control  position control  shape control  motion generation  robot tendril hardware  International Space Station  NASA Johnson Space Center  continuum robot backbones  theoretical plant growth-inspired approach  inspection operations  long thin continuum robot exploration  vine-inspired movement strategies  robot access  thin-stemmed plants  vine-inspired continuum robots  Tendons  Strain  Adaptation models  Hardware  Robot kinematics  Inspection 
Abstract: In this paper, we show how structures and strategies employed by thin-stemmed plants can be adapted to improve robot access to unstructured and congested environments. Specifically, we show how the use of vine-inspired movement strategies can enhance long thin continuum robot exploration and inspection operations. We introduce a new theoretical plant growth-inspired approach for modeling and motion generation of continuum robot backbones. The approach is demonstrated in numerous experiments including inspection within a high fidelity, full-scale mock-up of the International Space Station at NASA Johnson Space Center, using novel robot tendril hardware.


Title: The Role of Massive Morphing Wings for Maneuvering a Bio-Inspired Bat-Like Robot
Key Words: aerospace components  biomimetics  mobile robots  position control  robot dynamics  rolling torques  pitch torque generation  massive morphing wings  bio-inspired bat-like robot  inertial effects  wing shape  robotic platform  massive morphing-wings  wingbeats  Robots  Aerodynamics  Trajectory  Heuristic algorithms  Elbow 
Abstract: In this paper we present an approach for analyzing the inertial effects of changing the wing shape for steering a bat-like robot. Using BaTboT, a robotic platform with massive morphing-wings, we have estimated the generation of pitching and rolling torques, which are directly related to forward and turning maneuvers. Results let us conclude that faster retraction of the wings during the upstroke, and slower extension during the downstroke increase both pitching and rolling torques in about 50% compared to those wingbeats with equal periods for retraction/extension. Also, we determined that the pitch torque generation is proportional to 0.6m1/f, whereas the rolling torque is promotional to 0.1m1/f, being m the mass of the robot and f the flapping frequency of the wings.


Title: Stability and Predictability in Dynamically Complex Physical Interactions
Key Words: human-robot interaction  pendulums  perturbation techniques  robust control  trajectory control  human control strategy  suspended pendulum  cart-pendulum system  assistive perturbations  resistive perturbations  trajectory stability  cart trajectories  robust control strategies  dynamically complex physical interactions  stability properties  human-object interaction  simplified 2D model  virtual implementation  Perturbation methods  Task analysis  Trajectory  Robots  Mathematical model  Stability analysis  Jacobian matrices 
Abstract: This study examines human control of physical interaction with objects that exhibit complex (nonlinear, chaotic, underactuated) dynamics. We hypothesized that humans exploited stability properties of the human-object interaction. Using a simplified 2D model for carrying a “cup of coffee”, we developed a virtual implementation to identify human control strategies. Transporting a cup of coffee was modeled as a cart with a suspended pendulum, where humans moved the cart on a horizontal line via a robotic manipulandum. The specific task was to transport the cart-pendulum system to a target, as fast as possible, while accommodating assistive and resistive perturbations. To assess trajectory stability, we applied contraction analysis. We showed that when the perturbation was assistive, humans absorbed the perturbation by controlling cart trajectories into a contraction region prior to the perturbation. When the perturbation was resistive, subjects passed through a contraction region following the perturbation. Entering a contraction region stabilizes performance and makes the dynamics more predictable. This human control strategy could inspire more robust control strategies for physical interaction in robots.


Title: First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle
Key Words: autonomous aerial vehicles  image colour analysis  mobile robots  path planning  robot vision  stereo image processing  multiroom exploration task  DelFly Explorer  autonomous indoor exploration mission  room exploration  stereo-vision based droplet algorithm  heading-based door passage algorithm  flapping wing vehicles  autonomous exploration tasks  autonomous multiroom exploration  wing vehicle  MAVs  autonomous indoor navigation  rotary wings  flapping wing MAV  stereo vision system  microair vehicles  monocular color based Snake-gate algorithm  Task analysis  Robot sensing systems  Navigation  Collision avoidance  Cameras  Image color analysis 
Abstract: One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.


Title: Evaluating Robust Trajectory Control of a Miniature Rolling and Spinning Robot in Outdoor Conditions
Key Words: adaptive control  control system synthesis  feedback  legged locomotion  motion control  nonlinear control systems  robust control  trajectory control  variable structure systems  robust trajectory control  spinning robot mechanism  robot stability  trajectory following accuracy  wheel velocity response  ASMC controller  trajectory following control  miniature spherical rolling robot  nonlinear adaptive sliding mode  locomotory rolling patterns  roll angle stability  ISMC controller  integral sliding controller  Trajectory  Wheels  Spinning  Mobile robots  Mathematical model  Robustness  Spherical Robot  Rolling gait  Central Pattern Generator (CPG)  Trajectory following  Adaptive sliding mode (ASMC) Control 
Abstract: This paper presents trajectory following control experiments of a miniature spherical rolling and spinning robot mechanism on three different types of outdoor surfaces. The research is inspired from the efficient locomotory rolling patterns of various insects in unstructured environment. A nonlinear adaptive sliding mode (ASMC) feedback method maintains the robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed trajectory following control policy is developed, implemented and tested for the miniature spherical robot on three different types of irregular surfaces in outdoors. Trajectory following accuracy, roll angle stability and wheel velocity response are three parameters measured to evaluate robot performance. ASMC controller is compared with an integral sliding (ISMC) controller. Experimental results show that proposed control policy is able to manage an accurate trajectory following amidst robust control of a rolling and spinning robot on three types of irregular surface in practical outdoor conditions.


Title: Bio-Inspired Tensegrity Flexural Joints
Key Words: biomechanics  manipulator kinematics  motion control  tensegrity flexural manipulator  OpenSim simulation environment  tension analysis  human leg behavior  tensegrity manipulator  revolute joint  robotics literature model  bio-inspired tensegrity flexural joints  Knee  Legged locomotion  Joints  Biological system modeling  Hip  Muscles 
Abstract: Most robotics literature model the human's knee and hip as a revolute joint with limited range of rotation. Although somehow close to reality, this approach neglects a critical aspect of these joints, which is their internal flexibility. This paper presents a prototype tensegrity flexural manipulator whose kinematic behavior is inspired by human leg's gait. This prototype, which considers a hybrid (flexible-rigid) structure of the knee and hip would be able to better approximate real behavior and hopefully lead to a better design of artificial (prosthetic) knees and hips. The behavior of the proposed tensegrity manipulator was firstly predicted using OpenSim simulation environment. The paper reports the comparisons between the simulations, physical prototypes and human leg behavior for a variety of ranges of motions and tension analysis.


Title: Grasp Quality Evaluation with Whole Arm Kinematic Noise Propagation
Key Words: grippers  manipulator kinematics  path planning  probability  robust control  arm configurations  force closure region  kinematic robot structure  arm kinematic noise propagation  grasp quality evaluation  local robustness  arm configuration  grasp quality metric  redundant robot  Measurement  Force  Kinematics  Manipulators  Ellipsoids  Random variables 
Abstract: In this paper we propose a new approach to evaluate grasps that accounts for both the kinematic structure of the robot and the noise at its joints. Our starting observation is that with a redundant robot the same grasp can be implemented with different arm configurations, and these may display significant differences in terms of robustness to disturbances. Consequently, the grasp quality metric is seen as a random variable depending on the arm configuration. Starting from a first order approximation for the error, we introduce the high probability force closure region as a tool to evaluate the local robustness of an arm configuration, and we then introduce a new metric Qarm to rank different configurations according to the robustness to noise. By combining this method in an offline/online framework, we demonstrate through large scale simulations that this approach successfully captures aspects that were neglected in former literature regarding grasp evaluation, and can successfully be integrated into future grasp planners.


Title: Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning
Key Words: collision avoidance  finite element analysis  learning (artificial intelligence)  mobile robots  motion control  neurocontrollers  path planning  position control  realtime planning  high-DOF deformable bodies  arbitrarily-shaped volumetric deformable bodies  complex environments  high-dimensional configuration spaces  dynamics constraints  two-stage learning method  multitask controller  dynamic movement primitives  neural-network controller  DMP task  finite element method  contact invariant optimization  gradient-based method  two-stage learning algorithm  trained DMP controller  different navigation tasks  learned motion planner  walking deformable robots  obstacle avoidance  Deep Q-Learning  Planning  Deformable models  Robots  Finite element analysis  Strain  Computational modeling  Task analysis 
Abstract: We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.


Title: Grasping Flat Objects by Exploiting Non-Convexity of the Object and Support Surface
Key Words: concave programming  dexterous manipulators  geometry  grippers  nonconvexity  support surface  grasp strategy  environmental contact  nonconvex geometry  object-surface combination  domestic flat objects grasping  Grasping  Robots  Three-dimensional displays  Color  Geometry  Grippers  Visualization 
Abstract: In this paper we propose a grasp strategy which exploits environmental contact for grasping domestic flat objects placed or hinged on support surfaces. The proposed grasp strategy considers the non-convex geometry of the object-surface combination, as this appears in objects like plates on tables or handles on cupboards. Following the fact that state-of-the-art grasp planners fail to produce candidate grasps for flat objects due to the environmental constraint of the support surface, this work utilizes compliant interaction of the hand with the support surface, inspired by human grasp strategies.


Title: Caging Loops in Shape Embedding Space: Theory and Computation
Key Words: geometry  grippers  object detection  robot vision  topology  shape embedding space  robot gripper  surface geometry  caging grasps  Caging Loops  target object  Grasping  Grippers  Robots  Shape  Geometry  Topology  Robustness 
Abstract: We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.


Title: Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning
Key Words: convolution  dexterous manipulators  end effectors  feedforward neural nets  grippers  industrial manipulators  learning (artificial intelligence)  manipulator dynamics  deep learning  vacuum-based end effectors  multifinger grippers  suction cup  external wrenches  pneumatic suction gripper  point clouds  grasp quality convolutional neural network  robust vacuum suction grasp targets  gravity wrench  parallel-jaw grippers  object pose  material properties  GQ-CNN  ABB YuMi  adversarial  Three-dimensional displays  Robustness  Robots  Analytical models  Seals  Computational modeling  Planning 
Abstract: Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.


Title: Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation
Key Words: control engineering computing  human-robot interaction  learning by example  manipulators  neural nets  robot programming  robot vision  telerobotics  virtual reality  virtual reality teleoperation  robot skill acquisition  raw pixels  consumer-grade Virtual Reality headsets  hand tracking hardware  deep neural network policies  manipulation tasks  deep imitation learning  PR2 robot  RGB-D images  Robots  Task analysis  Neural networks  Three-dimensional displays  Head  Visualization  Grippers 
Abstract: Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.


Title: Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning
Key Words: collision avoidance  learning (artificial intelligence)  life testing  mobile robots  neurocontrollers  regression analysis  autonomous vehicle  imitation learning  surrogate agents  test scenario generation  performance modes  deep neural networks  imitator surrogates  mission performance  simulation-based testing  on-line imitation  complex mission  target vehicle  behavioral modes  dataset aggregation  collision avoidance  Testing  Training  Autonomous vehicles  Trajectory  Adaptation models  History 
Abstract: In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.


Title: Feature-Based Transfer Learning for Robotic Push Manipulation
Key Words: CAD  learning (artificial intelligence)  manipulators  contact models  motion models  point cloud object model  CAD model  contact-based predictors  robotic push manipulation  feature-based transfer learning  Robots  Three-dimensional displays  Predictive models  Solid modeling  Kernel  Probability density function  Training 
Abstract: This paper presents a data-efficient approach to learning transferable forward models for robotic push manipulation. Our approach extends our previous work on contact-based predictors by leveraging information on the pushed object's local surface features. We test the hypothesis that, by conditioning predictions on local surface features, we can achieve generalisation across objects of different shapes. In doing so, we do not require a CAD model of the object but rather rely on a point cloud object model (PCOM). Our approach involves learning motion models that are specific to contact models. Contact models encode the contacts seen during training time and allow generating similar contacts at prediction time. Predicting on familiar ground reduces the motion models' sample complexity while using local contact information for prediction increases their transferability. In extensive experiments in simulation, our approach is capable of transfer learning for various test objects, outperforming a baseline predictor. We support those results with a proof of concept on a real robot.


Title: Inducing Probabilistic Context-Free Grammars for the Sequencing of Movement Primitives
Key Words: Bayes methods  context-free grammars  formal languages  grammars  humanoid robots  learning (artificial intelligence)  Markov processes  Monte Carlo methods  motion control  probability  robot dynamics  robots  rule-based nature  formal grammars  complex robot policies  composing primitives  modern robotics  inducing probabilistic context-free grammars  simple movement primitives  complex sequences  degree-of-freedom lightweight robotic arm  Markov Chain Monte Carlo optimization  grammar space  robot movement primitives  physical nature  yet unsolved challenge  complicated challenge  way robot policies  hierarchical concept  recursively structured tasks  hierarchically tasks  Grammar  Robots  Task analysis  Probabilistic logic  Sequential analysis  Markov processes  Optimization 
Abstract: Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. In this work, we exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned applying a Markov Chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Restrictions to these operators guarantee continuous sequences while reducing the grammar space. We validate our method on a redundant 7 degree-of-freedom lightweight robotic arm on tasks that require the generation of complex sequences consisting of simple movement primitives.


Title: Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations
Key Words: image colour analysis  learning (artificial intelligence)  neural nets  object detection  robots  convolutional pose machines  human-readable plans learning  domain randomization  Baxter robot  image space  synthetic images  perception network  program execution  program generation  human-readable program  synthetically trained neural networks  world space  Task analysis  Training  Neural networks  Robot sensing systems  Robustness  Stacking 
Abstract: We present a system to infer and execute a human-readable program from a real-world demonstration. The system consists of a series of neural networks to perform perception, program generation, and program execution. Leveraging convolutional pose machines, the perception network reliably detects the bounding cuboids of objects in real images even when severely occluded, after training only on synthetic images using domain randomization. To increase the applicability of the perception network to new scenarios, the network is formulated to predict in image space rather than in world space. Additional networks detect relationships between objects, generate plans, and determine actions to reproduce a real-world demonstration. The networks are trained entirely in simulation, and the system is tested in the real world on the pick-and-place problem of stacking colored cubes using a Baxter robot.


Title: Generalized Task-Parameterized Skill Learning
Key Words: Gaussian processes  humanoid robots  human-robot interaction  learning (artificial intelligence)  manipulators  mixture models  motion control  robot programming  generalized task-parameterized skill learning  human skills  task-parameterized Gaussian mixture model  TP-GMM  human-robot collaboration  dual-arm manipulation  learning framework  task parameters  robot joint limits  task-parameterized learning  learned skills  real robotic systems  task constraints  learning perspective  Programming by demonstration  Task analysis  Trajectory  Robot kinematics  Optimization  Feature extraction  Robot sensing systems 
Abstract: Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.


Title: Teaching Human Teachers to Teach Robot Learners
Key Words: automatic programming  computer aided instruction  control engineering computing  data visualisation  feedback  human-robot interaction  robot programming  robots  teaching  robot learners generalisable skills  demonstration data sets  ambiguous demonstrations  teaching phase  interactive teaching process  robust teaching process  human teachers  heuristic rules  robot learners teaching  undemonstrated states  visual feedback  programming by demonstration  PbD  feedback visualisation  Task analysis  Education  Trajectory  Robot sensing systems  Visualization  Service robots 
Abstract: Using Programming by Demonstration to teach robot learners generalisable skills relies on having effective human teachers. This paper aims to address two problems commonly observed in demonstration data sets that arise due to poor teaching strategies; undemonstrated states and ambiguous demonstrations. Overcoming these issues through the use of visual feedback and simple heuristic rules is investigated as a potential way of guiding novice users to more effectively teach robot learners to generalise a task. The proposed method intends to offer the user a more transparent understanding of the robot learner's model state during the teaching phase, to create a more interactive and robust teaching process. Results from a single-factor, three-phase repeated measures study with n=30 participants, comparing the proposed feedback and heuristic rules set against an unguided condition, show a statistically significant (F(2,58)=7.952,p=0.001) improvement of user teaching efficiency of approximately 180% when using the proposed feedback visualisation.


Title: Sensor-Based Reactive Symbolic Planning in Partially Known Environments
Key Words: collision avoidance  mobile robots  sensors  differential drive robot  LIDAR sensor  passive objects  deliberative planner  symbolic commands  obstacle avoidance  reactive planner  sensor-based reactive symbolic planning  nonconvex environments  convex obstacles  high-level commands  Robot sensing systems  Planning  Task analysis  Grippers  Laser radar  Collision avoidance 
Abstract: This paper considers the problem of completing assemblies of passive objects in nonconvex environments, cluttered with convex obstacles of unknown position, shape and size that satisfy a specific separation assumption. A differential drive robot equipped with a gripper and a LIDAR sensor, capable of perceiving its environment only locally, is used to position the passive objects in a desired configuration. The method combines the virtues of a deliberative planner generating high-level, symbolic commands, with the formal guarantees of convergence and obstacle avoidance of a reactive planner that requires little onboard computation and is used online. The validity of the proposed method is verified both with formal proofs and numerical simulations.


Title: Near-optimal Irrevocable Sample Selection for Periodic Data Streams with Applications to Marine Robotics
Key Words: autonomous underwater vehicles  environmental science computing  mobile robots  optimisation  sampling methods  set theory  spatiotemporal phenomena  optimal irrevocable sample selection  periodic data streams  marine robotics  spatiotemporal phenomena  classical secretary problem  random order  environmental monitoring domains  spatiotemporal structure  representative samples  periodic structure  monotone submodular utility function  Martha's Vineyard Coastal Observatory  phytoplankton sample locations  information-theoretic sense  periodic secretary algorithm  theoretical performance guarantees  sample selection algorithm  environmental dataset  optimal sample set  Entropy  Mutual information  Robot sensing systems  Prediction algorithms  Real-time systems  Periodic structures 
Abstract: We consider the task of monitoring spatiotemporal phenomena in real-time by deploying limited sampling resources at locations of interest irrevocably and without knowledge of future observations. This task can be modeled as an instance of the classical secretary problem. Although this problem has been studied extensively in theoretical domains, existing algorithms require that data arrive in random order to provide performance guarantees. These algorithms will perform arbitrarily poorly on data streams such as those encountered in robotics and environmental monitoring domains, which tend to have spatiotemporal structure. We focus on the problem of selecting representative samples from phenomena with periodic structure and introduce a novel sample selection algorithm that recovers a near-optimal sample set according to any monotone submodular utility function. We evaluate our algorithm on a seven-year environmental dataset collected at the Martha's Vineyard Coastal Observatory and show that it selects phytoplankton sample locations that are nearly optimal in an information-theoretic sense for predicting phytoplankton concentrations in locations that were not directly sampled. The proposed periodic secretary algorithm can be used with theoretical performance guarantees in many real-time sensing and robotics applications for streaming, irrevocable sample selection from periodic data streams.


Title: Autonomous Feature Tracing and Adaptive Sampling in Real-World Underwater Environments
Key Words: autonomous underwater vehicles  lakes  mobile robots  temperature sensors  real-world operation  adaptive sampling missions  AUV  Autonomous feature tracing  real-world Underwater environments  underwater environmental sensing  compact high resolution  temperature sensing module  microstructure  turbulence measurements  sensing requirements  horizontal variation capture  water bodies  Temperature measurement  Lakes  Microorganisms  Robot sensing systems  Trajectory  Temperature sensors 
Abstract: Applications of robots for gathering data in underwater environments has been limited due to the challenges posed by the medium. We have developed a miniature, agile, easy to carry and deploy Autonomous Underwater Vehicle (AUV) equipped with a suite of sensors for underwater environmental sensing. We have also developed a compact high resolution fast temperature sensing module for the AUV for microstructure and turbulence measurements in water bodies. In this paper, we describe a number of algorithms and subsystems of the AUV that enable autonomous real-world operation, and present the data gathered in an experimental campaign in collaboration with limnologists. We demonstrate adaptive sampling missions where the AUV could autonomously locate a zone of interest and adapt its trajectory to stay in it. Further, it could execute specific behaviors to accommodate special sensing requirements necessary to enhance the quality of the data collected. In these missions, the AUV could autonomously trace a feature and capture horizontal variation in various quantities, including turbidity and temperature fluctuations, allowing limnologists to study lake phenomena in an additional dimension.


Title: Navigating Congested Environments with Risk Level Sets
Key Words: collision avoidance  mobile robots  multi-agent systems  road vehicles  risk level set  congested environment navigation  cluttered environment  congestion cost  occupancy risk  cost function  planning space  agent planning  autonomous vehicle driving  risk threshold  conservative behavior  aggressive behavior  Planning  Level set  Navigation  Vehicle dynamics  Autonomous vehicles  Collision avoidance  Cost function 
Abstract: In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.


Title: Topological Multi-Robot Belief Space Planning in Unknown Environments
Key Words: Bayes methods  graph theory  multi-robot systems  path planning  topology  graph pruning  topological properties  factor graphs  topological space  embedded state space  high-dimensional state spaces  announced path approach  topological multirobot belief space planning  BSP approaches  factor graph representation  posterior beliefs  Planning  Robot kinematics  Simultaneous localization and mapping  Linear programming  Aerospace electronics 
Abstract: In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.


Title: Efficient Stabilization of Zero-Slope Walking for Bipedal Robots Following Their Passive Fixed-Point Trajectories
Key Words: gait analysis  legged locomotion  motion control  stability  trajectory control  biped walking  stabilization  control law  ankle torques  hip  counterweight joint  energy input  numerical simulations  semicircular feet  compliant legs  passive fixed-point trajectories  bipedal robots  zero-slope walking  passive gaits  stable gaits  nonlinear PD terms  virtual-gravity components  Legged locomotion  Foot  Gravity  Hip  Damping  Torso  Stability analysis 
Abstract: This paper presents an efficient method of stabilizing the gait of an underactuated biped with compliant legs and semicircular feet. First, the model is defined, incorporating elements that are often present in experimental biped robots. The biped's passive behavior is studied through numerical simulations that provide insight into the gravity's contribution as an energy input to the system. Based on this study, it is shown that an augmented biped -with the addition of a counterweight joint at the hip- is able to perform stable gaits with minimal input. This design is implemented easily as it does not require ankle torques; instead, both motors are mounted at the biped's hip. The control law used for the stabilization is the combination of virtual-gravity components with non-linear PD terms. The stable gaits performed by the augmented biped on level floor strongly resemble the passive gaits of the original biped walking on a slope, resulting in an efficient, natural-like motion of low transport cost.


Title: Straight-Leg Walking Through Underconstrained Whole-Body Control
Key Words: humanoid robots  legged locomotion  quadratic programming  reachability analysis  robot kinematics  straight-leg walking  whole-body control  natural gait  bipedal robots  straightened legs  complex height planning  whole-body controller  straightest possible leg configuration  run-time  controller solutions  leg joint angle objectives  null-space  quadratic program motion objectives  toe-off motion  kinematic reachability  Legged locomotion  Iterative closest point algorithm  Trajectory  Planning  Acceleration  Foot 
Abstract: We present an approach for achieving a natural, efficient gait on bipedal robots using straightened legs and toe-off. Our algorithm avoids complex height planning by allowing a whole-body controller to determine the straightest possible leg configuration at run-time. The controller solutions are biased towards a straight leg configuration by projecting leg joint angle objectives into the null-space of the other quadratic program motion objectives. To allow the legs to remain straight throughout the gait, toe-off was utilized to increase the kinematic reachability of the legs. The toe-off motion is achieved through underconstraining the foot position, allowing it to emerge naturally. We applied this approach of under-specifying the motion objectives to the Atlas humanoid, allowing it to walk over a variety of terrain. We present both experimental and simulation results and discuss performance limitations and potential improvements.


Title: Agile and Adaptive Hopping Height Control for a Pneumatic Robot
Key Words: legged locomotion  pneumatic actuators  hop height every step  discontinuous terrain  safe footholds  bipedal running  quadrupedal running  constrained vertical hopping  pneumatic robot  vertical height  hopping robot  pneumatically actuated hopper  Legged locomotion  Valves  Computational modeling  Actuators  Atmospheric modeling  Force 
Abstract: This paper presents a controller for the vertical height of a hopping robot. The ability to accurately change the hop height every step will contribute toward the traversal of discontinuous terrain with limited safe footholds, with application to bipedal or quadrupedal running. A key feature of the approach presented is the use of information from previous hops/steps to inform the control of the current step. As well as avoiding modelling errors, this allows the robot to make on-line adjustments in response to changes in system parameters or the environment. The algorithm is simple enough to be easily implemented on a low power hardware, not requiring computationally demanding optimisation or numerical simulation. The effectiveness of this approach has been demonstrated for constrained vertical hopping in simulation and on a pneumatically actuated hopper.


Title: Robust Rough-Terrain Locomotion with a Quadrupedal Robot
Key Words: collision avoidance  legged locomotion  mobile robots  motion control  optimisation  path planning  pose estimation  robot dynamics  robot kinematics  terrain mapping  robust rough-terrain locomotion  natural settings  industrial settings  motion planner  perceptive rough-terrain locomotion  safe footholds  collision-free swing-leg motions  acquired terrain map  optimization approach  significant obstacles  quadrupedal robot ANYmal  locomotion planner  dynamic environments  urban settings  pose optimization approach  Legged locomotion  Robot sensing systems  Planning  Collision avoidance  Surface treatment 
Abstract: Robots working in natural, urban, and industrial settings need to be able to navigate challenging environments. In this paper, we present a motion planner for the perceptive rough-terrain locomotion with quadrupedal robots. The planner finds safe footholds along with collision-free swing-leg motions by leveraging an acquired terrain map. To this end, we present a novel pose optimization approach that enables the robot to climb over significant obstacles. We experimentally validate our approach with the quadrupedal robot ANYmal by autonomously traversing obstacles such steps, inclines, and stairs. The locomotion planner re-plans the motion at every step to cope with disturbances and dynamic environments. The robot has no prior knowledge of the scene, and all mapping, state estimation, control, and planning is performed in real-time onboard the robot.


Title: Central Pattern Generator With Inertial Feedback for Stable Locomotion and Climbing in Unstructured Terrain
Key Words: feedback  legged locomotion  motion control  neurophysiology  sensory feedback  inertial feedback  open-loop control strategy  complexity  terrain steepness  challenging terrains  steep terrains  hexapod robot  steep terrain  legged locomotion  body posture  CPG framework  level terrain  open-loop gait generation  CPG models  locomotive performance  gait adaptation  swimming legged robots  crawling legged robots  articulated robots  gaits  central pattern generator models  unstructured terrain  stable locomotion  Legged locomotion  Robot sensing systems  Limit-cycles  Robot kinematics  Adaptation models  Oscillators 
Abstract: Inspired by the locomotor nervous system of vertebrates, central pattern generator (CPG) models can be used to design gaits for articulated robots, such as crawling, swimming or legged robots. Incorporating sensory feedback for gait adaptation in these models can improve the locomotive performance of such robots in challenging terrain. However, many CPG models to date have been developed exclusively for open-loop gait generation for traversing level terrain. In this paper, we present a novel approach for incorporating inertial feedback into the CPG framework for the control of body posture during legged locomotion on steep, unstructured terrain. That is, we adapt the limit cycle of each leg of the robot with time to simultaneously produce locomotion and body posture control. We experimentally validate our approach on a hexapod robot, locomoting in a variety of steep, challenging terrains (grass, rocky slide, stairs). We show how our approach can be used to level the robot's body, allowing it to locomote at a relatively constant speed, even as terrain steepness and complexity prevents the use of an open-loop control strategy.


Title: On Time Optimization of Centroidal Momentum Dynamics
Key Words: angular momentum  concave programming  convex programming  humanoid robots  minimisation  mobile robots  path planning  position control  robot dynamics  time optimal control  fixed timing  motion plans  timing optimization  nonconvex problem  time-optimized dynamically consistent trajectories  centroidal dynamics  time variables  nonconvexity  contact forces  momentum trajectories  convex relaxation  trajectory optimization techniques  multicontact scenarios  dynamically consistent motions  centroidal momentum dynamics  Optimization  Dynamics  Robots  Kinematics  Torque  Mathematical model  Trajectory 
Abstract: Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing ††Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.


Title: Toward Intuitive Teleoperation in Surgery: Human-Centric Evaluation of Teleoperation Algorithms for Robotic Needle Steering
Key Words: biomechanics  cognition  force feedback  haptic interfaces  medical robotics  needles  robot kinematics  steering systems  surgery  telerobotics  robotically steered needles  joint space control  Cartesian space control  hub-centered steering  user experience  user cognitive workload  muscle fatigue  human-centric metrics  human-centric evaluation  teleoperation algorithms  teleoperated systems  physiological metrics  cognitive metrics  teleoperation performance  intuitive teleoperation  robotic needle steering  kinematic metrics  teleoperation mappings  teleoperation strategies  steering control mapping  Needles  Aerospace electronics  Task analysis  Kinematics  Haptic interfaces  Measurement  Sensors 
Abstract: The effectiveness of control algorithms for teleoperated systems is typically evaluated through experimental performance measures, post-experimental user surveys, and theoretical analysis. However, none of these methods provide an objective assessment of teleoperation algorithms with respect to the real-time changes of human users during teleoperated tasks in terms of physiological, kinematic, or cognitive metrics. In this study, we recruited subjects to control robotically steered needles in a randomized experiment, using four different teleoperation mappings (joint space control, steering control, and Cartesian space control with and without force feedback). We investigated how the choice of these algorithms affect both performance and user response. Our novel steering control mapping, which mimics hub-centered steering, is significantly correlated with decreased cognitive stress and improved teleoperation performance when compared to joint space control. Overall, user experience and teleoperation performance were significantly improved with Cartesian space control, resulting in faster needle insertion, higher targeting accuracy, lower cognitive load, and smoother movements. Furthermore, while additional haptic feedback in Cartesian space provided an improved performance, it may increase user cognitive workload and muscle fatigue. These results highlight the importance of considering human-centric metrics when designing novel teleoperation strategies for complex systems.


Title: Human-guided Optical Manipulation of Multiple Microscopic Objects
Key Words: collision avoidance  decision making  manipulators  micromanipulators  multi-robot systems  radiation pressure  human-guided optical manipulation  multiple microscopic objects  control systems  multiple microobjects  robotic control technique  automated optical manipulation system  precise manipulation  productive manipulation  Robots  Microscopy  Optical microscopy  Potential energy  Biomedical optical imaging  Collision avoidance 
Abstract: Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.


Title: Enhanced Tele-interaction in Unknown Environments Using Semi-Autonomous Motion and Impedance Regulation Principles
Key Words: collision avoidance  human-robot interaction  mobile robots  telerobotics  human intervention  tele-interaction  shared-autonomy Tele-Interaction control approach  impendance colliding  impedance setting  physical interactions  slave robot  human pilot  shared-autonomy control principles  autonomous impedance regulation  autonomous manner  physical constraints  robot platform  interaction forces  physical obstacles  remote robot  impedance modulators  autonomous motion  motion commands  remote workspace  human operator  remote environment  hazardous environments  robotics teleoperation  impedance regulation principles  Robots  Impedance  Task analysis  Collision avoidance  Payloads  Trajectory  Correlation 
Abstract: Robotics teleoperation has been extensively studied and considered in the past in several task scenarios where direct human intervention is not possible due to the hazardous environments. In such applications, both communication degradation and reduced perception of the remote environment are practical issues that can challenge the human operator while controlling the robot and attempting to physically interact within the remote workspace. To address this challenge, we introduce a novel shared-autonomy Tele-Interaction control approach that blends the motion commands from the pilot (master side) with locally (slave side) executed autonomous motion and impedance modulators. This enables a remote robot to handle and autonomously avoid physical obstacles during manoeuvring, reduce interaction forces during contacts, and finally accommodate different payload conditions while at the same time operating with a “default” low impedance setting. We implemented and experimentally validated the proposed method both on simulation and on a real robot platform called CENTAURO. A series of tasks, such as maneuvering through the physical constraints of the remote environment in an autonomous manner, pushing and lifting heavy objects with autonomous impedance regulation and colliding with the rigid geometry of the remote environment were executed. The obtained results demonstrate the effectiveness of the shared-autonomy control principles that eventually aim to reduce the level of attention and stress of human pilot while manoeuvring the slave robot, and at the same time to enhance the robustness of the robot during physical interactions even if accidentally occurred.


Title: Intuitive Hand Teleoperation by Novice Operators Using a Continuous Teleoperation Subspace
Key Words: dexterous manipulators  motion control  telerobotics  intuitive control method  pose spaces  low-dimensional teleoperation subspace  continuous teleoperation subspace  nonanthropomorphic robot  teleoperation subspaces  teleoperation subspace mapping  intuitive hand teleoperation  novice operators  human-in-the-loop manipulation  autonomous grasping  input device  teleoperation methods  Aerospace electronics  Grasping  Kinematics  Task analysis  Teleoperators  Shape 
Abstract: Human-in-the-loop manipulation is useful in when autonomous grasping is not able to deal sufficiently well with corner cases or cannot operate fast enough. Using the teleoperator's hand as an input device can provide an intuitive control method but requires mapping between pose spaces which may not be similar. We propose a low-dimensional and continuous teleoperation subspace which can be used as an intermediary for mapping between different hand pose spaces. We present an algorithm to project between pose space and teleoperation subspace. We use a non-anthropomorphic robot to experimentally prove that it is possible for teleoperation subspaces to effectively and intuitively enable teleoperation. In experiments, novice users completed pick and place tasks significantly faster using teleoperation subspace mapping than they did using state of the art teleoperation methods.


Title: Avoiding Human-Robot Collisions Using Haptic Communication
Key Words: collision avoidance  haptic interfaces  human-robot interaction  mobile robots  service robots  telerobotics  collision scenario  haptic communication channel  human movement  human-robot collisions  autonomous navigation  populated environments  mobile robots  human-robot communication  navigation tasks  human users  wearable haptic interface  distinct haptic cues  vibration amplitudes  single human-single robot orthogonal encounter scenario  Collision avoidance  Haptic interfaces  Robot kinematics  Navigation  Legged locomotion  Predictive models 
Abstract: Fully autonomous navigation in populated environments is still a challenging problem for mobile robots. This paper explores the idea of using active human-robot communication to facilitate navigation tasks. We propose to convey a robot's intent to human users via a wearable haptic interface. The interface can display distinct haptic cues by modulating vibration amplitudes and patterns. We applied the concept to a single human/single robot orthogonal encounter scenario, where one of the two parties has to yield the right of way to avoid collision. Under certain conditions, the robot's intent (to yield to the human or not) is revealed to the human via the haptic interface prior to the interaction. We conducted an experiment with 10 users, in which the robot was teleoperated as a substitute for autonomy. Results show that, when given priority, users become more risk-accepting and use different strategies to navigate the collision scenario than when the robot takes priority or there is no haptic communication channel. In addition, we propose a social-force based model to predict human movement during navigation. The effect of communication can be explained as a shift in the user's safety buffer and expectation of the robot's future velocity.


Title: High Speed Whole Body Dynamic Motion Experiment with Real Time Master-Slave Humanoid Robot System
Key Words: humanoid robots  motion control  robot dynamics  smoothing methods  stability  telerobotics  master-slave operations  foot landing delay prediction  trajectory smoothing method  master-slave tennis swing experiment  high kick motion experiment  life-sized humanoid robot JAXON  high speed whole body dynamic motion experiment  online real time whole body master-slave control  dynamic whole body master-slave experiment  flexible master-slave operation  real time master-slave humanoid robot system  Foot  Master-slave  Humanoid robots  Interpolation  Dynamics  Real-time systems 
Abstract: In this paper, we propose novel methods suitable for online real time whole body master-slave control with real life-sized humanoid robot. We conducted some dynamic whole body master-slave experiment with life-sized humanoid robot, and we achieved speedier and flexible master-slave operation compared to conventional study. Conventionally, master-slave operations with humanoid robots were available with only the upper body of the humanoid robot, and the COM movement was limited to be static. In our previous study, we introduced LIP model based restrictions to ensure the balance stability. In this study, we extend the safety restrictions by introducing foot landing delay prediction and trajectory smoothing method suitable for real robot. We conducted master-slave tennis swing experiment and high kick motion experiment with life-sized humanoid robot “JAXON”, and we evaluated the effectiveness of our proposed methods and system.


Title: Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds
Key Words: biomimetics  control engineering computing  convolution  feedforward neural nets  handicapped aids  learning (artificial intelligence)  mobile robots  robotic guide dog  interclass trail variations  deep convolutional neural network  virtual worlds  man-made trails  pedestrian environments  contact feedback  tactile trails  autonomous trail-following  virtual real-world environments  visually impaired  Dogs  Cameras  Robot vision systems  Navigation  Mobile robots 
Abstract: Navigation in pedestrian environments is critical to enabling independent mobility for the blind and visually impaired (BVI) in their daily lives. White canes have been commonly used to obtain contact feedback for following walls, curbs, or man-made trails, whereas guide dogs can assist in avoiding physical contact with obstacles or other pedestrians. However, the infrastructures of tactile trails or guide dogs are expensive to maintain. Inspired by the autonomous lane following of self-driving cars, we wished to combine the capabilities of existing navigation solutions for BVI users. We proposed an autonomous, trail-following robotic guide dog that would be robust to variances of background textures, illuminations, and interclass trail variations. A deep convolutional neural network (CNN) is trained from both the virtual and realworld environments. Our work included major contributions: 1) conducting experiments to verify that the performance of our models trained in virtual worlds was comparable to that of models trained in the real world; 2) conducting user studies with 10 blind users to verify that the proposed robotic guide dog could effectively assist them in reliably following man-made trails.


Title: Deep Encoder-Decoder Networks for Mapping Raw Images to Dynamic Movement Primitives
Key Words: backpropagation  handwriting recognition  handwritten character recognition  neural nets  dynamic movement primitives  cost functions  raw image mapping  backpropagation  MNIST database  deep encoder-decoder network  associated movement trajectories  perception-action couplings  encoder-decoder networks  calculated movements  handwriting movements  Trajectory  Differential equations  Neural networks  Cost function  Training  Robot kinematics 
Abstract: In this paper we propose a new approach for learning perception-action couplings. We show that by collecting a suitable set of raw images and the associated movement trajectories, a deep encoder-decoder network can be trained that takes raw images as input and outputs the corresponding dynamic movement primitives. We propose suitable cost functions for training the network and describe how to calculate their gradients to enable effective training by back-propagation. We tested the proposed approach both on a synthetic dataset and on a widely used MNIST database to generate handwriting movements from raw images of digits. The calculated movements were also applied for digit writing with a real robot.


Title: What is (Missing or Wrong) in the Scene? A Hybrid Deep Boltzmann Machine for Contextualized Scene Modeling
Key Words: Boltzmann machines  image classification  learning (artificial intelligence)  restricted Boltzmann machines  hybrid deep Boltzmann machine  scene classification dataset  baseline models  different objects  visible nodes  BM  hybrid Boltzmann Machine  contextualized scene modeling  scene reasoning tasks  Training  Task analysis  Robots  Computational modeling  Context modeling  Estimation  Cognition 
Abstract: Scene models allow robots to reason about what is in the scene, what else should be in it, and what should not be in it. In this paper, we propose a hybrid Boltzmann Machine (BM) for scene modeling where relations between objects are integrated. To be able to do that, we extend BM to include tri-way edges between visible (object) nodes and make the network to share the relations across different objects. We evaluate our method against several baseline models (Deep Boltzmann Machines, and Restricted Boltzmann Machines) on a scene classification dataset, and show that it performs better in several scene reasoning tasks.


Title: Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator
Key Words: control engineering computing  convolution  feature extraction  feedforward neural nets  image classification  image colour analysis  manipulators  mobile robots  object detection  object recognition  operating systems (computers)  robot programming  robot vision  scene classification  unified architecture  global scene features  regional object features  object recognition  continuous robot beliefs  robotics applications  Robot Operating System  mobile manipulator  object detection  object locations  network predictions  SUN RGBD dataset  3D space  unified convolutional neural network  Proposals  Robots  Object detection  Object recognition  Three-dimensional displays  Semantics  Feature extraction 
Abstract: Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.


Title: AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection
Key Words: image classification  learning (artificial intelligence)  object detection  multiple object detection  AffordanceNet  object localization  object classification  affordance label  robust resizing strategy  deconvolutional layer sequence  real-time robotic applications  testing environments  end-to-end architecture  multitask loss function  affordance mask  RGB images  object affordance detection  end-to-end deep learning approach  Feature extraction  Robots  Computer architecture  Object detection  Training  Image segmentation  Machine learning 
Abstract: We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net.


Title: ContextualNet: Exploiting Contextual Information Using LSTMs to Improve Image-Based Localization
Key Words: convolution  feedforward neural nets  learning (artificial intelligence)  pose estimation  SLAM (robots)  CNN-LSTM model  pose estimation  single monocular image  Convolutional Neural Networks  image-based localization  ContextualNet  image content  indoor office space  Feature extraction  Cameras  Context modeling  Computer vision  Logic gates  Neural networks 
Abstract: Convolutional Neural Networks (CNN) have successfully been utilized for localization using a single monocular image [1]. Most of the work to date has either focused on reducing the dimensionality of data for better learning of parameters during training or on developing different variations of CNN models to improve pose estimation. Many of the best performing works solely consider the content in a single image, while the context from historical images is ignored. In this paper, we propose a combined CNN-LSTM which is capable of incorporating contextual information from historical images to better estimate the current pose. Experimental results achieved using a dataset collected in an indoor office space improved the overall system results to 0.8 m & 2.5° at the third quartile of the cumulative distribution as compared with 1.5 m & 3.0° achieved by PoseNet [1]. Furthermore, we demonstrate how the temporal information exploited by the CNN-LSTM model assists in localizing the robot in situations where image content does not have sufficient features.


Title: Learning Human-Aware Path Planning with Fully Convolutional Networks
Key Words: convolution  feedforward neural nets  learning (artificial intelligence)  mobile robots  navigation  path planning  random processes  trees (mathematics)  robot social navigation  Fully Convolutional Neural Networks  mobile robots  human-aware path planning learning  optimal Rapidly-exploring Random Tree planner  robot navigation  classification problem  Robots  Navigation  Task analysis  Trajectory  Cost function  Feature extraction 
Abstract: This work presents an approach to learn path planning for robot social navigation by demonstration. We make use of Fully Convolutional Neural Networks (FCNs) to learn from expert's path demonstrations a map that marks a feasible path to the goal as a classification problem. The use of FCNs allows us to overcome the problem of manually designing/identifying the cost-map and relevant features for the task of robot navigation. The method makes use of optimal Rapidly-exploring Random Tree planner (RRT*) to overcome eventual errors in the path prediction; the FCNs prediction is used as cost-map and also to partially bias the sampling of the configuration space, leading the planner to behave similarly to the learned expert behavior. The approach is evaluated in experiments with real trajectories and compared with Inverse Reinforcement Learning algorithms that use RRT* as underlying planner.


Title: Pedestrian Prediction by Planning Using Deep Neural Networks
Key Words: collision avoidance  convolution  learning (artificial intelligence)  mobile robots  neural nets  pedestrians  traffic engineering computing  monolithic neural network  inverse reinforcement learning  pedestrian prediction  deep neural networks  collision avoidance  autonomous vehicles  goal-directed planning  mixture density function  motion prediction  convolutional network  traffic participant prediction  trajectories  Planning  Network topology  Topology  Convolution  Learning (artificial intelligence)  Trajectory  Prediction algorithms 
Abstract: Accurate traffic participant prediction is the prerequisite for collision avoidance of autonomous vehicles. In this work, we propose to predict pedestrians using goal-directed planning. For this, we infer a mixture density function for possible destinations. We use these destinations as the goal states of a planning stage that performs motion prediction based on common behavior patterns. The patterns are learned by a fully convolutional network operating on maps of the environment. We show that this entire system can be modeled as one monolithic neural network and trained via inverse reinforcement learning. Experimental validation on real world data shows the system's ability to predict both, destinations and trajectories accurately.


Title: Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction
Key Words: feature selection  human-robot interaction  image motion analysis  learning (artificial intelligence)  mobile robots  pose estimation  recurrent neural nets  stochastic processes  human robot cooperation scenario  prediction model  action prediction dataset  human motion data  human-robot cooperation  recurrent neural network approach  multiple action sequences prediction  assistive applications  nonverbal cues  neural networks  human action prediction problem  continuous spaces  discrete spaces  encoder-decoder recurrent neural network topology  discrete action prediction problem  action sequences  feature selection  stochastic reward  Predictive models  Decoding  Hidden Markov models  Recurrent neural networks  Robot kinematics  Trajectory 
Abstract: Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.


Title: Text2Action: Generative Adversarial Synthesis from Language to Action
Key Words: recurrent neural nets  robots  text analysis  video signal processing  sequence to sequence model  Baxter robot  virtual agent  generative adversarial synthesis  Text2action  MSR-Video-to-Text  action decoder RNN  text encoder recurrent neural network  generative network  SEQ2SEQ  sequence model  generative adversarial network  human behavior  sentence  human action sequence  generative model  Decoding  Gallium nitride  Hidden Markov models  Generative adversarial networks  Robots  Recurrent neural networks  Generators 
Abstract: In this paper, we propose a generative model which learns the relationship between language and human action in order to generate a human action sequence given a sentence describing human behavior. The proposed generative model is a generative adversarial network (GAN), which is based on the sequence to sequence (SEQ2SEQ) model. Using the proposed generative network, we can synthesize various actions for a robot or a virtual agent using a text encoder recurrent neural network (RNN) and an action decoder RNN. The proposed generative network is trained from 29,770 pairs of actions and sentence annotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video dataset. We demonstrate that the network can generate human-like actions which can be transferred to a Baxter robot, such that the robot performs an action based on a provided sentence. Results show that the proposed generative network correctly models the relationship between language and action and can generate a diverse set of actions from the same sentence.


Title: A Data-driven Model for Interaction-Aware Pedestrian Motion Prediction in Object Cluttered Environments
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  motion estimation  navigation  neural nets  pedestrians  human motion behavior  prediction accuracy  data-driven model  interaction-aware pedestrian motion prediction  object cluttered environments  interaction-aware motion prediction approach  human navigation behavior  Long-Short Term Memory neural networks  static obstacles  trajectory forecasting  polar angle space  Predictive models  Robots  Trajectory  Adaptation models  Navigation  Planning  Neural networks 
Abstract: This paper reports on a data-driven, interaction-aware motion prediction approach for pedestrians in environments cluttered with static obstacles. When navigating in such workspaces shared with humans, robots need accurate motion predictions of the surrounding pedestrians. Human navigation behavior is mostly influenced by their surrounding pedestrians and by the static obstacles in their vicinity. In this paper we introduce a new model based on Long-Short Term Memory (LSTM) neural networks, which is able to learn human motion behavior from demonstrated data. To the best of our knowledge, this is the first approach using LSTMs, that incorporates both static obstacles and surrounding pedestrians for trajectory forecasting. As part of the model, we introduce a new way of encoding surrounding pedestrians based on a 1d-grid in polar angle space. We evaluate the benefit of interaction-aware motion prediction and the added value of incorporating static obstacles on both simulation and real-world datasets by comparing with state-of-the-art approaches. The results show, that our new approach outperforms the other approaches while being very computationally efficient and that taking into account static obstacles for motion predictions significantly improves the prediction accuracy, especially in cluttered environments.


Title: Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data
Key Words: feature extraction  feedforward neural nets  gesture recognition  image classification  image motion analysis  learning (artificial intelligence)  motion recognition  spatiotemporal features  dense occupancy grids  3D point cloud data  end-to-end spatiotemporal gesture learning approach  dynamic gestures  spatiotemporal learning  point cloud data augmentation  3D convolutional neural network  gestures sample data  Three-dimensional displays  Robot sensing systems  Feature extraction  Solid modeling  Training data  Spatiotemporal phenomena  Hidden Markov models 
Abstract: In this paper, we demonstrate an end-to-end spatiotemporal gesture learning approach for 3D point cloud data using a new gestures dataset of point clouds acquired from a 3D sensor. Nine classes of gestures were learned from gestures sample data. We mapped point cloud data into dense occupancy grids, then time steps of the occupancy grids are used as inputs into a 3D convolutional neural network which learns the spatiotemporal features in the data without explicit modeling of gesture dynamics. We also introduced a 3D region of interest jittering approach for point cloud data augmentation. This resulted in an increased classification accuracy of up to 10% when the augmented data is added to the original training data. The developed model is able to classify gestures from the dataset with 84.44% accuracy. We propose that point cloud data will be a more viable data type for scene understanding and motion recognition, as 3D sensors become ubiquitous in years to come.


Title: Functional Object-Oriented Network: Construction & Expansion
Key Words: knowledge representation  object-oriented methods  manipulation sequences  knowledge retrieval algorithm  object categories  functional units  object similarity  video sources  knowledge spanning  object-motion affordances  structured knowledge representation  functional object-oriented network  Task analysis  Robots  Merging  Sun  Knowledge representation  Mirrors  Neurons 
Abstract: We build upon the functional object-oriented network (FOON), a structured knowledge representation which is constructed from observations of human activities and manipulations. A FOON can be used for representing object-motion affordances. Knowledge retrieval through graph search allows us to obtain novel manipulation sequences using knowledge spanning across many video sources, hence the novelty in our approach. However, we are limited to the sources collected. To further improve the performance of knowledge retrieval as a follow up to our previous work, we discuss generalizing knowledge to be applied to objects which are similar to what we have in FOON without manually annotating new sources of knowledge. We discuss two means of generalization: 1) expanding our network through the use of object similarity to create new functional units from those we already have, and 2) compressing the functional units by object categories rather than specific objects. We discuss experiments which compare the performance of our knowledge retrieval algorithm with both expansion and compression by categories.


Title: 3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data
Key Words: cameras  codecs  image annotation  image coding  learning (artificial intelligence)  mobile robots  object detection  pedestrians  pose estimation  robot vision  service robots  SLAM (robots)  long-term temporal information  sequence-to-sequence LSTM encoder-decoder  on-the-fly prediction  global coordinate system  T-Pose-LSTM model  human trajectory prediction  long-term mobile robot deployments  3DOF pedestrian trajectory prediction learned  Long-Term autonomous mobile robot deployment data  autonomous mobile service robots  monocular camera images  range-finder sensors  3DOF pedestrian trajectory prediction approach  temporal 3DOF-pose long-short-term memory  robust human detection  Trajectory  Cameras  Robot kinematics  Robot vision systems  Two dimensional displays  Mobile robots 
Abstract: This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.


Title: Conditional Compatibility Branch and Bound for Feature Cloud Matching
Key Words: computational complexity  image matching  SLAM (robots)  statistical distributions  tree searching  chi-square test  gating threshold  joint compatibility branch and bound  conditional compatibility branch and bound  feature cloud matching  incremental posterior joint compatibility  IPJC  FastJCBB  global optimal data association  Joint Compatibility test  JC test based search algorithm  CC test  conditional probability distribution  feature pairing  Conditional Compatibility test  Probabilistic logic  Robots  Measurement errors  Computational complexity  Probability distribution  Integrated circuits  Feature Cloud Matching  Scan Matching  Data Association  Conditional Compatibility Test 
Abstract: In this paper, we consider the problem of data association in feature cloud matching. While Joint Compatibility (JC) test is a widely adopted technique for searching the global optimal data association, it becomes less restrictive as more features are well matched. The early well-matched features contribute little to total matching cost while the gating threshold increases in the chi-square test, which allows the acceptance of bad feature pairings in the last step. In this paper, we propose the Conditional Compatibility (CC) test, which is not only more restrictive than JC test, but also probabilistically sound. The proposed test of a new feature pairing is based on the conditional probability distribution of feature locations given the early pairings. CC test can be added into any JC test based search algorithm, such as Joint Compatibility Branch and Bound (JCBB), Incremental Posterior Joint Compatibility (IPJC) and FastJCBB, without increasing much computational complexity. The more restrictive criterion of accepting a feature pairing, not only helps to reject bad associations, but also bounds the search space, which substantially improves the search efficiency. The real matching experiments justify that our algorithm produces better feature cloud matching results in a more efficient manner.


Title: Assigning Visual Words to Places for Loop Closure Detection
Key Words: image matching  image recognition  image representation  image segmentation  mobile robots  probability  robot vision  SLAM (robots)  simultaneous localization and mapping  image stream  image match  dynamic segmentation  nearest neighbor voting scheme  image descriptors  query time  on-line clustering algorithm  visual vocabulary construction  robotic applications  LCD  place recognition  loop closure detection  visual words  Visualization  Liquid crystal displays  Robots  Databases  Pipelines  Feature extraction  Vocabulary 
Abstract: Place recognition of pre-visited areas, widely known as Loop Closure Detection (LCD), constitutes one of the most important components in robotic applications, where the robot needs to estimate its pose while navigating through the field (e.g., simultaneous localization and mapping). In this paper, we present a novel approach for LCD based on the assignment of Visual Words (VWs) to particular places of the traversed path. The system operates in real time and does not require any pre-training procedure, such as visual vocabulary construction or descriptor-space dimensionality reduction. A place is defined through a dynamic segmentation of the incoming image stream and is assigned with VWs through the usage of an on-line clustering algorithm. At query time, image descriptors are converted into VWs on the map accumulating votes to the corresponding places. By means of a probability function, the mechanism is capable of identifying a loop closing candidate place. A nearest neighbor voting scheme on the descriptors' space allows the system to select the most appropriate image match at the chosen place. Geometrical and temporal consistency checks are applied on the proposed loop closing pair increasing the system's performance. Evaluation took place on several publicly available and challenging datasets offering high precision and recall scores as compared to other state-of-the-art approaches.


Title: Localization Under Topological Uncertainty for Lane Identification of Autonomous Vehicles
Key Words: hidden Markov models  mobile robots  position control  remotely operated vehicles  road traffic control  topology  VSM-HMM  topological uncertainty  lane membership  topological localization process  topological structure estimation  AV lane estimation  lane identification  autonomous vehicles  topological location  decision-making  public roads  variable structure multiple hidden Markov model  metric location  Earth mover distance  Hidden Markov models  Computational modeling  Topology  Roads  Uncertainty  Measurement  Vehicle dynamics 
Abstract: Autonomous vehicles (AVs) require accurate metric and topological location estimates for safe, effective navigation and decision-making. Although many high-definition (HD) roadmaps exist, they are not always accurate since public roads are dynamic, shaped unpredictably by both human activity and nature. Thus, AVs must be able to handle situations in which the topology specified by the map does not agree with reality. We present the Variable Structure Multiple Hidden Markov Model (VSM-HMM) as a framework for localizing in the presence of topological uncertainty, and demonstrate its effectiveness on an AV where lane membership is modeled as a topological localization process. VSM-HMMs use a dynamic set of HMMs to simultaneously reason about location within a set of most likely current topologies and therefore may also be applied to topological structure estimation as well as AV lane estimation. In addition, we present an extension to the Earth Mover's Distance which allows uncertainty to be taken into account when computing the distance between belief distributions on simplices of arbitrary relative sizes.


Title: Stabilizing Traffic with Autonomous Vehicles
Key Words: frequency-domain analysis  intelligent transportation systems  linear systems  mobile robots  nonlinear programming  optimal control  road safety  road traffic control  road vehicles  stability  autonomously controlled vehicles  autonomous vehicles  human-driven vehicles  traffic stabilization  safer roads  energy savings  single-lane system stabilization  linear string stability  optimality conditions  frequency-domain analysis  nonlinear optimization problem  safety constraint  optimal linear controller  traffic conditions  human driver behavior  Autonomous vehicles  Vehicle dynamics  Stability criteria  Optimization  Mathematical model 
Abstract: Autonomous vehicles promise safer roads, energy savings, and more efficient use of existing infrastructure, among many other benefits. Although the effect of autonomous vehicles has been studied in the limits (near-zero or full penetration), the transition range requires new formulations, mathematical modeling, and control analysis. In this article, we study the ability of small numbers of autonomous vehicles to stabilize a single-lane system of human-driven vehicles. We formalize the problem in terms of linear string stability, derive optimality conditions from frequency-domain analysis, and pose the resulting nonlinear optimization problem. In particular, we introduce two conditions which simultaneously stabilize traffic while imposing a safety constraint on the autonomous vehicle and limiting degradation of performance. With this optimal linear controller in a system with typical human driver behavior, we can numerically determine that only a 6% uniform penetration of autonomously controlled vehicles (i.e. one per string of up to 16 human-driven vehicles) is necessary to stabilize traffic across all traffic conditions.


Title: Automated Process for Incorporating Drivable Path into Real-Time Semantic Segmentation
Key Words: cameras  image segmentation  mobile robots  object detection  path planning  road traffic  road vehicles  robot vision  path prediction model  camera sensors  autonomous vehicle systems  vision systems  real-time semantic segmentation  intelligent vehicles  odometry  monocular camera  car-width drivable lane  path proposal category  intelligent vehicle system  drivable path information  human operation  clear lane markings  urban roads  Semantics  Cameras  Roads  Image segmentation  Sensors  Proposals  Trajectory 
Abstract: Vision systems are widely used in autonomous vehicle systems due to the rich information that camera sensors provide of the surrounding environment. This paper presents an automatic algorithm to obtain the drivable path of a vehicle operating in urban roads with or without clear lane markings. The developed system projects trajectories obtained during human operation of the vehicle and utilizes these to generate automatic labels for training a semantic based path prediction model. The system segments an urban scenario into 13 categories including vehicles, pedestrian, undrivable road, other categories relevant to urban roads, and a new class for a path proposal. The drivable path information is essential particularly in unstructured scenarios, and is critical for an intelligent vehicle system to make sound driving decisions. The path proposal category is a car-width drivable lane estimated to be safe to drive for the vehicle under consideration. The data collection, model training and inference process requires only images from a monocular camera and odometry from a low-cost IMU combined with a wheel encoder. The algorithm has been successfully demonstrated on the Sydney University campus, which is a challenging environment without clear road markings. The algorithm was demonstrated to run in real-time, proving its applicability for intelligent vehicles.


Title: SeDAR - Semantic Detection and Ranging: Humans can Localise without LiDAR, can Robots?
Key Words: feature extraction  image colour analysis  image matching  image representation  mobile robots  pose estimation  robot vision  vision-based approaches  high level semantic cues  floorplan  global localisation approach  range measurements  robotic scan-matching algorithms  SeDAR  semantic detection and ranging  pose estimation  2D geometry  2D representation  discriminative landmarks  RGB images  Semantics  Robot sensing systems  Three-dimensional displays  Two dimensional displays  Robustness 
Abstract: How does a person work out their location using a floorplan? It is probably safe to say that we do not explicitly measure depths to every visible surface and try to match them against different pose estimates in the floorplan. And yet, this is exactly how most robotic scan-matching algorithms operate. Similarly, we do not extrude the 2D geometry present in the floorplan into 3D and try to align it to the real-world. And yet, this is how most vision-based approaches localise. Humans do the exact opposite. Instead of depth, we use high level semantic cues. Instead of extruding the floorplan up into the third dimension, we collapse the 3D world into a 2D representation. Evidence of this is that many of the floorplans we use in everyday life are not accurate, opting instead for high levels of discriminative landmarks. In this work, we use this insight to present a global localisation approach that relies solely on the semantic labels present in the floorplan and extracted from RGB images. While our approach is able to use range measurements if available, we demonstrate that they are unnecessary as we can achieve results comparable to state-of-the-art without them.


Title: Design of a Novel 3-DoF Leg with Series and Parallel Compliant Actuation for Energy Efficient Articulated Robots
Key Words: actuators  control system synthesis  elasticity  legged locomotion  motion control  similar mass  mass distribution  biarticulated actuation configuration  mechanical design  actuation configuration principles  3-DoF leg  parallel compliant actuation  series-elastic main actuators  leg design  energy efficient articulated robots  Legged locomotion  Actuators  Knee  Pulleys  Torque  Energy storage 
Abstract: This work presents the development of a 3-DoF leg with series and parallel compliant actuation. Series-elastic main actuators are combined with parallel high efficiency energy storage branches, to substantially improve energy efficiency. The leg design is semi-anthropomorphic, with similar mass and mass distribution to the human limb, and includes a biarticulated actuation configuration. The parallel branches are driven by secondary motors and their design parameters are optimised. The mechanical design of the prototype leg is presented, introducing details of the actuation configuration principles employed. Preliminary experimental data are presented, in which a baseline series-elastic-only configuration is compared with configurations with mono- and biarticulated parallel branches, respectively. The results effectively demonstrate the concept's potential, showing improvements of 53% and 60% in electrical power consumption while the leg is executing loaded cyclic motion profiles.


Title: Design of a Serial-Parallel Hybrid Leg for a Humanoid Robot
Key Words: end effectors  gait analysis  humanoid robots  legged locomotion  manipulator kinematics  medical robotics  motion control  position control  trajectory tracking  gait trajectory  bar-linkage mechanism  serial mechanism  twin 3 DOF serial chains  parallel mechanisms  serial mechanisms  6 DOF leg mechanism  humanoid robot  serial-parallel Hybrid Leg  inverse kinematics  forward kinematics  conventional serial leg  commercial robot  kinematic specification  hardware prototype  knee pitch rotation  Legged locomotion  Kinematics  Couplings  Prototypes  Hip  Hardware 
Abstract: This paper presents a 6 DOF leg mechanism for a humanoid robot. The proposed Hybrid Leg is designed to combine serial and parallel mechanisms and consists of a pair of twin 3 DOF serial chains in parallel. A 5-bar-linkage mechanism is implemented to the serial mechanism to generate 2 DOF motion regarding hip and knee pitch rotation. The hardware prototype is designed by matching the kinematic specification of a commercial robot's leg to compare the proposed mechanism with a conventional serial leg. We derive the analytical expressions of its forward and inverse kinematics. End-effector workspaces are shown with plots and inverse dynamics analysis of Hybrid Leg and serial leg with a given walking gait trajectory is presented. Hardware experiment is conducted with a prototype to verify the simulated workspace and trajectory tracking performance.


Title: Self-Engaging Spined Gripper with Dynamic Penetration and Release for Steep Jumps
Key Words: actuators  adhesion  aerospace robotics  bone  gait analysis  grippers  impact (mechanical)  legged locomotion  robot kinematics  substrates  dynamic penetration  steep jumps  high impact forces  low duty cycles  monopedal jumping robots  slipping foot  dynamic jumping robot  surface approach speed  cycle time  penetrable substrate  gripper mechanism  robot Salto  angled spines  penetrable inclines  holding angles  leg crouch-extension  actuators  static adhesion  ceiling  self engaging spined gripper  kinematics  Grippers  Pins  Robot kinematics  Legged locomotion  Couplings  Substrates 
Abstract: Due to high impact forces and low duty cycles, monopedal jumping robots are particularly susceptible to failure from a slipping foot. Spines provide a solution to reduce slip, but there has been little research on how to effectively engage them into a surface with a dynamic jumping robot. Previous robots utilizing spines operate in different regimes of surface approach speed and cycle time. For a penetrable substrate, spines must be directed into the surface at suitable holding angles, then extracted before the foot leaves the ground. We accomplished this by designing a gripper mechanism for the robot Salto that pushes in angled spines along their length and is kinematically constrained to engage/disengage with leg crouch/extension. The resulting mechanism introduces no new actuators, enables jumping on penetrable inclines up to 60°, and enables static adhesion to hold 7.5 times the robot's weight from a ceiling.


Title: Simplified Quasi-Steady Aeromechanic Model for Flapping-Wing Robots with Passively Rotating Hinges
Key Words: aerodynamics  aerospace components  approximation theory  bending strength  drag  hinges  Navier-Stokes equations  robot kinematics  torque  model predictions  flapping-wing robots  flexural passive wing hinges  aerodynamic forces  balanced torque  quasisteady aeromechanic model  rotating hinge  mechanical complexity  drag  stroke-averaged forces  Aerodynamics  Torque  Robots  Fasteners  Predictive models  Drag  Force 
Abstract: At millimeter and centimeter scales, flapping-wing robots often employ flexural passive wing hinges to eliminate extra actuation and mechanical complexity. In this paper, we propose a modified quasi-steady model for predicting aerodynamic forces from a flapping wing with a passively rotating hinge. The model is based on a simplifying assumption of balanced torque (aerodynamic torque equals to the restoring torque from the hinge). The resulting lift and drag can then be accurately predicted by the modified quasi-steady model without direct knowledge of the angle of attack of the wing. Approximate expression of stroke-averaged forces are also derived. We performed flapping experiments on a centimeter-scale device and the measured lifts show good agreement with the model predictions.


Title: Surface Edge Explorer (see): Planning Next Best Views Directly from 3D Observations
Key Words: computational geometry  feature extraction  image reconstruction  mesh generation  solid modelling  Surface Edge Explorer  Best View planning  NBV planning approaches  voxel grids  triangulated meshes  surface geometry  high-resolution models  Surface representations  multiple survey stages  scene-model-free NBV planning approach  density representation  current measurements  observed surface boundaries  surface coverage  evaluated state-of-the-art volumetric approaches  Next Best views  time 3.0 d  Planning  Computational modeling  Density measurement  Geometry  Surface treatment  Three-dimensional displays 
Abstract: Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.


Title: Fusing Object Context to Detect Functional Area for Cognitive Robots
Key Words: feature extraction  image classification  image fusion  image recognition  learning (artificial intelligence)  object detection  object context  deep learning  object detection dataset  current object detection framework  functional area detection  functionality-related feature  object-related  potential image regions  deep-model-based classifier  functional area image dataset  area detection problem  image recognition  cognitive robot  Feature extraction  Object detection  Robots  Task analysis  Machine learning  Proposals  Image recognition 
Abstract: A cognitive robot usually needs to perform multiple tasks in practice and needs to locate the desired area for each task. Since deep learning has achieved substantial progress in image recognition, to solve this area detection problem, it is straightforward to label a functional area (affordance) image dataset and apply a well-trained deep-model-based classifier on all the potential image regions. However, annotating the functional area is time consuming and the requirement of large amount of training data limits the application scope. We observe that the functional area are usually related to the surrounding object context. In this work, we propose to use the existing object detection dataset and employ the object context as effective prior to improve the performance without additional annotated data. In particular, we formulate a two-stream network that fuses the object-related and functionality-related feature for functional area detection. The whole system is formulated in an end-to-end manner and easy to implement with current object detection framework. Experiments demonstrate that the proposed network outperforms current method by almost 20% in terms of precision and recall.


Title: Ultra-Fast Multi-Scale Shape Estimation of Light Transport Matrix for Complex Light Reflection Objects
Key Words: cameras  image reconstruction  image resolution  light reflection  optical projectors  shape measurement  sparse matrices  multiple light paths  complex light reflection objects  Light Transport Matrix estimation  LT Matrix estimation  high resolution measurement  sparse matrix representation  ultra-fast multiscale shape estimation  target objects  specular reflection  light path  memory efficiency  256 × 256 resolution projector  camera system  3D measurement methods  Cameras  Three-dimensional displays  Estimation  Sparse matrices  Shape  Shape measurement  Sensors 
Abstract: 3D measurement of target objects characterized by specular reflection or subsurface scatterings cannot be measured by traditional 3D measurement methods because these targets have multiple light paths that make it difficult to determine the unique surface. We define these objects as complex light reflection objects. In this case, 3D measurement methods based on Light Transport (LT) Matrix estimation may be a solution to measure these complex light reflection objects, because LT Matrix captures every light path, and we can identify all 3D points on the target shape by using LT Matrix. However, these methods either provide low resolution results, or they are too slow for use in robot vision in practice. In this paper, we suppress the computational cost of LT Matrix estimation by dividing LT Matrix estimation into multi-scale. The proposed method reduces the number of candidate combinations between camera pixels and projector pixels greatly by using the information given by low resolution observations. The proposed algorithm allows high resolution measurement of the LT Matrix very efficiently. Furthermore, careful implementation of our method by using a sparse matrix representation achieves memory efficiency. We evaluated our method by measuring 3D points for a 256 × 256 resolution projector and camera system, which is an LT matrix 4096 times larger than that developed in our previous study [1] and 100 times faster than our naïve implementation of [2].


Title: A Deep Learning-Based Stalk Grasping Pipeline
Key Words: crops  image segmentation  industrial manipulators  learning (artificial intelligence)  mobile robots  robot vision  stalk segmentation  grasp point generation pipeline  high stalk density  lighting variation  custom-built ground robot  end-to-end system  average grasping accuracy  Generative Adversarial Network  in-situ sorghum stalk detection  online pipeline  deep learning-based high throughput  labor-intensive phenotyping processes  robotic solutions  plant attributes  precise measurements  fast measurements  deep learning-based stalk grasping pipeline  pixel-wise stalk detection  grasp point detection  stalk detection F1 score  Robots  Pipelines  Image segmentation  Generators  Three-dimensional displays  Gallium nitride  Cameras 
Abstract: The need for fast and precise measurements of plant attributes makes robotic solutions an ideal replacement for labor-intensive phenotyping processes. In this work we present a deep learning-based high throughput, online pipeline for in-situ sorghum stalk detection and grasping. We use a variation of Generative Adversarial Network (GAN) for stalk segmentation trained on a relatively small number of images followed by a grasp point generation pipeline. The presented pipeline is robust to field challenges such as occlusions, high stalk density and lighting variation, and was deployed on a custom-built ground robot. We tested our end-to-end system in a field of Sorghum bicolor in South Carolina, USA, achieving an average grasping accuracy of 74.13% and a stalk detection F1 score of 0.90. Grasp point detection for plant manipulation takes an average of 0.98 seconds, and pixel-wise stalk detection takes 0.2 seconds per image.


Title: Configuration of Perception Systems via Planning Over Factor Graphs
Key Words: assembling  graph theory  planning (artificial intelligence)  production engineering computing  sensor fusion  sensors  perception systems  factor graph  automated systems  data processing algorithms  sensor noise  calibration errors  planning problem  probabilistic graphical models  configuration space  perceptions systems  perception steps  sensor data fusion  industrial assembly  Task analysis  Planning  Robot sensing systems  Uncertainty  Semantics  Cameras  Probabilistic logic 
Abstract: Sensor guided, automated systems require the composition of various sensors and data processing algorithms to obtain relevant information for performing their task. Many applications have additional requirements such as a certain accuracy, which has to be achieved despite sensor noise and calibration errors. In this paper we model the configuration of perception systems as a planning problem over probabilistic graphical models. We work on a subset of the full configuration space of perceptions systems, specifically the used sensors, data processing algorithms and view poses. Based on a semantic description of the goal, available sensors and data processing algorithms, our system plans perception steps and sensor data fusion autonomously. The planner operates by constructing a factor graph until the accuracy requirements of tasks are fulfilled or unobtainable with the available action set. We validate our approach in an industrial assembly scenario.


Title: Intelligent Shipwreck Search Using Autonomous Underwater Vehicles
Key Words: archaeology  autonomous underwater vehicles  control engineering computing  image processing  intelligent control  marine control  mobile robots  path planning  sonar  archaeological survey  intelligent shipwreck search  autonomous underwater vehicles  autonomous robot system  multistep pipeline  high altitude scan  low-resolution side scan sonar data  image processing software  AUV path planner  archaeological sites  underwater archaeological sites  ranking algorithm  Sonar  Proposals  Clustering algorithms  Pipelines  Feature extraction  Software 
Abstract: This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.


Title: A Robust Model Predictive Control Approach for Autonomous Underwater Vehicles Operating in a Constrained Workspace
Key Words: autonomous underwater vehicles  collision avoidance  mobile robots  nonlinear control systems  predictive control  robust control  robust Model Predictive Control approach  constrained workspace  underwater robotic vehicles  static obstacles  workspace boundary  thruster saturation  vehicle velocity  control design  ocean currents  control inputs  way-point tracking mission  control strategy  constrained test tank  Nonlinear Model Predictive Control scheme  way points  underwater robotic vehicle  Oceans  Robots  Underwater vehicles  Mathematical model  Vehicle dynamics  Energy consumption  Computational modeling 
Abstract: This paper presents a novel Nonlinear Model Predictive Control (NMPC) scheme for underwater robotic vehicles operating in a constrained workspace including static obstacles. The purpose of the controller is to guide the vehicle towards specific way points. Various limitations such as: obstacles, workspace boundary, thruster saturation and predefined desired upper bound of the vehicle velocity are captured as state and input constraints and are guaranteed during the control design. The proposed scheme incorporates the full dynamics of the vehicle in which the ocean currents are also involved. Hence, the control inputs calculated by the proposed scheme are formulated in a way that the vehicle will exploit the ocean currents, when these are in favor of the way-point tracking mission which results in reduced energy consumption by the thrusters. The performance of the proposed control strategy is experimentally verified using a 4 Degrees of Freedom (DoF) underwater robotic vehicle inside a constrained test tank with obstacles.


Title: Design, Modeling, and Nonlinear Model Predictive Tracking Control of a Novel Autonomous Surface Vehicle
Key Words: autonomous underwater vehicles  boats  Global Positioning System  hydrodynamics  indoor environment  matrix algebra  mobile robots  motion control  nonlinear control systems  predictive control  tracking  trajectory control  nonlinear model predictive tracking control  autonomous surface vehicle  autonomous robotic boat  indoor environments  outdoor environments  cross type four-thruster configuration  robot prototype  nonlinear dynamic model  NMPC algorithm  surface swarm robotics testbeds  trajectory tracking  holonomic motions  fiberglass  centripetal matrix  Coriolis  hydrodynamic  damping  GPS modules  inertial measurement unit  IMU  swimming pool  natural river  code generation strategy  Boats  Vehicle dynamics  Symmetric matrices  Global Positioning System  Heuristic algorithms  Robot kinematics 
Abstract: In this paper, we present the design, modeling, and real-time nonlinear model predictive control (NMPC) of an autonomous robotic boat. The robot is easy to manufacture, highly maneuverable, and capable of accurate trajectory tracking in both indoor and outdoor environments. In particular, a cross type four-thruster configuration is proposed for the robotic boat to produce efficient holonomic motions. The robot prototype is rapidly 3D-printed and then sealed by adhering several layers of fiberglass. To achieve accurate tracking control, we formulate an NMPC strategy for the four-control-input boat with control input constraints, where the nonlinear dynamic model includes a Coriolis and centripetal matrix, the hydrodynamic added mass, and damping. By integrating “GPS” modules and an inertial measurement unit (IMU) into the robot, we demonstrate accurate trajectory tracking of the robotic boat along preplanned paths in both a swimming pool and a natural river. Furthermore, the code generation strategy employed in our paper yields a two order of magnitude improvement in the run time of the NMPC algorithm compared to similar systems. The robot is designed to form the basis for surface swarm robotics testbeds, on which collective algorithms for surface transportation and self-assembly of dynamic floating infrastructures can be assessed.


Title: Reinforcement Learning of Depth Stabilization with a Micro Diving Agent
Key Words: embedded systems  learning (artificial intelligence)  microrobots  multi-agent systems  robot programming  underwater vehicles  model-based value-function RL algorithm  micro underwater agents  underwater robotics  underwater depth stabilization  light embedded systems  control tasks  microdiving agent  reinforcement learning  Computational modeling  Learning (artificial intelligence)  Task analysis  Robot kinematics  Heuristic algorithms  Force 
Abstract: Reinforcement learning (RL) allows robots to solve control tasks through interaction with their environment. In this paper we study a model-based value-function RL approach, which is suitable for computationally limited robots and light embedded systems. We develop a diving agent, which uses the RL algorithm for underwater depth stabilization. Simulations and experiments with the micro diving agent demonstrate its ability to learn the depth stabilization task.


Title: Dynamic Reconfiguration of Mission Parameters in Underwater Human-Robot Collaboration
Key Words: feedforward neural nets  finite state machines  gesture recognition  human-robot interaction  mobile robots  hand gestures  hand gesture recognition  gesture-to-instruction mapping  finite-state machine  convolutional neural network  human-robot collaborative tasks  autonomous underwater robots  parameter reconfiguration method  real-time programming  underwater human-robot collaboration  mission parameters  dynamic reconfiguration  Robustness  Task analysis  Visualization  Robot sensing systems  Unmanned underwater vehicles  Gesture recognition 
Abstract: This paper presents a real-time programming and parameter reconfiguration method for autonomous underwater robots in human-robot collaborative tasks. Using a set of intuitive and meaningful hand gestures, we develop a syntactically simple framework that is computationally more efficient than a complex, grammar-based approach. In the proposed framework, a convolutional neural network is trained to provide accurate hand gesture recognition; subsequently, a finite-state machine- based deterministic model performs efficient gesture-to-instruction mapping and further improves robustness of the interaction scheme. The key aspect of this framework is that it can be easily adopted by divers for communicating simple instructions to underwater robots without using artificial tags such as fiducial markers or requiring memorization of a potentially complex set of language rules. Extensive experiments are performed both on field-trial data and through simulation, which demonstrate the robustness, efficiency, and portability of this framework in a number of different scenarios. Finally, a user interaction study is presented that illustrates the gain in the ease of use of our proposed interaction framework compared to the existing methods for the underwater domain.


Title: Gaussian Process Adaptive Sampling Using the Cross-Entropy Method for Environmental Sensing and Monitoring
Key Words: bathymetry  entropy  Gaussian processes  learning (artificial intelligence)  mobile robots  optimisation  path planning  sampling methods  single ROI  deepest region  coastal bathymetry mapping mission validate  efficient sampling strategy  latest sensory measurements  sampling density  CE trajectory optimization  higher spatial variability  exhibit extreme sensory measurements  exploring learning  initial stage  path planning  GP-UCB  GP upper confidence  receding-horizon Cross-Entropy trajectory optimization  environmental sensing  cross-entropy method  Gaussian process adaptive sampling  Robot sensing systems  Adaptation models  Optimization  Predictive models  Trajectory  Uncertainty 
Abstract: In this paper, we focus on adaptive sampling on a Gaussian Processes (GP) using the receding-horizon Cross-Entropy (CE) trajectory optimization. Specifically, we employ the GP upper confidence bound (GP-UCB) as the optimization criteria to adaptively plan sampling paths that balance the exploitation-exploration trade-off. Path planning at the initial stage focuses on exploring and learning a model of the environment, and later, on exploiting the learned model to focus sampling around regions that exhibit extreme sensory measurements and much higher spatial variability, denoted as the Region of Interest (ROI). The integration of the CE trajectory optimization allows the sampling density to be dynamically adjusted based on the latest sensory measurements, thus providing an efficient sampling strategy for sensing and localizing the ROI. We demonstrate the effectiveness of the proposed method in exploring simulated scalar fields with single or multiple ROIs. Field experiments with an Unmanned Surface Vehicle (USV) in a coastal bathymetry mapping mission validate the approach's capability in quickly exploring and mapping the given area, and then focusing and increasing the sampling density around the deepest region, as a surrogate for e.g. the extremal concentration of a pollutant in the environment.


Title: OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World
Key Words: control engineering computing  decision making  learning (artificial intelligence)  manipulators  neural nets  optimisation  decision-making problems  reinforcement learning architecture  OptLayer  neural network  closest actions  safe actions  robot reaching tasks  practical constrained optimization  deep reinforcement learning techniques  Robot kinematics  Neural networks  Task analysis  Optimization  Learning (artificial intelligence)  Training 
Abstract: While deep reinforcement learning techniques have recently produced considerable achievements on many decision-making problems, their use in robotics has largely been limited to simulated worlds or restricted motions, since unconstrained trial-and-error interactions in the real world can have undesirable consequences for the robot or its environment. To overcome such limitations, we propose a novel reinforcement learning architecture, OptLayer, that takes as inputs possibly unsafe actions predicted by a neural network and outputs the closest actions that satisfy chosen constraints. While learning control policies often requires carefully crafted rewards and penalties while exploring the range of possible actions, OptLayer ensures that only safe actions are actually executed and unsafe predictions are penalized during training. We demonstrate the effectiveness of our approach on robot reaching tasks, both simulated and in the real world.


Title: Composable Deep Reinforcement Learning for Robotic Manipulation
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  composable deep reinforcement  model-free deep reinforcement learning  simulated robotic manipulation  model-free methods  real-world robotic tasks  maximum entropy policies  soft Q-learning  real-world robotic manipulation  Entropy  Robots  Learning (artificial intelligence)  Neural networks  Machine learning  Task analysis  Training 
Abstract: Model-free deep reinforcement learning has been shown to exhibit good performance in domains ranging from video games to simulated robotic manipulation and locomotion. However, model-free methods are known to perform poorly when the interaction time with the environment is limited, as is the case for most real-world robotic tasks. In this paper, we study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation. The application of this method to real-world manipulation is facilitated by two important features of soft Q-learning. First, soft Q-learning can learn multimodal exploration strategies by learning policies represented by expressive energy-based models. Second, we show that policies learned with soft Q-learning can be composed to create new policies, and that the optimality of the resulting policy can be bounded in terms of the divergence between the composed policies. This compositionality provides an especially valuable tool for real-world manipulation, where constructing new policies by composing existing skills can provide a large gain in efficiency over training from scratch. Our experimental evaluation demonstrates that soft Q-learning is substantially more sample efficient than prior model-free deep reinforcement learning methods, and that compositionality can be performed for both simulated and real-world tasks.


Title: Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning
Key Words: collision avoidance  decentralised control  gradient methods  learning (artificial intelligence)  mobile robots  multi-robot systems  multiscenario multistage training framework  optimal policy  policy gradient  reinforcement learning algorithm  learned sensor-level collision avoidance policy  final learned policy  collision-free paths  large-scale robot system  deep reinforcement learning  safe collision avoidance policy  efficient collision avoidance policy  optimally decentralized multirobot collision avoidance  agent-level feature extraction  decentralized methods  maps raw sensor measurements  multirobot systems  decentralized sensor-level collision avoidance policy  local collision-free action  distributed multirobot collision avoidance systems  Collision avoidance  Robot sensing systems  Robot kinematics  Navigation  Robustness  Training 
Abstract: Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots on rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. We validate the learned sensor-level collision avoidance policy in a variety of simulated scenarios with thorough performance evaluations and show that the final learned policy is able to find time efficient, collision-free paths for a large-scale robot system. We also demonstrate that the learned policy can be well generalized to new scenarios that do not appear in the entire training period, including navigating a heterogeneous group of robots and a large-scale scenario with 100 robots. Videos are available at https://sites.google.com/view/drlmaca.


Title: Tensegrity Robot Locomotion Under Limited Sensory Inputs via Deep Reinforcement Learning
Key Words: learning systems  mobile robots  motion control  neurocontrollers  nonlinear dynamical systems  search problems  state-space methods  nonlinear dynamics  high-dimensional state space  robotic systems  space exploration  tensegrity robot locomotion  deep reinforcement learning algorithms  policy learning process  locomotion control policies  neural network policies  mirror descent guided policy search  end-to-end locomotion policies  tensegrity robotics  Robot sensing systems  Neural networks  Aerospace electronics  Hardware  NASA  Training 
Abstract: Tensegrity robots are composed of rigid rods connected by elastic cables, and their unique light-weight yet compliant structure makes them an appealing choice for space exploration. However, locomotion control for these robotic systems remains difficult due to their nonlinear dynamics and high-dimensional state space. We demonstrate that in the domain of tensegrity robotics, it is possible to efficiently learn end-to-end locomotion policies using mirror descent guided policy search (MDGPS) even with limited sensory inputs. We compare learned neural network policies with other locomotion control policies in various testing environments; and results show that neural network policies consistently outperform others. We also shed light to the policy learning process by analyzing different choices of observation inputs to the robot. Moreover these findings motivate exploration of deep reinforcement learning algorithms in the domain of tensegrity robotics. We show preliminary results with one such locomotion example on discontinuous rough terrains.


Title: Applying Asynchronous Deep Classification Networks and Gaming Reinforcement Learning-Based Motion Planners to Mobile Robots
Key Words: control engineering computing  game theory  learning (artificial intelligence)  mobile robots  neural nets  path planning  pattern classification  gaming reinforcement learning-based motion planner  mobile robotic platform  deep classifier  asynchronous deep classification network  visual recognition  motion planning  deep learning-based algorithms  TT2-bot  embedded neural networks  Mobile robots  Learning (artificial intelligence)  Machine learning  Neural networks  Sensors  Training 
Abstract: In this paper, we propose a new methodology to embed deep learning-based algorithms in both visual recognition and motion planning for general mobile robotic platforms. A framework for an asynchronous deep classification network is introduced to integrate heavy deep classification networks into a mobile robot with no loss of system bandwidth. Moreover, a gaming reinforcement learning-based motion planner, a novel and convenient embodiment of reinforcement learning, is introduced for simple implementation and high applicability. The proposed approaches are implemented and evaluated on a developed robot, TT2-bot. The evaluation was based on a mission devised for a qualitative evaluation of the general purposes and performances of a mobile robotic platform. The robot was required to recognize targets with a deep classifier and plan the path effectively using a deep motion planner. As a result, the robot verified that the proposed approaches successfully integrate deep learning technologies on the stand-alone mobile robot. The embedded neural networks for recognition and path planning were critical components for the robot.


Title: Learning with Training Wheels: Speeding up Training with a Simple Controller for Deep Reinforcement Learning
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  three-term control  DRL network  standard Deep Deterministic Policy Gradient network  training wheels  deep reinforcement learning  robotic applications  robot applications  Assisted Reinforcement Learning  PID controller  local planning  navigation problems  simple control law  Training  Navigation  Acceleration  Robot kinematics  Machine learning  Task analysis 
Abstract: Deep Reinforcement Learning (DRL) has been applied successfully to many robotic applications. However, the large number of trials needed for training is a key issue. Most of existing techniques developed to improve training efficiency (e.g. imitation) target on general tasks rather than being tailored for robot applications, which have their specific context to benefit from. We propose a novel framework, Assisted Reinforcement Learning, where a classical controller (e.g. a PID controller) is used as an alternative, switchable policy to speed up training of DRL for local planning and navigation problems. The core idea is that the simple control law allows the robot to rapidly learn sensible primitives, like driving in a straight line, instead of random exploration. As the actor network becomes more advanced, it can then take over to perform more complex actions, like obstacle avoidance. Eventually, the simple controller can be discarded entirely. We show that not only does this technique train faster, it also is less sensitive to the structure of the DRL network and consistently outperforms a standard Deep Deterministic Policy Gradient network. We demonstrate the results in both simulation and real-world experiments.


Title: Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods
Key Words: learning (artificial intelligence)  Monte Carlo methods  neural nets  robot vision  deep neural network models  off-policy correction  vision-based robotic grasping  off-policy methods  deep reinforcement learning algorithms  off-policy learning  Monte Carlo methods  Grasping  Robots  Task analysis  Benchmark testing  Monte Carlo methods  Machine learning  Training 
Abstract: In this paper, we explore deep reinforcement learning algorithms for vision-based robotic grasping. Model-free deep reinforcement learning (RL) has been successfully applied to a range of challenging environments, but the proliferation of algorithms makes it difficult to discern which particular approach would be best suited for a rich, diverse task like grasping. To answer this question, we propose a simulated benchmark for robotic grasping that emphasizes off-policy learning and generalization to unseen objects. Off-policy learning enables utilization of grasping data over a wide variety of objects, and diversity is important to enable the method to generalize to new objects that were not seen during training. We evaluate the benchmark tasks against a variety of Q-function estimation methods, a method previously proposed for robotic grasping with deep neural network models, and a novel approach based on a combination of Monte Carlo return estimation and an off-policy correction. Our results indicate that several simple methods provide a surprisingly strong competitor to popular algorithms such as double Q-learning, and our analysis of stability sheds light on the relative tradeoffs between the algorithms1.


Title: Overcoming Exploration in Reinforcement Learning with Demonstrations
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  reinforcement learning  reward function  task horizon  RL methods  exploration problem  multistep robotics tasks  robot arm  deep deterministic policy gradients  hindsight experience replay  simulated robotics tasks  Task analysis  Robots  Learning (artificial intelligence)  Stacking  Training  Mathematical model  Games 
Abstract: Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.


Title: Fast Image-Based Geometric Change Detection Given a 3D Model
Key Words: image reconstruction  image sequences  object detection  solid modelling  stereo image processing  fast image-based geometric change detection  multiple images  self-recorded image sequences  robotic applications  3D model  3D location  Three-dimensional displays  Solid modeling  Computational modeling  Cameras  Robots  Two dimensional displays  Uncertainty 
Abstract: 3D models of the environment are used in numerous robotic applications and should reflect the current state of the world. In this paper, we address the problem of quickly finding structural changes between the current state of the world and a given 3D model using a small number of images. Our approach finds inconsistencies between pairs of images by re-projecting an image onto another one by passing through the given 3D model. This process leads to ambiguities, which we resolve by combining multiple images such that the 3D location of the change can be estimated. A focus of our approach is that it can be executed fast enough to allow the operation on a mobile system. We implemented our approach in C++ and released it as open source software. We tested it on existing datasets as well as on self-recorded image sequences and 3D models, which we publicly share. Our experiments show that our method quickly finds changes in the geometry of a scene.


Title: Multimodal 2D Image to 3D Model Registration via a Mutual Alignment of Sparse and Dense Visual Features
Key Words: geometry  image registration  solid modelling  multimodal 2D image  3D model registration  dense visual features  2D/3D registration methods  geometric features  feature type  hybrid registration framework  visual sensors  3D model  Mutual Alignment  geometric visual features  sparse visual features  2D/3D alignment  Three-dimensional displays  Cameras  Solid modeling  Visualization  Feature extraction  Two dimensional displays  Sensors 
Abstract: Many fields of application could benefit from an accurate registration of measurements of different modalities over a known 3D model. However, aligning a 2D image to a 3D model is a challenging task and is even more complex when the two have a different modality. Most of the 2D/3D registration methods are based on either geometric or dense visual features. Both have their own advantages and their own drawbacks. We propose, in this paper, to mutually exploit the advantages of one feature type to reduce the drawbacks of the other one. For this, an hybrid registration framework has been designed to mutually align geometrical and dense visual features in order to obtain an accurate final 2D/3D alignment. We evaluate and compare the proposed registration method on real data acquired by a robot equipped with several visual sensors. The results highlights the robustness of the method and its ability to produce wide convergence domain and a high registration accuracy.


Title: An Efficient Volumetric Mesh Representation for Real-Time Scene Reconstruction Using Spatial Hashing
Key Words: computational geometry  data structures  image reconstruction  image representation  mesh generation  sensor fusion  solid modelling  real-time scene reconstruction  spatial hashing  flexible data structures  3D data fusion  mesh refinement  mesh quality  mesh memory consumption  volumetric mesh representation  Hamming distance  3D reconstruction  Three-dimensional displays  Real-time systems  Data integration  Mesh generation  Rendering (computer graphics)  Data structures  Sensors 
Abstract: Mesh plays an indispensable role in dense realtime reconstruction essential in robotics. Efforts have been made to maintain flexible data structures for 3D data fusion, yet an efficient incremental framework specifically designed for online mesh storage and manipulation is missing. We propose a novel framework to compactly generate, update, and refine mesh for scene reconstruction upon a volumetric representation. Maintaining a spatial-hashed field of cubes, we distribute vertices with continuous value on discrete edges that support O(1) vertex accessing and forbid memory redundancy. By introducing Hamming distance in mesh refinement, we further improve the mesh quality regarding the triangle type consistency with a low cost. Lock-based and lock-free operations were applied to avoid thread conflicts in GPU parallel computation. Experiments demonstrate that the mesh memory consumption is significantly reduced while the running speed is kept in the online reconstruction process.


Title: Mapping with Dynamic-Object Probabilities Calculated from Single 3D Range Scans
Key Words: control engineering computing  laser ranging  mobile robots  navigation  neural nets  probability  robot vision  SLAM (robots)  KITTI dataset  mapping process  mapping module  dynamic object  pointwise probability  neural network  laser range data  3D grid map  navigation functions  robot perceptions  dynamic environments  safe navigation  robust navigation  autonomous robotic systems  single 3D range scans  dynamic-object probabilities  time 3.0 d  Three-dimensional displays  Cameras  Neural networks  Measurement by laser beam  Lasers  Laser beams  Image segmentation 
Abstract: Various autonomous robotic systems require maps for robust and safe navigation. Particularly when robots are employed in dynamic environments, accurate knowledge about which components of the robot perceptions belong to dynamic and static aspects in the environment can greatly improve navigation functions. In this paper we propose a novel method for building 3D grid maps using laser range data in dynamic environments. Our approach uses a neural network to estimate the pointwise probability of a point belonging to a dynamic object. The output from our network is fed to the mapping module for building a 3D grid map containing only static parts of the environment. We present experimental results obtained by training our neural network using the KITTI dataset and evaluating it in a mapping process using our own dataset. In extensive experiments, we show that maps generated using the proposed probability about dynamic objects increases the accuracy of the resulting maps.


Title: A Survey of Voxel Interpolation Methods and an Evaluation of Their Impact on Volumetric Map-Based Visual Odometry
Key Words: cameras  computational geometry  distance measurement  image reconstruction  interpolation  medical image processing  pose estimation  robot vision  SLAM (robots)  camera trajectories  trilinear interpolation method  depth-camera pose tracking  performance degradation  truncated signed distance field  voxel-based map representations  geometric interpolation methods  intermediate options  nearest neighbors  voxel volumes  volumetric map-based visual odometry  voxel interpolation methods  Interpolation  Memory management  Three-dimensional displays  Pose estimation  Extrapolation  Two dimensional displays  Image resolution 
Abstract: Voxel volumes are simple to implement and lend themselves to many of the tools and algorithms available for 2D images. However, the additional dimension of voxels may be costly to manage in memory when mapping large spaces at high resolutions. While lowering the resolution and using interpolation is common work-around, in the literature we often find that authors either use trilinear interpolation or nearest neighbors and rarely any of the intermediate options. This paper presents a survey of geometric interpolation methods for voxel-based map representations. In particular we study the truncated signed distance field (TSDF) and the impact of using fewer than 8 samples to perform interpolation within a depth-camera pose tracking and mapping scenario. We find that lowering the number of samples fetched to perform the interpolation results in performance similar to the commonly used trilinear interpolation method, but leads to higher frame-rates. We also report that lower bit-depth generally leads to performance degradation, though not as much as may be expected, with voxels containing as few as 3 bits sometimes resulting in adequate estimation of camera trajectories.


Title: Complex Urban LiDAR Data Set
Key Words: graph theory  mobile robots  optical radar  pose estimation  radar computing  SLAM (robots)  complex urban environments  light detection and ranging data set  fiber optic gyro  inertial measurement unit  Global Positioning System  vehicle pose estimation  graph simultaneous location and mapping algorithm  graph SLAM algorithm  Robot Operating System environment  raw sensor data  2D LiDAR  16-ray 3D LiDARs  LiDAR sensors  three-dimensional LiDAR  building complexes  high-rise buildings  complex urban LiDAR data set  frequency 100.0 Hz  Laser radar  Three-dimensional displays  Global Positioning System  Two dimensional displays  Sensor systems  Urban areas 
Abstract: This paper presents a Light Detection and Ranging (LiDAR) data set that targets complex urban environments. Urban environments with high-rise buildings and congested traffic pose a significant challenge for many robotics applications. The presented data set is unique in the sense it is able to capture the genuine features of an urban environment (e.g. metropolitan areas, large building complexes and underground parking lots). Data of two-dimensional (2D) and three-dimensional (3D) LiDAR, which are typical types of LiDAR sensors, are provided in the data set. The two 16-ray 3D LiDARs are tilted on both sides for maximal coverage. One 2D LiDAR faces backward while the other faces forwards to collect data of roads and buildings, respectively. Raw sensor data from Fiber Optic Gyro (FOG), Inertial Measurement Unit (IMU), and the Global Positioning System (GPS) are presented in a file format for vehicle pose estimation. The pose information of the vehicle estimated at 100 Hz is also presented after applying the graph simultaneous localization and mapping (SLAM) algorithm. For the convenience of development, the file player and data viewer in Robot Operating System (ROS) environment were also released via the web page. The full data sets are available at: http://irap.kaist.ac.kr/dataset. In this website, 3D preview of each data set is provided using WebGL.


Title: Live Structural Modeling Using RGB-D SLAM
Key Words: image colour analysis  image fusion  image texture  robot vision  SLAM (robots)  solid modelling  live structural modeling  dense point cloud  shape map  single point cloud  metric primitive modeling  RGB-D SLAM  primitive shape localization  shape fusion  Shape  Three-dimensional displays  Simultaneous localization and mapping  Cameras  Computational modeling  History  Estimation 
Abstract: This paper presents a method for localizing primitive shapes in a dense point cloud computed by the RGB-D SLAM system. To stably generate a shape map containing only primitive shapes, the primitive shape is incrementally modeled by fusing the shapes estimated at previous frames in the SLAM, so that an accurate shape can be finally generated. Specifically, the history of the fusing process is used to avoid the influence of error accumulation in the SLAM. The point cloud of the shape is then updated by fusing the points in all the previous frames into a single point cloud. In the experimental results, we show that metric primitive modeling in texture-less and unprepared environments can be achieved online.


Title: Adaptive Sampling and Online Learning in Multi-Robot Sensor Coverage with Mixture of Gaussian Processes
Key Words: Gaussian processes  learning (artificial intelligence)  multi-robot systems  optimisation  online learning  multirobot sensor coverage  online environmental sampling  multirobot coverage control  environmental phenomenon  robot team  Gaussian Process  locally learned Gaussian Processes  collective model learning  simultaneous adaptive sampling  density function  sensing performance optimization  Robot sensing systems  Adaptation models  Density functional theory  Temperature distribution  Data models 
Abstract: We consider the problem of online environmental sampling and modeling for multi-robot sensor coverage, where a team of robots spread out over the workspace in order to optimize the overall sensing performance. In contrast to most existing works on multi-robot coverage control that assume prior knowledge of the distribution of environmental phenomenon, also known as density function, we relax this assumption and enable the robot team to efficiently learn the model of the unknown density function Online using adaptive sampling and non-parametric inference such as Gaussian Process (GP). To capture significantly different components of the environmental phenomenon, we propose a new approach with mixture of locally learned Gaussian Processes for collective model learning and an information-theoretic criterion for simultaneous adaptive sampling in multi-robot coverage. Our approach demonstrates a better generalization of the environment modeling and thus the improved performance of coverage without assuming the density function is known a priori. We demonstrate the effectiveness of our algorithm via simulations of information gathering from indoor static sensors.


Title: Coordinated Dense Aerial Traffic with Self-Driving Drones
Key Words: air traffic control  autonomous aerial vehicles  collision avoidance  decentralised control  multi-robot systems  coordinated dense aerial traffic  general air traffic control solution  decentralized air traffic control solution  package-delivery scenarios  intelligent collective collision avoidance  motion planning  jam-free optimal traffic flow  force-based distributed multirobot control model  behaviour-driven velocity alignment  self-organized queueing  conflict-avoiding self-driving  Drones  Mathematical model  Atmospheric modeling  Oscillators  Acceleration  Task analysis  Roads 
Abstract: In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.


Title: Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems
Key Words: decision making  multi-agent systems  multi-robot systems  planning (artificial intelligence)  multirobot  small-scale synchronous decision-making scenarios  asynchronous agents  multiple strategic adversaries  adversary strategies  optimized stratagems  unified policy  near-optimality  optimal adversarial policy switching  decentralized asynchronous multiagent systems  communication capabilities  Switches  Planning  Task analysis  Robot kinematics  Probabilistic logic 
Abstract: A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.


Title: Data Ferrying with Swarming UAS in Tactical Defence Networks
Key Words: mobile robots  multi-robot systems  harsh communication environments  UAS  human-swarm interaction  data dissemination capabilities  indoor flight facilities  physical swarm robotic platforms  radio-frequency communications  swarm members  tactical defence networks  Emulation  Convergence  Australia  Radio frequency  Data models  Robot kinematics 
Abstract: In this paper we categorise swarming into four classes, depending on the manner in which swarm members communicate. We identify two of these classes as ready candidates for the provision of communications within tactical defence networks in which radio-frequency communications are highly contested or denied. We demonstrate the feasibility of a swarm-robotics approach to data ferrying from both of these classes using simulation, emulation, and physical swarm robotic platforms within indoor flight facilities. The results show strong alignment between data dissemination capabilities of the simulated and physical systems; we envisage these techniques providing communications between not only troops, but also other swarm robotic platforms, thereby enabling swarm robotics applications and human-swarm interaction within harsh communications environments.


Title: Distance-Based Multi-Robot Coordination on Pocket Drones
Key Words: learning (artificial intelligence)  particle filtering (numerical methods)  recurrent neural nets  remotely operated vehicles  Deep Q-Learning Network  recurrent network  UWB-distance information  neural networks  distance-based multirobot coordination  pocket drones  MicroAerial Vehicles  recurrent neural network  Drones  Robot kinematics  Recurrent neural networks  Hardware  Robot sensing systems  Distance measurement 
Abstract: We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.


Title: Human-in-the-Loop Mixed-Initiative Control Under Temporal Tasks
Key Words: control engineering computing  human-robot interaction  learning (artificial intelligence)  mobile robots  motion control  path planning  planning (artificial intelligence)  temporal logic  plan adaptation scheme  short-term tasks  iterative inverse reinforcement learning algorithm  human preference  plan synthesis  human-in-the-loop simulations  mixed-initiative control  motion control  task planning problem  mobile robots  high-level tasks  Linear Temporal Logic  hard constraints  soft constraints  robot autonomy  additive terms  contingent task assignments  online coordination scheme  mixed-initiative continuous controller  temporal tasks  human initiatives  Task analysis  Safety  Robot kinematics  Automata  Planning  Navigation 
Abstract: This paper considers the motion control and task planning problem of mobile robots under complex high-level tasks and human initiatives. The assigned task is specified as Linear Temporal Logic (LTL) formulas that consist of hard and soft constraints. The human initiative influences the robot autonomy in two explicit ways: with additive terms in the continuous controller and with contingent task assignments. We propose an online coordination scheme that encapsulates (i) a mixed-initiative continuous controller that ensures all-time safety despite of possible human errors, (ii) a plan adaptation scheme that accommodates new features discovered in the workspace and short-term tasks assigned by the operator during run time, and (iii) an iterative inverse reinforcement learning (IRL) algorithm that allows the robot to asymptotically learn the human preference on the parameters during the plan synthesis. The results are demonstrated by both realistic human-in-the-loop simulations and experiments.


Title: Cooperative Adaptive Control for Cloud-Based Robotics
Key Words: adaptive control  cloud computing  control engineering computing  control system synthesis  decentralised control  Lyapunov methods  manipulators  multi-robot systems  adaptive control  robot manipulators  synchronous centralized update laws  parameter convergence  time-varying network topologies  nonidealized networked conditions  planar manipulator  cloud-based robotics  inertial parameters  collective sufficient richness notion  decentralized update laws  Adaptive control  Manipulators  Convergence  Robot sensing systems  Cloud computing  Trajectory 
Abstract: This paper studies collaboration through the cloud in the context of cooperative adaptive control for robot manipulators. We first consider the case of multiple robots manipulating a common object through synchronous centralized update laws to identify unknown inertial parameters. Through this development, we introduce a notion of Collective Sufficient Richness, wherein parameter convergence can be enabled through teamwork in the group. The introduction of this property and the analysis of stable adaptive controllers that benefit from it constitute the main new contributions of this work. Building on this original example, we then consider decentralized update laws, time-varying network topologies, and the influence of communication delays on this process. Perhaps surprisingly, these nonidealized networked conditions inherit the same benefits of convergence being determined through collective effects for the group. Simple simulations of a planar manipulator identifying an unknown load are provided to illustrate the central idea and benefits of Collective Sufficient Richness.


Title: Optimized Environment Exploration for Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  image reconstruction  mobile robots  path planning  quadtrees  tree data structures  viewpoint generation process  consistent maps  noisy sonar data  optimized environment exploration  autonomous underwater  autonomous robotic environment exploration  underwater domain  noisy acoustic sensors  high localization error  control disturbances  robotic exploration algorithm  underwater vehicles  view planning  path planning algorithms  exploration approach  quadtree data structure  relevant queries  natural environments  underwater maps  map representation  optical coverage  time 3.0 d  Cameras  Sonar  Planning  Robot sensing systems  Inspection  Three-dimensional displays 
Abstract: Achieving full autonomous robotic environment exploration in the underwater domain is very challenging, mainly due to noisy acoustic sensors, high localization error, control disturbances of the water and lack of accurate underwater maps. In this work we present a robotic exploration algorithm for underwater vehicles that does not rely on prior information about the environment. Our method has been greatly influenced by many robotic exploration, view planning and path planning algorithms. The proposed method constitutes a significant improvement over our previous work [1]: Firstly, we refine our exploration approach to improve robustness; Secondly, we propose an alternative map representation based on the quadtree data structure that allows different relevant queries to be performed efficiently, reducing the computational cost of the viewpoint generation process; Thirdly, we present an algorithm that is capable of generating consistent maps even when noisy sonar data is used. The aforementioned contributions have increased the reliability of the algorithm, allowing new real experiments performed in artificial structures but also in more challenging natural environments, from which we provide a 3D reconstruction to show that with this algorithm full optical coverage is obtained.


Title: Pilot Surveys for Adaptive Informative Sampling
Key Words: aerospace control  environmental factors  Gaussian processes  mobile robots  path planning  regression analysis  sampling methods  sampling trajectory  Gaussian Process regression  pilot surveys  adaptive informative sampling  GP hyperparameter estimation  path planning decisions  environmental field modeling  informative samples  adaptive sampling techniques  GP regression  Adaptation models  Data models  Kernel  Robots  Gaussian processes  Estimation  Optimization 
Abstract: Adaptive sampling has been shown to be an effective method for modeling environmental fields, such as algae concentrations in the ocean. In adaptive sampling, a robot adapts its sampling trajectory based on data that it is collecting. This data is often aggregated into models, using techniques such as Gaussian Process (G P) regression. The (hyper-)parameters for these models need to be manually set or, ideally, estimated from data. For GP regression, hyperparameters are typically estimated using prior data. This paper addresses the case where initial hyperparameters need to be estimated, but no prior data is available. Without prior data or accurately pre-defined hyperparameters, adaptive sampling techniques may fail, because there is no good model to base path planning decisions on. One method of gathering data is to perform a pilot survey. This survey needs to select informative samples for initiating the model, but without having a model to determine where best to sample. In this work, we evaluate four pilot surveys, which use a softmax function on the distance between waypoints and previously sampled data for waypoint selection. Simulation results show that pilot surveys that maximize waypoint spread over randomization lead to more stable estimation of GP hyperparameters, and create accurate models more quickly.


Title: Gaze-Assisted Adaptive Motion Scaling Optimization Using Graded and Preference Based Bayesian Approaches
Key Words: adaptive control  Bayes methods  human-robot interaction  medical robotics  optimisation  surgery  telerobotics  gaze-assisted adaptive motion scaling optimization  Bayesian approaches  master-slave surgical systems  slave robot  gaze-assisted intention recognition scheme  Bayesian approach  human-robot interface  Bayesian optimization methods  Robots  Bayes methods  Instruments  Linear programming  Optimization methods  Master-slave 
Abstract: A key component to the success of master-slave surgical systems is the quality of the master interface used to relay the surgeon's instructions to the slave robot. In previous work the authors developed a gaze-assisted intention recognition scheme, allowing the system to dynamically adapt the motion scaling based on where the user is trying to reach. This allowed users to perform tasks significantly more quickly and with less need for clutching. However, the system possessed a number of core parameters that were manually optimized, potentially providing a non-optimal solution depending on the user. This paper presents a Bayesian approach to the problem of optimizing a human-robot interface in a user-specific manner. Two Bayesian optimization methods are studied: one in which users are asked to grade robot behavior for a given set of parameters, and one where only preference relative to other parameter sets is expressed. The performance of these optimizations is evaluated in a blind comparison user study, demonstrating that the optimized parameters are preferred to the manually optimized ones in over 90 % of cases after only 12 test samples. These parameters are further shown to perform at least as well as the manually optimized ones in all cases, and showing statistically significant improvement in the case of the graded optimization.


Title: Learning to Race Through Coordinate Descent Bayesian Optimisation
Key Words: automobiles  Bayes methods  Hilbert spaces  mobile robots  optimisation  robot dynamics  vehicle dynamics  dynamical model  robot  car racing simulation  descent Bayesian optimisation  race track  kernel Hilbert space  Bayesian optimisation  Optimization  Robot kinematics  Bayes methods  Search problems  Kernel  Linear programming 
Abstract: In the automation of many kinds of processes, the observable outcome can often be described as the combined effect of an entire sequence of actions, or controls, applied throughout the process execution. In these cases, strategies to optimise control policies for individual stages of the process are not applicable, and instead the whole policy needs to be optimised at once. On the other hand, the cost to evaluate the policy's performance might also be high, being desirable that a solution can be found with as few interactions as possible with the real system. We consider the problem of optimising control policies to allow a robot to complete a given race track within a minimum amount of time. We assume that the robot has no prior information about the track or its own dynamical model, just an initial valid driving example. Localisation is only applied to monitor the robot and to provide an indication of its position along the track's centre axis. With that in mind, we propose a method for finding a policy that minimises the time per lap while keeping the vehicle on the track using a Bayesian optimisation (BO) approach over a reproducing kernel Hilbert space. We apply an algorithm to search more efficiently over high-dimensional policy-parameter spaces with BO, by iterating over each dimension individually, in a sequential coordinate descent-like scheme. Experiments demonstrate the performance of the algorithm against other methods in a simulated car racing environment.


Title: Towards Emergence of Tool Use in Robots: Automatic Tool Recognition and Use Without Prior Tool Learning
Key Words: cognition  object recognition  robot vision  automatic tool recognition  human dexterity  skill transfer  robots cognition  robots capabilities  tools embodiment  object recognition  Tools  Task analysis  Kinematics  Automobiles  Robot sensing systems  Dynamics 
Abstract: Humans are adept at tool use. We can intuitively and immediately improvise and use unknown objects in our environment as tools, to assist us in performing tasks. In this study, we provide similar cognition and capabilities to robots. Neuroscientific studies on tool use have suggested that human dexterity with tools is enabled by the embodiment of the tools, which in effect, allows humans to immediately transfer prior skills acquired without tools, onto tasks requiring tool use. Here, utilizing the theoretical results from our investigations on embodiment and tool use in humans over the last years, we propose a concept and algorithm to enable similar skill transfer by robots. Our algorithm enables a robot that has had no prior learning with tools, to automatically recognize an object (seen for the first time) in its environment as a potential tool for an otherwise unattainable task, and use the tool to perform the task thereafter.


Title: Put-in-Box Task Generated from Multiple Discrete Tasks by aHumanoid Robot Using Deep Learning
Key Words: feature extraction  humanoid robots  learning (artificial intelligence)  manipulators  recurrent neural nets  multiple discrete tasks  deep learning  deep neural networks  robot manipulation model  DNNs  long sequential dynamic tasks  multiple short sequential tasks  multiple timescale recurrent neural network  MTRNN  initial motion steps  final motion steps  initial image input  subtask  put-in-box task  Task analysis  Robots  Feature extraction  Switches  Neurons  Training  Convolution 
Abstract: For robots to have a wide range of applications, they must be able to execute numerous tasks. However, recent studies into robot manipulation using deep neural networks (DNN) have primarily focused on single tasks. Therefore, we investigate a robot manipulation model that uses DNNs and can execute long sequential dynamic tasks by performing multiple short sequential tasks at appropriate times. To generate compound tasks, we propose a model comprising two DNNs: a convolutional autoencoder that extracts image features and a multiple timescale recurrent neural network (MTRNN) to generate motion. The internal state of the MTRNN is constrained to have similar values at the initial and final motion steps; thus, motions can be differentiated based on the initial image input. As an example compound task, we demonstrate that the robot can generate a “Put-In-Box” task that is divided into three subtasks: open the box, grasp the object and put it into the box, and close the box. The subtasks were trained as discrete tasks, and the connections between each subtask were not trained. With the proposed model, the robot could perform the Put-In-Box task by switching among subtasks and could skip or repeat subtasks depending on the situation.


Title: CASSL: Curriculum Accelerated Self-Supervised Learning
Key Words: grippers  learning (artificial intelligence)  sensitivity analysis  adaptive-underactuated multifingered gripper  curriculum accelerated self-supervised learning  variance-based global sensitivity analysis  control parameters  control dimensions  training data  CASSL orders  higher-dimensional action  map visual information  clever sampling strategy  data collection efforts  higher-dimensional control  low-dimensional action  self-supervised learning approaches  complete end-to-end learning  staged curriculum learning  CASSL framework  Aerospace electronics  Grasping  Training  Task analysis  Robots  Sensitivity analysis 
Abstract: Recent self-supervised learning approaches focus on using a few thousand data points to learn policies for high-level, low-dimensional action spaces. However, scaling this framework for higher-dimensional control requires either scaling up the data collection efforts or using a clever sampling strategy for training. We present a novel approach - Curriculum Accelerated Self-Supervised Learning (CASSL) - to train policies that map visual information to high-level, higher-dimensional action spaces. CASSL orders the sampling of training data based on control dimensions: the learning and sampling are focused on few control parameters before other parameters. The right curriculum for learning is suggested by variance-based global sensitivity analysis of the control space. We apply our CASSL framework to learning how to grasp using an adaptive, underactuated multi-fingered gripper, a challenging system to control. Our experimental results indicate that CASSL provides significant improvement and generalization compared to baseline methods such as staged curriculum learning (8% increase) and complete end-to-end learning with random exploration (14% improvement) tested on a set of novel objects.


Title: Learning to Control Redundant Musculoskeletal Systems with Neural Networks and SQP: Exploiting Muscle Properties
Key Words: biomechanics  biomimetics  bone  humanoid robots  learning (artificial intelligence)  muscle  neural nets  nonlinear control systems  physiological models  quadratic programming  machine learning approaches  muscle stimulations  high actuator redundancy  learned forward model  neural network  biomimetic muscle-driven robot show  nonlinearity  biomechanical musculoskeletal systems  quadratic programming  SQP  Muscles  Joints  Robots  Biological system modeling  Torque  Biomechanics 
Abstract: Modeling biomechanical musculoskeletal systems reveals that the mapping from muscle stimulations to movement dynamics is highly nonlinear and complex, which makes it difficult to control those systems with classical techniques. In this work, we not only investigate whether machine learning approaches are capable of learning a controller for such systems. We are especially interested in the question if the structure of the musculoskeletal apparatus exhibits properties that are favorable for the learning task. In particular, we consider learning a control policy from target positions to muscle stimulations. To account for the high actuator redundancy of biomechanical systems, our approach uses a learned forward model represented by a neural network and sequential quadratic programming to obtain the control policy, which also enables us to alternate the co-contraction level and hence allows to change the stiffness of the system and to include optimality criteria like small muscle stimulations. Experiments on both a simulated musculoskeletal model of a human arm and a real biomimetic muscle-driven robot show that our approach is able to learn an accurate controller despite high redundancy and nonlinearity, while retaining sample efficiency.


Title: Q-CP: Learning Action Values for Cooperative Planning
Key Words: iterative methods  learning (artificial intelligence)  learning systems  mobile robots  Monte Carlo methods  multi-robot systems  navigation  path planning  state-space methods  stochastic games  tree searching  uncertain systems  multirobot systems  manifold applications  unstructured scenarios  state dimensionality  model-based reinforcement learning algorithm  Q-learning  curse-of-dimensionality  cooperation scenario  mobile robots  robot behaviors  uncertainties  state space exploration  action values learning  stochastic cooperative games  cooperative navigation problem  cooperative planning  Monte-Carlo tree search iterations  general-sum games  KUKA YouBots  robot hand-overs  coordination task  Robot kinematics  Games  Monte Carlo methods  Task analysis  Planning  Stochastic processes 
Abstract: Research on multi-robot systems has demonstrated promising results in manifold applications and domains. Still, efficiently learning an effective robot behaviors is very difficult, due to unstructured scenarios, high uncertainties, and large state dimensionality (e.g, hyper-redundant and groups of robot). To alleviate this problem, we present Q-CP a cooperative model-based reinforcement learning algorithm, which exploits action values to both (1) guide the exploration of the state space and (2) generate effective policies. Specifically, we exploit Q-learning to attack the curse-of-dimensionality in the iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on different stochastic cooperative (general-sum) games: (1) a simple cooperative navigation problem among 3 robots, (2) a cooperation scenario between a pair of KUKA YouBots performing hand-overs, and (3) a coordination task between two mobile robots entering a door. The obtained results show the effectiveness of Q- CP in the chosen applications, where action values drive the exploration and reduce the computational demand of the planning process while achieving good performance.


Title: Robust Localization of Mobile Robots Considering Reliability of LiDAR Measurements
Key Words: mobile robots  optical radar  optical sensors  pose estimation  reliability  robot vision  mobile robot  LiDAR measurements  localization errors  LiDAR sensor-based localization  optical sensors  robust localization  range measurements  reliability  Light Detection and Ranging sensor  pose estimation  Reliability  Laser radar  Robot sensing systems  Optical sensors  Glass  Adaptive optics  Optical variables measurement 
Abstract: In this study, we propose a novel Light Detection and Ranging (LiDAR) sensor-based localization method for localization of a mobile robot. In localization using the LiDAR sensor, localization errors occur when real range measurements differ from reference distances computed from a map. This study focuses on three factors that cause differences between real range measurements and reference distances. The first factor corresponds to optical characteristics of the LiDAR sensor for objects such as glass walls and mirrors. The second factor corresponds to occlusions by dynamic obstacles. The third factor corresponds to static changes in the environment. In practical applications, three factors often simultaneously occur. Although there have been many previous works, robust localization to overcome these three difficulties is still a challenging problem. This study proposes a novel robust localization scheme that exploits only reliable range measurements. A LiDAR sensor-based localization scheme can be successfully executed by utilizing only a few reliable range measurements. Therefore, the computation of reliability plays a significant role. The computation of reliability is divided into two steps. The first step considers characteristics of optical sensors. The second step mainly deals with the effects of obstacles. The observation likelihood model exploits computed reliability for pose estimation. The proposed scheme was successfully verified through various experiments under challenging situations.


Title: Sparse Gaussian Processes on Matrix Lie Groups: A Unified Framework for Optimizing Continuous-Time Trajectories
Key Words: continuous time systems  Gaussian processes  Lie groups  matrix algebra  mobile robots  motion control  optimisation  path planning  regression analysis  state estimation  trajectory control  nonparametric representation  trajectory distributions  sparse GP regression  robot state  locally linear GPs  state estimation  motion planning tasks  sparse Gaussian processes  continuous-time trajectories  trajectory optimization  matrix Lie groups  robot motion reasoning  Trajectory  Simultaneous localization and mapping  Estimation  Planning  Sparse matrices  Gaussian processes 
Abstract: Continuous-time trajectories are useful for reasoning about robot motion in a wide range of tasks. Sparse Gaussian processes (GPs) can be used as a non-parametric representation for trajectory distributions that enables fast trajectory optimization by sparse GP regression. However, most previous approaches that utilize sparse GPs for trajectory optimization are limited by the fact that the robot state is represented in vector space. In this paper, we first extend previous works to consider the state on general matrix Lie groups by applying a constant-velocity prior and defining locally linear GPs. Next, we discuss how sparse GPs on Lie groups provide a unified continuous-time framework for trajectory optimization for solving a number of robotics problems including state estimation and motion planning. Finally, we demonstrate and evaluate our approach on several different estimation and motion planning tasks with both synthetic and real-world experiments.


Title: Complexity Analysis and Efficient Measurement Selection Primitives for High-Rate Graph SLAM
Key Words: computational complexity  graph theory  iterative methods  Newton method  optimisation  SLAM (robots)  complexity analysis  globally-efficient structure  favorable global structures  Gauss-Newton iteration  factorization step  primary computational bottleneck  graph structure  existing analytic gap  quantitative metric called elimination complexity  significant computation reductions  measurement decimation  simple heuristics  aggressive pruning  significant computational savings  structurally-naïve techniques  global level  edge count  SLAM graph  graph-based SLAM  high-rate graph  efficient measurement selection primitives  Simultaneous localization and mapping  Complexity theory  Optimization  Sparse matrices  Extraterrestrial measurements  Linear algebra 
Abstract: Sparsity has been widely recognized as crucial for efficient optimization in graph-based SLAM. Because the sparsity and structure of the SLAM graph reflect the set of incorporated measurements, many methods for sparsification have been proposed in hopes of reducing computation. These methods often focus narrowly on reducing edge count without regard for structure at a global level. Such structurally-naïve techniques can fail to produce significant computational savings, even after aggressive pruning. In contrast, simple heuristics such as measurement decimation and keyframing are known empirically to produce significant computation reductions. To demonstrate why, we propose a quantitative metric called elimination complexity (EC) that bridges the existing analytic gap between graph structure and computation. EC quantifies the complexity of the primary computational bottleneck: the factorization step of a Gauss-Newton iteration. Using this metric, we show rigorously that decimation and keyframing impose favorable global structures and therefore achieve computation reductions on the order of r2/9 and r3, respectively, where r is the pruning rate. We additionally present numerical results showing EC provides a good approximation of computation in both batch and incremental (iSAM2) optimization and demonstrate that pruning methods promoting globally-efficient structure outperform those that do not.


Title: Dense Planar-Inertial SLAM with Structural Constraints
Key Words: distance measurement  image reconstruction  least squares approximations  optimisation  robot vision  SLAM (robots)  dense visual odometry estimation  planar measurements  SLAM framework  IMU biases  planar landmarks  incremental smoothing  Bayes Tree  IMU data  visual information  modeling planes  IMU states  reconstruction results  SLAM algorithms  structural constraints  DPI-SLAM system  planar-inertial SLAM system  novel dense planar-inertial SLAM  dense 3D models  indoor environments  hand-held RGB-D sensor  inertial measurement unit  preinte-grated IMU measurements  factor graph  incremental mapping  probabilistic global optimization  Simultaneous localization and mapping  Optimization  Three-dimensional displays  Real-time systems  Estimation  Visualization 
Abstract: In this work, we develop a novel dense planar-inertial SLAM (DPI-SLAM) system to reconstruct dense 3D models of large indoor environments using a hand-held RGB-D sensor and an inertial measurement unit (IMU). The preinte-grated IMU measurements are loosely-coupled with the dense visual odometry (VO) estimation and tightly-coupled with the planar measurements in a full SLAM framework. The poses, velocities, and IMU biases are optimized together with the planar landmarks in a global factor graph using incremental smoothing and mapping with the Bayes Tree (iSAM2). With odometry estimation using both RGB-D and IMU data, our system can keep track of the poses of the sensors even without sufficient planes or visual information (e.g. textureless walls) temporarily. Modeling planes and IMU states in the fully probabilistic global optimization reduces the drift that distorts the reconstruction results of other SLAM algorithms. Moreover, structural constraints between nearby planes (e.g. right angles) are added into the DPI-SLAM system, which further recovers the drift and distortion. We test our DPI-SLAM on large indoor datasets and demonstrate its state-of-the-art performance as the first planar-inertial SLAM system.


Title: Radiation Source Localization in GPS-Denied Environments Using Aerial Robots
Key Words: gamma-ray detection  Global Positioning System  mobile robots  photomultipliers  radioactive sources  radioactivity measurement  solid scintillation detectors  radiation measurements  radioactive source localization  radiation mapping  thallium-doped cesium iodide scintillator  indoor GPS-denied environments  Cesium-137 radiation source  GPS-denied localization  visual-inertial localization  autonomous nuclear radiation source localization  aerial robot  Scintillators  Calibration  Robot sensing systems  Detectors  Unmanned aerial vehicles  Radiation detectors 
Abstract: This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.


Title: LineDrone Technology: Landing an Unmanned Aerial Vehicle on a Power Line
Key Words: aircraft landing guidance  autonomous aerial vehicles  cameras  electrical maintenance  helicopters  inspection  optical radar  power overhead lines  remotely operated vehicles  robot vision  sensor fusion  LineDrone Technology  unmanned aerial vehicle landing  semiautomatic landing  vehicle onboard vision system  monocular camera  lidar  nondestructive testing  multirotor unmanned aerial vehicle capable  power transmission lines  landing assistance  Cameras  Payloads  Unmanned aerial vehicles  Inspection  Laser radar  Task analysis  Machine vision 
Abstract: This paper presents the design of a multirotor unmanned aerial vehicle (UAV) capable of landing semiautomatically on a power line while carrying a payload. The vehicle then rolls along the line to perform an inspection. Special attention is given to the vehicle's onboard vision system, which consists of a monocular camera and LiDAR used together to compute the pose of the vehicle relative to the power line. Landing assistance is provided to the pilot by a position-based visual controller that aligns and keeps the vehicle centered along the power line. The pilot remains in control of vertical and longitudinal movement during descent. The proposed approach was tested on a full-scale test line and shows promise for future applications of high value to the electric industry such as non-destructive testing of power transmission lines.


Title: Pseudo-bearing Measurements for Improved Localization of Radio Sources with Multirotor UAVs
Key Words: autonomous aerial vehicles  directive antennas  helicopters  mobile radio  mobile robots  omnidirectional antennas  radionavigation  pseudobearing measurements  radio frequency sources  RF source  directional antenna  omnidirectional antenna  antenna theory  ground tests  multirotor UAVs  radio sources localization  bearing-like measurements  unmanned aerial vehicles  Antenna measurements  Directional antennas  Gain  Radio frequency  Extraterrestrial measurements  Rotation measurement 
Abstract: Localizing radio frequency (RF) sources is an important application for unmanned aerial vehicles (UAVs), Localization is often carried out by estimating bearing to an RF source, which can be achieved by rotating a directional antenna in place. Multirotor UAVs are well-suited for this sensing modality because they can efficiently rotate in place. However, a full rotation from a single location is needed to account for scale factors affecting the directional antenna's measurements. Although easy to perform, these rotations tend to be slow and delay localization. In this paper, we equip a multirotor UAV with a directional antenna and an omnidirectional antenna. The omnidirectional antenna serves to normalize measurements made by the directional antenna, yielding “pseudo-bearing” measurements. These bearing-like measurements are less informative than bearing measurements but do not require a full rotation, leading to more measurements and faster localization. We validate the normalization with antenna theory and ground tests. Claims of improved localization are validated with simulations and flight tests on a multirotor UAV. Our setup significantly reduces localization time compared to a multirotor UAV equipped with only a directional antenna.


Title: Onboard State Dependent LQR for Agile Quadrotors
Key Words: aircraft control  attitude control  autonomous aerial vehicles  control system synthesis  helicopters  linear quadratic control  mobile robots  state estimation  time-varying systems  trajectory control  onboard state dependent LQR  agile quadrotors  quadrotor control  multiple cascaded subproblems  rotational dynamics  translational dynamics  cascaded attitude controller  attitude dynamics  robustness  LQR controller  rotational states  translational states  time-varying system dynamics  control parameters  linearization  Vehicle dynamics  Acceleration  Trajectory  Quaternions  Attitude control  Visualization  Regulators 
Abstract: State-of-the-art approaches in quadrotor control split the problem into multiple cascaded subproblems, exploiting the different time scales of the rotational and translational dynamics. They calculate a desired acceleration as input for a cascaded attitude controller but omit the attitude dynamics. These approaches use limits on the desired acceleration to maintain feasibility and robustness through the control cascade. We propose an implementation of an LQR controller, which: (I) is linearized depending on the quadrotor's state; (II) unifies the control of rotational and translational states; (III) handles time-varying system dynamics and control parameters. Our implementation is efficient enough to compute the full linearization and solution of the LQR at a minimum of 10 Hz on the vehicle using a common ARM processor. We show four successful experiments: (I) controlling at hover state with large disturbances; (II) tracking along a trajectory; (III) tracking along an infeasible trajectory; (IV) tracking along a trajectory with disturbances. All the experiments were done using only onboard visual inertial state estimation and LQR computation. To the best of our knowledge, this is the first implementation and evaluation of a state-dependent LQR capable of onboard computation while providing this amount of versatility and performance.


Title: Autonomous Fixed-Wing Aerobatics: From Theory to Flight
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  helicopters  Matlab  microcontrollers  mobile robots  position control  autonomous fixed-wing aerobatics  unmanned aerial vehicles  conventional fixed-wing aircraft  hardware-in-the-loop simulator  Pixhawk microcontroller  Xplane physics engine  HIL simulator  flight platform  agile fixed-wing UAV  rotorcraft  orientation time histories  position time histories  Matlab-Simulink high-fidelity simulation  Aircraft  Aerodynamics  Atmospheric modeling  Control systems  Mathematical model  Aerospace control  Propellers 
Abstract: Unmanned aerial vehicles (UAVs) are increasingly being proposed for a wide range of applications. A promising new class of these vehicles, known as agile fixed-wing UAV s, is intended to bridge the gap between conventional fixed-wing aircraft, which can cover long distances efficiently, and rotorcraft, which are typically very maneuverable. This paper addresses the implementation of a controller for agile UAVs, beginning with a hardware-in-the-loop (HIL) simulator, followed by testing on a real platform, both implemented on the Pixhawk microcontroller. We replace the Xplane physics engine used in the standard Pixhawk HIL with our own in-house Matlab/Simulink high-fidelity simulation of an agile UA V. The HIL simulator is found to provide substantial advantages in the transition from pure simulation to experimental testing. Once the controller is integrated into the flight platform, flight tests are conducted, and the results of those tests are compared to those from the HIL simulation and those obtained from the pure simulation environment, for maneuvers including hover, aggressive turnaround, knife-edge, and rolling Harrier. The desired position and orientation time histories were successfully tracked with the proposed implementation, demonstrating the impressive autonomous maneuverability that can be achieved by this type of aircraft.


Title: Towards X-Ray Medical Imaging with Robots in the Open: Safety Without Compromising Performances
Key Words: collision avoidance  control engineering computing  end effectors  linear quadratic control  manipulator dynamics  medical image processing  medical robotics  mobile robots  motion control  robot vision  control solution  robotic manipulator  generic safe controller  Linear Quadratic Problem formulation  unified energetic formulation  kinetic energy  redundant Kuka LWR4+ robot  X-ray medical imaging  end-effector  Robots  Task analysis  Torque  Safety  Collision avoidance  X-ray imaging  Aerospace electronics 
Abstract: In this paper, a control solution featuring an energetic constraint is developed to improve the safety of a robotic manipulator sharing its workspace with humans. This general control structure, exploits a generic safe controller that ensures the respect of multiple constraints thanks to a Linear Quadratic Problem formulation. With a unified energetic formulation, the controller allows to explicitly limit both the kinetic energy when moving and the wrench applied to the environment in case of contact with an unexpected obstacle. This control approach is experimented on a redundant Kuka LWR4+ robot which end-effector shall precisely point toward a given location while following a trajectory.


Title: Safety-Enhanced Human-Robot Interaction Control of Redundant Robot for Teleoperated Minimally Invasive Surgery
Key Words: adaptive control  fuzzy control  human-robot interaction  manipulators  medical robotics  surgery  telerobotics  robot manipulator  human-robot interaction  teleoperated minimally invasive surgery  surgical task execution  virtual surgical tasks  compliant null space motion  tele-operated MIS tasks  implemented impedance control  safety-enhanced compliant behavior  teleoperation control  redundant robot  safety-enhanced human-robot interaction control  Task analysis  Null space  Manipulators  Human-robot interaction  Torque  Surgery 
Abstract: In this paper, a teleoperation control of a 7-DoF robot manipulator for Minimally Invasive Surgery (MIS), which guarantees a safety-enhanced compliant behavior in the null space, is described. The redundancy of the manipulator is exploited to provide a flexible workspace for nurses or other staff (assisting physicians, patient support). The issue with safety and accurate surgical task execution may arise in the presence of human-robot interaction. Based on the implemented impedance control of tele-operated MIS tasks, a safety enhanced constraint is applied on the compliant null space motion. At the same time, the control approach integrates an adaptive fuzzy compensator to guarantee the accuracy of the surgical tasks during the uncertain human-robot interaction. The performance of the proposed algorithm is verified with virtual surgical tasks. The results showed that the compliant null space motion is constrained in a safe area, and also that the accuracy of tool tip is improved, providing a flexible and safe collaborative behavior in the null space for human-robot interaction during surgical tasks.


Title: Three-Dimensional Surgical Needle Localization and Tracking Using Stereo Endoscopic Image Streams
Key Words: Bayes methods  biomedical optical imaging  endoscopes  medical image processing  medical robotics  rendering (computer graphics)  robot kinematics  3D surgical needle localization  stereoendoscopic image streams  robot kinematics  computer vision techniques  da Vinci® Surgical Robotic System  stereo endoscopic camera images  three-dimensional tracking  da Vinci ® robot endoscope  Needles  Robots  Task analysis  Surgery  Image segmentation  Bayes methods  Atmospheric measurements 
Abstract: This paper presents algorithms for three-dimensional tracking of surgical needles using the stereo endoscopic camera images obtained from the da Vinci® Surgical Robotic System. The proposed method employs Bayesian state estimation, computer vision techniques, and robot kinematics. A virtual needle rendering procedure is implemented to create simulated images of the surgical needle under the da Vinci ® robot endoscope, which makes it possible to measure the similarity between the rendered needle image and the real needle. A particle filter algorithm using the mentioned techniques is then used for tracking the surgical needle. The performance of the tracking is experimentally evaluated using an actual da Vinci® surgical robotic system and quantitatively validated in a ROS/Gazebo simulation thereof.


Title: Robotic Assistance-as-Needed for Enhanced Visuomotor Learning in Surgical Robotics Training: An Experimental Study
Key Words: learning (artificial intelligence)  medical robotics  surgery  telerobotics  visuomotor learning  complex visuomotor training  da Vinci Research Kit surgical console  surgical teleoperated robots  surgical practice  hands-on training  surgical robotics training  Task analysis  Training  Robot kinematics  Wires  Tools  Surgery 
Abstract: Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.


Title: Semi-Autonomous Laparoscopic Robotic Electro-Surgery with a Novel 3D Endoscope
Key Words: biomedical optical imaging  endoscopes  kidney  medical image processing  medical robotics  surgery  3D endoscope  robotic surgical system  cutting depth  freedom electro-surgical tool  robotic system  imaging system  laparoscopic camera  open loop control scheme  porcine cadaver kidney  robotic laparoscopic surgery system  semiautonomous laparoscopic robotic electro-surgery  Robots  Imaging  Surgery  Three-dimensional displays  Laparoscopes  Kidney  Task analysis 
Abstract: This paper reports a robotic laparoscopic surgery system performing electro-surgery on porcine cadaver kidney, and evaluates its accuracy in an open loop control scheme to conduct targeting and cutting tasks guided by a novel 3D endoscope. We describe the design and integration of the novel laparoscopic imaging system that is capable of reconstructing the surgical field using structured light. A targeting task is first performed to determine the average positioning error of the system as guided by the laparoscopic camera. The imaging system is then used to reconstruct the surface of a porcine cadaver kidney, and generate a cutting trajectory with consistent depth. The paper concludes by using the robotic system in open loop control to cut this trajectory using a multi degree of freedom electro-surgical tool. It is demonstrated that for a cutting depth of 3 mm, the robotic surgical system follows the trajectory with an average depth of 2.44 mm and standard deviation of 0.34 mm. The average positional accuracy of the system was 2.74±0.99 mm.


Title: An Ultrasonic Bone Cutting Tool for the da Vinci Research Kit
Key Words: biomedical transducers  biomedical ultrasonics  bone  finite element analysis  genetic algorithms  medical robotics  surgery  ultrasonic transducers  finite element software  cutting phantom  research kit system  ultrasonic system  multiobjective genetic algorithm  ultrasonic transducer  minimally invasive ultrasonic bone cutting tool  da Vinci research kit  Acoustics  Impedance  Finite element analysis  Transducers  Bones  Surgery  Cutting tools 
Abstract: This paper presents a minimally invasive ultrasonic bone cutting tool designed for the da Vinci® research kit (dVRK). An ultrasonic transducer is modelled using finite element software, and correlated with testing results using an impedance analyzer. A multi-objective genetic algorithm is then used to design and analyze the remaining components of the ultrasonic system, in order to maximize system performance. The system is fabricated and mounted to the da Vinci® research kit system and tested on a cutting phantom.


Title: Fast and Reliable Autonomous Surgical Debridement with Cable-Driven Robots Using a Two-Phase Calibration Procedure
Key Words: biological tissues  calibration  cameras  diseases  edge detection  end effectors  endoscopes  medical robotics  neural nets  position control  robot vision  surgery  telerobotics  fragment phantoms  cable-driven robots  diseased tissue fragments  da Vinci Research Kit  cable-driven systems  two-phase coarse-to-fine calibration method  red calibration marker  end effector  open-loop trajectories  camera pixels  internal robot end-effector configurations  robotic surgical assistants  deep neural network  end-effector position  random forest  two-phase calibration procedure  surgical debridement  fine transformation bias  residual compensation bias  coarse transformation bias  time 7.3 s to 15.8 s  size 4.55 mm  size 2.14 mm  size 1.08 mm  Calibration  Cameras  Grippers  Robot kinematics  Robot vision systems  Tools 
Abstract: Automating precision subtasks such as debridement (removing dead or diseased tissue fragments) with Robotic Surgical Assistants (RSAs) such as the da Vinci Research Kit (dVRK) is challenging due to inherent nOnlinearities in cable-driven systems. We propose and evaluate a novel two-phase coarse-to-fine calibration method. In Phase I (coarse), we place a red calibration marker on the end effector and let it randomly move through a set of open-loop trajectories to obtain a large sample set of camera pixels and internal robot end-effector configurations. This coarse data is then used to train a Deep Neural Network (DNN) to learn the coarse transformation bias. In Phase II (fine), the bias from Phase I is applied to move the end -effector toward a small set of specific target points on a printed sheet. For each target, a human operator manually adjusts the end -effector position by direct contact (not through teleoperation) and the residual compensation bias is recorded. This fine data is then used to train a Random Forest (RF) to learn the fine transformation bias. Subsequent experiments suggest that without calibration, position errors average 4.55mm. Phase I can reduce average error to 2.14mm and the combination of Phase I and Phase II can reduces average error to 1.08mm. We apply these results to debridement of raisins and pumpkin seeds as fragment phantoms. Using an endoscopic stereo camera with standard edge detection, experiments with 120 trials achieved average success rates of 94.5 %, exceeding prior results with much larger fragments (89.4%) and achieving a speedup of 2.1x, decreasing time per fragment from 15.8 seconds to 7.3 seconds. Source code, data, and videos are available at https://sites.google.com/view/calib-icra/.


Title: Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
Key Words: aircraft control  autonomous aerial vehicles  game theory  helicopters  mobile robots  multi-robot systems  optimal control  path planning  trajectory control  multiple quadrotors  flag game  distributed trajectory planning algorithm  WiFi based communication infrastructure  autopilot modules  low power computing modules  suboptimal control action  adversarial game  Gazebo robot simulator  multiple UAVs  quadrotor platform  flight testing  robot operating system  ROS  Games  Software algorithms  Software  Hardware  Real-time systems  Testing  Computational modeling 
Abstract: We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.


Title: Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View
Key Words: aerospace computing  autonomous aerial vehicles  groupware  image fusion  Kalman filters  multi-robot systems  nonlinear filters  pose estimation  robot vision  stereo image processing  monocular-inertial odometry  Extended Kalman Filter  collaborative scene estimation  monocular camera  variable-baseline stereo rig  inertial sensor  Unmanned Aerial Vehicles  collaborative robot operation  collaborative 6DoF relative pose estimation  UAV  Cameras  Simultaneous localization and mapping  Collaboration  Estimation  Unmanned aerial vehicles 
Abstract: Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.


Title: Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots
Key Words: approximation theory  computational complexity  graph theory  multi-robot systems  optimisation  path planning  O(n3) time complexity  optimal assignments  multiple robots  fixed goal formations  standard assignment problem  transformed problem  formation parameters  linear sum assignment problem  variable goal formation problem  location parameters  Collision avoidance  Robot kinematics  Trajectory  Shape  Cost function 
Abstract: This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.


Title: Machine Learning for Placement-Insensitive Inertial Motion Capture
Key Words: calibration  image motion analysis  image sensors  multilayer perceptrons  sensor positions  body segments  standard deviation  calibration values  rotation matrices  inertial motion-capture systems  latency errors  motion data  sensor-displacement patterns  multilayer perceptrons  rotational transformations  kinematic algorithms  sensor movement  performance degradation  Euler angles  placement-insensitive inertial motion capture  machine learning  joint angles  sensor data  time 3.0 hour  Tracking  Robot sensing systems  Motion segmentation  Machine learning  Calibration  Kinematics  Neural networks 
Abstract: Although existing inertial motion-capture systems work reasonably well (≤10° error in Euler angles), their accuracy suffers when sensor positions change relative to the associated body segments (±60° mean error and 120° standard deviation). We attribute this performance degradation to undermined calibration values, sensor movement latency and displacement offsets. The latter specifically leads to incongruent rotation matrices in kinematic algorithms that rely on rotational transformations. To overcome these limitations, we propose to employ machine-learning techniques. In particular, we use multi-layer perceptrons to learn sensor-displacement patterns based on 3 hours of motion data collected from 12 test subjects in the lab over 215 trials. Furthermore, to compensate for calibration and latency errors, we directly process sensor data with deep neural networks and estimate the joint angles. Based on these approaches, we demonstrate up to 69% reduction in tracking errors.


Title: Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace
Key Words: actuators  biomechanics  feedback  medical robotics  optimisation  patient rehabilitation  robot dynamics  robot kinematics  wrist robots  analytical stiffness model  bounded nonlinear multiobjective optimization  parallel architecture  wearable hip  ankle  parallel-actuated robotic shoulder exoskeleton  sagittal plane  Shoulder  Actuators  Exoskeletons  Kinematics  End effectors 
Abstract: The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.


Title: Adaptive Oscillator-Based Control for Active Lower-Limb Exoskeleton and its Metabolic Impact
Key Words: adaptive control  artificial limbs  gait analysis  handicapped aids  medical robotics  muscle  patient rehabilitation  active lower-limb exoskeleton  metabolic impact  hip abduction/adduction  hip extension/flexion  knee extension/flexion joints  walking environment  adaptive oscillator-based control  electric actuators  Foot  Legged locomotion  Exoskeletons  Hip  Torque  Knee  Oscillators 
Abstract: We developed a robotic lower-limb exoskeleton for those who have weakened muscle due to aging and experience difficulty in walking or getting up without help. The exoskeleton covering both limbs from the feet to the waist has 6 electric actuators in the hip abduction/adduction, hip extension/flexion and knee extension/flexion joints. For users with volitional motion, delivering assistance power according to their intention is a challenging task. We propose an adaptive oscillator-based controller to assist users walk in the lower-limb exoskeleton. To adapt to changes in walking speed and environment, motion command from the controller is modulated by estimate walking speed and walking environment recognized as one of the following categories: level ground, stairs up/down and slope up/down. Experimental results demonstrate the feasibility of the proposed environment recognition method and the impact of assistance on the metabolic cost of walking on level and inclined treadmills.


Title: Human-Exoskeleton System Dynamics Identification Using Affordable Sensors
Key Words: gait analysis  Kalman filters  kinematics  medical robotics  Wii Balance Board  joint kinematics  body segment inertial parameters  human locomotor apparatus  augmented regressor matrix  ground reaction force  dynamic identification pipeline  QR visual markers  extended Kalman filter  human-exoskeleton system dynamics identification  lower limb exoskeleton  Exoskeletons  Kinematics  Solid modeling  Dynamics  Three-dimensional displays  Calibration  Mathematical model 
Abstract: This paper presents a practical method to identify body segments inertial parameters of a human-exoskeleton system using affordable and easy-to-use sensors. First, the joints and the base kinematics are estimated based on the use of an extended Kalman filter and QR visual markers. Then, joints kinematics are used in a dynamic identification pipeline together with the ground reaction force and moments collected with an affordable Wii Balance Board. The identification process is done using an augmented regressor matrix to identify at once each segment mass, center of mass 3D position and inertia tensor elements of both human locomotor apparatus and exoskeleton. The proposed method is able to accurately estimate external force and moments, with less than 6 % of normalized RMS difference in average, and is experimentally validated with a subject wearing a full lower limb exoskeleton.


Title: A Locomotion Recognition System Using Depth Images
Key Words: artificial limbs  feature extraction  finite state machines  gait analysis  handicapped aids  intelligent robots  motion control  orthotics  robot vision  wearable robots  lower-limb assistive device  depth images  prostheses  daily living activities  intelligent controller  innovative locomotion recognition system  feature extraction subsystem  finite-state-machine based recognition subsystem  limb movements  locomotion modes  transition states  locomotion tasks  Powered lower-limb orthoses  wearable robot  Cameras  Task analysis  Image edge detection  Feature extraction  Legged locomotion 
Abstract: Powered lower-limb orthoses and prostheses are attracting an increasing amount of attention in assisting daily living activities. To safely and naturally collaborate with human users, the key technology relies on an intelligent controller to accurately decode users' movement intention. In this work, we proposed an innovative locomotion recognition system based on depth images. Composed of a feature extraction subsystem and a finite-state-machine based recognition subsystem, the proposed approach is capable of capturing both the limb movements and the terrains right in front of the user. This makes it possible to anticipate the detection of locomotion modes, especially at transition states, thus enabling the associated wearable robot to deliver a smooth and seamless assistance. Validation experiments were implemented with nine subjects to trace a track that comprised of standing, walking, stair ascending, and stair descending, for three rounds each. The results showed that in steady state, the proposed system could recognize all four locomotion tasks with approximate 100% of accuracy. Out of 216 mode transitions, 82.4% of the intended locomotion tasks can be detected before the transition happened. Thanks to its high accuracy and promising prediction performance, the proposed locomotion recognition system is expected to significantly improve the safety as well as the effectiveness of a lower-limb assistive device.


Title: Design of Frictional 2D-Anisotropy Surface for Wriggle Locomotion of Printable Soft-Bodied Robots
Key Words: friction  mobile robots  continuum robots  soft-bodied robots  snake robot  serpentine locomotion  wriggle soft-bodied robot  high friction material  low friction material  snake-like soft-bodied robots  frictional 2D-anisotropy surface  printable soft-bodied robots  anisotropic structure  Friction  Tendons  Anisotropic magnetoresistance  DC motors  Mobile robots  Surface morphology 
Abstract: Soft-bodied and continuum robots have shown great adaptability to the environment thanks to its flexibility of the body. They have great potential in environment exploring or rescuing mission. One of those robots is snake-like soft-bodied robots. A snake robot is often made by attaching passive wheels along a long body to achieve frictional anisotropy. This anisotropic structure helps to propel the body with serpentine locomotion and prevents it from sliding laterally. However, with a snake-like soft-bodied robot, attaching wheels is not only clumsy but also adding weight to the robot. In this paper, being inspired by the scales on the skin of a snake, we propose a designing scheme to achieve an all-printed wriggle soft-bodied robot by patterning high and low friction material to the ventral side of the robot. Compared to a totally flat ventral, we are able to speed-up the serpentine locomotion 2.8 times. Besides, by changing the configuration of high/low friction material, our wriggle soft-bodied robot can easily move forward or backward just by switching the controlling signal. The fabrication time is just less than 1 hour and the robot can achieve the speed of 26 mm/s.


Title: Inchworm Locomotion Mechanism Inspired Self-Deformable Capsule-Like Robot: Design, Modeling, and Experimental Validation
Key Words: actuators  biomechanics  biomimetics  deformation  robot dynamics  robot kinematics  crawling locomotion behavior  inchworm-like crawling movement  deformable properties  bio-inspired design  robot kinematics  experimental validation  actuated deformation capability  soft actuation mechanisms  inchworm locomotion mechanism  self-deformable capsule-like robot  rigid elements-based morphing structure  robot deformation  Robots  Force  Strain  Friction  Kinetic theory  Biological system modeling 
Abstract: Inspired by the inchworm locomotion mechanism, this paper presents our recently developed self-deformable capsule-like robot. The robot has the actuated deformation capability that relies on a novel rigid elements-based morphing structure (REMS) and its soft actuation mechanisms. When the robot deforms, it generates the crawling locomotion behavior and thus friction waves between the robot and contact surface to facilitate the inchworm-like crawling movement. The paper starts reviewing the deformable properties of natural biological entities like capsules, presents state of the art of the current capsule-like robots, and details the bio-inspired design of the self-deformable capsule-like robot by describing the model of robot kinematics and its locomotion mechanism. Both simulation and experimental results validate the excellent performance of this capsule-like robot. The developed self-deformable capsule-like robot has the advantage of crawling on varied surfaces and it also has the capabilities to crawl in a variety of narrow pipes based on the deformation elicited locomotion nature of the robot.


Title: Realtime On-Board Attitude Estimation of High-Frequency Flapping Wing MAVs Under Large Instantaneous Oscillation
Key Words: aerodynamics  aerospace components  aerospace control  autonomous aerial vehicles  sensor fusion  realtime on-board attitude estimation  high-frequency flapping wing MAVs  instantaneous oscillation  fixed wings  rotary wings  high-frequency wing flapping  aerial vehicles  Flapping Wing Micro Aerial Vehicles  FWMAVs  instantaneous oscillations  Magnetometers  Robot sensing systems  Aerodynamics  Estimation  Accelerometers  Magnetic flux  Magnetomechanical effects 
Abstract: Unlike conventional aerial vehicles of fixed or rotary wings, realtime on-board attitude estimation of insect or hummingbird scale Flapping Wing Micro Aerial Vehicles (FWMAVs) is very challenging due to the severe instantaneous oscillations (approximately ten times of gravity on our platform) induced by high-frequency wing flapping. In this work, we present a novel sensor fusion algorithm for realtime on-board attitude estimation of FWMAVs. The algorithm is proposed with adaptive model-based compensation for both sensing drift and aerodynamic forces induced by flapping wings. We validated our approach on a 12.5 grams hummingbird robot. The experimental results demonstrated the accuracy, convergence, and robustness of the proposed algorithm.


Title: FireAnt: A Modular Robot with Full-Body Continuous Docks
Key Words: mobile robots  robotic assembly  self-assembly  modular 2D robot  full-body continuous docks  docking mechanism  mechanical complexity  robotic self-assembling structures  inert fireant robots  Robot sensing systems  Plastics  Copper  Strips  Wires 
Abstract: Nature offers many examples of organisms coming together to form self-assembling structures. The attachment methods these organisms employ allow them to grab onto others' bodies, often without need for specific alignment or orientation, an ability absent from most existing robotic self-assembling structures, which require complicated sensing and specific alignment. This paper presents FireAnt, a modular 2D robot that demonstrates full-body continuous docks, an attachment mechanism able to attach anywhere onto other robots at any orientation, eliminating the need for alignment mechanisms and complex sensors. Such docks allow FireAnt to climb over copies of itself, something critical to self-assembling structures. This paper first discusses the design of FireAnt before presenting test results that show the strength and reliability of the continuous docks and demonstrate FireAnt's ability to traverse an environment consisting of inert FireAnt robots. The work presented in this paper provides a docking mechanism that can minimize the mechanical complexity of modular robots and will allow the creation of swarms of rigid and adaptable self-assembling structures.


Title: Perception-Informed Autonomous Environment Augmentation with Modular Robots
Key Words: collision avoidance  mobile robots  planning (artificial intelligence)  high-level planner  disconnected regions  hardware experiments  planning tools  robot locomotion capabilities  specially-designed building blocks  environment characterization algorithm  modular robot systems  building structures  high-level tasks  perception-informed autonomous environment augmentation  Task analysis  Hardware  Mobile robots  Bridges  Buildings  Planning 
Abstract: We present a system enabling a modular robot to autonomously build structures in order to accomplish high-level tasks. Building structures allows the robot to surmount large obstacles, expanding the set of tasks it can perform. This addresses a common weakness of modular robot systems, which often struggle to traverse large obstacles. This paper presents the hardware, perception, and planning tools that comprise our system. An environment characterization algorithm identifies features in the environment that can be augmented to create a path between two disconnected regions of the environment. Specially-designed building blocks enable the robot to create structures that can augment the environment to make obstacles traversable. A high-level planner reasons about the task, robot locomotion capabilities, and environment to decide if and where to augment the environment in order to perform the desired task. We validate our system in hardware experiments.


Title: Design and Online Calibration of a Highly Compact Microgripper
Key Words: calibration  grippers  image sensors  microassembling  micromanipulators  microsensors  position measurement  compact microgripper  microobject manipulation  flexure hinge  low impedance grasping mechanism  kinematics analysis  fine element analysis  FEA  fibrous microring assembling  visual-based calibration method  position sensors  laser sensor  embedded sensors  dexterous manipulation  Grippers  Force  Fasteners  Calibration  Robot sensing systems  Strain measurement  Prototypes 
Abstract: Microgrippers play a significant role in manipulation of micro-objects. To achieve dexterous and precise manipulation, a microgripper is required to be compactly designed and embedded with sensing feedback. Meanwhile, to convert the sensor position into displacement of the microgripper, the embedded sensors should be calibrated by additional equipment like laser sensor. However, a microgripper always needs to be calibrated during manipulation (online calibration), which is still a big challenge with current technology. In this paper, we proposed a highly compact microgripper integrated with position sensors, and a visual-based calibration method to handle such challenge. Moreover, to enhance grasping accuracy, flexure hinges are employed to achieve a low impedance grasping mechanism and to avoid the backlash in traditional bearing. Furthermore, kinematics analysis and Fine Element Analysis (FEA) are implemented to improve the design efficiency. Finally, fibrous micro-rings are successfully assembled, and the results reveal that the calibrated microgripper can be well employed to operate micro-objects.


Title: Grasping of Unknown Objects Using Deep Convolutional Neural Networks Based on Depth Images
Key Words: dexterous manipulators  end effectors  feedforward neural nets  grippers  humanoid robots  learning (artificial intelligence)  pose estimation  rendering (computer graphics)  robot vision  Deep Convolutional Neural Networks  training input  high-quality grasps  analytical grasp planners  rendered depth images  training objects  deep learning techniques  robotic grasping  approach directions  grasping setup  big data grasping database  qualitative grasping experiments  humanoid robot ARMAR-III  unknown objects  data-driven  deep learning approach  Grasping  Robots  Training  Data models  Databases  Feature extraction  Machine learning 
Abstract: We present a data-driven, bottom-up, deep learning approach to robotic grasping of unknown objects using Deep Convolutional Neural Networks (DCNNs). The approach uses depth images of the scene as its sole input for synthesis of a single-grasp solution during execution, adequately portraying the robot's visual perception during exploration of a scene. The training input consists of precomputed high-quality grasps, generated by analytical grasp planners, accompanied with rendered depth images of the training objects. In contrast to previous work on applying deep learning techniques to robotic grasping, our approach is able to handle full end-effector poses and therefore approach directions other than the view direction of the camera. Furthermore, the approach is not limited to a certain grasping setup (e. g. parallel jaw gripper) by design. We evaluate the method regarding its force-closure performance in simulation using the KIT and YCB object model datasets as well as a big data grasping database. We demonstrate the performance of our approach in qualitative grasping experiments on the humanoid robot ARMAR-III.


Title: Grasp Planning for Load Sharing in Collaborative Manipulation
Key Words: dexterous manipulators  force control  grippers  human-robot interaction  industrial manipulators  lifting  manipulators  collaborative manipulation  manipulation task  grasp location  human robot collaborative lifting task  grasp planning  grasp analysis approach  load sharing  partial observability  two-agent decentralized set-up  Task analysis  Robot kinematics  Planning  Collaboration  Force  Quadratic programming 
Abstract: In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.


Title: Human-Inspired Object Manipulation Control with the Anatomically Correct Testbed Hand
Key Words: biocontrol  biomechanics  dexterous manipulators  force control  manipulator dynamics  mechanical stability  muscle  position control  human neuromuscular system  grasp stability  human-inspired object manipulation control  anatomically correct testbed hand  dexterous manipulation  robotic hand  object-level impedance control strategies  grasp forces  robotic system  object stiffness control gains  object-space stiffness control algorithm  object size  object shape  grasp stability bounds  object-space stiffness  low-level stiffness  ACT hand  Robots  Force  Tendons  Task analysis  Muscles  Frequency modulation  Mathematical model 
Abstract: Dexterous manipulation with robotic hands can be achieved using object-level impedance control strategies, which allow intuitive regulation of object position, external environmental interactions, and grasp forces. However, for grasp stability, object stiffness gains are limited by the inherent compliance of the robotic system, object size/shape, and applied grasp forces, which can lead to restricted manipulation capabilities. In this work, we first use analytical modeling techniques to explore the theoretical passivity bounds on object stiffness control gains to ensure grasp stability. Then, an object-space stiffness control algorithm is developed for the Anatomically Correct Testbed (ACT) hand, a robotic hand designed to replicate the complex tendon and joint structure of the human hand, and grasp stability bounds are experimentally tested for various task scenarios. Finally, inspired by the hierarchical structure of the human neuromuscular system, we develop a novel control strategy that implements low-level stiffness in muscle-space, while also emulating a separately defined object-space stiffness in quasi-static conditions. Experimental results demonstrate that this control strategy increases achievable object stiffness without sacrificing grasp stability, leading to significantly increased manipulation capabilities.


Title: Improving Superquadric Modeling and Grasping with Prior on Object Shapes
Key Words: grippers  humanoid robots  pattern classification  superquadric modeling  grasping  object shape  object modeling  humanoid robots  superquadric functions  object classifier  robot hands  robotic system  iCub humanoid robot  Grasping  Shape  Computational modeling  Robots  Three-dimensional displays  Pipelines  Optimization 
Abstract: This paper proposes an object modeling and grasping pipeline for humanoid robots. This work improves our previous approach based on superquadric functions. In particular, we speed up and refine the modeling process by using prior information on the object shape provided by an object classifier. We use our previous method for the computation of grasping pose to obtain pose candidates for both the robot hands and, then, we automatically choose the best candidate for grasping the object according to a given quality index. The performance of our pipeline has been assessed on a real robotic system, the iCub humanoid robot. The robot can grasp 18 objects of the YCB and iCub World datasets considerably different in terms of shape and dimensions with a high success rate.


Title: Active Reward Learning from Critiques
Key Words: Bayes methods  control engineering computing  learning (artificial intelligence)  query processing  robot programming  critiques  active reward Learning  programming robots  active Bayesian inverse reinforcement learning  trajectory queries  labeling process  active learning  Trajectory  Robots  Learning (artificial intelligence)  Bayes methods  Entropy  Task analysis  Uncertainty 
Abstract: Learning from demonstration algorithms, such as Inverse Reinforcement Learning, aim to provide a natural mechanism for programming robots, but can often require a prohibitive number of demonstrations to capture important subtleties of a task. Rather than requesting additional demonstrations blindly, active learning methods leverage uncertainty to query the user for action labels at states with high expected information gain. However, this approach can still require a large number of labels to adequately reduce uncertainty and may also be unintuitive, as users are not accustomed to determining optimal actions in a single out-of-context state. To address these shortcomings, we propose a novel trajectory-based active Bayesian inverse reinforcement learning algorithm that (1) queries the user for critiques of automatically generated trajectories, rather than asking for demonstrations or action labels, (2) utilizes trajectory segmentation to expedite the critique / labeling process, and (3) predicts the user's critiques to generate the most highly informative trajectory queries. We evaluated our algorithm in simulated domains, finding it to compare favorably to prior work and a randomized baseline.


Title: Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling
Key Words: estimation theory  learning (artificial intelligence)  learning systems  measurement uncertainty  mobile robots  Monte Carlo methods  sampling methods  uncertainty handling  uncertainty estimation method utilizing  Monte Carlo sampling  robotics applications  autonomous driving  epistemic uncertainties  aleatoric uncertainties  uncertainty acquisition  demonstration method  sampling-free variance modeling  mixture density network  uncertainty-aware learning  Uncertainty  Predictive models  Noise measurement  Data models  Training  Estimation  Measurement uncertainty 
Abstract: In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. Then, we show that it can be decomposed into explained variance and unexplained variance where the connections between aleatoric and epistemic uncertainties are addressed. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learning from demonstration method for autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset.


Title: Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration
Key Words: feature extraction  learning (artificial intelligence)  pattern classification  robots  LfD scenarios  human feature selection  robot learner  informative features  multiclass classification task  computational feature selection  human selected features  informative task features  general-purpose robot  learning computation  robotic agent learning classification tasks  human-driven feature selection  Task analysis  Feature extraction  Robots  Training  Training data  Object recognition  Support vector machines 
Abstract: The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.


Title: Object-Centric Approach to Prediction and Labeling of Manipulation Tasks
Key Words: cameras  graph theory  mobile robots  object recognition  robot vision  object-centric approach  manipulation tasks  human manipulation actions  object trajectories  context specific human vocabulary  directed action graph representation  pre-computed Location Areas  offline teaching phase  graph generation  online action recognition phase  high-level reasoning  sensor observation  visual sensory input  depth camera  LA  sector-maps  SM  Service robots  Hidden Markov models  Vocabulary  Feature extraction  Knowledge based systems  Task analysis  Action Recognition  Motion analysis  Graph method  Location Area  Sector-Map  Knowledge representation 
Abstract: We propose an object-centric framework to label and predict human manipulation actions from observations of the object trajectories in 3D space. The goal is to lift the low-level sensor observation to a context specific human vocabulary. The low-level visual sensory input from a depth camera is processed into high-level descriptive action labels using a directed action graph representation. It is built based on the concepts of pre-computed Location Areas (LA), regions within a scene where an action typically occur, and Sector-Maps (SM), reference trajectories between the LAs. The framework consists of two stages, an offline teaching phase for graph generation, and an online action recognition phase that maps the current observations to the generated graph. This graph representation allows the framework to predict the most probable action from the observed motion in real-time and to adapt its structure whenever a new LA appears. Furthermore, the descriptive action labels enable not only a better exchange of information between a human and a robot but they allow also the robots to perform high-level reasoning. We present experimental results on real human manipulation actions using a system designed with this framework to show the performance of prediction and labeling that can be achieved.


Title: Deep Auxiliary Learning for Visual Localization and Odometry
Key Words: distance measurement  feature extraction  learning (artificial intelligence)  neural nets  pose estimation  video signal processing  state-of-the-art SIFT-based approaches  deep learning technique  multitask learning  Geometric Consistency Loss  visual odometry estimation  global localization  parameter sharing  multitask model  consecutive monocular images  VLocNet  convolutional neural networks  action execution  robot  visual localization  Task analysis  Visual odometry  Estimation  Visualization  Training  Robustness 
Abstract: Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.


Title: An Experimental Investigation of Extra Measurements for Solving the Direct Kinematics of Cable-Driven Parallel Robots
Key Words: manipulator kinematics  position control  CDPR  extra measurements  extra sensors  cable orientations  direct kinematics  cable-driven parallel robots  cable length measurements  model-based approach  cable tension sensors  Measurement uncertainty  Mathematical model  Robot sensing systems  Kinematics  Instruments 
Abstract: Solving the direct kinematics (DK) of cable-driven parallel robots (CDPR) based only on the cable length measurements is a demanding problem that is still not well mastered, especially for robots having sagging cables. A model-based approach may be used to solve this problem but the model parameters and measurements are uncertain, thereby leading to positioning inaccuracy. A possible way to improve the accuracy and speed up the solving is to add extra measurements. For that purpose a preliminary step is to determine what type of measurements are possible and then to estimate how accurate they are. For that purpose we have used a CDPR with 4 cables that has been instrumented with various types of extra measurements: cable tensions and orientations, platform orientation. Ground truth has been established and we have compared the data provided by the extra sensors with their real values. This work shows that cable tensions sensors and platform orientation sensors are not good candidates to be used for the DK while cable orientations may be obtained with a good accuracy both in static poses or during a quasi-static motion.


Title: Reconfiguration Analysis and Motion Planning of a Novel Reconfigurable Mobile Manipulator Torso
Key Words: bars  flexible manipulators  manipulator dynamics  manipulator kinematics  mobile robots  motion control  path planning  position control  reconfiguration analysis  mutual mode transition rules  kinematics model  motion planning  reconfiguration rules  ReConBot  flexible torso  straight bar-shape base  metamorphic kinematic chains  configuration states  reconfigurable mobile manipulator torso  2RER reconfigurable parallel mechanism  transition handling  singularity position  Kinematics  Torso  Mathematical model  Robot kinematics  Planning  Manipulators 
Abstract: A novel 2-RER reconfigurable parallel mechanism (ReConBot) considered as the flexible torso of the mobile manipulator is proposed. This paper deals with the analysis of reconfiguration, kinematics, and motion planning. The ReConBot is composed of straight bar-shape base and moving platforms and two metamorphic kinematic chains (MKC) consisted of a revolute (R) joint, a planar (E) joint, and an R joint in sequence. Firstly, mobility and reconfiguration analysis discuss the conditions and mutual mode transition rules of 12 possible configuration states. And then, the kinematics model covers all states with Cartesian coordinate and axis/angle representations. What's more, the motion planning following the rules of the mode transition is explained and illustrated together with a case study. Furthermore, the method of handling the transition at singularity position is discussed. Finally, the robotic system and its experiments verify the correctness of the theoretical analysis and the validation of reconfiguration rules.


Title: Efficient Event-Driven Forward Kinematics of Open Kinematic Chains with O(Log n) Complexity
Key Words: computational complexity  manipulator kinematics  matrix algebra  open kinematic chains  event-driven forward kinematics algorithms  computational resources  root joint  conventional forward kinematics  computation time  event-driven FK algorithms  sensory data  homogeneous transformation matrix  time-variance  algebraic structures  Kinematics  Robot sensing systems  Heuristic algorithms  Robot kinematics  Complexity theory  Real-time systems 
Abstract: This paper presents novel event-driven forward kinematics algorithms for open kinematic chains with O(log n) complexity. This event-driven algorithm can efficiently update forward kinematics only when new sensory data comes. This will also contribute to localization of computational resources at sensitive joints to the position of the endpoint (e.g. a fingertip), like a root joint. We constructed 3 event-driven FK algorithms. We proved that the algorithms have the complexity of O(logn) for updating 1 joint angle, and O(logn) for obtaining a homogeneous transformation matrix between links. We compared the 3 algorithms with a conventional forward kinematics algorithm in the viewpoint of complexity, computation time, time-variance and algebraic structures. The results showed that the computation time is well adequate for real-time computation. Computation time is less than 2 us per 1 query, for 40,000 kinematic chains.


Title: Reactive Magnetic-Field-Inspired Navigation for Non-Holonomic Mobile Robots in Unknown Environments
Key Words: mobile robots  navigation  path planning  TurtleBot mobile robot platform  local sensory information  arbitrary-shaped convex environment  magnetic fields  nonholonomic mobile robot taking inspiration  reactive robot navigation method  unknown environments  nonholonomic mobile robots  reactive magnetic-field-inspired navigation  Robot sensing systems  Collision avoidance  Navigation  Mobile robots  Force  Wires 
Abstract: In this paper, we present a reactive robot navigation method for a non-holonomic mobile robot taking inspiration from the phenomena observed in magnetic fields. The algorithm is shown to be able to guide mobile robots in arbitrary-shaped convex environment without being trapped in local minima by exploiting the local sensory information without priori knowledge about the environment. A preliminary validation study involving simulation of and experiments with a TurtleBot mobile robot platform show the advantage of the proposed method over existing ones.


Title: Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
Key Words: aerospace control  autonomous aerial vehicles  closed loop systems  mobile robots  optimisation  position control  propellers  closed-loop aerial transformation  aerial grasping  shape adaptive transformation  aerial manipulation  HALO  horizontal plane transformable aerial robot  closed-loop multilinks structure  flight control  serial-link structure  propeller  optimization planning method  Unmanned aerial vehicles  Propellers  Shape  Grasping  Servomotors  Force  End effectors 
Abstract: In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.


Title: Towards a Flying Assistant Paradigm: the OTHex
Key Words: autonomous aerial vehicles  control system synthesis  estimation theory  geometry  manipulators  mobile robots  robust control  trajectory control  maintenance tasks  task-driven custom design  experimental validations  control framework  low-level geometric controller  external wrench estimator  admittance filter  trajectory generator  external force disturbances  Flying Assistant paradigm  OTHex platform  aerial manipulation  LAAS-CNRS  multidirectional thrust platform  human operators  long bars  assembly tasks  ground manipulators  Propellers  Bars  Trajectory  Robots  Task analysis  Admittance  Force 
Abstract: This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.


Title: LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation
Key Words: decentralised control  hydraulic actuators  machine control  rotors  valves  robotic system  LASDRA  valve turning  trajectory tracking  strong/sturdy base actuator/structure  actuators  hydraulic actuation  large-size aerial skeleton system  large-size dexterously-articulated robot  internal actuation  external actuation  distributed rotors  distributed rotor actuation  Rotors  Robots  Force  Loading  Torque  Hydraulic systems  Actuators 
Abstract: Electrical motor and hydraulic actuation widely-used in robotics are “internal actuation” with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as “external actuation”, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.


Title: A Flying Gripper Based on Cuboid Modular Robots
Key Words: autonomous aerial vehicles  grippers  helicopters  mobile robots  multi-robot systems  position control  degree of freedom  four-bar linkage  aperture angle  cuboid frame  docking mechanism  vertical edges  grasp object  cuboid modular robots  flying Gripper  hovering performance  DOF  Grippers  Apertures  Robots  Rotors  Grasping  Propellers  Shape 
Abstract: We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.


Title: ACT: An Autonomous Drone Cinematography System for Action Scenes
Key Words: cinematography  motion estimation  remotely operated vehicles  video cameras  action scenes  aerial filming  autonomous cinematography system  autonomous drone cinematography system  state-of-the-art drone camera system  real-time dynamical camera planning strategy  drone platform  human action  external motion capture systems  drone cinematography systems  aesthetic objectives  Cameras  Drones  Three-dimensional displays  Skeleton  Planning  Robot vision systems  Trajectory 
Abstract: Drones are enabling new forms of cinematography. Aerial filming via drones in action scenes is difficult because it requires users to understand the dynamic scenarios and operate the drone and camera simultaneously. Existing systems allow the user to manually specify the shots and guide the drone to capture footage, while none of them employ aesthetic objectives to automate aerial filming in action scenes. Meanwhile, these drone cinematography systems depend on the external motion capture systems to perceive the human action, which is limited to the indoor environment. In this paper, we propose an Autonomous CinemaTography system “ACT” on the drone platform to address the above the challenges. To our knowledge, this is the first drone camera system which can autonomously capture cinematic shots of action scenes based on limb movements in both indoor and outdoor environments. Our system includes the following novelties. First, we propose an efficient method to extract 3D skeleton points via a stereo camera. Second, we design a real-time dynamical camera planning strategy that fulfills the aesthetic objectives for filming and respects the physical limits of a drone. At the system level, we integrate cameras and GPUs into the limited space of a drone and demonstrate the feasibility of running the entire cinematography system onboard in real-time. Experimental results in both simulation and real-world scenarios demonstrate that our cinematography system “ACT” can capture more expressive video footage of human action than that of a state-of-the-art drone camera system.


Title: Approximate Branch and Bound for Fast, Risk-Bound Stochastic Path Planning
Key Words: integer programming  linear programming  mobile robots  path planning  stochastic processes  tree searching  risk-bound stochastic path planning  often intractable problem  autonomous agents  complex stochastic processes  fast path planning  chance constraint  stochastic path planning problem  nonconvex problem  scales computational effort  MILP approach  parallelized sampling-based approach  Computational modeling  Stochastic processes  Trajectory  Uncertainty  Planning  Aerospace electronics 
Abstract: Path planning under uncertainty is a difficult and often intractable problem. Autonomous agents must model and reason about complex stochastic processes to quickly derive high quality plans. Most approaches separate the model of uncertainty from the planning; a model is selected and then a controller derived. This work proposes an approach for fast path planning under uncertainty that scales the model of uncertainty such that good policies receive the most effort. To do this, we use an innovative form of the problem's chance constraint to formulate a convex, stochastic path planning problem from the non-convex problem. Next, a bound on the path's expected cost is developed that allows a trade-off between speed of computation and accuracy. The bound is trivially parallelized on a GPU. Finally, a modified branch and bound algorithm is introduced that scales computational effort for more promising solutions. The method is benchmarked against existing approaches including those using Boole's inequality, a MILP approach, and a parallelized sampling-based approach. It outperforms other approaches based on speed and the ability to meet the chance constraint while not being overly conservative.


Title: Rapidly-Exploring Random Vines (RRV) for Motion Planning in Configuration Spaces with Narrow Passages
Key Words: collision avoidance  eigenvalues and eigenfunctions  mobile robots  random processes  sampling methods  trees (mathematics)  configuration space  tree expansion  eigenvectors  classical RRT algorithm  rapidly-exploring random vines algorithm  motion planning problem  narrow passage  Space exploration  Planning  Terminology  Principal component analysis  Probabilistic logic  Robots  Collision avoidance 
Abstract: Classical RRT algorithm is blind to efficiently explore configuration space for expanding the tree through a narrow passage when solving a motion planning (MP) problem. Although there have been several attempts to deal with narrow passages which are based on a wide spectrum of assumptions and configuration setups, we solve this problem in rather general way. We use dominant eigenvectors of the configuration sets formed by properly sampling the space around the nearest node, to efficiently expand the tree around the obstacles and through narrow passages. Unlike classical RRT, our algorithm is aware of having the tree nodes in front of a narrow passage and in a narrow passage, which enables a proper tree expansion in a vine-like manner. A thorough comparison with RRT, RRT-connect, and DDRRT algorithm is provided by solving three different difficult MP problems. The results suggest a significant superiority the proposed Rapidly-exploring Random Vines (RRV) algorithm might have in configuration spaces with narrow passages.


Title: Dancing PRM*: Simultaneous Planning of Sampling and Optimization with Configuration Free Space Approximation
Key Words: approximation theory  optimisation  path planning  grid-based approaches  optimization-based planner  resolution-complete factors  spatial information  empirical information  learned information  optimization-based local planner  asymptotic optimal planners  simultaneous planning  configuration free space approximation  optimal motion planning  sampling-based planner  Dancing PRM  Planning  Approximation algorithms  Trajectory  Optimization  Robots  Probabilistic logic  Linear programming 
Abstract: A recent trend in optimal motion planning has broadened the research area toward the hybridization of sampling, optimization and grid-based approaches. We can expect that synergy from such integrations leads to overall performance improvement, but seamless integration and generalization is still an open problem. In this paper, we suggest a hybrid motion planning algorithm utilizing a sampling-based and optimization-based planner while simultaneously approximating a configuration free space. Unlike conventional optimization-based approaches, the proposed algorithm does not depend on a priori information or resolution-complete factors, e.g., a distance field. Ours instead learns spatial information on the fly by exploiting empirical information during the execution, and decentralizes the information over the constructed graph for efficient access. With the help of the learned information, our optimization-based local planner exploits the local area to identify the connectivity of configuration free space without depending on the precomputed domain knowledge. To show the novelty of proposed algorithm, we evaluate it against other asymptotic optimal planners in both synthetic and complex benchmarks with varying degrees of freedom. We also discuss the performance improvement, properties and limitations we have observed.


Title: Randomized Kinodynamic Planning for Constrained Systems
Key Words: collision avoidance  large-scale systems  manipulators  mobile robots  random processes  robot dynamics  robot kinematics  state-space methods  trajectory control  trees (mathematics)  kinodynamic RRT planner  atlas  state-space manifold  randomized kinodynamic planner  holonomic constraints  constrained systems  high-dimensional dynamical systems  parallel manipulators  complex systems  trajectories  robots  Mathematical model  Robot kinematics  Planning  Trajectory  Manifolds  Standards 
Abstract: Kinodynamic RRT planners are considered to be general tools for effectively finding feasible trajectories for high-dimensional dynamical systems. However, they struggle when holonomic constraints are present in the system, such as those arising in parallel manipulators, in robots that cooperate to fulfill a given task, or in situations involving contacts with the environment. In such cases, the state space becomes an implicitly-defined manifold, which makes the diffusion heuristic inefficient and leads to inaccurate dynamical simulations. To address these issues, this paper presents an extension of the kinodynamic RRT planner that constructs an atlas of the state-space manifold incrementally, and uses this atlas both to generate random states and to dynamically steer the system towards such states. To the best of our knowledge, this is the first randomized kinodynamic planner that explicitly takes holonomic constraints into account. We validate the approach in significantly-complex systems.


Title: Learning Sampling Distributions for Robot Motion Planning
Key Words: collision avoidance  mobile robots  sampling methods  robot motion planning  sampling-based motion planning  collision-avoidance  variational autoencoder  bias sampling  Planning  Robots  Probabilistic logic  Manifolds  Collision avoidance  Feature extraction  Acceleration 
Abstract: A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to “small” regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for nonuniform sampling, whereby a sampling distribution is learned from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost.


Title: Deep Object-Centric Representations for Generalizable Robot Learning
Key Words: intelligent robots  learning (artificial intelligence)  manipulators  visual perception  robotic manipulation  generalizable robot learning  object-centric representations  reinforcement learning  object-level attentional mechanism  perception system  semantic feature space  Task analysis  Visualization  Semantics  Trajectory  Computer vision  Standards 
Abstract: Robotic manipulation in complex open-world scenarios requires both reliable physical manipulation skills and effective and generalizable perception. In this paper, we propose using an object-centric prior and a semantic feature space for the perception system of a learned policy. We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy. A task-independent attention locates possible objects in the scene, and a task-specific attention identifies which objects are predictive of the trajectories. The scope of the task-specific attention is easily adjusted by showing demonstrations with distractor objects or with diverse relevant objects. Our results indicate that this approach exhibits good generalization across object instances using very few samples, and can be used to learn a variety of manipulation tasks using reinforcement learning.


Title: Real-time 3D Glint Detection in Remote Eye Tracking Based on Bayesian Inference
Key Words: Bayes methods  gaze tracking  human-robot interaction  object detection  stereo image processing  remote eye tracking  Bayesian inference  human gaze  cognitive states  gaze-based interaction  human-robot collaboration  gaze estimation  3D glint detection  Cameras  Gaze tracking  Feature extraction  Three-dimensional displays  Probabilistic logic  Solid modeling  Calibration 
Abstract: As human gaze provides information on our cognitive states, actions, and intentions, gaze-based interaction has the potential to enable a fluent and natural human-robot collaboration. In this work, we focus on reliable gaze estimation in remote eye tracking based on calibration-free methods. Although these methods work well in controlled settings, they fail when illumination conditions change or other objects induce noise. We propose a novel, adaptive method based on a probabilistic model, which reliably detects glints from stereo images and evaluate our method using a data set that contains different challenges with regarding to light and reflections.


Title: Generative One-Shot Learning (GOL): A Semi-Parametric Approach to One-Shot Learning in Autonomous Vision
Key Words: computer vision  learning (artificial intelligence)  mobile robots  neural nets  object recognition  Pareto optimisation  GOL  input single one-shot objects  environment perception  autonomous vision  semiparametric approach  deep neural networks  visual perception  driving environment  training perceptions systems  generative framework  highly autonomous driving systems  generative one-shot learning  HAD systems  Pareto optimal solutions  object detection algorithms  Pareto optimization  Training  Autonomous vehicles  Generators  Linear programming  Probability density function 
Abstract: Highly Autonomous Driving (HAD) systems rely on deep neural networks for the visual perception of the driving environment. Such networks are train on large manually annotated databases. In this work, a semi-parametric approach to one-shot learning is proposed, with the aim of bypassing the manual annotation step required for training perceptions systems used in autonomous driving. The proposed generative framework, coined Generative One-Shot Learning (GOL), takes as input single one-shot objects, or generic patterns, and a small set of so-called regularization samples used to drive the generative process. New synthetic data is generated as Pareto optimal solutions from one-shot objects using a set of generalization functions built into a generalization generator. GOL has been evaluated on environment perception challenges encountered in autonomous vision.


Title: Adaptive Deep Learning Through Visual Domain Localization
Key Words: generalisation (artificial intelligence)  humanoid robots  human-robot interaction  image classification  learning (artificial intelligence)  robot vision  robot vision  domain shift  end-to-end deep domain adaptation architecture  target domain  training time  human-robot interactions  adaptive deep  visual domain localization  commercial robot  illumination conditions  domain adaptation methods  robotics applications  computer vision  generalization issue  iCub World database  Visualization  Training  Adaptive systems  Adaptation models  Machine learning  Service robots 
Abstract: A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.


Title: Towards Understanding Object-Directed Actions: A Generative Model for Grounding Syntactic Categories of Speech Through Visual Perception
Key Words: Bayes methods  cognition  hidden Markov models  human-robot interaction  image segmentation  learning (artificial intelligence)  manipulators  object detection  robot vision  object-directed actions  human arm joints  manipulating objects  segmented objects  successful human-robot collaboration  high-level cognitive functions  human language  human actions  Hidden Markov models  Grounding  Tagging  Three-dimensional displays  Robots  Computational modeling  Probabilistic logic 
Abstract: Creating successful human-robot collaboration requires robots to have high-level cognitive functions that could allow them to understand human language and actions in space. To meet this target, an elusive challenge that we address in this paper is to understand object-directed actions through grounding language based on visual cues representing the dynamics of human actions on objects, object characteristics (color and geometry), and spatial relationships between objects in a tabletop scene. The proposed probabilistic framework investigates unsupervised Part-of-Speech (POS) tagging to determine syntactic categories of words so as to infer grammatical structure of language. The dynamics of object-directed actions are characterized through the locations of the human arm joints - modeled on a Hidden Markov Model (HMM) - while manipulating objects, in addition to those of objects represented in 3D point clouds. These corresponding point clouds to segmented objects encode geometric features and spatial semantics of referents and landmarks in the environment. The proposed Bayesian learning model is successfully evaluated through interaction experiments between a human user and Toyota HSR robot in space.


Title: Enhancing Underwater Imagery Using Generative Adversarial Networks
Key Words: autonomous underwater vehicles  decision making  image colour analysis  image denoising  image fusion  image restoration  neural nets  robot vision  Generative Adversarial Networks  autonomous underwater vehicles  AUVs  intelligent decision making  color distortion  noisy images  distorted images  underwater image restoration  underwater imagery  visual data quality  visual underwater scene quality  Nonlinear distortion  Gallium nitride  Generators  Image color analysis  Visualization  Sensors 
Abstract: Autonomous underwater vehicles (AUVs) rely on a variety of sensors - acoustic, inertial and visual - for intelligent decision making. Due to its non-intrusive, passive nature and high information content, vision is an attractive sensing modality, particularly at shallower depths. However, factors such as light refraction and absorption, suspended particles in the water, and color distortion affect the quality of visual data, resulting in noisy and distorted images. AUVs that rely on visual sensing thus face difficult challenges and consequently exhibit poor performance on vision-driven tasks. This paper proposes a method to improve the quality of visual underwater scenes using Generative Adversarial Networks (GANs), with the goal of improving input to vision-driven behaviors further down the autonomy pipeline. Furthermore, we show how recently proposed methods are able to generate a dataset for the purpose of such underwater image restoration. For any visually-guided underwater robots, this improvement can result in increased safety and reliability through robust visual perception. To that effect, we present quantitative and qualitative data which demonstrates that images corrected through the proposed approach generate more visually appealing images, and also provide increased accuracy for a diver tracking algorithm.


Title: Faster R-CNN with Classifier Fusion for Small Fruit Detection
Key Words: convolution  crops  feedforward neural nets  image classification  image fusion  object detection  probability  recurrent neural nets  robot vision  multiple classifiers  classifier correlation  small fruit detection  Faster R-CNN network  multiple classifier fusion  objectness classification  probabilities  agricultural robots  Proposals  Correlation  Feature extraction  Image segmentation  Machine learning  Robots  Adaptation models 
Abstract: The-state-of-the-art of fruit detection with Faster R-CNN shows lack of detection advantage on small fruits. One of reasons is only single level features is used for localization of proposal candidates. In this paper, we propose to incorporate a multiple classifier fusion strategy into a Faster R-CNN network for small fruit detection. We utilize features from three different levels to learn three classifiers for objectness classification in the stage of proposal localization. Probabilities from classifiers are combined by a simple convolutional layer to generate final objectness classification for proposal candidates. In order to keep diversity of multiple classifiers, a novel loss term of classifier correlation is introduced into original loss function. Experimental results show that our model is feasible for detecting small fruits.


Title: Robot Button Pressing in Human Environments
Key Words: calibration  mobile robots  service robots  robot button pressing  human environments  service robots  mobile robot  SwitchIt  hand-held tablet  buttons categorization  Force  Robot sensing systems  Switches  Reliability  Pressing  Service robots 
Abstract: In order to conduct many desirable functions, service robots will need to actuate buttons and switches that are designed for humans. This paper presents the design of a robot named SwitchIt that is small, relatively inexpensive, easily mounted on a mobile robot, and actuates buttons reliably. Its operating characteristics were developed after conducting a systematic study of buttons and switches in human environments. From this study, we develop a categorization of buttons based on a set of physical properties relevant for robots to operate them. After a human calibrates and annotates buttons in the robot's environment using a hand-held tablet, the system automatically recognizes, pushes, and detects the state of a variety of buttons. Empirical tests demonstrate that the system succeeds in operating 95.7% of 234 total buttons/switches in an office building and a household environment.


Title: Enhancing Overall Object Placement by Understanding Uncertain Spatial and Qualitative Distance Information in User Commands
Key Words: human-robot interaction  speech-based user interfaces  uncertain spatial terms  uncertain qualitative terms  placement location  object placement  qualitative distance information  voice commands  peer companions  daily assistive tasks  assistive robot companions  voice instructions  Task analysis  Navigation  Visualization  Robot kinematics  Service robots  Manipulators  human-robot interactions  human friendly robotics  service robotics  object manipulation  spatial infor-mation 
Abstract: Humans prefer to use voice commands to guide their peer companions in daily assistive tasks. In human perspective, they expect same behavior from assistive robot companions as well. The paper presents an approach towards using such voice instructions based on uncertain and qualitative information to describe object placements. Consider a case in which a set of objects has to be arranged on a table in a particular spatial area. In such a situation, humans will prefer to use a single command regarding overall arrangement rather than repeating the same command for each and every object placement. In such scenarios, people will be comfortable with commands which are simple and with non-technical words. Most of such commands include uncertain spatial terms such as “Left”, “Middle”, “Right” and uncertain qualitative terms such as “Together”, “Little separately”, “Separately” to describe the arrangement. For example “Keep all objects together in the middle of the table” and “Keep objects separately on the right side of the table” can be considered. But in some situations, these commands will not give a direct idea about the placement location of the objects. For instance, “Keep the middle of the table free” can be cited. Therefore, the robot must be able to understand precisely such information in commands before executing them. The experiments are conducted in a simulated domestic environment. Results of the experiment are presented and discussed.


Title: Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots
Key Words: Bayes methods  collision avoidance  human-robot interaction  learning (artificial intelligence)  mobile robots  object detection  predictive control  robot vision  robust control  service robots  trajectory control  variational techniques  RoboCup@Home 2017 Social Standard Platform League  robust functions  home service robots  service-oriented robots  human assistance  commercial service robot  RGB-D camera  deep learning methods  variational Bayesian techniques  deep learning modules  dynamic home environment  deep Bayesian trajectory prediction method  collision avoidance  robust human following  smooth person following capability  human cooperation  robustness  target detection  robot following ability  Robot kinematics  Trajectory  Collision avoidance  Robustness  Robot sensing systems  Bayes methods 
Abstract: The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.


Title: Ruling the Control Authority of a Service Robot Based on Information Precision
Key Words: geriatrics  handicapped aids  mobile robots  path planning  position control  service robots  SLAM (robots)  active sensing system  control law  senior user guidance  path following problem  landmarks  actuator control  accurate localisation  exact localisation  robotic walking assistant  information precision  service robot  control authority  design strategy  massive data collection  SLAM approaches  Robot sensing systems  Estimation error  Uncertainty  Probabilistic logic  Service robots  Automobiles 
Abstract: We consider the problem of guiding a senior user along a path using a robotic walking assistant. This is a particular type of path following problem, for which most of the solutions available in the literature require an exact localisation of the robot in the environment. An accurate localisation is obtained either with a heavy infrastructure (e.g., an active sensing system deployed in the environment or deploying landmarks in known positions) or using SLAM approaches with a massive data collection. Our key observation is that the intervention of the system (and a good level of accuracy) is only required in proximity of difficult decision points, while we can rely on the user in an environment where the only possibility is just to maintain a course (e.g., a corridor). The direct implication is that we can instrument the environment with a heavy infrastructure only in certain areas. This design strategy has to be complemented by an adequate control law that shifts the authority (i.e., the control of the actuators) between the robot and the user according to the accuracy of the information available to the robot. Such a control law is exactly the contribution of this paper.


Title: A Nonparametric Motion Flow Model for Human Robot Cooperation
Key Words: Gaussian processes  human-robot interaction  image motion analysis  image representation  image sequences  learning (artificial intelligence)  optimisation  nonparametric motion flow model  human robot cooperation method  partial trajectory information  target trajectories  learned motion description  underlying reward function  interacting trajectories  variance functions  temporal properties  spatial properties  motion flow similarity measure  motion trajectory  Trajectory  Motion measurement  Kernel  Computational modeling  Robot sensing systems  Task analysis 
Abstract: In this paper, we present a novel nonparametric motion flow model that effectively describes a motion trajectory of a human and its application to human robot cooperation. To this end, motion flow similarity measure which considers both spatial and temporal properties of a trajectory is proposed by utilizing the mean and variance functions of a Gaussian process. We also present a human robot cooperation method using the proposed motion flow model. Given a set of interacting trajectories of two workers, the underlying reward function of cooperating behaviors is optimized by using the learned motion description as an input to the reward function where a stochastic trajectory optimization method is used to control a robot. The presented human robot cooperation method is compared with the state-of-the-art algorithm, which utilizes a mixture of interaction primitives (MIP), in terms of the RMS error between generated and target trajectories. While the proposed method shows comparable performance with the MIP when the full observation of human demonstrations is given, it shows superior performance when partial trajectory information is given.


Title: Learning by Demonstration and Adaptation of Finishing Operations Using Virtual Mechanism Approach
Key Words: force sensors  grinding  grinding machines  industrial robots  iterative learning control  polishing  polishing machines  robot dynamics  robot kinematics  surface finishing  finishing operations  virtual mechanism approach  passive digitizer  optimal robot execution  serial kinematic chain  augmented system  polishing tools  grinding tool  iterative learning controller  Robot kinematics  Task analysis  Tools  Service robots  Trajectory  Quaternions 
Abstract: In this paper we propose a new approach for efficient programming of grinding and polishing operation. In the proposed system, the initial policy is performed by a skilled operator and recorded with a passive digitizer. The demonstrated policy comprises both position and force data. The optimal robot execution of the task is provided by applying a virtual mechanism approach, which models the polishing/grinding tool as a serial kinematic chain. By joining the robot and the virtual mechanism in an augmented system, additional degrees of freedom are obtained and redundancy resolution can be applied to optimize the demonstrated motion. Another benefit of the proposed approach is that the same policy can be transferred to different combination of robots and grinding/polishing tools without any modification of the captured motion. The proposed approach requires known contact point between the treated object and the polishing/grinding tool. We propose a novel approach for accurate estimation of this point using data obtained from the force-torque sensor. Finally, the demonstrated path is refined to compensate for inaccurate calibration and different dynamics of a robot and the human demonstrator using iterative learning controller. The proposed method was verified in a real industrial environment.


Title: Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration
Key Words: humanoid robots  learning systems  manipulator kinematics  probability  trajectory control  joint space  motion constraints  probabilistic formulation  dynamic movement primitives  probabilistic treatment  trajectory constraints  hybrid space learning  motion smoothness  robot null-space  hybrid probabilistic trajectory optimization  null-space exploration  Cartesian space  learning from demonstration  Jacobian-based inverse kinematics  Probabilistic logic  Task analysis  Robot kinematics  Acceleration  Trajectory optimization 
Abstract: In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.


Title: Feature-constrained Active Visual SLAM for Mobile Robot Navigation
Key Words: collision avoidance  mobile robots  navigation  path planning  robot vision  SLAM (robots)  sensory constraints  iterative motion planning framework  collision avoidance  online mapping  associated map points  distance-optimal path planner  data-driven approach  continuous identification  feature-based Visual Simultaneous Localization  vision-based navigation  failure avoidance  mobile robot navigation  feature-constrained active Visual SLAM  Cameras  Navigation  Collision avoidance  Simultaneous localization and mapping  Planning 
Abstract: This paper focuses on tracking failure avoidance during vision-based navigation to a desired goal in unknown environments. While using feature-based Visual Simultaneous Localization and Mapping (VSLAM), continuous identification and association of map points are required during motion. Thus, we discuss a motion planning framework that takes into account sensory constraints for a reliable navigation. We use information available in the SLAM and propose a data-driven approach to predict the number of map points associated in a given pose. Then, a distance-optimal path planner utilizes the model to constrain paths such that the number of associated map points in each pose is above a threshold. We also include an online mapping of the environment for collision avoidance. Overall, we propose an iterative motion planning framework that enables real-time replanning after the acquisition of more information. Experiments in two environments demonstrate the performance of the proposed framework.


Title: Level-Headed: Evaluating Gimbal-Stabilised Visual Teach and Repeat for Improved Localisation Performance
Key Words: feature extraction  mobile robots  path planning  robot vision  rough terrain  unstructured terrain  border patrol  agricultural work  sensor-based navigation  erratic motion  feature-poor environments test feature tracking  repeat matching  salient point features  Grizzly Robotic Utility Vehicle  actively gimbaled camera  image motion  search-and-rescue  field-deployable ground robot  vision-based route-following  feature extraction  Transforms  Cameras  Visualization  Robot sensing systems  Robustness  Navigation 
Abstract: Operating in rough, unstructured terrain is an essential requirement for any truly field-deployable ground robot. Search-and-rescue, border patrol and agricultural work all require operation in environments with little established infrastructure for easy navigation. This presents challenges for sensor-based navigation such as vision, where erratic motion and feature-poor environments test feature tracking and hinder the performance of repeat matching of point features. For vision-based route-following methods such as Visual Teach and Repeat (VT&R), maintaining similar visual perspective of salient point features is critical for reliable odometry and accurate localisation over long periods. In this paper, we investigate a potential solution to these challenges by integrating a gimbaled camera with VT&R on a Grizzly Robotic Utility Vehicle (RUV) for testing at high speeds and in visually challenging environments. We examine the benefits and drawbacks of using an actively gimbaled camera to attenuate image motion and control viewpoint. We compare the use of a gimbaled camera to our traditional fixed stereo configuration and demonstrate cases of improved performance in Visual Odometry (VO), localisation and path following in several sets of outdoor experiments.


Title: Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion
Key Words: distance measurement  mobile robots  motion control  motion estimation  position control  robot vision  motion estimation process  positioning inaccuracy  structured environments  rotational motion  drift-free rotation  SO(3)-manifold constrained mean shift algorithm  multiple orthogonal planes  rotation estimate  structural regularities  drift-free rotational motion  low-drift visual odometry algorithm  translational motion  Cameras  Tracking  Three-dimensional displays  Estimation  Visual odometry  Feature extraction  Image segmentation 
Abstract: We present a low-drift visual odometry algorithm that separately estimates rotational and translational motion from lines, planes, and points found in RGB-D images. Previous methods estimate drift-free rotational motion from structural regularities to reduce drift in the rotation estimate, which is the primary source of positioning inaccuracy in visual odometry. However, multiple orthogonal planes are required to be visible throughout the entire motion estimation process; otherwise, these VO approaches fail. We propose a new approach to estimate drift-free rotational motion jointly from both lines and planes by exploiting environmental regularities. We track the spatial regularities with an efficient SO(3)-manifold constrained mean shift algorithm. Once the drift-free rotation is found, we recover the translational motion from all tracked points with and without depth by minimizing the de-rotated reprojection error. We compare the proposed algorithm to other state-of-the-art visual odometry methods on a variety of RGB-D datasets (including especially challenging pure rotations) and demonstrate improved accuracy and lower drift error.


Title: Visual Homing via Guided Locality Preserving Matching
Key Words: computational complexity  feature extraction  image matching  motion estimation  guided locality preserving matching  GLPM  panoramic images  linear space complexities  visual homing problem  sparse feature matches  homing directions  feature matching  mismatch removal  dense motion flow estimation  Tikhonov regularization  Visualization  Feature extraction  Electronic mail  Cost function  Measurement  Closed-form solutions  Intelligent robots 
Abstract: This study proposes a simple yet surprisingly effective feature matching approach, termed as guided locality preserving matching (GLPM), for visual homing of panoramic images. The key idea of our approach is merely to preserve the neighborhood structures of potential true matches between two panoramic images. We formulate it into a mathematical model, and derive a simple closed-form solution with linearithmic time and linear space complexities. This enables our method to accomplish the mismatch removal from hundreds of putative correspondences in only a few milliseconds. To handle extremely large proportions of outliers, we further design a guided matching strategy based on the proposed method, using the matching result on a small putative set with a high inlier ratio to guide the matching on a large putative set. This strategy can also significantly boost true matches without sacrifice in accuracy. To apply our GLPM to the visual homing problem, we develop a method for dense motion flow estimation from sparse feature matches based on Tikhonov regularization. Moreover, the focus-of-contraction/focus-of-expansion is derived to determine homing directions. The effectiveness of our method is demonstrated on a panoramic database in both feature matching and visual homing.


Title: LOGOS: Local Geometric Support for High-Outlier Spatial Verification
Key Words: feature extraction  pose estimation  outlier removal  LOGOS  local geometric support  high-outlier spatial verification  visual localization  orientation information  inlier points  secondary localization verification  benchmark localization datasets  local neighbourhoods  pose estimation  Visualization  Feature extraction  Robustness  Urban areas  Transforms  Pose estimation  Robots 
Abstract: This paper presents LOGOS, a method of spatial verification for visual localization that is robust in the presence of a high proportion of outliers. LOGOS uses scale and orientation information from local neighbourhoods of features to determine which points are likely to be inliers. The inlier points can be used for secondary localization verification and pose estimation. LOGOS is demonstrated on a number of benchmark localization datasets and outperforms RANSAC as a method of outlier removal and localization verification in scenarios that require robustness to many outliers.


Title: Selection and Compression of Local Binary Features for Remote Visual SLAM
Key Words: feature extraction  feature selection  mobile robots  multi-robot systems  robot vision  SLAM (robots)  feature selection stage  remote visual SLAM  autonomous robotics  collaborative SLAM approaches  multiple robots  feature coding scheme  simultaneous localization and mapping  visual sensors  embedded devices  local binary features extraction  centralized powerful processing node  Visualization  Encoding  Simultaneous localization and mapping  Feature extraction  Task analysis  Image coding 
Abstract: In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.


Title: Counterexamples for Robotic Planning Explained in Structured Language
Key Words: control engineering computing  formal verification  integer programming  linear programming  Markov processes  natural languages  path planning  robots  complex automaton  mixed-integer linear programming  Markov decision processes  model checking  warehouse robots planning  robotic mission plan  MDP model  robotic behavior  structured natural language sentences  Robots  Natural languages  Planning  Computational modeling  Charging stations  Model checking  Markov processes 
Abstract: Automated techniques such as model checking have been used to verify models of robotic mission plans based on Markov decision processes (MDPs) and generate counterexamples that may help diagnose requirement violations. However, such artifacts may be too complex for humans to understand, because existing representations of counterexamples typically include a large number of paths or a complex automaton. To help improve the interpretability of counterexamples, we define a notion of explainable counterexample, which includes a set of structured natural language sentences to describe the robotic behavior that lead to a requirement violation in an MDP model of robotic mission plan. We propose an approach based on mixed-integer linear programming for generating explainable counterexamples that are minimal, sound and complete. We demonstrate the usefulness of the proposed approach via a case study of warehouse robots planning.


Title: Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand
Key Words: automobiles  collision avoidance  mobile robots  optimal control  optimisation  road traffic  scheduling  potential collision situations  road geometries  joint motion plans  multivehicle motion planning  road network  Vienna Convention  desired deadlines  integrated route  road traffic  motion planning problem  social optimal mobility-on-demand  self-driving cars  bubble spaces  queue scheduling  Roads  Planning  Delays  Task analysis  Sensors  Trajectory  Automobiles 
Abstract: In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.


Title: Verifying Controllers Against Adversarial Examples with Bayesian Optimization
Key Words: Bayes methods  Gaussian processes  learning (artificial intelligence)  optimisation  robots  safety  complex safety specifications  complex controllers  Bayesian optimization  adversarial examples  coherent optimization framework  Gaussian Process prior  individual functions  reinforcement learning  reward functions  smooth functions  complex boolean combinations  adversarial counter examples  safety constraints  Bayesian Optimization  active-testing framework  safety-critical applications  Safety  Uncertainty  Robots  Testing  Trajectory  Optimization  Bayes methods 
Abstract: Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.


Title: On the Relationship Between Bisimulation and Combinatorial Filter Reduction
Key Words: bisimulation equivalence  computational complexity  filtering theory  minimisation  polynomials  equivalence relation  filter minimization problem  polynomial time  bisimulation relations  bisimilarity relation -the union  equivalent behavior-is NP-hard  combinatorial filter reduction  bisimulation quotient operation  input filter  Minimization  Robots  Task analysis  Color  Computational modeling  Cognition  Partitioning algorithms 
Abstract: Combinatorial filters are discrete structures for modeling and reasoning about robotic systems. Such filters are of interest not only because of the potential for reduction of the computational power needed to execute the filter, but also for the insight they can sometimes provide into the information requirements of certain robotic tasks. It is known that the filter minimization problem -that is, for a given filter, to find a combinatorial filter with the minimal number of states among all filters with equivalent behavior-is NP-hard. Intuition might suggest that the well-known notion of bisimulation might be of direct use for this minimization problem. Indeed, the bisimilarity relation -the union of all bisimulation relations over the state space of the original filter-is an equivalence relation, and one might attempt to reduce a filter by merging states that are equivalent under this relation. This paper studies this relationship between bisimulation and combinatorial filter reduction. Specifically, we show that every filter minimization problem can be solved by computing a quotient of the input filter with some relation, but that for some filters, the bisimilarity relation is not the correct relation for this purpose. We also characterize the result of the bisimulation quotient operation as the solution to a different, stricter filter minimization problem, and identify several classes of filters for which a variant of bisimulation, called compatibility, can be used to minimize filters in polynomial time.


Title: Learning-Based Model Predictive Control Under Signal Temporal Logic Specifications
Key Words: control system synthesis  Gaussian processes  learning (artificial intelligence)  predictive control  regression analysis  temporal logic  learning-based model predictive control method  differential constraints  dynamical systems  control strategy synthesis method  signal temporal logic specifications  specific rules  model predictive control procedure  learned margin  signal temporal logic formula  designed controller  traditional control scheme  Predictive control  Robustness  Collision avoidance  Task analysis  Gaussian processes  Service robots 
Abstract: This paper presents a control strategy synthesis method for dynamical systems with differential constraints while satisfying a set of given rules in consideration of their importances. A special attention is given to situations where all rules cannot be met in order to fulfill a given task. Such dilemmas compel us to make a decision on the degree of satisfaction of each rule including which rule should be maintained or not. In this work, we propose a learning-based model predictive control method in order to solve this problem, where a key insight is to combine a learning method and traditional control scheme so that the designed controller behaves close to human experts. A rule is represented as a signal temporal logic (STL) formula. A robustness slackness, a margin to the satisfaction of the rule, is learned from expert's demonstrations using Gaussian process regression. The learned margin is used in a model predictive control procedure, which helps to decide how much to obey each rule, even ignoring specific rules. In track driving simulation, we show that the proposed method generates human-like behavior and efficiently handles dilemmas as human teachers do.


Title: Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty
Key Words: control engineering computing  formal specification  mobile robots  multi-robot systems  operating systems (computers)  path planning  temporal logic  probabilistic options  temporal logic-based multirobot cooperation  temporal dependencies  task specification  robot team  temporal logic specifications  goal specification  ROS implementation  Robot kinematics  Task analysis  Uncertainty  Planning  Resource management  Probabilistic logic 
Abstract: Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.


Title: Path Clustering with Homology Area
Key Words: computational complexity  mesh generation  pattern clustering  topology  triangulated mesh  topology  path clustering  pairwise distance calculations  triangle inequality  minimum homology area  Clustering methods  Topology  Clustering algorithms  Toy manufacturing industry  Robots  Programming  Support vector machines 
Abstract: Path clustering has found many applications in recent years. Common approaches to this problem use aggregates of the distances between points to provide a measure of dissimilarity between paths which do not satisfy the triangle inequality. Furthermore, they do not take into account the topology of the space where the paths are embedded. To tackle this, we extend previous work in path clustering with relative homology, by employing minimum homology area as a measure of distance between homologous paths in a triangulated mesh. Further, we show that the resulting distance satisfies the triangle inequality, and how we can exploit the properties of homology to reduce the amount of pairwise distance calculations necessary to cluster a set of paths. We further compare the output of our algorithm with that of DTW on a toy dataset of paths, as well as on a dataset of real-world paths.


Title: GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability
Key Words: actuators  belts  drives  grippers  legged locomotion  manipulator kinematics  motion control  springs (mechanical)  finger  synchronous belt drive  underactuated graspers  serial kinematic chain  scalable kinematic structure  kinematic analysis  prototype robot  multimodal locomotion  robotic platform  active gripping surface  underactuated fingers  multipurpose grasper  manipulation  grasping  GraspMan  Grasping  Belts  Actuators  Task analysis  Grippers  Manipulators 
Abstract: In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as “legs” or “wheels” of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.


Title: Design and Evaluation of a Novel Cable-Driven Gripper with Perception Capabilities for Strawberry Picking Robots
Key Words: agriculture  closed loop systems  grippers  infrared detectors  manipulators  position control  robot vision  robust control  gripper design  cable-driven gripper  autonomous harvesting  IR sensors  manipulator arm  vision algorithm  robustness  positional error tolerance  high-level closed-loop control  strawberry picking robots  Grippers  Servomotors  Containers  Sensors  Robots  Mechanical cables  Pulleys 
Abstract: This paper presents a novel cable-driven gripper with perception capabilities for autonomous harvesting of strawberries. Experiments show that the gripper allows for more accurate and faster picking of strawberries compared to existing systems. The gripper consists of four functional parts for sensing, picking, transmission, and storing. It has six fingers that open to form a closed space to swallow a target strawberry and push other surrounding berries away from the target. Equipped with three IR sensors, the gripper controls a manipulator arm to correct for positional error, and can thus pick strawberries that are not exactly localized by the vision algorithm, improving the robustness. Experiments show that the gripper is gentle on the berries as it merely cuts the stem and there is no physical interaction with the berries during the cutting process. We show that the gripper has close-to-perfect successful picking rate when addressing isolated strawberries. By including internal perception, we get high positional error tolerance, and avoid using slow, high-level closed-loop control. Moreover, the gripper can store several berries, which reduces the overall travel distance for the manipulator, and decreases the time needed to pick a single strawberry substantially. The experiments show that the gripper design decreased picking execution time noticeably compared to results found in literature.


Title: Underactuated Hand Design Using Mechanically Realizable Manifolds
Key Words: actuators  dexterous manipulators  grippers  manipulator kinematics  stability  hand synergies  kinematic hand model  physical underactuation mechanism  hand posture  single-actuator hand  underactuated hand design  mechanically realizable manifolds  joint coordination patterns  planning algorithms  robotic grasping  mechanically realizable manifold  Tendons  Force  Optimization  Springs  Manifolds  Kinematics  Grasping 
Abstract: Hand synergies, or joint coordination patterns, have become an effective tool for achieving versatile robotic grasping with simple hands or planning algorithms. Here we propose a method to determine the hand synergies such that they can be physically implemented in an underactuated fashion. Given a kinematic hand model and a set of desired grasps, our algorithm optimizes a Mechanically Realizable Manifold designed to be achievable by a physical underactuation mechanism, enabling the resulting hand to achieve the desired grasps with few actuators. Furthermore, in contrast to existing methods for determining synergies which are only concerned with hand posture, our method explicitly optimizes the stability of the target grasps. We implement this method in the design of a three-finger single-actuator hand as an example, and evaluate its effectiveness numerically and experimentally.


Title: Robotic Handling of Liquids with Spilling Avoidance: A Constraint-Based Control Approach
Key Words: industrial manipulators  materials handling  motion control  path planning  sloshing  handling liquids  service robotic applications  motion planning  liquid transfer  sloshing control  anti spilling constraint  spilling avoidance constraint  constraint-based control  sloshing suppression  industrial ABB robot  robotic manipulators  Liquids  Robots  Trajectory  Containers  Task analysis  Acceleration  Optimization 
Abstract: Handling liquids with spilling avoidance is a topic of interest for a broad range of fields, both in industry and in service robotic applications. In this paper we present a new control architecture for motion planning of industrial robots, able to tackle the problem of liquid transfer with sloshing control. We do not focus on a complete sloshing suppression, but we show how to enforce an anti spilling constraint. This less conservative approach allows to impose higher accelerations, reducing motion time. A constraint-based approach, amenable to an Online implementation, has been developed. The proposed controller generates trajectories in real time, in order to follow a reference path, while being compliant to the spilling avoidance constraint. The approach has been validated on a 6 degree of freedom industrial ABB robot.


Title: A Robust Robot Design for Item Picking
Key Words: calibration  cameras  grippers  industrial manipulators  learning (artificial intelligence)  path planning  robot vision  service robots  feature-based comparison  gripper system  grasping strategy  robust performance  target items  robot system  dual 6 degrees of freedom industrial arms  error recovery strategies  fixed calibrated frame  multiple stereo cameras  vision system  custom-designed top-open extendable shelf  calibrated table  fixed bases  module designs  component selection  motion planning  system requirements  Amazon Robotics Challenge  reliable system  stable system  item picking  robust robot design  Cameras  Manipulators  Task analysis  Planning  Service robots  Robot vision systems 
Abstract: In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.


Title: Physics-Based Selection of Informative Actions for Interactive Perception
Key Words: mobile robots  robot dynamics  robot kinematics  visual perception  physics-based selection  informative action  forceful interactions  task-relevant information  informative interactions  articulated mechanisms  action selection task  interactive perception methods  information gain  robust manipulation  Kinematics  Task analysis  Dynamics  Robot sensing systems  Shape  Force 
Abstract: Interactive perception exploits the correlation between forceful interactions and changes in the observed signals to extract task-relevant information from the sensor stream. Finding the most informative interactions to perceive complex objects, like articulated mechanisms, is challenging because the outcome of the interaction is difficult to predict. We propose a method to select the most informative action while deriving a model of articulated mechanisms that includes kinematic, geometric, and dynamic properties. Our method addresses the complexity of the action selection task based on two insights. First, we show that for a class of interactive perception methods, information gain can be approximated by the amount of motion induced in the mechanism. Second, we resort to physics simulations grounded in the real-world through interactive perception to predict possible action outcomes. Our method enables the robot to autonomously select actions for interactive perception that reveal most information, given the current knowledge of the world. This leads to improved perception and more accurate world models, finally enabling robust manipulation.


Title: Pick and Place Without Geometric Object Models
Key Words: geometry  learning (artificial intelligence)  manipulators  geometric object models  robotic pick  deep reinforcement learning problem  deep RL  robotic manipulation frame  low level states  pick-place  regrasping problems  exact geometry  sensor perception  Shape  History  Task analysis  Robot sensing systems  Three-dimensional displays  Geometry 
Abstract: We propose a novel formulation of robotic pick and place as a deep reinforcement learning (RL) problem. Whereas most deep RL approaches to robotic manipulation frame the problem in terms of low level states and actions, we propose a more abstract formulation. In this formulation, actions are target reach poses for the hand and states are a history of such reaches. We show this approach can solve a challenging class of pick-place and regrasping problems where the exact geometry of the objects to be handled is unknown. The only information our method requires is: 1) the sensor perception available to the robot at test time; 2) prior knowledge of the general class of objects for which the system was trained. We evaluate our method using objects belonging to two different categories, mugs and bottles, both in simulation and on real hardware. Results show a major improvement relative to a shape primitives baseline.


Title: Automatic Material Properties Estimation for the Physics-Based Robotic Garment Folding
Key Words: clothing  fabrics  industrial robots  iterative methods  laser ranging  optimisation  automatic material properties estimation  physics-based robotic garment folding  fabric material property  iterative strategy  optimisation task  laser range finder  Fabrics  Estimation  Robots  Grippers  Material properties  Clothing  Measurement by laser beam 
Abstract: The estimation of the fabric material property during the folding is presented. The available techniques for the accurate garment folding rely on known material properties. Currently, the properties are estimated by an operator in advance of folding. We propose an iterative strategy, which updates the property while the garment is folded. The estimation is formulated as an optimisation task. It is based on measurements from a laser range finder. The proposed algorithm improves the estimation iteratively and prevents the garment from slipping at the same time. We demonstrate the estimation procedure for 10 fabric strips of different materials.


Title: Slipping Control Algorithms for Object Manipulation with Sensorized Parallel Grippers
Key Words: deformation  dexterous manipulators  force measurement  force sensors  grippers  mechanical contact  tactile sensors  torque measurement  object manipulation  sensorized parallel grippers  parallel jaw grippers  in-hand manipulation tasks  controlled sliding motion  grasped object  rotational sliding maneuver  grip force  translational sliding  rotational slippage  linear slippage  fragile objects  deformable objects  controlled rotational sliding  in-hand manipulation actions  sensorized gripper  six-axis force/tactile sensor  contact force  torque measurements  slipping control algorithms  in-hand manipulation action  Force  Robot sensing systems  Grippers  Friction  Task analysis  Dynamics 
Abstract: Parallel jaw grippers have a limited dexterity, however they can still be used for in-hand manipulation tasks, such as pivoting or other controlled sliding motions of the grasped object. A rotational sliding maneuver is challenging since the grasped object can easily slip if the grip force is not properly adjusted to allow rotational sliding while avoiding translational sliding at the same time. This paper has a twofold aim. First, it intends to refine control algorithms to avoid both rotational and linear slippage, already presented by the authors, by proposing a novel sliding motion model that leads to a grip force as small as possible to avoid slippage, so as to enlarge the set of fragile and deformable objects that can be safely grasped with this approach. Second, the paper exploits the motion model to set up a new algorithm for controlled rotational sliding, thus enabling challenging in-hand manipulation actions. All control algorithms are sensor-based, exploiting a sensorized gripper equipped with a six-axis force/tactile sensor, which provides contact force and torque measurements as well as orientation of the object with respect to the gripper. A set of experiments are executed on a Kuka iiwa showing how the proposed control algorithms are effective to both avoid slippage and allow a controlled sliding motion.


Title: Semantic Robot Programming for Goal-Directed Manipulation in Cluttered Scenes
Key Words: graph theory  image colour analysis  learning (artificial intelligence)  manipulators  path planning  pose estimation  robot programming  robot vision  object geometries  Semantic Robot Programming  task planning  motion planning  Discriminatively-Informed Generative Estimation of Scenes and Transforms  DIGEST method  RGBD images  goal-directed manipulation  cluttered scene dataset  Michigan Progress Fetch robot  object poses  robot manipulator  SRP  semantic mapping  Task analysis  Semantics  Robot programming  Estimation  Planning  Detectors 
Abstract: We present the Semantic Robot Programming (SRP) paradigm as a convergence of robot programming by demonstration and semantic mapping. In SRP, a user can directly program a robot manipulator by demonstrating a snapshot of their intended goal scene in workspace. The robot then parses this goal as a scene graph comprised of object poses and inter-object relations, assuming known object geometries. Task and motion planning is then used to realize the user's goal from an arbitrary initial scene configuration. Even when faced with different initial scene configurations, SRP enables the robot to seamlessly adapt to reach the user's demonstrated goal. For scene perception, we propose the Discriminatively-Informed Generative Estimation of Scenes and Transforms (DIGEST) method to infer the initial and goal states of the world from RGBD images. The efficacy of SRP with DIGEST perception is demonstrated for the task of tray-setting with a Michigan Progress Fetch robot. Scene perception and task execution are evaluated with a public household occlusion dataset and our cluttered scene dataset.


Title: Off-Road Lidar Simulation with Data-Driven Terrain Primitives
Key Words: geophysics computing  mobile robots  optical radar  remote sensing by laser beam  vegetation  perception algorithms  geometric terrain representation  Lidar rays  off-road Lidar simulation  vegetation  trees  shrubs  data logs  off-road environments  state estimation algorithms  high-fidelity sensor-realistic simulation  scale off-road robot applications  data-driven terrain primitives  Lidar observations  natural terrain  Laser radar  Software  Three-dimensional displays  Robot sensing systems  Training 
Abstract: Developing software for large scale off-road robot applications is challenging and tedious due to cost, logistics, and rigor of field testing. High-fidelity sensor-realistic simulation can speed up the development process for perception and state estimation algorithms. We focus on Lidar simulation for robots operating in off-road environments. Lidars are integral sensors for robots, and Lidar simulation for off-road environments is particularly challenging due to the way Lidar rays interact with natural terrain such as vegetation. A hybrid geometric terrain representation has been shown to model Lidar observations well [1]. However, previous work has only been able to simulate a single, fixed scene, and the entire scene had to be precisely surveyed. In this work, we add semantic information to the hybrid geometric model. This allows us to extract terrain primitives, such as trees and shrubs, from data logs. Our approach uses these primitives to compose arbitrary scenes for Lidar simulation. We evaluate our simulator on a real-world environment of interest, and show that primitives derived using our approach generalize to new scenes.


Title: Historical Data is Useful for Navigation Planning: Data Driven Route Generation for Autonomous Ship
Key Words: autonomous underwater vehicles  collision avoidance  marine control  marine navigation  mobile robots  ships  Navigation Feature  historical data  navigation planning  data driven route generation  autonomous ship  automated generation  autonomous surface vessel  robotic surface vessel  Historical Automatic Identification System data  AIS locations  nearest neighbour based path retrieval  Ship Feature  AIS records  Marine vehicles  Navigation  Artificial intelligence  Noise measurement  Planning  Path planning  Databases 
Abstract: This work presents a method for automated generation of navigation plan for autonomous or robotic surface vessel. Historical Automatic Identification System (AIS) data is of significant value to this problem. The method joins AIS locations of a same vessel at different time and locations in a region into a route. Next, it automatically computes navigation plans using nearest neighbour based path retrieval relying on two representations, Ship Feature and Navigation Feature. Before starting service, existing AIS records in the form of ship properties and corresponding route are preprocessed and stored in the form of Ship and Navigation Feature. During online retrieval, given input constraints in vector form, nearest neighbour of this query vector in the same space is found and corresponding path of the neighbour is returned as recommended path. Analysis was done in four and two dimensional spaces for Ship and Navigation Feature respectively. Application of the method is demonstrated in two regions of Australian, covering Bass Strait and Great Australian Bight.


Title: A Preliminary Study of Ice-Relative Underwater Vehicle Navigation Beneath Moving Sea Ice
Key Words: autonomous underwater vehicles  Kalman filters  marine navigation  mobile robots  navigation  nonlinear filters  oceanographic techniques  position control  ships  under-ice navigation methods  extended Kalman filter  sufficient satellite beacon separation  vehicle position  ice velocities  vehicle trajectory  ice survey  navigation sensors  ship  precision vehicle  satellite navigation beacons  precision navigation capabilities  under-ice robotic vehicles  moving stationary sea ice  underwater robotic vehicle navigation  vehicle navigation beneath moving sea ice  ice-relative  size 7.6 km  size 1.2 km  Satellite navigation systems  Marine vehicles  Sea ice  Sonar navigation  Acoustics 
Abstract: This paper addresses the problem of underwater robotic vehicle navigation relative to moving or stationary sea ice. A brief review of previously-reported under-ice navigation methods is given, as well as a brief motivation for the use of under-ice robotic vehicles with precision navigation capabilities. We then describe our proposed approach, which employs two or more satellite navigation beacons atop the sea ice along with other precision vehicle and ship mounted navigation sensors to estimate vehicle, ice, and ship states by means of an Extended Kalman Filter. Navigation results for a simulated 7.6 km under ice survey are presented for varying satellite beacon separation. Preliminary analysis suggests that for the simulated sensors, vehicle trajectory, and ice velocities, the proposed method can accurately estimate vehicle position up to 1.2 km from the deployment ship given sufficient satellite beacon separation. Decreased beacon separation results in divergence of the vehicle's position estimate at large standoff distances from the ship. We conclude with suggestions for future improvements.


Title: A Soft Robot for Random Exploration of Terrestrial Environments
Key Words: control engineering computing  industrial robots  mass production  microrobots  motion control  multi-robot systems  soft robot  random exploration  terrestrial environments  unknown terrains  adequate locomotion strategy  fast exploration  obstacles negotiation  mass manufacturing  minimalistic design  roll  soft cage  swarm operations  randomly moving miniature robots  Robots  Propellers  Aerodynamics  Shock absorbers  Batteries 
Abstract: A swarm of randomly moving miniature robots is an effective solution for the exploration of unknown terrains. However, the deployment of a swarm of miniature robots poses two challenges: finding an adequate locomotion strategy for fast exploration and obstacles negotiation; and implementing simple design and control solutions suited for mass manufacturing. Here, we tackle these challenges by developing a new soft robot with a minimalistic design and a simple control strategy that can randomly propel itself above obstacles and roll on the ground upon landing. The robot is equipped with two propellers that are periodically activated to jump, a soft cage that protects the robot from impacts and allows to passively roll on the ground, and a passive self-righting mechanism for repetitive jumps. The minimalistic control and design reduce the complexity of the mechanics and electronics and are instrumental to the production of a large number of robots. In the paper, the key design aspects of the robot are discussed, the locomotion of a single prototype is experimentally characterized, and improvements of the system for future swarm operations are discussed.


Title: Micro Underwater Vehicle Hydrobatics: A Submerged Furuta Pendulum
Key Words: attitude control  autonomous underwater vehicles  control system synthesis  marine control  microrobots  mobile robots  pendulums  robust control  stability  vehicle dynamics  submerged Furuta pendulum  HippoCampus microunderwater vehicle  fluid volumes  tightly constrained settings  agile vehicle dynamics  robust attitude control scheme  aerial drones  underwater domain  control method  microunderwater vehicle hydrobatics  submerged Furuta pendulum stabilization  Vehicle dynamics  Hippocampus  Attitude control  Hydrodynamics  Force  Monitoring  Drones 
Abstract: We present the new HippoCampus micro underwater vehicle, first introduced in [1]. It is designed for monitoring confined fluid volumes. These tightly constrained settings demand agile vehicle dynamics. Moreover, we adapt a robust attitude control scheme for aerial drones to the underwater domain. We demonstrate the performance of the controller with a challenging maneuver. A submerged Furuta pendulum is stabilized by HippoCampus after a swing-up. The experimental results reveal the robustness of the control method, as the system quickly recovers from strong physical disturbances, which are applied to the system.


Title: Satellite-Based Tele-Operation of an Underwater Vehicle-Manipulator System. Preliminary Experimental Results
Key Words: artificial satellites  end effectors  manipulator kinematics  mobile robots  remotely operated vehicles  satellite communication  satellite links  telerobotics  underwater vehicles  UVMS  Underwater Vehicle-Manipulator System  satellite link  task-priority-based inverse kinematics algorithm  satellite-based tele-operation  European project  underwater intervention  remote control room  satellite communication link  DexROV  cognitive engine  communication latency  end effector  size 2017.0 inch  Task analysis  Trajectory  Kinematics  Satellite communication  Exoskeletons  Engines  Robustness 
Abstract: Within the European project DexROV the topic of underwater intervention is addressed. In particular, a remote control room is connected through a satellite communication link to surface vessel, which is in turn connected to an UVMS (Underwater Vehicle-Manipulator System) with an umbilical cable. The operator may interact with the system using a joystick or exoskeleton. Since a direct teleoperation is not feasible, a cognitive engine is in charge of handling communication latency or interruptions caused by the satellite link, and the UVMS should have sufficient autonomy in dealing with low level constraints or secondary objectives. To this purpose, a task-priority-based inverse kinematics algorithm has been developed in order to allow the operator to control only the end effector, while the algorithm is in charge of handling both operative and joint-space constraints. This paper describes some preliminary experimental results achieved during the DexROV campaign of July 2017 in Marseilles (France), where most of the components have been successfully integrated and the inverse kinematics nicely run.


Title: Robust Dense Mapping for Large-Scale Dynamic Environments
Key Words: cameras  image motion analysis  image reconstruction  image segmentation  mobile robots  motion control  object detection  path planning  pose estimation  robot vision  stereo image processing  robust dense mapping  large-scale dynamic environments  stereo-based dense mapping algorithm  large-scale dynamic urban environments  static background  high-level mobile robotic tasks  crowded environments  instance-aware semantic segmentation  sparse scene flow  visual odometry  depth maps  stereo input  map pruning technique  reconstruction accuracy  stationary objects  moving objects detection  path planning  camera poses estimation  frequency 2.5 Hz  Three-dimensional displays  Cameras  Semantics  Vehicle dynamics  Dynamics  Real-time systems  Heuristic algorithms 
Abstract: We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately, which is desirable for high-level mobile robotic tasks such as path planning in crowded environments. We use both instance-aware semantic segmentation and sparse scene flow to classify objects as either background, moving, or potentially moving, thereby ensuring that the system is able to model objects with the potential to transition from static to dynamic, such as parked cars. Given camera poses estimated from visual odometry, both the background and the (potentially) moving objects are reconstructed separately by fusing the depth maps computed from the stereo input. In addition to visual odometry, sparse scene flow is also used to estimate the 3D motions of the detected moving objects, in order to reconstruct them accurately. A map pruning technique is further developed to improve reconstruction accuracy and reduce memory consumption, leading to increased scalability. We evaluate our system thoroughly on the well-known KITTI dataset. Our system is capable of running on a PC at approximately 2.5Hz, with the primary bottleneck being the instance-aware semantic segmentation, which is a limitation we hope to address in future work. The source code is available from the project Websitea.


Title: Self-triggered Adaptive Planning and Scheduling of UAV Operations
Key Words: adaptive control  autonomous aerial vehicles  collision avoidance  energy consumption  helicopters  mobile robots  noise  reachability analysis  risk analysis  scheduling  trajectory optimisation (aerospace)  obstacles avoidance  energy consumption  trajectory curvature  self-triggered adaptive planning  unmanned aerial vehicles  scheduling  quadrotor UAV motion planning  obstacles detection  time consumption  constant periodic sensor measurements  online speed adaptation policy  risk-based analysis  noise  reachability analysis  Trajectory  Robot sensing systems  Safety  Unmanned aerial vehicles  Reachability analysis  Schedules 
Abstract: Modern unmanned aerial vehicles (UAVs) rely on constant periodic sensor measurements to detect and avoid obstacles. However, constant checking and replanning are time and energy consuming and are often not necessary especially in situations in which the UAV can safely fly in uncluttered environments without entering unsafe states. Thus, in this paper, we propose a self-triggered framework that leverages reachability analysis to schedule the next time to check sensor measurements and perform replanning while guaranteeing safety under noise and disturbance effects. Further, we relax sensor checking and motion replanning operations by leveraging a risk-based analysis that determines the likelihood to reach undesired states over a certain time horizon. We also propose an online speed adaptation policy based on the planned trajectory curvature to minimize drift from the desired path due to the system dynamics. Finally, we validate the proposed approach with simulations and experiments for a quadrotor UAV motion planning case study in a cluttered environment.


Title: Intent-Aware Multi-Agent Reinforcement Learning
Key Words: aerospace robotics  control engineering computing  decision theory  function approximation  learning (artificial intelligence)  Markov processes  multi-agent systems  planning (artificial intelligence)  robot dynamics  low-level planning algorithms  intent-aware multiagent reinforcement learning  learning algorithm  planning process  partially observable Markov decision process  linear function approximation  intent-aware multiagent planning  aerial robots  human interaction  dynamic process  POMDP  Planning  Prediction algorithms  Automata  Vehicles  History  Computational modeling 
Abstract: This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.


Title: Improving Model-Based Balance Controllers Using Reinforcement Learning and Adaptive Sampling
Key Words: humanoid robots  learning (artificial intelligence)  optimal control  sampling methods  control signals  adaptive sampling  model-based balance controllers  humanoid model  in-place balancing  training disturbances  standard reinforcement learning formulations  deep reinforcement learning techniques  control policy  RoA  model-based optimal controller  learning framework  full-body actions  nonplanar pushes  full-body dynamics  optimal control theory  Perturbation methods  Hip  Adaptation models  Robots  Training  Lips  Learning (artificial intelligence) 
Abstract: Balance control to recover from a wide range of disturbances is an important skill for humanoid robots. Traditionally, researchers have often designed a balance controller by applying optimal control theory on a simplified model that abstracts the full-body dynamics. However, the resulting controller may not be able to recover from unexpected scenarios such as non-planar pushes, or fail to exploit full-body actions such as balancing with arm movements. This paper presents a learning framework for enhancing the performance of a model-based optimal controller by expanding the region of attraction (RoA). We train a control policy that generates additional control signals on top of the model-based controller using deep reinforcement learning techniques. Instead of relying on standard reinforcement learning formulations, we explicitly model the region of attraction and continuously adjust it during the training. By drawing the training disturbances at the boundary of the RoA, we can effectively expand the RoA while avoiding local minima. We test our learning framework for in-place balancing as well as balancing with stepping on a humanoid model in simulation.


Title: Deep Reinforcement Learning Supervised Autonomous Exploration in Office Environments
Key Words: decision making  learning (artificial intelligence)  mobile robots  path planning  supervised autonomous exploration  office environments  exploration region selection  autonomous robot exploration task  greedy methods  long-term planning  deep reinforcement learning  exploration knowledge  office blueprints  DRL model  next-best-view selection approach  structural integrity measurement  office maps  decision making process  Planning  Optimization  Prediction algorithms  Task analysis  Predictive models  Computer architecture  Uncertainty 
Abstract: Exploration region selection is an essential decision making process in autonomous robot exploration task. While a majority of greedy methods are proposed to deal with this problem, few efforts are made to investigate the importance of predicting long-term planning. In this paper, we present an algorithm that utilizes deep reinforcement learning (DRL) to learn exploration knowledge over office blueprints, which enables the agent to predict a long-term visiting order for unexplored subregions. On the basis of this algorithm, we propose an exploration architecture that integrates a DRL model, a next-best-view (NBV) selection approach and a structural integrity measurement to further improve the exploration performance. At the end of this paper, we evaluate the proposed architecture against other methods on several new office maps, showing that the agent can efficiently explore uncertain regions with a shorter path and smarter behaviors.


Title: Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search
Key Words: Bayes methods  control engineering computing  learning (artificial intelligence)  legged locomotion  manipulators  maximum likelihood estimation  motion control  optimisation  search problems  Most Likely Expected Improvement  5DOF planar arm  6-legged robot  transfer learning task  acquisition function  data-efficient direct policy search  automatic prior selection  Bayesian optimization  Optimization  Bayes methods  Legged locomotion  Task analysis  Predictive models  Computational modeling 
Abstract: One of the most interesting features of Bayesian optimization for direct policy search is that it can leverage priors (e.g., from simulation or from previous tasks) to accelerate learning on a robot. In this paper, we are interested in situations for which several priors exist but we do not know in advance which one fits best the current situation. We tackle this problem by introducing a novel acquisition function, called Most Likely Expected Improvement (MLEI), that combines the likelihood of the priors and the expected improvement. We evaluate this new acquisition function on a transfer learning task for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has to learn to walk on flat ground and on stairs, with priors corresponding to different stairs and different kinds of damages. Our results show that MLEI effectively identifies and exploits the priors, even when there is no obvious match between the current situations and the priors.


Title: Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning
Key Words: computational complexity  learning (artificial intelligence)  neural nets  predictive control  model-free learning  model-free fine-tuning  model-free deep reinforcement learning algorithms  model-based algorithms  model predictive control  model-based reinforcement learning algorithm  complex locomotion tasks  deep neural network dynamics models  model-free learner  model-based approaches  model-free methods  sample complexity  model-based deep reinforcement learning  robotic skills  MPC  plausible gaits  stable gaits  Task analysis  Predictive models  Neural networks  Data models  Heuristic algorithms  Machine learning  Complexity theory 
Abstract: Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.


Title: Adapting Parameterized Motions Using Iterative Learning and Online Collision Detection
Key Words: Bayes methods  collision avoidance  Gaussian processes  intelligent robots  learning (artificial intelligence)  optimisation  robotic assembly  servomotors  signal classification  iterative learning  online collision detection  robust robot system  uncertainty-tolerant motions  Gaussian Process learning  Bayesian Optimization  robot motor currents  assembly process  medium-sized productions  parameterized motions  Collision avoidance  Robot sensing systems  Robustness  Robotic assembly  Trajectory 
Abstract: Achieving both the flexibility and robustness required to advance the use of robotics in small and medium-sized productions is an essential but difficult task. A fundamental problem is making the robot run blindly without additional sensors while still being robust to uncertainties and variations in the assembly processes. In this paper, we address the use of parameterized motions suitable for blind execution and robust to uncertainties in the assembly process. Collisions and incorrect assemblies are detected based on robot motor currents while motion parameters are updated based on Bayesian Optimization utilizing Gaussian Process learning. This allows for motion parameters to be optimized using real world trials which incorporate all uncertainties inherent in the assembly process without requiring advanced robot and sensor setups. The result is a simple and straightforward system which helps the user automatically find robust and uncertainty-tolerant motions. We present experiments for an assembly case showing both detection and learning in the real world and how these combine to a robust robot system.


Title: Trajectory Replanning for Quadrotors Using Kinodynamic Search and Elastic Optimization
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  elasticity  helicopters  mobile robots  optimal control  path planning  pipes  predictive control  quadratic programming  robot dynamics  robot kinematics  robot vision  search problems  splines (mathematics)  trajectory control  quadratically constrained quadratic programming problem  receding horizon replanner design  trajectory replanning  grid structure  dynamically feasible time-parameterized trajectory  B-spline based kinodynamic search algorithm  greedy search  B-spline parameterization  position-only shortest path search  monocular vision-based quadrotor  replanning system  local control property  expanded elastic tube  optimal control point placement  EO approach  RBK search  post-optimization process  elastic optimization approach  Splines (mathematics)  Trajectory  Optimization  Real-time systems  Process control  Planning  Complexity theory 
Abstract: We focus on a replanning scenario for quadrotors where considering time efficiency, non-static initial state and dynamical feasibility is of great significance. We propose a real-time B-spline based kinodynamic (RBK) search algorithm, which transforms a position-only shortest path search (such as A * and Dijkstra) into an efficient kinodynamic search, by exploring the properties of B-spline parameterization. The RBK search is greedy and produces a dynamically feasible time-parameterized trajectory efficiently, which facilitates non-static initial state of the quadrotor. To cope with the limitation of the greedy search and the discretization induced by a grid structure, we adopt an elastic optimization (EO) approach as a post-optimization process, to refine the control point placement provided by the RBK search. The EO approach finds the optimal control point placement inside an expanded elastic tube which represents the free space, by solving a Quadratically Constrained Quadratic Programming (QCQP) problem. We design a receding horizon replanner based on the local control property of B-spline. A systematic comparison of our method against two state-of-the-art methods is provided. We integrate our replanning system with a monocular vision-based quadrotor and validate our performance onboard.


Title: On Bisection Continuous Collision Checking Method: Spherical Joints and Minimum Distance to Obstacles
Key Words: collision avoidance  mobile robots  motion control  path planning  bisection Continuous Collision checking method  spherical joints  Continuous Collision Detection method  tight motion bounds  sampling-based motion planning technique  Baxter research robot  minimum distance extension  obstacle minimum distance  robotic systems  Collision avoidance  Charge coupled devices  Planning  Computational modeling  Manipulators  Motion segmentation 
Abstract: In this paper, we adapt the Continuous Collision Detection (CCD) method proposed in [1] to efficiently handle the case of spherical and two revolute joints, this kind of joints is very common in modern robotic systems. The new formulations provide more tight motion bounds, thus increase the success rate of checking collision-free paths. We also propose an extension to get the minimum distance to obstacles along a path, this information is primordial as it allows sampling-based motion planning techniques to sort collision-free paths according to their minimum clearance. We have integrated our implementation into a sampling-based motion planning technique and validated it through simulation and on the real Baxter research robot. The experiments revealed that the method not only does not miss any collision between the robot and the obstacles, but also the minimum distance extension provides the path with the maximum clearance at no additional computational cost.


Title: Avoidance of High-Speed Obstacles Based on Velocity Obstacles
Key Words: collision avoidance  mobile robots  velocity control  time horizon  obstacle avoidance algorithm  collision avoidance  two-period velocity obstacle algorithm  high-speed obstacles avoidance  mobile robots  Collision avoidance  Robot kinematics  Prediction algorithms  Heuristic algorithms  Robot sensing systems  Dynamics 
Abstract: For obstacles moving with high speeds, existing motion planning methods can rarely guarantee collision avoidance. This paper proposes a viable two-period velocity obstacle algorithm where one period predicts potential collisions within a limited time horizon, and the second period foresees collisions beyond that horizon. The second period is activated only when the obstacle's moving speed is larger than the maximum speed of the robot. The applicability of the new algorithm and the related computation issues are discussed. Both computer simulations and laboratory experiments illustrated the effectiveness of the proposed obstacle avoidance algorithm.


Title: NanoMap: Fast, Uncertainty-Aware Proximity Queries with Lazy Search Over Local 3D Data
Key Words: cartography  collision avoidance  mobile robots  navigation  sensors  NanoMap  uncertainty-aware proximity queries  lazy search  local 3D data  local 3D information  robustly plan motions  local map structure  mapping approaches  global map fusion  motion planner  pose-uncertainty-aware local 3D geometric information  noisy relative pose transforms  depth sensor measurements  minimum-uncertainty view  motion planning  fast 3D obstacle avoidance  mapping techniques  Uncertainty  Robot sensing systems  Planning  Three-dimensional displays  Collision avoidance  History  Current measurement 
Abstract: We would like robots to be able to safely navigate at high speed, efficiently use local 3D information, and robustly plan motions that consider pose uncertainty of measurements in a local map structure. This is hard to do with previously existing mapping approaches, like occupancy grids, that are focused on incrementally fusing 3D data into a common world frame. In particular, both their fragile sensitivity to state estimation errors and computational cost can be limiting. We develop an alternative framework, NanoMap, which alleviates the need for global map fusion and enables a motion planner to efficiently query pose-uncertainty-aware local 3D geometric information. The key idea of NanoMap is to store a history of noisy relative pose transforms and search over a corresponding set of depth sensor measurements for the minimum-uncertainty view of a queried point in space. This approach affords a variety of capabilities not offered by traditional mapping techniques: (a) the pose uncertainty associated with 3D data can be incorporated in motion planning, (b) poses can be updated (i.e., from loop closures) with minimal computational effort, and (c) 3D data can be fused lazily for the purpose of planning. We provide an open-source implementation of NanoMap, and analyze its capabilities and computational efficiency in simulation experiments. Finally, we demonstrate in hardware its effectiveness for fast 3D obstacle avoidance onboard a quadrotor flying up to 10 m/s.


Title: A Sensorless Collision Detection Approach Based on Virtual Contact Points
Key Words: collision avoidance  force control  manipulators  virtual contact points  force-sensorless collision detection approach  virtual contacts  virtual instantaneous powers  2D collision detection tasks  3D collision detection tasks  DOF spatial manipulator validate  contact link  Collision avoidance  Task analysis  Manipulators  Force  Two dimensional displays  Robot sensing systems 
Abstract: This paper presents a force-sensorless collision detection approach based on virtual contacts. A series of indices based on virtual instantaneous powers are introduced associating to several virtual contacts defined on corresponding links of a manipulator. A possible contact link can be determined by comparing the introduced indices without any force or tactile sensors. Simulation results of 2D collision detection tasks by using a three DOF (Degree of Freedom) planar manipulator and 3D collision detection tasks by using a six DOF spatial manipulator validate the effectiveness of the proposed collision detection approach.


Title: Probabilistic Graph Security for Networked Multi-Robot Systems
Key Words: binary decision diagrams  Boolean functions  graph theory  mobile robots  multi-robot systems  probability  networked multirobot systems  robot interactions  existing control-theoretic notion  network attacks  left invertibility  dynamical system  probabilistic robot communication  adversarial influence  probabilistic graph security problem  system reliability  efficient graphical representation  binary decision diagrams  networked MRS  mobile multirobot teams  mobile MRS  reduced order BDD  Robot sensing systems  Probabilistic logic  Observers  Security  Boolean functions 
Abstract: In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time.


Title: Controlling the Interaction of a Multi-Robot System with External Entities
Key Words: force control  multi-robot systems  external entities  dynamic interaction model  multirobot system  interaction control  local deformations  coupling actions  passivity property  safety guarantees  Robots  Couplings  Multi-robot systems  Dynamics  Force  Damping  Collision avoidance 
Abstract: In this paper we consider a multi-robot system that shares the environment with external entities, and we propose a methodology for controlling the interaction with them. In particular, we consider the problem of achieving a desired dynamic interaction model, in such a way that the multi-robot system exchanges desired forces with external entities. This is obtained by introducing local deformations of the coupling actions among the robots. The proposed method ensures preservation of the passivity property, which provides safety guarantees in the interaction with the (possibly poorly known) external entities.


Title: Network Topology Inference in Swarm Robotics
Key Words: graph theory  inference mechanisms  multi-robot systems  network theory (graphs)  swarm intelligence  network topology inference  swarm robotics  topological graph  swarm intelligence  Trajectory  Robots  Network topology  Acceleration  Australia  Mathematical model  Atmospheric measurements 
Abstract: Swarm robotics refers to the implementation of swarm intelligence features like autonomy and self-organization to a collective of robots. This study focuses on the construction of a topological graph that represents both the magnitude and orientation of swarm interactions. Such structure is used for identifying global parameters like leadership and to derive a relationship between the distribution of interaction magnitudes and swarm parameters. Interaction magnitudes were derived from the trajectory distance between nearest neighbors and it was found that the distribution is able to differentiate between only a small subset of controllers, communication ranges and swarm sizes. Leader detection was based on the analysis of position vectors orientation in local neighborhoods. The method was successful at a 100% rate for 10 and 30 robots, while for 60 a minimum rate of 67% was obtained. Additionally, processing times never exceeded a simulation duration for swarms up to 30 robots, with the potential to parallelize for larger sizes.


Title: Using Hardware Specialization and Hierarchy to Simplify Robotic Swarms
Key Words: mobile robots  multi-robot systems  work distribution  hardware specialization  classical distributed robotics problem  robotic swarms  simulated environment  shape formation  Shape  Task analysis  Hardware  Robot sensing systems  Legged locomotion  Collision avoidance 
Abstract: Specialization has always been a tool for work distribution and simplification in nature and in distributed robotics. We present a novel approach to use hardware specialization hierarchically to enhance the capabilities of a swarm without increasing complexity, allowing a numerous group of robots to benefit from the extended features of a few to complete a task that was impossible for them before. We tested the concept under a simulated environment with a classical distributed robotics problem, shape formation, and validated the simulated results against a real experiment.


Title: From Swarms to Stars: Task Coverage in Robot Swarms with Connectivity Constraints
Key Words: distributed control  mobile robots  multi-robot systems  navigation  optimisation  scheduling  Task coverage  Robot swarms  connectivity constraints  swarm robotics  complex tasks  control algorithms  globally coordinated behaviours  spatial coverage  global connectivity  distributed Robot Navigation Controller  RNC  global Task Scheduling Controller  minimal computational load  connectivity assessment  real-life robot experiments  coverage optimality  Task analysis  Robot kinematics  Navigation  Eigenvalues and eigenfunctions  Computational modeling  Multi-robot systems 
Abstract: Swarm robotics carries the potential of solving complex tasks using simple devices. To do so, however, one must define distributed control algorithms capable of producing globally coordinated behaviours. We propose a methodology to address the problem of the spatial coverage of multiple tasks with a swarm of robots that must not lose global connectivity. Our methodology comprises two layers: (i) a distributed Robot Navigation Controller (RNC) is responsible for simultaneously guaranteeing connectivity and pursuit of multiple tasks; and (ii) a global Task Scheduling Controller approximates the optimal strategy for the RNC with minimal computational load. Our contributions include: (i) a qualitative analysis of the literature on connectivity assessment, (ii) our proposed methodology, (iii) simulations in a multi-physics environment, (iv) real-life robot experiments, and (v) the experimental validation of connectivity, coverage optimality, and fault-tolerance.


Title: Using Information Invariants to Compare Swarm Algorithms and General Multi-Robot Algorithms
Key Words: mobile robots  multi-robot systems  swarm intelligence  multirobot algorithms  proximal neighbors  emergent collective behaviors  all-to-all communication  deliberative collaboration  supervisory operator  mission constraints  application domains - navigation  dynamic area coverage  online algorithm selection decisions  offline system design decisions  robotic swarms  information invariants  Heuristic algorithms  Robot kinematics  Robot sensing systems  Collision avoidance  Multi-robot systems  Navigation 
Abstract: Robotic swarms are decentralized multi-robot systems whose members use local information from proximal neighbors to execute simple reactive control laws that result in emergent collective behaviors. In contrast, members of a general multi-robot system may have access to global information, all-to-all communication or sophisticated deliberative collaboration. Some algorithms in the literature are applicable to robotic swarms. Others require the extra complexity of general multi-robot systems. Given an application domain, a system designer or supervisory operator must choose an appropriate system or algorithm respectively that will enable them to achieve their goals while satisfying mission constraints (e.g, bandwidth, energy, time limits). In this paper, we compare representative swarm and general multi-robot algorithms in two application domains - navigation and dynamic area coverage - with respect to several metrics (e.g, completion time, distance travelled). Our objective is to characterize each class of algorithms to inform offline system design decisions by engineers or online algorithm selection decisions by supervisory operators. Our contributions are (a) an empirical performance comparison of representative swarm and general multi-robot algorithms in two application domains, (b) a comparative analysis of the algorithms based on the theory of information invariants, which provides a theoretical characterization supported by our emnirical results.


Title: Learning Robust Policies for Object Manipulation with Robot Swarms
Key Words: Hilbert spaces  learning systems  mobile robots  multi-robot systems  robotic assembly  robust control  search problems  swarm size  robust policies learning  Hilbert space embeddings  policy search methods  low-level object movement policy  high-level assembly plan  assembly process  policy search method  autonomous object assembly  swarm robotics  robot swarms  object manipulation  Robot sensing systems  Task analysis  Light sources  Robustness  Kernel  Trajectory 
Abstract: Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.


Title: Modeling and Identification of a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
Key Words: compensation  flexible manipulators  linear systems  springs (mechanical)  spring based mechanism  flexible link arm  single link flexible arm  linear springs  flexible link robotics  passive gravity compensation  spring-based compensation  lumped-mass methodology  vibrational frequency  Gravity  Springs  Torque  DC motors  Wires  Robots  Payloads 
Abstract: In this paper, we present an experimental study concerning the gravity compensation of flexible link arms based on linear springs. In the field of flexible link robotics, the gravity compensation based on counterweights has been successfully applied in the past, but little effort has been made to examine the potential benefits and difficulties of using spring-based compensation mechanisms. This paper focuses on the modeling and identification of a single link flexible arm compensated with a spring based mechanism. As modeling approach, we followed the lumped-mass methodology to develop a model capable of reproducing the first vibrational frequency of the flexible link arm. Keeping in mind the forces that interact with the flexible link, a combination of sensors is suggested in order to measure and estimate the most important variables of the system. Subsequently, a very simple and reliable identification method based on the time and frequency response of the system is proposed. Finally, the results of the modeling and identification are validated on our experimental platform.


Title: A Nonlinear Control Strategy for Extensible Continuum Robots
Key Words: closed loop systems  control system synthesis  manipulators  nonlinear control systems  PD control  variable structure systems  extensible continuum robots  closed-loop control  adaptation-based control law  rigid-link control device  extensible continuum manipulator  nonlinear control strategy  set-point tracking  Manipulator dynamics  Mathematical model  Convergence  Kinematics  Jacobian matrices 
Abstract: In this paper, we describe a novel nonlinear control strategy for the closed-loop control of extensible continuum robots. Previous attempts at controlling continuum robots have proved difficult due to the complexity of their system dynamics. Taking advantage of a previously developed dynamic model for a three-section, planar, continuum manipulator, we develop an adaptation-based control law. We present simulation results of a set-point tracking between a rigid-link control device and an extensible continuum manipulator. Experimental results of the controller implemented on a six degree-of-freedom continuum robot are also presented.


Title: Continuously Controllable Series Clutches for Efficient Robot Actuation
Key Words: actuators  clutches  energy conservation  friction  gears  mobile robots  muscle  torque  controllable series clutches  efficient robot actuation  energy efficiency potential  continuously controllable clutches  robot joints  biological muscles  purely gravity driven robot link motion phases  gear friction  motor effort  energetic benefits  direct drives  unforced motion phases  high torque density  conventional geared robotic drive technology  mature geared robotic drive technology  forced motion phases  general functional principle  particular clutch implementation  harmonic link motions  friction torque  Friction  Torque  Robots  Actuators  Tendons  Mathematical model 
Abstract: This paper investigates the energy efficiency potential of continuously controllable clutches between the motors and links of robot joints. Inspired by biological muscles, the clutch enables free, purely gravity driven robot link motion phases gradually disengaged from gear friction, not requiring motor effort. The concept combines the energetic benefits of direct drives during unforced motion phases with the high torque density of conventional and mature geared robotic drive technology during forced motion phases. The paper specifies the general functional principle of the clutch for energy saving independent of any particular clutch implementation. The feasible energy saving of up to 60 % is investigated for harmonic link motions with varying frequencies and with respect to different ratios of link weight to friction torque. The outcomes of the theoretical investigations are supported by first experimental results.


Title: Stiffness Modulator: A Novel Actuator for Human Augmentation
Key Words: actuators  biomechanics  elastic constants  medical robotics  muscle  portable instruments  sit-to-stand-task  cocontracted antagonistic muscles  metabolic energy cost  self-contained stiffness modulator  muscle activity  compliant actuators  stiffness modulation  human augmentation  human knee joint  stiffness augmentation  portable stiffness modulator  Modulation  Springs  Actuators  Force  Muscles 
Abstract: Stiffness modulators are devices that promote a novel means of actuation; they provide stiffness modulation without deliberately doing mechanical work. These type of compliant actuators may be used for human augmentation to complement co-contracted antagonistic muscles and as such reduce muscle activity and metabolic energy cost. Despite the theoretical appeal of this concept, its implementation remains elusive in practical applications. This is particularly true for human augmentation which requires a portable stiffness modulator. In this paper, we present a compact, lightweight, and self-contained stiffness modulator. Using this device, we demonstrate stiffness augmentation of the human knee joint in a sit to stand task. The experimental results indicate that the proposed device is able to assist a human by reducing muscle activity while drawing minimal battery power.


Title: Cartman: The Low-Cost Cartesian Manipulator that Won the Amazon Robotics Challenge
Key Words: industrial manipulators  robot vision  warehouse automation  autonomous warehousing  robotic vision  manipulation  Cartesian robot system Cartman  experience-centred design methodology  low-cost cartesian manipulator  Amazon Robotics Challenge  pick-and-place robot  Task analysis  Manipulators  Tools  Grippers  Planning  Robustness 
Abstract: The Amazon Robotics Challenge enlisted sixteen teams to each design a pick-and-place robot for autonomous warehousing, addressing development in robotic vision and manipulation. This paper presents the design of our custom-built, cost-effective, Cartesian robot system Cartman, which won first place in the competition finals by stowing 14 (out of 16) and picking all 9 items in 27 minutes, scoring a total of 272 points. We highlight our experience-centred design methodology and key aspects of our system that contributed to our competitiveness. We believe these aspects are crucial to building robust and effective robotic systems.


Title: Slip Detection with Combined Tactile and Visual Information
Key Words: feature extraction  force control  grippers  image capture  image sequences  learning (artificial intelligence)  manipulators  neural nets  pattern classification  robot vision  tactile sensors  robot arm  grasping positions  slip detection  visual information  robotic manipulation  deep neural network  GelSight tactile sensor  grasping forces  DNN training  grasp stability  tactile information  gripper  camera-based tactile sensor  image sequences  image capture  Grippers  Grasping  Cameras  Tactile sensors  Force 
Abstract: Slip detection plays a vital role in robotic manipulation and it has long been a challenging problem in the robotic community. In this paper, we propose a new method based on deep neural network (DNN) to detect slip. The training data is acquired by a GelSight tactile sensor and a camera mounted on a gripper when we use a robot arm to grasp and lift 94 daily objects with different grasping forces and grasping positions. The DNN is trained to classify whether a slip occurred or not. To evaluate the performance of the DNN, we test 10 unseen objects in 152 grasps. A detection accuracy as high as 88.03 % is achieved. It is anticipated that the accuracy can be further improved with a larger dataset. This method is beneficial for robots to make stable grasps, which can be widely applied to automatic force control, grasping strategy selection and fine manipulation.


Title: Realtime State Estimation with Tactile and Visual Sensing. Application to Planar Manipulation
Key Words: end effectors  feedback  object detection  pose estimation  position control  robot vision  SLAM (robots)  state estimation  touch (physiological)  tactile input  visual input  incremental smoothing  visual sensing  contact sensing  end-effector  realtime state estimation  robust object state estimation  visual sensor  visual feedback  object shapes  object manipulation  incremental smoothing and mapping  iSAM  planar manipulation  object poses estimation  Robot sensing systems  Visualization  Cost function  State estimation  Cameras 
Abstract: Accurate and robust object state estimation enables successful object manipulation. Visual sensing is widely used to estimate object poses. However, in a cluttered scene or in a tight workspace, the robot's end-effector often occludes the object from the visual sensor. The robot then loses visual feedback and must fall back on open-loop execution. In this paper, we integrate both tactile and visual input using a framework for solving the SLAM problem, incremental smoothing and mapping (iSAM), to provide a fast and flexible solution. Visual sensing provides global pose information but is noisy in general, whereas contact sensing is local, but its measurements are more accurate relative to the end-effector. By combining them, we aim to exploit their advantages and overcome their limitations. We explore the technique in the context of a pusher-slider system. We adapt iSAM's measurement cost and motion cost to the pushing scenario, and use an instrumented setup to evaluate the estimation quality with different object shapes, on different surface materials, and under different contact modes.


Title: Touch-Based Grasp Primitives for Soft Hands: Applications to Human-to-Robot Handover Tasks and Beyond
Key Words: actuators  dexterous manipulators  end effectors  grippers  human-robot interaction  mobile robots  tactile sensors  grasp response  hand adaptability  human inspiration  autonomous grasp sensory-motor primitives  simple touch-based approach  human-robot interaction  soft end effectors  soft robotic hands  adaptable hands  human-to-robot handover tasks  touch-based grasp primitives  soft robotic manipulation  human maneuvering  human wrist  hand closure commands  arm motions  grasping  contact  robotic arm  under-actuated soft anthropomorphic robotic hand  Pisa/IIT SoftHand  Robot sensing systems  Robot kinematics  Acceleration  Wrist  Task analysis 
Abstract: Recently, the avenue of adaptable, soft robotic hands has opened simplified opportunities to grasp different items; however, the potential of soft end effectors (SEEs) is still largely unexplored, especially in human-robot interaction. In this paper, we propose, for the first time, a simple touch-based approach to endow a SEE with autonomous grasp sensory-motor primitives, in response to an item passed to the robot by a human (human-to-robot handover). We capitalize on human inspiration and minimalistic sensing, while hand adaptability is exploited to generalize grasp response to different objects. We consider the Pisa/IIT SoftHand (SH), an under-actuated soft anthropomorphic robotic hand, which is mounted on a robotic arm and equipped with Inertial Measurement Units (IMUs) on the fingertips. These sensors detect the accelerations arisen from contact with external items. In response to a contact, the hand pose and closure are planned for grasping, by executing arm motions with hand closure commands. We generate these motions from human wrist poses acquired from a human maneuvering the SH to grasp an object from a table. We obtained 86% of successful grasps, considering many objects passed to the SH in different manners. We also tested our techniques in preliminary experiments, where the robot moved to autonomously grasp objects from a surface. Results are positive and open interesting perspectives for soft robotic manipulation.


Title: Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning
Key Words: decision theory  graph theory  learning (artificial intelligence)  Markov processes  mobile robots  navigation  path planning  probability  search problems  control problem  single follower robot  visual contact  moving target  plausible predictions  predictive models  discrete hypotheses  combinatorial search  physical space  model target behavior  learned navigation reward function  semantic terrain features  search methods  predictive pursuit algorithm  multiple satellite maps  simulation scenarios  inverse reinforcement learning  long term behavior  short term behavior  planning pursuit paths  locations  graph representation  latent destination  position  POMDP solvers  domain specific knowledge  model based probabilistic pursuit  Navigation  Planning  Trajectory  Visualization  Entropy  Predictive models  Learning (artificial intelligence) 
Abstract: We address the integrated prediction, planning, and control problem that enables a single follower robot (the photographer) to quickly re-establish visual contact with a moving target (the subject) that has escaped the follower's field of view. We deal with this scenario, which reactive controllers are typically ill-equipped to handle, by making plausible predictions about the long- and short-term behavior of the target, and planning pursuit paths that will maximize the chance of seeing the target again. At the core of our pursuit method is the use of predictive models of target behavior, which help narrow down the set of possible future locations of the target to a few discrete hypotheses, as well as the use of combinatorial search in physical space to check those hypotheses efficiently. We model target behavior in terms of a learned navigation reward function, using Inverse Reinforcement Learning, based on semantic terrain features of satellite maps. Our pursuit algorithm continuously predicts the latent destination of the target and its position in the future, and relies on efficient graph representation and search methods in order to navigate to locations at which the target is most likely to be seen at an anticipated time. We perform extensive evaluation of our predictive pursuit algorithm over multiple satellite maps, thousands of simulation scenarios, against state-of-the art MDP and POMDP solvers. We show that our method significantly outperforms them by exploiting domain-specific knowledge, while being able to run in real-time.


Title: U sing a UAV for Destructive Surveys of Mosquito Population
Key Words: autonomous aerial vehicles  diseases  graph theory  integer programming  path planning  travelling salesman problems  destructive surveys  mosquito population  electrified screen  UAV path  mosquito elimination  trajectory planning  traveling salesman problem  milling with turn cost  lawn mower problem  grid graph  optimized energy consumption  Integer Programming  mosquito-borne diseases  mosquito-killing UAV  Unmanned aerial vehicles  Sociology  Statistics  Global Positioning System  Robots  Monitoring  Wind tunnels 
Abstract: This paper introduces techniques for mosquito population surveys in the field using electrified screens (bug zappers) mounted to a UAV. Instrumentation on the UAV logs the UAV path and the GPS location, altitude, and time of each mosquito elimination. Hardware experiments with a UAV equipped with an electrified screen provide real-time measurements of (former) mosquito locations and mosquito-free volumes. Planning a trajectory for the UAV that maximizes the number of mosquito kills is related to the Traveling Salesman Problem, the Lawn Mower Problem and, most closely, Milling with Turn Cost. We reduce this problem to considering variants of covering a grid graph with minimum turn cost, corresponding to optimized energy consumption. We describe an exact method based on Integer Programming that is able to compute provably optimal instances with over 1,500 pixels. These solutions are then implemented on the UAV.


Title: Optical Fiber-Based Sensor for Assessing Electric Current in Unmanned Aerial Vehicles with ROS Interface
Key Words: autonomous aerial vehicles  diffraction gratings  electric current measurement  fibre optic sensors  permanent magnets  Robot Operating System package  hysteresis  optical fiber-based sensor  sensing technology  unmanned aerial vehicles electric motors  ROS interface  sensing system  electric current measurements  linear electric current sensitivity  flexible sensing scheme  permanent Neodymium magnet  Long-Period Fiber Grating sensor  current 0.22 A  current 0.08 A  Robot sensing systems  Current  Optical fiber sensors  Optical fibers  Current measurement  Fiber gratings 
Abstract: In this work, we propose and experimentally validate a novel optical fiber-based sensor for monitoring and assessing electric current in unmanned aerial vehicles electric motors. The proposed sensing technology combines a Long-Period Fiber Grating sensor and a permanent Neodymium magnet, providing a small and flexible sensing scheme deployed inside the arm of the drone. The experimental results show that good accuracy and linear electric current sensitivity of 0.21 A and 2.08 A/nm, respectively, were achieved with electric current measurements at a 100 Hz sampling rate. The values of hysteresis and repeatability achieved were 0.08 A and 0.22 A, respectively. Finally, a Robot Operating System package for interfacing with the sensing system was developed and tested, which greatly simplifies the deployment of the sensor in robotics applications.


Title: A Lightweight, Compliant, Contact-Resistance-Based Airflow Sensor for Quadcopter Ground Effect Sensing
Key Words: aerodynamics  aerospace components  aircraft testing  autonomous aerial vehicles  design engineering  elastomers  flow measurement  flow sensors  helicopters  turbulence  wind tunnels  winds speeds  Crazyflie 2.0 quadcopter  turbulent flow  thrust level  aircraft testing  autonomous aerial vehicles  design engineering  quadcopter ground effect sensing  compliant contact-resistance-based airflow sensor  lightweight contact-resistance-based airflow sensor  wind tunnel characterization  sensor deflection  air flow speeds  flexible conductive pillar  elastomeric contact-resistance-based airflow sensor  nonobstructive solutions  power 42.0 muW  Wind speed  Robot sensing systems  Wind tunnels  Fabrication  Market research  Hair 
Abstract: Sensors to measure quadcopter ground effect are often relatively large, heavy, and require significant power, which restricts their applicability when it comes to small quadcopters and other aircraft that require lightweight and non-obstructive solutions. This paper presents the design of an elastomeric contact-resistance-based airflow sensor to measure ground effect with a mass of approximately 0.04 g and a power draw of 42 μW when in operation. It uses a rigid flap attached to the top of a flexible conductive pillar (CNT/PDMS), which deflects with varying winds speeds. A simple model is presented to describe expected trends between air flow speeds and sensor deflection and is compared with a wind tunnel characterization of the sensor for varying airflows. The sensor is characterized in a wind tunnel to identify a minimum airflow necessary for sensor functionality. Finally, sensors are attached to a Crazyflie 2.0 (Bitcraze) quadcopter and tested for performance in detecting ground effect, where there is a clear trend between sensor output and the intensity of the turbulent flow, related to proximity to ground and thrust level.


Title: Experiments in Fast, Autonomous, GPS-Denied Quadrotor Flight
Key Words: aircraft control  aircraft navigation  autonomous aerial vehicles  collision avoidance  helicopters  mobile robots  mixed indoor environments  outdoor environments  specific component technologies  high speed navigation capability  high speed autonomous flights  obstacle rich environments  GPS-denied quadrotor flight  unknown environments  robotics  fast computation  tight integration  subsystems  latency  perception-action loop  aerial robots  payload capacity  navigation system  quadrotor system  Cameras  Navigation  Robot vision systems  Laser radar  Payloads 
Abstract: High speed navigation through unknown environments is a challenging problem in robotics. It requires fast computation and tight integration of all the subsystems on the robot such that the latency in the perception-action loop is as small as possible. Aerial robots add a limitation of payload capacity, which restricts the amount of computation that can be carried onboard. This requires efficient algorithms for each component in the navigation system. In this paper, we describe our quadrotor system which is able to smoothly navigate through mixed indoor and outdoor environments and is able to fly at speeds of more than 18 m/s. We provide an overview of our system and details about the specific component technologies that enable the high speed navigation capability of our platform. We demonstrate the robustness of our system through high speed autonomous flights and navigation through a variety of obstacle rich environments.


Title: A Self-contained Teleoperated Quadrotor: On-Board State-Estimation and Indoor Obstacle Avoidance
Key Words: autonomous aerial vehicles  cameras  collision avoidance  distance measurement  feedback  Global Positioning System  helicopters  image sequences  Kalman filters  mobile robots  path planning  probability  sensors  state estimation  telerobotics  tracking  on-board state-estimation  indoor obstacle avoidance  unmanned aerial vehicles  GPS signal  teleoperated quadrotor UAV platform  onboard miniature computer  linear velocity  Kalman filter integration  inertial flow  optical flow  depth measurements  robo-centric obstacle model  collision-free navigation  distance measurements  cramped spaces  sensors  tracking  RGB-D camera  visual feedback  probabilistic  Collision avoidance  Robot sensing systems  Estimation  Cameras  Robot kinematics 
Abstract: Indoor operation of unmanned aerial vehicles (UAV s) poses many challenges due to the lack of GPS signal and cramped spaces. The presence of obstacles in an unfamiliar environment requires reliable state estimation and active algorithms to prevent collisions. In this paper, we present a teleoperated quadrotor UAV platform equipped with an onboard miniature computer and a minimal set of sensors for this task. The platform is capable of highly accurate state-estimation, tracking of desired velocity commanded by the user and ensuring collision-free navigation. The robot estimates its linear velocity through a Kalman filter integration of inertial and optical flow (OF) readings with corresponding distance measurements. An RGB-D camera serves the purpose of providing visual feedback to the operator and depth measurements to build a probabilistic, robo-centric obstacle model, allowing the robot to avoid collisions. The platform is thoroughly validated in experiments in an obstacle rich environment.


Title: Safe Teleoperation of Dynamic UAVs Through Control Barrier Functions
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  helicopters  human-robot interaction  Lyapunov methods  quadratic programming  assistive training solution  safe human teleoperated flight  control approach  motion capture environment  safe teleoperation  control barrier functions  human operators  highly dynamic systems  constrained environment  quadrotor systems  potential obstacles  presented supervisory controller  safety constraints  dynamic UAV  exponential control barrier function  Safety  Trajectory  Collision avoidance  Vehicle dynamics  Dynamics  Robots  Task analysis 
Abstract: This paper presents a method for assisting human operators to teleoperate highly dynamic systems such as quadrotors inside a constrained environment with safety guarantees. Our method enables human operators to focus on manually operating and flying quadrotor systems without the need to focus on avoiding potential obstacles. This is achieved with the presented supervisory controller overriding human input to enforce safety constraints when necessary. This method can be used as an assistive training solution for novice pilots to begin flying quadrotors without crashing them. Our supervisory controller uses an Exponential control barrier function based quadratic program to achieve safe human teleoperated flight. We demonstrate and validate our control approach through several experiments with multiple users with varying skill levels for three different scenarios of a quadrotor flying in a motion capture environment with virtual and physical constraints.


