total paper: 159
Title: DroneEARS: Robust Acoustic Source Localization with Aerial Drones
Key Words: acoustic signal processing  array signal processing  autonomous aerial vehicles  sensor arrays  DroneEARS  robust acoustic source localization  aerial drones  microaerial vehicles  high value mobile sensing assets  external sensing scene  acoustic clues  MAV auditory system  robust acoustic localization system  MAV propeller units  sensor arrays  binaural sensing system  geo-locating sound sources  sparse sensor array design  platform constraints  severe ego-noise  received signal-to-noise ratio  source localization accuracy  physical space-of-interest  mobility-aided beamforming  Acoustics  Robot sensing systems  Sensor arrays  Signal to noise ratio  Array signal processing  Propellers 
Abstract: Micro aerial vehicles (MAVs), an emerging class of aerial drones, are fast turning into high value mobile sensing assets. While MAVs have a large sensory gamut at their disposal; vision continues to dominate the external sensing scene, with limited usability in scenarios that offer acoustic clues. Therefore, we endeavor to provision a MAV auditory system (i.e., ears); and as part of this goal, our preliminary aim is to develop a robust acoustic localization system for detecting sound sources in the physical space-of-interest. However, devising this capability is extremely challenging due to strong ego-noise from the MAV propeller units, which is both wideband and non-stationary. It is well known that beamformers with large sensor arrays can overcome high noise levels; but in an attempt to cater to the platform (i.e., space, payload and computation) constraints of a MAV, we propose DroneEARS: a binaural sensing system for geo-locating sound sources. It combines the benefits of sparse (two elements) sensor array design (for meeting the platform constraints), and our proposed mobility-aided beamforming (for overcoming the severe ego-noise and its other complex characteristics) to significantly enhance the received signal-to-noise ratio (SNR). We demonstrate the efficacy of DroneEARS by empirical evaluations, and show that it provides a SNR improvement of 15-18 dB compared to many conventional and widely used techniques. This SNR gain translates to a source localization accuracy of approximately 40 cm within a scan region of 6m × 3m , that is, one order of magnitude better than competing methodologies.


Title: Trajectory Generation for Minimum Closed-Loop State Sensitivity
Key Words: autonomous aerial vehicles  closed loop systems  mobile robots  Monte Carlo methods  optimisation  controller dynamics  reference trajectory  system trajectories  trajectory optimization problems  closed-loop sensitivity  trajectory generation  minimum closed-loop state sensitivity  dynamical system fulfil  nominal parameters  closed-loop trajectory  system/controller pair  control inputs  system states  robotic systems  Monte Carlo simulations  unicycle  quadrotor UAV  Trajectory  Sensitivity  Task analysis  Optimization  Uncertainty  Robots  Robustness 
Abstract: In this paper we propose a novel general method to let a dynamical system fulfil at best a control task when the nominal parameters are not perfectly known. The approach is based on the introduction of the novel concept of closed-loop sensitivity, a quantity that relates parameter variations to deviations of the closed-loop trajectory of the system/controller pair. This new definition takes into account the dependency of the control inputs from the system states and nominal parameters as well as from the controller dynamics. The reference trajectory to be tracked is taken as optimization variable, and the dynamics of both the sensitivity and of its gradient are computed analytically along the system trajectories. We then show how this computation can be effectively exploited for solving trajectory optimization problems aimed at generating a reference trajectory that minimizes a norm of the closed-loop sensitivity. The theoretical results are validated via an extensive campaign of Monte Carlo simulations for two relevant robotic systems: a unicycle and a quadrotor UAV.


Title: Online Safe Trajectory Generation for Quadrotors Using Fast Marching Method and Bernstein Basis Polynomial
Key Words: autonomous aerial vehicles  clutter  computational geometry  convex programming  helicopters  indoor environment  mobile robots  path planning  polynomials  search problems  state estimation  trajectory control  online safe trajectory generation  Bernstein basis polynomial  onboard state estimation  velocity field  Euclidean signed distance field  time allocation  flight corridor  piecewise Bézier curves  outdoor environments  convex programs  autonomous navigation  marching-based path searching method  light-weight quadrotor platform  online quadrotor motion planning  cluttered indoor environments  ESDF  open-source package  Resource management  Planning  Trajectory optimization  Safety  Autonomous robots 
Abstract: In this paper, we propose a framework for online quadrotor motion planning for autonomous navigation in unknown environments. Based on the onboard state estimation and environment perception, we adopt a fast marching-based path searching method to find a path on a velocity field induced by the Euclidean signed distance field (ESDF) of the map, to achieve better time allocation. We generate a flight corridor for the quadrotor to travel through by inflating the path against the environment. We represent the trajectory as piecewise Bézier curves by using Bernstein polynomial basis and formulate the trajectory generation problem as typical convex programs. By using Bézier curves, we are able to bound positions and higher order dynamics of the trajectory entirely within safe regions. The proposed motion planning method is integrated into a customized light-weight quadrotor platform and is validated by presenting fully autonomous navigation in unknown cluttered indoor and outdoor environments. We also release our code for trajectory generation as an open-source package.


Title: The Dubins Traveling Salesman Problem with Neighborhoods in the Three-Dimensional Space
Key Words: Three-dimensional displays  Trajectory  Atmospheric modeling  Airplanes  Solid modeling  Two dimensional displays  Optimization 
Abstract: We introduce an extension of the Dubins Traveling Salesman Problem with Neighborhoods into the 3D space in which a fixed-wing aerial vehicle is requested to visit a set of target regions while the vehicle motion constraints are satisfied, i.e., the minimum turning radius and maximum climb and dive angles. The primary challenge is to address both the combinatorial optimization part of finding the sequence of target visits and the continuous optimization part of the final trajectory determination. Due to its high complexity, we propose to address both parts of the problem separately by a decoupled approach in which the sequence is determined by a new distance function designed explicitly for the utilized 3D Dubins Airplane model. The final trajectory is then found by a local optimization which improves the solution quality. The proposed approach provides significantly better solutions than using Euclidean distance in the sequencing part of the problem. Moreover, the found solutions are of the competitive quality to the sampling-based algorithm while its computational requirements are about two orders of magnitude lower.


Title: Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  multi-robot systems  path planning  trajectory control  motion planning  robotics community  FaSTrack  sensor measurements  meta-planning notion  Crazyflie 2.0 quadrotor  adaptive realtime safe trajectory planning  safety guarantee  online planner  offline computation  motion plans  modular safety guarantee  Planning  Trajectory  Safety  Real-time systems  Robustness  Navigation  Computational modeling 
Abstract: Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of “meta-planning” in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.


Title: Cross-Layer Retrofitting of UAVs Against Cyber-Physical Attacks
Key Words: autonomous aerial vehicles  helicopters  security of data  vehicle dynamics  BlueBox  cyber-physical attacks  cyber-physical platform  unmanned aerial vehicles  security threats  sophisticated attacks  generic security framework  vehicle dynamics  cross-layer retrofitting  UAV  off-the-shelf quadcopter  controller  motors  operating system  vehicle control system  Software  Hardware  Security  Sensor fusion  Vehicle dynamics  Control systems 
Abstract: As a rapidly growing cyber-physical platform, unmanned aerial vehicles are facing more security threats as their capabilities and applications continue to expand. Adversaries with detailed knowledge about the vehicle could orchestrate sophisticated attacks that are not easily detected or handled by the vehicle's control system. In this work, we purpose a generic security framework, termed BlueBox, capable of detecting and handling a variety of cyber-physical attacks. To demonstrate an application of BlueBox in practice, we retrofitted an off-the-shelf quadcopter. A series of attacks were then launched by embedding malicious code in the control software and by altering the vehicle's hardware with the specific targeting of sensors, controller, motors, vehicle dynamics, and operating system. Experimental results verified that BlueBox was capable of both detecting a variety of cyber-physical attacks, while also providing the means in which to recover from such attacks.


Title: Investigation of Communicative Flight Paths for Small Unmanned Aerial Systems * This work was supported by NSF NRI 1638099
Key Words: aircraft control  autonomous aerial vehicles  humanoid robots  human-robot interaction  human-humanoid robot interactions  avian flight paths  sUAS manufacturers  sUAS flight paths  human-robot interaction  small Unmanned Aerial System flight paths  human-human interactions  Biology  Humanoid robots  Stakeholders  Batteries  Aerospace electronics  Service robots 
Abstract: This project seeks to generate small Unmanned Aerial System (sUAS) flight paths that are broadly understood by the general population and can communicate states about both the sUAS and its understanding of the world. Previous work in sUAS flight paths has sought to communicate intent, destination, or emotion of the system without focusing on concrete states (e.g., low battery, landing, etc.). This work leverages biologically-based flight paths and experimental methodologies from human-human and human-humanoid robot interactions to assess the understanding of avian flight paths to communicate sUAS states to novice users. If successful, this work should inform: the human-robot interaction community about the perception of flight paths, sUAS manufacturers on how their systems could communicate with both operators and bystanders, and end users on ways to communicate with others when flying systems in public spaces. General design implications and future directions of work are suggested to build on the results here, which suggest that novice users gravitate towards labels they understand (draw attention and landing) while avoiding more technical labels (lost sensor).


Title: ModQuad: The Flying Modular Structure that Self-Assembles in Midair
Key Words: attitude control  autonomous aerial vehicles  mobile robots  multi-robot systems  robot dynamics  self-assembly  midair  modular robotic structure  self-assemble  agile flying modules  quadrotor platform  ModQuad swarm  modular flying structures  decentralized modular attitude controller  docking method  flying modular structure  flying structure assembling  cooperative flying method  Robot kinematics  Rotors  Buildings  Payloads  Shape  Task analysis 
Abstract: We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.


Title: Autonomous Battery Exchange of UAVs with a Mobile Ground Base
Key Words: autonomous aerial vehicles  control engineering computing  mobile robots  multi-robot systems  planetary rovers  small scale UAV  autonomous battery exchange operation  autonomous operations  landed UAV  ground rover  autonomous outdoor experiments  collaborative software framework  robotic systems  persistence  battery exchange mechanism  service station  robotic arm  mobile ground base  Batteries  Task analysis  Actuators  Robot kinematics  Planning  Manipulators 
Abstract: This paper presents the autonomous battery exchange operation for small scale UAVs, using a mobile ground base that carries a robotic arm and a service station containing the battery exchange mechanism. The goal of this work is to demonstrate the means to increase the autonomy and persistence of robotic systems without requiring human intervention. The design and control of the system and its components are presented in detail, as well as the collaborative software framework used to plan and execute complex missions. Finally, the results of autonomous outdoor experiments are presented, in which the ground rover successfully localizes, retrieves, services, and deploys the landed UAV, proving its capacity to extend and enhance autonomous operations.


Title: Local Behavior-Based Navigation in Rough Off-Road Scenarios Based on Vehicle Kinematics
Key Words: mobile robots  off-road vehicles  path planning  robot dynamics  robot kinematics  trajectory control  elevation grid map  robot orientation  behavior-based control paradigm  rough terrains  traversability  occupancy maps  on-road local navigation approaches  trajectory candidates  behavior-based local navigation approach  vehicle kinematics  rough off-road scenarios  Wheels  Navigation  Trajectory  Robot sensing systems  Axles  Three-dimensional displays  robotics  off-road navigation  behavior-based control  tentacles 
Abstract: This paper describes a novel behavior-based local navigation approach for rough off-road scenarios. Trajectory candidates are generated based on vehicle kinematics and dynamics as well as the desired global trajectory. In contrast to on-road local navigation approaches, the work at hand proposes the use of a shiftable elevation grid map instead of occupancy maps since traversability in rough terrains does not only depend on location, but also on the robot's orientation. The traversability is evaluated by determining tire contact points with the terrain to take various different safety and efficiency aspects like underbody collisions and rollover risk into account. By exploiting the behavior-based control paradigm, the navigation approach can be easily extended and its robustness is shown in experimental evaluations using an Unimog U5023.


Title: A Parametric MPC Approach to Balancing the Cost of Abstraction for Differential-Drive Mobile Robots
Key Words: mobile robots  motion control  predictive control  Parametric MPC approach  differential-drive mobile robots  three-state unicycle model  two-state single-integrator model  maneuverability costs  control signal  Parametric Model Predictive Control method  Mobile robots  Wheels  Robot kinematics  Predictive control  Measurement  Parametric statistics 
Abstract: When designing control strategies for differential-drive mobile robots, one standard tool is the consideration of a point at a fixed distance along a line orthogonal to the wheel axis instead of the full pose of the vehicle. This abstraction supports replacing the non-holonomic, three-state unicycle model with a much simpler two-state single-integrator model (i.e., a velocity-controlled point). Yet this transformation comes at a performance cost, through the robot's precision and maneuverability. This work contains derivations for expressions of these precision and maneuverability costs in terms of the transformation's parameters. Furthermore, these costs show that only selecting the parameter once over the course of an application may cause an undue loss of precision. Model Predictive Control (MPC) represents one such method to ameliorate this condition. However, MPC typically realizes a control signal, rather than a parameter, so this work also proposes a Parametric Model Predictive Control (PMPC) method for parameter and sampling horizon optimization. Experimental results are presented that demonstrate the effects of the parameterization on the deployment of algorithms developed for the single-integrator model on actual differential-drive mobile robots.


Title: Spherical Visual Gyroscope for Autonomous Robots Using the Mixture of Photometric Potentials
Key Words: aerospace components  attitude control  autonomous aerial vehicles  cameras  end effectors  gyroscopes  image sensors  image sequences  least squares approximations  mobile robots  nonlinear programming  robot vision  robust control  spherical visual gyroscope  autonomous robots  direct omnidirectional visual gyroscope  mobile robotic platforms  camera-robot  pixel intensities  extended convergence domain  spherical image sequences  robot arm  3D orientation  Mixture of Photometric Potentials  image-similarity measure  nonlinear least-squares optimization scheme  twin-fisheye camera  end-effector  fixed-wing UAV  robust attitude estimates  Cameras  Visualization  Gyroscopes  Robot vision systems  Three-dimensional displays  Convergence 
Abstract: In this paper, we present a new direct omnidirectional visual gyroscope for mobile robotic platforms. The gyroscope estimates the 3D orientation of a camera-robot by comparing the current spherical image with that acquired at a reference pose. By transforming pixel intensities into a Mixture of Photometric Potentials, we introduce a novel image-similarity measure which can be seamlessly integrated into a classical nonlinear least-squares optimization scheme, offering an extended convergence domain. Our method provides accurate and robust attitude estimates, and it is easy-to-use since it involves a single tuning parameter, the width of the photometric potentials (Gaussian functions, in this work) controlling the power of attraction of each pixel. The visual gyroscope has been successfully tested on spherical image sequences generated by a twin-fisheye camera mounted on the end-effector of a robot arm and on a fixed-wing UAV.


Title: Correlation Flow: Robust Optical Flow Using Kernel Cross-Correlators
Key Words: aircraft control  aircraft navigation  autonomous aerial vehicles  cameras  helicopters  mobile robots  position control  correlation flow  reliable velocity estimation  robust trajectory estimation  robust optical flow  kernel cross-correlators  position estimation  autonomous robot navigation  autonomous navigation  kernel cross-correlator based algorithm  monocular camera  ROS framework  yaw rate  Kernel  Optical sensors  Optical imaging  Correlation  Correlators  Robustness  Estimation 
Abstract: Robust velocity and position estimation is crucial for autonomous robot navigation. The optical flow based methods for autonomous navigation have been receiving increasing attentions in tandem with the development of micro unmanned aerial vehicles. This paper proposes a kernel cross-correlator (KCC) based algorithm to determine optical flow using a monocular camera, which is named as correlation flow (CF). Correlation flow is able to provide reliable and accurate velocity estimation and is robust to motion blur. In addition, it can also estimate the altitude velocity and yaw rate, which are not available by traditional methods. Autonomous flight tests on a quadcopter show that correlation flow can provide robust trajectory estimation with very low processing power. The source codes are released based on the ROS framework.


Title: Validation of the Robot Rendezvous and Grasping Manoeuvre Using Microgravity Simulators
Key Words: aerospace robotics  artificial satellites  control system synthesis  end effectors  industrial robots  multi-robot systems  path planning  space debris  space vehicles  robot rendezvous  grasping manoeuvre  unmanned chaser satellite  performing rendezvous  grasping manoeuvres  space debris  manoeuvres high disturbances  manipulator arm end-effector  robotic subsystem  chaser rendezvous  planar air-bearing microgravity simulators  industrial robots  specified test-bed system  Manipulators  Satellites  Orbits  Space vehicles  Service robots  Control systems 
Abstract: Robots mounted on an unmanned chaser satellite could be used for performing rendezvous and grasping manoeuvres in order to repair satellites or remove space debris from orbit. Use of manipulators for such purposes is challenging, since the performed task need to be done autonomously, accurately and with high level of robustness. During manoeuvres high disturbances might appear e.g. due to contact between the manipulator arm end-effector and the target spacecraft. In this paper an approach for validation of the robotic subsystem during chaser rendezvous and grasping manoeuvre has been shown. Two type of testbed systems were used: planar air-bearing microgravity simulators and a test-bed system with industrial robots. The proposed approach took advantage of possible replacement of particular subsystem in reference model or reference hardware in specified test-bed system. The list of tests performed are included in the paper.


Title: Collision-Based Contact Mode Estimation for Dynamic Rigid Body Capture
Key Words: aerospace robotics  collision avoidance  manipulator dynamics  mobile robots  motion estimation  multi-robot systems  particle filtering (numerical methods)  robot vision  space debris  vehicle dynamics  space debris  Brach collision model  collision-based contact mode estimation  particle filter  pre-capture phase  motion estimation error  reasonable computation resources  collision-triggered filter  moving rigid body  force-torque sensor  dynamic rigid body capture  Estimation  Robot sensing systems  Computational modeling  Collision avoidance  Predictive models  Bayes methods 
Abstract: This paper proposes real-time collision-based contact mode estimation with only a force-torque sensor for capturing a moving rigid body. The contact modes are defined for determining when to generate the signal to close the robotic hand for establishing object closure. In our particle filter approach, collision-triggered filter is used to determine the contact mode with the least amount of computation. Brach's collision model is used for our collision model-based approach for a rigid body because it is computationally light-weighted and enables the sampling of three collision properties for the particle filter. The validity of our method is experimentally demonstrated by achieving the highest success rate using the reasonable computation resources required (average of 3.9 milliseconds and worst of 6.1 milliseconds with our setup), and verifying each computation resource (or number of particles) based on the size of motion estimation error in the pre-capture phase.


Title: Robust Visual Localization for Hopping Rovers on Small Bodies
Key Words: cameras  planetary rovers  pose estimation  robot vision  SLAM (robots)  space vehicles  visual SLAM algorithms  ORB-SLAM2  orbiting primary spacecraft  onboard visual simultaneous localization and mapping  visual SLAM implementation  wide field of view camera  off-nadir camera pointing angles  narrow FOV camera  orbiting spacecraft  visual appearance  high-contrast shadows  hopping rover  illumination angles  Solar System bodies  collaborative visual localization method  robust visual localization  time 1.0 hour to 12.0 hour  Cameras  Space vehicles  Visualization  Simultaneous localization and mapping  Optimization  Lighting  Solar system 
Abstract: We present a collaborative visual localization method for rovers designed to hop and tumble across the surface of small Solar System bodies, such as comets and asteroids. In a two-phase approach, an orbiting primary spacecraft first maps the surface of a body by capturing images from various poses and illumination angles; these images are processed to create a prior map of 3D landmarks. In the second phase, a hopping rover is deployed to the surface where it uses a camera to relocalize to the prior map and to perform onboard visual simultaneous localization and mapping (SLAM). Small bodies present several unique challenges to existing visual SLAM algorithms, such as high-contrast shadows that move quickly over the surface due to the short (e.g. 1-12 hour) rotational periods, and large changes in visual appearance between orbit and the surface, where image scale varies by many orders of magnitude (kilometers to centimeters). In this work, we describe how to augment ORB-SLAM2-a state of the art visual SLAM implementation-to handle large variations in illumination by fusing prior images with varying illumination angles. We demonstrate how a hopping rover can use a wide field of view (FOV) camera to relocalize to prior maps captured by an orbiting spacecraft with a narrow FOV camera, and how the growth of pose and scale errors can be bounded by periodic loop closures during large hops. The proposed method is evaluated with sequences of images captured around a mock asteroid; it is shown to be robust to varying illumination angles, scene scale changes, and off-nadir camera pointing angles.


Title: Bounding Drift in Cooperative Localisation Through the Sharing of Local Loop Closures
Key Words: graph theory  mobile robots  robot vision  SLAM (robots)  direct intervehicle observations  fuses single vehicle SLAM  cooperative localisation  data association  map data  local subgraphs  shared states  localisation accuracy  bounding drift  local loop closures  robotic scenarios  data consistency  bandwidth limitations  single vehicle visual SLAM framework  Information matrix  Simultaneous localization and mapping  Bandwidth  Jacobian matrices  Visualization  Message systems 
Abstract: Handling loop closures and intervehicle observations in cooperative robotic scenarios remains a challenging problem due to data consistency, bandwidth limitations and increased computation requirements. This paper develops a general cooperative localisation and single vehicle Visual SLAM framework that includes direct intervehicle observations and pose to pose loop closures on each vehicle with states shared as required. This fuses single vehicle SLAM with cooperative localisation and avoids data association of map data across limited communication networks. The base problem is developed as a factor graph with each vehicle solving local subgraphs that are split based on intervehicle observations. We modify the order of variable elimination in subgraphs through manipulation of the square-root of the Information matrix to extract updates that include the historic states involved in the loop closures and do not require transmission of other states not involved in the measurement or retransmission of previously shared states. We demonstrate the effect on localisation accuracy and bandwidth using data captured from a set of five robots observing each other and landmarks compared to both single vehicle SLAM, pure cooperative localisation and a centralised solution.


Title: Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming
Key Words: autonomous aerial vehicles  concave programming  knapsack problems  mobile robots  multi-robot systems  stochastic programming  chance-constrained 0-1 knapsack problem  variance-mean plane  deterministic knapsack problems  multirobot team selection problem  optimal chance constrained knapsack problem  2D discrete optimization problem  risk-averse knapsack problem  Robots  Optimization  Random variables  Task analysis  Batteries  Linear programming  Approximation algorithms 
Abstract: Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.


Title: Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication
Key Words: aerospace robotics  asymptotic stability  compensation  controllability  distributed control  helicopters  mobile robots  trajectory optimisation (aerospace)  exponential stability  distributed compensation scheme  controllability  local optimization problem  entire assembly  distributed wrench controller  rigidly attached quadrotor aerial robots  multiple quadrotors  subsequent trajectory optimization  output wrench space  control wrench  group control authority  Robot kinematics  Trajectory  Torque  Three-dimensional displays  Payloads  Unmanned aerial vehicles 
Abstract: We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.


Title: Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning
Key Words: cables (mechanical)  dynamic programming  mobile robots  multi-robot systems  optimal control  path planning  planning problems  aerial robots  transportation task  ground robots  nonrigid inextensible cables  heterogeneous multirobot system  multiple aerial vehicles  general constrained optimal planning problem  multiple ground vehicles  cooperative object transportation  modeling problems  dynamic programming  Vehicle dynamics  Manipulators  Load modeling  Unmanned aerial vehicles  Dynamics 
Abstract: In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.


Title: Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints
Key Words: autonomous aerial vehicles  delays  distributed control  mobile robots  multi-robot systems  intermittent communications  high-level decision skills  distributed decision architecture  hybrid planner  distributed execution algorithm  delays  surveillance missions  ground robots  heterogeneous robots  field multirobot missions  autonomous aerial robot  unavoidable disturbances  integrating planning and execution  communication constrains  time constraints  decentralized repairs  Maintenance engineering  Planning  Computer architecture  Robot kinematics  Surveillance  Delays 
Abstract: Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.


Title: Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning
Key Words: learning (artificial intelligence)  mobile robots  path planning  socially compliant navigation  raw depth inputs  mobile robots  socially compliant manner  generative adversarial imitation learning strategy  raw sensory input  GAIL-based approach  behavior cloning policy  social force model  Force  Navigation  Cloning  Sensors  Mobile robots  Learning (artificial intelligence)  Visualization 
Abstract: We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.


Title: Robot Navigation from Human Demonstration: Learning Control Behaviors
Key Words: learning (artificial intelligence)  mobile robots  optimal control  robot navigation  human collaborators  dynamic environments  disaster recovery  unmanned ground vehicle  UGV  fast field adaptation  minimal human supervision  visual perception  inverse optimal control  minimal human supervisory examples  navigation behavior  real-world environment  minimal human demonstration  Navigation  Robots  Trajectory  Entropy  Training  Collision avoidance  Task analysis 
Abstract: When working alongside human collaborators in dynamic environments such as a disaster recovery, an unmanned ground vehicle (UGV) may require fast field adaptation to perform its duties or learn novel tasks. In disaster recovery situations, personnel and equipment are constrained, so training must be accomplished with minimal human supervision. In this paper, we introduce a novel framework which uses learned visual perception and inverse optimal control trained with minimal human supervisory examples. This approach is used to learn to mimic navigation behavior and is demonstrated through extensive evaluation in a real-world environment. Finally, we demonstrate the ability to learn an additional behavior with minimal human demonstration in the field.


Title: Design and Analysis of a Fixed-Wing Unmanned Aerial-Aquatic Vehicle
Key Words: aerospace components  autonomous aerial vehicles  autonomous underwater vehicles  closed loop systems  mobile robots  optimisation  fixed-wing unmanned aerial-aquatic vehicle  fixed-wing vehicle  aerobatic post-stall maneuvers  water-to-air transition execution  direct hybrid trajectory optimization  closed-loop control  Propellers  Vehicle dynamics  Prototypes  Unmanned aerial vehicles  Design tools 
Abstract: In this paper, we describe the design and analysis of a fixed-wing unmanned aerial-aquatic vehicle. Inspired by prior work in aerobatic post-stall maneuvers for fixed-wing vehicles [1], we explore the feasibility of executing a water-to-air transition with a fixed-wing vehicle using almost entirely commercial off-the-shelf components (excluding the fuselage). To do this, we first propose a conceptual design based on observations about the dominant forces and dimensionless analysis. We then further refine this concept by building a design tool based on simplified models to explore the design space. To verify the results of the design tool, we use a higher fidelity model along with a direct hybrid trajectory optimization approach to show via numerical simulation that the water-to-air transition is feasible. Finally, we successfully test our design experimentally by hand-piloting a prototype vehicle through the water-to-air transition and discuss our approach for replacing the human-pilot with closed-loop control.


Title: An Empirical Evaluation of Ground Effect for Small-Scale Rotorcraft
Key Words: aircraft control  autonomous aerial vehicles  helicopters  propellers  rotors  helicopter ground effect  hover performance  multirotor UAV  rotor performance  single-rotor configuration  fixed propellers  propeller configuration  UAV flight controller  flight stability  ground effect  helicopter models  Cheeseman-Bennett model  small-scale rotorcraft  Rotors  Propellers  Mathematical model  Atmospheric modeling  Blades  Helicopters 
Abstract: Ground effect refers to the apparent increase in lift that an aircraft experiences when it flies close to the ground. For helicopters, this effect has been modeled since the 1950's based on the work of Cheeseman and Bennett, perhaps the most common method for predicting hover performance due to ground effect. This model, however, is based on assumptions that do not hold for small-scale rotorcraft because it was developed specifically for conventional helicopters. It is not clear if the Cheeseman-Bennett model can be applied to today's multirotor UAVs. In this paper, we compare the Cheeseman-Bennett model to experimental results for rotor performance due to ground effect in several small-scale multirotor and single-rotor configurations. Experimental findings suggest that some of the conventional thinking surrounding helicopter ground effect cannot be applied directly to rotorcraft using fixed propellers at variable speeds (e.g. multirotors), and that it is necessary to adjust the helicopter models to better reflect the differences in such aircraft. The experimental results for multirotors presented are for multiple propeller configurations, speeds and spacings. Ultimately, this work will facilitate the development of an improved UAV flight controller that can accurately account for ground effect to improve flight stability near surfaces and structures.


Title: Design, Modeling and Control of a Solar-Powered Quadcopter
Key Words: aerodynamics  aerospace control  control system synthesis  energy harvesting  feedback  helicopters  solar powered vehicles  virtualisation  long-endurance missions  aerodynamic  feedback control system  virtual simulation  solar energy harvesting capabilities  solar-powered quadcopter  Solar panels  Prototypes  Batteries  Photovoltaic cells  Payloads  Propellers  Aerodynamics  Solar Energy  Quadcopter  System Design  Vehicle Control 
Abstract: This paper presents the design, modeling, control, and experimental test of a solar-powered quadcopter to allow for long-endurance missions. We first present the design of a large-scale quadcopter that incorporates solar energy harvesting capabilities. Based on the design results, we built the dynamical model of the customized quadcopter with analysis of the aerodynamic influence. A feedback control system is developed for the solar-powered quadcopter that takes into account the wind disturbance and is verified in virtual simulation examples. All parameters used in the modeling and simulations are based on a developed prototype of the solar-powered quadcopter. Flight tests with the prototype are presented to validate the feasibility and theoretical basis of the solar-powered quadcopter.


Title: The UNAV, a Wind-Powered UAV for Ocean Monitoring: Performance, Control and Validation
Key Words: actuators  aerodynamics  aerospace components  aircraft control  autonomous aerial vehicles  autonomous underwater vehicles  drag  hydrodynamics  vehicle dynamics  UNAv  Unmanned Nautical Air-water vehicle  albatrosses  sailboats  wind power  ocean monitoring  wind-powered UAV  multiinput longitudinal flight controller  trim analysis  sailboat  airborne wings  gravity-cancelling force  high lift-to-drag ratio  albatross  span-wise axes  vertical surface-piercing hydrofoil keel  vertical wing-sail  glider-type airframe  Drag  Force  Sea surface  Aerodynamics  Wind  Atmospheric modeling 
Abstract: Wind power is the source of propulsive energy for sailboats and albatrosses. We present the UNAv, an Unmanned Nautical Air-water vehicle, that borrows features from both. It is composed of a glider-type airframe fitted with a vertical wing-sail extending above the center of mass of the system and a vertical surface-piercing hydrofoil keel extending below. The sail and keel are both actuated in pitch about their span-wise axes. Like an albatross, the UNAv is fully streamlined, high lift-to-drag ratio and generates the gravity-cancelling force by means of its airborne wings. Like a sailboat, the UNAv interacts with water and may access the full magnitude of the wind. A trim analysis predicts that a 3.4-meter span, 3 kg system could stay airborne in winds as low as 2.8 m/s (5.5 knots), and travel several times faster than the wind speed. Trim flight requires the ability to fly at extreme low height with the keel immersed in water. For that purpose, a multi-input longitudinal flight controller that leverages fast flap actuation is presented. The flight maneuver is demonstrated experimentally.


Title: Vehicle Detection, Tracking and Behavior Analysis in Urban Driving Environments Using Road Context
Key Words: driver information systems  learning (artificial intelligence)  object detection  object tracking  optical radar  real-time systems  road traffic  road vehicles  sensor fusion  traffic engineering computing  2D Lidar  deep learning  vehicle tracking  Lidar sensor fusion  global map coordinate system  track management  data association  high precision range estimation  monocular camera  robust fusion system  tracking system  real-time vehicle detection  road context  urban driving environments  behavior analysis  Roads  Laser radar  Sensor fusion  Robot sensing systems  Vehicle detection  Estimation  Autonomous vehicles 
Abstract: We present a real-time vehicle detection and tracking system to accomplish the complex task of driving behavior analysis in urban environments. We propose a robust fusion system that combines a monocular camera and a 2D Lidar. This system takes advantage of three key components: robust vehicle detection using deep learning techniques, high precision range estimation from Lidar, and road context from the prior map knowledge. The camera and Lidar sensor fusion, data association and track management are all performed in the global map coordinate system by taking into account the sensors' characteristics. Lastly, behavior reasoning is performed by examining the tracked vehicle states in the lane coordinate system in which the road context is encoded. We validated our approach by tracking a leading vehicle while it performed usual urban driving behaviors such as lane keeping, stop-and-go at intersections, lane changing, overtaking and turning. The leading vehicle was tracked consistently throughout the 2.3 km route and its behavior was classified reliably.


Title: GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation
Key Words: autonomous aerial vehicles  distance measurement  graph theory  Kalman filters  mobile robots  nonlinear filters  optimisation  pose estimation  robot vision  sensor fusion  SLAM (robots)  GOMSF  proprioceptive measurements  exteroceptive measurements  navigation algorithms  agile mobile robots  Unmanned Aerial Vehicles  UAV pose estimation  graph optimization based multisensor fusion  6 Degree-of-Freedom visual-inertial odometry poses  extended Kalman filter  Robot sensing systems  Robot kinematics  Optimization  Pose estimation  Global Positioning System  Time measurement 
Abstract: Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.


Title: Grasp a Moving Target from the Air: System & Control of an Aerial Manipulator
Key Words: autonomous aerial vehicles  force control  manipulator dynamics  mobile robots  motion control  robot vision  rotors  visual servoing  CoM offset motion  center of mass  aerial grasping experiments  aerial vehicle  aerial manipulator control system  independent control structure  hex-rotor  fixed-base manipulator  Manipulator dynamics  Grasping  Control systems  Kinematics  Vehicle dynamics 
Abstract: Grasping a moving target has been investigated extensively for fixed-base manipulator. However, such a task becomes much more challenging when the manipulator is free flying in the air with an UAV. Towards moving target grasping, this paper presents an aerial manipulator system composed of a hex-rotor and a 7-DoF (Degree of Freedom) manipulator. An independent control structure is used in the aerial manipulator control system, i.e., the hex-rotor and the manipulator are controlled separately. In the hex-rotor's controller, the system CoM (Center of Mass) offset motion is used to compensate disturbance of the robotic arm. In the manipulator's controller, the relative kinematics between the target and the aerial vehicle is taken into consideration to grasp the target. At last aerial grasping experiments are conducted to validate the feasibility of the proposed control scheme and the reliability of our aerial manipulator system.


Title: Practical Motion Segmentation for Urban Street View Scenes
Key Words: cameras  image motion analysis  image segmentation  image sequences  traffic engineering computing  video signal processing  generic motion segmentation algorithms  KITTI dataset  video sequence annotation  restricted camera movement  application-specific factors  urban environment  image-based motion segmentation  urban street view scenes  practical motion segmentation  realistic motion segmentation benchmark dataset  Motion segmentation  Trajectory  Computer vision  Cameras  Transmission line matrix methods  Semantics  Computational modeling 
Abstract: Though a long-studied problem, motion segmentation has yet to migrate into practical applications. We argue that a vital step towards that goal lies in addressing motion segmentation for the specific setting of interest. To this end, this paper presents a new approach for image-based motion segmentation in the case of vehicles navigating inside an urban environment. We exploit two application-specific factors - the restricted camera movement and the known type of moving objects - to deal with the two major limiting factors - missing data and strong perspective effects - that affect most previous “generic” motion segmentation algorithms. By constraining the geometry and exploiting known semantic classes in the scene, we achieve much higher accuracy than previous approaches. In addition to the novel algorithm, we contribute a more realistic motion segmentation benchmark dataset for moving platforms by annotating real video sequences from the KITTI dataset. Experiments on this dataset and other synthetic data confirm the effectiveness of the proposed approach.


Title: SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud
Key Words: computer games  feedforward neural nets  image classification  image segmentation  learning (artificial intelligence)  object detection  optical radar  pattern clustering  Grand Theft Auto  video game  autonomous driving  road-objects  semantic segmentation  3D LiDAR point cloud  real-time road-object segmentation  recurrent CRF  realistic training data  LiDAR simulator  extra training data  3D bounding boxes  point-wise segmentation labels  CNN model  instance-level labels  point-wise label map  transformed LiDAR point cloud  convolutional neural networks  SqueezeSeg  end-to-end pipeline  point-wise classification problem  LiDAR point clouds  time 8.2 ms to 9.2 ms  time 3.0 d  Three-dimensional displays  Laser radar  Computational modeling  Pipelines  Autonomous vehicles  Semantics  Clustering algorithms 
Abstract: We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize large amounts of realistic training data. Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime (8.7±0.5 ms per frame), highly desirable for autonomous driving. Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data. Our source code is open-source released1. The paper is accompanied by a video2 containing a high level introduction and demonstrations of this work.


Title: Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments
Key Words: cameras  distance measurement  feature extraction  image classification  image sensors  learning (artificial intelligence)  mobile robots  motion estimation  object detection  pose estimation  robot vision  SLAM (robots)  stereo image processing  self-supervised distractor learning  robust monocular visual odometry  self-supervised approach  distractors  camera images  cluttered urban environments  per-pixel ephemerality mask  depth map  deep convolutional network  monocular visual odometry pipeline  sparse features  dense photometric matching  metric-scale VO  single camera  robust VO methods  odometry drift  egomotion estimation  moving vehicles  urban traffic  vehicle motion  ephemerality  offline multisession mapping approaches  Three-dimensional displays  Cameras  Robustness  Visual odometry  Motion estimation  Entropy  Training data 
Abstract: We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.


Title: Navigating Occluded Intersections with Autonomous Vehicles Using Deep Reinforcement Learning
Key Words: learning systems  mobile robots  navigation  path planning  road vehicles  autonomous vehicles  unsignaled intersections  Deep RL  intersection handling problem  deep reinforcement learning system  occluded intersections  active sensing behaviors  Autonomous vehicles  Automobiles  Machine learning  Safety  Navigation  Learning (artificial intelligence) 
Abstract: Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of Deep Reinforcement Learning to handle intersection problems. Using recent advances in Deep RL, we are able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. We then explore a system's ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. Our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule-based methods, and the failures of our current deep reinforcement learning system point to future research directions.


Title: Autonomous Vehicle Navigation in Rural Environments Without Detailed Prior Maps
Key Words: collision avoidance  least squares approximations  mobile robots  recursive filters  robot vision  sensors  prior maps  positive societal impact  autonomous vehicle navigating  recursive filtering approach  navigate road networks  least-squares residual approach  vehicle frame  sensor-based perception system  global navigation  sparse topological maps  mapless driving framework  autonomous navigation  autonomous driving technology  transmit detailed maps  urban areas  rural environments  autonomous vehicle navigation  Roads  Navigation  Autonomous vehicles  Trajectory  Robot sensing systems  Reliability 
Abstract: State-of-the-art autonomous driving systems rely heavily on detailed and highly accurate prior maps. However, outside of small urban areas, it is very challenging to build, store, and transmit detailed maps since the spatial scales are so large. Furthermore, maintaining detailed maps of large rural areas can be impracticable due to the rapid rate at which these environments can change. This is a significant limitation for the widespread applicability of autonomous driving technology, which has the potential for an incredibly positive societal impact. In this paper, we address the problem of autonomous navigation in rural environments through a novel mapless driving framework that combines sparse topological maps for global navigation with a sensor-based perception system for local navigation. First, a local navigation goal within the sensor view of the vehicle is chosen as a waypoint leading towards the global goal. Next, the local perception system generates a feasible trajectory in the vehicle frame to reach the waypoint while abiding by the rules of the road for the segment being traversed. These trajectories are updated to remain in the local frame using the vehicle's odometry and the associated uncertainty based on the least-squares residual and a recursive filtering approach, which allows the vehicle to navigate road networks reliably, and at high speed, without detailed prior maps. We demonstrate the performance of the system on a full-scale autonomous vehicle navigating in a challenging rural environment and benchmark the system on a large amount of collected data.


Title: Design of an Autonomous Racecar: Perception, State Estimation and System Integration
Key Words: mobile robots  road vehicles  state estimation  modular redundant sub-systems  lateral accelerations  longitudinal accelerations  flüela driverless  onboard sensing  Formula Student Driverless competition  system integration  autonomous racecar  Automobiles  State estimation  Robot sensing systems  Current measurement  Laser radar  Wheels  Global Positioning System 
Abstract: This paper introduces jlüela driverless: the first autonomous racecar to win a Formula Student Driverless competition. In this competition, among other challenges, an autonomous racecar is tasked to complete 10 laps of a previously unknown racetrack as fast as possible and using only onboard sensing and computing. The key components of flüela's design are its modular redundant sub-systems that allow robust performance despite challenging perceptual conditions or partial system failures. The paper presents the integration of key components of our autonomous racecar, i.e., system design, EKF-based state estimation, LiDAR-based perception, and particle filter-based SLAM. We perform an extensive experimental evaluation on real-world data, demonstrating the system's effectiveness by outperforming the next-best ranking team by almost half the time required to finish a lap. The autonomous racecar reaches lateral and longitudinal accelerations comparable to those achieved by experienced human drivers.


Title: Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling
Key Words: Bayes methods  convolution  feedforward neural nets  filtering theory  intelligent transportation systems  mobile robots  Monte Carlo methods  road traffic  time series  traffic engineering computing  unsupervised learning  complex interactions  dynamic occupancy grid prediction  urban autonomous driving  deep learning approach  long-term situation prediction  intelligent vehicles  complex downtown scenarios  multiple road users  motor vehicles  Bayesian filtering technique  environment representation  machine learning  deep convolutional neural network  spatially distributed velocity estimates  raw data sequence  input time series  multiple sensors  convolutional neural networks  road user interaction  pixel-wise balancing  static cells  dynamic cells  unsupervised learning character  pedestrians  bikes  distributed velocity estimation  Monte-Carlo simulation  Vehicle dynamics  Machine learning  Sensor fusion  Roads  Time series analysis  Laser radar 
Abstract: Long-term situation prediction plays a crucial role for intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation. Experiments show the ability to model complex interactions.


Title: Realtime Vehicle and Pedestrian Tracking for Didi Udacity Self-Driving Car Challenge
Key Words: image fusion  object tracking  optical radar  pedestrians  road vehicles  traffic engineering computing  road scene evaluation subsystem  vehicle tracking  image processing  LIDAR processing  pedestrian tracking  DiDi-Udacity Self-Driving Challenge datasets  frequency 25.0 Hz  Radar tracking  Laser radar  Cameras  Three-dimensional displays  Sensor fusion 
Abstract: The efficiency and execution time of a road scene evaluation subsystem directly influences a self-driving car's control effectiveness. This article presents a novel approach to fuse data from various sensors (camera, LIDAR, radar, IMU) for pedestrian and vehicle tracking. Our approach, thanks to modern methods of image processing and power of GPU for LIDAR processing, achieves 25Hz update frequency for tracking. The system has been tested on the DiDi-Udacity Self-Driving Challenge datasets.


Title: Scalable Decision Making with Sensor Occlusions for Autonomous Driving
Key Words: collision avoidance  decision making  Markov processes  mobile robots  optimisation  path planning  road safety  road vehicles  road users  scalable decision making  sensor occlusions  POMDP solution techniques  optimal avoidance strategy  decomposition method  computational cost  partially observable Markov decision process  robust navigation  autonomous driving  Automobiles  Uncertainty  Roads  Acceleration  Autonomous vehicles  Approximation algorithms  Robot sensing systems 
Abstract: Autonomous driving in urban areas requires avoiding other road users with only partial observability of the environment. Observations are only partial because obstacles can occlude the field of view of the sensors. The problem of robust and efficient navigation under uncertainty can be framed as a partially observable Markov decision process (POMDP). In order to bypass the computational cost of scaling the formulation to avoiding multiple road users, this paper demonstrates a decomposition method that leverages the optimal avoidance strategy for a single user. We evaluate the performance of two POMDP solution techniques augmented with the decomposition method for scenarios involving a pedestrian crosswalk and an intersection.


Title: Design and Analysis of a Novel Underwater Glider - RoBuoy
Key Words: autonomous underwater vehicles  design engineering  mathematical analysis  mechatronics  mobile robots  oceanographic equipment  variable buoyancy method  autonomous underwater vehicles  underwater robots  mechatronic system  underwater gliders RoBuoy  metallic bellows  integrated mathematical model  wings  open loop performance  power efficient  actuated metallic bellows  parts fouling  optimized dimensions  Actuators  Buoyancy  Bellows  Surges  Pistons  Unmanned underwater vehicles  Prototypes 
Abstract: Underwater gliders are special class of autonomous underwater vehicles (AUVs) proven to be power efficient with better range and endurance compared to the conventional underwater robots. Most of the existing underwater gliders use `change of mass' based variable buoyancy (VB) method in which the overall system architecture and construction are complex. A novel underwater glider RoBuoy based on the `change of volume' concept of variable buoyancy method is presented here. RoBuoy uses actuated metallic bellows to change the volume which makes the system simple and modular in construction without any compromise in the performance. It uses minimal number of parts compared to the existing gliders which reduces the overall complexity of the system. Also, most of the conventional gliders use the external fluid for its working which may result in corrosion or fouling of parts and requires frequent maintenance. In the proposed glider, all the vital parts required for its working, apart from the sensing payloads are enclosed inside the hull, thereby increasing the durability. In this paper, a detailed design of RoBuoy is discussed with its possible modes of operation. An integrated mathematical model considering the individual dynamics of the actuator, hull/fuselage, and the wings has been developed and the open loop performance of the glider is studied at different input conditions. An experimental prototype has been designed and fabricated based on optimized dimensions, with the required mechatronic system. Experiments have been conducted and the results prove the feasibility of the concept.


Title: Encoderless Gimbal Calibration of Dynamic Multi-Camera Clusters
Key Words: angular measurement  calibration  cameras  encoderless gimbal calibration  dynamic multiCamera Clusters  Dynamic Camera Clusters  multicamera systems  cameras  joint angle measurements  time-varying transformation  static camera  motor encoders  transformation chain  encoderless gimbal mechanism  online estimation  Cameras  Calibration  Robot vision systems  Estimation  Reluctance motors  Kinematics  Vehicle dynamics 
Abstract: Dynamic Camera Clusters (DCCs) are multi-camera systems where one or more cameras are mounted on actuated mechanisms such as a gimbal. Existing methods for DCC calibration rely on joint angle measurements to resolve the time-varying transformation between the dynamic and static camera. This information is usually provided by motor encoders, however, joint angle measurements are not always readily available on off-the-shelf mechanisms. In this paper, we present an encoderless approach for DCC calibration which simultaneously estimates the kinematic parameters of the transformation chain as well as the unknown joint angles. We also demonstrate the integration of an encoderless gimbal mechanism with a state-of-the art VIO algorithm, and show the extensions required in order to perform simultaneous online estimation of the joint angles and vehicle localization state. The proposed calibration approach is validated both in simulation and on a physical DCC composed of a 2-DOF gimbal mounted on a UAV. Finally, we show the experimental results of the calibrated mechanism integrated into the OKVIS VIO package, and demonstrate successful online joint angle estimation while maintaining localization accuracy that is comparable to a standard static multi-camera configuration.


Title: A Low-Cost Navigation Strategy for Yield Estimation in Vineyards
Key Words: agriculture  image colour analysis  image resolution  object detection  yield estimation  grape varieties  vineyard management  low-cost navigation strategy  navigation algorithm  grape pictures  low-cost autonomous system  RGB camera  RGB image processing  Navigation  Pipelines  Yield estimation  Cameras  Robot vision systems  Lasers 
Abstract: Accurate yield estimation is very important for improving the vineyard management, the quality of the grapes and the health of the vines. The most common systems use RGB image processing for achieving a good estimation. In order to collect images, robots or farming vehicles can be equipped with a RGB camera. In this paper, we propose a low-cost autonomous system which can navigate through a vineyard while collecting grape pictures in order to provide a yield estimation. Our system uses only a laser scanner to detect the row and follows it until its end, then it navigates towards the next one, exploiting the knowledge of the vineyard. The navigation algorithm was tested both in simulation and in a real environment with good results. Furthermore, a yield estimation of two different grape varieties is presented.


Title: Robust Target-Relative Localization with Ultra-Wideband Ranging and Communication
Key Words: aircraft communication  aircraft navigation  altimeters  autonomous aerial vehicles  helicopters  Kalman filters  nonlinear filters  position control  sensors  target tracking  ultra wideband communication  quadcopter  autonomous flight  Extended Kalman Filter  UWB ranging measurements  onboard sensors  altimeters  optical flow  UWB based communication capability  robust target-relative localization  ultra-wideband ranging communication  Ultra-wideband ranging sensors  Distance measurement  Sensors  Antenna measurements  Robustness  Iron  Robots  Kalman filters 
Abstract: In this paper we propose a method to achieve relative positioning and tracking of a target by a quadcopter using Ultra-wideband (UWB) ranging sensors, which are strategically installed to help retrieve both relative position and bearing between the quadcopter and target. To achieve robust localization for autonomous flight even with uncertainty in the speed of the target, two main features are developed. First, an estimator based on Extended Kalman Filter (EKF) is developed to fuse UWB ranging measurements with data from onboard sensors including inertial measurement unit (IMU), altimeters and optical flow. Second, to properly handle the coupling of the target's orientation with the range measurements, UWB based communication capability is utilized to transfer the target's orientation to the quadcopter. Experiments results demonstrate the ability of the quadcopter to control its position relative to the target autonomously in both cases when the target is static and moving.


Title: Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response
Key Words: approximation theory  computational complexity  greedy algorithms  mobile robots  multi-robot systems  optimisation  service robots  N task arrivals  service tasks  redeployment cost  one-stage greedy algorithm  constant-factor approximation algorithm  service cost  multiple service robots  autonomous robots  re-deployment algorithms  task response optimization  NP-hard  Robots  Task analysis  Time factors  Approximation algorithms  Probability distribution  Measurement  Vehicle dynamics 
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.


Title: Multi-robot Dubins Coverage with Autonomous Surface Vehicles
Key Words: computational complexity  mobile robots  multi-robot systems  path planning  remotely operated vehicles  travelling salesman problems  multirobot Dubins coverage  aerial monitoring  single robot approaches  multirobot approaches  Dubins vehicle kinematics  environmental monitoring  multirobot team  Dubins vehicles  NP-complete problems  salesman problem-k-TSP-formulation  autonomous surface vehicles  large scale coverage operations  marine exploration  Robot sensing systems  Clustering algorithms  Task analysis  Lakes  Multi-robot systems  Kinematics 
Abstract: In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.


Title: Joint Multi-Policy Behavior Estimation and Receding-Horizon Trajectory Planning for Automated Urban Driving
Key Words: collision avoidance  Markov processes  mobile robots  multi-robot systems  path planning  road vehicles  multipolicy decision-making  traffic participants  planned trajectory  ego-vehicle  safe trajectories  multiple motion policies  receding-horizon planner  simulated multivehicle intersection scenarios  joint multipolicy behavior  automated urban driving  urban environments  autonomous vehicle  multiple motion hypothesis  joint behavior estimation  observable Markov decision processes  receding-horizon control  receding-horizon trajectory planning  Trajectory  Planning  Estimation  Space vehicles  Uncertainty  Roads  Computational modeling 
Abstract: When driving in urban environments, an autonomous vehicle must account for the interaction with other traffic participants. It must reason about their future behavior, how its actions affect their future behavior, and potentially consider multiple motion hypothesis. In this paper we introduce a method for joint behavior estimation and trajectory planning that models interaction and multi-policy decision-making. The method leverages Partially Observable Markov Decision Processes to estimate the behavior of other traffic participants given the planned trajectory for the ego-vehicle, and Receding-Horizon Control for generating safe trajectories for the ego-vehicle. To achieve safe navigation we introduce chance constraints over multiple motion policies in the receding-horizon planner. These constraints account for uncertainty over the behavior of other traffic participants. The method is capable of running in real-time and we show its performance and good scalability in simulated multi-vehicle intersection scenarios.


Title: Best Response Model Predictive Control for Agile Interactions Between Autonomous Ground Vehicles
Key Words: game theory  information theory  mobile robots  nonlinear control systems  predictive control  remotely operated vehicles  stochastic systems  best response model predictive control  AutoRally platforms  nonlinear stochastic systems  information theoretic model predictive control algorithm  iterated best response  game theoretic notion  autonomous control  autonomous ground vehicles  Games  Stochastic processes  Predictive control  Nash equilibrium  Optimization  Vehicle dynamics  Prediction algorithms 
Abstract: We introduce an algorithm for autonomous control of multiple fast ground vehicles operating in close proximity to each other. The algorithm is based on a combination of the game theoretic notion of iterated best response, and an information theoretic model predictive control algorithm designed for non-linear stochastic systems. We test the algorithm on two one-fifth scale AutoRally platforms traveling at speeds upwards of 8 meters per second, while maintaining a following distance of under two meters from bumper-to-bumper.


Title: Deep Learning a Quadrotor Dynamic Model for Multi-Step Prediction
Key Words: aircraft control  autonomous aerial vehicles  control engineering computing  helicopters  learning (artificial intelligence)  mobile robots  motion control  predictive control  recurrent neural nets  robot dynamics  robot kinematics  trajectory control  quadrotor dynamic model  motion prediction  dynamic systems  long horizons  deep learning  deep recurrent neural networks  quadrotor motion model  initial system state  motor speeds  prediction horizon  recurrent neural network state initialization  quadrotor vehicle flights  indoor flight arena  hybrid network architecture  system identification methods  robust state predictions  time 2.0 s  frequency 100.0 Hz  Mathematical model  Predictive models  Vehicle dynamics  Aerodynamics  Recurrent neural networks  Training 
Abstract: We develop a multi-step motion prediction modeling method for dynamic systems over long horizons using deep learning. Building on previous work, we propose a novel hybrid network architecture, by combining deep recurrent neural networks with a quadrotor motion model created using classic system identification methods. The proposed model takes only the initial system state and motor speeds over the prediction horizon as inputs and returns robust state predictions for up to two seconds of motion at 100 Hz. We employ recurrent neural network state initialization during training, to exploit real-world dataset collected from quadrotor vehicle flights in an indoor flight arena. Our experiments demonstrate that the proposed hybrid network model consistently outperforms both black box and rigid body dynamics predictions over single and multi-step prediction scenarios, with an order of magnitude improvements in velocity estimates in particular.


Title: Safe Learning of Quadrotor Dynamics Using Barrier Certificates
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  Gaussian processes  helicopters  learning systems  mobile robots  nonlinear control systems  probability  uncertain systems  complex dynamical systems  accurate nonlinear models  data-driven approach  Gaussian processes  learning process  barrier certificates  safe learning  learning controller  quadrotor dynamics  Safety  Control systems  Computational modeling  Gaussian processes  Adaptation models  Lyapunov methods  System dynamics 
Abstract: To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. Simulation results are provided to demonstrate the effectiveness of the proposed approach.


Title: IMLS-SLAM: Scan-to-Model Matching Based on 3D Data
Key Words: collision avoidance  mobile robots  optical radar  remotely operated vehicles  road traffic control  robot vision  SLAM (robots)  stereo image processing  robotics community  stereo cameras  depth sensors  Velodyne LiDAR  autonomous driving  low-drift SLAM algorithm  3D LiDAR data  scan-to-model matching framework  specific sampling strategy  LiDAR scans  Velodyne HDL32  Velodyne HDL64  global drift  IMLS-SLAM  3D data  simultaneous localization and mapping  localized LiDAR sweeps  IMLS surface representation  implicit moving least squares  size 4.0 km  size 16.0 m  time 10.0 year  Three-dimensional displays  Laser radar  Simultaneous localization and mapping  Two dimensional displays  Iterative closest point algorithm  Observability 
Abstract: The Simultaneous Localization And Mapping (SLAM) problem has been well studied in the robotics community, especially using mono, stereo cameras or depth sensors. 3D depth sensors, such as Velodyne LiDAR, have proved in the last 10 years to be very useful to perceive the environment in autonomous driving, but few methods exist that directly use these 3D data for odometry. We present a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method relies on a scan-to-model matching framework. We first have a specific sampling strategy based on the LiDAR scans. We then define our model as the previous localized LiDAR sweeps and use the Implicit Moving Least Squares (IMLS) surface representation. We show experiments with the Velodyne HDL32 with only 0.40% drift over a 4 km acquisition without any loop closure (i.e., 16 m drift after 4 km). We tested our solution on the KITTI benchmark with a Velodyne HDL64 and ranked among the best methods (against mono, stereo and LiDAR methods) with a global drift of only 0.69%.


Title: Perception-aware Receding Horizon Navigation for MAVs
Key Words: aircraft control  collision avoidance  mobile robots  navigation  path planning  robot vision  state estimation  perception-aware receding horizon navigation  microaerial vehicle  state estimation uncertainty  perception-aware receding horizon approach  monocular state estimation  candidate trajectories  perception quality  collision probability  receding horizon navigation framework  improved state estimation accuracy  goal-reaching task  purely-reactive navigation system  MAV  Trajectory  State estimation  Planning  Navigation  Cameras  Measurement  Task analysis 
Abstract: To reach a given destination safely and accurately, a micro aerial vehicle needs to be able to avoid obstacles and minimize its state estimation uncertainty at the same time. To achieve this goal, we propose a perception-aware receding horizon approach. In our method, a single forward-looking camera is used for state estimation and mapping. Using the information from the monocular state estimation and mapping system, we generate a library of candidate trajectories and evaluate them in terms of perception quality, collision probability, and distance to the goal. The best trajectory to execute is then selected as the one that maximizes a reward function based on these three metrics. To the best of our knowledge, this is the first work that integrates active vision within a receding horizon navigation framework for a goal reaching task. We demonstrate by simulation and real-world experiments on an actual quadrotor that our active approach leads to improved state estimation accuracy in a goal-reaching task when compared to a purely-reactive navigation system, especially in difficult scenes (e.g., weak texture).


Title: Viewpoint-Tolerant Place Recognition Combining 2D and 3D Information for UAV Navigation
Key Words: autonomous aerial vehicles  distance measurement  geometry  mobile robots  path planning  robot vision  stereo image processing  3D information  UAV navigation  Unmanned Aerial Vehicles  vision-based odometry  loop-closure detection  place recognition framework  local 3D geometry  viewpoint-tolerant place recognition  2D Information  hand-held datasets  perceptual aliasing  binary features  Simultaneous localization and mapping  Three-dimensional displays  Visualization  Vocabulary  Image recognition  Navigation 
Abstract: The booming interest in Unmanned Aerial Vehicles (UAV s) is fed by their potentially great impact, however progress is hindered by their limited perception capabilities. While vision-based odometry was shown to run successfully onboard UAV s, loop-closure detection to correct for drift or to recover from tracking failures, has so far, proven particularly challenging for UAVs. At the heart of this is the problem of viewpoint-tolerant place recognition; in stark difference to ground robots, UAVs can revisit a scene from very different viewpoints. As a result, existing approaches struggle greatly as the task at hand violates underlying assumptions in assessing scene similarity. In this paper, we propose a place recognition framework, which exploits both efficient binary features and noisy estimates of the local 3D geometry, which are anyway computed for visual-inertial odometry onboard the UAV. Attaching both an appearance and a geometry signature to each `location', the proposed approach demonstrates unprecedented recall for perfect precision as well as high quality loop-closing transformations on both flying and hand-held datasets exhibiting large viewpoint and appearance changes as well as perceptual aliasing.


Title: Flexible Stereo: Constrained, Non-Rigid, Wide-Baseline Stereo Vision for Fixed-Wing Aerial Platforms
Key Words: aerospace components  angular velocity measurement  autonomous aerial vehicles  cameras  collision avoidance  Kalman filters  nonlinear filters  pose estimation  robot vision  stereo image processing  landing maneuvers  wing model  probability density function  measured deviations  nominal relative baseline transformation  relative pose measurements  relative perspective N-point problem  inertial measurement units  highly accurate baseline transformations  flexible stereo  wide-baseline stereo vision  fixed-wing aerial platforms  computationally efficient method  visual-inertial sensor rigs  fixed-wing unmanned aerial vehicle  estimated relative poses  highly accurate depth maps  obstacle avoidance  low-altitude flights  extended Kalman filter  Cameras  Visualization  Mathematical model  Quaternions  Unmanned aerial vehicles  Real-time systems  Accelerometers 
Abstract: This paper proposes a computationally efficient method to estimate the time-varying relative pose between two visual-inertial sensor rigs mounted on the flexible wings of a fixed-wing unmanned aerial vehicle (UAV). The estimated relative poses are used to generate highly accurate depth maps in real-time and can be employed for obstacle avoidance in low-altitude flights or landing maneuvers. The approach is structured as follows: Initially, a wing model is identified by fitting a probability density function to measured deviations from the nominal relative baseline transformation. At runtime, the prior knowledge about the wing model is fused in an Extended Kalman filter (EKF) together with relative pose measurements obtained from solving a relative perspective N-point problem (PNP), and the linear accelerations and angular velocities measured by the two inertial measurement units (IMU) which are rigidly attached to the cameras. Results obtained from extensive synthetic experiments demonstrate that our proposed framework is able to estimate highly accurate baseline transformations and depth maps.


Title: Visual-Inertial Navigation Algorithm Development Using Photorealistic Camera Simulation in the Loop
Key Words: aerospace computing  autonomous aerial vehicles  computer vision  control engineering computing  image sensors  inertial navigation  rendering (computer graphics)  virtual reality  vision-based perception  virtual reality  visual-inertial navigation algorithm  high-rate cameras  image simulation system  photorealistic camera simulation  agile maneuvering  on-board inertial measurement unit  rapidly prototype computing  on-board camera images  NVIDIA Jetson Tegra X1 system-on-chip compute module  inertial sensors  microUAV platform  vision-in-the-loop control algorithms  agile microUnmanned Aerial Vehicles  Cameras  Sensors  Visualization  Real-time systems  Unmanned aerial vehicles  Navigation  Solid modeling 
Abstract: The development of fast, agile micro Unmanned Aerial Vehicles (UAVs) has been limited by (i) on-board computing hardware restrictions, (ii) the lack of sophisticated vision-based perception and vision-in-the-loop control algorithms, and (iii) the absence of development environments where such systems and algorithms can be rapidly and easily designed, implemented, and validated. Here, we first present a new micro UAV platform that integrates high-rate cameras, inertial sensors, and an NVIDIA Jetson Tegra X1 system-on-chip compute module that boasts 256 GPU cores. The UAV mechanics and electronics were designed and built in house, and are described in detail. Second, we present a novel “virtual reality” development environment, in which photorealistically-rendered synthetic on-board camera images are generated in real time while the UAV is in flight. This development environment allows us to rapidly prototype computing and sensing hardware as well as perception and control algorithms, using real physics, real interoceptive sensor data (e.g., from the on-board inertial measurement unit), and synthetic exteroceptive sensor data (e.g., from synthetic cameras). Third, we demonstrate repeated agile maneuvering with closed-loop vision-based perception and control algorithms, which we have developed using this environment.


Title: Map-Aware Particle Filter for Localization
Key Words: distance measurement  Global Positioning System  optical radar  particle filtering (numerical methods)  SLAM (robots)  map-aware particle filter  2D LiDAR localization  GPS localization  map information  localization sensors  particle filter framework  map-matching  prior occupancy grid  vehicle localization  Trajectory  Roads  Atmospheric measurements  Particle measurements  Sensors  Particle filters  Two dimensional displays 
Abstract: This work presents a method to improve vehicle localization by using the information from a prior occupancy grid to bound the possible poses. The method, named Map-Aware Particle Filter, uses a nonlinear approach to map-matching that can be integrated into a particle filter framework for localization. Each particle is re-weighted based on the validity of its current position in the map. In addition, we buffer the trajectory followed by the vehicle and then append it to each particle's pose. We then quantify the overlap between the trajectory and the map's free space. This serves as a measure of each particle's validity given the trajectory and the shape of the map. We evaluated the method by performing experiments with different types of localization sensors: First, (i) we significantly reduced the drift inherent to dead reckoning. By only using wheel odometry and map information we achieved loop closure over a distance of approximately 3 km. We also (ii) increased the accuracy of GPS localization. Finally, (iii) we fused a fragile 2D LiDAR localization with the map information. The resulting system had a higher robustness and managed to close the loop in an outdated map where it had failed before.


Title: Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller
Key Words: autonomous aerial vehicles  iterative methods  learning (artificial intelligence)  nonlinear control systems  optimal control  optimisation  path planning  predictive control  sampling methods  trajectory optimisation (aerospace)  direct optimal control  control policy  optimal state-control trajectories  nonlinear predictive controller  nonlinear optimization problem  model-based methodology  control cycle  kinodynamic probabilistic roadmap  nonlinear solver  unmanned aerial vehicle  UAV  complex dynamical systems  sampling-based planning  policy learning  Computational modeling  Approximation algorithms  Optimal control  Planning  Robots  Trajectory optimization 
Abstract: Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.


Title: Acceleration of Gradient-Based Path Integral Method for Efficient Optimal and Inverse Optimal Control
Key Words: convergence of numerical methods  gradient methods  learning (artificial intelligence)  optimal control  optimisation  predictive control  gradient-based path integral method  inverse optimal control  accelerated path integral method  gradient descent  iterative path integral method  optimization methods  momentum-based acceleration  momentum-based methods  Nesterov Accelerated Gradient  simulated control systems  model predictive control  path integral networks  accelerated PI-Net  reinforcement learning  Iterative methods  Acceleration  Optimal control  Convergence  Mirrors  Trajectory  Vehicle dynamics 
Abstract: This paper deals with a new accelerated path integral method, which iteratively searches optimal controls with a small number of iterations. This study is based on the recent observations that a path integral method for reinforcement learning can be interpreted as gradient descent. This observation also applies to an iterative path integral method for optimal control, which sets a convincing argument for utilizing various optimization methods for gradient descent, such as momentum-based acceleration, step-size adaptation and their combination. We introduce these types of methods to the path integral and demonstrate that momentum-based methods, like Nesterov Accelerated Gradient and Adam, can significantly improve the convergence rate to search for optimal controls in simulated control systems. We also demonstrate that the accelerated path integral could improve the performance on model predictive control for various vehicle navigation tasks. Finally, we represent this accelerated path integral method as a recurrent network, which is the accelerated version of the previously proposed path integral networks (PI-Net). We can train the accelerated PI-Net more efficiently for inverse optimal control with less RAM than the original PI-Net.


Title: A General Pipeline for 3D Detection of Vehicles
Key Words: automobiles  convolution  feature extraction  feedforward neural nets  mobile robots  robot vision  traffic engineering computing  2D detection network  generalised car models  two-stage convolutional neural network  3D detection algorithms  general pipeline  autonomous driving  flexible pipeline  3D point cloud  model fitting algorithm  3D box detection  2D vehicle detection  Three-dimensional displays  Two dimensional displays  Automobiles  Pipelines  Solid modeling  Proposals  Laser radar 
Abstract: Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection.


Title: Mono-Stixels: Monocular Depth Reconstruction of Dynamic Street Scenes
Key Words: cameras  image motion analysis  image reconstruction  image representation  image segmentation  image sequences  stereo image processing  monocular depth reconstruction  dynamic street scenes  semantic information  pixel-wise semantic segmentation  camera motion  optical flow estimation  depth reconstruction  stereo depth measurements  monostixel model  Semantics  Cameras  Optical imaging  Vehicle dynamics  Estimation  Dynamics  Motion segmentation 
Abstract: In this paper we present mono-stixels, a compact environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth, motion and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates, pixel-wise semantic segmentation and camera motion. The optical flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are reduced to only up to two degrees of freedom. Furthermore, we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and reliable depth reconstruction of both the static and moving parts of the scene. Thereby, mono-stixels overcome the limitation to static scenes of previous structure-from-motion approaches.


Title: Modeling Driver Behavior from Demonstrations in Dynamic Environments Using Spatiotemporal Lattices
Key Words: collision avoidance  driver information systems  learning (artificial intelligence)  mobile robots  road vehicles  spatiotemporal lattices  path planners  intelligent vehicles  cost function  model parameters  demonstrated driving data  Inverse Reinforcement  IRL methods  forward control problem  traditional path-planning techniques  conformal spatiotemporal state lattice  dynamic obstacles  model assessment  IRL framework  highly dynamic environments  highway tactical driving task  instrumented vehicle  driver behavior modeling  Trajectory  Lattices  Task analysis  Spatiotemporal phenomena  Vehicle dynamics  Learning (artificial intelligence)  Cost function 
Abstract: One of the most challenging tasks in the development of path planners for intelligent vehicles is the design of the cost function that models the desired behavior of the vehicle. While this task has been traditionally accomplished by hand-tuning the model parameters, recent approaches propose to learn the model automatically from demonstrated driving data using Inverse Reinforcement Learning (IRL). To determine if the model has correctly captured the demonstrated behavior, most IRL methods require obtaining a policy by solving the forward control problem repetitively. Calculating the full policy is a costly task in continuous or large domains and thus often approximated by finding a single trajectory using traditional path-planning techniques. In this work, we propose to find such a trajectory using a conformal spatiotemporal state lattice, which offers two main advantages. First, by conforming the lattice to the environment, the search is focused only on feasible motions for the robot, saving computational power. And second, by considering time as part of the state, the trajectory is optimized with respect to the motion of the dynamic obstacles in the scene. As a consequence, the resulting trajectory can be used for the model assessment. We show how the proposed IRL framework can successfully handle highly dynamic environments by modeling the highway tactical driving task from demonstrated driving data gathered with an instrumented vehicle.


Title: Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
Key Words: decision making  human-robot interaction  intelligent transportation systems  learning (artificial intelligence)  probability  highway on-ramp-off-ramps  human-robot interaction policies  multimodal probabilistic model-based planning  traffic weaving scenario  human-in-the-loop simulation  candidate future robot actions  interaction history  action distributions  direct learning  candidate robot action sequences  human responses  massively parallel sampling  real-time robot policy construction  human-human exemplars  future human actions  multimodal probability distributions  inherent multimodal uncertainty  experienced drivers  entering exiting cars  decision making  Robots  Vehicles  Predictive models  History  Cognition  Probabilistic logic  Weaving 
Abstract: This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.


Title: Drive Video Analysis for the Detection of Traffic Near-Miss Incidents
Key Words: automobiles  driver information systems  learning (artificial intelligence)  object detection  road safety  road traffic  video signal processing  traffic near-miss incidents  self-driving cars  advanced driver assistance system equipped vehicles  dangerous traffic  normal drivers  novel traffic database  mounting driving recorders  automated systems  database instances  large-scale traffic near-miss incident database  monocular driving recorder  NIDB traffic  primary database-related improvements  near-miss scenes  near-miss detection  drive video analysis  near-miss incident  motion representation  performance level  Databases  Vehicles  Autonomous automobiles  Semantics  Advanced driver assistance systems  Public transportation  Training 
Abstract: Because of their recent introduction, self-driving cars and advanced driver assistance system (ADAS) equipped vehicles have had little opportunity to learn, the dangerous traffic (including near-miss incident) scenarios that provide normal drivers with strong motivation to drive safely. Accordingly, as a means of providing learning depth, this paper presents a novel traffic database that contains information on a large number of traffic near-miss incidents that were obtained by mounting driving recorders in more than 100 taxis over the course of a decade. The study makes the following two main contributions: (i) In order to assist automated systems in detecting near-miss incidents based on database instances, we created a large-scale traffic near-miss incident database (NIDB) that consists of video clip of dangerous events captured by monocular driving recorders. (ii) To illustrate the applicability of NIDB traffic near-miss incidents, we provide two primary database-related improvements: parameter fine-tuning using various near-miss scenes from NIDB, and foreground/background separation into motion representation. Then, using our new database in conjunction with a monocular driving recorder, we developed a near-miss recognition method that provides automated systems with a performance level that is comparable to a human-level understanding of near-miss incidents (64.5% vs. 68.4% at near-miss recognition, 61.3% vs. 78.7% at near-miss detection).


Title: A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  biomimetics  control system synthesis  elastomers  electroactive polymer actuators  force control  mobile robots  motion control  remotely operated vehicles  velocity control  thrust force  actuation layers  fin-like dielectric elastomer actuator  DEA design  fish fins undulatory motions  tunable DEAs  soft actuators  autonomous planar swimming  actuator designs  swimming speed  vertical swimming  underwater operation  elastomers  autonomous mobility  AUV  miniature autonomous underwater vehicle  modular dielectric elastomer actuator  Aquatic robots  Power supplies  Propulsion  Dielectric elastomer actuators 
Abstract: In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.


Title: Autonomous Bio-Inspired Small-Object Detection and Avoidance
Key Words: collision avoidance  Fourier analysis  helicopters  image sequences  mobile robots  navigation  object detection  robot vision  small-field motion-sensitive interneurons  insect visuomotor system  small-field object detection  artificial potential function-based low-order steering control law  small-field clutter  bio-inspired approach  autonomous robots  autonomous vehicles  bio-inspired navigation technique  Fourier residual analysis  instantaneous optic flow  Optical sensors  Optical imaging  Navigation  Biomedical optical imaging  Insects  Neurons 
Abstract: Small-object detection and avoidance in unknown environments is a significant challenge to overcome for small autonomous vehicles that are generally highly agile and restricted in payload and computational processing power. Typical machine-vision and range measurement based solutions suffer either from restricted fields-of-view or significant computational complexity and are not easily portable to small platforms. In this paper, a novel bio-inspired navigation technique is introduced that is modeled using analogues of the small-field motion-sensitive interneurons of the insect visuomotor system. The proposed technique achieves small-field object detection based on Fourier residual analysis of instantaneous optic flow. The small field signal is used to extract relative range and bearing of the nearest obstacle, which is then combined with an artificial potential function-based low-order steering control law. The proposed sensing and control scheme is experimentally validated with a quadrotor vehicle that is able to effectively navigate an unknown environment laden with small-field clutter. This bio-inspired approach is computationally efficient and serves as a robust, reflexive solution to the problem of small-object detection and avoidance for autonomous robots.


Title: Visual Grasping for a Lightweight Aerial Manipulator Based on NSGA-II and Kinematic Compensation
Key Words: autonomous aerial vehicles  calibration  collision avoidance  compensation  genetic algorithms  manipulator dynamics  manipulator kinematics  visual grasping  lightweight aerial manipulator  complex kinematics/dynamics  motion constraints  X8 coaxial octocopter  4-DoF manipulator  grasping control problem  NSGA-II method  trajectory planning  kinematic compensation-based visual trajectory tracking  trajectory generation  dynamic parameter calibration  Manipulator dynamics  Trajectory  Grasping  Kinematics  Acceleration  Visualization 
Abstract: The grasping control of an aerial manipulator in practical environments is challenging due to its complex kinematics/dynamics and motion constraints. This paper introduces a lightweight aerial manipulator, which is combined with an X8 coaxial octocopter and a 4-DoF manipulator. To address the grasping control problem, we develop an efficient scheme containing trajectory generation, visual trajectory tracking, and kinematic compensation. The NSGA-II method is utilized to implement the multiobjective optimization for trajectory planning. Motion constraints and collision avoidance are also considered in the optimization. A kinematic compensation-based visual trajectory tracking is introduced to address the coupled nature between manipulator and VAV body. No dynamic parameter calibration is needed. Finally, several experiments are performed to verify the stability and feasibility of the proposed approach.


Title: Liftoff of a 190 mg Laser-Powered Aerial Vehicle: The Lightest Wireless Robot to Fly
Key Words: aerospace robotics  autonomous aerial vehicles  avionics  electronics packaging  feedback  microcontrollers  microrobots  mobile robots  power convertors  robot dynamics  wire tethers  high-voltage power electronics  severely constrained weight budgets  wireless liftoff  fast-turnaround laser based circuit fabrication technique  onboard electronics  high voltage bias  drive signals  insect scale aerial robots  aerial vehicle  power electronics package  wireless robot  laser-powered aerial vehicle  microcontroller  feedback control  mass 190.0 mg  mass 104.0 mg  wavelength 976.0 nm  Actuators  Insects  Microcontrollers  High-voltage techniques  Capacitors  Robot sensing systems 
Abstract: To date, insect scale aerial robots have required wire tethers for providing power due to the challenges of integrating the required high-voltage power electronics within their severely constrained weight budgets. In this paper we present a significant milestone in the achievement of flight autonomy: the first wireless liftoff of a 190 mg aerial vehicle. Our robot is remotely powered using a 976 nm laser and integrates a complete power electronics package weighing a total of 104 mg, using commercially available components and fabricated using a fast-turnaround laser based circuit fabrication technique. The onboard electronics include a lightweight boost converter capable of producing high voltage bias and drive signals of over 200 V at up to 170 Hz and regulated by a microcontroller performing feedback control. We present our system design and analysis, detailed description of our fabrication method, and results from flight experiments.


Title: SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
Key Words: augmented reality  autonomous aerial vehicles  mobile computing  mobile robots  navigation  robot vision  SLAM (robots)  visual SLAM  augmented reality systems  nonfunctional requirements  mobile phone-based AR application  tight energy budget  UAV navigation system  SLAMBench2  benchmarking framework  open source  close source  performance metrics  ORB-SLAM2  publicly-available software framework  SLAM applications  SLAM systems  SLAM algorithms  multiobjective head-to-head benchmarking  functional requirements  Simultaneous localization and mapping  Measurement  Trajectory  Benchmark testing  User interfaces  C++ languages 
Abstract: SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.


Title: Towards Globally Consistent Visual-Inertial Collaborative SLAM
Key Words: autonomous aerial vehicles  mobile robots  path planning  robot vision  SLAM (robots)  globally consistent tracking  autonomous robot navigation  monocular-inertial odometry  vision-based perception  metric scale estimation  benchmarking datasets  UAVs  monocular-inertial sensor suite  unmanned aerial vehicles  visual-inertial collaborative SLAM  drift correction  Simultaneous localization and mapping  Collaboration  Unmanned aerial vehicles  Optimization  Measurement  Trajectory 
Abstract: Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.


Title: Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
Key Words: mobile robots  multi-robot systems  path planning  probability  potential contingency task  multirobot mission planning  expected mission completion time  probability  Task analysis  Robot kinematics  Uncertainty  Schedules  Marine vehicles  Resource management 
Abstract: In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.


Title: Vision Based Collaborative Path Planning for Micro Aerial Vehicles
Key Words: cameras  collision avoidance  covariance matrices  mobile robots  optimisation  path planning  robot vision  trees (mathematics)  microaerial vehicles  collaborative path-planning framework  localization uncertainty  two-step planning framework  visual-fidelity aerial vehicle simulator  Planning  Uncertainty  Cameras  Three-dimensional displays  Collaboration  Optimization  Path planning 
Abstract: In this paper, we present a collaborative path-planning framework for a group of micro aerial vehicles that are capable of localizing through vision. Each of the micro aerial vehicles is assumed to be equipped with a forward facing monocular camera. The vehicles initially use their captured images to build 3D maps through common features; and subsequently track these features to localize through 3D-2D correspondences. The planning algorithm, while connecting start locations to provided goal locations, also aims to reduce the localization uncertainty of the vehicles in the group. To achieve this, we develop a two-step planning framework: the first step attempts to build an improved map of the environment by solving the next-best-view problem for multiple cameras. We express this as a black-box optimization problem and solve it using the Covariance Matrix Adaption evolution strategy (CMA-ES). Once an improved map is available, the second stage of the planning framework performs belief space planning for the vehicles individually using the rapidly exploring random belief tree (RRBT) algorithm. Through the RRBT approach, the planner generates paths that ensure feature visibility while attempting to optimize path cost and reduce localization uncertainty. We validate our approach using experiments conducted in a high visual-fidelity aerial vehicle simulator, Microsoft AirSim.


Title: Semi-Dense Visual-Inertial Odometry and Mapping for Quadrotors with SWAP Constraints
Key Words: helicopters  inertial navigation  mobile robots  path planning  robot vision  state estimation  stereo image processing  semidense visual-inertial odometry  quadrotors  SWAP constraints  autonomous navigation capabilities  dense 3D maps  indoor environments  visual inertial state estimation  microaerial vehicles  size, weight, and power constraints  stereo camera  Cameras  Three-dimensional displays  Visual odometry  Optimization  Navigation  Robot vision systems 
Abstract: Micro Aerial Vehicles have the potential to assist humans in real life tasks involving applications such as smart homes, search and rescue, and architecture construction. To enhance autonomous navigation capabilities these vehicles need to be able to create dense 3D maps of the environment, while concurrently estimating their own motion. In this paper, we are particularly interested in small vehicles that can navigate cluttered indoor environments. We address the problem of visual inertial state estimation, control and 3D mapping on platforms with Size, Weight, And Power (SWAP) constraints. The proposed approach is validated through experimental results on a 250 g, 22 cm diameter quadrotor equipped only with a stereo camera and an IMU with a computationally-limited CPU showing the ability to autonomously navigate, while concurrently creating a 3D map of the environment.


Title: Screw-Powered Propulsion in Granular Media: An Experimental and Computational Study
Key Words: aerospace propulsion  blades  design engineering  discrete element method  fasteners  glass  granular materials  planetary rovers  propellers  shafts  space vehicles  tracked vehicles  transportation  vehicle dynamics  thrust force  granular media  screw-powered propulsion  industrial processes  pontoon shaft  arctic media  tracked vehicles  screw design  soda-lime glass beads  screw-propelled vehicles  transportation  dewatering  blades damage  blade sinkage  lunar rover design  aqueous media  angular velocity  double-helix Archimedes screw generating propulsive force  miniaturized exploration vehicle  discrete element modeling software  size 5.0 cm  size 8.0 cm  size 10.0 cm  size 1.8 mm to 2.2 mm  size 4 cm  Fasteners  Friction  Force  Glass  Media  Young's modulus  Propulsion 
Abstract: Screw-Propelled Vehicles (SPV's) have been widely used for terrestrial applications such as transportation over mud, snow, and amphibious environments. Similar vehicles have also been applied to industrial processes such as dewatering. Typical designs rely on a large pontoon shaft and relatively small blades to prevent unwanted sinkage or blade damage. These types of vehicles were considered during the design of the first lunar rover, given their success in aqueous and arctic media and simplicity compared to tracked vehicles. Studies have looked at the mobility of SPV's on the surface of granular media but there are not any computational and experimental studies on propulsive buried screws. Understanding the role of screw design and its angular velocity on thrust force is key to the advancement and control of SPV's. This study presents experimental and computational results of a submerged, double-helix Archimedes screw generating propulsive force against a bed of soda-lime glass beads. Thus, this research forms the basis for design of a future miniaturized exploration vehicle for space applications. In our study, we used two different screw designs (5 cm radius, 10 cm length, 63 and 44 degrees helix angle corresponding to 4 cm and 8 cm pitch, respectively) submerged in 2mm glass beads (90% roundness with sizes 1.8 mm to 2.2 mm), For both screws, a similar trend is observed between rotational speed and thrust force. We used EDEM, a Discrete Element Modeling (DEM) software for computational studies of the screw interactions with granular media. There is 5-20% discrepancy between our computational and experimental results. We will discuss possible sources of error and the potential for using DEM as a design tool for SPV's.


Title: Clothoid-Based Global Path Planning for Autonomous Vehicles in Urban Scenarios
Key Words: curve fitting  mobile robots  path planning  road traffic  road vehicles  roads  autonomous vehicles  urban scenario  intelligent vehicles  kinematic constraints  continuous-curvature paths  low curvature derivatives  clothoid-based global path planning  road network representation  Roads  Path planning  Geometry  Autonomous vehicles  Wheels  Kinematics  Computational modeling 
Abstract: Intelligent vehicles require an efficient way to compute a feasible path that connects its current localization to a destination point. To achieve that, the knowledge about the road network, including its geometry, is important since connections between roads can be used in the path planning. This work consists on computing a feasible global path for autonomous vehicles with kinematic constraints. Piecewise linear continuous-curvature paths composed of clothoids, circular arcs, and straight lines are used for this purpose. Low curvature derivatives provide comfort to passengers. This approach provides a compact road network representation as only the parameters of the curves are stored. A real urban scenario with straight and curved roads, multiple lanes, intersections, and roundabouts is modeled and the proposed approach is validated. As a result of the proposed approaches, door-to-door global continuous-curvature paths are generated considering the shortest traveled distance.


Title: Information Based Mobile Sensor Planning for Source Term Estimation of a Non-Continuous Atmospheric Release
Key Words: air pollution  atmospheric chemistry  atmospheric techniques  Bayes methods  chemical sensors  disperse systems  hazardous materials  inverse problems  mobile sensor planning  Bayes' theorem  static sensors  single mobile sensor  chemical sensor  dispersion parameters  Gaussian puff dispersion model  meteorological information  inverse problem  hazardous material  noncontinuous atmospheric release  source term estimation  Robot sensing systems  Dispersion  Atmospheric modeling  Unmanned aerial vehicles  Position measurement  Wind speed  Mathematical model 
Abstract: Ahstract- This paper presents a method to estimate the original location and the mass of an instantaneous release of hazardous material into the atmosphere. It is formulated as an inverse problem, where concentration observations from a mobile sensor are fused with meteorological information and a Gaussian puff dispersion model to characterise the source. Bayes' theorem is used to estimate the parameters of the release taking into account the uncertainty that exists in the dispersion parameters and meteorological variables. An information based reward is used to guide an unmanned aerial vehicle equipped with a chemical sensor to the expected most informative measurement locations. Simulation results compare the performance between a single mobile sensor with various amounts of static sensors.


Title: Fore-Aft Leg Specialization Controller for a Dynamic Quadruped
Key Words: legged locomotion  robot dynamics  trajectory control  fore-aft leg specialization controller  running animals  robotic counterparts  functional dynamic decomposition  Dynamic Quadruped  trajectory-based controller  Legged locomotion  Trajectory  Force  Springs  Vehicle dynamics  Robot kinematics 
Abstract: Many running animals, unlike their robotic counterparts, have distinct morphologies and functional roles for their front and rear legs. In this paper we present a new control approach for a 5kg autonomous dynamic quadruped that explicitly encodes separate roles for each contralateral pair of legs. This controller utilizes a functional dynamic decomposition similar to Raibert's three part control law, but focuses on fore-aft leg specialization to regulate the robot's performance. The velocity of this controller, which exceeds 5 body lengths per sec, is compared with an improved trajectory-based controller and shown to be significantly more robust to changes in environment.


Title: Deep Lidar CNN to Understand the Dynamics of Moving Vehicles
Key Words: image colour analysis  image sensors  image sequences  learning (artificial intelligence)  neural net architecture  optical radar  semantic networks  pretext tasks  test time  including distilled image information  standard image-based optical flow  novel lidar-flow feature  semantic information  image data  consecutive lidar scans  testing time  CNN architecture  external observed vehicles  observer vehicle  proprio-motion  autonomous cars  Deep Learning solutions  RGB images  semantically rich information  Autonomous Driving  perception technologies  Deep lidar CNN  Laser radar  Task analysis  Vehicle dynamics  Three-dimensional displays  Dynamics  Machine learning  Semantics 
Abstract: Perception technologies in Autonomous Driving are experiencing their golden age due to the advances in Deep Learning. Yet, most of these systems rely on the semantically rich information of RGB images. Deep Learning solutions applied to the data of other sensors typically mounted on autonomous cars (e.g. lidars or radars) are not explored much. In this paper we propose a novel solution to understand the dynamics of moving vehicles of the scene from only lidar information. The main challenge of this problem stems from the fact that we need to disambiguate the proprio-motion of the “observer” vehicle from that of the external “observed” vehicles. For this purpose, we devise a CNN architecture which at testing time is fed with pairs of consecutive lidar scans. However, in order to properly learn the parameters of this network, during training we introduce a series of so-called pretext tasks which also leverage on image data. These tasks include semantic information about vehicleness and a novel lidar-flow feature which combines standard image-based optical flow with lidar scans. We obtain very promising results and show that including distilled image information only during training, allows improving the inference results of the network at test time, even when image data is no longer used.


Title: Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach
Key Words: collision avoidance  Markov processes  mobile robots  motion control  multi-agent systems  multi-robot systems  random processes  stochastic processes  motion trajectories  planning-based approach  dynamic objects  planning-based social force approach  joint long-term prediction  individual agent velocities  social forces  weighted random walk algorithm  stochastic motion policies  long-term predictions  multiple agents  joint motion  local interactions  long-term human motion prediction  dynamic environments  intelligent vehicles  mobile robots  Trajectory  Prediction algorithms  Force  Predictive models  Planning  Stochastic processes  Robots 
Abstract: The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.


Title: Footstep Planning in Rough Terrain for Bipedal Robots Using Curved Contact Patches
Key Words: humanoid robots  legged locomotion  off-road vehicles  path planning  robot vision  rough terrain  rough terrain stepping  WALK-MAN humanoid robot  flat foothold contact analysis  rough local terrain surfaces  curved patch modeling system  6DoF footstep sequences  black box walking controller  proper environment modeling  visual perception  foothold placements  exteroceptive perception  curved contact patches  bipedal robots  footstep planning  Planning  Three-dimensional displays  Rough surfaces  Surface roughness  Robot sensing systems  Navigation 
Abstract: Bipedal robots have gained a lot of locomotion capabilities the past few years, especially in the control level. Navigation over complex and unstructured environments using exteroceptive perception, is still an active research topic. In this paper, we present a footstep planning system to produce foothold placements, using visual perception and proper environment modeling, given a black box walking controller. In particular, we extend a state-of-the-art search-based planning approach (ARA*) that produces 6DoF footstep sequences in 3D space for flat uneven terrain, to also handle rough curved surfaces, e.g. rocks. This is achieved by integrating both a curved patch modeling system for rough local terrain surfaces and a flat foothold contact analysis based on visual range input data, into the existing planning framework. The system is experimentally validated using real-world point clouds, while rough terrain stepping demonstrations are presented on the WALK-MAN humanoid robot, in simulation.


Title: Robust and Precise Vehicle Localization Based on Multi-Sensor Fusion in Diverse City Scenes
Key Words: Global Positioning System  Kalman filters  optical radar  road vehicles  satellite navigation  sensor fusion  LiDAR  localization system  GNSS RTK module  urban downtown  complementary sensors  precise localization system  robust localization system  precise vehicle localization  localization measurements  error-state Kalman filter  ambiguity resolution success rate  multisensor fusion framework  size 60.0 km  size 5.0 cm to 10.0 cm  Laser radar  Three-dimensional displays  Estimation  Sensors  Global navigation satellite system  Autonomous vehicles  Robustness 
Abstract: We present a robust and precise localization system that achieves centimeter-level localization accuracy in disparate city scenes. Our system adaptively uses information from complementary sensors such as GNSS, LiDAR, and IMU to achieve high localization accuracy and resilience in challenging scenes, such as urban downtown, highways, and tunnels. Rather than relying only on LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and altitude cues to significantly improve localization system accuracy and robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion framework and achieves a better ambiguity resolution success rate. An error-state Kalman filter is applied to fuse the localization measurements from different sources with novel uncertainty estimation. We validate, in detail, the effectiveness of our approaches, achieving 5-10cm RMS accuracy and outperforming previous state-of-the-art systems. Importantly, our system, while deployed in a large autonomous driving fleet, made our vehicles fully autonomous in crowded city streets despite road construction that occurred from time to time. A dataset including more than 60 km real traffic driving in various urban roads is used to comprehensively test our system.


Title: Safe Distributed Lane Change Maneuvers for Multiple Autonomous Vehicles Using Buffered Input Cells
Key Words: collision avoidance  computational geometry  decision making  feedback  mobile robots  position control  road safety  road vehicles  safe distributed lane change maneuvers  multiple autonomous vehicles  reciprocal collision avoidance method  autonomous cars  linear dynamics  buffered input cell  Voronoi cell  Voronoi diagrams  vehicles control input  control stack  freeway driving scenario  decision-making layer  trajectory planning layer  feedback controller  BIC method  human-driven car  Collision avoidance  Robots  Vehicle dynamics  Aerospace electronics  Traffic control  Autonomous vehicles  Planning 
Abstract: This paper introduces the Buffered Input Cell as a reciprocal collision avoidance method for multiple vehicles with high-order linear dynamics, extending recently proposed methods based on the Buffered Voronoi Cell [1] and generalized Voronoi diagrams [2]. We prove that if each vehicle's control input remains in its Buffered Input Cell at each time step, collisions will be avoided indefinitely. The method is fast, reactive, and only requires that each vehicle measures the relative position of neighboring vehicles. We incorporate this collision avoidance method as one layer of a complete lane change control stack for autonomous cars in a freeway driving scenario. The lane change control stack comprises a decision-making layer, a trajectory planning layer, a trajectory following feedback controller, and the Buffered Input Cell for collision avoidance. We show in simulations that collisions are avoided with multiple vehicles simultaneously changing lanes on a freeway. We also show in simulations that autonomous cars using the BIC method effectively avoid collisions with an aggressive human-driven car.


Title: Deep Predictive Models for Collision Risk Assessment in Autonomous Driving
Key Words: Bayes methods  collision avoidance  decision making  driver information systems  image colour analysis  learning (artificial intelligence)  recurrent neural nets  risk management  video streaming  Deep Predictive Models  collision risk assessment  autonomous driving  predictive approach  assisted driving  deep predictive model  video streams  RGB images  temporal information  multi-modal information  proprioceptive state  Bayesian convolutional LSTM  decision making  Predictive models  Accidents  Stochastic processes  Uncertainty  Bayes methods  Cameras  Tensile stress 
Abstract: In this paper, we investigate a predictive approach for collision risk assessment in autonomous and assisted driving. A deep predictive model is trained to anticipate imminent accidents from traditional video streams. In particular, the model learns to identify cues in RGB images that are predictive of hazardous upcoming situations. In contrast to previous work, our approach incorporates (a) temporal information during decision making, (b) multi-modal information about the environment, as well as the proprioceptive state and steering actions of the controlled vehicle, and (c) information about the uncertainty inherent to the task. To this end, we discuss Deep Predictive Models and present an implementation using a Bayesian Convolutional LSTM. Experiments in a simple simulation environment show that the approach can learn to predict impending accidents with reasonable accuracy, especially when multiple cameras are used as input sources.


Title: End-to-End Driving Via Conditional Imitation Learning
Key Words: collision avoidance  learning systems  mobile robots  road traffic control  driving policy functions  conditional imitation learning  sensorimotor coordination  vision-based driving  robotic truck  driving policies  deep networks  high-level navigational commands  urban driving  high-level command input  condition imitation  Robot sensing systems  Task analysis  Vehicles  Cameras  Roads  Navigation 
Abstract: Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.


Title: Predicting Ego-Vehicle Paths from Environmental Observations with a Deep Neural Network
Key Words: driver information systems  feature extraction  image motion analysis  learning (artificial intelligence)  neural nets  road vehicles  static vehicle environment  grid-based prediction  varying assistance tasks  baseline approaches  environmental observations  deep neural network  advanced driver assistance systems  predictive model  road topologies  environmental properties  path extraction  ego-vehicle path prediction  ego-vehicle motion  Predictive models  Vehicles  Sensors  Roads  Trajectory  Data models  Motion measurement 
Abstract: Advanced driver assistance systems allow for increasing user comfort and safety by sensing the environment and anticipating upcoming hazards. Often, this requires to accurately predict how situations will change. Recent approaches make simplifying assumptions on the predictive model of the Ego-Vehicle motion or assume prior knowledge, such as road topologies, to be available. However, in many urban areas this assumption is not satisfied. Furthermore, temporary changes (e.g. construction areas, vehicles parked on the street) are not considered by such models. Since many cars observe the environment with several different sensors, predictive models can benefit from them by considering environmental properties. In this work, we present an approach for an Ego-Vehicle path prediction from such sensor measurements of the static vehicle environment. Besides proposing a learned model for predicting the driver's multi-modal future path as a grid-based prediction, we derive an approach for extracting paths from it. In driver assistance systems both can be used to solve varying assistance tasks. The proposed approach is evaluated on real driving data and outperforms several baseline approaches.


Title: Learning Steering Bounds for Parallel Autonomous Systems
Key Words: Bayes methods  cameras  control engineering computing  Gaussian processes  learning (artificial intelligence)  mixture models  mobile robots  neural nets  path planning  road vehicles  robot vision  steering systems  parallel autonomous systems  deep learning  autonomous driving task  camera data input  autonomous navigation  vehicle control  continuous control probability distribution  deep neural network based algorithm  steering angles  parallel autonomy setting  driving conditions  variational Bayesian methods  steering bounds learning  end-to-end learning  steering control options  Gaussian mixture models  Autonomous vehicles  Navigation  Neural networks  Probability distribution  Decision making  Machine learning  Bayes methods 
Abstract: Deep learning has been successfully applied to “end-to-end” learning of the autonomous driving task, where a deep neural network learns to predict steering control commands from camera data input. However, the learned representations do not support higher-level decision making required for autonomous navigation, nor the uncertainty estimates required for parallel autonomy, where vehicle control is shared between human and robot. This paper tackles the problem of learning a representation to predict a continuous control probability distribution, and thus steering control options and bounds for those options, which can be used for autonomous navigation. Each mode of the distribution encodes a possible macro-action that the system could execute at that instant, and the covariances of the modes place bounds on safe steering control values. Our approach has the added advantage of being trained on unlabeled data collected from inexpensive cameras. The deep neural network based algorithm generates a probability distribution over the space of steering angles, from which we leverage Variational Bayesian methods to extract a mixture model and compute the different possible actions in the environment. A bound, which the autonomous vehicle must respect in our parallel autonomy setting, is then computed for each of these actions. We evaluate our approach on a challenging dataset containing a wide variety of driving conditions, and show that our algorithm is capable of parameterizing Gaussian Mixture Models for possible actions, and extract steering bounds with a mean error of only 2 degrees. Additionally, we demonstrate our system working on a full scale autonomous vehicle and evaluate its ability to successful handle various different parallel autonomy situations.


Title: End to End Learning of Spiking Neural Network Based on R-STDP for a Lane Keeping Vehicle
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  neural nets  road vehicles  robot vision  SLAM (robots)  spiking neural network  lane keeping vehicle  mobile applications  mobile robot applications  reward-modulated spike-timing-dependent-plasticity  reinforcement learning  Pioneer robot  lane information  robot tasks control  end to end learning approach  R-STDP  SNNs training  neuromorphic vision sensor  lateral localization accuracy  Voltage control  Task analysis  Robot sensing systems  Training  Synapses  Neurons 
Abstract: Learning-based methods have demonstrated clear advantages in controlling robot tasks, such as the information fusion abilities, strong robustness, and high accuracy. Meanwhile, the on-board systems of robots have limited computation and energy resources, which are contradictory with state-of-the-art learning approaches. They are either too lightweight to solve complex problems or too heavyweight to be used for mobile applications. On the other hand, training spiking neural networks (SNNs) with biological plausibility has great potentials of performing fast computation and energy efficiency. However, the lack of effective learning rules for SNNs impedes their wide usage in mobile robot applications. This paper addresses the problem by introducing an end to end learning approach of spiking neural networks for a lane keeping vehicle. We consider the reward-modulated spike-timing-dependent-plasticity (R-STDP) as a promising solution in training SNNs, since it combines the advantages of both reinforcement learning and the well-known STDP. We test our approach in three scenarios that a Pioneer robot is controlled to keep lanes based on an SNN. Specifically, the lane information is encoded by the event data from a neuromorphic vision sensor. The SNN is constructed using R-STDP synapses in an all-to-all fashion. We demonstrate the advantages of our approach in terms of the lateral localization accuracy by comparing with other state-of-the-art learning algorithms based on SNNs.


Title: Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation
Key Words: estimation theory  image matching  interpolation  object detection  object tracking  statistical distributions  stereo image processing  target object clouds  sparse point clouds  point-to-distribution matching technique  tracking algorithm  3D point clouds  direct point-to-point matching method  real-time object tracking  Estimation of Vertical Distributions  object-tracking strategy  EVD  interpolation method  3D interpolation  Three-dimensional displays  Target tracking  Real-time systems  Solid modeling  Interpolation  Vehicle dynamics  Laser radar 
Abstract: While object tracking for 3D point clouds has been widely researched in recent years, most trackers employ a direct point-to-point matching method under the assumption that target object clouds are dense, although the method is not suitable for sparse point clouds. In this paper, we introduce a novel object-tracking strategy that enables even sparse point clouds to be tracked properly. The strategy involves estimating distributions, called as Estimation of Vertical Distributions (EVD), by the proposed interpolation method to augment data and by a point-to-distribution matching technique. The EVD step generates vertical distributions of unoccupied areas on a target object using the distributions of the occupied areas and then seeks the optimal solution through a coarse-to-fine grid search to guarantee real-time performance. In order to verify the proposed tracking algorithm, we have tested our tracker on real world data collected by our own platform, and the results have demonstrated that the tracker outperforms other trackers.


Title: Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
Key Words: ecology  hydrological equipment  hydrological techniques  microorganisms  multi-robot systems  remotely operated vehicles  reservoirs  water quality  data-driven behavior  real geophysical data  MODIS measurements  water-sampling apparatus  water quality sensor  plankton-rich water samples  chlorophyll density  autonomous surface vehicles plan  water-sampling behavior  efficient measurement  fresh-water systems  measuring contamination levels  drinking water  physical sampling  strategic water sampling  heterogeneous multirobot system  water reservoir  explorer robot  water sampling apparatus  ASV  Pollution measurement  Geophysical measurements  Robot sensing systems  Real-time systems  Time measurement  Water pollution 
Abstract: Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.


Title: Robust Model-Aided Inertial Localization for Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  C++ language  drag  inertial navigation  Kalman filters  marine navigation  nonlinear filters  vehicle model parameter error  ADCP-aiding  DVL bottom-lock loss  IMU biases  navigation filter  DVL dropouts  robust model-aided inertial localization  autonomous underwater vehicles  Unscented Kalman Filter  inertial model-aiding  Acoustic Doppler Current Profiler measurement incorporation  Earth rotation  tactical grade IMU  heading convergence  data denial  drag  thrust model  MTK  ROCK  FlatFish AUV  Navigation  Mathematical model  Accelerometers  Damping  Uncertainty  Acoustics  Acceleration 
Abstract: This paper presents a manifold based Unscented Kalman Filter that applies a novel strategy for inertial, model-aiding and Acoustic Doppler Current Profiler (ADCP) measurement incorporation. The filter is capable of observing and utilizing the Earth rotation for heading estimation with a tactical grade IMU, and utilizes information from the vehicle model during DVL drop outs. The drag and thrust model-aiding accounts for the correlated nature of vehicle model parameter error by applying them as states in the filter. ADCP-aiding provides further information for the model-aiding in the case of DVL bottom-lock loss. Additionally this work was implemented using the MTK and ROCK framework in C++, and is capable of running in real-time on computing available on the FlatFish AUV. The IMU biases are estimated in a fully coupled approach in the navigation filter. Heading convergence is shown on a real-world data set. Further experiments show that the filter is capable of consistent positioning, and data denial validates the method for DVL dropouts due to very low or high altitude scenarios.


Title: Preliminary Evaluation of Cooperative Navigation of Underwater Vehicles without a DVL Utilizing a Dynamic Process Model
Key Words: attitude control  autonomous underwater vehicles  Global Positioning System  marine control  mobile robots  path planning  robot dynamics  robot kinematics  sensors  velocity measurement  preliminary evaluation  dynamic process model  fully dynamic vehicle process model  acoustic modem  surface vehicle  at-sea experimental trials  JHU Iver3 autonomous underwater vehicle  underwater vehicle navigation  DVL acoustic bottom-lock range  kinematic process model  dynamical process model  submerged vehicle  underwater communication  velocity measurements  attitude sensor  Acoustics  Underwater vehicles  Kinematics  Global Positioning System  Sensors 
Abstract: This paper reports a preliminary study for use of a fully dynamic vehicle process model in combined underwater communication and navigation (cooperative navigation) of underwater vehicles equipped with an acoustic modem, attitude, and depth sensors, but lacking a Doppler velocity log (DVL), and a surface vehicle equipped with an acoustic modem and GPS. We report both simulation and at-sea experimental trials with the JHU Iver3 autonomous underwater vehicle (AUV). The case of underwater vehicle navigation without a DVL is of interest in several use-cases including (a) small and low-cost underwater vehicles for which DVLs may be impractical or infeasible due to their size and cost and (b) for missions in which the vehicle's altitude above the sea floor (or depth beneath overhead ice) exceeds the DVL acoustic bottom-lock range. To the best of our knowledge, all previous studies on cooperative navigation have reported use of a kinematic process model, which works well in the presence of frequent, high-accuracy velocity measurements, as is the case when the vehicle is equipped with a DVL. This preliminary study suggests that the dynamical process model may offer a significant advantage over the purely kinematic model in the absence of frequent, high-accuracy velocity measurements, as is the case when the submerged vehicle is not equipped with a DVL.


Title: Online System Identification and Calibration of Dynamic Models for Autonomous Ground Vehicles
Key Words: calibration  mobile robots  vehicles  wheels  high-fidelity dynamical model  constant time algorithm  autonomous ground vehicles  dynamic models  online system identification  scale four wheel drive vehicle  estimated parameter  model parameters  informative motion segments  robotic platform  Calibration  Vehicle dynamics  Motion segmentation  Dynamics  Wheels  Friction 
Abstract: This paper is concerned with system identification and the calibration of parameters of dynamic models used in different robotic platforms. A constant time algorithm has been developed in order to automatically calibrate the parameters of a high-fidelity dynamical model for a robotic platform. The presented method is capable of choosing informative motion segments in order to calibrate model parameters in constant time while also calculating a confidence level on each estimated parameter. Simulations and experiments with a ⅛ th scale four wheel drive vehicle are performed to calibrate two of the parameters of test vehicle which demonstrate the accuracy and efficiency of the approach.


Title: Dynamic Modeling and Identification of an Heterogeneously Actuated Underwater Manipulator Arm
Key Words: actuators  autonomous underwater vehicles  gears  manipulators  mobile robots  position control  telerobotics  arms parameters  linear actuators  identification procedure  manipulator arms  dynamic modeling  heterogeneously actuated underwater manipulator arm  electrically driven underwater robot manipulator  Ifremer's HROV Ariane underwater vehicle  hybrid remotely operated vehicle  Manipulator dynamics  Actuators  Vehicle dynamics  Gears  Friction  Mathematical model 
Abstract: This paper deals with the dynamic modeling and identification of an electrically driven underwater robot manipulator. The proposed study includes the dynamic modeling of the actuators of the arm as well as the identification of the parameters of the model. The proposed method deals with the specific case of heterogeneously actuated arms, namely arms with actuators behaving differently for each joint, being considered at the kinematic level. Indeed, we show how to estimate the arms parameters when some of their revolute joints are directly actuated by geared motors, while the others are actuated by linear actuators. A minimum set of identifiable parameters is determined, and adequate excitation trajectories are generated and used in the identification procedure. Realtime experimental validation on the manipulator arms of Ifremer's HROV (Hybrid Remotely Operated Vehicle) Ariane underwater vehicle demonstrates that the proposed method improves the estimation of the dynamic model.


Title: A Scalable Multi-Robot Task Allocation Algorithm
Key Words: computational complexity  industrial robots  mobile robots  multi-robot systems  nearest neighbour methods  pattern clustering  vehicle routing  warehouse automation  CVRP instance  nCAR  scalable multirobot task allocation algorithm  modern warehouses  docking station  route planning  capacity-constrained vehicle routing problem  nearest-neighbor based clustering and routing  Task analysis  Heuristic algorithms  Clustering algorithms  Resource management  Routing  Service robots 
Abstract: In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.


Title: Sonar Visual Inertial SLAM of Underwater Structures
Key Words: oceanographic techniques  SLAM (robots)  sonar  underwater sound  underwater vehicles  underwater structures  acoustic range data  sonar visual inertial SLAM  visual-inertial state estimation package  resource management  marine archaeology  underwater acoustic sensor  underwater cave  underwater wrecks  underwater domain  Sonar  Cameras  Visualization  Sonar navigation  Simultaneous localization and mapping  Underwater structures 
Abstract: This paper presents an extension to a state of the art Visual-Inertial state estimation package (OKVIS) in order to accommodate data from an underwater acoustic sensor. Mapping underwater structures is important in several fields, such as marine archaeology, search and rescue, resource management, hydrogeology, and speleology. Collecting the data, however, is a challenging, dangerous, and exhausting task. The underwater domain presents unique challenges in the quality of the visual data available; as such, augmenting the exteroceptive sensing with acoustic range data results in improved reconstructions of the underwater structures. Experimental results from underwater wrecks, an underwater cave, and a submerged bus demonstrate the performance of our approach.


Title: Autonomous Control of the Interacting-BoomCopter UAV for Remote Sensor Mounting
Key Words: aircraft control  autonomous aerial vehicles  finite state machines  mobile robots  propellers  robot vision  target tracking  Interacting-BoomCopter UAV  remote sensor mounting  sensor package  vertical surface  unmanned aerial vehicle  on-board webcam  reversible propeller  aerial manipulation task  vehicle design  image processing algorithms  target tracking  extended finite state machine  high-level autonomous control  autonomous control strategy  I-BC platform  autonomous sensor  Task analysis  Propellers  Webcams  Unmanned aerial vehicles  Inspection  Force  Control systems 
Abstract: This paper presents a novel approach for autonomously mounting a sensor package on a vertical surface with an unmanned aerial vehicle (UAV). The Interacting-BoomCopter (I-BC) UAV uses an on-board webcam and computer along with a horizontally-mounted reversible propeller on its front boom to autonomously perform the aerial manipulation task. An overview of the vehicle design is presented along with the image processing algorithms used for target tracking, and the implementation of an extended finite state machine (EFSM) for carrying out the high-level autonomous control. The effectiveness of the autonomous control strategy and I-BC platform are examined through the performance of several autonomous sensor mounting flight tests.


Title: Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles
Key Words: aerospace robotics  collision avoidance  helicopters  mobile robots  predictive control  robot dynamics  vehicle dynamics  path planning  trajectory generation algorithms  MPC  sequential linear quadratic  SLQ  obstacle-avoidance algorithm  Model Predictive Control  dynamic environments  planning algorithms  multirotor  suspended load  Heuristic algorithms  Trajectory  Cost function  Mathematical model  Vehicle dynamics  Load modeling  Computational modeling 
Abstract: This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.


Title: Asymmetric Collaborative Bar Stabilization Tethered to Two Heterogeneous Aerial Vehicles
Key Words: autonomous aerial vehicles  force  stability  three-term control  asymmetric collaborative bar stabilization tethered  unmanned aerial vehicles  rigid links  tensile forces  control objective  PID control law  decoupled motions  cascaded motions  system asymmetries  cable lengths  UAV  systems physical parameters  Bars  Force  Unmanned aerial vehicles  Dynamics  Mathematical model  Trajectory 
Abstract: We consider a system composed of a bar tethered to two unmanned aerial vehicles (UAVs), where the cables behave as rigid links under tensile forces, and with the control objective of stabilizing the bar's pose around a desired pose. Each UAV is equipped with a PID control law, and we verify that the bar's motion is decomposable into three decoupled motions, namely a longitudinal, a lateral and a vertical. We then provide relations between the UAV s' gains, which, if satisfied, allows us to decompose each of those motions into two cascaded motions; the latter relations between the UAV s' gains are found so as to counteract the system asymmetries, such as the different cable lengths and the different UAV s' weights. Finally, we provide conditions, based on the system's physical parameters, that describe good and bad types of asymmetries. We present experiments that demonstrate the stabilization of the bar's pose.


Title: First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle
Key Words: autonomous aerial vehicles  image colour analysis  mobile robots  path planning  robot vision  stereo image processing  multiroom exploration task  DelFly Explorer  autonomous indoor exploration mission  room exploration  stereo-vision based droplet algorithm  heading-based door passage algorithm  flapping wing vehicles  autonomous exploration tasks  autonomous multiroom exploration  wing vehicle  MAVs  autonomous indoor navigation  rotary wings  flapping wing MAV  stereo vision system  microair vehicles  monocular color based Snake-gate algorithm  Task analysis  Robot sensing systems  Navigation  Collision avoidance  Cameras  Image color analysis 
Abstract: One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.


Title: Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning
Key Words: collision avoidance  learning (artificial intelligence)  life testing  mobile robots  neurocontrollers  regression analysis  autonomous vehicle  imitation learning  surrogate agents  test scenario generation  performance modes  deep neural networks  imitator surrogates  mission performance  simulation-based testing  on-line imitation  complex mission  target vehicle  behavioral modes  dataset aggregation  collision avoidance  Testing  Training  Autonomous vehicles  Trajectory  Adaptation models  History 
Abstract: In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.


Title: Near-optimal Irrevocable Sample Selection for Periodic Data Streams with Applications to Marine Robotics
Key Words: autonomous underwater vehicles  environmental science computing  mobile robots  optimisation  sampling methods  set theory  spatiotemporal phenomena  optimal irrevocable sample selection  periodic data streams  marine robotics  spatiotemporal phenomena  classical secretary problem  random order  environmental monitoring domains  spatiotemporal structure  representative samples  periodic structure  monotone submodular utility function  Martha's Vineyard Coastal Observatory  phytoplankton sample locations  information-theoretic sense  periodic secretary algorithm  theoretical performance guarantees  sample selection algorithm  environmental dataset  optimal sample set  Entropy  Mutual information  Robot sensing systems  Prediction algorithms  Real-time systems  Periodic structures 
Abstract: We consider the task of monitoring spatiotemporal phenomena in real-time by deploying limited sampling resources at locations of interest irrevocably and without knowledge of future observations. This task can be modeled as an instance of the classical secretary problem. Although this problem has been studied extensively in theoretical domains, existing algorithms require that data arrive in random order to provide performance guarantees. These algorithms will perform arbitrarily poorly on data streams such as those encountered in robotics and environmental monitoring domains, which tend to have spatiotemporal structure. We focus on the problem of selecting representative samples from phenomena with periodic structure and introduce a novel sample selection algorithm that recovers a near-optimal sample set according to any monotone submodular utility function. We evaluate our algorithm on a seven-year environmental dataset collected at the Martha's Vineyard Coastal Observatory and show that it selects phytoplankton sample locations that are nearly optimal in an information-theoretic sense for predicting phytoplankton concentrations in locations that were not directly sampled. The proposed periodic secretary algorithm can be used with theoretical performance guarantees in many real-time sensing and robotics applications for streaming, irrevocable sample selection from periodic data streams.


Title: Autonomous Feature Tracing and Adaptive Sampling in Real-World Underwater Environments
Key Words: autonomous underwater vehicles  lakes  mobile robots  temperature sensors  real-world operation  adaptive sampling missions  AUV  Autonomous feature tracing  real-world Underwater environments  underwater environmental sensing  compact high resolution  temperature sensing module  microstructure  turbulence measurements  sensing requirements  horizontal variation capture  water bodies  Temperature measurement  Lakes  Microorganisms  Robot sensing systems  Trajectory  Temperature sensors 
Abstract: Applications of robots for gathering data in underwater environments has been limited due to the challenges posed by the medium. We have developed a miniature, agile, easy to carry and deploy Autonomous Underwater Vehicle (AUV) equipped with a suite of sensors for underwater environmental sensing. We have also developed a compact high resolution fast temperature sensing module for the AUV for microstructure and turbulence measurements in water bodies. In this paper, we describe a number of algorithms and subsystems of the AUV that enable autonomous real-world operation, and present the data gathered in an experimental campaign in collaboration with limnologists. We demonstrate adaptive sampling missions where the AUV could autonomously locate a zone of interest and adapt its trajectory to stay in it. Further, it could execute specific behaviors to accommodate special sensing requirements necessary to enhance the quality of the data collected. In these missions, the AUV could autonomously trace a feature and capture horizontal variation in various quantities, including turbidity and temperature fluctuations, allowing limnologists to study lake phenomena in an additional dimension.


Title: Navigating Congested Environments with Risk Level Sets
Key Words: collision avoidance  mobile robots  multi-agent systems  road vehicles  risk level set  congested environment navigation  cluttered environment  congestion cost  occupancy risk  cost function  planning space  agent planning  autonomous vehicle driving  risk threshold  conservative behavior  aggressive behavior  Planning  Level set  Navigation  Vehicle dynamics  Autonomous vehicles  Collision avoidance  Cost function 
Abstract: In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.


Title: Algorithms for Routing of Unmanned Aerial Vehicles with Mobile Recharging Stations
Key Words: autonomous aerial vehicles  battery powered vehicles  computational complexity  travelling salesman problems  vehicle routing  Unmanned Aerial Vehicles  mobile recharging stations  energy-limited Unmanned Aerial Vehicle  stationary recharging stations  Unmanned Ground Vehicles  UGV  Traveling Salesperson Problem  stationary charging stations  UAV mission  Routing  NP-Hard  Generalized TSP  Batteries  Unmanned aerial vehicles  Charging stations  Land vehicles  Optimization  Monitoring  Planning 
Abstract: We study the problem of finding a tour for an energy-limited Unmanned Aerial Vehicle (UAV) to visit a set of sites in the least amount of time. We envision scenarios where the UAV can be recharged along the way either by landing on stationary recharging stations or on Unmanned Ground Vehicles (UGVs) acting as mobile recharging stations. This leads to a new variant of the Traveling Salesperson Problem (TSP). We present an algorithm that finds not only the order in which to visit the sites but also when and where to land on the charging stations to recharge. Our algorithm plans tours for the UGVs as well as determines best locations to place stationary charging stations. While the problems we study are NP-Hard, we present a practical solution using Generalized TSP that finds the optimal solution. If the UGVs are slower, the algorithm also finds the minimum number of UGVs required to support the UAV mission such that the UAV is not required to wait for the UGV. Our simulation results show that the running time is acceptable for reasonably sized instances.


Title: MergeNet: A Deep Net Architecture for Small Obstacle Discovery
Key Words: image colour analysis  learning (artificial intelligence)  neural net architecture  object tracking  traffic engineering computing  lost and found dataset  complementary features  RGBD input  high level features  low level features  weight-sharing  multistage training procedure  annotation process  autonomous driving  on-road scenes  novel network architecture  small obstacle discovery  deep net architecture  MergeNet  Roads  Image segmentation  Strips  Semantics  Training  Autonomous vehicles  Task analysis 
Abstract: We present here, a novel network architecture called MergeNet for discovering small obstacles for on-road scenes in the context of autonomous driving. The basis of the architecture rests on the central consideration of training with less amount of data since the physical setup and the annotation process for small obstacles is hard to scale. For making effective use of the limited data, we propose a multi-stage training procedure involving weight-sharing, separate learning of low and high level features from the RGBD input and a refining stage which learns to fuse the obtained complementary features. The model is trained and evaluated on the Lost and Found dataset and is able to achieve state-of-art results with just 135 images in comparison to the 1000 images used by the previous benchmark. Additionally, we also compare our results with recent methods trained on 6000 images and show that our method achieves comparable performance with only 1000 training samples.


Title: Pedestrian Prediction by Planning Using Deep Neural Networks
Key Words: collision avoidance  convolution  learning (artificial intelligence)  mobile robots  neural nets  pedestrians  traffic engineering computing  monolithic neural network  inverse reinforcement learning  pedestrian prediction  deep neural networks  collision avoidance  autonomous vehicles  goal-directed planning  mixture density function  motion prediction  convolutional network  traffic participant prediction  trajectories  Planning  Network topology  Topology  Convolution  Learning (artificial intelligence)  Trajectory  Prediction algorithms 
Abstract: Accurate traffic participant prediction is the prerequisite for collision avoidance of autonomous vehicles. In this work, we propose to predict pedestrians using goal-directed planning. For this, we infer a mixture density function for possible destinations. We use these destinations as the goal states of a planning stage that performs motion prediction based on common behavior patterns. The patterns are learned by a fully convolutional network operating on maps of the environment. We show that this entire system can be modeled as one monolithic neural network and trained via inverse reinforcement learning. Experimental validation on real world data shows the system's ability to predict both, destinations and trajectories accurately.


Title: Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization
Key Words: graph theory  intelligent transportation systems  optimisation  pose estimation  sensor fusion  stereo image processing  3D localization  factor graph-based optimization  autonomous driving  3D pose measurement  asynchronous multisensor fusion  asynchronous-measurement alignment  graph nodes  out-of-sequence measurement alignment  multiple navigation sensors  modular sensor-fusion system  autonomous vehicles  3D mapping  asynchronous sensors  multiple heterogeneous sensors  Sensors  Three-dimensional displays  Optimization  Atmospheric measurements  Particle measurements  Frequency measurement  Laser radar 
Abstract: In this paper, we address the problem of optimally fusing multiple heterogeneous and asynchronous sensors for use in 3D mapping and localization of autonomous vehicles. To this end, based on the factor graph-based optimization framework, we design a modular sensor-fusion system that allows for efficient and accurate incorporation of multiple navigation sensors operating at different sampling rates. In particular, we develop a general method of out-of-sequence (asynchronous) measurement alignment to incorporate heterogeneous sensors into a factor graph for mapping and localization in 3D, without requiring the addition of new graph nodes, thus allowing the graph to have an overall reduced complexity. The proposed sensor-fusion system is validated on a real-world experimental dataset, in which the asynchronous-measurement alignment is shown to have an improved performance when compared to a naive approach without alignment.


Title: Localization Under Topological Uncertainty for Lane Identification of Autonomous Vehicles
Key Words: hidden Markov models  mobile robots  position control  remotely operated vehicles  road traffic control  topology  VSM-HMM  topological uncertainty  lane membership  topological localization process  topological structure estimation  AV lane estimation  lane identification  autonomous vehicles  topological location  decision-making  public roads  variable structure multiple hidden Markov model  metric location  Earth mover distance  Hidden Markov models  Computational modeling  Topology  Roads  Uncertainty  Measurement  Vehicle dynamics 
Abstract: Autonomous vehicles (AVs) require accurate metric and topological location estimates for safe, effective navigation and decision-making. Although many high-definition (HD) roadmaps exist, they are not always accurate since public roads are dynamic, shaped unpredictably by both human activity and nature. Thus, AVs must be able to handle situations in which the topology specified by the map does not agree with reality. We present the Variable Structure Multiple Hidden Markov Model (VSM-HMM) as a framework for localizing in the presence of topological uncertainty, and demonstrate its effectiveness on an AV where lane membership is modeled as a topological localization process. VSM-HMMs use a dynamic set of HMMs to simultaneously reason about location within a set of most likely current topologies and therefore may also be applied to topological structure estimation as well as AV lane estimation. In addition, we present an extension to the Earth Mover's Distance which allows uncertainty to be taken into account when computing the distance between belief distributions on simplices of arbitrary relative sizes.


Title: Stabilizing Traffic with Autonomous Vehicles
Key Words: frequency-domain analysis  intelligent transportation systems  linear systems  mobile robots  nonlinear programming  optimal control  road safety  road traffic control  road vehicles  stability  autonomously controlled vehicles  autonomous vehicles  human-driven vehicles  traffic stabilization  safer roads  energy savings  single-lane system stabilization  linear string stability  optimality conditions  frequency-domain analysis  nonlinear optimization problem  safety constraint  optimal linear controller  traffic conditions  human driver behavior  Autonomous vehicles  Vehicle dynamics  Stability criteria  Optimization  Mathematical model 
Abstract: Autonomous vehicles promise safer roads, energy savings, and more efficient use of existing infrastructure, among many other benefits. Although the effect of autonomous vehicles has been studied in the limits (near-zero or full penetration), the transition range requires new formulations, mathematical modeling, and control analysis. In this article, we study the ability of small numbers of autonomous vehicles to stabilize a single-lane system of human-driven vehicles. We formalize the problem in terms of linear string stability, derive optimality conditions from frequency-domain analysis, and pose the resulting nonlinear optimization problem. In particular, we introduce two conditions which simultaneously stabilize traffic while imposing a safety constraint on the autonomous vehicle and limiting degradation of performance. With this optimal linear controller in a system with typical human driver behavior, we can numerically determine that only a 6% uniform penetration of autonomously controlled vehicles (i.e. one per string of up to 16 human-driven vehicles) is necessary to stabilize traffic across all traffic conditions.


Title: Data-Driven Model Predictive Control of Autonomous Mobility-on-Demand Systems
Key Words: demand forecasting  intelligent transportation systems  predictive control  recurrent neural nets  road traffic control  end-to-end performance  customer demand  data-driven Model Predictive Control  LSTM neural network  travel demand  Autonomous Mobility-on-Demand systems control  DiDi Chuxing  MPC algorithm  transportation system  optimal rebalancing strategy  AMoD system  Prediction algorithms  Predictive control  Transportation  Pricing  Control systems  Steady-state  Real-time systems 
Abstract: The goal of this paper is to present an end-to-end, data-driven framework to control Autonomous Mobility-on-Demand systems (AMoD, i.e. fleets of self-driving vehicles). We first model the AMoD system using a time-expanded network, and present a formulation that computes the optimal rebalancing strategy (i.e., preemptive repositioning) and the minimum feasible fleet size for a given travel demand. Then, we adapt this formulation to devise a Model Predictive Control (MPC) algorithm that leverages short-term demand forecasts based on historical data to compute rebalancing strategies. Using simulations based on real customer data from DiDi Chuxing, we test the end-to-end performance of this controller with a state-of-the-art LSTM neural network to predict customer demand: we show that this approach scales very well for large systems (indeed, the computational complexity of the MPC algorithm does not depend on the number of customers and of vehicles in the system) and outperforms state-of-the-art rebalancing strategies by reducing the mean customer wait time by up to to 89.6 %.


Title: Automated Process for Incorporating Drivable Path into Real-Time Semantic Segmentation
Key Words: cameras  image segmentation  mobile robots  object detection  path planning  road traffic  road vehicles  robot vision  path prediction model  camera sensors  autonomous vehicle systems  vision systems  real-time semantic segmentation  intelligent vehicles  odometry  monocular camera  car-width drivable lane  path proposal category  intelligent vehicle system  drivable path information  human operation  clear lane markings  urban roads  Semantics  Cameras  Roads  Image segmentation  Sensors  Proposals  Trajectory 
Abstract: Vision systems are widely used in autonomous vehicle systems due to the rich information that camera sensors provide of the surrounding environment. This paper presents an automatic algorithm to obtain the drivable path of a vehicle operating in urban roads with or without clear lane markings. The developed system projects trajectories obtained during human operation of the vehicle and utilizes these to generate automatic labels for training a semantic based path prediction model. The system segments an urban scenario into 13 categories including vehicles, pedestrian, undrivable road, other categories relevant to urban roads, and a new class for a path proposal. The drivable path information is essential particularly in unstructured scenarios, and is critical for an intelligent vehicle system to make sound driving decisions. The path proposal category is a car-width drivable lane estimated to be safe to drive for the vehicle under consideration. The data collection, model training and inference process requires only images from a monocular camera and odometry from a low-cost IMU combined with a wheel encoder. The algorithm has been successfully demonstrated on the Sydney University campus, which is a challenging environment without clear road markings. The algorithm was demonstrated to run in real-time, proving its applicability for intelligent vehicles.


Title: Design, Modeling, and Analysis of Inductive Resonant Coupling Wireless Power Transfer for Micro Aerial Vehicles (MAVs)
Key Words: battery powered vehicles  coils  inductive power transmission  WPT system  transmit coil  WPT circuit design  power-transfer model  two-coil system  WPT circuitry  wirelessly powered MAV  inductive resonant coupling  microaerial vehicle  power transfer system  Batteries  Magnetic resonance  Integrated circuit modeling  Geometry  Analytical models  Couplings  Wireless power transfer 
Abstract: This paper presents the design, modeling, analysis, and experimental validation of an inductive resonant wireless power transfer (WPT) system to power a micro aerial vehicle (MAV). Using WPT, in general, enables longer flight times, virtually eliminates the need for batteries, and minimizes down time for recharging or replacing batteries. The proposed WPT system consists of a transmit coil, which can either be fixed to ground or placed on a mobile platform, and a receive coil carried by the MAV. The details of the WPT circuit design are presented. A power-transfer model is developed for the two-coil system, where the model is used to select suitable coil geometries to maximize the power received by the MAV for hovering. Analysis, simulation, and experimental results are presented to demonstrate the effectiveness of the WPT circuitry. Finally, a wirelessly powered MAV that hovers above the transmit coil is demonstrated in a laboratory setting.


Title: Active Image-Based Modeling with a Toy Drone
Key Words: autonomous aerial vehicles  data acquisition  image reconstruction  image sensors  solid modelling  stereo image processing  iterative linear method  multiview stereo problem  online model reconstruction  toy unmanned aerial vehicle  data acquisition  toy drone  image-based modeling techniques  photo-realistic 3D models  multi-view stereo algorithm  active image-based modeling  Three-dimensional displays  Image reconstruction  Solid modeling  Unmanned aerial vehicles  Planning  Pipelines  Cameras 
Abstract: Image-based modeling techniques [1]-[3] can now generate photo-realistic 3D models from images. But it is up to users to provide high quality images with good coverage and view overlap, which makes the data capturing process tedious and time consuming. We seek to automate data capturing for image-based modeling. The core of our system is an iterative linear method to solve the multi-view stereo (MVS) problem quickly and plan the Next-Best-View (NBV) effectively. Our fast MVS algorithm enables online model reconstruction and quality assessment to determine the NBVs on the fly. We test our system with a toy unmanned aerial vehicle (UAV) in simulated, indoor and outdoor experiments. Results show that our system improves the efficiency of data acquisition and ensures the completeness of the final model.


Title: Intelligent Shipwreck Search Using Autonomous Underwater Vehicles
Key Words: archaeology  autonomous underwater vehicles  control engineering computing  image processing  intelligent control  marine control  mobile robots  path planning  sonar  archaeological survey  intelligent shipwreck search  autonomous underwater vehicles  autonomous robot system  multistep pipeline  high altitude scan  low-resolution side scan sonar data  image processing software  AUV path planner  archaeological sites  underwater archaeological sites  ranking algorithm  Sonar  Proposals  Clustering algorithms  Pipelines  Feature extraction  Software 
Abstract: This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.


Title: A Robust Model Predictive Control Approach for Autonomous Underwater Vehicles Operating in a Constrained Workspace
Key Words: autonomous underwater vehicles  collision avoidance  mobile robots  nonlinear control systems  predictive control  robust control  robust Model Predictive Control approach  constrained workspace  underwater robotic vehicles  static obstacles  workspace boundary  thruster saturation  vehicle velocity  control design  ocean currents  control inputs  way-point tracking mission  control strategy  constrained test tank  Nonlinear Model Predictive Control scheme  way points  underwater robotic vehicle  Oceans  Robots  Underwater vehicles  Mathematical model  Vehicle dynamics  Energy consumption  Computational modeling 
Abstract: This paper presents a novel Nonlinear Model Predictive Control (NMPC) scheme for underwater robotic vehicles operating in a constrained workspace including static obstacles. The purpose of the controller is to guide the vehicle towards specific way points. Various limitations such as: obstacles, workspace boundary, thruster saturation and predefined desired upper bound of the vehicle velocity are captured as state and input constraints and are guaranteed during the control design. The proposed scheme incorporates the full dynamics of the vehicle in which the ocean currents are also involved. Hence, the control inputs calculated by the proposed scheme are formulated in a way that the vehicle will exploit the ocean currents, when these are in favor of the way-point tracking mission which results in reduced energy consumption by the thrusters. The performance of the proposed control strategy is experimentally verified using a 4 Degrees of Freedom (DoF) underwater robotic vehicle inside a constrained test tank with obstacles.


Title: Design, Modeling, and Nonlinear Model Predictive Tracking Control of a Novel Autonomous Surface Vehicle
Key Words: autonomous underwater vehicles  boats  Global Positioning System  hydrodynamics  indoor environment  matrix algebra  mobile robots  motion control  nonlinear control systems  predictive control  tracking  trajectory control  nonlinear model predictive tracking control  autonomous surface vehicle  autonomous robotic boat  indoor environments  outdoor environments  cross type four-thruster configuration  robot prototype  nonlinear dynamic model  NMPC algorithm  surface swarm robotics testbeds  trajectory tracking  holonomic motions  fiberglass  centripetal matrix  Coriolis  hydrodynamic  damping  GPS modules  inertial measurement unit  IMU  swimming pool  natural river  code generation strategy  Boats  Vehicle dynamics  Symmetric matrices  Global Positioning System  Heuristic algorithms  Robot kinematics 
Abstract: In this paper, we present the design, modeling, and real-time nonlinear model predictive control (NMPC) of an autonomous robotic boat. The robot is easy to manufacture, highly maneuverable, and capable of accurate trajectory tracking in both indoor and outdoor environments. In particular, a cross type four-thruster configuration is proposed for the robotic boat to produce efficient holonomic motions. The robot prototype is rapidly 3D-printed and then sealed by adhering several layers of fiberglass. To achieve accurate tracking control, we formulate an NMPC strategy for the four-control-input boat with control input constraints, where the nonlinear dynamic model includes a Coriolis and centripetal matrix, the hydrodynamic added mass, and damping. By integrating “GPS” modules and an inertial measurement unit (IMU) into the robot, we demonstrate accurate trajectory tracking of the robotic boat along preplanned paths in both a swimming pool and a natural river. Furthermore, the code generation strategy employed in our paper yields a two order of magnitude improvement in the run time of the NMPC algorithm compared to similar systems. The robot is designed to form the basis for surface swarm robotics testbeds, on which collective algorithms for surface transportation and self-assembly of dynamic floating infrastructures can be assessed.


Title: Reinforcement Learning of Depth Stabilization with a Micro Diving Agent
Key Words: embedded systems  learning (artificial intelligence)  microrobots  multi-agent systems  robot programming  underwater vehicles  model-based value-function RL algorithm  micro underwater agents  underwater robotics  underwater depth stabilization  light embedded systems  control tasks  microdiving agent  reinforcement learning  Computational modeling  Learning (artificial intelligence)  Task analysis  Robot kinematics  Heuristic algorithms  Force 
Abstract: Reinforcement learning (RL) allows robots to solve control tasks through interaction with their environment. In this paper we study a model-based value-function RL approach, which is suitable for computationally limited robots and light embedded systems. We develop a diving agent, which uses the RL algorithm for underwater depth stabilization. Simulations and experiments with the micro diving agent demonstrate its ability to learn the depth stabilization task.


Title: Real-Time Underwater 3D Reconstruction Using Global Context and Active Labeling
Key Words: cameras  feature extraction  feedforward neural nets  image classification  image reconstruction  image resolution  image sensors  sonar imaging  underwater vehicles  underwater environments  sonar images  low-resolution imagery  standard cameras  automatic feature extractors  sonar imagery  environment reconstructions  high data capture rates  standard imaging sonars  high-quality frames  feature annotation  real-time reconstruction capability  underwater vehicle  time underwater 3D reconstruction  real-time 3D reconstruction  convolutional neural network  Image reconstruction  Feature extraction  Real-time systems  Three-dimensional displays  Imaging  Sonar measurements 
Abstract: In this work we develop a novel framework that enables the real-time 3D reconstruction of underwater environments using features from 2D sonar images. Due to noisy and low-resolution imagery as compared with standard cameras, automatic feature extractors for sonar images are not reliable in many scenarios. Thus, a human often needs to hand-select features in sonar imagery for environment reconstructions. Given the high data capture rates of standard imaging sonars (on the order of 20Hz), hand-annotating the features in every frame cannot be done in real-time. To address this we use a Convolutional Neural Network (CNN) that analyzes incoming imagery in real-time and proposes only a small subset of high-quality frames to the user for feature annotation. We demonstrate that our approach provides real-time reconstruction capability without loss in classification performance on datasets captured onboard our underwater vehicle while operating in a variety of environments.


Title: Dynamic Reconfiguration of Mission Parameters in Underwater Human-Robot Collaboration
Key Words: feedforward neural nets  finite state machines  gesture recognition  human-robot interaction  mobile robots  hand gestures  hand gesture recognition  gesture-to-instruction mapping  finite-state machine  convolutional neural network  human-robot collaborative tasks  autonomous underwater robots  parameter reconfiguration method  real-time programming  underwater human-robot collaboration  mission parameters  dynamic reconfiguration  Robustness  Task analysis  Visualization  Robot sensing systems  Unmanned underwater vehicles  Gesture recognition 
Abstract: This paper presents a real-time programming and parameter reconfiguration method for autonomous underwater robots in human-robot collaborative tasks. Using a set of intuitive and meaningful hand gestures, we develop a syntactically simple framework that is computationally more efficient than a complex, grammar-based approach. In the proposed framework, a convolutional neural network is trained to provide accurate hand gesture recognition; subsequently, a finite-state machine- based deterministic model performs efficient gesture-to-instruction mapping and further improves robustness of the interaction scheme. The key aspect of this framework is that it can be easily adopted by divers for communicating simple instructions to underwater robots without using artificial tags such as fiducial markers or requiring memorization of a potentially complex set of language rules. Extensive experiments are performed both on field-trial data and through simulation, which demonstrate the robustness, efficiency, and portability of this framework in a number of different scenarios. Finally, a user interaction study is presented that illustrates the gain in the ease of use of our proposed interaction framework compared to the existing methods for the underwater domain.


Title: Gaussian Process Adaptive Sampling Using the Cross-Entropy Method for Environmental Sensing and Monitoring
Key Words: bathymetry  entropy  Gaussian processes  learning (artificial intelligence)  mobile robots  optimisation  path planning  sampling methods  single ROI  deepest region  coastal bathymetry mapping mission validate  efficient sampling strategy  latest sensory measurements  sampling density  CE trajectory optimization  higher spatial variability  exhibit extreme sensory measurements  exploring learning  initial stage  path planning  GP-UCB  GP upper confidence  receding-horizon Cross-Entropy trajectory optimization  environmental sensing  cross-entropy method  Gaussian process adaptive sampling  Robot sensing systems  Adaptation models  Optimization  Predictive models  Trajectory  Uncertainty 
Abstract: In this paper, we focus on adaptive sampling on a Gaussian Processes (GP) using the receding-horizon Cross-Entropy (CE) trajectory optimization. Specifically, we employ the GP upper confidence bound (GP-UCB) as the optimization criteria to adaptively plan sampling paths that balance the exploitation-exploration trade-off. Path planning at the initial stage focuses on exploring and learning a model of the environment, and later, on exploiting the learned model to focus sampling around regions that exhibit extreme sensory measurements and much higher spatial variability, denoted as the Region of Interest (ROI). The integration of the CE trajectory optimization allows the sampling density to be dynamically adjusted based on the latest sensory measurements, thus providing an efficient sampling strategy for sensing and localizing the ROI. We demonstrate the effectiveness of the proposed method in exploring simulated scalar fields with single or multiple ROIs. Field experiments with an Unmanned Surface Vehicle (USV) in a coastal bathymetry mapping mission validate the approach's capability in quickly exploring and mapping the given area, and then focusing and increasing the sampling density around the deepest region, as a surrogate for e.g. the extremal concentration of a pollutant in the environment.


Title: Complex Urban LiDAR Data Set
Key Words: graph theory  mobile robots  optical radar  pose estimation  radar computing  SLAM (robots)  complex urban environments  light detection and ranging data set  fiber optic gyro  inertial measurement unit  Global Positioning System  vehicle pose estimation  graph simultaneous location and mapping algorithm  graph SLAM algorithm  Robot Operating System environment  raw sensor data  2D LiDAR  16-ray 3D LiDARs  LiDAR sensors  three-dimensional LiDAR  building complexes  high-rise buildings  complex urban LiDAR data set  frequency 100.0 Hz  Laser radar  Three-dimensional displays  Global Positioning System  Two dimensional displays  Sensor systems  Urban areas 
Abstract: This paper presents a Light Detection and Ranging (LiDAR) data set that targets complex urban environments. Urban environments with high-rise buildings and congested traffic pose a significant challenge for many robotics applications. The presented data set is unique in the sense it is able to capture the genuine features of an urban environment (e.g. metropolitan areas, large building complexes and underground parking lots). Data of two-dimensional (2D) and three-dimensional (3D) LiDAR, which are typical types of LiDAR sensors, are provided in the data set. The two 16-ray 3D LiDARs are tilted on both sides for maximal coverage. One 2D LiDAR faces backward while the other faces forwards to collect data of roads and buildings, respectively. Raw sensor data from Fiber Optic Gyro (FOG), Inertial Measurement Unit (IMU), and the Global Positioning System (GPS) are presented in a file format for vehicle pose estimation. The pose information of the vehicle estimated at 100 Hz is also presented after applying the graph simultaneous localization and mapping (SLAM) algorithm. For the convenience of development, the file player and data viewer in Robot Operating System (ROS) environment were also released via the web page. The full data sets are available at: http://irap.kaist.ac.kr/dataset. In this website, 3D preview of each data set is provided using WebGL.


Title: Coordinated Dense Aerial Traffic with Self-Driving Drones
Key Words: air traffic control  autonomous aerial vehicles  collision avoidance  decentralised control  multi-robot systems  coordinated dense aerial traffic  general air traffic control solution  decentralized air traffic control solution  package-delivery scenarios  intelligent collective collision avoidance  motion planning  jam-free optimal traffic flow  force-based distributed multirobot control model  behaviour-driven velocity alignment  self-organized queueing  conflict-avoiding self-driving  Drones  Mathematical model  Atmospheric modeling  Oscillators  Acceleration  Task analysis  Roads 
Abstract: In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.


Title: Distance-Based Multi-Robot Coordination on Pocket Drones
Key Words: learning (artificial intelligence)  particle filtering (numerical methods)  recurrent neural nets  remotely operated vehicles  Deep Q-Learning Network  recurrent network  UWB-distance information  neural networks  distance-based multirobot coordination  pocket drones  MicroAerial Vehicles  recurrent neural network  Drones  Robot kinematics  Recurrent neural networks  Hardware  Robot sensing systems  Distance measurement 
Abstract: We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.


Title: Optimized Environment Exploration for Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  image reconstruction  mobile robots  path planning  quadtrees  tree data structures  viewpoint generation process  consistent maps  noisy sonar data  optimized environment exploration  autonomous underwater  autonomous robotic environment exploration  underwater domain  noisy acoustic sensors  high localization error  control disturbances  robotic exploration algorithm  underwater vehicles  view planning  path planning algorithms  exploration approach  quadtree data structure  relevant queries  natural environments  underwater maps  map representation  optical coverage  time 3.0 d  Cameras  Sonar  Planning  Robot sensing systems  Inspection  Three-dimensional displays 
Abstract: Achieving full autonomous robotic environment exploration in the underwater domain is very challenging, mainly due to noisy acoustic sensors, high localization error, control disturbances of the water and lack of accurate underwater maps. In this work we present a robotic exploration algorithm for underwater vehicles that does not rely on prior information about the environment. Our method has been greatly influenced by many robotic exploration, view planning and path planning algorithms. The proposed method constitutes a significant improvement over our previous work [1]: Firstly, we refine our exploration approach to improve robustness; Secondly, we propose an alternative map representation based on the quadtree data structure that allows different relevant queries to be performed efficiently, reducing the computational cost of the viewpoint generation process; Thirdly, we present an algorithm that is capable of generating consistent maps even when noisy sonar data is used. The aforementioned contributions have increased the reliability of the algorithm, allowing new real experiments performed in artificial structures but also in more challenging natural environments, from which we provide a 3D reconstruction to show that with this algorithm full optical coverage is obtained.


Title: Learning to Race Through Coordinate Descent Bayesian Optimisation
Key Words: automobiles  Bayes methods  Hilbert spaces  mobile robots  optimisation  robot dynamics  vehicle dynamics  dynamical model  robot  car racing simulation  descent Bayesian optimisation  race track  kernel Hilbert space  Bayesian optimisation  Optimization  Robot kinematics  Bayes methods  Search problems  Kernel  Linear programming 
Abstract: In the automation of many kinds of processes, the observable outcome can often be described as the combined effect of an entire sequence of actions, or controls, applied throughout the process execution. In these cases, strategies to optimise control policies for individual stages of the process are not applicable, and instead the whole policy needs to be optimised at once. On the other hand, the cost to evaluate the policy's performance might also be high, being desirable that a solution can be found with as few interactions as possible with the real system. We consider the problem of optimising control policies to allow a robot to complete a given race track within a minimum amount of time. We assume that the robot has no prior information about the track or its own dynamical model, just an initial valid driving example. Localisation is only applied to monitor the robot and to provide an indication of its position along the track's centre axis. With that in mind, we propose a method for finding a policy that minimises the time per lap while keeping the vehicle on the track using a Bayesian optimisation (BO) approach over a reproducing kernel Hilbert space. We apply an algorithm to search more efficiently over high-dimensional policy-parameter spaces with BO, by iterating over each dimension individually, in a sequential coordinate descent-like scheme. Experiments demonstrate the performance of the algorithm against other methods in a simulated car racing environment.


Title: Long-Term Visual Localization Using Semantically Segmented Images
Key Words: feature extraction  image segmentation  particle filtering (numerical methods)  transforms  particle filter based semantic localization solution  SIFT-features  vehicle localization  semantically labeled 3D point maps  autonomous vehicles  long-term visual navigation  robust cross-seasonal localization  semantically segmented images  long-term visual localization  image segmenter  hand-crafted feature descriptors  Semantics  Cameras  Roads  Image segmentation  Visualization  Robustness  Feature extraction 
Abstract: Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.


Title: Radiation Source Localization in GPS-Denied Environments Using Aerial Robots
Key Words: gamma-ray detection  Global Positioning System  mobile robots  photomultipliers  radioactive sources  radioactivity measurement  solid scintillation detectors  radiation measurements  radioactive source localization  radiation mapping  thallium-doped cesium iodide scintillator  indoor GPS-denied environments  Cesium-137 radiation source  GPS-denied localization  visual-inertial localization  autonomous nuclear radiation source localization  aerial robot  Scintillators  Calibration  Robot sensing systems  Detectors  Unmanned aerial vehicles  Radiation detectors 
Abstract: This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.


Title: LineDrone Technology: Landing an Unmanned Aerial Vehicle on a Power Line
Key Words: aircraft landing guidance  autonomous aerial vehicles  cameras  electrical maintenance  helicopters  inspection  optical radar  power overhead lines  remotely operated vehicles  robot vision  sensor fusion  LineDrone Technology  unmanned aerial vehicle landing  semiautomatic landing  vehicle onboard vision system  monocular camera  lidar  nondestructive testing  multirotor unmanned aerial vehicle capable  power transmission lines  landing assistance  Cameras  Payloads  Unmanned aerial vehicles  Inspection  Laser radar  Task analysis  Machine vision 
Abstract: This paper presents the design of a multirotor unmanned aerial vehicle (UAV) capable of landing semiautomatically on a power line while carrying a payload. The vehicle then rolls along the line to perform an inspection. Special attention is given to the vehicle's onboard vision system, which consists of a monocular camera and LiDAR used together to compute the pose of the vehicle relative to the power line. Landing assistance is provided to the pilot by a position-based visual controller that aligns and keeps the vehicle centered along the power line. The pilot remains in control of vertical and longitudinal movement during descent. The proposed approach was tested on a full-scale test line and shows promise for future applications of high value to the electric industry such as non-destructive testing of power transmission lines.


Title: Pseudo-bearing Measurements for Improved Localization of Radio Sources with Multirotor UAVs
Key Words: autonomous aerial vehicles  directive antennas  helicopters  mobile radio  mobile robots  omnidirectional antennas  radionavigation  pseudobearing measurements  radio frequency sources  RF source  directional antenna  omnidirectional antenna  antenna theory  ground tests  multirotor UAVs  radio sources localization  bearing-like measurements  unmanned aerial vehicles  Antenna measurements  Directional antennas  Gain  Radio frequency  Extraterrestrial measurements  Rotation measurement 
Abstract: Localizing radio frequency (RF) sources is an important application for unmanned aerial vehicles (UAVs), Localization is often carried out by estimating bearing to an RF source, which can be achieved by rotating a directional antenna in place. Multirotor UAVs are well-suited for this sensing modality because they can efficiently rotate in place. However, a full rotation from a single location is needed to account for scale factors affecting the directional antenna's measurements. Although easy to perform, these rotations tend to be slow and delay localization. In this paper, we equip a multirotor UAV with a directional antenna and an omnidirectional antenna. The omnidirectional antenna serves to normalize measurements made by the directional antenna, yielding “pseudo-bearing” measurements. These bearing-like measurements are less informative than bearing measurements but do not require a full rotation, leading to more measurements and faster localization. We validate the normalization with antenna theory and ground tests. Claims of improved localization are validated with simulations and flight tests on a multirotor UAV. Our setup significantly reduces localization time compared to a multirotor UAV equipped with only a directional antenna.


Title: Onboard State Dependent LQR for Agile Quadrotors
Key Words: aircraft control  attitude control  autonomous aerial vehicles  control system synthesis  helicopters  linear quadratic control  mobile robots  state estimation  time-varying systems  trajectory control  onboard state dependent LQR  agile quadrotors  quadrotor control  multiple cascaded subproblems  rotational dynamics  translational dynamics  cascaded attitude controller  attitude dynamics  robustness  LQR controller  rotational states  translational states  time-varying system dynamics  control parameters  linearization  Vehicle dynamics  Acceleration  Trajectory  Quaternions  Attitude control  Visualization  Regulators 
Abstract: State-of-the-art approaches in quadrotor control split the problem into multiple cascaded subproblems, exploiting the different time scales of the rotational and translational dynamics. They calculate a desired acceleration as input for a cascaded attitude controller but omit the attitude dynamics. These approaches use limits on the desired acceleration to maintain feasibility and robustness through the control cascade. We propose an implementation of an LQR controller, which: (I) is linearized depending on the quadrotor's state; (II) unifies the control of rotational and translational states; (III) handles time-varying system dynamics and control parameters. Our implementation is efficient enough to compute the full linearization and solution of the LQR at a minimum of 10 Hz on the vehicle using a common ARM processor. We show four successful experiments: (I) controlling at hover state with large disturbances; (II) tracking along a trajectory; (III) tracking along an infeasible trajectory; (IV) tracking along a trajectory with disturbances. All the experiments were done using only onboard visual inertial state estimation and LQR computation. To the best of our knowledge, this is the first implementation and evaluation of a state-dependent LQR capable of onboard computation while providing this amount of versatility and performance.


Title: Autonomous Fixed-Wing Aerobatics: From Theory to Flight
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  helicopters  Matlab  microcontrollers  mobile robots  position control  autonomous fixed-wing aerobatics  unmanned aerial vehicles  conventional fixed-wing aircraft  hardware-in-the-loop simulator  Pixhawk microcontroller  Xplane physics engine  HIL simulator  flight platform  agile fixed-wing UAV  rotorcraft  orientation time histories  position time histories  Matlab-Simulink high-fidelity simulation  Aircraft  Aerodynamics  Atmospheric modeling  Control systems  Mathematical model  Aerospace control  Propellers 
Abstract: Unmanned aerial vehicles (UAVs) are increasingly being proposed for a wide range of applications. A promising new class of these vehicles, known as agile fixed-wing UAV s, is intended to bridge the gap between conventional fixed-wing aircraft, which can cover long distances efficiently, and rotorcraft, which are typically very maneuverable. This paper addresses the implementation of a controller for agile UAVs, beginning with a hardware-in-the-loop (HIL) simulator, followed by testing on a real platform, both implemented on the Pixhawk microcontroller. We replace the Xplane physics engine used in the standard Pixhawk HIL with our own in-house Matlab/Simulink high-fidelity simulation of an agile UA V. The HIL simulator is found to provide substantial advantages in the transition from pure simulation to experimental testing. Once the controller is integrated into the flight platform, flight tests are conducted, and the results of those tests are compared to those from the HIL simulation and those obtained from the pure simulation environment, for maneuvers including hover, aggressive turnaround, knife-edge, and rolling Harrier. The desired position and orientation time histories were successfully tracked with the proposed implementation, demonstrating the impressive autonomous maneuverability that can be achieved by this type of aircraft.


Title: Adaptive Attitude Control for a Tail-Sitter UAV with Single Thrust-Vectored Propeller
Key Words: adaptive control  aerodynamics  aircraft control  attitude control  autonomous aerial vehicles  control system synthesis  least squares approximations  Lyapunov methods  propellers  stability  unified controller  attitude dynamics model  flight regimes  Lyapunov stability theory  control challenges  rotary wing UAVs  fixed wing  tail-sitter unmanned aerial vehicles  tail-sitter UAV  adaptive attitude control  control scheme  adaptive controller  quaternion attitude description  full-regime aerodynamics model  thrust vectoring model  single thrust-vectored propeller  cumbersome controller switchings  transition flights  Propellers  Aerodynamics  Atmospheric modeling  Attitude control  Aircraft  Mathematical model  Quaternions 
Abstract: Tail-sitter unmanned aerial vehicles (UAVs) have gained extensive popularity in recent years due to their inherent advantages of both fixed wing and rotary wing UAVs. However, these advantages are accompanied with control challenges because of two different flight regimes and drastically changing dynamics during transition flights. This paper focuses on the design of a unified controller free from cumbersome controller switchings and applicable in all attitude range for a tail-sitter with single thrust-vectored propeller. To achieve this, both thrust vectoring model and full-regime aerodynamics model are built first, after which a complete attitude dynamics model of the tail-sitter is established utilizing the quaternion attitude description to avoid the singularity problem. An adaptive controller is then derived based on a simplified model using the Lyapunov stability theory with unknown system parameters identified online by forgetting factor recursive least square (FF-RLS) method. Flight experiments are conducted to demonstrate the feasibility and effectiveness of the proposed control scheme.


Title: Online Aerodynamic Model Identification on Small Fixed-Wing UAVs with Uncertain Flight Data
Key Words: aerodynamics  aerospace components  aircraft control  autonomous aerial vehicles  least squares approximations  Monte Carlo methods  real-time systems  sensors  wind tunnels  small fixed-wing unmanned aerial vehicles  total least squares estimation  ordinary least squares method  low-cost sensor system  insufficient system excitation  variable forgetting factor  Monte Carlo approach  compound aerodynamic variables  uncertainty estimation  real-time schemes  wind-tunnel experiments  real-time estimation  uncertain flight data  online aerodynamic model identification  Aerodynamics  Atmospheric modeling  Estimation  Uncertainty  Real-time systems  Aircraft  Adaptation models 
Abstract: This paper focuses on real-time estimation of the aerodynamic model parameters of small-scale fixed wing Unmanned Aerial Vehicles (UAVs) without the aid of wind-tunnel experiments, using exclusively flight data. The key tool of the following analysis centers around the principles of Total Least Squares estimation. Contrary to Ordinary Least Squares, this method accounts for errors in both explanatory data and variables to-be-explained. This is a highly desirable property for UAVs equipped with low-cost sensor systems. The proposed implementation combines both batch and real-time schemes, while deals efficiently with the problem of Insufficient System Excitation. Online adaptation to model changes is performed by applying a Variable Forgetting Factor to the estimation data. Finally, a Monte Carlo approach is developed for uncertainty estimation regarding compound aerodynamic variables.


Title: Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
Key Words: aircraft control  autonomous aerial vehicles  game theory  helicopters  mobile robots  multi-robot systems  optimal control  path planning  trajectory control  multiple quadrotors  flag game  distributed trajectory planning algorithm  WiFi based communication infrastructure  autopilot modules  low power computing modules  suboptimal control action  adversarial game  Gazebo robot simulator  multiple UAVs  quadrotor platform  flight testing  robot operating system  ROS  Games  Software algorithms  Software  Hardware  Real-time systems  Testing  Computational modeling 
Abstract: We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.


Title: Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View
Key Words: aerospace computing  autonomous aerial vehicles  groupware  image fusion  Kalman filters  multi-robot systems  nonlinear filters  pose estimation  robot vision  stereo image processing  monocular-inertial odometry  Extended Kalman Filter  collaborative scene estimation  monocular camera  variable-baseline stereo rig  inertial sensor  Unmanned Aerial Vehicles  collaborative robot operation  collaborative 6DoF relative pose estimation  UAV  Cameras  Simultaneous localization and mapping  Collaboration  Estimation  Unmanned aerial vehicles 
Abstract: Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.


Title: BFM: a Scalable and Resource-Aware Method for Adaptive Mission Planning of UAVs
Key Words: autonomous aerial vehicles  belief networks  decision making  embedded systems  Markov processes  planning  quality of service  target tracking  diagnosis modules  Bayesian Networks  mission specifications  Markov Decision Processes  BFM model  application configurations  embedded system level  UAV level  target tracking mission  applications specifications  MDP model  embedded applications  resource-aware method  adaptive mission planning  external hazards  FMEA tables  scalable model  modular method  decision making process  UAV  internal hazards  Quality of service  Target tracking  Monitoring  Computational modeling  Sensor systems and applications  Context modeling 
Abstract: UAVs must continuously adapt their mission to face unexpected internal or external hazards. This paper proposes a new BFM model (Bayesian Networks built from FMEA tables for MDP). This scalable model offers a modular and comprehensive method to incorporate different types of diagnosis modules based on BN (Bayesian Networks) and FMEA table (Failure Mode and Effects Analysis) to mission specifications expressed as a MDP (Markov Decision Processes). The BFM model implements the complete decision making process that covers both the application configurations at the embedded system level and the mission planning at the UAV level. These decisions are based on the QoS (Quality of Service) of applications, the resource use and the system and sensors health. We demonstrate on a case study for a target tracking mission that the BFM model can interface hazards and applications specifications and can improve the success and quality of the mission. To the best of our knowledge, this is the first proposal of a systematic method that integrates diagnosis modules to MDP model in order to take care of the implementation of embedded applications during a mission.


Title: Realtime On-Board Attitude Estimation of High-Frequency Flapping Wing MAVs Under Large Instantaneous Oscillation
Key Words: aerodynamics  aerospace components  aerospace control  autonomous aerial vehicles  sensor fusion  realtime on-board attitude estimation  high-frequency flapping wing MAVs  instantaneous oscillation  fixed wings  rotary wings  high-frequency wing flapping  aerial vehicles  Flapping Wing Micro Aerial Vehicles  FWMAVs  instantaneous oscillations  Magnetometers  Robot sensing systems  Aerodynamics  Estimation  Accelerometers  Magnetic flux  Magnetomechanical effects 
Abstract: Unlike conventional aerial vehicles of fixed or rotary wings, realtime on-board attitude estimation of insect or hummingbird scale Flapping Wing Micro Aerial Vehicles (FWMAVs) is very challenging due to the severe instantaneous oscillations (approximately ten times of gravity on our platform) induced by high-frequency wing flapping. In this work, we present a novel sensor fusion algorithm for realtime on-board attitude estimation of FWMAVs. The algorithm is proposed with adaptive model-based compensation for both sensing drift and aerodynamic forces induced by flapping wings. We validated our approach on a 12.5 grams hummingbird robot. The experimental results demonstrated the accuracy, convergence, and robustness of the proposed algorithm.


Title: Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
Key Words: aerospace control  autonomous aerial vehicles  closed loop systems  mobile robots  optimisation  position control  propellers  closed-loop aerial transformation  aerial grasping  shape adaptive transformation  aerial manipulation  HALO  horizontal plane transformable aerial robot  closed-loop multilinks structure  flight control  serial-link structure  propeller  optimization planning method  Unmanned aerial vehicles  Propellers  Shape  Grasping  Servomotors  Force  End effectors 
Abstract: In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.


Title: Towards a Flying Assistant Paradigm: the OTHex
Key Words: autonomous aerial vehicles  control system synthesis  estimation theory  geometry  manipulators  mobile robots  robust control  trajectory control  maintenance tasks  task-driven custom design  experimental validations  control framework  low-level geometric controller  external wrench estimator  admittance filter  trajectory generator  external force disturbances  Flying Assistant paradigm  OTHex platform  aerial manipulation  LAAS-CNRS  multidirectional thrust platform  human operators  long bars  assembly tasks  ground manipulators  Propellers  Bars  Trajectory  Robots  Task analysis  Admittance  Force 
Abstract: This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.


Title: Emulating a Fully Actuated Aerial Vehicle Using Two Actuators
Key Words: actuators  aerodynamics  autonomous aerial vehicles  blades  helicopters  position control  rotors  vehicle dynamics  flat body attitude  fully actuated aerial vehicle  actuators  microair vehicles  quadrotors  downward thrust  spatial trajectories  coaxial helicopter  thrust vector  translation dynamics  cyclic flapping response  Rotors  Blades  Aircraft  Force  Fasteners  Actuators  Trajectory 
Abstract: Micro air vehicles exemplified by quadrotors generate downward thrust in their body fixed frame and may only maneuver spatially by changing their orientation. As a result of this underactuation they are fundamentally incapable of simultaneously regulating orientation and position. Furthermore, their feasible maneuvers are limited to spatial trajectories with continuously differentiable acceleration. We present a coaxial helicopter which emulates full actuation over forces and torques (six degrees of freedom) using only two actuators. The orientation of the thrust vector from each rotor is governed by the drive motor by exciting a cyclic flapping response in special articulated blades. The useful separation of orientation and translation dynamics is demonstrated in flight experiments by tracking spatial trajectories while maintaining flat body attitude as well as tracking desired orientations near hover while station keeping.


Title: A Flying Gripper Based on Cuboid Modular Robots
Key Words: autonomous aerial vehicles  grippers  helicopters  mobile robots  multi-robot systems  position control  degree of freedom  four-bar linkage  aperture angle  cuboid frame  docking mechanism  vertical edges  grasp object  cuboid modular robots  flying Gripper  hovering performance  DOF  Grippers  Apertures  Robots  Rotors  Grasping  Propellers  Shape 
Abstract: We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.


Title: ACT: An Autonomous Drone Cinematography System for Action Scenes
Key Words: cinematography  motion estimation  remotely operated vehicles  video cameras  action scenes  aerial filming  autonomous cinematography system  autonomous drone cinematography system  state-of-the-art drone camera system  real-time dynamical camera planning strategy  drone platform  human action  external motion capture systems  drone cinematography systems  aesthetic objectives  Cameras  Drones  Three-dimensional displays  Skeleton  Planning  Robot vision systems  Trajectory 
Abstract: Drones are enabling new forms of cinematography. Aerial filming via drones in action scenes is difficult because it requires users to understand the dynamic scenarios and operate the drone and camera simultaneously. Existing systems allow the user to manually specify the shots and guide the drone to capture footage, while none of them employ aesthetic objectives to automate aerial filming in action scenes. Meanwhile, these drone cinematography systems depend on the external motion capture systems to perceive the human action, which is limited to the indoor environment. In this paper, we propose an Autonomous CinemaTography system “ACT” on the drone platform to address the above the challenges. To our knowledge, this is the first drone camera system which can autonomously capture cinematic shots of action scenes based on limb movements in both indoor and outdoor environments. Our system includes the following novelties. First, we propose an efficient method to extract 3D skeleton points via a stereo camera. Second, we design a real-time dynamical camera planning strategy that fulfills the aesthetic objectives for filming and respects the physical limits of a drone. At the system level, we integrate cameras and GPUs into the limited space of a drone and demonstrate the feasibility of running the entire cinematography system onboard in real-time. Experimental results in both simulation and real-world scenarios demonstrate that our cinematography system “ACT” can capture more expressive video footage of human action than that of a state-of-the-art drone camera system.


Title: Generative One-Shot Learning (GOL): A Semi-Parametric Approach to One-Shot Learning in Autonomous Vision
Key Words: computer vision  learning (artificial intelligence)  mobile robots  neural nets  object recognition  Pareto optimisation  GOL  input single one-shot objects  environment perception  autonomous vision  semiparametric approach  deep neural networks  visual perception  driving environment  training perceptions systems  generative framework  highly autonomous driving systems  generative one-shot learning  HAD systems  Pareto optimal solutions  object detection algorithms  Pareto optimization  Training  Autonomous vehicles  Generators  Linear programming  Probability density function 
Abstract: Highly Autonomous Driving (HAD) systems rely on deep neural networks for the visual perception of the driving environment. Such networks are train on large manually annotated databases. In this work, a semi-parametric approach to one-shot learning is proposed, with the aim of bypassing the manual annotation step required for training perceptions systems used in autonomous driving. The proposed generative framework, coined Generative One-Shot Learning (GOL), takes as input single one-shot objects, or generic patterns, and a small set of so-called regularization samples used to drive the generative process. New synthetic data is generated as Pareto optimal solutions from one-shot objects using a set of generalization functions built into a generalization generator. GOL has been evaluated on environment perception challenges encountered in autonomous vision.


Title: Enhancing Underwater Imagery Using Generative Adversarial Networks
Key Words: autonomous underwater vehicles  decision making  image colour analysis  image denoising  image fusion  image restoration  neural nets  robot vision  Generative Adversarial Networks  autonomous underwater vehicles  AUVs  intelligent decision making  color distortion  noisy images  distorted images  underwater image restoration  underwater imagery  visual data quality  visual underwater scene quality  Nonlinear distortion  Gallium nitride  Generators  Image color analysis  Visualization  Sensors 
Abstract: Autonomous underwater vehicles (AUVs) rely on a variety of sensors - acoustic, inertial and visual - for intelligent decision making. Due to its non-intrusive, passive nature and high information content, vision is an attractive sensing modality, particularly at shallower depths. However, factors such as light refraction and absorption, suspended particles in the water, and color distortion affect the quality of visual data, resulting in noisy and distorted images. AUVs that rely on visual sensing thus face difficult challenges and consequently exhibit poor performance on vision-driven tasks. This paper proposes a method to improve the quality of visual underwater scenes using Generative Adversarial Networks (GANs), with the goal of improving input to vision-driven behaviors further down the autonomy pipeline. Furthermore, we show how recently proposed methods are able to generate a dataset for the purpose of such underwater image restoration. For any visually-guided underwater robots, this improvement can result in increased safety and reliability through robust visual perception. To that effect, we present quantitative and qualitative data which demonstrates that images corrected through the proposed approach generate more visually appealing images, and also provide increased accuracy for a diver tracking algorithm.


Title: Level-Headed: Evaluating Gimbal-Stabilised Visual Teach and Repeat for Improved Localisation Performance
Key Words: feature extraction  mobile robots  path planning  robot vision  rough terrain  unstructured terrain  border patrol  agricultural work  sensor-based navigation  erratic motion  feature-poor environments test feature tracking  repeat matching  salient point features  Grizzly Robotic Utility Vehicle  actively gimbaled camera  image motion  search-and-rescue  field-deployable ground robot  vision-based route-following  feature extraction  Transforms  Cameras  Visualization  Robot sensing systems  Robustness  Navigation 
Abstract: Operating in rough, unstructured terrain is an essential requirement for any truly field-deployable ground robot. Search-and-rescue, border patrol and agricultural work all require operation in environments with little established infrastructure for easy navigation. This presents challenges for sensor-based navigation such as vision, where erratic motion and feature-poor environments test feature tracking and hinder the performance of repeat matching of point features. For vision-based route-following methods such as Visual Teach and Repeat (VT&R), maintaining similar visual perspective of salient point features is critical for reliable odometry and accurate localisation over long periods. In this paper, we investigate a potential solution to these challenges by integrating a gimbaled camera with VT&R on a Grizzly Robotic Utility Vehicle (RUV) for testing at high speeds and in visually challenging environments. We examine the benefits and drawbacks of using an actively gimbaled camera to attenuate image motion and control viewpoint. We compare the use of a gimbaled camera to our traditional fixed stereo configuration and demonstrate cases of improved performance in Visual Odometry (VO), localisation and path following in several sets of outdoor experiments.


Title: Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand
Key Words: automobiles  collision avoidance  mobile robots  optimal control  optimisation  road traffic  scheduling  potential collision situations  road geometries  joint motion plans  multivehicle motion planning  road network  Vienna Convention  desired deadlines  integrated route  road traffic  motion planning problem  social optimal mobility-on-demand  self-driving cars  bubble spaces  queue scheduling  Roads  Planning  Delays  Task analysis  Sensors  Trajectory  Automobiles 
Abstract: In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.


Title: Historical Data is Useful for Navigation Planning: Data Driven Route Generation for Autonomous Ship
Key Words: autonomous underwater vehicles  collision avoidance  marine control  marine navigation  mobile robots  ships  Navigation Feature  historical data  navigation planning  data driven route generation  autonomous ship  automated generation  autonomous surface vessel  robotic surface vessel  Historical Automatic Identification System data  AIS locations  nearest neighbour based path retrieval  Ship Feature  AIS records  Marine vehicles  Navigation  Artificial intelligence  Noise measurement  Planning  Path planning  Databases 
Abstract: This work presents a method for automated generation of navigation plan for autonomous or robotic surface vessel. Historical Automatic Identification System (AIS) data is of significant value to this problem. The method joins AIS locations of a same vessel at different time and locations in a region into a route. Next, it automatically computes navigation plans using nearest neighbour based path retrieval relying on two representations, Ship Feature and Navigation Feature. Before starting service, existing AIS records in the form of ship properties and corresponding route are preprocessed and stored in the form of Ship and Navigation Feature. During online retrieval, given input constraints in vector form, nearest neighbour of this query vector in the same space is found and corresponding path of the neighbour is returned as recommended path. Analysis was done in four and two dimensional spaces for Ship and Navigation Feature respectively. Application of the method is demonstrated in two regions of Australian, covering Bass Strait and Great Australian Bight.


Title: A Preliminary Study of Ice-Relative Underwater Vehicle Navigation Beneath Moving Sea Ice
Key Words: autonomous underwater vehicles  Kalman filters  marine navigation  mobile robots  navigation  nonlinear filters  oceanographic techniques  position control  ships  under-ice navigation methods  extended Kalman filter  sufficient satellite beacon separation  vehicle position  ice velocities  vehicle trajectory  ice survey  navigation sensors  ship  precision vehicle  satellite navigation beacons  precision navigation capabilities  under-ice robotic vehicles  moving stationary sea ice  underwater robotic vehicle navigation  vehicle navigation beneath moving sea ice  ice-relative  size 7.6 km  size 1.2 km  Satellite navigation systems  Marine vehicles  Sea ice  Sonar navigation  Acoustics 
Abstract: This paper addresses the problem of underwater robotic vehicle navigation relative to moving or stationary sea ice. A brief review of previously-reported under-ice navigation methods is given, as well as a brief motivation for the use of under-ice robotic vehicles with precision navigation capabilities. We then describe our proposed approach, which employs two or more satellite navigation beacons atop the sea ice along with other precision vehicle and ship mounted navigation sensors to estimate vehicle, ice, and ship states by means of an Extended Kalman Filter. Navigation results for a simulated 7.6 km under ice survey are presented for varying satellite beacon separation. Preliminary analysis suggests that for the simulated sensors, vehicle trajectory, and ice velocities, the proposed method can accurately estimate vehicle position up to 1.2 km from the deployment ship given sufficient satellite beacon separation. Decreased beacon separation results in divergence of the vehicle's position estimate at large standoff distances from the ship. We conclude with suggestions for future improvements.


Title: Micro Underwater Vehicle Hydrobatics: A Submerged Furuta Pendulum
Key Words: attitude control  autonomous underwater vehicles  control system synthesis  marine control  microrobots  mobile robots  pendulums  robust control  stability  vehicle dynamics  submerged Furuta pendulum  HippoCampus microunderwater vehicle  fluid volumes  tightly constrained settings  agile vehicle dynamics  robust attitude control scheme  aerial drones  underwater domain  control method  microunderwater vehicle hydrobatics  submerged Furuta pendulum stabilization  Vehicle dynamics  Hippocampus  Attitude control  Hydrodynamics  Force  Monitoring  Drones 
Abstract: We present the new HippoCampus micro underwater vehicle, first introduced in [1]. It is designed for monitoring confined fluid volumes. These tightly constrained settings demand agile vehicle dynamics. Moreover, we adapt a robust attitude control scheme for aerial drones to the underwater domain. We demonstrate the performance of the controller with a challenging maneuver. A submerged Furuta pendulum is stabilized by HippoCampus after a swing-up. The experimental results reveal the robustness of the control method, as the system quickly recovers from strong physical disturbances, which are applied to the system.


Title: Satellite-Based Tele-Operation of an Underwater Vehicle-Manipulator System. Preliminary Experimental Results
Key Words: artificial satellites  end effectors  manipulator kinematics  mobile robots  remotely operated vehicles  satellite communication  satellite links  telerobotics  underwater vehicles  UVMS  Underwater Vehicle-Manipulator System  satellite link  task-priority-based inverse kinematics algorithm  satellite-based tele-operation  European project  underwater intervention  remote control room  satellite communication link  DexROV  cognitive engine  communication latency  end effector  size 2017.0 inch  Task analysis  Trajectory  Kinematics  Satellite communication  Exoskeletons  Engines  Robustness 
Abstract: Within the European project DexROV the topic of underwater intervention is addressed. In particular, a remote control room is connected through a satellite communication link to surface vessel, which is in turn connected to an UVMS (Underwater Vehicle-Manipulator System) with an umbilical cable. The operator may interact with the system using a joystick or exoskeleton. Since a direct teleoperation is not feasible, a cognitive engine is in charge of handling communication latency or interruptions caused by the satellite link, and the UVMS should have sufficient autonomy in dealing with low level constraints or secondary objectives. To this purpose, a task-priority-based inverse kinematics algorithm has been developed in order to allow the operator to control only the end effector, while the algorithm is in charge of handling both operative and joint-space constraints. This paper describes some preliminary experimental results achieved during the DexROV campaign of July 2017 in Marseilles (France), where most of the components have been successfully integrated and the inverse kinematics nicely run.


Title: Robust Dense Mapping for Large-Scale Dynamic Environments
Key Words: cameras  image motion analysis  image reconstruction  image segmentation  mobile robots  motion control  object detection  path planning  pose estimation  robot vision  stereo image processing  robust dense mapping  large-scale dynamic environments  stereo-based dense mapping algorithm  large-scale dynamic urban environments  static background  high-level mobile robotic tasks  crowded environments  instance-aware semantic segmentation  sparse scene flow  visual odometry  depth maps  stereo input  map pruning technique  reconstruction accuracy  stationary objects  moving objects detection  path planning  camera poses estimation  frequency 2.5 Hz  Three-dimensional displays  Cameras  Semantics  Vehicle dynamics  Dynamics  Real-time systems  Heuristic algorithms 
Abstract: We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately, which is desirable for high-level mobile robotic tasks such as path planning in crowded environments. We use both instance-aware semantic segmentation and sparse scene flow to classify objects as either background, moving, or potentially moving, thereby ensuring that the system is able to model objects with the potential to transition from static to dynamic, such as parked cars. Given camera poses estimated from visual odometry, both the background and the (potentially) moving objects are reconstructed separately by fusing the depth maps computed from the stereo input. In addition to visual odometry, sparse scene flow is also used to estimate the 3D motions of the detected moving objects, in order to reconstruct them accurately. A map pruning technique is further developed to improve reconstruction accuracy and reduce memory consumption, leading to increased scalability. We evaluate our system thoroughly on the well-known KITTI dataset. Our system is capable of running on a PC at approximately 2.5Hz, with the primary bottleneck being the instance-aware semantic segmentation, which is a limitation we hope to address in future work. The source code is available from the project Websitea.


Title: Self-triggered Adaptive Planning and Scheduling of UAV Operations
Key Words: adaptive control  autonomous aerial vehicles  collision avoidance  energy consumption  helicopters  mobile robots  noise  reachability analysis  risk analysis  scheduling  trajectory optimisation (aerospace)  obstacles avoidance  energy consumption  trajectory curvature  self-triggered adaptive planning  unmanned aerial vehicles  scheduling  quadrotor UAV motion planning  obstacles detection  time consumption  constant periodic sensor measurements  online speed adaptation policy  risk-based analysis  noise  reachability analysis  Trajectory  Robot sensing systems  Safety  Unmanned aerial vehicles  Reachability analysis  Schedules 
Abstract: Modern unmanned aerial vehicles (UAVs) rely on constant periodic sensor measurements to detect and avoid obstacles. However, constant checking and replanning are time and energy consuming and are often not necessary especially in situations in which the UAV can safely fly in uncluttered environments without entering unsafe states. Thus, in this paper, we propose a self-triggered framework that leverages reachability analysis to schedule the next time to check sensor measurements and perform replanning while guaranteeing safety under noise and disturbance effects. Further, we relax sensor checking and motion replanning operations by leveraging a risk-based analysis that determines the likelihood to reach undesired states over a certain time horizon. We also propose an online speed adaptation policy based on the planned trajectory curvature to minimize drift from the desired path due to the system dynamics. Finally, we validate the proposed approach with simulations and experiments for a quadrotor UAV motion planning case study in a cluttered environment.


Title: Intent-Aware Multi-Agent Reinforcement Learning
Key Words: aerospace robotics  control engineering computing  decision theory  function approximation  learning (artificial intelligence)  Markov processes  multi-agent systems  planning (artificial intelligence)  robot dynamics  low-level planning algorithms  intent-aware multiagent reinforcement learning  learning algorithm  planning process  partially observable Markov decision process  linear function approximation  intent-aware multiagent planning  aerial robots  human interaction  dynamic process  POMDP  Planning  Prediction algorithms  Automata  Vehicles  History  Computational modeling 
Abstract: This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.


Title: Trajectory Replanning for Quadrotors Using Kinodynamic Search and Elastic Optimization
Key Words: aircraft control  autonomous aerial vehicles  control system synthesis  elasticity  helicopters  mobile robots  optimal control  path planning  pipes  predictive control  quadratic programming  robot dynamics  robot kinematics  robot vision  search problems  splines (mathematics)  trajectory control  quadratically constrained quadratic programming problem  receding horizon replanner design  trajectory replanning  grid structure  dynamically feasible time-parameterized trajectory  B-spline based kinodynamic search algorithm  greedy search  B-spline parameterization  position-only shortest path search  monocular vision-based quadrotor  replanning system  local control property  expanded elastic tube  optimal control point placement  EO approach  RBK search  post-optimization process  elastic optimization approach  Splines (mathematics)  Trajectory  Optimization  Real-time systems  Process control  Planning  Complexity theory 
Abstract: We focus on a replanning scenario for quadrotors where considering time efficiency, non-static initial state and dynamical feasibility is of great significance. We propose a real-time B-spline based kinodynamic (RBK) search algorithm, which transforms a position-only shortest path search (such as A * and Dijkstra) into an efficient kinodynamic search, by exploring the properties of B-spline parameterization. The RBK search is greedy and produces a dynamically feasible time-parameterized trajectory efficiently, which facilitates non-static initial state of the quadrotor. To cope with the limitation of the greedy search and the discretization induced by a grid structure, we adopt an elastic optimization (EO) approach as a post-optimization process, to refine the control point placement provided by the RBK search. The EO approach finds the optimal control point placement inside an expanded elastic tube which represents the free space, by solving a Quadratically Constrained Quadratic Programming (QCQP) problem. We design a receding horizon replanner based on the local control property of B-spline. A systematic comparison of our method against two state-of-the-art methods is provided. We integrate our replanning system with a monocular vision-based quadrotor and validate our performance onboard.


Title: MPC-based Collision Avoidance Strategy for Existing Marine Vessel Guidance Systems
Key Words: collision avoidance  marine control  predictive control  MPC-based collision avoidance strategy  marine vessel guidance systems  COLREGS  MPC COLAV algorithm  simulation-based model predictive control  Collision avoidance  Computational modeling  Trajectory  Cost function  Mathematical model  Vehicle dynamics  Propulsion 
Abstract: This paper presents a viable approach for incorporating collision avoidance strategies into existing guidance and control systems on marine vessels. We propose a method that facilitates the use of simulation-based Model Predictive Control (MPC) for collision avoidance (COLAV) on marine vessels. Any COLAV strategy to be applied in real traffic must adhere to the international regulations for preventing collisions at sea (COLREGS). The proposed MPC COLAV method does not rely on an accurate model of the guidance system to achieve vessel behaviors that are compliant with the COLREGS. Rather, it depends on transitional costs in the MPC objective for collision avoidance maneuvers that are being executed by the marine vessel. Hence, it is straightforward to implement the MPC COLAV on different vessels without specific knowledge of the vessel's guidance strategy. Moreover, it offers the possibility to switch between different (possibly application specific) guidance strategies on the same vessel while running the same MPC COLAV algorithm. We present results from full scale experiments that show the viability of our method in different collision avoidance scenarios.


Title: U sing a UAV for Destructive Surveys of Mosquito Population
Key Words: autonomous aerial vehicles  diseases  graph theory  integer programming  path planning  travelling salesman problems  destructive surveys  mosquito population  electrified screen  UAV path  mosquito elimination  trajectory planning  traveling salesman problem  milling with turn cost  lawn mower problem  grid graph  optimized energy consumption  Integer Programming  mosquito-borne diseases  mosquito-killing UAV  Unmanned aerial vehicles  Sociology  Statistics  Global Positioning System  Robots  Monitoring  Wind tunnels 
Abstract: This paper introduces techniques for mosquito population surveys in the field using electrified screens (bug zappers) mounted to a UAV. Instrumentation on the UAV logs the UAV path and the GPS location, altitude, and time of each mosquito elimination. Hardware experiments with a UAV equipped with an electrified screen provide real-time measurements of (former) mosquito locations and mosquito-free volumes. Planning a trajectory for the UAV that maximizes the number of mosquito kills is related to the Traveling Salesman Problem, the Lawn Mower Problem and, most closely, Milling with Turn Cost. We reduce this problem to considering variants of covering a grid graph with minimum turn cost, corresponding to optimized energy consumption. We describe an exact method based on Integer Programming that is able to compute provably optimal instances with over 1,500 pixels. These solutions are then implemented on the UAV.


Title: Optical Fiber-Based Sensor for Assessing Electric Current in Unmanned Aerial Vehicles with ROS Interface
Key Words: autonomous aerial vehicles  diffraction gratings  electric current measurement  fibre optic sensors  permanent magnets  Robot Operating System package  hysteresis  optical fiber-based sensor  sensing technology  unmanned aerial vehicles electric motors  ROS interface  sensing system  electric current measurements  linear electric current sensitivity  flexible sensing scheme  permanent Neodymium magnet  Long-Period Fiber Grating sensor  current 0.22 A  current 0.08 A  Robot sensing systems  Current  Optical fiber sensors  Optical fibers  Current measurement  Fiber gratings 
Abstract: In this work, we propose and experimentally validate a novel optical fiber-based sensor for monitoring and assessing electric current in unmanned aerial vehicles electric motors. The proposed sensing technology combines a Long-Period Fiber Grating sensor and a permanent Neodymium magnet, providing a small and flexible sensing scheme deployed inside the arm of the drone. The experimental results show that good accuracy and linear electric current sensitivity of 0.21 A and 2.08 A/nm, respectively, were achieved with electric current measurements at a 100 Hz sampling rate. The values of hysteresis and repeatability achieved were 0.08 A and 0.22 A, respectively. Finally, a Robot Operating System package for interfacing with the sensing system was developed and tested, which greatly simplifies the deployment of the sensor in robotics applications.


Title: A Lightweight, Compliant, Contact-Resistance-Based Airflow Sensor for Quadcopter Ground Effect Sensing
Key Words: aerodynamics  aerospace components  aircraft testing  autonomous aerial vehicles  design engineering  elastomers  flow measurement  flow sensors  helicopters  turbulence  wind tunnels  winds speeds  Crazyflie 2.0 quadcopter  turbulent flow  thrust level  aircraft testing  autonomous aerial vehicles  design engineering  quadcopter ground effect sensing  compliant contact-resistance-based airflow sensor  lightweight contact-resistance-based airflow sensor  wind tunnel characterization  sensor deflection  air flow speeds  flexible conductive pillar  elastomeric contact-resistance-based airflow sensor  nonobstructive solutions  power 42.0 muW  Wind speed  Robot sensing systems  Wind tunnels  Fabrication  Market research  Hair 
Abstract: Sensors to measure quadcopter ground effect are often relatively large, heavy, and require significant power, which restricts their applicability when it comes to small quadcopters and other aircraft that require lightweight and non-obstructive solutions. This paper presents the design of an elastomeric contact-resistance-based airflow sensor to measure ground effect with a mass of approximately 0.04 g and a power draw of 42 μW when in operation. It uses a rigid flap attached to the top of a flexible conductive pillar (CNT/PDMS), which deflects with varying winds speeds. A simple model is presented to describe expected trends between air flow speeds and sensor deflection and is compared with a wind tunnel characterization of the sensor for varying airflows. The sensor is characterized in a wind tunnel to identify a minimum airflow necessary for sensor functionality. Finally, sensors are attached to a Crazyflie 2.0 (Bitcraze) quadcopter and tested for performance in detecting ground effect, where there is a clear trend between sensor output and the intensity of the turbulent flow, related to proximity to ground and thrust level.


Title: Experiments in Fast, Autonomous, GPS-Denied Quadrotor Flight
Key Words: aircraft control  aircraft navigation  autonomous aerial vehicles  collision avoidance  helicopters  mobile robots  mixed indoor environments  outdoor environments  specific component technologies  high speed navigation capability  high speed autonomous flights  obstacle rich environments  GPS-denied quadrotor flight  unknown environments  robotics  fast computation  tight integration  subsystems  latency  perception-action loop  aerial robots  payload capacity  navigation system  quadrotor system  Cameras  Navigation  Robot vision systems  Laser radar  Payloads 
Abstract: High speed navigation through unknown environments is a challenging problem in robotics. It requires fast computation and tight integration of all the subsystems on the robot such that the latency in the perception-action loop is as small as possible. Aerial robots add a limitation of payload capacity, which restricts the amount of computation that can be carried onboard. This requires efficient algorithms for each component in the navigation system. In this paper, we describe our quadrotor system which is able to smoothly navigate through mixed indoor and outdoor environments and is able to fly at speeds of more than 18 m/s. We provide an overview of our system and details about the specific component technologies that enable the high speed navigation capability of our platform. We demonstrate the robustness of our system through high speed autonomous flights and navigation through a variety of obstacle rich environments.


Title: A Self-contained Teleoperated Quadrotor: On-Board State-Estimation and Indoor Obstacle Avoidance
Key Words: autonomous aerial vehicles  cameras  collision avoidance  distance measurement  feedback  Global Positioning System  helicopters  image sequences  Kalman filters  mobile robots  path planning  probability  sensors  state estimation  telerobotics  tracking  on-board state-estimation  indoor obstacle avoidance  unmanned aerial vehicles  GPS signal  teleoperated quadrotor UAV platform  onboard miniature computer  linear velocity  Kalman filter integration  inertial flow  optical flow  depth measurements  robo-centric obstacle model  collision-free navigation  distance measurements  cramped spaces  sensors  tracking  RGB-D camera  visual feedback  probabilistic  Collision avoidance  Robot sensing systems  Estimation  Cameras  Robot kinematics 
Abstract: Indoor operation of unmanned aerial vehicles (UAV s) poses many challenges due to the lack of GPS signal and cramped spaces. The presence of obstacles in an unfamiliar environment requires reliable state estimation and active algorithms to prevent collisions. In this paper, we present a teleoperated quadrotor UAV platform equipped with an onboard miniature computer and a minimal set of sensors for this task. The platform is capable of highly accurate state-estimation, tracking of desired velocity commanded by the user and ensuring collision-free navigation. The robot estimates its linear velocity through a Kalman filter integration of inertial and optical flow (OF) readings with corresponding distance measurements. An RGB-D camera serves the purpose of providing visual feedback to the operator and depth measurements to build a probabilistic, robo-centric obstacle model, allowing the robot to avoid collisions. The platform is thoroughly validated in experiments in an obstacle rich environment.


Title: Safe Teleoperation of Dynamic UAVs Through Control Barrier Functions
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  helicopters  human-robot interaction  Lyapunov methods  quadratic programming  assistive training solution  safe human teleoperated flight  control approach  motion capture environment  safe teleoperation  control barrier functions  human operators  highly dynamic systems  constrained environment  quadrotor systems  potential obstacles  presented supervisory controller  safety constraints  dynamic UAV  exponential control barrier function  Safety  Trajectory  Collision avoidance  Vehicle dynamics  Dynamics  Robots  Task analysis 
Abstract: This paper presents a method for assisting human operators to teleoperate highly dynamic systems such as quadrotors inside a constrained environment with safety guarantees. Our method enables human operators to focus on manually operating and flying quadrotor systems without the need to focus on avoiding potential obstacles. This is achieved with the presented supervisory controller overriding human input to enforce safety constraints when necessary. This method can be used as an assistive training solution for novice pilots to begin flying quadrotors without crashing them. Our supervisory controller uses an Exponential control barrier function based quadratic program to achieve safe human teleoperated flight. We demonstrate and validate our control approach through several experiments with multiple users with varying skill levels for three different scenarios of a quadrotor flying in a motion capture environment with virtual and physical constraints.


