TY  - CONF
TI  - Augmenting Action Model Learning by Non-Geometric Features
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7769
EP  - 7775
AU  - I. Nematollahi
AU  - D. Kuhner
AU  - T. Welschehold
AU  - W. Burgard
PY  - 2019
KW  - Gaussian processes
KW  - grippers
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mixture models
KW  - mobile robots
KW  - teaching
KW  - action model learning
KW  - nongeometric features
KW  - manipulation actions
KW  - action-induced reactions
KW  - measured liquid levels
KW  - explicit case dependent programming
KW  - external features
KW  - dynamic system
KW  - action imitation
KW  - geometric trajectory
KW  - real-world robot experiments
KW  - Gaussian mixture model representation
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Liquids
KW  - Force measurement
KW  - Grippers
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794153
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning from demonstration is a powerful tool for teaching manipulation actions to a robot. It is, however, an unsolved problem how to consider knowledge about the world and action-induced reactions such as forces imposed onto the gripper or measured liquid levels during pouring without explicit and case dependent programming. In this paper, we present a novel approach to include such knowledge directly in form of measured features. To this end, we use action demonstrations together with external features to learn a motion encoded by a dynamic system in a Gaussian Mixture Model (GMM) representation. Accordingly, during action imitation, the system is able to couple the geometric trajectory of the motion to measured features in the scene. We demonstrate the feasibility of our approach with a broad range of external features in real-world robot experiments including a drinking, a handover and a pouring task.
ER  - 

TY  - CONF
TI  - Skill Acquisition via Automated Multi-Coordinate Cost Balancing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7776
EP  - 7782
AU  - H. Ravichandar
AU  - S. R. Ahmadzadeh
AU  - M. A. Rana
AU  - S. Chernova
PY  - 2019
KW  - convex programming
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - learning framework
KW  - MCCB
KW  - point-to-point movement skills
KW  - multiple differential coordinates
KW  - local geometric properties
KW  - convex optimization problem
KW  - multicoordinate cost function
KW  - complex skill datasets
KW  - skill acquisition
KW  - automated multicoordinate cost balancing
KW  - Trajectory
KW  - Laplace equations
KW  - Cost function
KW  - Task analysis
KW  - Encoding
KW  - Robots
DO  - 10.1109/ICRA.2019.8793762
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a learning framework, named Multi-Coordinate Cost Balancing (MCCB), to address the problem of acquiring point-to-point movement skills from demonstrations. MCCB encodes demonstrations simultaneously in multiple differential coordinates that specify local geometric properties. MCCB generates reproductions by solving a convex optimization problem with a multi-coordinate cost function and linear constraints on the reproductions, such as initial, target, and via points. Further, since the relative importance of each coordinate system in the cost function might be unknown for a given skill, MCCB learns optimal weighting factors that balance the cost function. We demonstrate the effectiveness of MCCB via detailed experiments conducted on one handwriting dataset and three complex skill datasets.
ER  - 

TY  - CONF
TI  - Real-time Multisensory Affordance-based Control for Adaptive Object Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7783
EP  - 7790
AU  - V. Chu
AU  - R. A. Gutierrez
AU  - S. Chernova
AU  - A. L. Thomaz
PY  - 2019
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - adaptive object manipulation
KW  - RMAC
KW  - multisensory inputs
KW  - real-time multisensory affordance-based control
KW  - affordance models
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Trajectory
KW  - Adaptation models
KW  - Real-time systems
KW  - Data models
DO  - 10.1109/ICRA.2019.8793860
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the challenge of how a robot can adapt its actions to successfully manipulate objects it has not previously encountered. We introduce Real-time Multisensory Affordance-based Control (RMAC), which enables a robot to adapt existing affordance models using multisensory inputs. We show that using the combination of haptic, audio, and visual information with RMAC allows the robot to learn afforance models and adaptively manipulate two very different objects (drawer, lamp), in multiple novel configurations. Offline evaluations and real-time online evaluations show that RMAC allows the robot to accurately open different drawer configurations and turn-on novel lamps with an average accuracy of 75%.
ER  - 

TY  - CONF
TI  - Learning Behavior Trees From Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7791
EP  - 7797
AU  - K. French
AU  - S. Wu
AU  - T. Pan
AU  - Z. Zhou
AU  - O. C. Jenkins
PY  - 2019
KW  - control engineering computing
KW  - decision trees
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - LfD methods
KW  - decision trees
KW  - household cleaning task
KW  - Robotic Learning from Demonstration
KW  - primitive actions
KW  - Fetch robot
KW  - human teaching
KW  - robot programming
KW  - behavior trees
KW  - Task analysis
KW  - Decision trees
KW  - Service robots
KW  - Hidden Markov models
KW  - Real-time systems
KW  - Games
DO  - 10.1109/ICRA.2019.8794104
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic Learning from Demonstration (LfD) allows anyone, not just experts, to program a robot for an arbitrary task. Many LfD methods focus on low level primitive actions such as manipulator trajectories. Complex multistep task with many primitive actions must be learned from demonstration if LfD is to encompass the full range of task a user may desire. Existing methods represent the high level task in various forms including, finite state machines, decision trees, formal logic, among others. Behavior trees are proposed as an alternative representation of high level task. Behavior trees are an execution model for the control of a robot designed for real time execution, modularity, and, consequently, transparency. Real time execution allows the robot to reactively perform the task. Modularity allows the reuse of learned primitive actions and high level task in new situations, speeding up the process of learning in new scenarios. Transparency allows users to understand and interactively modify the learned model. Behavior trees are used to represent high level tasks by building on the relationship it has with decision trees. We demonstrate a human teaching our Fetch robot a household cleaning task.
ER  - 

TY  - CONF
TI  - Leveraging Temporal Reasoning for Policy Selection in Learning from Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7798
EP  - 7804
AU  - E. Carpio
AU  - M. Clark-Turner
AU  - P. Gesel
AU  - M. Begum
PY  - 2019
KW  - graph theory
KW  - learning by example
KW  - probability
KW  - temporal reasoning
KW  - policy selection
KW  - temporal reasoning model
KW  - Allen's interval algebra
KW  - sequential relations
KW  - parallel temporal relations
KW  - probabilistic inference
KW  - temporal context graph
KW  - learning from demonstration
KW  - perceptual aliasing
KW  - Task analysis
KW  - Hidden Markov models
KW  - Cognition
KW  - Context modeling
KW  - Robots
KW  - Algebra
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8794461
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High-level human activities often have rich temporal structures that determine the order in which atomic actions are executed. We propose the Temporal Context Graph (TCG), a temporal reasoning model that integrates probabilistic inference with Allen's interval algebra, to capture these temporal structures. TCGs are capable of modeling tasks with cyclical atomic actions and consisting of sequential and parallel temporal relations. We present Learning from Demonstration as the application domain where the use of TCGs can improve policy selection and address the problem of perceptual aliasing. Experiments validating the model are presented for learning two tasks from demonstration that involve structured human-robot interactions. The source code for this implementation is available at https://github.com/AssistiveRoboticsUNH/TCG.
ER  - 

TY  - CONF
TI  - Imitating Human Search Strategies for Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7821
EP  - 7827
AU  - D. Ehlers
AU  - M. Suomalainen
AU  - J. Lundell
AU  - V. Kyrki
PY  - 2019
KW  - collision avoidance
KW  - end effectors
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - alignment tasks
KW  - human demonstrations
KW  - state invariant dynamics model
KW  - exploration distribution
KW  - search trajectory
KW  - deterministic ergodic control
KW  - position domains
KW  - superposed forces
KW  - learnt strategy
KW  - 3D electricity socket task
KW  - search task
KW  - human search strategies
KW  - Trajectory
KW  - Task analysis
KW  - Robot sensing systems
KW  - Search problems
KW  - Sockets
KW  - Impedance
DO  - 10.1109/ICRA.2019.8793780
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Learning from Demonstration method for teaching robots to perform search strategies imitated from humans in scenarios where alignment tasks fail due to position uncertainty. The method utilizes human demonstrations to learn both a state invariant dynamics model and an exploration distribution that captures the search area covered by the demonstrator. We present two alternative algorithms for computing a search trajectory from the exploration distribution, one based on sampling and another based on deterministic ergodic control. We augment the search trajectory with forces learnt through the dynamics model to enable searching both in force and position domains. An impedance controller with superposed forces is used for reproducing the learnt strategy. We experimentally evaluate the method on a KUKA LWR4+ performing a 2D peg-in-hole and a 3D electricity socket task. Results show that the proposed method can, with only few human demonstrations, learn to complete the search task.
ER  - 

TY  - CONF
TI  - Active Multi-Contact Continuous Tactile Exploration with Gaussian Process Differential Entropy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7844
EP  - 7850
AU  - D. Driess
AU  - D. Hennes
AU  - M. Toussaint
PY  - 2019
KW  - end effectors
KW  - entropy
KW  - Gaussian processes
KW  - mobile robots
KW  - path planning
KW  - tactile sensors
KW  - touch (physiological)
KW  - active multicontact continuous tactile exploration
KW  - Gaussian process differential entropy
KW  - active tactile exploration framework
KW  - exploration strategy
KW  - information theoretic context
KW  - nonmyopic multistep planning
KW  - end-effectors
KW  - tactile stimuli
KW  - compliant controller framework
KW  - tactile exploration approach
KW  - nonconvex objects
KW  - Gaussian process implicit surface model
KW  - sliding based tactile exploration
KW  - End effectors
KW  - Surface treatment
KW  - Robot sensing systems
KW  - Shape
KW  - Gaussian processes
KW  - Entropy
DO  - 10.1109/ICRA.2019.8793773
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the present work, we propose an active tactile exploration framework to obtain a surface model of an unknown object utilizing multiple contacts simultaneously. To incorporate these multiple contacts, the exploration strategy is based on the differential entropy of the underlying Gaussian process implicit surface model, which formalizes the exploration with multiple contacts within an information theoretic context and additionally allows for nonmyopic multi-step planning. In contrast to many previous approaches, the robot continuously slides along the surface with its end-effectors to gather the tactile stimuli, instead of touching it at discrete locations. This is realized by closely integrating the surface model into the compliant controller framework. Furthermore, we extend our recently proposed sliding based tactile exploration approach to handle non-convex objects. In the experiments, it is shown that multiple contacts simultaneously leads to a more efficient exploration of complex, non-convex objects, not only in terms of time, but also with respect to the total moved distance of all end-effectors. Finally, we demonstrate our methodology with a real PR2 robot that explores an object with both of its arms.
ER  - 

TY  - CONF
TI  - Learning Robust Manipulation Skills with Guided Policy Search via Generative Motor Reflexes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7851
EP  - 7857
AU  - P. Ennen
AU  - P. Bresenitz
AU  - R. Vossen
AU  - F. Hees
PY  - 2019
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - search problems
KW  - trajectory control
KW  - robust manipulation skills
KW  - control policies
KW  - complex manipulation tasks
KW  - high-dimensional neural networks
KW  - robot actions
KW  - real-world trajectory samples
KW  - resulting neural networks
KW  - policy representation
KW  - robust actions
KW  - broader state space
KW  - state-dependent motor reflex
KW  - similar motor reflexes
KW  - real-world manipulation tasks
KW  - guided policy search
KW  - generative motor reflexes map states
KW  - state-action policies
KW  - Neural networks
KW  - Trajectory
KW  - Robots
KW  - Robustness
KW  - Reinforcement learning
KW  - Space exploration
KW  - Training
DO  - 10.1109/ICRA.2019.8793775
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guided Policy Search enables robots to learn control policies for complex manipulation tasks efficiently. Therein, the control policies are represented as high-dimensional neural networks which derive robot actions based on states. However, due to the small number of real-world trajectory samples in Guided Policy Search, the resulting neural networks are only robust in the neighbourhood of the trajectory distribution explored by real-world interactions. In this paper, we present a new policy representation called Generative Motor Reflexes, which is able to generate robust actions over a broader state space compared to previous methods. In contrast to prior state-action policies, Generative Motor Reflexes map states to parameters for a state-dependent motor reflex, which is then used to derive actions. Robustness is achieved by generating similar motor reflexes for many states. We evaluate the presented method in simulated and real-world manipulation tasks, including contact-rich peg-in-hole tasks. Using these evaluation tasks, we show that policies represented as Generative Motor Reflexes lead to robust manipulation skills also outside the explored trajectory distribution with less training needs compared to previous methods.
ER  - 

TY  - CONF
TI  - Incremental Learning of Spatial-Temporal Features in Human Motion Patterns with Mixture Model for Planning Motion of a Collaborative Robot in Assembly Lines
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7858
EP  - 7864
AU  - A. KANAZAWA
AU  - J. KINUGAWA
AU  - K. KOSUGE
PY  - 2019
KW  - assembling
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - product quality
KW  - productivity
KW  - spatial-temporal features
KW  - human motion patterns
KW  - collaborative robot
KW  - assembly lines
KW  - incremental learning system
KW  - planning motion
KW  - products quality
KW  - workers behavior
KW  - Task analysis
KW  - Hidden Markov models
KW  - Mixture models
KW  - Predictive models
KW  - Data models
KW  - Trajectory
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8794227
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collaborative robots are expected to work in cooperation with humans to improve productivity and maintain the quality of products. In the previous study, we have proposed an incremental learning system for adaptively scheduling a motion of the collaborative robot based on a worker's behavior. Although this system could model the worker's motion pattern precisely and robustly without collecting the worker's data in advance, it required two different models for modeling the worker's spatial and temporal features respectively and was not well considered for generalization. In this paper, we extend the previous incremental learning system by integrating the spatial and temporal models using a mixture model. In addition, we install a new incremental learning algorithm which improves a generalization capability of the mixture model and avoids overfitting in the situation where the prior information is limited. Implementing the proposed algorithm, we evaluate the effectiveness of the proposed system by experiments for several workers and for several assembly processes.
ER  - 

TY  - CONF
TI  - Learning Quickly to Plan Quickly Using Modular Meta-Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7865
EP  - 7871
AU  - R. Chitnis
AU  - L. P. Kaelbling
AU  - T. Lozano-Pérez
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - multiobject manipulation problems
KW  - continuous state
KW  - continuous operator parameters
KW  - state description
KW  - discrete parameters
KW  - single specializer
KW  - modular meta-learning approach
KW  - action spaces
KW  - 3D pick-and-place tasks
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Skeleton
KW  - Search problems
KW  - Companies
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794342
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multi-object manipulation problems in continuous state and action spaces can be solved by planners that search over sampled values for the continuous parameters of operators. The efficiency of these planners depends critically on the effectiveness of the samplers used, but effective sampling in turn depends on details of the robot, environment, and task. Our strategy is to learn functions called speciatizers that generate values for continuous operator parameters, given a state description and values for the discrete parameters. Rather than trying to learn a single specializer for each operator from large amounts of data on a single task, we take a modular meta-learning approach. We train on multiple tasks and learn a variety of specializers that, on a new task, can be quickly adapted using relatively little data - thus, our system learns quickly to plan quickly using these specializers. We validate our approach experimentally in simulated 3D pick-and-place tasks with continuous state and action spaces. Visit http://tinyurl.com/chitnis-icra-19 for a supplementary video.
ER  - 

TY  - CONF
TI  - Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7872
EP  - 7878
AU  - G. Tatiya
AU  - J. Sinapov
PY  - 2019
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - recurrent neural nets
KW  - robot vision
KW  - multisensory object category recognition
KW  - interactive behavioral exploration
KW  - deep learning methodology
KW  - visual data
KW  - haptic sensory data
KW  - haptic data
KW  - auditory data
KW  - sensory modality
KW  - visual information
KW  - dominant modality
KW  - auditory networks
KW  - convolutional neural networks
KW  - haptic networks
KW  - tensor-train gated recurrent unit network
KW  - robot category recognition
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Visualization
KW  - Convolution
KW  - Network architecture
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794095
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When identifying an object and its properties, humans use features from multiple sensory modalities produced when manipulating the object. Motivated by this cognitive process, we propose a deep learning methodology for object category recognition which uses visual, auditory, and haptic sensory data coupled with exploratory behaviors (e.g., grasping, lifting, pushing, etc.). In our method, as the robot performs an action on an object, it uses a Tensor-Train Gated Recurrent Unit network to process its visual data, and Convolutional Neural Networks to process haptic and auditory data. We propose a novel strategy to train a single neural network that inputs video, audio and haptic data, and demonstrate that its performance is better than separate neural networks for each sensory modality. The proposed method was evaluated on a dataset in which the robot explored 100 different objects, each belonging to one of 20 categories. While the visual information was the dominant modality for most categories, adding the additional haptic and auditory networks further improves the robot's category recognition accuracy. For some of the behaviors, our approach outperforms the previous published baseline for the dataset which used handcrafted features for each modality. We also show that a robot does not need the sensory data from the entire interaction, but instead can make a good prediction early on during behavior execution.
ER  - 

TY  - CONF
TI  - Discontinuity-Sensitive Optimal Control Learning by Mixture of Experts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7892
EP  - 7898
AU  - G. Tang
AU  - K. Hauser
PY  - 2019
KW  - approximation theory
KW  - function approximation
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - discontinuity-sensitive optimal control learning
KW  - machine learning method
KW  - parametric input
KW  - problem parameters
KW  - optimal solutions
KW  - problem-optimum map
KW  - discrete homotopy classes
KW  - control switching
KW  - MoE
KW  - standard neural networks
KW  - dynamic vehicle control problems
KW  - nonlinear optimal control problems
KW  - function approximators
KW  - mixture of experts model
KW  - trajectory prediction
KW  - Trajectory
KW  - Training
KW  - Optimal control
KW  - Neural networks
KW  - Optimization
KW  - Standards
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793909
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a machine learning method to predict the solutions of related nonlinear optimal control problems given some parametric input, such as the initial state. The map between problem parameters to optimal solutions is called the problem-optimum map, and is often discontinuous due to nonconvexity, discrete homotopy classes, and control switching. This causes difficulties for traditional function approximators such as neural networks, which assume continuity of the underlying function. This paper proposes a mixture of experts (MoE) model composed of a classifier and several regressors, where each regressor is tuned to a particular continuous region. A novel training approach is proposed that trains classifier and regressors independently. MoE greatly outperforms standard neural networks, and achieves highly reliable trajectory prediction (over 99.5% accuracy) in several dynamic vehicle control problems.
ER  - 

TY  - CONF
TI  - Wormhole Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7899
EP  - 7905
AU  - A. Zanardi
AU  - J. Zilly
AU  - A. Aumiller
AU  - A. Censi
AU  - E. Frazzoli
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image sensors
KW  - infrared detectors
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object detector
KW  - invariance properties
KW  - visible-light RGB camera
KW  - infrared sensor
KW  - temporary sensor
KW  - infrared detector
KW  - RGB-inferred labels
KW  - infrared-inferred labels
KW  - transfer learning
KW  - wormhole learning
KW  - pretrained RGB detector
KW  - Detectors
KW  - Task analysis
KW  - Robot sensing systems
KW  - Cameras
KW  - Lighting
KW  - Training
KW  - Mutual information
DO  - 10.1109/ICRA.2019.8794336
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Typically, to enlarge the operating domain of an object detector, more labeled training data is required. We describe a method called wormhole learning, which allows to extend the operating domain without additional data, but only with temporary access to an auxiliary sensor with certain invariance properties. We describe the instantiation of this principle with a regular visible-light RGB camera as the main sensor, and an infrared sensor as the temporary sensor. We start with a pre-trained RGB detector; then we train the infrared detector based on the RGB-inferred labels; finally we re-train the RGB detector based on the infrared-inferred labels. After these two transfer-learning steps, the RGB detector has enlarged its operating domain by inheriting part of the invariance to illumination of the infrared sensor; in particular, the RGB detector is now able to see much better at night. We analyze the wormhole learning phenomenon by bounding the possible gain in accuracy using mutual information properties of the two sensors and considered operating domain.
ER  - 

TY  - CONF
TI  - Sharing the Load: Human-Robot Team Lifting Using Muscle Activity
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7906
EP  - 7912
AU  - J. DelPreto
AU  - D. Rus
PY  - 2019
KW  - control engineering computing
KW  - electromyography
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - lifting
KW  - muscle
KW  - neural nets
KW  - robotic assembly
KW  - signal detection
KW  - human-robot team lifting
KW  - muscle activity
KW  - surface electromyography
KW  - muscle signals
KW  - continuous setpoint algorithm
KW  - biceps activity
KW  - triceps activity
KW  - assembly tasks
KW  - physical human-robot collaboration
KW  - surface EMG
KW  - neural network
KW  - Muscles
KW  - Task analysis
KW  - Electromyography
KW  - Robot kinematics
KW  - Signal processing algorithms
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794414
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Seamless communication of desired motions and goals is essential for enabling effective physical human-robot collaboration. In such cases, muscle activity measured via surface electromyography (EMG) can provide insight into a person's intentions while minimally distracting from the task. The presented system uses two muscle signals to create a control framework for team lifting tasks in which a human and robot lift an object together. A continuous setpoint algorithm uses biceps activity to estimate changes in the user's hand height, and also allows the user to explicitly adjust the robot by stiffening or relaxing their arm. In addition to this pipeline, a neural network trained only on previous users classifies biceps and triceps activity to detect up or down gestures on a rolling basis; this enables finer control over the robot and expands the feasible workspace. The resulting system is evaluated by 10 untrained subjects performing a variety of team lifting and assembly tasks with rigid and flexible objects.
ER  - 

TY  - CONF
TI  - Position control of medical cable-driven flexible instruments by combining machine learning and kinematic analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7913
EP  - 7919
AU  - R. A. Porto
AU  - F. Nageotte
AU  - P. Zanne
AU  - M. d. Mathelin
PY  - 2019
KW  - cables (mechanical)
KW  - control engineering computing
KW  - endoscopes
KW  - flexible manipulators
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - medical computing
KW  - medical robotics
KW  - position control
KW  - robot kinematics
KW  - surgery
KW  - medical cable-driven flexible instruments
KW  - machine learning
KW  - kinematic analysis
KW  - cable transmissions
KW  - medical endoscopic systems
KW  - flexible medical robotic systems
KW  - open-loop accuracy
KW  - Position Inverse Kinematic Model
KW  - off-line learning
KW  - learning process
KW  - STRAS medical robot
KW  - position control
KW  - kinematic models
KW  - hysteresis effects
KW  - Instruments
KW  - Hysteresis motors
KW  - Hysteresis
KW  - Training
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793692
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Non-linearities in cable transmissions are important limitations for the accurate control of flexible instruments used in medical endoscopic systems. Hysteresis effects greatly impact the accuracy of conventional kinematic models. This is especially critical for implementing automatic motions in flexible medical robotic systems. In this paper, we propose a method for improving open-loop accuracy of flexible instruments by implementing a Position Inverse Kinematic Model which is able to take into account hysteresis effects. In order to avoid complex physical modeling, the method relies on the off-line learning of the behavior of the instruments. Basic knowledge of the kinematic is also incorporated in the learning process in order to make it fast. The validity of the approach is demonstrated by the execution of 2D and 3D trajectories with the instruments of the STRAS medical robot. The accuracy is shown to be significantly improved with respect to other learning-based methods.
ER  - 

TY  - CONF
TI  - Online Learning for Proactive Obstacle Avoidance with Powered Transfemoral Prostheses
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7920
EP  - 7925
AU  - M. Gordon
AU  - N. Thatte
AU  - H. Geyer
PY  - 2019
KW  - adaptive control
KW  - collision avoidance
KW  - kinematics
KW  - medical control systems
KW  - prosthetics
KW  - regression analysis
KW  - regression model
KW  - kinematic data
KW  - obstacle avoidance system
KW  - obstacle avoidance success rates
KW  - prosthetic limb
KW  - adaptive system
KW  - powered prosthetic limbs
KW  - stumble recovery systems
KW  - powered prostheses
KW  - direct knee control
KW  - mechanically-passive transfemoral prosthetic limbs
KW  - powered transfemoral prostheses
KW  - proactive obstacle avoidance
KW  - online learning
KW  - amputee subject
KW  - obstacle negotiation success rate
KW  - trip avoidance system
KW  - nonamputee subject
KW  - Collision avoidance
KW  - Trajectory
KW  - Knee
KW  - Prosthetics
KW  - Legged locomotion
KW  - Sensitivity
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794001
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Avoiding obstacles poses a significant challenge for amputees using mechanically-passive transfemoral prosthetic limbs due to their lack of direct knee control. In contrast, powered prostheses can potentially improve obstacle avoidance via their ability to add energy to the system. In past work, researchers have proposed stumble recovery systems for powered prosthetic limbs that provide assistance in the event of a trip. However, these systems only aid recovery after an obstacle has disrupted the user's gait and do not proactively help the amputee avoid obstacles. To address this problem, we designed an adaptive system that learns online to use kinematic data from the prosthetic limb to detect the user's obstacle avoidance intent in early swing. When the system detects an obstacle, it alters the planned swing trajectory to help avoid trips. Additionally, the system uses a regression model to predict the required knee flexion angle for the trip response. We validated the system by comparing obstacle avoidance success rates with and without the obstacle avoidance system. For a non-amputee subject wearing the prosthesis through an adapter, the trip avoidance system improved the obstacle negotiation success rate from 37% to 89%, while an amputee subject improved his success rate from 35% to 71% when compared to utilizing minimum jerk trajectories for the knee and ankle joints.
ER  - 

TY  - CONF
TI  - Passive Dynamic Object Locomotion by Rocking and Walking Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7926
EP  - 7932
AU  - A. Nazir
AU  - J. Seo
PY  - 2019
KW  - end effectors
KW  - gait analysis
KW  - legged locomotion
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - passive dynamic object locomotion
KW  - walking manipulation
KW  - zigzag path
KW  - kinematics
KW  - rocking motion
KW  - manipulator arm
KW  - robotic manipulation technique
KW  - rock-and-walk object transportation technique
KW  - simple end-effector
KW  - stable gait
KW  - rock-walk object locomotion
KW  - gravity force
KW  - Dynamics
KW  - Legged locomotion
KW  - Gravity
KW  - Manipulator dynamics
KW  - Kinematics
KW  - Rocks
DO  - 10.1109/ICRA.2019.8794163
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel robotic manipulation technique for transporting objects on the ground in a passive dynamic, nonprehensile manner. The object is manipulated to rock from side to side repeatedly; in the meantime, the force of gravity enables the object to roll along a zigzag path that is eventually heading forward. We call it rock-and-walk object locomotion. First, we examine the kinematics and dynamics of the rocking motion to understand how the states of the object evolve. We then discuss how to control the robot to connect individual rocking motions into a stable gait of the object. Our rock-and-walk object transportation technique is implemented using a conventional manipulator arm and a simple end-effector, interacting with the object in a nonprehensile manner in favor of the passive dynamics of the object. A set of experiments demonstrates successful object locomotion.
ER  - 

TY  - CONF
TI  - Autonomous Latching System for Robotic Boats
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7933
EP  - 7939
AU  - L. A. Mateos
AU  - W. Wang
AU  - B. Gheneti
AU  - F. Duarte
AU  - C. Ratti
AU  - D. Rus
PY  - 2019
KW  - boats
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - robot vision
KW  - robotic assembly
KW  - autonomous latching system
KW  - autonomous robotic boats
KW  - multiple boats
KW  - dynamic united floating infrastructure
KW  - latching mechanism
KW  - vision-based robot controller
KW  - docking
KW  - rotation movement
KW  - self-driving robotic boats
KW  - Robots
KW  - Boats
KW  - Sockets
KW  - Latches
KW  - Computer interfaces
KW  - Three-dimensional displays
KW  - Laser beams
DO  - 10.1109/ICRA.2019.8793525
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous robotic boats are devised to transport people and goods similar to self-driving cars. One of the attractive features specially applied in water environment is to dynamically link and join multiple boats into one unit in order to form floating infrastructure such as bridges, markets or concert stages, as well as autonomously self-detach to perform individual tasks.In this paper we present a novel latching system that enables robotic boats to create dynamic united floating infrastructure while overcoming water disturbances. The proposed latching mechanism is based on the spherical joint (ball and socket) that allows rotation and free movements in two planes at the same time. In this configuration, the latching system is capable to securely and efficiently assemble/disassemble floating structures. The vision-based robot controller guides the self-driving robotic boats to latch with high accuracy in the millimeter range. Moreover, in case the robotic boat fails to latch due to harsh weather, the autonomous latching system is capable to recompute and reposition to latch successfully. We present experimental results from latching and docking in indoor environments. Also, we present results in outdoor environments from latching a couple of robotic boats in open water with calm and turbulent currents.
ER  - 

TY  - CONF
TI  - Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7940
EP  - 7946
AU  - Y. Girdhar
AU  - L. Cai
AU  - S. Jamieson
AU  - N. McGuire
AU  - G. Flaspohler
AU  - S. Suman
AU  - B. Claus
PY  - 2019
KW  - autonomous underwater vehicles
KW  - geophysical image processing
KW  - image representation
KW  - object detection
KW  - oceanographic techniques
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - unsupervised learning
KW  - co-robotic exploration
KW  - bandwidth tunable technique
KW  - real-time probabilistic scene modeling
KW  - communication constrained environments
KW  - deep sea
KW  - scene complexity
KW  - bandwidth requirements
KW  - underwater robot
KW  - high-level semantic scene constructs
KW  - artificially constructed tank environment
KW  - science interests
KW  - unsupervised scene model impact
KW  - resulting scene model
KW  - coral reef
KW  - bandwidth constraints
KW  - scene maps streaming
KW  - Robot sensing systems
KW  - Bandwidth
KW  - Oceans
KW  - Data models
KW  - Visualization
KW  - Bayes methods
DO  - 10.1109/ICRA.2019.8794132
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m×10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantity how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.
ER  - 

TY  - CONF
TI  - UWStereoNet: Unsupervised Learning for Depth Estimation and Color Correction of Underwater Stereo Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7947
EP  - 7954
AU  - K. A. Skinner
AU  - J. Zhang
AU  - E. A. Olson
AU  - M. Johnson-Roberson
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - feature extraction
KW  - geophysical image processing
KW  - image colour analysis
KW  - image matching
KW  - image resolution
KW  - image restoration
KW  - light propagation
KW  - neural nets
KW  - oceanographic techniques
KW  - spatial variables measurement
KW  - stereo image processing
KW  - unsupervised learning
KW  - visual perception
KW  - unsupervised learning
KW  - stereo cameras
KW  - navigation
KW  - underwater robotic systems
KW  - constrained camera geometry
KW  - feature detection
KW  - underwater light propagation lead
KW  - deep learning
KW  - underwater image restoration
KW  - unsupervised deep neural network
KW  - input raw color underwater stereo imagery
KW  - color corrected imagery
KW  - underwater image formation
KW  - image processing techniques
KW  - depth estimation
KW  - stereo vision algorithms
KW  - disparity estimation
KW  - DNN
KW  - Image color analysis
KW  - Estimation
KW  - Image restoration
KW  - Cameras
KW  - Attenuation
KW  - Stereo vision
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8794272
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Stereo cameras are widely used for sensing and navigation of underwater robotic systems. They can provide high resolution color views of a scene; the constrained camera geometry enables metrically accurate depth estimation; they are also relatively cost-effective. Traditional stereo vision algorithms rely on feature detection and matching to enable triangulation of points for estimating disparity. However, for underwater applications, the effects of underwater light propagation lead to image degradation, reducing image quality and contrast. This makes it especially challenging to detect and match features, especially from varying viewpoints. Recently, deep learning has shown success in end-to-end learning of dense disparity maps from stereo images. Still, many state-of-the-art methods are supervised and require ground truth depth or disparity, which is challenging to gather in subsea environments. Simultaneously, deep learning has also been applied to the problem of underwater image restoration. Again, it is difficult or impossible to gather real ground truth data for this problem. In this work, we present an unsupervised deep neural network (DNN) that takes input raw color underwater stereo imagery and outputs dense depth maps and color corrected imagery of underwater scenes. We leverage a model of the process of underwater image formation, image processing techniques, as well as the geometric constraints inherent to the stereo vision problem to develop a modular network that outperforms existing methods.
ER  - 

TY  - CONF
TI  - Design and Parameter Optimization of a 3-PSR Parallel Mechanism for Replicating Wave and Boat Motion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7955
EP  - 7961
AU  - K. Talke
AU  - D. Drotman
AU  - N. Stroumtsos
AU  - M. de Oliveira
AU  - T. Bewley
PY  - 2019
KW  - autonomous aerial vehicles
KW  - boats
KW  - marine safety
KW  - motion control
KW  - optimisation
KW  - pitch control (position)
KW  - ball joint mounting angle
KW  - experimental testing
KW  - boat motion replication
KW  - parameter optimization
KW  - 3-PSR parallel mechanism
KW  - three-degree-of-freedom
KW  - prismatic-spherical-revolute parallel mechanism
KW  - unmanned aerial vehicle
KW  - unmanned surface vehicle
KW  - lookup table
KW  - geometric constraints
KW  - wave replication
KW  - three actuated linear rails
KW  - UAV winch payload
KW  - inertial measurement unit
KW  - Boats
KW  - Fasteners
KW  - Testing
KW  - Rails
KW  - Sea state
KW  - Kinematics
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2019.8793473
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a low-cost, three-degree-of-freedom (3-DOF) prismatic-spherical-revolute (PSR) parallel mechanism used as a testing platform for an unmanned aerial vehicle (UAV) tethered to an unmanned surface vehicle (USV). The mechanism has three actuated linear rails kinematically linked to a platform which replicates boat motion up to 2.5 m vertical heave (sea state 4, Douglas Sea Scale). A lookup table relating relative slider heights to platform roll and pitch was developed numerically leveraging geometric constraints. A design parameter study optimized the arm length, platform size, and ball joint mounting angle relative to the overall radius to maximize the workspace. For this design, a maximum roll and pitch range from -32° to 32° and -25° to 35°, respectively, is achievable. A prototype was manufactured to carry the tethered UAV winch payload. Experimental testing confirmed the workspace and demonstrated boat motion replication, validated using an inertial measurement unit (IMU).
ER  - 

TY  - CONF
TI  - A Framework for On-line Learning of Underwater Vehicles Dynamic Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7969
EP  - 7975
AU  - B. Wehbe
AU  - M. Hildebrandt
AU  - F. Kirchner
PY  - 2019
KW  - marine navigation
KW  - mobile robots
KW  - regression analysis
KW  - robot dynamics
KW  - support vector machines
KW  - tracking
KW  - underwater vehicles
KW  - vehicle dynamics
KW  - on-line learning
KW  - underwater vehicles dynamic models
KW  - accurate tracking controllers
KW  - navigation algorithms
KW  - high fidelity performance
KW  - robot dynamics
KW  - incremental support vector regression method
KW  - Robots
KW  - Vehicle dynamics
KW  - Adaptation models
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Support vector machines
KW  - Data models
DO  - 10.1109/ICRA.2019.8794403
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning the dynamics of robots from data can help achieve more accurate tracking controllers, or aid their navigation algorithms. However, when the actual dynamics of the robots change due to external conditions, on-line adaptation of their models is required to maintain high fidelity performance. In this work, a framework for on-line learning of robot dynamics is developed to adapt to such changes. The proposed framework employs an incremental support vector regression method to learn the model sequentially from data streams. In combination with the incremental learning, strategies for including and forgetting data are developed to obtain better generalization over the whole state space. The framework is tested in simulation and real experimental scenarios demonstrating its adaptation capabilities to changes in the robot's dynamics.
ER  - 

TY  - CONF
TI  - Incorporating End-to-End Speech Recognition Models for Sentiment Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7976
EP  - 7982
AU  - E. Lakomkin
AU  - M. A. Zamani
AU  - C. Weber
AU  - S. Magg
AU  - S. Wermter
PY  - 2019
KW  - emotion recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - pattern classification
KW  - recurrent neural nets
KW  - speech recognition
KW  - text analysis
KW  - linguistic modality
KW  - expressed emotion
KW  - spoken text
KW  - ground-truth transcriptions
KW  - speech recognition mistakes
KW  - automatic speech recognition output
KW  - character-level recurrent neural network
KW  - sentiment recognition
KW  - acoustic modality
KW  - binary sentiment classification task
KW  - emotion recognition
KW  - synergistic effect
KW  - auditory transcribed text
KW  - transcribed text
KW  - sentiment intensity
KW  - end-to-end speech recognition models
KW  - sentiment analysis
KW  - ASR systems
KW  - multimodal corpus of sentiment intensity
KW  - MOSI
KW  - Acoustics
KW  - Feature extraction
KW  - Speech recognition
KW  - Training
KW  - Computational modeling
KW  - Computer architecture
KW  - Emotion recognition
DO  - 10.1109/ICRA.2019.8794468
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Previous work on emotion recognition demonstrated a synergistic effect of combining several modalities such as auditory, visual, and transcribed text to estimate the affective state of a speaker. Among these, the linguistic modality is crucial for the evaluation of an expressed emotion. However, manually transcribed spoken text cannot be given as input to a system practically. We argue that using ground-truth transcriptions during training and evaluation phases leads to a significant discrepancy in performance compared to real-world conditions, as the spoken text has to be recognized on the fly and can contain speech recognition mistakes. In this paper, we propose a method of integrating an automatic speech recognition (ASR) output with a character-level recurrent neural network for sentiment recognition. In addition, we conduct several experiments investigating sentiment recognition for human-robot interaction in a noise-realistic scenario which is challenging for the ASR systems. We quantify the improvement compared to using only the acoustic modality in sentiment recognition. We demonstrate the effectiveness of this approach on the Multimodal Corpus of Sentiment Intensity (MOSI) by achieving 73,6% accuracy in a binary sentiment classification task, exceeding previously reported results that use only acoustic input. In addition, we set a new state-of-the-art performance on the MOSI dataset (80.4% accuracy, 2% absolute improvement).
ER  - 

TY  - CONF
TI  - Improved Optical Flow for Gesture-based Human-robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7983
EP  - 7989
AU  - J. Chang
AU  - A. Tejero-de-Pablos
AU  - T. Harada
PY  - 2019
KW  - feature extraction
KW  - gesture recognition
KW  - human-robot interaction
KW  - neural nets
KW  - service robots
KW  - gesture interaction
KW  - human motion
KW  - gesture-based human-robot interaction
KW  - house service robot
KW  - practical robot applications
KW  - gesture recognition methods
KW  - optical flow estimation method
KW  - speed-accuracy trade-off
KW  - deep learning-based methods
KW  - feature extractors
KW  - midway features
KW  - Estimation
KW  - Optical imaging
KW  - Feature extraction
KW  - Gesture recognition
KW  - Robots
KW  - Optical fiber networks
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8793825
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Gesture interaction is a natural way of communicating with a robot as an alternative to speech. Gesture recognition methods leverage optical flow in order to understand human motion. However, while accurate optical flow estimation (i.e., traditional) methods are costly in terms of runtime, fast estimation (i.e., deep learning) methods' accuracy can be improved. In this paper, we present a pipeline for gesture-based human-robot interaction that uses a novel optical flow estimation method in order to achieve an improved speed-accuracy trade-off. Our optical flow estimation method introduces four improvements to previous deep learning-based methods: strong feature extractors, attention to contours, midway features, and a combination of these three. This results in a better understanding of motion, and a finer representation of silhouettes. In order to evaluate our pipeline, we generated our own dataset, MIBURI, which contains gestures to command a house service robot. In our experiments, we show how our method improves not only optical flow estimation, but also gesture recognition, offering a speed-accuracy trade-off more realistic for practical robot applications.
ER  - 

TY  - CONF
TI  - Decentralization of Multiagent Policies by Learning What to Communicate
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7990
EP  - 7996
AU  - J. Paulos
AU  - S. W. Chen
AU  - D. Shishika
AU  - V. Kumar
PY  - 2019
KW  - decentralised control
KW  - multi-agent systems
KW  - multi-robot systems
KW  - neurocontrollers
KW  - optimisation
KW  - multiagent policies
KW  - agent architecture
KW  - training methodology
KW  - neural networks
KW  - task-oriented communication semantics
KW  - communication-unaware expert policy
KW  - perimeter defense game
KW  - communication constraints
KW  - collaborative tasks
KW  - optimization
KW  - decentralization
KW  - Neural networks
KW  - Pins
KW  - Task analysis
KW  - Training
KW  - Games
KW  - Computer architecture
KW  - Decoding
DO  - 10.1109/ICRA.2019.8793777
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Effective communication is required for teams of robots to solve sophisticated collaborative tasks. In practice it is typical for both the encoding and semantics of communication to be manually defined by an expert; this is true regardless of whether the behaviors themselves are bespoke, optimization based, or learned. We present an agent architecture and training methodology using neural networks to learn task-oriented communication semantics based on the example of a communication-unaware expert policy. A perimeter defense game illustrates the system's ability to handle dynamically changing numbers of agents and its graceful degradation in performance as communication constraints are tightened or the expert's observability assumptions are broken.
ER  - 

TY  - CONF
TI  - Acquisition of Word-Object Associations from Human-Robot and Human-Human Dialogues
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7997
EP  - 8003
AU  - S. Sadeghi
AU  - B. Oosterveld
AU  - E. Krause
AU  - M. Scheutz
PY  - 2019
KW  - human-robot interaction
KW  - knowledge acquisition
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - human-robot dialogues
KW  - word-object associations
KW  - human-human dialogues
KW  - robotic system
KW  - AI agents
KW  - cross-situational learning
KW  - Instruction-based word learning
KW  - Robots
KW  - Semantics
KW  - Syntactics
KW  - Learning systems
KW  - Linguistics
KW  - Education
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793615
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Past work on acquisition of word-object associations in robots has focused on either fast instruction-based methods which accept highly constrained input or gradual cross-situational learning methods, but not a mixture of both. In this paper, we present an integrated robotic system which allows for a combination of these methods to contribute to the task of learning the labels of objects in AI agents. We demonstrate the expanded word learning capabilities in the outcome system and how learning from both human-human and human-robot dialogues can be achieved in one integrated system.
ER  - 

TY  - CONF
TI  - Robot Object Referencing through Legible Situated Projections
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8004
EP  - 8010
AU  - T. Weng
AU  - L. Perlmutter
AU  - S. Nikolaidis
AU  - S. Srinivasa
AU  - M. Cakmak
PY  - 2019
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - mobile robots
KW  - object detection
KW  - target object
KW  - PR2 robot
KW  - robot object
KW  - legible situated projections
KW  - reference objects
KW  - complex task-oriented human-robot collaborations
KW  - robot-to-human information transfer
KW  - visual referencing
KW  - arrow-object match functions
KW  - head-mounted projector
KW  - Task analysis
KW  - Collaboration
KW  - Legged locomotion
KW  - Communication channels
KW  - Visualization
KW  - Computer science
DO  - 10.1109/ICRA.2019.8793638
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to reference objects in the environment is a key communication skill that robots need for complex, task-oriented human-robot collaborations. In this paper we explore the use of projections, which are a powerful communication channel for robot-to-human information transfer as they allow for situated, instantaneous, and parallelized visual referencing. We focus on the question of what makes a good projection for referencing a target object. To that end, we mathematically formulatelegibility of projections intended to reference an object, and propose alternative arrow-object match functions for optimally computing the placement of an arrow to indicate a target object in a cluttered scene. We implement our approach on a PR2 robot with a head-mounted projector. Through an online (48 participants) and an in-person (12 participants) user study we validate the effectiveness of our approach, identify the types of scenes where projections may fail, and characterize the differences between alternative match functions.
ER  - 

TY  - CONF
TI  - Security-Aware Synthesis of Human-UAV Protocols
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8011
EP  - 8017
AU  - M. Elfar
AU  - H. Zhu
AU  - M. L. Cummings
AU  - M. Pajic
PY  - 2019
KW  - autonomous aerial vehicles
KW  - command and control systems
KW  - control engineering computing
KW  - formal verification
KW  - learning (artificial intelligence)
KW  - military aircraft
KW  - stochastic games
KW  - security-aware synthesis
KW  - human-UAV protocols
KW  - collaboration protocols
KW  - human-unmanned aerial vehicle
KW  - geolocation task
KW  - stochastic game-based model
KW  - stealthy false-data injection attacks
KW  - collected experimental data
KW  - human-UAV coalition
KW  - H-UAV protocol synthesis
KW  - human operators
KW  - UAV hidden-information constraint
KW  - RESCHU-SA testbed
KW  - geolocation strategies
KW  - model checkers
KW  - command and control systems
KW  - Games
KW  - Task analysis
KW  - Protocols
KW  - Geology
KW  - Stochastic processes
KW  - Security
KW  - Global Positioning System
DO  - 10.1109/ICRA.2019.8794385
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we synthesize collaboration protocols for human-unmanned aerial vehicle (H-UAV) command and control systems, where the human operator aids in securing the UAV by intermittently performing geolocation tasks to confirm its reported location. We first present a stochastic game-based model for the system that accounts for both the operator and an adversary capable of launching stealthy false-data injection attacks, causing the UAV to deviate from its path. We also describe a synthesis challenge due to the UAV's hidden-information constraint. Next, we perform human experiments using a developed RESCHU-SA testbed to recognize the geolocation strategies that operators adopt. Furthermore, we deploy machine learning techniques on the collected experimental data to predict the correctness of a geolocation task at a given location based on its geographical features. By representing the model as a delayed-action game and formalizing the system objectives, we utilize off-the-shelf model checkers to synthesize protocols for the human-UAV coalition that satisfy these objectives. Finally, we demonstrate the usefulness of the H-UAV protocol synthesis through a case study where the protocols are experimentally analyzed and further evaluated by human operators.
ER  - 

TY  - CONF
TI  - Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8018
EP  - 8025
AU  - K. Koreitem
AU  - J. Li
AU  - I. Karp
AU  - T. Manderson
AU  - G. Dudek
PY  - 2019
KW  - convolutional neural nets
KW  - decoding
KW  - encoding
KW  - gesture recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - protocols
KW  - variable length codes
KW  - optimal variable-length prefix codes
KW  - interrobot communication
KW  - action sequences
KW  - swimming robot
KW  - communication protocol
KW  - whole-body gestures
KW  - radio-denied environments
KW  - passive communication
KW  - full-body gestures
KW  - underwater communication
KW  - robot gesture execution
KW  - classical decoding methods
KW  - observer robot
KW  - convolutional network
KW  - natural activity
KW  - Robots
KW  - Encoding
KW  - Decoding
KW  - Three-dimensional displays
KW  - Visualization
KW  - Heuristic algorithms
KW  - Target tracking
DO  - 10.1109/ICRA.2019.8793644
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.
ER  - 

TY  - CONF
TI  - WISDOM: WIreless Sensing-assisted Distributed Online Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8026
EP  - 8033
AU  - C. Adhivarahan
AU  - K. Dantu
PY  - 2019
KW  - least mean squares methods
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - WISDOM
KW  - spatial sensing
KW  - robotics
KW  - augmented reality
KW  - urban spaces
KW  - wireless access points
KW  - coarse orientation
KW  - average Root Mean Square mapping error
KW  - wireless sensing-assisted distributed online mapping
KW  - robot swarm
KW  - custom ICP algorithm
KW  - absolute trajectory error
KW  - average root mean square mapping error
KW  - size 0.2 m
KW  - size 1.3 m
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Robot kinematics
KW  - Visualization
KW  - Merging
DO  - 10.1109/ICRA.2019.8793932
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Spatial sensing is a fundamental requirement for applications in robotics and augmented reality. In urban spaces such as malls, airports, apartments, and others, it is quite challenging for a single robot to map the whole environment. So, we employ a swarm of robots to perform the mapping. One challenge with this approach is merging sub-maps built by each robot. In this work, we use wireless access points, which are ubiquitous in most urban spaces, to provide us with coarse orientation between sub-maps, and use a custom ICP algorithm to refine this orientation to merge them. We demonstrate our approach with maps from a building on campus and evaluate it using two metrics. Our results show that, in the building we studied, we can achieve an average Absolute Trajectory error of 0.2m in comparison to a map created by a single robot and average Root Mean Square mapping error of 1.3m from ground truth landmark locations.
ER  - 

TY  - CONF
TI  - Learning Recursive Bayesian Nonparametric Modeling of Moving Targets via Mobile Decentralized Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8034
EP  - 8040
AU  - C. Liu
AU  - Y. Chen
AU  - J. Gemerek
AU  - H. Yang
AU  - S. Ferrari
PY  - 2019
KW  - Bayes methods
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - recursive estimation
KW  - sensor fusion
KW  - mobile decentralized sensors
KW  - multisensor applications
KW  - GP recursive fusion law
KW  - recursive DPGP fusion approach
KW  - data fusion
KW  - Gaussian processes
KW  - recursive Bayesian nonparametric modeling
KW  - Dirichlet process
KW  - Sensor fusion
KW  - Computational modeling
KW  - Gaussian processes
KW  - Time measurement
KW  - Kinematics
KW  - Velocity measurement
DO  - 10.1109/ICRA.2019.8793879
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bayesian nonparametric models, such as the Dirichlet Process Gaussian Process (DPGP), have been shown very effective at learning models of dynamic targets exclusively from data. Previous work on batch DPGP learning and inference, however, ceases to be efficient in multi-sensor applications that require decentralized measurements to be obtained sequentially over time. Batch processing, in this case, leads to redundant computations that may hinder online applicability. This paper develops a recursive approach for DPGP learning and inference in which a novel Dirichlet Process prior based on Wasserstein metric is used for measuring the similarity between multiple Gaussian Processes (GPs). Combined with the GP recursive fusion law, the proposed recursive DPGP fusion approach enables efficient online data fusion. The problem of active sensing for recursive DPGP learning and inference is also investigated by uncertainty reduction via expected mutual information. Simulation and experimental results show that the proposed approach successfully learns the models of moving targets and outperforms existing benchmark methods.
ER  - 

TY  - CONF
TI  - UAV/UGV Autonomous Cooperation: UAV assists UGV to climb a cliff by attaching a tether
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8041
EP  - 8047
AU  - T. Miki
AU  - P. Khrapchenkov
AU  - K. Hori
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - inertial navigation
KW  - mobile robots
KW  - off-road vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - Unmanned Aerial Vehicle
KW  - Unmanned Ground Vehicle
KW  - tether attachment device
KW  - steep terrain
KW  - tether anchoring
KW  - UGV autonomous cooperation
KW  - UAV autonomous cooperation
KW  - visual inertial navigation
KW  - collaborative navigation
KW  - 3D voxel mapping
KW  - obstacle avoidance planning
KW  - traversability analysis
KW  - Robot sensing systems
KW  - Navigation
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Trajectory
KW  - Attitude control
DO  - 10.1109/ICRA.2019.8794265
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a novel cooperative system for an Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV) which utilizes the UAV not only as a flying sensor but also as a tether attachment device. Two robots are connected with a tether, allowing the UAV to anchor the tether to a structure located at the top of a steep terrain, impossible to reach for UGVs. Thus, enhancing the poor traversability of the UGV by not only providing a wider range of scanning and mapping from the air, but also by allowing the UGV to climb steep terrains with the winding of the tether. In addition, we present an autonomous framework for the collaborative navigation and tether attachment in an unknown environment. The UAV employs visual inertial navigation with 3D voxel mapping and obstacle avoidance planning. The UGV makes use of the voxel map and generates an elevation map to execute path planning based on a traversability analysis. Furthermore, we compared the pros and cons of possible methods for the tether anchoring from multiple points of view. To increase the probability of successful anchoring, we evaluated the anchoring strategy with an experiment. Finally, the feasibility and capability of our proposed system were demonstrated by an autonomous mission experiment in the field with an obstacle and a cliff.
ER  - 

TY  - CONF
TI  - Distributed Motion Tomography for Reconstruction of Flow Fields*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8048
EP  - 8054
AU  - D. Chang
AU  - F. Zhang
AU  - J. Sun
PY  - 2019
KW  - inverse problems
KW  - linear systems
KW  - multi-agent systems
KW  - nonlinear equations
KW  - nonlinear systems
KW  - optimisation
KW  - distributed nonlinear Kaczmarz method
KW  - constrained consensus problem
KW  - gyre flow field
KW  - distributed motion tomography
KW  - mobile sensing agents
KW  - inverse problem
KW  - distributed multiagent systems
KW  - flow field reconstruction
KW  - nonlinear system of equations
KW  - optimization approach
KW  - linear system of equations
KW  - Trajectory
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Optimization
KW  - Tomography
KW  - Estimation
KW  - Inverse problems
DO  - 10.1109/ICRA.2019.8793797
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper considers a group of mobile sensing agents in a flow field and presents a distributed method for motion tomography (MT) that estimates the underlying flow field. MT formulates an underdetermined nonlinear system of equations as an inverse problem. Inspired by the Kaczmarz method which is an optimization approach for solving a linear system of equations, our previous work developed a nonlinear Kaczmarz method that solves the system of equations associated with MT. Considering distributed multi-agent systems for MT, this paper extends the nonlinear Kaczmarz method into a distributed framework. The distributed nonlinear Kaczmarz method is developed by formulating a constrained consensus problem that belongs to a class of projected consensus algorithms. To study the convergence and consensus for the method, its linear case is analyzed first and then its nonlinear case is discussed. The nonlinear case of the method is further validated through simulations by estimating a gyre flow field using mobile sensor networks with different numbers of neighboring agents. Resulting estimated flow fields are compared with a flow field estimated by its centralized counterpart.
ER  - 

TY  - CONF
TI  - Who Takes What: Using RGB-D Camera and Inertial Sensor for Unmanned Monitor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8063
EP  - 8069
AU  - H. Kao
AU  - T. Ke
AU  - K. C. Lin
AU  - Y. Tseng
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - human computer interaction
KW  - image colour analysis
KW  - image matching
KW  - image sensors
KW  - Internet of Things
KW  - robot vision
KW  - video signal processing
KW  - WTW
KW  - IMU data
KW  - inertial sensor
KW  - RGB-d camera
KW  - unmanned monitor
KW  - IoT
KW  - human-environment interaction
KW  - Internet of Things
KW  - vision-based approaches
KW  - user-object matching
KW  - video recorded
KW  - Cameras
KW  - Skeleton
KW  - Feature extraction
KW  - Monitoring
KW  - Reliability
KW  - Trajectory
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793858
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Advanced Internet of Things (IoT) techniques have made human-environment interaction much easier. Existing solutions usually enable such interactions without knowing the identities of action performers. However, identifying users who are interacting with environments is a key to enable personalized service. To provide such add-on service, we propose WTW (who takes what), a system that identifies which user takes what object. Unlike traditional vision-based approaches, which are typically vulnerable to blockage, our WTW combines the feature information of three types of data, i.e., images, skeletons and IMU data, to enable reliable user-object matching and identification. By correlating the moving trajectory of a user monitored by inertial sensors with the movement of an object recorded in the video, our WTW reliably identifies a user and matches him/her with the object on action. Our prototype evaluation shows that WTW achieves a recognition rate of over 90% even in a crowd. The system is reliable even when users locate close by and take objects roughly at the same time.
ER  - 

TY  - CONF
TI  - Sound-Indicated Visual Object Detection for Robotic Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8070
EP  - 8076
AU  - F. Wang
AU  - D. Guo
AU  - H. Liu
AU  - J. Zhou
AU  - F. Sun
PY  - 2019
KW  - acoustic signal detection
KW  - audio signal processing
KW  - microphones
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - source separation
KW  - supervised learning
KW  - robotic exploration
KW  - microphones
KW  - cameras
KW  - physical world
KW  - visual modalities
KW  - audio modalities
KW  - robotic platforms
KW  - robotic sound-indicated visual object detection framework
KW  - two-stream weakly-supervised deep learning architecture
KW  - sounding object localization
KW  - AudioSet
KW  - Visualization
KW  - Object detection
KW  - Robots
KW  - Feature extraction
KW  - Task analysis
KW  - Semantics
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8794166
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots are usually equipped with microphones and cameras to perceive and understand the physical world. Though visual object detection technology has achieved great success, the detection in other modalities remains unsolved. In this paper, we establish a novel robotic sound-indicated visual object detection framework, and develop a two-stream weakly-supervised deep learning architecture to connect the visual and audio modalities for localizing the sounding object. A dataset is constructed from the AudioSet to validate the proposed method and some promising applications are demonstrated on robotic platforms.
ER  - 

TY  - CONF
TI  - HG-DAgger: Interactive Imitation Learning with Human Experts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8077
EP  - 8083
AU  - M. Kelly
AU  - C. Sidrane
AU  - K. Driggs-Campbell
AU  - M. J. Kochenderfer
PY  - 2019
KW  - learning (artificial intelligence)
KW  - HG-DAgger
KW  - interactive imitation learning
KW  - behavioral cloning
KW  - data mismatch
KW  - DAgger algorithm
KW  - sampling schemes
KW  - action labels
KW  - autonomous driving task
KW  - corrective actions
KW  - Safety
KW  - Cloning
KW  - Training
KW  - Measurement
KW  - Trajectory
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793698
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Imitation learning has proven to be useful for many real-world problems, but approaches such as behavioral cloning suffer from data mismatch and compounding error issues. One attempt to address these limitations is the DAgger algorithm, which uses the state distribution induced by the novice to sample corrective actions from the expert. Such sampling schemes, however, require the expert to provide action labels without being fully in control of the system. This can decrease safety and, when using humans as experts, is likely to degrade the quality of the collected labels due to perceived actuator lag. In this work, we propose HG-DAgger, a variant of DAgger that is more suitable for interactive imitation learning from human experts in real-world systems. In addition to training a novice policy, HG-DAgger also learns a safety threshold for a model-uncertainty-based risk metric that can be used to predict the performance of the fully trained novice in different regions of the state space. We evaluate our method on both a simulated and real-world autonomous driving task, and demonstrate improved performance over both DAgger and behavioral cloning.
ER  - 

TY  - CONF
TI  - Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-mounted IMU
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8084
EP  - 8091
AU  - B. Gromov
AU  - G. Abbate
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2019
KW  - gesture recognition
KW  - human-robot interaction
KW  - mobile robots
KW  - pointed locations
KW  - slow ground robots
KW  - proximity human-robot interaction
KW  - pointing gestures
KW  - wrist-mounted IMU
KW  - co-located humans
KW  - mobile robots
KW  - moving robot
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Drones
KW  - Trajectory
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794399
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a system for interaction between co-located humans and mobile robots, which uses pointing gestures sensed by a wrist-mounted IMU. The operator begins by pointing, for a short time, at a moving robot. The system thus simultaneously determines: that the operator wants to interact; the robot they want to interact with; and the relative pose among the two. Then, the system can reconstruct pointed locations in the robot's own reference frame, and provide real-time feedback about them so that the user can adapt to misalignments. We discuss the challenges to be solved to implement such a system and propose practical solutions, including variants for fast flying robots and slow ground robots. We report different experiments with real robots and untrained users, validating the individual components and the system as a whole.
ER  - 

TY  - CONF
TI  - Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8100
EP  - 8106
AU  - J. Laconte
AU  - S. Deschênes
AU  - M. Labussière
AU  - F. Pomerleau
PY  - 2019
KW  - Gaussian distribution
KW  - optical radar
KW  - sensor fusion
KW  - multiple sensors
KW  - Robosense RS-LiDAR-16
KW  - accurate maps
KW  - lidar measurement bias estimation
KW  - return waveform modelling
KW  - zero-mean Gaussian distribution
KW  - localisation drifts
KW  - Laser radar
KW  - Laser beams
KW  - Two dimensional displays
KW  - Sensors
KW  - Laser modes
KW  - Robots
KW  - Computational modeling
KW  - Bias Estimation
KW  - Sensor Error Modelling
KW  - Waveform Modelling
KW  - LIDAR
KW  - 3D Mapping
DO  - 10.1109/ICRA.2019.8793671
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a context of 3D mapping, it is very important to obtain accurate measurements from sensors. In particular, Light Detection And Ranging (LIDAR) measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles. We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.
ER  - 

TY  - CONF
TI  - An Extrinsic Calibration Tool for Radar, Camera and Lidar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8107
EP  - 8113
AU  - J. Domhof
AU  - J. F. P. Kooij
AU  - D. M. Gavrila
PY  - 2019
KW  - calibration
KW  - cameras
KW  - Gaussian noise
KW  - optical radar
KW  - pose estimation
KW  - probability
KW  - radar imaging
KW  - lidar
KW  - joint extrinsic calibration
KW  - sensing modalities
KW  - calibration target design
KW  - calibration procedure
KW  - multimodal measurements
KW  - optimization criterion
KW  - error terms
KW  - sensor pairs
KW  - calibration boards
KW  - calibration performance
KW  - camera errors
KW  - radar errors
KW  - extrinsic calibration tool
KW  - novel open-source tool
KW  - loop closure constraints
KW  - pose estimation
KW  - zero mean Gaussian noise
KW  - probabilistic model
KW  - Calibration
KW  - Cameras
KW  - Laser radar
KW  - Tools
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8794186
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel open-source tool for extrinsic calibration of radar, camera and lidar. Unlike currently available offerings, our tool facilitates joint extrinsic calibration of all three sensing modalities on multiple measurements. Furthermore, our calibration target design extends existing work to obtain simultaneous measurements for all these modalities. We study how various factors of the calibration procedure affect the outcome on real multi-modal measurements of the target. Three different configurations of the optimization criterion are considered, namely using error terms for a minimal amount of sensor pairs, or using terms for all sensor pairs with additional loop closure constraints, or by adding terms for structure estimation in a probabilistic model. The experiments further evaluate how the number of calibration boards affect calibration performance, and robustness against different levels of zero mean Gaussian noise. Our results show that all configurations achieve good results for lidar to camera errors and that fully connected pose estimation shows the best performance for lidar to radar errors when more than five board locations are used.
ER  - 

TY  - CONF
TI  - Compensation of measurement noise and bias in geometric attitude estimation*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8130
EP  - 8135
AU  - Y. Mitikiri
AU  - K. Mohseni
PY  - 2019
KW  - approximation theory
KW  - geometry
KW  - Kalman filters
KW  - nonlinear filters
KW  - measurement noise
KW  - geometric attitude estimation
KW  - geometry-based analytic attitude estimation
KW  - single reference vector
KW  - rigid body attitude estimation
KW  - residual error
KW  - geometric solution
KW  - rate measurements
KW  - methodical perturbation analysis
KW  - bias estimator
KW  - nonlinear problem
KW  - optimal Kalman gain
KW  - vector measurement
KW  - linearization approximations
KW  - sxtended Kalman filter
KW  - Angular velocity
KW  - Velocity measurement
KW  - Noise measurement
KW  - Measurement uncertainty
KW  - Q measurement
KW  - Estimation
KW  - Quaternions
DO  - 10.1109/ICRA.2019.8793504
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A geometry-based analytic attitude estimation using a rate measurement and measurement of a single reference vector has been recently proposed. Because rigid body attitude estimation is a fundamentally nonlinear problem, the geometry-based method does not contain errors consequent to linearization approximations. A critical source of residual error in the geometric solution is on account of the noise and bias in the vector and rate measurements. A methodical perturbation analysis of the attitude estimate is performed in this paper that reveals the effects of measurement noise and bias, and provides means to compensate for, or filter out, such errors. Application of the filter and compensation provides better attitude estimation than a standard Extended Kalman filter using an optimal Kalman gain. The geometric method is first verified in experiments and then simulation results are provided that validate the better performance of the geometric attitude and bias estimator.
ER  - 

TY  - CONF
TI  - Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8152
EP  - 8158
AU  - Z. Liang
AU  - M. Yang
AU  - L. Deng
AU  - C. Wang
AU  - B. Wang
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - graph theory
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - hierarchical depthwise graph convolutional neural network
KW  - 3D semantic segmentation
KW  - point clouds
KW  - point cloud semantic segmentation
KW  - depthwise convolution
KW  - pointwise convolution
KW  - local feature extraction
KW  - local features
KW  - global features
KW  - graph convolution
KW  - depthwise graph convolution
KW  - Three-dimensional displays
KW  - Convolution
KW  - Feature extraction
KW  - Semantics
KW  - Memory management
KW  - Shape
KW  - Convolutional neural networks
DO  - 10.1109/ICRA.2019.8794052
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a hierarchical depthwise graph convolutional neural network (HDGCN) for point cloud semantic segmentation. The main chanllenge for learning on point clouds is to capture local structures or relationships. Graph convolution has the strong ability to extract local shape information from neighbors. Inspired by depthwise convolution, we propose a depthwise graph convolution which requires less memory consumption compared with the previous graph convolution. While depthwise graph convolution aggregates features channel-wisely, pointwise convolution is used to learn features across different channels. A customized block called DGConv is specially designed for local feature extraction based on depthwise graph convolution and pointwise convolution. The DGConv block can extract features from points and transfer features to neighbors while being invariant to different point orders. HDGCN is constructed by a series of DGConv blocks using a hierarchical structure which can extract both local and global features of point clouds. Experiments show that HDGCN achieves the state-of-the-art performance in the indoor dataset S3DIS and the outdoor dataset Paris-Lille-3D.
ER  - 

TY  - CONF
TI  - CELLO-3D: Estimating the Covariance of ICP in the Real World
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8190
EP  - 8196
AU  - D. Landry
AU  - F. Pomerleau
AU  - P. Giguère
PY  - 2019
KW  - covariance analysis
KW  - covariance matrices
KW  - data analysis
KW  - image registration
KW  - iterative methods
KW  - state estimation
KW  - CELLO-3D
KW  - state estimation frameworks
KW  - closed-form covariance estimation algorithms
KW  - data-driven approach
KW  - uncertainty estimation
KW  - closed-form solutions
KW  - covariance estimation and learning through likelihood optimization framework
KW  - iterative closest point registrations
KW  - 3D datasets
KW  - ICP registrations
KW  - real 3D point clouds
KW  - Three-dimensional displays
KW  - Estimation
KW  - Linear programming
KW  - Uncertainty
KW  - Prediction algorithms
KW  - Measurement
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793516
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The fusion of Iterative Closest Point (ICP) registrations in existing state estimation frameworks relies on an accurate estimation of their uncertainty. In this paper, we study the estimation of this uncertainty in the form of a covariance. First, we scrutinize the limitations of existing closed-form covariance estimation algorithms over 3D datasets. Then, we set out to estimate the covariance of ICP registrations through a data-driven approach, with over 5100000 registrations on 1020 pairs from real 3D point clouds. We assess our solution upon a wide spectrum of environments, ranging from structured to unstructured and indoor to outdoor. The capacity of our algorithm to predict covariances is accurately assessed, as well as the usefulness of these estimations for uncertainty estimation over trajectories. The proposed method estimates covariances better than existing closed-form solutions, and makes predictions that are consistent with observed trajectories.
ER  - 

TY  - CONF
TI  - Low-latency Visual SLAM with Appearance-Enhanced Local Map Building
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8213
EP  - 8219
AU  - Y. Zhao
AU  - W. Ye
AU  - P. A. Vela
PY  - 2019
KW  - file organisation
KW  - image enhancement
KW  - image fusion
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - appearance-enhanced local map building
KW  - local map module
KW  - local map contents
KW  - co-visibility local map building
KW  - compact local map
KW  - downstream data association
KW  - mapped features
KW  - local map size
KW  - appearance-based local map building method
KW  - low-latency visual SLAM
KW  - pose estimation
KW  - multi-index hashing
KW  - online hash table selection algorithm
KW  - MIH
KW  - VO-VSLAM mean performance
KW  - Three-dimensional displays
KW  - Buildings
KW  - Optimization
KW  - Feature extraction
KW  - Indexing
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8794046
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A local map module is often implemented in modern VO/VSLAM systems to improve data association and pose estimation. Conventionally, the local map contents are determined by co-visibility. While co-visibility is cheap to establish, it utilizes the relatively-weak temporal prior (i.e. seen before, likely to be seen now), therefore admitting more features into the local map than necessary. This paper describes an enhancement to co-visibility local map building by incorporating a strong appearance prior, which leads to a more compact local map and latency reduction in downstream data association. The appearance prior collected from the current image influences the local map contents: only the map features visually similar to the current measurements are potentially useful for data association. To that end, mapped features are indexed and queried with Multi-index Hashing (MIH). An online hash table selection algorithm is developed to further reduce the query overhead of MIH and the local map size. The proposed appearance-based local map building method is integrated into a state-of-the-art VO/VSLAM system. When evaluated on two public benchmarks, the size of the local map, as well as the latency of real-time pose tracking in VO/VSLAM are significantly reduced. Meanwhile, the VO/VSLAM mean performance is preserved or improves.
ER  - 

TY  - CONF
TI  - Incremental Visual-Inertial 3D Mesh Generation with Structural Regularities
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8220
EP  - 8226
AU  - A. Rosinol
AU  - T. Sattler
AU  - M. Pollefeys
AU  - L. Carlone
PY  - 2019
KW  - computational complexity
KW  - computational geometry
KW  - graph theory
KW  - mesh generation
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - state estimation
KW  - structural regularities
KW  - point cloud representation
KW  - tightly couple mesh regularization
KW  - VIO optimization
KW  - per-frame approach
KW  - visual-inertial odometry algorithms
KW  - visual-inertial 3D mesh generation
KW  - decouple state estimation
KW  - factor-graph formulation
KW  - computational complexity
KW  - memory usage
KW  - localization accuracy
KW  - Three-dimensional displays
KW  - Optimization
KW  - Two dimensional displays
KW  - State estimation
KW  - Cameras
KW  - Histograms
KW  - Mesh generation
KW  - SLAM
KW  - Vision-Based Navigation
KW  - Sensor Fusion
DO  - 10.1109/ICRA.2019.8794456
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual-Inertial Odometry (VIO) algorithms typically rely on a point cloud representation of the scene that does not model the topology of the environment. A 3D mesh instead offers a richer, yet lightweight, model. Nevertheless, building a 3D mesh out of the sparse and noisy 3D landmarks triangulated by a VIO algorithm often results in a mesh that does not fit the real scene. In order to regularize the mesh, previous approaches decouple state estimation from the 3D mesh regularization step, and either limit the 3D mesh to the current frame [1], [2] or let the mesh grow indefinitely [3], [4]. We propose instead to tightly couple mesh regularization and state estimation by detecting and enforcing structural regularities in a novel factor-graph formulation. We also propose to incrementally build the mesh by restricting its extent to the time-horizon of the VIO optimization; the resulting 3D mesh covers a larger portion of the scene than a per-frame approach while its memory usage and computational complexity remain bounded. We show that our approach successfully regularizes the mesh, while improving localization accuracy, when structural regularities are present, and remains operational in scenes without regularities.
ER  - 

TY  - CONF
TI  - Unsupervised Out-of-context Action Understanding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8227
EP  - 8233
AU  - H. Kataoka
AU  - Y. Satoh
PY  - 2019
KW  - convolutional neural nets
KW  - image sequences
KW  - motion estimation
KW  - unsupervised learning
KW  - human action
KW  - video sequence
KW  - unsupervised label
KW  - synthetic databases
KW  - unsupervised learning method
KW  - O2CA ground truth
KW  - SURREAL-O2CA
KW  - unsupervised out-of-context action understanding
KW  - Databases
KW  - Unsupervised learning
KW  - Sports
KW  - Context modeling
KW  - Legged locomotion
KW  - Video sequences
DO  - 10.1109/ICRA.2019.8793709
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents an unsupervised out-of-context action (O2CA) paradigm that is based on facilitating understanding by separately presenting both human action and context within a video sequence. As a means of generating an unsupervised label, we comprehensively evaluate responses from action-based (ActionNet) and context-based (ContextNet) convolutional neural networks (CNNs). Additionally, we have created three synthetic databases based on the human action (UCF101, HMDB51) and motion capture (mocap) (SURREAL) datasets. We then conducted experimental comparisons between our approach and conventional approaches. We also compared our unsupervised learning method with supervised learning using an O2CA ground truth given by synthetic data. From the results obtained, we achieved a 96.8 score on Synth-UCF, a 96.8 score on Synth-HMDB, and 89.0 on SURREAL-O2CA with F-score.
ER  - 

TY  - CONF
TI  - Air-to-Ground Surveillance Using Predictive Pursuit
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8234
EP  - 8240
AU  - S. Dutta
AU  - C. Ekenna
PY  - 2019
KW  - autonomous aerial vehicles
KW  - Markov processes
KW  - mobile robots
KW  - object tracking
KW  - path planning
KW  - surveillance
KW  - target tracking
KW  - air-to-ground surveillance
KW  - predictive pursuit
KW  - Markov decision process
KW  - tracking time
KW  - location detection accuracy
KW  - air-to-ground robot surveillance scenario
KW  - surveillance algorithms
KW  - camera
KW  - unmanned ground vehicle
KW  - UGV
KW  - observed path
KW  - pursuit algorithm
KW  - target localization
KW  - high predictive accuracy
KW  - Planning
KW  - Surveillance
KW  - Markov processes
KW  - Prediction algorithms
KW  - Trajectory
KW  - Measurement
KW  - Drones
DO  - 10.1109/ICRA.2019.8794073
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a probabilistic prediction model with a novel variant of the Markov decision process to improve tracking time and location detection accuracy in an air-to-ground robot surveillance scenario. While most surveillance algorithms focus mainly on controls of an unmanned aerial vehicle (UAV) and camera for faster tracking of an unmanned ground vehicle (UGV), this paper proposes a way of minimizing detection and tracking time by applying a prediction model to the first observed path taken by the UGV. We present a pursuit algorithm that addresses the problem of target (UGV) localization by combining prediction of used planning algorithm by the target, and application of the same planning algorithm to predict future trajectories. Our results show a high predictive accuracy based on a final position attained by the target and the location predicted by our model.
ER  - 

TY  - CONF
TI  - Online Planning for Target Object Search in Clutter under Partial Observability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8241
EP  - 8247
AU  - Y. Xiao
AU  - S. Katt
AU  - A. t. Pas
AU  - S. Chen
AU  - C. Amato
PY  - 2019
KW  - manipulators
KW  - Markov processes
KW  - Monte Carlo methods
KW  - path planning
KW  - PA-POMCP algorithm
KW  - action partially observable Monte-Carlo planning
KW  - object movements
KW  - manipulation actions
KW  - partially observable Markov decision process
KW  - target object search task
KW  - partial observability
KW  - online planning
KW  - Search problems
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Uncertainty
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793494
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The problem of finding and grasping a target object in a cluttered, uncertain environment, target object search, is a common and important problem in robotics. One key challenge is the uncertainty of locating and recognizing each object in a cluttered environment due to noisy perception and occlusions. Furthermore, the uncertainty in localization makes manipulation difficult and uncertain. To cope with these challenges, we formulate the target object search task as a partially observable Markov decision process (POMDP), enabling the robot to reason about perceptual and manipulation uncertainty while searching. To further address the manipulation difficulty, we propose Parameterized Action Partially Observable Monte-Carlo Planning (PA-POMCP), an algorithm that evaluates manipulation actions by taking into account the effect of the robot's current belief on the success of the action execution. In addition, a novel run-time initial belief generator and a state value estimator are introduced in this paper to facilitate the PA-POMCP algorithm. Our experiments show that our methods solve the target object search task in settings where simpler methods either take more object movements or fail.
ER  - 

TY  - CONF
TI  - Learning to Drive in a Day
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8248
EP  - 8254
AU  - A. Kendall
AU  - J. Hawke
AU  - D. Janz
AU  - P. Mazur
AU  - D. Reda
AU  - J. Allen
AU  - V. Lam
AU  - A. Bewley
AU  - A. Shah
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - robot vision
KW  - autonomous driving tasks
KW  - single monocular image
KW  - safety driver
KW  - model-free deep reinforcement learning algorithm
KW  - lane following
KW  - on-vehicle
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Markov processes
KW  - Global Positioning System
KW  - Sensors
KW  - Training
DO  - 10.1109/ICRA.2019.8793742
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.
ER  - 

TY  - CONF
TI  - Generating Adversarial Driving Scenarios in High-Fidelity Simulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8271
EP  - 8277
AU  - Y. Abeysirigoonawardena
AU  - F. Shkurti
AU  - G. Dudek
PY  - 2019
KW  - automobile industry
KW  - Bayes methods
KW  - computer vision
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - program testing
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - transportation
KW  - self-driving policy
KW  - simulated pedestrians
KW  - self-driving behavior
KW  - high-fidelity simulators
KW  - public roads
KW  - software tests
KW  - self-driving software
KW  - adversarial self-driving scenarios
KW  - self-driving vehicles
KW  - transportation systems
KW  - simulated driving scenarios
KW  - driving scenario generation
KW  - self-driving car industry
KW  - Bayesian optimization
KW  - vision-based imitation learning
KW  - Optimization
KW  - Accidents
KW  - Rendering (computer graphics)
KW  - Bayes methods
KW  - Reinforcement learning
KW  - Roads
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793740
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on high-fidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.
ER  - 

TY  - CONF
TI  - Data-Driven Contact Clustering for Robot Simulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8278
EP  - 8284
AU  - M. Kim
AU  - J. Yoon
AU  - D. Son
AU  - D. Lee
PY  - 2019
KW  - control engineering computing
KW  - force sensors
KW  - learning (artificial intelligence)
KW  - multilayer perceptrons
KW  - optimisation
KW  - pattern clustering
KW  - robots
KW  - data-driven contact clustering
KW  - rigid-body robot simulation
KW  - multilayer perceptron network
KW  - constraint-based optimization contact solver
KW  - contact simulation
KW  - data-driven learning-based contact clustering
KW  - force sensors
KW  - torque sensors
KW  - MLP network
KW  - Force
KW  - Numerical models
KW  - Robot sensing systems
KW  - Data models
KW  - Numerical stability
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793938
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel data-driven learning-based contact clustering (i.e., of contact points and contact normals) framework for rigid-body robot simulation, with its accuracy established/verified by real experimental data. We first construct an experimental robotic setup with force/torque (F/T) sensors to collect real contact motion/force data. We then design a multilayer perceptron (MLP) network for the contact clustering based on the full motion and force/torque information of the contacts. We also adopt the constraint-based optimization contact solver to facilitate the learning of our MLP network during the training. Our proposed data-driven/learning-based contact clustering framework is then verified against the experimental setup, compared with other techniques/simulators and shown to significantly (or meaningfully) enhance the accuracy of contact simulation as compared to them.
ER  - 

TY  - CONF
TI  - Pavilion: Bridging Photo-Realism and Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8285
EP  - 8290
AU  - F. Jiang
AU  - Q. Hao
PY  - 2019
KW  - control engineering computing
KW  - image sequences
KW  - mobile robots
KW  - sensor fusion
KW  - virtual reality
KW  - Pavilion
KW  - bridging photo-realism
KW  - robotics
KW  - sensor fusion
KW  - robot control
KW  - novel open-source simulation system
KW  - robot perception
KW  - kinematic control
KW  - ROS
KW  - shader-based method
KW  - optical flow ground-truth data
KW  - Gazebo-compatible real-time simulation system
KW  - control algorithms
KW  - simulation environment
KW  - state-of-the-art simulators
KW  - simulation accuracy
KW  - simulation environments
KW  - unreal engine
KW  - simulation description format robot models
KW  - robot operating system
KW  - Engines
KW  - Robot sensing systems
KW  - Data models
KW  - Real-time systems
KW  - Pipelines
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8794235
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simulation environments play a centric role in the research of sensor fusion and robot control. This paper presents Pavilion, a novel open-source simulation system, for robot perception and kinematic control based on the Unreal Engine and the Robot Operating System (ROS). The novelty of this work includes threefold: (1) developing a shader-based method to generate optical flow ground-truth data with the Unreal Engine, (2) developing a toolset to remove binary incompatibility between ROS and the Unreal Engine to enable real-time interaction, and (3) developing a method to directly import Simulation Description Format (SDF) robot models into the Unreal Engine at runtime. Finally, a Gazebo-compatible real-time simulation system is developed to enable training and evaluation of a large number of sensor fusion, planning, decision and control algorithms. The system can be implemented on both Linux and macOS, with the latest version of ROS. Various experiments have been performed to validate the superior performance of the proposed simulation environment over other state-of-the-art simulators in terms of number of modalities, simulation accuracy, latency and degree of integration difficulty.
ER  - 

TY  - CONF
TI  - A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8291
EP  - 8297
AU  - M. Kalia
AU  - N. Navab
AU  - T. Salcudean
PY  - 2019
KW  - augmented reality
KW  - kinematics
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - Stereo-No CDE
KW  - CDE technique
KW  - forward kinematics joint encoder data
KW  - surgical field
KW  - virtual surgical instrument method
KW  - AR technique
KW  - blue-red color spectrum
KW  - tissue surface
KW  - tumor
KW  - medical abnormality
KW  - surgical robotics
KW  - color depth encoding
KW  - real-time interactive augmented reality depth estimation
KW  - Tools
KW  - Robots
KW  - Tumors
KW  - Image color analysis
KW  - Cameras
KW  - Instruments
KW  - Biomedical imaging
DO  - 10.1109/ICRA.2019.8793610
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Augmented reality (AR) is a promising technology where the surgeon can see the medical abnormality in the context of the patient. It makes the anatomy of interest visible to the surgeon which otherwise is not visible. It can result in better surgical precision and therefore, potentially better surgical outcomes and faster recovery times. Despite these benefits, the current AR systems suffer from two major challenges; first, incorrect depth perception and, second, the lack of suitable evaluation systems. Therefore, in the current paper we addressed both of these problems. We proposed a color depth encoding (CDE) technique to estimate the distance between the tumor and the tissue surface using a surgical instrument. We mapped the distance between the tumor and the tissue surface to the blue-red color spectrum. For evaluation and interaction with our AR technique, we propose to use a virtual surgical instrument method using the CAD model of the instrument. The users were asked to reach the judged distance in the surgical field using the virtual tool. Realistic tool movement was simulated by collecting the forward kinematics joint encoder data. The results showed significant improvement in depth estimation, time for task completion and confidence, using our CDE technique with and without stereo versus other two cases, that are, Stereo-No CDE and No Stereo-No CDE.
ER  - 

TY  - CONF
TI  - Force-based Heterogeneous Traffic Simulation for Autonomous Vehicle Testing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8298
EP  - 8304
AU  - Q. Chao
AU  - X. Jin
AU  - H. Huang
AU  - S. Foong
AU  - L. Yu
AU  - S. Yeung
PY  - 2019
KW  - computer simulation
KW  - control engineering computing
KW  - driver information systems
KW  - mobile robots
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - traffic engineering computing
KW  - self-driving tests
KW  - force-based concept
KW  - heterogenous traffic simulation
KW  - realistic urban environment
KW  - personal mobility devices
KW  - pedestrians
KW  - autonomous vehicles
KW  - traffic control
KW  - high-fidelity driving simulator
KW  - autonomous vehicle testing
KW  - force-based heterogeneous traffic simulation
KW  - Force
KW  - Autonomous vehicles
KW  - Roads
KW  - Acceleration
KW  - Bicycles
KW  - Testing
KW  - Urban areas
DO  - 10.1109/ICRA.2019.8794430
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent failures in real-world self-driving tests have suggested a paradigm shift from directly learning in real-world roads to building a high-fidelity driving simulator as an alternative, effective, and safe tool to handle intricate traffic environments in urban areas. To date, traffic simulation can construct virtual urban environments with various weather conditions, day and night, and traffic control for autonomous vehicle testing. However, mutual interactions between autonomous vehicles and pedestrians are rarely modeled in existing simulators. Besides vehicles and pedestrians, the usage of personal mobility devices is increasing in congested cities as an alternative to the traditional transport system. A simulator that considers all potential road-users in a realistic urban environment is urgently desired. In this work, we propose a novel, extensible, and microscopic method to build heterogenous traffic simulation using the force-based concept. This force-based approach can accurately replicate the sophisticated behaviors of various road users and their interactions through a simple and unified way. Furthermore, we validate our approach through simulation experiments and comparisons to the popular simulators currently used for research and development of autonomous vehicles.
ER  - 

TY  - CONF
TI  - Dual Refinement Network for Single-Shot Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8305
EP  - 8310
AU  - X. Chen
AU  - X. Yang
AU  - S. Kong
AU  - Z. Wu
AU  - J. Yu
PY  - 2019
KW  - convolutional neural nets
KW  - object detection
KW  - single-stage detector
KW  - dual refinement network
KW  - anchor refinement
KW  - single-shot object detection
KW  - object detection methods
KW  - two-stage detectors
KW  - anchor-offset detection
KW  - PASCAL VOC
KW  - ImageNet VID datasets
KW  - Feature extraction
KW  - Detectors
KW  - Head
KW  - Proposals
KW  - Object detection
KW  - Fuses
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8793816
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object detection methods fall into two categories, i.e., two-stage and single-stage detectors. The former is characterized by high detection accuracy while the latter usually has a considerable inference speed. Hence, it is imperative to fuse their merits for a better accuracy vs. speed trade-off. To this end, we propose a dual refinement network (DRN) to boost the performance of the single-stage detector. Inheriting from the advantages of two-stage approaches (i.e., two-step regression and accurate features for detection), anchor refinement and feature offset refinement are conducted in a novel anchor-offset detection, where the detection head is comprised of deformable convolutions. Moreover, to leverage contextual information for describing objects, we design a multi-deformable head, in which multiple detection paths with different receptive field sizes devote themselves to detecting objects. Extensive experiments on PASCAL VOC and ImageNet VID datasets are conducted, and we achieve a state-of-the-art detection performance in terms of both accuracy and inference speed.
ER  - 

TY  - CONF
TI  - Distant Vehicle Detection Using Radar and Vision
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8311
EP  - 8317
AU  - S. Chadwick
AU  - W. Maddern
AU  - P. Newman
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - convolutional neural nets
KW  - image capture
KW  - object detection
KW  - road vehicle radar
KW  - distant vehicle detection
KW  - autonomous vehicles
KW  - convolutional neural networks
KW  - image-based object detectors
KW  - radar data
KW  - vision
KW  - KITTI
KW  - cameras
KW  - focal lengths
KW  - Cameras
KW  - Radar imaging
KW  - Detectors
KW  - Object detection
KW  - Doppler radar
KW  - Training
DO  - 10.1109/ICRA.2019.8794312
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For autonomous vehicles to be able to operate successfully they need to be aware of other vehicles with sufficient time to make safe, stable plans. Given the possible closing speeds between two vehicles, this necessitates the ability to accurately detect distant vehicles. Many current image-based object detectors using convolutional neural networks exhibit excellent performance on existing datasets such as KITTI. However, the performance of these networks falls when detecting small (distant) objects. We demonstrate that incorporating radar data can boost performance in these difficult situations. We also introduce an efficient automated method for training data generation using cameras of different focal lengths.
ER  - 

TY  - CONF
TI  - Customizing Object Detectors for Indoor Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8318
EP  - 8324
AU  - S. Alabachi
AU  - G. Sukthankar
AU  - R. Sukthankar
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - helicopters
KW  - neurocontrollers
KW  - object detection
KW  - robot vision
KW  - indoor robots
KW  - object detection models
KW  - convolutional neural networks
KW  - large-scale labeled datasets
KW  - training data
KW  - DUNet
KW  - dense upscaled network
KW  - Detectors
KW  - Object detection
KW  - Robots
KW  - Feature extraction
KW  - Labeling
KW  - Computer architecture
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793551
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object detection models based on convolutional neural networks (CNNs) demonstrate impressive performance when trained on large-scale labeled datasets. While a generic object detector trained on such a dataset performs adequately in applications where the input data is similar to user photographs, the detector performs poorly on small objects, particularly ones with limited training data or imaged from uncommon viewpoints. Also, a specific room will have many objects that are missed by standard object detectors, frustrating a robot that continually operates in the same indoor environment.This paper describes a system for rapidly creating customized object detectors. Data is collected from a quadcopter that is teleoperated with an interactive interface. Once an object is selected, the quadcopter autonomously photographs the object from multiple viewpoints to collect data to train DUNet (Dense Upscaled Network), our proposed model for learning customized object detectors from scratch given limited data. Our experiments compare the performance of learning models from scratch with DUNet vs. fine tuning existing state of the art object detectors, both on our indoor robotics domain and on standard datasets.
ER  - 

TY  - CONF
TI  - Semi Supervised Deep Quick Instance Detection and Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8325
EP  - 8331
AU  - A. Kumar
AU  - L. Behera
PY  - 2019
KW  - convolutional neural nets
KW  - data acquisition
KW  - image segmentation
KW  - object detection
KW  - supervised learning
KW  - class-agnostic object detection
KW  - semisupervised labeling
KW  - occlusion aware clutter synthesis
KW  - online learning
KW  - semisupervised deep quick instance detection
KW  - semisupervised deep quick learning framework
KW  - data acquisition
KW  - convolutional neural network
KW  - pixelwise semantic segmentation
KW  - Image segmentation
KW  - Task analysis
KW  - Object segmentation
KW  - Clutter
KW  - Semantics
KW  - Labeling
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793595
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd rd, 4th and 5 th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC'17 where novel features such as instance detection and online learning has been added.
ER  - 

TY  - CONF
TI  - Mixed Frame-/Event-Driven Fast Pedestrian Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8332
EP  - 8338
AU  - Z. Jiang
AU  - P. Xia
AU  - K. Huang
AU  - W. Stechele
AU  - G. Chen
AU  - Z. Bing
AU  - A. Knoll
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - convolutional neural nets
KW  - image fusion
KW  - image sensors
KW  - pedestrians
KW  - traffic engineering computing
KW  - conventional frame-based camera
KW  - bad light condition
KW  - high-speed motion
KW  - gray-scale frames
KW  - traffic monitoring scenario
KW  - YOLOv3 models
KW  - YOLO-tiny models
KW  - confidence map fusion method
KW  - CNN-based detection results
KW  - DAVIS channels
KW  - intelligent transportation system
KW  - mixed frame-event-driven fast pedestrian detection
KW  - ITS
KW  - frame-based camera
KW  - dynamic and active pixel sensor
KW  - asynchronous low-latency temporal contrast events
KW  - convolutional neural networks
KW  - TUM campus
KW  - Voltage control
KW  - Vision sensors
KW  - Feature extraction
KW  - Neuromorphics
KW  - Cameras
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793924
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pedestrian detection has attracted enormous research attention in the field of Intelligent Transportation System (ITS) due to that pedestrians are the most vulnerable traffic participants. So far, almost all pedestrian detection solutions are based on the conventional frame-based camera. However, they cannot perform very well in scenarios with bad light condition and high-speed motion. In this work, a Dynamic and Active Pixel Sensor (DAVIS), whose two channels concurrently output conventional gray-scale frames and asynchronous low-latency temporal contrast events of light intensity, was first used to detect pedestrians in a traffic monitoring scenario. Data from two camera channels were fed into Convolutional Neural Networks (CNNs) including three YOLOv3 models and three YOLO-tiny models to gather bounding boxes of pedestrians with respective confidence map. Furthermore, a confidence map fusion method combining the CNN-based detection results from both DAVIS channels was proposed to obtain higher accuracy. The experiments were conducted on a custom dataset collected on TUM campus. Benefiting from the high speed, low latency and wide dynamic range of the event channel, our method achieved higher frame rate and lower latency than those only using a conventional camera. Additionally, it reached higher average precision by using the fusion approach.
ER  - 

TY  - CONF
TI  - Real-Time Vehicle Detection from Short-range Aerial Image with Compressed MobileNet
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8339
EP  - 8345
AU  - Y. He
AU  - Z. Pan
AU  - L. Li
AU  - Y. Shan
AU  - D. Cao
AU  - L. Chen
PY  - 2019
KW  - feature extraction
KW  - mobile computing
KW  - motorcycles
KW  - neural nets
KW  - object detection
KW  - road vehicles
KW  - traffic engineering computing
KW  - MobileNet family network engineering
KW  - compressed MobileNet
KW  - feature map downsampling stage
KW  - feature map plateau stage
KW  - reduced inference time
KW  - vehicle categories
KW  - crowded bicycles
KW  - high detection accuracy
KW  - real-time detection speed
KW  - real time vehicle detection
KW  - object interference
KW  - short-range aerial image
KW  - crowded motorcycles
KW  - truck
KW  - car
KW  - bus
KW  - Convolution
KW  - Neural networks
KW  - Proposals
KW  - Vehicle detection
KW  - Object detection
KW  - Computational modeling
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793673
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Vehicle detection from short-range aerial image faces challenges including vehicle blocking, irrelevant object interference, motion blurring, color variation etc., leading to the difficulty to achieve high detection accuracy and real-time detection speed. In this paper, benefiting from the recent development in MobileNet family network engineering, we propose a compressed MobileNet which is not only internally resistant to the above listed challenges but also gains the best detection accuracy/speed tradeoff when comparing with the original MobileNet. In a nutshell, we reduce the bottleneck architecture number during the feature map downsampling stage but add more bottlenecks during the feature map plateau stage, neither extra FLOPs nor parameters are thus involved but reduced inference time and better accuracy are expected. We conduct experiment on our collected 5-k short-range aerial images, containing six vehicle categories: truck, car, bus, bicycle, motorcycle, crowded bicycles and crowded motorcycles. Our proposed compressed MobileNet achieves 110 FPS (GPU), 31 FPS (CPU) and 15 FPS (mobile phone), 1.2 times faster and 2% more accurate (mAP) than the original MobileNet.
ER  - 

TY  - CONF
TI  - Guaranteed Active Constraints Enforcement on Point Cloud-approximated Regions for Surgical Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8346
EP  - 8352
AU  - T. Kastritsi
AU  - D. Papageorgiou
AU  - I. Sarantopoulos
AU  - S. Stavridis
AU  - Z. Doulgeri
AU  - G. A. Rovithakis
PY  - 2019
KW  - end effectors
KW  - force control
KW  - haptic interfaces
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - path planning
KW  - surgery
KW  - point cloud-approximated regions
KW  - surgical applications
KW  - human-robot interaction controller
KW  - pHRI
KW  - sensitive tissues
KW  - restricted region
KW  - constraint enforcement
KW  - interaction force
KW  - constraint satisfaction
KW  - KUKA LWR4+ robot
KW  - 3D point-cloud
KW  - artificial potential fields
KW  - active constraint enforcement
KW  - kinesthetic guidance
KW  - KUKA LWR4+ robot end-effector
KW  - KUKA virtual slave
KW  - Tools
KW  - Force
KW  - Three-dimensional displays
KW  - Surgery
KW  - End effectors
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8793953
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, a passive physical human-robot interaction (pHRI) controller is proposed to intraoperatively ensure that sensitive tissues will not be damaged by the robot's tool. The proposed scheme uses the point cloud of the restricted region's surface as constraint definition and Artificial Potential fields for constraint enforcement. The controller is proven to be passive with respect to the interaction force and to guarantee constraint satisfaction in all cases. The proposed methodology is experimentally validated by the kinesthetic guidance of a KUKA LWR4+ robot's end-effector driving a virtual slave KUKA in the vicinity of a 3D point-cloud of a kidney and its adjacent vessels.
ER  - 

TY  - CONF
TI  - Designing an Accurate and Customizable Epidural Anesthesia Haptic Simulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8353
EP  - 8359
AU  - T. sénac
AU  - A. Lelevé
AU  - R. Moreau
AU  - L. Krahenbuhl
AU  - F. Sigwalt
AU  - C. Bauert
AU  - Q. Rouby
PY  - 2019
KW  - computer simulation
KW  - haptic interfaces
KW  - medical computing
KW  - pneumatic cylinder
KW  - electrical haptic interface
KW  - epidural anesthesia haptic simulator
KW  - medical procedure
KW  - Needles
KW  - Haptic interfaces
KW  - Force
KW  - Anesthesia
KW  - Prototypes
KW  - Bones
KW  - Training
DO  - 10.1109/ICRA.2019.8794199
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Epidural anesthesia, despite being a relatively common medical procedure, remains quite demanding in terms of skills as it is mostly blind and thus heavily reliant on the haptic sensations. Although some training support solutions exist, anesthetists consider them mostly inefficient or impractical. A few attempts at creating a simulator for this particular procedure exist but each one lacks one of the important requirements of the procedure. This article introduces a haptic simulator featuring a more complete and realistic simulation of the procedure than we could observe in existing simulators. The simulator is composed of a generic electrical haptic interface coupled with a pneumatic cylinder.
ER  - 

TY  - CONF
TI  - Sleeve Pneumatic Artificial Muscles for Antagonistically Actuated Joints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8360
EP  - 8366
AU  - M. F. Cullinan
AU  - C. McGinn
AU  - K. Kelly
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - muscle
KW  - orthotics
KW  - pneumatic actuators
KW  - PAM types
KW  - sleeve pneumatic artificial muscles
KW  - paper sleeve PAMs
KW  - popular muscle configuration
KW  - joint rotation
KW  - traditional PAMs
KW  - joint configuration
KW  - antagonistically actuated joints
KW  - Muscles
KW  - Force
KW  - Torque
KW  - Actuators
KW  - Fitting
KW  - Pulleys
KW  - Bladder
DO  - 10.1109/ICRA.2019.8794193
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pneumatic artificial muscles (PAMs) have been researched for applications in powered exoskeletons, orthosis and robotics. Their high force to mass ratio, low cost and inherent compliance are particularly advantageous for systems requiring physical interaction with humans.Sleeve PAMs, which introduce an internal structure to the actuator, offer improved force capacity, contraction ratio, efficiency and operating bandwidth. In this paper sleeve PAMs are applied to a popular muscle configuration; that of a joint operated antagonistically by two muscles. It is shown that the sleeve PAM can increases the range of joint rotation by 14% or load capacity by over 50% of that of a comparable joint actuated with traditional PAMs, depending on the joint configuration. The stiffness of joints actuated with both PAM types is also studied, particularly the case of closed system operation (mass of air in the PAMs is constant), where the reduced volume of the sleeve PAM significantly increases the observed stiffness. Finally energy consumption is considered, showing substantial savings in the case of joints actuated with sleeve PAMs.
ER  - 

TY  - CONF
TI  - Sensing Shear Forces During Food Manipulation: Resolving the Trade-Off Between Range and Sensitivity
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8367
EP  - 8373
AU  - H. Song
AU  - T. Bhattacharjee
AU  - S. S. Srinivasa
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - force sensors
KW  - grippers
KW  - haptic interfaces
KW  - sensors
KW  - shear strength
KW  - tactile sensors
KW  - bite acquisition success
KW  - shear forces
KW  - food manipulation
KW  - autonomous assistive feeding systems
KW  - deformable food items
KW  - force feedback
KW  - shear sensing fingertip tactile sensors
KW  - sensing range
KW  - bite acquisition successes
KW  - robotic gripper
KW  - varying weights
KW  - compliance
KW  - Tactile sensors
KW  - Sensitivity
KW  - Force
KW  - Calibration
KW  - Force measurement
DO  - 10.1109/ICRA.2019.8794350
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous assistive feeding systems need to acquire deformable food items of varying physical characteristics to be able to feed users. However, bite acquisition of these deformable food items is challenging without force feedback of appropriate range and sensitivity. We developed custom solutions using two widely-used shear sensing fingertip tactile sensors and calibrated them to the range of forces needed for manipulating food items. We compared their performance with traditional force/torque sensors and showed the trade-off between the range and the sensitivity of the fingertip tactile sensors in detecting potential bite acquisition successes for food items with widely varying weights and compliance. We then developed a control policy, using which a robotic gripper equipped with the fingertip tactile sensors can autonomously regulate the sensing range and the sensitivity to be able to skewer food items of different compliance and detect their bite acquisition success attempts.
ER  - 

TY  - CONF
TI  - Benchmarking Resilience of Artificial Hands
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8374
EP  - 8380
AU  - F. Negrello
AU  - M. Garabini
AU  - G. Grioli
AU  - N. Tsagarakis
AU  - A. Bicchi
AU  - M. G. Catalano
PY  - 2019
KW  - actuators
KW  - dexterous manipulators
KW  - end effectors
KW  - human-robot interaction
KW  - impact testing
KW  - prosthetics
KW  - artificial hands
KW  - harsh interactions
KW  - irregular physical interactions
KW  - disaster scenario
KW  - standardized test
KW  - hand resilience
KW  - impact tests
KW  - standard test
KW  - robot hands
KW  - resilience evaluation framework
KW  - Resilience
KW  - Soft robotics
KW  - Robustness
KW  - Strain
KW  - Standards
KW  - Prosthetics
DO  - 10.1109/ICRA.2019.8793793
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The deployment of robotics in real-world scenarios, which may involve harsh and irregular physical interactions with the environment, such as those when robots operating in a disaster scenario, or the interactions that prosthetic devices may experience, demands hardware, which is physically resilient. The end-effectors, as the main media of interaction, are probably the parts at the highest risk. The capability of robotic hands to survive severe impacts is thus a necessity for the effective deployment of reliable robotic solutions in real-world tasks. Although, this robustness capability has been noted and discussed in the robotics community for long time, the literature does not provide a systematic study nor there is any proposal of standardized test or metric to evaluate hand resilience. In this work, inspired by the works of Charpy and Izod for the systematic definition of resilience and toughness of materials through impact tests, we consider extending the standard test to robot hands. We introduce a resilience evaluation framework, including a precisely defined experimental set-up and test procedure. As an example of application of the procedure, we apply it to experimentally characterize two robot hands, with a similar conceptual architecture but different size and material. From these tests we obtain several insights, including the observation that the dominant factor in hand resilience is their compliance and actuation principle, and that the use, under certain design conditions, of lightweight materials, such as plastic instead of aluminum, may not necessarily reduce the mechanical strength of the overall system.
ER  - 

TY  - CONF
TI  - CHiMP: A Contact based Hilbert Map Planner
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8381
EP  - 8387
AU  - C. Uhde
AU  - E. Dean-Leon
AU  - G. Cheng
PY  - 2019
KW  - gradient methods
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stochastic processes
KW  - tactile sensors
KW  - multimodal robot skin
KW  - contact-based robot system
KW  - skin compliant control
KW  - tactile-based explorative behavior
KW  - CHiMP
KW  - skin-based sparse contact data
KW  - contact-based 3D path planning approach
KW  - 6 DOF robot arm
KW  - stochastic functional gradient path planner
KW  - contact based Hilbert map planner
KW  - manipulators
KW  - Trajectory
KW  - Skin
KW  - Planning
KW  - Kernel
KW  - Robot sensing systems
KW  - Cost function
DO  - 10.1109/ICRA.2019.8794013
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents a new contact-based 3D path planning approach for manipulators using robot skin. We make use of the Stochastic Functional Gradient Path Planner, extending it to the 3D case, and assess its usefulness in combination with multi-modal robot skin. Our proposed algorithm is verified on a 6 DOF robot arm that has been covered with multi-modal robot skin. The experimental platform is combined with a skin based compliant controller, making the robot inherently reactive. We implement different state-of-the-art planners within our contact-based robot system to compare their performance under the same conditions. In this way, all the planners use the same skin compliant control during evaluation. Furthermore, we extend the stochastic planner with tactile-based explorative behavior to improve its performance, especially for unknown environments. We show that CHiMP is able to outperform state of the art algorithms when working with skin-based sparse contact data.
ER  - 

TY  - CONF
TI  - A Novel Reconfigurable Revolute Joint with Adjustable Stiffness
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8388
EP  - 8393
AU  - Z. Li
AU  - W. Chen
AU  - S. Bai
PY  - 2019
KW  - elasticity
KW  - mechanical engineering computing
KW  - springs (mechanical)
KW  - adjustable stiffness
KW  - JASR
KW  - zero-length base link four-bar linkage
KW  - hard-spring behaviour
KW  - light-weight structure
KW  - design parameters
KW  - reconfigurable revolute joint
KW  - Springs
KW  - Rubber
KW  - Pins
KW  - Shafts
KW  - Couplings
KW  - Robots
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793906
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a novel revolute joint of adjustable stiffness with reconfigurability (JASR) is presented. The JASR is designed with zero-length base link four-bar linkage, and allows adjusting its stiffness to achieve soft- and hard-spring behaviour. The new joint has a compact and light-weight structure and can be integrated in robot and transmissions for different applications. In the paper, mathematical models are developed for the JASR, with which influences of design parameters on stiffness performance are analyzed. A prototype of JASR is constructed and preliminary test results demonstrate the compliance properties of the new joint.
ER  - 

TY  - CONF
TI  - A novel force sensor with zero stiffness at contact transition based on optical line generation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8394
EP  - 8400
AU  - J. Begey
AU  - M. Nierenberger
AU  - P. Pfeiffer
AU  - S. Lecler
AU  - P. Renaud
PY  - 2019
KW  - fibre optic sensors
KW  - force sensors
KW  - medical robotics
KW  - zero stiffness
KW  - contact transition
KW  - optical line generation
KW  - robotic system
KW  - stiff environment
KW  - passive compliance
KW  - robot control
KW  - optical measurement process
KW  - compliant sensor body
KW  - force sensor
KW  - medical robotization
KW  - low off-axis sensitivity
KW  - additive manufacturing
KW  - Springs
KW  - Optical variables measurement
KW  - Optical sensors
KW  - Laser beams
KW  - Robot sensing systems
KW  - Force
KW  - Force sensors
DO  - 10.1109/ICRA.2019.8794183
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotization of medical acts often requires the evaluation of contacts between a robotic system and a patient, for safety or efficiency reasons. When contact occurs with a stiff environment, instabilities and vibrations can appear and a passive compliance is therefore needed. In this paper, we propose to embed compliance in a force sensor and to develop a novel force sensor with large compliance, i.e. a zero stiffness at contact transition to ease robot control. To get at the same time a satisfying measurement range and low off-axis sensitivity, an optical measurement process based on an optical line generated thanks to additive manufacturing is exploited. A compliant sensor body allowing the desired stiffness profile is presented and the specific optical measurement technique is developed. Finally, a prototype of the proposed force sensor is evaluated experimentally.
ER  - 

TY  - CONF
TI  - Hydraulically-actuated compliant revolute joint for medical robotic systems based on multimaterial additive manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8401
EP  - 8407
AU  - A. Pfeil
AU  - M. Siegfarth
AU  - F. Geiskopf
AU  - T. P. Pusch
AU  - L. Barbé
AU  - P. Renaud
PY  - 2019
KW  - biomedical MRI
KW  - compliance control
KW  - design engineering
KW  - hydraulic actuators
KW  - manipulator kinematics
KW  - medical image processing
KW  - medical robotics
KW  - polymers
KW  - rapid prototyping (industrial)
KW  - telerobotics
KW  - three-dimensional printing
KW  - hydraulic cylinder
KW  - hydraulically-actuated compliant revolute joint
KW  - medical robotic systems
KW  - multimaterial additive manufacturing
KW  - hydraulic energy
KW  - seal design
KW  - miniature hydraulic cylinders
KW  - rack-and-pinion mechanism
KW  - magnetic resonance imaging
KW  - Gears
KW  - Hydraulic systems
KW  - Robots
KW  - Standards
KW  - Shape
KW  - Force
KW  - Three-dimensional printing
DO  - 10.1109/ICRA.2019.8793666
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, an active compliant revolute joint actuated by hydraulic energy is developed. The joint is made of polymer for integration in medical robotic systems, even in a challenging environment such as Magnetic Resonance Imaging (MRI). The use of multimaterial additive manufacturing allows us to develop two original aspects. First, a new seal design is proposed to build miniature hydraulic cylinders embedded in the active joint, with low level of friction. Second, a rack-and-pinion mechanism is being integrated to a compliant revolute joint to obtain a high level of compactness. Design and experimental assessment of the hydraulic cylinder and the compliant joint with embedded rack-and-pinion are presented, as well as an illustration in the context of needle manipulation with passive teleoperation.
ER  - 

TY  - CONF
TI  - Model-Based On-line Estimation of Time-Varying Nonlinear Joint Stiffness on an e-Series Universal Robots Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8408
EP  - 8414
AU  - E. Madsen
AU  - O. S. Rosenlund
AU  - D. Brandt
AU  - X. Zhang
PY  - 2019
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - feedback
KW  - feedforward
KW  - flexible manipulators
KW  - gears
KW  - least squares approximations
KW  - manipulator dynamics
KW  - position control
KW  - time-varying systems
KW  - model-based feedforward controllers
KW  - e-series manipulators
KW  - UR5e manipulator
KW  - transmission deformation
KW  - elastic torques
KW  - parametric model
KW  - recursive least squares strategy
KW  - robot joint stiffness
KW  - feedback controllers
KW  - robot joints
KW  - gear meshing
KW  - driven link
KW  - drive actuator
KW  - dynamic time-varying displacement
KW  - lightweight strain-wave type transmissions
KW  - elasticity
KW  - e-series universal robots manipulator
KW  - time-varying nonlinear joint stiffness
KW  - model-based on-line estimation
KW  - Torque
KW  - Robot sensing systems
KW  - Friction
KW  - Mathematical model
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2019.8793935
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flexibility commonly exists in the joints of many industrial robots due to the elasticity of the lightweight strain-wave type transmissions being used. This leads to a dynamic time-varying displacement between the position of the drive actuator and that of the driven link. Furthermore, the joint flexibility changes with time due to the material slowly being worn off at the gear meshing. Knowing the stiffness of the robot joints is of great value, e.g. in the design of new model-based feedforward and feedback controllers, and for predictive maintenance in the case of gearing unit failure. In this paper, we address on-line estimation of robot joint stiffness using a recursive least squares strategy based on a parametric model taking into account the elastic torques' nonlinear dependency on transmission deformation. Robustness is achieved in the presence of measurement noise and in poor excitation conditions. The method can be easily extended to general classes of serial-link multi-degree-of-freedom robots. The estimation technique uses only feedback signals that are readily available on Universal Robots' e-Series manipulators. Experiments on the new UR5e manipulator demonstrate the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - A Rolling Flexure Mechanism for Progressive Stiffness Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8415
EP  - 8421
AU  - J. Malzahn
AU  - E. Barrett
AU  - N. Tsagarakis
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - finite element analysis
KW  - mobile robots
KW  - prototypes
KW  - springs (mechanical)
KW  - torque control
KW  - progressive stiffness Actuators
KW  - robot performance
KW  - 2D components
KW  - physical interaction performance
KW  - passive rolling flexure design principle
KW  - linear series elastic actuators
KW  - torque-deflection characteristics
KW  - finite element analysis
KW  - laboratory prototypes
KW  - Force
KW  - Actuators
KW  - Springs
KW  - Torque
KW  - Stress
KW  - Robots
KW  - Torque control
DO  - 10.1109/ICRA.2019.8794004
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Linear Series Elastic Actuators exhibit a restricted design space. This inevitably leads to design trade-offs translating into robot performance limitations. These prevent robots from eventually reaching human comparable soft but also powerful physical interaction performance.This work presents a novel fixed passive rolling flexure design principle enabling the realization of a wide range of progressive torque-deflection characteristics. The proposed principle displays low hysteresis and can be manufactured in single 2D components. The paper derives the analytic foundation for the rolling flexure principle and is supported by numerical finite element analysis. The theory is validated by experimental results obtained on two laboratory prototypes.
ER  - 

TY  - CONF
TI  - Locomotion Dynamics of a Miniature Wave-Like Robot, Modeling and Experiments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8422
EP  - 8428
AU  - L. Drory
AU  - D. Zarrouk
PY  - 2019
KW  - actuators
KW  - force control
KW  - friction
KW  - legged locomotion
KW  - motion control
KW  - pipes
KW  - robot dynamics
KW  - locomotion dynamics
KW  - dynamic locomotion analysis
KW  - wave robot
KW  - propulsion force
KW  - locomotion models
KW  - advance time ratio
KW  - friction forces
KW  - miniature model
KW  - miniature wave-like robot
KW  - minimally actuated wave-like robot kinematics
KW  - crawling environments
KW  - flexible tube-like shapes
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794015
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a recent study, we developed a minimally actuated wave-like robot and analyzed its kinematics. In this paper, we present the dynamic locomotion analysis of a miniature version of this wave robot. We examine different crawling environments, determine under which conditions it can advance, and evaluate its propulsion force. We first developed two locomotion models to characterize the cases where the robot is crawling between two straight surfaces or over a single flat surface. We specified the conditions in which the robot will advance and the advance time ratio as a function of the friction forces and weight of the robot. Next, we developed highly flexible tube-like shapes that we molded from silicone rubber to experimentally test the forces acting on the robot inside these tubes. Finally, we designed a miniature model of the robot and experimentally validated its crawling conditions (see video).
ER  - 

TY  - CONF
TI  - Fabric Soft Poly-Limbs for Physical Assistance of Daily Living Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8429
EP  - 8435
AU  - P. H. Nguyen
AU  - I. B. Imran Mohd
AU  - C. Sparks
AU  - F. L. Arellano
AU  - W. Zhang
AU  - P. Polygerinos
PY  - 2019
KW  - actuators
KW  - artificial limbs
KW  - fabrics
KW  - finite element analysis
KW  - manipulators
KW  - soft-waist belt
KW  - physical assistance
KW  - daily living tasks
KW  - additional limb
KW  - mobile manipulation assistance
KW  - soft actuators
KW  - high-strength inflatable fabrics
KW  - systematic design rules
KW  - highly compliant soft robotic limbs
KW  - fabric based components behavior
KW  - finite-element method models
KW  - FEM models
KW  - fSPL articulation capabilities
KW  - fabric soft arm
KW  - fabric soft poly-limbs
KW  - Actuators
KW  - Fabrics
KW  - Payloads
KW  - Manipulators
KW  - Heating systems
KW  - Force
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794294
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design and development of a highly articulated, continuum, wearable, fabric-based Soft Poly-Limb (fSPL). This fabric soft arm acts as an additional limb that provides the wearer with mobile manipulation assistance through the use of soft actuators made with high-strength inflatable fabrics. In this work, a set of systematic design rules is presented for the creation of highly compliant soft robotic limbs through an understanding of the fabric based components behavior as a function of input pressure. These design rules are generated by investigating a range of parameters through computational finite-element method (FEM) models focusing on the fSPL's articulation capabilities and payload capacity in 3D space. The theoretical motion and payload outputs of the fSPL and its components are experimentally validated as well as additional evaluations verify its capability to safely carry loads 10.1x its body weight, by wrapping around the object. Finally, we demonstrate how the fully collapsible fSPL can comfortably be stored in a soft-waist belt and interact with the wearer through spatial mobility and preliminary pick-and-place control experiments.
ER  - 

TY  - CONF
TI  - Design of a Soft Ankle-Foot Orthosis Exosuit for Foot Drop Assistance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8436
EP  - 8442
AU  - C. M. Thalman
AU  - J. Hsu
AU  - L. Snyder
AU  - P. Polygerinos
PY  - 2019
KW  - actuators
KW  - elastic constants
KW  - electromyography
KW  - finite element analysis
KW  - gait analysis
KW  - kinematics
KW  - medical control systems
KW  - orthotics
KW  - soft ankle-foot orthosis exosuit
KW  - foot drop assistance
KW  - natural gait restoration
KW  - soft actuators
KW  - thermally-bonded nylon
KW  - swing phase
KW  - gait cycle
KW  - ankle joint proprioception
KW  - variable stiffness soft actuator
KW  - computational model
KW  - fabric actuators
KW  - dorsiflexion actuator
KW  - soft AFO
KW  - ankle dorsiflexion
KW  - finite element analysis
KW  - electromyography studies
KW  - Actuators
KW  - Foot
KW  - Fabrics
KW  - Force
KW  - Fabrication
KW  - Muscles
DO  - 10.1109/ICRA.2019.8794005
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design of a soft ankle-foot orthosis (AFO) exosuit to aid natural gait restoration for individuals suffering from foot drop. The sock-like AFO is comprised of soft actuators made from fabric-based, thermally-bonded nylon and designed to be worn over the users shoes. The system assists dorsiflexion during swing phase of the gait cycle utilizing a contracting soft actuator, and provides ankle joint proprioception during stance with a variable stiffness soft actuator. A computational model is developed using finite element analysis to optimize the performance characteristics of the fabric actuators prior to fabrication, maximize contraction, and minimize overall volume. The dorsiflexion actuator is able to achieve a linear tensile force of 197 N at 200 kPa. The variable stiffness actuator generates up to 1. 2 Nm of torque at the same pressure. The computational model and soft AFO are experimentally validated and with a healthy participant through kinematic and electromyography studies. When active the AFO is capable of reducing by 13.3% the activity of the muscle responsible for ankle dorsiflexion during the swing phase.
ER  - 

TY  - CONF
TI  - A Depth Camera-Based Soft Fingertip Device for Contact Region Estimation and Perception-Action Coupling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8443
EP  - 8449
AU  - I. Huang
AU  - J. Liu
AU  - R. Bajcsy
PY  - 2019
KW  - cameras
KW  - deformation
KW  - estimation theory
KW  - robots
KW  - tactile sensors
KW  - depth camera-based soft fingertip device
KW  - contact region estimation
KW  - perception-action coupling
KW  - robotic applications
KW  - unconstrained environments
KW  - dynamic environments
KW  - soft robotic technologies
KW  - soft tactile sensor design
KW  - human fingertip
KW  - perception mechanism
KW  - compliance-modulating capabilities
KW  - estimation sensitivity
KW  - internal fluid states
KW  - force-deformation characteristics
KW  - Robot sensing systems
KW  - Cameras
KW  - Three-dimensional displays
KW  - Force
KW  - Estimation
KW  - Image reconstruction
DO  - 10.1109/ICRA.2019.8793612
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As the demand for robotic applications in unconstrained and dynamic environments rises, so does the benefit of advancing the state of the art in soft robotic technologies. However, the complex capabilities of soft robots elicited by their high-dimensional, non-linear characteristics simultaneously yield difficult challenges in control and sensing. Moreover, embedding tactile sensing capabilities in soft materials is often expensive and difficult to fabricate. In recent years, however, the invention of small-scale depth-sensing cameras introduced a promising channel for soft tactile sensor design. In this work, we propose a novel soft device inspired by the human fingertip that not only utilizes a small depth camera as the perception mechanism, but also possesses compliance-modulating capabilities. We demonstrate its ability to accurately estimate contact regions upon interaction with an external obstacle, and show that the estimation sensitivity can be modulated via internal fluid states. In addition, we determine an empirical model of the device's force-deformation characteristics under simplifying assumptions, and validate its performance with real-time force matching control experiments.
ER  - 

TY  - CONF
TI  - A Pipe-Climbing Soft Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8450
EP  - 8456
AU  - G. Singh
AU  - S. Patiballa
AU  - X. Zhang
AU  - G. Krishnan
PY  - 2019
KW  - bending
KW  - design engineering
KW  - elastomers
KW  - mobile robots
KW  - motion control
KW  - pipes
KW  - pneumatic actuators
KW  - modular design
KW  - flexible actuators
KW  - pipe-climbing soft robot
KW  - bio-inspired soft pneumatic robot
KW  - cylinder
KW  - soft pneumatic actuators
KW  - FREEs
KW  - deformation behavior
KW  - bending actuators
KW  - fiber reinforced elastomeric enclosure
KW  - forward motion
KW  - Actuators
KW  - Pneumatic systems
KW  - Prototypes
KW  - Soft robotics
KW  - Strain
KW  - Torso
KW  - Soft robotics
KW  - Crawling Robot
KW  - Artificial muscles
KW  - McKibben muscles
DO  - 10.1109/ICRA.2019.8793815
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design and testing of a bio-inspired soft pneumatic robot that can achieve locomotion along the outside of a cylinder. The robot uses soft pneumatic actuators called FREEs (Fiber Reinforced Elastomeric Enclosure), which can have a wide range of deformation behavior upon pressurization. The robot being soft and compliant can grasp and move along cylinders of varying dimensions. Two different types of FREEs are used in the robot namely (a) extending FREEs and (b) bending FREEs. These actuators are arranged in such a way that the bending actuators are used to grip the pipe while the extending actuators generate forward motion as well as bending for direction control. The modular design of the robot provides simplicity and ease of maintenance. The entire robot is made of flexible actuators and can withstand external impact with minimal to no damage. The maximum speed achieved for horizontal motion is 4.2 mm/s and for vertical motion is 2.1 mm/s.
ER  - 

TY  - CONF
TI  - Generation of Stealth Walking Gait on Low-friction Road Surface
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8464
EP  - 8469
AU  - F. Asano
PY  - 2019
KW  - friction
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - wheels
KW  - AMCC
KW  - horizontal ground reaction force
KW  - low-friction road surface
KW  - planar underactuated rimless wheel
KW  - stealth walking gait
KW  - adaptive walking gaits
KW  - underactuated walkers
KW  - control torques
KW  - frictionless road surface
KW  - angular momentum constraint control
KW  - stance-leg motion
KW  - linearized motion equation
KW  - Legged locomotion
KW  - Foot
KW  - Mathematical model
KW  - Wheels
KW  - Roads
KW  - Trajectory
KW  - Force
DO  - 10.1109/ICRA.2019.8794409
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The author has investigated the method of stealth walking for generating adaptive walking gaits of underactuated walkers without having the control torques at the feet. This approach is also effective for achieving careful walking on the frictionless road surface by applying angular momentum constraint control (AMCC); the generated gait completes in one step while maintaining the horizontal ground reaction force to zero. The result is mathematically thorough, but is not realistic because any uncertainties in the system cannot be permitted. This paper then discusses more realistic slidingresistant situation: stealth walking on the low-friction road surface. First, we introduce a model of a planar underactuated rimless wheel, and describe the equation of motion and the control input for AMCC. Second, we specify the linearized equation of motion with AMCC, and derive the analytical solution of the stance-leg motion which is used as a desired trajectory for the nonlinear model. Furthermore, we discuss the optimality of the upper-body control during the double-limb support phase from the sliding-resistant characteristics point of view through mathematical and numerical investigations.
ER  - 

TY  - CONF
TI  - Support Surface Estimation for Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8470
EP  - 8476
AU  - T. Homberger
AU  - L. Wellhausen
AU  - P. Fankhauser
AU  - M. Hutter
PY  - 2019
KW  - Gaussian processes
KW  - legged locomotion
KW  - path planning
KW  - regression analysis
KW  - robot dynamics
KW  - terrain mapping
KW  - legged robots
KW  - legged systems
KW  - rugged outdoor environments
KW  - terrain geometry
KW  - foothold planning
KW  - safe locomotion
KW  - penetrable terrain
KW  - depth sensors
KW  - haptic information
KW  - foot contact closure locations
KW  - exteroceptive sensing
KW  - dense support surface estimate
KW  - Gaussian process regression
KW  - support surface estimation procedure
KW  - penetrable surface layer
KW  - discrete penetration depth measurements
KW  - continuous support surface estimate
KW  - partial exteroceptive information
KW  - terrain topography
KW  - quadrupedal robot ANYmal
KW  - Vegetation mapping
KW  - Surface topography
KW  - Kernel
KW  - Estimation
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793646
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The high agility of legged systems allows them to operate in rugged outdoor environments. In these situations, knowledge about the terrain geometry is key for foothold planning to enable safe locomotion. However, on penetrable or highly compliant terrain (e.g. grass) the visibility of the supporting ground surface is obstructed, i.e. it cannot directly be perceived by depth sensors. We present a method to estimate the underlying terrain topography by fusing haptic information about foot contact closure locations with exteroceptive sensing. To obtain a dense support surface estimate from sparsely sampled footholds we apply Gaussian process regression. Exteroceptive information is integrated into the support surface estimation procedure by estimating the height of the penetrable surface layer from discrete penetration depth measurements at the footholds. The method is designed such that it provides a continuous support surface estimate even if there is only partial exteroceptive information available due to shadowing effects. Field experiments with the quadrupedal robot ANYmal show how the robot can smoothly and safely navigate in dense vegetation.
ER  - 

TY  - CONF
TI  - ALMA - Articulated Locomotion and Manipulation for a Torque-Controllable Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8477
EP  - 8483
AU  - C. D. Bellicoso
AU  - K. Krämer
AU  - M. Stäuble
AU  - D. Sako
AU  - F. Jenelten
AU  - M. Bjelonic
AU  - M. Hutter
PY  - 2019
KW  - end effectors
KW  - human-robot interaction
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - torque control
KW  - unstructured environments
KW  - ALMA
KW  - torque-controlled quadrupedal robot
KW  - dynamic locomotion
KW  - online motion planning framework
KW  - whole-body controller
KW  - hierarchical optimization algorithm
KW  - operational space end-effector control
KW  - human-robot collaboration
KW  - torso posture optimization
KW  - torque-controllable robot
KW  - robotic mobile manipulation
KW  - six degrees of freedom robotic arm
KW  - articulated locomotion and manipulation
KW  - reactive human-robot collaboration
KW  - Legged locomotion
KW  - Task analysis
KW  - Grippers
KW  - Robot kinematics
KW  - Tracking
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794273
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The task of robotic mobile manipulation poses several scientific challenges that need to be addressed to execute complex manipulation tasks in unstructured environments, in which collaboration with humans might be required. Therefore, we present ALMA, a motion planning and control framework for a torque-controlled quadrupedal robot equipped with a six degrees of freedom robotic arm capable of performing dynamic locomotion while executing manipulation tasks. The online motion planning framework, together with a whole-body controller based on a hierarchical optimization algorithm, enables the system to walk, trot and pace while executing operational space end-effector control, reactive human-robot collaboration and torso posture optimization to increase the arm's workspace. The torque control of the whole system enables the implementation of compliant behavior, allowing a user to safely interact with the robot. We verify our framework on the real robot by performing tasks such as opening a door and carrying a payload together with a human.
ER  - 

TY  - CONF
TI  - Real-time Model Predictive Control for Versatile Dynamic Motions in Quadrupedal Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8484
EP  - 8490
AU  - Y. Ding
AU  - A. Pandala
AU  - H. Park
PY  - 2019
KW  - legged locomotion
KW  - motion control
KW  - predictive control
KW  - quadratic programming
KW  - robot dynamics
KW  - versatile dynamic motions
KW  - quadrupedal robot
KW  - single rigid body dynamics
KW  - rotation matrices
KW  - quaternions
KW  - unwinding phenomenon
KW  - MPC control law
KW  - periodic quadrupedal gaits
KW  - model predictive control framework
KW  - quadratic program
KW  - QP
KW  - Euler angles
KW  - acrobatic maneuvers
KW  - Legged locomotion
KW  - Dynamics
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793669
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new Model Predictive Control (MPC) framework for controlling various dynamic movements of a quadrupedal robot. System dynamics are represented by linearizing single rigid body dynamics in three-dimensional (3D) space. Our formulation linearizes rotation matrices without resorting to parameterizations like Euler angles and quaternions, avoiding issues of singularity and unwinding phenomenon, respectively. With a carefully chosen configuration error function, the MPC control law is transcribed into a Quadratic Program (QP) which can be solved efficiently in realtime. Our formulation can stabilize a wide range of periodic quadrupedal gaits and acrobatic maneuvers. We show various simulation as well as experimental results to validate our control strategy. Experiments prove the application of this framework with a custom QP solver could reach execution rates of 160 Hz on embedded platforms.
ER  - 

TY  - CONF
TI  - Scanning the Internet for ROS: A View of Security in Robotics Research
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8514
EP  - 8521
AU  - N. DeMarinis
AU  - S. Tellex
AU  - V. P. Kemerlis
AU  - G. Konidaris
AU  - R. Fonseca
PY  - 2019
KW  - control engineering computing
KW  - image sensors
KW  - Internet
KW  - IP networks
KW  - operating systems (computers)
KW  - robot programming
KW  - robot vision
KW  - ROS
KW  - public Internet
KW  - image sensor information
KW  - publicly-accessible platforms
KW  - robotics research
KW  - Robot Operating System
KW  - robotic sensors
KW  - robotic actuators
KW  - IPv4 address space
KW  - American university
KW  - Robot sensing systems
KW  - Security
KW  - Actuators
KW  - Internet
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794451
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Security is particularly important in robotics, as robots can directly perceive and affect the physical world. We describe the results of a scan of the entire IPv4 address space of the Internet for instances of the Robot Operating System (ROS), a widely used robotics software platform. We identified a number of hosts supporting ROS that are exposed to the public Internet, thereby allowing anyone to access robotic sensors and actuators. As a proof of concept, and with the consent of the relevant researchers, we were able to read image sensor information from and actuate a physical robot present in a research lab in an American university. This paper gives an overview of our findings, including our methodology, the geographic distribution of publicly-accessible platforms, the sorts of sensor and actuator data that is available, and the different kinds of robots and sensors that our scan uncovered. Additionally, we offer recommendations on best practices to mitigate these security issues in the future.
ER  - 

TY  - CONF
TI  - Risk Averse Robust Adversarial Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8522
EP  - 8528
AU  - X. Pan
AU  - D. Seita
AU  - Y. Gao
AU  - J. Canny
PY  - 2019
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - probability
KW  - risk averse robust adversarial reinforcement learning
KW  - deep reinforcement learning
KW  - computer games
KW  - robotic control
KW  - automotive accidents
KW  - optimization
KW  - probability
KW  - RARARL
KW  - self-driving vehicle controller
KW  - Reinforcement learning
KW  - Training
KW  - Mathematical model
KW  - Robustness
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Accidents
DO  - 10.1109/ICRA.2019.8794293
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep reinforcement learning has recently made significant progress in solving computer games and robotic control tasks. A known problem, though, is that policies overfit to the training environment and may not avoid rare, catastrophic events such as automotive accidents. A classical technique for improving the robustness of reinforcement learning algorithms is to train on a set of randomized environments, but this approach only guards against common situations. Recently, robust adversarial reinforcement learning (RARL) was developed, which allows efficient applications of random and systematic perturbations by a trained adversary. A limitation of RARL is that only the expected control objective is optimized; there is no explicit modeling or optimization of risk. Thus the agents do not consider the probability of catastrophic events (i.e., those inducing abnormally large negative reward), except through their effect on the expected objective. In this paper we introduce risk-averse robust adversarial reinforcement learning (RARARL), using a risk-averse protagonist and a risk-seeking adversary. We test our approach on a self-driving vehicle controller. We use an ensemble of policy networks to model risk as the variance of value functions. We show through experiments that a risk-averse agent is better equipped to handle a risk-seeking adversary, and experiences substantially fewer crashes compared to agents trained without an adversary. Supplementary materials are available at https://sites.google.com/view/rararl.
ER  - 

TY  - CONF
TI  - Bounded Collision Force by the Sobolev Norm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8529
EP  - 8535
AU  - K. Haninger
AU  - D. Surdilovic
PY  - 2019
KW  - compliance control
KW  - control system synthesis
KW  - end effectors
KW  - feedback
KW  - force control
KW  - H2 control
KW  - manipulator dynamics
KW  - mechanical contact
KW  - springs (mechanical)
KW  - Sobolev norm
KW  - robot inertia
KW  - analytical models
KW  - maximum collision force
KW  - simplified mass-spring robot model
KW  - end-effector compliance
KW  - system norm
KW  - maximum force
KW  - general dynamic system
KW  - feedback control
KW  - control theory
KW  - controller synthesis
KW  - admittance-controlled robot
KW  - linear flexible-joint robot
KW  - bounded collision force
KW  - robot contact
KW  - safety risks
KW  - collision force minimisation
KW  - Force
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Measurement
KW  - End effectors
KW  - Admittance
DO  - 10.1109/ICRA.2019.8793711
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot making contact with an environment or human presents potential safety risks, including excessive collision force. While experiments on the effect of robot inertia, relative velocity, and interface stiffness on collision are in literature, analytical models for maximum collision force are limited to a simplified mass-spring robot model. This simplified model limits the analysis of control (force/torque, impedance, or admittance) or compliant robots (joint and end-effector compliance). Here, the Sobolev norm is adapted to be a system norm, giving rigorous bounds on the maximum force on a stiffness element in a general dynamic system, allowing the study of collision with more accurate models and feedback control. The Sobolev norm can be found through the H2 norm of a transformed system, allowing efficient computation, connection with existing control theory, and controller synthesis to minimize collision force. The Sobolev norm is validated, first experimentally with an admittance-controlled robot, then in simulation with a linear flexible-joint robot. It is then used to investigate the impact of control, joint flexibility and end-effector compliance on collision, and a trade-off between collision performance and environmental estimation uncertainty is shown.
ER  - 

TY  - CONF
TI  - Liability, Ethics, and Culture-Aware Behavior Specification using Rulebooks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8536
EP  - 8542
AU  - A. Censi
AU  - K. Slutsky
AU  - T. Wongpiromsarn
AU  - D. Yershov
AU  - S. Pendleton
AU  - J. Fu
AU  - E. Frazzoli
PY  - 2019
KW  - automobiles
KW  - cultural aspects
KW  - ethical aspects
KW  - formal specification
KW  - intelligent transportation systems
KW  - mobile robots
KW  - multi-agent systems
KW  - culture-aware behavior specification
KW  - autonomous agents
KW  - self-driving domain
KW  - liability-aware behavior specification
KW  - ethics-aware behavior specification
KW  - self-driving car behavior
KW  - Aptiv company
KW  - nuTonomy
KW  - violation metric
KW  - rulebook semantics
KW  - Automobiles
KW  - Planning
KW  - Autonomous automobiles
KW  - Ethics
KW  - Measurement
KW  - Trajectory
KW  - Semantics
DO  - 10.1109/ICRA.2019.8794364
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The behavior of self-driving cars must be compatible with an enormous set of conflicting and ambiguous objectives, from law, from ethics, from the local culture, and so on. This paper describes a new way to conveniently define the desired behavior for autonomous agents, which we use on the self-driving cars developed at nuTonomy, an Aptiv company. We define a “rulebook” as a pre-ordered set of “rules”, each akin to a violation metric on the possible outcomes (“realizations”). The rules are partially ordered by priority. The semantics of a rulebook imposes a pre-order on the set of realizations. We study the compositional properties of the rulebooks, and we derive which operations we can allow on the rulebooks to preserve previously-introduced constraints. While we demonstrate the application of these techniques in the self-driving domain, the methods are domain-independent.
ER  - 

TY  - CONF
TI  - Early Failure Detection of Deep End-to-End Control Policy by Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8543
EP  - 8549
AU  - K. Lee
AU  - K. Saigol
AU  - E. A. Theodorou
PY  - 2019
KW  - belief networks
KW  - control engineering computing
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - observability
KW  - predictive control
KW  - learned control policies
KW  - reinforcement learning
KW  - end-to-end imitation
KW  - predictive uncertainty
KW  - model predictive controller
KW  - fully-observable vision-based partially-observable systems
KW  - deep convolutional Bayesian neural networks
KW  - deep end-to-end control policy
KW  - Bayesian networks
KW  - mean value
KW  - corrective action
KW  - partial state observability
KW  - Uncertainty
KW  - Bayes methods
KW  - Task analysis
KW  - Neural networks
KW  - Safety
KW  - Training
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8794189
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose the use of Bayesian networks, which provide both a mean value and an uncertainty estimate as output, to enhance the safety of learned control policies under circumstances in which a test-time input differs significantly from the training set. Our algorithm combines reinforcement learning and end-to-end imitation learning to simultaneously learn a control policy as well as a threshold over the predictive uncertainty of the learned model, with no hand-tuning required. Corrective action, such as a return of control to the model predictive controller or human expert, is taken before the failure of tasks, when the uncertainty threshold is exceeded. We validate our method on fully-observable and vision-based partially-observable systems using cart-pole and autonomous driving simulations using deep convolutional Bayesian neural networks. We demonstrate that our method is robust to uncertainty resulting from varying system dynamics as well as from partial state observability.
ER  - 

TY  - CONF
TI  - Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8550
EP  - 8556
AU  - J. F. Fisac
AU  - N. F. Lugovoy
AU  - V. Rubies-Royo
AU  - S. Ghosh
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - control engineering computing
KW  - dynamic programming
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimal control
KW  - partial differential equations
KW  - dynamic programming equation
KW  - contraction mapping
KW  - Hamilton-Jacobi safety analysis
KW  - control-theoretic safety analysis
KW  - optimal safety policy
KW  - quantitative safety analysis
KW  - reinforcement learning techniques
KW  - time-discounted modification
KW  - optimal control problems
KW  - robust optimal control theory
KW  - autonomous robotic systems
KW  - policy gradient techniques
KW  - value learning
KW  - Safety
KW  - Automation
KW  - Reinforcement learning
KW  - Robots
KW  - Optimal control
KW  - Jacobian matrices
KW  - Reachability analysis
DO  - 10.1109/ICRA.2019.8794107
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Safety analysis is a necessary component in the design and deployment of autonomous robotic systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their application has in practice been restricted to problems with an additive payoff over time, unsuitable for reasoning about safety. In recent work, we introduced a time-discounted modification of the problem of maximizing the minimum payoff over time, central to safety analysis, through a modified dynamic programming equation that induces a contraction mapping. Here, we show how a similar contraction mapping can render reinforcement learning techniques amenable to quantitative safety analysis as tools to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We validate the correctness of our formulation by comparing safety results computed through Q-learning to analytic and numerical solutions, and demonstrate its scalability by learning safe sets and control policies for simulated systems of up to 18 state dimensions using value learning and policy gradient techniques.
ER  - 

TY  - CONF
TI  - Trajectory Planning for a Tractor with Multiple Trailers in Extremely Narrow Environments: A Unified Approach*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8557
EP  - 8562
AU  - B. Li
AU  - Y. Zhang
AU  - T. Acarma
AU  - Q. Kong
AU  - Y. Zhang
PY  - 2019
KW  - agricultural machinery
KW  - optimal control
KW  - path planning
KW  - sampling methods
KW  - search problems
KW  - vehicle dynamics
KW  - trajectory planning
KW  - multiple trailers
KW  - extremely narrow environments
KW  - unified approach
KW  - vehicle kinematics
KW  - underactuated constraints
KW  - nonholonomic constraints
KW  - prevalent sampling-based
KW  - rigid-body vehicles
KW  - tractor-trailer vehicle cases
KW  - generic n-trailer cases
KW  - tiny environments
KW  - adaptively homotopic warm-starting approach
KW  - numerical solution process
KW  - extremely tiny scenarios
KW  - online planning opportunities
KW  - Trajectory
KW  - Planning
KW  - Agricultural machinery
KW  - Kinematics
KW  - Optimal control
KW  - Wheels
KW  - Dispersion
DO  - 10.1109/ICRA.2019.8793955
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Trajectory planning for a tractor-trailer vehicle is challenging because the vehicle kinematics consists of underactuated and nonholonomic constraints that are highly coupled. Prevalent sampling-based or search-based planners suitable for rigid-body vehicles are not capable of handling the tractor-trailer vehicle cases. This work aims to deal with generic n-trailer cases in the tiny environments. To this end, an optimal control problem is formulated, which is beneficial in being accurate, straightforward, and unified. An adaptively homotopic warm-starting approach is proposed to facilitate the numerical solution process of the formulated optimal control problem. Compared with the existing sequential warm starting strategies, our proposal can adaptively define the subproblems with the purpose of making the gaps between adjacent subproblems “pleasant” for the solver. Unification and efficiency of the proposed adaptively homotopic warm-starting approach have been investigated in several extremely tiny scenarios. Our planner finds solutions that other existing planners cannot. Online planning opportunities are briefly discussed as well.
ER  - 

TY  - CONF
TI  - A Friction-Based Kinematic Model for Skid-Steer Wheeled Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8563
EP  - 8569
AU  - S. Rabiee
AU  - J. Biswas
PY  - 2019
KW  - friction
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - wheels
KW  - friction-based kinematic model
KW  - skid-steer drive systems
KW  - mobile robot platforms
KW  - normal operation
KW  - slippages
KW  - forward kinematics
KW  - slip prediction
KW  - skid-steer wheeled mobile robots
KW  - translational prediction error
KW  - rotational prediction error
KW  - skid-steer robot
KW  - system identification
KW  - model learning research
KW  - Mobile robots
KW  - Kinematics
KW  - Wheels
KW  - Force
KW  - Predictive models
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794216
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Skid-steer drive systems are widely used in mobile robot platforms. Such systems are subject to significant slippage and skidding during normal operation due to their nature. The ability to predict and compensate for such slippages in the forward kinematics of these types of robots is of great importance and provides the means for accurate control and safe navigation. In this work, we propose a new kinematic model capable of slip prediction for skid-steer wheeled mobile robots (SSWMRs). The proposed model outperforms the state-of-the-art in terms of both translational and rotational prediction error on a dataset composed of more than 6 km worth of trajectories traversed by a skid-steer robot. We also publicly release our dataset to serve as a benchmark for system identification and model learning research for SSWMRs.
ER  - 

TY  - CONF
TI  - Turning a Corner with a Dubins Car
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8570
EP  - 8576
AU  - A. Koval
AU  - V. Isler
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - optimisation
KW  - closed-form optimal path
KW  - efficient path planner
KW  - shortest collision-free Dubins paths
KW  - sufficient condition
KW  - closed-form solution
KW  - interior corner
KW  - elementary Dubins paths
KW  - RSRSR
KW  - RSRSL
KW  - LSRSR
KW  - LSRSL
KW  - Turning
KW  - Automobiles
KW  - Heuristic algorithms
KW  - Planning
KW  - Path planning
KW  - Approximation algorithms
KW  - Terminology
DO  - 10.1109/ICRA.2019.8794361
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the problem of computing shortest collision-free Dubins paths when turning a corner. We present a sufficient condition for a closed-form solution. Specifically, consider S as the set consisting of paths of the form RSRSR, RSRSL, LSRSR and LSRSL that pass through the interior corner, where sub-paths RSR, RSL, and LSR are elementary Dubins paths composed of segments which are either straight (S) or turning left (L) or right (R). We find the closed-form optimal path around a corner when S is nonempty. Our solution can be used in an efficient path planner, for example, when navigating corridors. It can also be used as a subroutine for planners such as RRTs.
ER  - 

TY  - CONF
TI  - Modeling and state estimation of a Micro Ball-balancing Robot using a high yaw-rate dynamic model and an Extended Kalman Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8577
EP  - 8583
AU  - E. Sihite
AU  - D. Yang
AU  - T. Bewley
PY  - 2019
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear control systems
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - microball-balancing robot
KW  - extended Kalman filter
KW  - linearized dynamic model
KW  - state estimator
KW  - yaw-rate ball-balancing robot dynamic model
KW  - raw on-board sensor measurements
KW  - EKF
KW  - Robot kinematics
KW  - Wheels
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Torque
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794169
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The state estimation and control of a ball-balancing robot under high yaw rate is a challenging problem due to its highly nonlinear 3D dynamic. The small size and low-cost components in our Micro Ball-Balancing Robot makes the system inherently very noisy which further increases the complexity of the problem. In order to drive the robot more aggressively such as translating and spinning at the same time, a good state estimator which works well under high yaw rates is required. This paper presents the derivation of a high yaw-rate Ball-Balancing Robot dynamic model and the implementation of said model in an Extended Kalman Filter (EKF) using raw on-board sensor measurements. The EKF using the new model is then compared to a Kalman Filter which uses a linearized dynamic model. The accuracy of the attitude estimates and the controller performance under high yaw rates were verified using a motion capture system.
ER  - 

TY  - CONF
TI  - Orientation-Aware Motion Planning in Complex Workspaces using Adaptive Harmonic Potential Fields
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8592
EP  - 8598
AU  - P. Vlantis
AU  - C. Vrohidis
AU  - C. P. Bechlioulis
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - orientation-aware motion planning
KW  - complex workspaces
KW  - adaptive harmonic potential fields
KW  - hybrid control scheme
KW  - navigation problem
KW  - planar robotic platform
KW  - approximate configuration space decomposition techniques
KW  - appropriate workspace transformations
KW  - adaptive potential field based control laws
KW  - configuration space representation
KW  - obstacle cluttered workspace
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Harmonic analysis
KW  - Navigation
KW  - Shape
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2019.8794053
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, a hybrid control scheme is presented in order to address the navigation problem for a planar robotic platform of arbitrary shape that is moving inside an obstacle cluttered workspace. Given an initial and desired robot configuration, we propose a methodology based on approximate configuration space decomposition techniques that makes use of heuristics to adaptively refine a partition of the configuration space into non-overlapping, adjacent slices. Furthermore, we employ appropriate workspace transformations and adaptive potential field based control laws that integrate elegantly with the type of configuration space representation used, in order to safely navigate within a given cell and successfully cross over to the next, for almost all initial configurations, until the desired configuration is reached. Finally, we present simulation results that demonstrate the efficacy of the proposed control scheme.
ER  - 

TY  - CONF
TI  - Energy-Aware Temporal Logic Motion Planning for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8599
EP  - 8605
AU  - T. Kundu
AU  - I. Saha
PY  - 2019
KW  - computability
KW  - mobile robots
KW  - path planning
KW  - power aware computing
KW  - temporal logic
KW  - trajectory control
KW  - motion planning problem
KW  - SMT solving problem
KW  - optimal trajectory
KW  - energy-aware trajectories
KW  - LTL specification
KW  - mobile robot
KW  - motion plan
KW  - battery charge
KW  - LTL formula
KW  - linear temporal logic
KW  - charging station locations
KW  - energy-aware temporal logic motion planning
KW  - satisfiability modulo theory
KW  - Trajectory
KW  - Charging stations
KW  - Batteries
KW  - Planning
KW  - Task analysis
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794395
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a methodology for synthesizing a motion plan for a mobile robot to ensure that the robot never gets depleted with battery charge while carrying out its mission successfully. The specification of the robot is provided in the form of an LTL (Linear Temporal Logic) formula. A trajectory satisfying an LTL formula may contain a loop whose repetitive execution causes the depletion of battery charge in the robot. The motion plan generated by our methodology ensures that the robot visits the charging station periodically in such a way that it never gets depleted with battery charge while carrying out its mission optimally. Given a set of potential charging station locations and an LTL specification, our algorithm also finds the best location for the charging station along with the optimal trajectory for the robot. We encode the motion planning problem as an SMT (Satisfiability Modulo Theory) solving problem and use the off-the-shelf SMT solver Z3 to solve the constraints to find the location of the charging station and generate an optimal trajectory for the robot. We apply our methodology to synthesize energy-aware trajectories for robots with different dynamics in various workspaces and for various LTL specifications.
ER  - 

TY  - CONF
TI  - Using Local Experiences for Global Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8606
EP  - 8612
AU  - C. Chamzas
AU  - A. Shrivastava
AU  - L. E. Kavraki
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - sampling methods
KW  - global motion planning
KW  - sampling-based planners
KW  - collision-free path
KW  - sampling strategy
KW  - Databases
KW  - Planning
KW  - Task analysis
KW  - Kinematics
KW  - Trajectory
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794317
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sampling-based planners are effective in many real-world applications such as robotics manipulation, navigation, and even protein modeling. However, it is often challenging to generate a collision-free path in environments where key areas are hard to sample. In the absence of any prior information, sampling-based planners are forced to explore uniformly or heuristically, which can lead to degraded performance. One way to improve performance is to use prior knowledge of environments to adapt the sampling strategy to the problem at hand. In this work, we decompose the workspace into local primitives, memorizing local experiences by these primitives in the form of local samplers, and store them in a database. We synthesize an efficient global sampler by retrieving local experiences relevant to the given situation. Our method transfers knowledge effectively between diverse environments that share local primitives and speeds up the performance dramatically. Our results show, in terms of solution time, an improvement of multiple orders of magnitude in two traditionally challenging high-dimensional problems compared to state-of-the-art approaches.
ER  - 

TY  - CONF
TI  - DMP Based Trajectory Tracking for a Nonholonomic Mobile Robot With Automatic Goal Adaptation and Obstacle Avoidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8613
EP  - 8619
AU  - R. S. Sharma
AU  - S. Shukla
AU  - H. Karki
AU  - A. Shukla
AU  - L. Behera
AU  - V. K.S.
PY  - 2019
KW  - collision avoidance
KW  - fuzzy logic
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - radial basis function networks
KW  - stability
KW  - steering systems
KW  - trajectory control
KW  - Dynamic Movement Primitive
KW  - motion planning
KW  - robot manipulator
KW  - nonholonomic mobile robot
KW  - Radial Basis Function Networks
KW  - robot goal position
KW  - Lyapunov stability theory-based analysis
KW  - dynamic obstacles
KW  - automatic goal adaptation
KW  - RBFN
KW  - DMP
KW  - gradient descent
KW  - static obstacles
KW  - trajectory tracking
KW  - damped spring model
KW  - steering angle dynamics
KW  - fuzzy logic
KW  - Mobile robots
KW  - Trajectory
KW  - Mathematical model
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793911
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dynamic Movement Primitive (DMP) which is popular for motion planning of a robot manipulator, has been adapted for a nonholonomic mobile robot to track the desired trajectory. DMP is a simple damped spring model with a forcing function, which learns the trajectory. The damped spring model attracts the robot towards the goal position, and the forcing function forces the robot to follow the given trajectory. Two Radial Basis Function Networks (RBFNs) have been used to learn the forcing function associated with the DMP model. Weight update laws are derived using the gradient descent approach to train the RBFNs. Fuzzy logic based steering angle dynamics is proposed to handle the asymmetric nature of an obstacle. The proposed scheme is capable enough to generate a smooth trajectory in the presence of an obstacle even when start and goal positions are altered, without losing the spatial information embedded while training. The convergence of the robot goal position has been shown using Lyapunov stability theory-based analysis. The approach has been extended to multiple static and dynamic obstacles for the successful convergence of the robot at the goal position. Both simulation and experimental results are provided to confirm the efficacy of the proposed scheme.
ER  - 

TY  - CONF
TI  - Predictive Collision Avoidance for the Dynamic Window Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8620
EP  - 8626
AU  - M. Missura
AU  - M. Bennewitz
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - predictive collision avoidance
KW  - dynamic window approach
KW  - foresighted navigation
KW  - mobile robots
KW  - factory floor installations
KW  - dynamic collision model
KW  - nonholonomic vehicles
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Acceleration
KW  - Collision avoidance
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794386
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Foresighted navigation is an essential skill for robots to rise from rigid factory floor installations to much more versatile mobile robots that partake in our everyday environment. The current state of the art that provides this mobility to some extent is the Dynamic Window Approach combined with a global start-to-target path planner. However, neither the Dynamic Window Approach nor the path planner are equipped to predict the motion of other objects in the environment. We propose a change in the Dynamic Window Approach-a dynamic collision model-that is capable of predicting future collisions with the environment by also taking into account the motion of other objects. We show in simulated experiments that our new way of computing the Dynamic Window Approach significantly reduces the number of collisions in a dynamic setting with nonholonomic vehicles while still being computationally efficient.
ER  - 

TY  - CONF
TI  - Kinematic Constraints Based Bi-directional RRT (KB-RRT) with Parameterized Trajectories for Robot Path Planning in Cluttered Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8627
EP  - 8633
AU  - D. Ghosh
AU  - G. Nandakumar
AU  - K. Narayanan
AU  - V. Honkote
AU  - S. Sharma
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - Bi-RRT algorithm
KW  - parameterized trajectories
KW  - robot path planning
KW  - complex missions
KW  - navigation capability
KW  - autonomous mobile robots
KW  - robust path planning algorithms
KW  - bidirectional-RRT
KW  - kinodynamic constraints
KW  - bidirectional RRT
KW  - trajectory planning
KW  - memory utilization
KW  - kinematic constraints
KW  - KB-RRT algorithm
KW  - Kinematics
KW  - Trajectory
KW  - Mobile robots
KW  - Navigation
KW  - Planning
DO  - 10.1109/ICRA.2019.8793896
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Optimal path planning and smooth trajectory planning are critical for effective navigation of mobile robots working towards accomplishing complex missions. For autonomous, real time and extended operations of mobile robots, the navigation capability needs to be executed at the edge. Thus, efficient compute, minimum memory utilization and smooth trajectory are the key parameters that drive the successful operation of autonomous mobile robots. Traditionally, navigation solutions focus on developing robust path planning algorithms which are complex and compute/memory intensive. Bidirectional-RRT(Bi-RRT) based path planning algorithms have gained increased attention due to their effectiveness and computational efficiency in generating feasible paths. However, these algorithms neither optimize memory nor guarantee smooth trajectories. To this end, we propose a kinematically constrained Bi-RRT (KB-RRT) algorithm, which restricts the number of nodes generated without compromising on the accuracy and incorporates kinodynamic constraints for generating smooth trajectories, together resulting in efficient navigation of autonomous mobile robots. The proposed algorithm is tested in a highly cluttered environment on an Ackermannsteering vehicle model with severe kinematic constraints. The experimental results demonstrate that KB-RRT achieves three times (3 X) better performance in terms of convergence rate and memory utilization compared to a standard Bi-RRT algorithm.
ER  - 

TY  - CONF
TI  - Predicting Vehicle Behaviors Over An Extended Horizon Using Behavior Interaction Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8634
EP  - 8640
AU  - W. Ding
AU  - J. Chen
AU  - S. Shen
PY  - 2019
KW  - recurrent neural nets
KW  - road vehicles
KW  - traffic engineering computing
KW  - recurrent neural network
KW  - interaction modeling
KW  - vehicle behaviors
KW  - autonomous vehicles
KW  - behavior detection
KW  - long-term future rewards
KW  - vehicle behavior interaction network
KW  - observation encoding
KW  - Planning
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Encoding
KW  - Autonomous vehicles
KW  - Recurrent neural networks
KW  - Prediction methods
DO  - 10.1109/ICRA.2019.8794146
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Anticipating possible behaviors of traffic participants is an essential capability of autonomous vehicles. Many behavior detection and maneuver recognition methods only have a very limited prediction horizon that leaves inadequate time and space for planning. To avoid unsatisfactory reactive decisions, it is essential to count long-term future rewards in planning, which requires extending the prediction horizon. In this paper, we uncover that clues to vehicle behaviors over an extended horizon can be found in vehicle interaction, which makes it possible to anticipate the likelihood of a certain behavior, even in the absence of any clear maneuver pattern. We adopt a recurrent neural network (RNN) for observation encoding, and based on that, we propose a novel vehicle behavior interaction network (VBIN) to capture the vehicle interaction from the hidden states and connection feature of each interaction pair. The output of our method is a probabilistic likelihood of multiple behavior classes, which matches the multimodal and uncertain nature of the distant future. A systematic comparison of our method against two state-of-the-art methods and another two baseline methods on a publicly available real highway dataset is provided, showing that our method has superior accuracy and advanced capability for interaction modeling.
ER  - 

TY  - CONF
TI  - Multimodal Spatio-Temporal Information in End-to-End Networks for Automotive Steering Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8641
EP  - 8647
AU  - M. Abou-Hussein
AU  - S. H. Müller
AU  - J. Boedecker
PY  - 2019
KW  - cameras
KW  - driver information systems
KW  - image sequences
KW  - road safety
KW  - steering systems
KW  - visual input data
KW  - onboard vehicle camera
KW  - empirical comparison
KW  - spatial spatio-temporal
KW  - real-life driver
KW  - predicted steering command
KW  - recurrent multimodal model
KW  - steering correction concept
KW  - multimodal spatio-temporal information
KW  - end-to-end networks
KW  - automotive steering prediction
KW  - end-to-end steering problem
KW  - Optical imaging
KW  - Adaptive optics
KW  - Computational modeling
KW  - Kernel
KW  - Training
KW  - Roads
KW  - Cameras
KW  - Autonomous steering
KW  - deep learning
KW  - spatio-temporal model
KW  - multimodal input
KW  - optical flow
KW  - RNN-LSTM
DO  - 10.1109/ICRA.2019.8794410
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the end-to-end steering problem using visual input data from an onboard vehicle camera. An empirical comparison between spatial, spatio-temporal and multimodal models is performed assessing each concept's performance from two points of evaluation. First, how close the model is in predicting and imitating a real-life driver's behavior, second, the smoothness of the predicted steering command. The latter is a newly proposed metric. Building on our results, we propose a new recurrent multimodal model. The suggested model has been tested on a custom dataset recorded by BMW, as well as the public dataset provided by Udacity. Results show that it outperforms previously released scores. Further, a steering correction concept from off-lane driving through the inclusion of correction frames is presented. We show that our suggestion leads to promising results empirically.
ER  - 

TY  - CONF
TI  - OVPC Mesh: 3D Free-space Representation for Local Ground Vehicle Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8648
EP  - 8654
AU  - F. Ruetz
AU  - E. Hernández
AU  - M. Pfeiffer
AU  - H. Oleynikova
AU  - M. Cox
AU  - T. Lowe
AU  - P. Borges
PY  - 2019
KW  - computational geometry
KW  - mesh generation
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - OVPC Mesh
KW  - 3D free-space representation
KW  - local ground vehicle navigation
KW  - autonomous unmanned ground vehicle
KW  - Visible Point Clouds Mesh
KW  - local point cloud data
KW  - UGV navigation
KW  - on visible point clouds mesh
KW  - watertight 3D mesh generation
KW  - trajectory planning
KW  - robot
KW  - Three-dimensional displays
KW  - Navigation
KW  - Robot sensing systems
KW  - Planning
KW  - Laser radar
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793503
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel approach for local 3D environment representation for autonomous unmanned ground vehicle (UGV) navigation called On Visible Point Clouds Mesh (OVPC Mesh). Our approach represents the surrounding of the robot as a watertight 3D mesh generated from local point cloud data in order to represent the free space surrounding the robot. It is a conservative estimation of the free space and provides a desirable trade-off between representation precision and computational efficiency, without having to discretize the environment into a fixed grid size. Our experiments analyze the usability of the approach for UGV navigation in rough terrain, both in simulation and in a fully integrated real-world system. Additionally, we compare our approach to well-known state-of the-art solutions, such as Octomap and Elevation Mapping and show that OVPC Mesh can provide reliable 3D information for trajectory planning while fulfilling real-time constraints.
ER  - 

TY  - CONF
TI  - Attention-based Lane Change Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8655
EP  - 8661
AU  - O. Scheel
AU  - N. S. Nagaraja
AU  - L. Schwarz
AU  - N. Navab
AU  - F. Tombari
PY  - 2019
KW  - path planning
KW  - recurrent neural nets
KW  - road vehicles
KW  - traffic engineering computing
KW  - function estimation problem
KW  - model understandability
KW  - lane change prediction model
KW  - attention-based recurrent model
KW  - prediction quality
KW  - attention-based lane change prediction
KW  - path planning
KW  - driver discomfort
KW  - Automobiles
KW  - Predictive models
KW  - Hidden Markov models
KW  - Task analysis
KW  - Vehicle dynamics
KW  - Bayes methods
DO  - 10.1109/ICRA.2019.8793648
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Lane change prediction of surrounding vehicles is a key building block of path planning. The focus has been on increasing the accuracy of prediction by posing it purely as a function estimation problem at the cost of model understandability. However, the efficacy of any lane change prediction model can be improved when both corner and failure cases are humanly understandable. We propose an attention-based recurrent model to tackle both understandability and prediction quality. We also propose metrics which reflect the discomfort felt by the driver. We show encouraging results on a publicly available dataset and proprietary fleet data.
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning With Model Uncertainty Estimates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8662
EP  - 8668
AU  - B. Lütjens
AU  - M. Everett
AU  - J. P. How
PY  - 2019
KW  - Bayes methods
KW  - collision avoidance
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - safety
KW  - model uncertainty estimates
KW  - current autonomous systems
KW  - strong reliance
KW  - black box predictions
KW  - deep neural networks
KW  - DNNs
KW  - unpredictable results
KW  - far-from-distribution test data
KW  - distributional shift
KW  - safety-critical applications
KW  - pedestrians
KW  - state-of-the-art extraction methods
KW  - Bayesian neural networks
KW  - MC-Dropout
KW  - computationally tractable uncertainty estimates
KW  - parallelizable uncertainty estimates
KW  - uncertainty-aware navigation
KW  - collision avoidance policy
KW  - unseen behavior
KW  - uncertainty-unaware baseline
KW  - safe reinforcement learning framework
KW  - Uncertainty
KW  - Collision avoidance
KW  - Neural networks
KW  - Computational modeling
KW  - Training
KW  - Data models
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8793611
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many current autonomous systems are being designed with a strong reliance on black box predictions from deep neural networks (DNNs). However, DNNs tend to be overconfident in predictions on unseen data and can give unpredictable results for far-from-distribution test data. The importance of predictions that are robust to this distributional shift is evident for safety-critical applications, such as collision avoidance around pedestrians. Measures of model uncertainty can be used to identify unseen data, but the state-of-the-art extraction methods such as Bayesian neural networks are mostly intractable to compute. This paper uses MC-Dropout and Bootstrapping to give computationally tractable and parallelizable uncertainty estimates. The methods are embedded in a Safe Reinforcement Learning framework to form uncertainty-aware navigation around pedestrians. The result is a collision avoidance policy that knows what it does not know and cautiously avoids pedestrians that exhibit unseen behavior. The policy is demonstrated in simulation to be more robust to novel observations and take safer actions than an uncertainty-unaware baseline.
ER  - 


