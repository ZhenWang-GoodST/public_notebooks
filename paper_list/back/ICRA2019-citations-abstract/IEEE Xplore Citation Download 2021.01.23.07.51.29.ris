TY  - CONF
TI  - Using DP Towards A Shortest Path Problem-Related Application
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8669
EP  - 8675
AU  - J. Jiao
AU  - R. Fan
AU  - H. Ma
AU  - M. Liu
PY  - 2019
KW  - directed graphs
KW  - dynamic programming
KW  - graph theory
KW  - image segmentation
KW  - object detection
KW  - search problems
KW  - traffic engineering computing
KW  - line segments
KW  - directed graph model
KW  - dynamic programming
KW  - shortest path problem-related application
KW  - curved lanes
KW  - autonomous driving systems
KW  - visual recognition tasks
KW  - lane detection
KW  - two-dimensional graph searching problem
KW  - optimal path finding
KW  - Search problems
KW  - Roads
KW  - Visualization
KW  - Shortest path problem
KW  - Mathematical model
KW  - Task analysis
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793603
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The detection of curved lanes is still challenging for autonomous driving systems. Although current cutting-edge approaches have performed well in real applications, most of them are based on strict model assumptions. Similar to other visual recognition tasks, lane detection can be formulated as a two-dimensional graph searching problem, which can be solved by finding several optimal paths along with line segments and boundaries. In this paper, we present a directed graph model, in which dynamic programming is used to deal with a specific shortest path problem. This model is particularly suitable to represent objects with long continuous shape structure, e.g., lanes and roads. We apply the designed model and proposed an algorithm for detecting lanes by formulating it as the shortest path problem. To evaluate the performance of our proposed algorithm, we tested five sequences (including 1573 frames) from the KITTI database. The results showed that our method achieves an average successful detection precision of 97.5%.
ER  - 

TY  - CONF
TI  - Improving dual-arm assembly by master-slave compliance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8676
EP  - 8682
AU  - M. Suomalainen
AU  - S. Calinon
AU  - E. Pignat
AU  - V. Kyrki
PY  - 2019
KW  - force control
KW  - human-robot interaction
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - multi-robot systems
KW  - robotic assembly
KW  - telerobotics
KW  - learning method
KW  - master-slave compliance
KW  - dual-arm assembly task
KW  - compliance parameters
KW  - human demonstration
KW  - compliant motions
KW  - assembly tasks
KW  - convergence region
KW  - alignment task
KW  - compliant axes
KW  - orientation error
KW  - single teleoperated manipulator
KW  - manipulators compliant
KW  - total joint motions
KW  - Task analysis
KW  - Manipulators
KW  - Tools
KW  - Jamming
KW  - Wrist
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793977
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we show how different choices regarding compliance affect a dual-arm assembly task. In addition, we present how the compliance parameters can be learned from a human demonstration. Compliant motions can be used in assembly tasks to mitigate pose errors originating from, for example, inaccurate grasping. We present analytical background and accompanying experimental results on how to choose the center of compliance to enhance the convergence region of an alignment task. Then we present the possible ways of choosing the compliant axes for accomplishing alignment in a scenario where orientation error is present. We show that an earlier presented Learning from Demonstration method can be used to learn motion and compliance parameters of an impedance controller for both manipulators. The learning requires a human demonstration with a single teleoperated manipulator only, easing the execution of demonstration and enabling usage of manipulators at difficult locations as well. Finally, we experimentally verify our claim that having both manipulators compliant in both rotation and translation can accomplish the alignment task with less total joint motions and in shorter time than moving one manipulator only. In addition, we show that the learning method produces the parameters that achieve the best results in our experiments.
ER  - 

TY  - CONF
TI  - Generation of Synchronized Configuration Space Trajectories of Multi-Robot Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8683
EP  - 8690
AU  - A. M. Kabir
AU  - A. Kanyuck
AU  - R. K. Malhan
AU  - A. V. Shembekar
AU  - S. Thakar
AU  - B. C. Shah
AU  - S. K. Gupta
PY  - 2019
KW  - multi-robot systems
KW  - optimisation
KW  - synchronized configuration space trajectories
KW  - multirobot systems
KW  - path-constrained trajectory generation
KW  - synchronous motion
KW  - nonlinear optimization problem
KW  - configuration variables
KW  - successive refinement techniques
KW  - parametric representation
KW  - Trajectory
KW  - Manipulators
KW  - Splines (mathematics)
KW  - Optimization
KW  - Robot kinematics
KW  - Tools
DO  - 10.1109/ICRA.2019.8794275
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We pose the problem of path-constrained trajectory generation for the synchronous motion of multi-robot systems as a non-linear optimization problem. Our method determines appropriate parametric representation for the configuration variables, generates an approximate solution as a starting point for the optimization method, and uses successive refinement techniques to solve the problem in a computationally efficient manner. We have demonstrated the effectiveness of the proposed method on challenging simulation and physical experiments with high degrees of freedom robotic systems.
ER  - 

TY  - CONF
TI  - REPLAB: A Reproducible Low-Cost Arm Benchmark for Robotic Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8691
EP  - 8697
AU  - B. Yang
AU  - D. Jayaraman
AU  - J. Zhang
AU  - S. Levine
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot programming
KW  - robot vision
KW  - reproducible low-cost arm benchmark
KW  - robotic learning
KW  - vision-based manipulation benchmark
KW  - robot arm
KW  - robotics
KW  - grasping benchmark
KW  - evaluation protocol
KW  - standardized evaluation
KW  - machine learning
KW  - REPLAB
KW  - Robots
KW  - Benchmark testing
KW  - Task analysis
KW  - Grasping
KW  - Hardware
KW  - Cameras
KW  - Calibration
DO  - 10.1109/ICRA.2019.8794390
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Standardized evaluation measures have aided in the progress of machine learning approaches in disciplines such as computer vision and machine translation. In this paper, we make the case that robotic learning would also benefit from benchmarking, and present a template for a vision-based manipulation benchmark. Our benchmark is built on “REPLAB,” a reproducible and self-contained hardware stack (robot arm, camera, and workspace) that costs about 2000 USD and occupies a cuboid of size 70x40x60 cm. Each REPLAB cell may be assembled within a few hours. Through this low-cost, compact design, REPLAB aims to drive wide participation by lowering the barrier to entry into robotics and to enable easy scaling to many robots. We envision REPLAB as a framework for reproducible research across manipulation tasks, and as a step in this direction, we define a grasping benchmark consisting of a task definition, evaluation protocol, performance measures, and a dataset of over 50,000 grasp attempts. We implement, evaluate, and analyze several previously proposed grasping approaches to establish baselines for this benchmark. Project page with assembly instructions, additional details, and videos: https://goo.gl/5F9dP4.
ER  - 

TY  - CONF
TI  - Stable Bin Packing of Non-convex 3D Objects with a Robot Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8698
EP  - 8704
AU  - F. Wang
AU  - K. Hauser
PY  - 2019
KW  - computational geometry
KW  - control engineering computing
KW  - industrial manipulators
KW  - production engineering computing
KW  - warehouse automation
KW  - nonconvex objects
KW  - bin packing
KW  - heightmap-minimization heuristic
KW  - constructive packing pipeline
KW  - placement plans
KW  - robot motion
KW  - automated warehousing domain
KW  - packing problem
KW  - fully automatic object packing
KW  - robot manipulator
KW  - nonconvex 3D objects
KW  - high-quality packing
KW  - robot packability constraints
KW  - Robots
KW  - Three-dimensional displays
KW  - Containers
KW  - Stability analysis
KW  - Collision avoidance
KW  - Pipelines
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794049
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent progress in the field of robotic manipulation has generated interest in fully automatic object packing in warehouses. This paper proposes a formulation of the packing problem that is tailored to the automated warehousing domain. Besides minimizing waste space inside a container, the problem requires stability of the object pile during packing and the feasibility of the robot motion executing the placement plans. To address this problem, a set of constraints are formulated, and a constructive packing pipeline is proposed to solve these constraints. The pipeline is able to pack geometrically complex, non-convex objects while satisfying stability and robot packability constraints. In particular, a new 3D positioning heuristic called Heightmap-Minimization heuristic is proposed, and heightmaps are used to speed up the search. Experimental evaluation of the method is conducted with a realistic physical simulator on a dataset of scanned real-world items, demonstrating stable and high-quality packing plans compared with other 3D packing methods.
ER  - 

TY  - CONF
TI  - A Constraint Programming Approach to Simultaneous Task Allocation and Motion Scheduling for Industrial Dual-Arm Manipulation Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8705
EP  - 8711
AU  - J. K. Behrens
AU  - R. Lange
AU  - M. Mansouri
PY  - 2019
KW  - constraint handling
KW  - industrial manipulators
KW  - motion control
KW  - optimisation
KW  - robot programming
KW  - robotic assembly
KW  - scheduling
KW  - robotic platforms
KW  - constraint programming approach
KW  - simultaneous task allocation
KW  - motion scheduling
KW  - industrial dual-arm manipulation tasks
KW  - dual-arm robots
KW  - industrial manipulation
KW  - assembly tasks
KW  - robot motion models
KW  - constraint optimization problems
KW  - makespan-optimized robot programs
KW  - industrial workplaces
KW  - robot-independent task model
KW  - lightweight dual-arm robots
KW  - ordered visiting constraint
KW  - ordering constraints
KW  - Task analysis
KW  - Planning
KW  - Manipulators
KW  - Robot kinematics
KW  - Job shop scheduling
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794022
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern lightweight dual-arm robots bring the physical capabilities to quickly take over tasks at typical industrial workplaces designed for workers. Low setup times - including the instructing/specifying of new tasks - are crucial to stay competitive. We propose a constraint programming approach to simultaneous task allocation and motion scheduling for such industrial manipulation and assembly tasks. Our approach covers the robot as well as connected machines. The key concept are Ordered Visiting Constraints, a descriptive and extensible model to specify such tasks with their spatiotemporal requirements and combinatorial or ordering constraints. Our solver integrates such task models and robot motion models into constraint optimization problems and solves them efficiently using various heuristics to produce makespan-optimized robot programs. For large manipulation tasks with 200 objects, our solver implemented using Google's Operations Research tools requires less than a minute to compute usable plans. The proposed task model is robot-independent and can easily be deployed to other robotic platforms. This portability is validated through several simulation-based experiments.
ER  - 

TY  - CONF
TI  - Self-Supervised Surgical Tool Segmentation using Kinematic Information
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8720
EP  - 8726
AU  - C. d. C. Rocha
AU  - N. Padoy
AU  - B. Rosa
PY  - 2019
KW  - calibration
KW  - convolutional neural nets
KW  - endoscopes
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - surgery
KW  - training labels
KW  - optimization method
KW  - unknown hand-eye calibration
KW  - imprecise kinematic model
KW  - fully-convolutional neural network
KW  - endoscopic images
KW  - flexible robotized endoscopy system
KW  - self-supervised surgical tool segmentation
KW  - kinematic information
KW  - task automation
KW  - minimally invasive surgical operations
KW  - modern machine learning methods
KW  - manually-annotated images
KW  - surgical context
KW  - patient-to-patient differences
KW  - annotated data
KW  - self-supervised approach
KW  - robot-assisted context
KW  - pose estimation
KW  - subtask automation
KW  - hand-eye calibration
KW  - pixel-wise classification
KW  - Tools
KW  - Image segmentation
KW  - Kinematics
KW  - Shape
KW  - Robot kinematics
KW  - Cost function
DO  - 10.1109/ICRA.2019.8794334
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgical tool segmentation in endoscopic images is the first step towards pose estimation and (sub-)task automation in challenging minimally invasive surgical operations. While many approaches in the literature have shown great results using modern machine learning methods such as convolutional neural networks, the main bottleneck lies in the acquisition of a large number of manually-annotated images for efficient learning. This is especially true in surgical context, where patient-to-patient differences impede the overall generalizability. In order to cope with this lack of annotated data, we propose a self-supervised approach in a robot-assisted context. To our knowledge, the proposed approach is the first to make use of the kinematic model of the robot in order to generate training labels. The core contribution of the paper is to propose an optimization method to obtain good labels for training despite an unknown hand-eye calibration and an imprecise kinematic model. The labels can subsequently be used for fine-tuning a fully-convolutional neural network for pixel-wise classification. As a result, the tool can be segmented in the endoscopic images without needing a single manually-annotated image. Experimental results on phantom and in vivo datasets obtained using a flexible robotized endoscopy system are very promising.
ER  - 

TY  - CONF
TI  - Needle Localization for Robot-assisted Subretinal Injection based on Deep Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8727
EP  - 8732
AU  - M. Zhou
AU  - X. Wang
AU  - J. Weiss
AU  - A. Eslami
AU  - K. Huang
AU  - M. Maier
AU  - C. P. Lohmann
AU  - N. Navab
AU  - A. Knoll
AU  - M. A. Nasseri
PY  - 2019
KW  - biomedical optical imaging
KW  - eye
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - optical tomography
KW  - surgery
KW  - visual feedback
KW  - microscope-integrated optical coherence tomography
KW  - robotic subretinal injection
KW  - needle segment
KW  - retinal surface
KW  - OCT volumetric images
KW  - MI-OCT
KW  - needle detection
KW  - human surgeons
KW  - robot-assisted surgery
KW  - high surgical precision
KW  - deep learning
KW  - robot-assisted subretinal injection
KW  - needle localization
KW  - Needles
KW  - Retina
KW  - Surgery
KW  - Image segmentation
KW  - Robots
KW  - Microscopy
KW  - Agriculture
DO  - 10.1109/ICRA.2019.8793756
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Subretinal injection is known to be a complicated task for ophthalmologists to perform, the main sources of difficulties are the fine anatomy of the retina, insufficient visual feedback, and high surgical precision. Image guided robot-assisted surgery is one of the promising solutions that bring significant surgical enhancement in treatment outcome and reduces the physical limitations of human surgeons. In this paper, we demonstrate a robust framework for needle detection and localization in subretinal injection using microscope-integrated Optical Coherence Tomography (MI-OCT) based on deep learning. The proposed method consists of two main steps: a) the preprocessing of OCT volumetric images; b) needle localization in the processed images. The first step is to coarsely localize the needle position based on the needle information above the retinal surface and crop the original image into a small region of interest (ROI). Afterward, the cropped small image is fed into a well trained network for detection and localization of the needle segment. The entire framework is extensively validated in ex-vivo pig eye experiments with robotic subretinal injection. The results show that the proposed method can localize the needle accurately with a confidence of 99.2%.
ER  - 

TY  - CONF
TI  - Robust Generalized Point Set Registration using Inhomogeneous Hybrid Mixture Models via Expectation Maximization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8733
EP  - 8739
AU  - Z. Min
AU  - M. Q. -. Meng
PY  - 2019
KW  - computer vision
KW  - expectation-maximisation algorithm
KW  - Gaussian distribution
KW  - Gaussian processes
KW  - image registration
KW  - iterative methods
KW  - optimisation
KW  - generalized point set registration
KW  - translation vector
KW  - surface points
KW  - inhomogeneous hybrid mixture models
KW  - expectation maximization
KW  - biomedical engineering communities
KW  - orientational vector
KW  - expectation-maximization framework
KW  - registration methods
KW  - Fisher distribution mixture models
KW  - GMM
KW  - FMM
KW  - PSR
KW  - Hidden Markov models
KW  - Mixture models
KW  - Probabilistic logic
KW  - Maximum likelihood estimation
KW  - Data models
KW  - Principal component analysis
KW  - Nonhomogeneous media
DO  - 10.1109/ICRA.2019.8794135
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Point set registration (PSR) is an important problem in computer vision, robotics and biomedical engineering communities. Usually, only positional information at each point is adopted in a registration. In this paper, the orientational vector (or normal vector) associated with each point is also utilized. Generalized point set registration is formulated and solved under the Expectation-Maximization (EM) framework. In the E-step, the posterior probabilities representing the correspondence probabilities are computed. In the Mstep, rigid transformation parameters including the rotation matrix, the translation vector are updated. The proposed algorithm stops when it converges to the optimal solution or a maximum number of iterations is achieved. The observed position set and normal vector set are assumed to follow Gaussian Mixture Models (GMMs) and Fisher distribution Mixture Models (FMMs), respectively. To further improve our algorithm's robustness, the hybrid mixture models (HMMs) are assumed to be inhomogeneous. Experimental results on the surface points extracted from a human femur' CT model show that our algorithm can achieve lower registration error, is more robust to noise and outliers than the state-of-the-art registration methods.
ER  - 

TY  - CONF
TI  - Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8740
EP  - 8746
AU  - Y. Guo
AU  - M. Sun
AU  - F. P. W. Lo
AU  - B. Lo
PY  - 2019
KW  - blood vessels
KW  - cameras
KW  - diseases
KW  - image matching
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - stents
KW  - stereo image processing
KW  - robotic platforms
KW  - autonomous personalized stent graft manufacturing
KW  - stereo vision systems
KW  - personalized stent-graft manufacturing
KW  - robotic arm
KW  - dynamic stereo microscope
KW  - static wide angle view stereo webcam
KW  - multiple stereo camera configuration
KW  - sewing process
KW  - stereo matching
KW  - feature identifications
KW  - visual-servoing system
KW  - real-time intelligent robotic control
KW  - visual guidance
KW  - automatic control
KW  - robotic personalized stent graft manufacturing
KW  - AAA patient
KW  - hybrid vision system
KW  - abdominal aortic aneurysms patient
KW  - DDPG
KW  - reinforcement learning
KW  - object localization
KW  - Microscopy
KW  - Robot kinematics
KW  - Needles
KW  - Webcams
KW  - Manipulators
KW  - Aneurysm
DO  - 10.1109/ICRA.2019.8794123
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.
ER  - 

TY  - CONF
TI  - Towards 3D Path Planning from a Single 2D Fluoroscopic Image for Robot Assisted Fenestrated Endovascular Aortic Repair
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8747
EP  - 8753
AU  - J. Zheng
AU  - X. Zhou
AU  - C. Riga
AU  - G. Yang
PY  - 2019
KW  - blood vessels
KW  - computerised tomography
KW  - diagnostic radiography
KW  - image registration
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - path planning
KW  - phantoms
KW  - CT scans
KW  - computed tomography
KW  - 2D intra-operative AAA skeletons
KW  - graph matching method
KW  - 3D preoperative AAA
KW  - 3D distance error
KW  - skeleton length
KW  - skeleton deformation
KW  - real-time 3D robotic path planning
KW  - Abdominal Aortic Aneurysm
KW  - skeleton instantiation framework
KW  - 2D fluoroscopic images
KW  - fenestrated endovascular aortic repair
KW  - single 2D fluoroscopic image
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Skeleton
KW  - Indexes
KW  - Robots
KW  - Arteries
KW  - Path planning
DO  - 10.1109/ICRA.2019.8793918
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The current standard of intra-operative navigation during Fenestrated Endovascular Aortic Repair (FEVAR) calls for the need of 3D alignments between inserted devices and aortic branches. The navigation commonly via 2D fluoroscopic images, lacks anatomical information, resulting in longer operation hours and radiation exposure. In this paper, a skeleton instantiation framework of Abdominal Aortic Aneurysm (AAA) from a single 2D fluoroscopic image is introduced for real-time 3D robotic path planning. A graph matching method is proposed to establish the correspondences between the 3D preoperative and 2D intra-operative AAA skeletons, and then the two skeletons are registered by skeleton deformation and regularization in respect to skeleton length and smoothness. Furthermore, deep learning was used to segment 3D preoperative AAA from Computed Tomography (CT) scans to facilitate the framework automation. Simulation, phantom and patient AAA data sets have been used to validate the proposed framework. 3D distance error of 2mm was achieved in the phantom setup. Performance advantages were also achieved in terms of accuracy, robustness and time-efficiency.
ER  - 

TY  - CONF
TI  - Multi-View Picking: Next-best-view Reaching for Improved Grasping in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8762
EP  - 8768
AU  - D. Morrison
AU  - P. Corke
AU  - J. Leitner
PY  - 2019
KW  - cameras
KW  - clutter
KW  - grippers
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - uncertainty handling
KW  - clutter
KW  - occlusions
KW  - active perception approach
KW  - informative viewpoints
KW  - MVP controller
KW  - multiple fixed viewpoints
KW  - next-best-view reaching
KW  - improved grasping
KW  - camera viewpoint selection
KW  - visual grasp detection
KW  - multiview picking controller
KW  - real-time grasp pose estimates
KW  - uncertainty reduction
KW  - Visualization
KW  - Entropy
KW  - Cameras
KW  - Grasping
KW  - Clutter
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793805
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Camera viewpoint selection is an important aspect of visual grasp detection, especially in clutter where many occlusions are present. Where other approaches use a static camera position or fixed data collection routines, our Multi-View Picking (MVP) controller uses an active perception approach to choose informative viewpoints based directly on a distribution of grasp pose estimates in real time, reducing uncertainty in the grasp poses caused by clutter and occlusions. In trials of grasping 20 objects from clutter, our MVP controller achieves 80% grasp success, outperforming a single-viewpoint grasp detector by 12%. We also show that our approach is both more accurate and more efficient than approaches which consider multiple fixed viewpoints. Code is available at https://github.com/dougsm/mvp_grasp.
ER  - 

TY  - CONF
TI  - A Multi-Sensor Next-Best-View Framework for Geometric Model-Based Robotics Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8769
EP  - 8775
AU  - J. Cui
AU  - J. T. Wen
AU  - J. Trinkle
PY  - 2019
KW  - computational geometry
KW  - image reconstruction
KW  - image sensors
KW  - inspection
KW  - mobile robots
KW  - robot vision
KW  - solid modelling
KW  - model building process
KW  - weld seam inspection
KW  - multisensor next-best-view framework
KW  - geometric model-based robotics applications
KW  - consecutive sensing actions
KW  - robotic 3D reconstruction systems
KW  - reconstruction goals
KW  - Modeling
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Cameras
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794423
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Geometric models are crucial for many robotics applications. Current robotic 3D reconstruction systems only focus on specific reconstruction goals which make them hard to adapt to different tasks. In this paper we present a next-best-view framework which allows robots to construct a geometric model incrementally through consecutive sensing actions. Instead of limiting the type and total number of sensors, in each sensing step we evaluate actions from all available sensors and pick the best to execute. Our framework is more comprehensive since the model building process can be designed to best accomplish different tasks. The system has been demonstrated in two experiments on 3D reconstruction and weld seam inspection, yielding promising results.
ER  - 

TY  - CONF
TI  - Model-Free Optimal Estimation and Sensor Placement Framework for Elastic Kinematic Chain
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8776
EP  - 8782
AU  - J. Ahn
AU  - J. Yoon
AU  - J. Lee
AU  - D. Lee
PY  - 2019
KW  - elasticity
KW  - manipulator kinematics
KW  - maximum likelihood estimation
KW  - motion control
KW  - optimal control
KW  - probability
KW  - sensor placement
KW  - sensors
KW  - inertial measurement unit sensors
KW  - high-DOF EKC
KW  - high-degree-of-freedom EKC
KW  - maximum a posteriori estimation
KW  - posterior probability
KW  - real-time output estimation
KW  - optimal placement
KW  - optimal IMU placement
KW  - MAP estimation
KW  - POD mode
KW  - nondominant modes
KW  - proper orthogonal decomposition
KW  - IMU sensors
KW  - elastic kinematic chain
KW  - sensor placement framework
KW  - model-free optimal estimation
KW  - Estimation
KW  - Robot sensing systems
KW  - Vibrations
KW  - Kinematics
KW  - Manipulators
KW  - Telerobotics
KW  - Covariance matrices
DO  - 10.1109/ICRA.2019.8793665
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel model-free optimal estimation and sensor placement framework for a high-DOF (degree-of-freedom) EKC (elastic kinematic chain) with only a limited number of IMU (inertial measurement unit) sensors based on POD (proper orthogonal decomposition) and MAP (maximum a posteriori) estimation. First, we (off-line) excite the system richly enough, collect the data and perform the POD to extract dominant and non-dominant modes. We then decide the minimum number of IMUs according to the dominant modes, and construct the prior distribution of the output (i.e., top-end position of EKC) based on the singular value of each POD mode. We also formulate the MAP estimation given the prior distribution and different placements of the IMUs and choose the optimal IMU placement to maximize the posterior probability. This optimal placement is then used for real-time output estimation of the EKC. Experiments are also performed to verify the theory.
ER  - 

TY  - CONF
TI  - Tree Search Techniques for Minimizing Detectability and Maximizing Visibility
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8791
EP  - 8797
AU  - Z. Zhang
AU  - J. Lee
AU  - J. M. Smereka
AU  - Y. Sung
AU  - L. Zhou
AU  - P. Tokekar
PY  - 2019
KW  - game theory
KW  - minimax techniques
KW  - Monte Carlo methods
KW  - tree searching
KW  - trees (mathematics)
KW  - tree search techniques
KW  - reconnaissance mission
KW  - pursuit-evasion problem
KW  - finite-horizon path
KW  - zero-sum game
KW  - game tree search algorithms
KW  - minimax search tree
KW  - Monte-Carlo search tree
KW  - detectability minimization
KW  - visibility maximization
KW  - visibility-based target search
KW  - pruning techniques
KW  - Games
KW  - Search problems
KW  - Planning
KW  - Monte Carlo methods
KW  - Game theory
KW  - Task analysis
KW  - Reconnaissance
DO  - 10.1109/ICRA.2019.8794305
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce and study the problem of planning a trajectory for an agent to carry out a reconnaissance mission while avoiding being detected by an adversarial guard. This introduces a multi-objective version of classical visibility-based target search and pursuit-evasion problem. In our formulation, the agent receives a positive reward for increasing its visibility (by exploring new regions) and a negative penalty every time it is detected by the guard. The objective is to find a finite-horizon path for the agent that balances the trade off between maximizing visibility and minimizing detectability.We model this problem as a discrete, sequential, two-player, zero-sum game. We use two types of game tree search algorithms to solve this problem: minimax search tree and Monte-Carlo search tree. Both search trees can yield the optimal policy but may require possibly exponential computational time and space. We propose several pruning techniques to reduce the computational cost while still preserving optimality guarantees. Simulation results show that the proposed strategy prunes approximately three orders of magnitude nodes as compared to the brute-force strategy. We also find that the Monte-Carlo search tree saves approximately one order of computational time as compared to the minimax search tree.
ER  - 

TY  - CONF
TI  - Chance Constrained Motion Planning for High-Dimensional Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8805
EP  - 8811
AU  - S. Dai
AU  - S. Schaffert
AU  - A. Jasour
AU  - A. Hofmann
AU  - B. Williams
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - optimal control
KW  - probability
KW  - chance constrained motion planning
KW  - high-dimensional robots
KW  - Probabilistic Chekov
KW  - chance-constrained motion planning system
KW  - degree-of-freedom robots
KW  - motion uncertainty
KW  - state information
KW  - observation noise models
KW  - deterministic motion planning
KW  - integrated trajectory optimization
KW  - sparse roadmap framework
KW  - planning speed
KW  - high-dimensional tasks
KW  - linear-quadratic Gaussian motion planning approach
KW  - robot state probability distribution
KW  - collision risk estimation
KW  - robotic planning tasks
KW  - p-Chekov system
KW  - user-specified chance constraints
KW  - real-world planning scenarios
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Collision avoidance
KW  - Task analysis
KW  - Estimation
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793660
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.
ER  - 

TY  - CONF
TI  - Complete and Near-Optimal Path Planning for Simultaneous Sensor-Based Inspection and Footprint Coverage in Robotic Crack Filling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8812
EP  - 8818
AU  - K. Yu
AU  - C. Guo
AU  - J. Yi
PY  - 2019
KW  - filling
KW  - inspection
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - sensors
KW  - surface cracks
KW  - near-optimal path planning
KW  - robotic crack
KW  - simultaneous robotic footprint
KW  - range sensors
KW  - complete sensor coverage
KW  - planning strategy
KW  - crack-filling robotic prototype
KW  - online planning algorithm
KW  - sensor-based inspection
KW  - near-optimal footprint coverage
KW  - online sensor-based complete coverage planning
KW  - online SCC planning
KW  - Robot sensing systems
KW  - Planning
KW  - Inspection
KW  - Space exploration
KW  - Surface cracks
DO  - 10.1109/ICRA.2019.8794407
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A simultaneous robotic footprint and sensor coverage planning scheme is proposed to efficiently detect all the unknown targets with range sensors and cover the targets with the robot's footprint in a structured environment. The proposed online Sensor-based Complete Coverage (online SCC) planning minimizes the total traveling distance of the robot, guarantees the complete sensor coverage of the whole free space, and achieves near-optimal footprint coverage of all the targets. The planning strategy is applied to a crack-filling robotic prototype to detect and fill all the unknown cracks on ground surfaces. Simulation and experimental results are presented that confirm the efficiency and effectiveness of the proposed online planning algorithm.
ER  - 

TY  - CONF
TI  - Approximate Stability Analysis for Drystacked Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8819
EP  - 8824
AU  - Y. Liu
AU  - M. Saboia
AU  - V. Thangavelu
AU  - N. Napp
PY  - 2019
KW  - building materials
KW  - geometry
KW  - linear programming
KW  - mechanical stability
KW  - planning
KW  - road building
KW  - shrinkage
KW  - construction materials
KW  - contact geometry
KW  - geometric safety factor
KW  - automated dry stacking procedure
KW  - building elements
KW  - structural stability analysis
KW  - kern
KW  - shrinkage
KW  - linear programming
KW  - fully simulated shaking test
KW  - heuristics-based planning
KW  - assembly process
KW  - Stability analysis
KW  - Force
KW  - Friction
KW  - Mathematical model
KW  - Stacking
KW  - Numerical stability
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794158
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce a fast approximate stability analysis into an automated dry stacking procedure. Evaluating structural stability is essential for any type of construction, but especially challenging in techniques where building elements remain distinct and do not use fasteners or adhesives. Due to the irregular shape of construction materials, autonomous agents have restricted knowledge of contact geometry, which makes existing analysis tools difficult to deploy. In this paper, a geometric safety factor called kern is used to estimate how much the contact interface can shrink and the structure still be feasible, where feasibility can be checked efficiently using linear programming. We validate the stability measure by comparing the proposed methods with a fully simulated shaking test in 2D. We also improve existing heuristics-based planning by adding the proposed measure into the assembly process.
ER  - 

TY  - CONF
TI  - User-Guided Offline Synthesis of Robot Arm Motion from 6-DoF Paths
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8825
EP  - 8831
AU  - P. Praveena
AU  - D. Rakita
AU  - B. Mutlu
AU  - M. Gleicher
PY  - 2019
KW  - control system synthesis
KW  - end effectors
KW  - manipulator kinematics
KW  - motion control
KW  - trajectory control
KW  - orientation goals
KW  - joint-space discontinuities
KW  - user specifications
KW  - user-guided offline synthesis
KW  - robot arm motion
KW  - 6-DoF path
KW  - robot arms
KW  - end-effector
KW  - trajectories
KW  - pose goals
KW  - self-collisions
KW  - kinematic singularities
KW  - Trajectory
KW  - End effectors
KW  - Interpolation
KW  - Kinematics
KW  - Optimization
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2019.8793483
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an offline method to generate smooth, feasible motion for robot arms such that end-effector pose goals of a 6-DoF path are matched within acceptable limits specified by the user. Our approach aims to accurately match the position and orientation goals of the given path, and allows deviation from these goals if there is danger of self-collisions, joint-space discontinuities or kinematic singularities. Our method generates multiple candidate trajectories, and selects the best by incorporating sparse user input that specifies what kinds of deviations are acceptable. We apply our method to a range of challenging paths and show that our method generates solutions that achieve smooth, feasible motions while closely approximating the given pose goals and adhering to user specifications.
ER  - 

TY  - CONF
TI  - Visual Robot Task Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8832
EP  - 8838
AU  - C. Paxton
AU  - Y. Barnoy
AU  - K. Katyal
AU  - R. Arora
AU  - G. D. Hager
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - Monte Carlo methods
KW  - neural net architecture
KW  - planning (artificial intelligence)
KW  - robot vision
KW  - tree searching
KW  - visual robot task planning
KW  - visual information
KW  - planning algorithm
KW  - neural network architecture
KW  - Monte Carlo tree search
KW  - block-stacking simulation
KW  - Task analysis
KW  - Planning
KW  - Visualization
KW  - Predictive models
KW  - Robots
KW  - Transforms
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793736
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Prospection is key to solving challenging problems in new environments, but it has not been deeply explored as applied to task planning for perception-driven robotics. We propose visual robot task planning, where we take in an input image and must generate a sequence of high-level actions and associated observations that achieve some task. In this paper, we describe a neural network architecture and associated planning algorithm that (1) learns a representation of the world that can generate prospective futures, (2) uses this generative model to simulate the result of sequences of high-level actions in a variety of environments, and (3) evaluates these actions via a variant of Monte Carlo Tree Search to find a viable solution to a particular problem. Our approach allows us to visualize intermediate motion goals and learn to plan complex activity from visual information, and used this to generate and visualize task plans on held-out examples of a block-stacking simulation.
ER  - 

TY  - CONF
TI  - Towards Blended Reactive Planning and Acting using Behavior Trees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8839
EP  - 8845
AU  - M. Colledanchise
AU  - D. Almeida
AU  - P. Ögren
PY  - 2019
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - trees (mathematics)
KW  - planning algorithm
KW  - dynamic environment
KW  - solution blend acting
KW  - external disturbances
KW  - external agent
KW  - behavior trees
KW  - robotics scenarios
KW  - blended reactive planning
KW  - back chaining
KW  - Planning
KW  - Heuristic algorithms
KW  - Task analysis
KW  - Service robots
KW  - Industries
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794128
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to effectively react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.
ER  - 

TY  - CONF
TI  - Visual Representations for Semantic Target Driven Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8846
EP  - 8852
AU  - A. Mousavian
AU  - A. Toshev
AU  - M. Fišer
AU  - J. Košecká
AU  - A. Wahid
AU  - J. Davidson
PY  - 2019
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - visual representations
KW  - semantic target driven navigation
KW  - semantic visual navigation
KW  - semantic segmentation
KW  - domain adaptation
KW  - computer vision algorithms
KW  - robot
KW  - deep network
KW  - navigation policy learning
KW  - Navigation
KW  - Visualization
KW  - Semantics
KW  - Training
KW  - Adaptation models
KW  - Robots
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793493
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned policies. Both the representation and the navigation policy can be readily applied to real non-synthetic environments as demonstrated on the Active Vision Dataset [1]. Our approach successfully gets to the target in 54% of the cases in unexplored environments, compared to 46% for a non-learning based approach, and 28% for a learning-based baseline.
ER  - 

TY  - CONF
TI  - Deep Object-Centric Policies for Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8853
EP  - 8859
AU  - D. Wang
AU  - C. Devin
AU  - Q. Cai
AU  - F. Yu
AU  - T. Darrell
PY  - 2019
KW  - computer games
KW  - convolutional neural nets
KW  - data visualisation
KW  - learning (artificial intelligence)
KW  - traffic engineering computing
KW  - object-centric models
KW  - object instances
KW  - end-to-end learning
KW  - Grand Theft Auto V simulator
KW  - object-agnostic methods
KW  - object-centric policies
KW  - autonomous driving
KW  - visuomotor skills
KW  - deep neural networks
KW  - robotics tasks
KW  - intuitive visualization
KW  - Berkeley DeepDrive Video dataset
KW  - Task analysis
KW  - Training
KW  - Taxonomy
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Feature extraction
KW  - Robots
DO  - 10.1109/ICRA.2019.8794224
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While learning visuomotor skills in an end-to-end manner is appealing, deep neural networks are often uninterpretable and fail in surprising ways. For robotics tasks, such as autonomous driving, models that explicitly represent objects may be more robust to new scenes and provide intuitive visualizations. We describe a taxonomy of “object-centric” models which leverage both object instances and end-to-end learning. In the Grand Theft Auto V simulator, we show that object-centric models outperform object-agnostic methods in scenes with other vehicles and pedestrians, even with an imperfect detector. We also demonstrate that our architectures perform well on real-world environments by evaluating on the Berkeley DeepDrive Video dataset, where an object-centric model outperforms object-agnostic models in the low-data regimes.
ER  - 

TY  - CONF
TI  - Neural Autonomous Navigation with Riemannian Motion Policy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8860
EP  - 8866
AU  - X. Meng
AU  - N. Ratliff
AU  - Y. Xiang
AU  - D. Fox
PY  - 2019
KW  - collision avoidance
KW  - geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - optimal control
KW  - predictive control
KW  - robot vision
KW  - image-based autonomous navigation technique
KW  - Riemannian motion policy framework
KW  - vehicular control
KW  - deep learning
KW  - policy structure
KW  - data complexity
KW  - modeling error
KW  - end-to-end learning
KW  - neural autonomous navigation
KW  - local geometry
KW  - RMP representation
KW  - indoor obstacle avoidance
KW  - Gibson environment
KW  - optimal control commands
KW  - visual images
KW  - control point RMPs
KW  - deep neural network
KW  - Acceleration
KW  - Geometry
KW  - Autonomous robots
KW  - Measurement
KW  - Neural networks
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794223
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - End-to-end learning for autonomous navigation has received substantial attention recently as a promising method for reducing modeling error. However, its data complexity, especially around generalization to unseen environments, is high. We introduce a novel image-based autonomous navigation technique that leverages in policy structure using the Riemannian Motion Policy (RMP) framework for deep learning of vehicular control. We design a deep neural network to predict control point RMPs of the vehicle from visual images, from which the optimal control commands can be computed analytically. We show that our network trained in the Gibson environment can be used for indoor obstacle avoidance and navigation on a real RC car, and our RMP representation generalizes better to unseen environments than predicting local geometry or predicting control commands directly.
ER  - 

TY  - CONF
TI  - Two-Stage Transfer Learning for Heterogeneous Robot Detection and 3D Joint Position Estimation in a 2D Camera Image Using CNN
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8883
EP  - 8889
AU  - J. Mišeikis
AU  - I. Brijačak
AU  - S. Yahyanejad
AU  - K. Glette
AU  - O. J. Elle
AU  - J. Torresen
PY  - 2019
KW  - calibration
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - dexterous manipulators
KW  - feature extraction
KW  - image classification
KW  - image colour analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - multi-robot systems
KW  - robot vision
KW  - two-stage transfer learning approach
KW  - multiobjective convolutional neural network
KW  - heterogeneous robot arms
KW  - eye-to-hand calibration
KW  - universal robots
KW  - two-stage transfer learning
KW  - 2D colour image
KW  - collision avoidance algorithms
KW  - fixed robot-camera setups
KW  - collision detection
KW  - factory floors
KW  - collaborative robots
KW  - 2D camera image
KW  - 3D joint position estimation
KW  - heterogeneous robot detection
KW  - multiobjective CNN
KW  - data collection approach
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Cameras
KW  - Robot vision systems
KW  - Calibration
DO  - 10.1109/ICRA.2019.8794077
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collaborative robots are becoming more common on factory floors as well as regular environments, however, their safety still is not a fully solved issue. Collision detection does not always perform as expected and collision avoidance is still an active research area. Collision avoidance works well for fixed robot-camera setups, however, if they are shifted around, Eye-to-Hand calibration becomes invalid making it difficult to accurately run many of the existing collision avoidance algorithms. We approach the problem by presenting a stand-alone system capable of detecting the robot and estimating its position, including individual joints, by using a simple 2D colour image as an input, where no Eye-to-Hand calibration is needed. As an extension of previous work, a two-stage transfer learning approach is used to re-train a multi-objective convolutional neural network (CNN) to allow it to be used with heterogeneous robot arms. Our method is capable of detecting the robot in real-time and new robot types can be added by having significantly smaller training datasets compared to the requirements of a fully trained network. We present data collection approach, the structure of the multi-objective CNN, the two-stage transfer learning training and test results by using real robots from Universal Robots, Kuka, and Franka Emika. Eventually, we analyse possible application areas of our method together with the possible improvements.
ER  - 

TY  - CONF
TI  - 3D Control of Rotating Millimeter-Scale Swimmers Through Obstacles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8890
EP  - 8896
AU  - J. Leclerc
AU  - H. Zhao
AU  - A. T. Becker
PY  - 2019
KW  - biomechanics
KW  - biomedical equipment
KW  - blood
KW  - blood vessels
KW  - medical control systems
KW  - propulsion
KW  - swimmer designs
KW  - rotating millimeter-scale swimmers
KW  - aorta
KW  - blood clot
KW  - rotational movement
KW  - high speed 3D navigation
KW  - Arteries
KW  - Electromagnets
KW  - Force
KW  - Trajectory
KW  - Manipulators
KW  - Velocity control
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794045
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study investigates the high speed 3D navigation of rotating millimeter-scale swimmers. The swimmers have a spiral-shaped surface to ensure propulsion. The rotational movement is used for propulsion and, in future work, could provide the power needed to remove blood clots. For instance, an abrasive tip could be used to progressively grind a blood clot. An algorithm to perform 3D control of rotating millimeter-scale swimmers was implemented and tested experimentally. The swimmers can follow a trajectory and can navigate without touching the walls inside a tube having a diameter of 15 mm. This diameter is smaller than the average diameter of the distal descending aorta, which is the smallest section of the aorta. Several swimmers designs were built and tested. The maximum velocity recorded for our best swimmer was 103.6 mm/s with a rotational speed of 477.5 rotations per second.
ER  - 

TY  - CONF
TI  - Automatic Optical Coherence Tomography Imaging of Stationary and Moving Eyes with a Robotically-Aligned Scanner
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8897
EP  - 8903
AU  - M. Draelos
AU  - P. Ortiz
AU  - R. Qian
AU  - B. Keller
AU  - K. Hauser
AU  - A. Kuo
AU  - J. Izatt
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - eye
KW  - medical image processing
KW  - medical robotics
KW  - optical tomography
KW  - pupil tracking accuracy
KW  - tracking bandwidth
KW  - optical coherence tomography imaging
KW  - sub-millimeter eye tracking accuracy
KW  - tracking eyes
KW  - stationary eyes
KW  - commercial robot arm
KW  - fast axial tracking
KW  - reference arm adjustment
KW  - fine alignment
KW  - stereo pupil cameras
KW  - coarse pupil cameras
KW  - fixed-base RGB-D cameras
KW  - automatic eye imaging
KW  - OCT scanner capable
KW  - ophthalmology offices
KW  - OCT screening
KW  - unconscious patients
KW  - OCT diagnostics
KW  - ophthalmic photographers
KW  - chinrest stabilization
KW  - tabletop instruments
KW  - clinical ophthalmic OCT systems
KW  - robotically-aligned scanner
KW  - size 12.0 mum
KW  - time 83.2 ms
KW  - frequency 9.7 Hz
KW  - Cameras
KW  - Tracking
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Face
KW  - Medical robotics
KW  - optical coherence tomography
KW  - image stabilization
DO  - 10.1109/ICRA.2019.8793524
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Optical coherence tomography (OCT) has found great success in ophthalmology where it plays a key role in screening and diagnostics. Clinical ophthalmic OCT systems are typically deployed as tabletop instruments that require chinrest stabilization and trained ophthalmic photographers to operate. These requirements preclude OCT diagnostics in bedbound or unconscious patients who cannot use a chinrest, and restrict OCT screening to ophthalmology offices. We present a robotically-aligned OCT scanner capable of automatic eye imaging without chinrests. The scanner features eye tracking from fixed-base RGB-D cameras for coarse and stereo pupil cameras for fine alignment, as well as galvanometer aiming for fast lateral tracking, reference arm adjustment for fast axial tracking, and a commercial robot arm for slow lateral and axial tracking. We demonstrate the system's performance autonomously aligning with stationary eyes, pursuing moving eyes, and tracking eyes undergoing physiologic motion. The system demonstrates sub-millimeter eye tracking accuracy, 12 μm lateral pupil tracking accuracy, 83.2 ms stabilization time following step disturbance, and 9.7 Hz tracking bandwidth.
ER  - 

TY  - CONF
TI  - Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8936
EP  - 8942
AU  - E. Vidal
AU  - M. Moll
AU  - N. Palomeras
AU  - J. D. Hernández
AU  - M. Carreras
AU  - L. E. Kavraki
PY  - 2019
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - trajectory control
KW  - vehicle dynamics
KW  - underwater robot
KW  - online multilayered motion planning
KW  - autonomous underwater vehicles
KW  - loosely coupled multilayered planning design
KW  - motion planner
KW  - hydro-dynamic forces
KW  - trajectory planning
KW  - robots onboard computer
KW  - AUVs
KW  - inevitable collision states
KW  - Planning
KW  - Trajectory
KW  - Lead
KW  - Vehicle dynamics
KW  - Robots
KW  - Dynamics
KW  - Unmanned underwater vehicles
DO  - 10.1109/ICRA.2019.8794009
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Underwater robots are subject to complex hydro-dynamic forces. These forces define how the vehicle moves, so it is important to consider them when planning trajectories. However, performing motion planning considering the dynamics on the robot's onboard computer is challenging due to the limited computational resources available. In this paper an efficient motion planning framework for autonomous underwater vehicles (AUVs) is presented. By introducing a loosely coupled multilayered planning design, our framework is able to generate dynamically feasible trajectories while keeping the planning time low enough for online planning. First, a fast path planner operating in a lower-dimensional projected space computes a lead path from the start to the goal configuration. Then, the lead path is used to bias the sampling of a second motion planner, which takes into account all the dynamic constraints. Furthermore, we propose a strategy for online planning that saves computational resources by generating the final trajectory only up to a finite horizon. By using the finite horizon strategy together with the multilayered approach, the sampling of the second planner focuses on regions where good quality solutions are more likely to be found, significantly reducing the planning time. To provide strong safety guarantees our framework also incorporates the conservative approximations of inevitable collision states (icss). finally, we present simulations and experiments using a real underwater robot to demonstrate the capabilities of our framework.
ER  - 

TY  - CONF
TI  - Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8943
EP  - 8950
AU  - M. A. Lee
AU  - Y. Zhu
AU  - K. Srinivasan
AU  - P. Shah
AU  - S. Savarese
AU  - L. Fei-Fei
AU  - A. Garg
AU  - J. Bohg
PY  - 2019
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - haptic feedback
KW  - visual feedback
KW  - robot controller
KW  - deep reinforcement learning
KW  - high-dimensional inputs
KW  - sample complexity
KW  - multimodal representation
KW  - sensory inputs
KW  - policy learning
KW  - peg insertion task
KW  - self-supervised learning
KW  - multimodal representations
KW  - contact-rich manipulation tasks
KW  - Task analysis
KW  - Robot sensing systems
KW  - Haptic interfaces
KW  - Visualization
KW  - Geometry
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8793485
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.
ER  - 

TY  - CONF
TI  - Deep Visuo-Tactile Learning: Estimation of Tactile Properties from Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8951
EP  - 8957
AU  - K. Takahashi
AU  - J. Tan
PY  - 2019
KW  - control engineering computing
KW  - end effectors
KW  - feature extraction
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - tactile sensors
KW  - visual perception
KW  - deep visuo-tactile learning
KW  - tactile sensor data
KW  - Webcam
KW  - tactile properties
KW  - visual perception
KW  - encoder-decoder network
KW  - latent variables
KW  - tactile features
KW  - visual features
KW  - RGB images
KW  - uSkin tactile sensor
KW  - end-effector
KW  - feature space
KW  - Sawyer robot
KW  - Tactile sensors
KW  - Training
KW  - Time series analysis
KW  - Decoding
DO  - 10.1109/ICRA.2019.8794285
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Estimation of tactile properties from vision, such as slipperiness or roughness, is important to effectively interact with the environment. These tactile properties help us decide which actions we should choose and how to perform them. E.g., we can drive slower if we see that we have bad traction or grasp tighter if an item looks slippery. We believe that this ability also helps robots to enhance their understanding of the environment, and thus enables them to tailor their actions to the situation at hand. We therefore propose a model to estimate the degree of tactile properties from visual perception alone (e.g., the level of slipperiness or roughness). Our method extends a encoder-decoder network, in which the latent variables are visual and tactile features. In contrast to previous works, our method does not require manual labeling, but only RGB images and the corresponding tactile sensor data. All our data is collected with a webcam and uSkin tactile sensor mounted on the end-effector of a Sawyer robot, which strokes the surfaces of 25 different materials. We show that our model generalizes to materials not included in the training data by evaluating the feature space, indicating that it has learned to associate important tactile properties with images.
ER  - 

TY  - CONF
TI  - Variational End-to-End Navigation and Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8958
EP  - 8964
AU  - A. Amini
AU  - G. Rosman
AU  - S. Karaman
AU  - D. Rus
PY  - 2019
KW  - cameras
KW  - Global Positioning System
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - probability
KW  - variational techniques
KW  - point-topoint navigation algorithms
KW  - full-scale autonomous vehicle
KW  - localization algorithm
KW  - variational end-to-end navigation
KW  - deep learning
KW  - autonomous vehicle control
KW  - raw sensory data
KW  - navigation instruction
KW  - end-to-end driving networks
KW  - point-to-point navigation
KW  - probabilistic localization
KW  - noisy GPS data
KW  - raw camera data
KW  - higher level roadmaps
KW  - probability distribution
KW  - deterministic control command
KW  - rough localization
KW  - real-world driving data
KW  - variational network
KW  - Navigation
KW  - Roads
KW  - Cameras
KW  - Robot sensing systems
KW  - Visualization
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2019.8793579
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep learning has revolutionized the ability to learn “end-to-end” autonomous vehicle control directly from raw sensory data. While there have been recent extensions to handle forms of navigation instruction, these works are unable to capture the full distribution of possible actions that could be taken and to reason about localization of the robot within the environment. In this paper, we extend end-to-end driving networks with the ability to perform point-to-point navigation as well as probabilistic localization using only noisy GPS data. We define a novel variational network capable of learning from raw camera data of the environment as well as higher level roadmaps to predict (1) a full probability distribution over the possible control commands; and (2) a deterministic control command capable of navigating on the route specified within the map. Additionally, we formulate how our model can be used to localize the robot according to correspondences between the map and the observed visual road topology, inspired by the rough localization that human drivers can perform. We test our algorithms on real-world driving data that the vehicle has never driven through before, and integrate our point-topoint navigation algorithms onboard a full-scale autonomous vehicle for real-time performance. Our localization algorithm is also evaluated over a new set of roads and intersections to demonstrates rough pose localization even in situations without any GPS prior.
ER  - 

TY  - CONF
TI  - Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8973
EP  - 8979
AU  - Y. Chebotar
AU  - A. Handa
AU  - V. Makoviychuk
AU  - M. Macklin
AU  - J. Issac
AU  - N. Ratliff
AU  - D. Fox
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - real world experience
KW  - simulation parameter distribution
KW  - policy training
KW  - policy transfer
KW  - policy behavior
KW  - sim-to-real loop
KW  - simulation randomization
KW  - swing-peg-in-hole
KW  - cabinet drawer opening
KW  - Adaptation models
KW  - Training
KW  - Data models
KW  - Robots
KW  - Computational modeling
KW  - Trajectory
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793789
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of transferring policies to the real world by training on a distribution of simulated scenarios. Rather than manually tuning the randomization of simulations, we adapt the simulation parameter distribution using a few real world roll-outs interleaved with policy training. In doing so, we are able to change the distribution of simulations to improve the policy transfer by matching the policy behavior in simulation and the real world. We show that policies trained with our method are able to reliably transfer to different robots in two real world tasks: swing-peg-in-hole and opening a cabinet drawer. The video of our experiments can be found at https://sites.google.com/view/simopt.
ER  - 

TY  - CONF
TI  - Robotic Orientation Control of Deformable Cells
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8980
EP  - 8985
AU  - C. Dai
AU  - Z. Zhang
AU  - Y. Lu
AU  - G. Shan
AU  - X. Wang
AU  - Q. Zhao
AU  - Y. Sun
PY  - 2019
KW  - biomechanics
KW  - cellular biophysics
KW  - deformation
KW  - manipulators
KW  - medical robotics
KW  - mobile robots
KW  - neurocontrollers
KW  - path planning
KW  - position control
KW  - robotic orientation control
KW  - deformable cells
KW  - robotic manipulation
KW  - deformable objects
KW  - rigid objects
KW  - robotics
KW  - deformable synthetic objects
KW  - rubber balls
KW  - clothes
KW  - biological cells
KW  - manual cell rotation control
KW  - robotic approach
KW  - mathematical modeling
KW  - path planning
KW  - minimal cell deformation
KW  - cell damage
KW  - force model
KW  - minimal force
KW  - contact mechanics model
KW  - manipulation path
KW  - compensation controller
KW  - oocyte orientation control
KW  - maximum oocyte deformation
KW  - Position control
KW  - Strain
KW  - Force
KW  - Robots
KW  - Shape
KW  - Path planning
KW  - Standards
DO  - 10.1109/ICRA.2019.8793986
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic manipulation of deformable objects (vs. rigid objects) has been a classic topic in robotics. Compared to deformable synthetic objects such as rubber balls and clothes, biological cells are highly deformable and more prone to damage. This paper presents robotic manipulation of deformable cells for orientation control (both out-of-plane and in-plane), which is required in both clinical (e.g., in vitro fertilization) and biomedical (e.g., clone) applications. Compared to manual cell rotation control based on empirical experience, the robotic approach, based on mathematical modeling and path planning, effectively rotates a cell while consistently maintaining minimal cell deformation to avoid cell damage. A force model is established to determine the minimal force applied by the micropipette to rotate a spherical or more generally, an ellipsoidal mouse oocyte. The force information is translated into indentation through a contact mechanics model, and the manipulation path of the micropipette is formed by connecting the indentation positions on the oocyte. A compensation controller is designed to compensate for the variations of mechanical properties across cells. The polar body of an oocyte is detected by deep neural networks with robustness to shape and size differences. Experimental results demonstrate that the system achieved an accuracy of 97.6% in polar body detection and an accuracy of 0.7° in oocyte orientation control with maximum oocyte deformation of 2.69 μm.
ER  - 

TY  - CONF
TI  - Drift-free Roll and Pitch Estimation for High-acceleration Hopping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8986
EP  - 8992
AU  - J. K. Yim
AU  - E. K. Wang
AU  - R. S. Fearing
PY  - 2019
KW  - acceleration control
KW  - attitude control
KW  - gyroscopes
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - stability
KW  - velocity control
KW  - monopedal jumping robots
KW  - onboard rate gyroscopes
KW  - encoders
KW  - attitude estimate disturbances
KW  - onboard velocity estimation
KW  - extreme stance accelerations
KW  - high-acceleration hopping
KW  - untethered robot
KW  - drift-free roll and pitch estimation
KW  - drift-free roll and pitch attitude estimation scheme
KW  - fully autonomous stable hopping control
KW  - rectangular path
KW  - onboard dead-reckoning
KW  - human wireless joystick direction
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Attitude control
KW  - Estimation
KW  - Gyroscopes
DO  - 10.1109/ICRA.2019.8793259
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We develop a drift-free roll and pitch attitude estimation scheme for monopedal jumping robots. The estimator uses only onboard rate gyroscopes and encoders and does not rely on external sensing or processing. It is capable of recovering from attitude estimate disturbances and, together with onboard velocity estimation, enables fully autonomous stable hopping control. The estimator performs well on a small untethered robot capable of large jumps and extreme stance accelerations. We demonstrate that the robot can follow a rectangular path using onboard dead-reckoning with less than 2 meters of drift over 200 seconds and 300 jumps covering 60 m. We also demonstrate that the robot can operate untethered outdoors under human wireless joystick direction.
ER  - 

TY  - CONF
TI  - Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8993
EP  - 8999
AU  - K. He
AU  - A. M. Wells
AU  - L. E. Kavraki
AU  - M. Y. Vardi
PY  - 2019
KW  - binary decision diagrams
KW  - mobile robots
KW  - pick-and-place tasks
KW  - binary decision diagram
KW  - UR5 robot
KW  - efficient symbolic reactive synthesis
KW  - compositional approach
KW  - explicit state approach
KW  - finite-horizon tasks
KW  - Task analysis
KW  - Robots
KW  - Planning
KW  - Games
KW  - Robotic assembly
KW  - Semantics
KW  - Binary decision diagrams
DO  - 10.1109/ICRA.2019.8794170
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When humans and robots perform complex tasks together, the robot must have a strategy to choose its actions based on observed human behavior. One well-studied approach for finding such strategies is reactive synthesis. Existing approaches for finite-horizon tasks have used an explicit state approach, which incurs high runtime. In this work, we present a compositional approach to perform synthesis for finite-horizon tasks based on binary decision diagrams. We show that for pick-and-place tasks, the compositional approach achieves orders-of-magnitude speed-ups compared to previous approaches. We demonstrate the synthesized strategy on a UR5 robot.
ER  - 

TY  - CONF
TI  - Combined Task and Motion Planning under Partial Observability: An Optimization-Based Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9000
EP  - 9006
AU  - C. Phiquepal
AU  - M. Toussaint
PY  - 2019
KW  - computational complexity
KW  - decision trees
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - partial observability
KW  - optimization-based approach
KW  - compute optimal plans
KW  - symbolic decision tree
KW  - path tree
KW  - optimal motion
KW  - independent optimizations
KW  - combined task and motion planning
KW  - optimization-based TAMP methods
KW  - Trajectory
KW  - Planning
KW  - Optimization
KW  - Observability
KW  - Task analysis
KW  - Robots
KW  - Decision trees
DO  - 10.1109/ICRA.2019.8793260
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel approach to Combined Task and Motion Planning (TAMP) under partial observability. Previous optimization-based TAMP methods [1][2] compute optimal plans and paths assuming full observability. However, partial observability requires the solution to be a policy that reacts to the observations that the agent receives. We consider a formulation where observations introduce additional branching in the symbolic decision tree. The solution is now given by a reactive policy on the symbolic level together with a path tree that describes the branchings of optimal motion depending on the observations. Our method works in two stages: First, the symbolic policy is optimized using approximate path costs estimated from independent optimizations of trajectory pieces. Second, we fix the best symbolic policy and optimize a joint trajectory tree. We test our approach on object manipulation and autonomous driving examples. We also compare the algorithm's performance to a state-of-the-art TAMP planner in fully observable cases.
ER  - 

TY  - CONF
TI  - Towards Robust Product Packing with a Minimalistic End-Effector
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9007
EP  - 9013
AU  - R. Shome
AU  - W. N. Tang
AU  - C. Song
AU  - C. Mitash
AU  - H. Kourtev
AU  - J. Yu
AU  - A. Boularias
AU  - K. E. Bekris
PY  - 2019
KW  - design engineering
KW  - end effectors
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - warehouse automation
KW  - object detection algorithms
KW  - manipulation primitives
KW  - cubic objects
KW  - vacuum-based end-effector
KW  - single robot arm
KW  - RGB-D data
KW  - failure conditions
KW  - robust pipeline
KW  - unstructured piles
KW  - packing tasks
KW  - order fulfillment
KW  - warehouse automation
KW  - hardware designs
KW  - sensor technologies
KW  - minimalistic end-effector
KW  - towards robust product packing
KW  - End effectors
KW  - Task analysis
KW  - Robot sensing systems
KW  - Pipelines
KW  - Three-dimensional displays
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793966
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Advances in sensor technologies, object detection algorithms, planning frameworks and hardware designs have motivated the deployment of robots in warehouse automation. A variety of such applications, like order fulfillment or packing tasks, require picking objects from unstructured piles and carefully arranging them in bins or containers. Desirable solutions need to be low-cost, easily deployable and controllable, making minimalistic hardware choices desirable. The challenge in designing an effective solution to this problem relates to appropriately integrating multiple components, so as to achieve a robust pipeline that minimizes failure conditions. The current work proposes a complete pipeline for solving such packing tasks, given access only to RGB-D data and a single robot arm with a vacuum-based end-effector, which is also used as a pushing finger. To achieve the desired level of robustness, three key manipulation primitives are identified, which take advantage of the environment and simple operations to successfully pack multiple cubic objects. The overall approach is demonstrated to be robust to execution and perception errors. The impact of each manipulation primitive is evaluated by considering different versions of the proposed pipeline, which incrementally introduce reasoning about object poses and corrective manipulation actions.
ER  - 

TY  - CONF
TI  - Gesture Recognition Via Flexible Capacitive Touch Electrodes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9028
EP  - 9034
AU  - L. J. Dankovich
AU  - S. Bergbreiter
PY  - 2019
KW  - biomechanics
KW  - biomedical electrodes
KW  - biomedical measurement
KW  - Bluetooth
KW  - capacitive sensors
KW  - gesture recognition
KW  - medical computing
KW  - microcontrollers
KW  - random forests
KW  - skin
KW  - tactile sensors
KW  - gesture recognition accuracy
KW  - basic finger
KW  - flexible capacitive touch electrodes
KW  - classification algorithms
KW  - random forest algorithm
KW  - wrist motions
KW  - Cutkosky Grasp Taxonomy
KW  - bluetooth transceiver
KW  - microcontroller
KW  - elbow
KW  - wireless wearable device
KW  - Electrodes
KW  - Muscles
KW  - Capacitance
KW  - Gesture recognition
KW  - Sensors
KW  - Wrist
KW  - Skin
DO  - 10.1109/ICRA.2019.8794202
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A novel wearable device for gesture recognition was developed and tested on five subjects. The low-cost, wireless wearable device was engineered with a set of seven flexible capacitive touch electrodes sewn into an armband to be worn on the forearm between the wrist and elbow. These capacitive touch electrodes were interfaced with a microcontroller and bluetooth transceiver for measurement and transmission. As different gestures are made, flexing muscles beneath the skin affect the capacitance measured on these seven electrodes. A set of 32 gestures were tested including the 16 grasps in the Cutkosky Grasp Taxonomy and 16 basic finger and wrist motions. Several classification algorithms were tested on this data. Using a Random Forest (RF) algorithm to classify the training data, an average gesture recognition accuracy of 95.6 ± 0.06% was achieved across all five subjects individually.
ER  - 

TY  - CONF
TI  - Robust Learning of Tactile Force Estimation through Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9035
EP  - 9042
AU  - B. Sundaralingam
AU  - A. S. Lambert
AU  - A. Handa
AU  - B. Boots
AU  - T. Hermans
AU  - S. Birchfield
AU  - N. Ratliff
AU  - D. Fox
PY  - 2019
KW  - control engineering computing
KW  - force feedback
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robots
KW  - tactile sensors
KW  - learned force model
KW  - robust learning
KW  - tactile force estimation
KW  - robot interaction
KW  - analytic models
KW  - robust model
KW  - SynTouch BioTac sensor
KW  - neural networks
KW  - voxelized input feature layer
KW  - spatial signals
KW  - sensor surface
KW  - robust tactile force model
KW  - force torque sensor
KW  - FT sensor
KW  - force inference
KW  - planar pushing task
KW  - force direction
KW  - force estimation
KW  - tactile sensor signals
KW  - force feedback grasp controller
KW  - Force
KW  - Robot sensing systems
KW  - Biological system modeling
KW  - Task analysis
KW  - Biosensors
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793502
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Current methods for estimating force from tactile sensor signals are either inaccurate analytic models or task-specific learned models. In this paper, we explore learning a robust model that maps tactile sensor signals to force. We specifically explore learning a mapping for the SynTouch BioTac sensor via neural networks. We propose a voxelized input feature layer for spatial signals and leverage information about the sensor surface to regularize the loss function. To learn a robust tactile force model that transfers across tasks, we generate ground truth data from three different sources: (1) the BioTac rigidly mounted to a force torque (FT) sensor, (2) a robot interacting with a ball rigidly attached to the same FT sensor, and (3) through force inference on a planar pushing task by formalizing the mechanics as a system of particles and optimizing over the object motion. A total of 140k samples were collected from the three sources. We achieve a median angular accuracy of 3.5 degrees in predicting force direction (66% improvement over the current state of the art) and a median magnitude accuracy of 0.06 N (93% improvement) on a test dataset. Additionally, we evaluate the learned force model in a force feedback grasp controller performing object lifting and gentle placement. Our results can be found on https: //sites.google.com/view/tactile-force.
ER  - 

TY  - CONF
TI  - Soft Robotic Glove with Integrated Sensing for Intuitive Grasping Assistance Post Spinal Cord Injury
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9059
EP  - 9065
AU  - Y. M. Zhou
AU  - D. Wagner
AU  - K. Nuckols
AU  - R. Heimgartner
AU  - C. Correia
AU  - M. Clarke
AU  - D. Orzel
AU  - C. O’Neill
AU  - R. Solinsky
AU  - S. Paganoni
AU  - C. J. Walsh
PY  - 2019
KW  - biomechanics
KW  - capacitive sensors
KW  - data gloves
KW  - elastomers
KW  - handicapped aids
KW  - injuries
KW  - neurophysiology
KW  - patient rehabilitation
KW  - soft robotic glove
KW  - integrated sensing
KW  - intuitive grasping assistance post spinal cord injury
KW  - multiarticular textile actuators
KW  - custom soft sensors
KW  - intuitive state machine intent detection controller
KW  - pressurized actuators
KW  - natural human fingers
KW  - textile-elastomer capacitive sensors
KW  - finger flexion
KW  - intuitive user control
KW  - state machine controller
KW  - integrated sensors
KW  - hand-object interactions
KW  - injury levels
KW  - inadvertent grasp triggers
KW  - Actuators
KW  - Force
KW  - Sensor phenomena and characterization
KW  - Textiles
KW  - Capacitive sensors
KW  - Strain
DO  - 10.1109/ICRA.2019.8794367
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a fully-integrated soft robotic glove with multi-articular textile actuators, custom soft sensors, and an intuitive state machine intent detection controller. We demonstrate that the pressurized actuators can generate motion and force comparable to natural human fingers through bench-top testing. We apply textile-elastomer capacitive sensors to the glove to track finger flexion via strain and detect contact with objects via force. Intuitive user control is achieved via a state machine controller based on signals from the integrated sensors to detect relative changes in hand-object interactions. Results from an initial evaluation with 3 participants with spinal cord injury (SCI), of varied injury levels and years since injury, wearing and controlling the glove show an average of 87% improvement in grasping force, and improvements in functional assessments for participants with recent injuries. A significant variation in response suggests further investigation is required to understand the adaptation needed across different injury levels and durations since injury. Additionally, we evaluate the controller and find an average of 3 seconds from user initiations to completed grasps, and 10% inadvertent grasp triggers and no false releases when objects are held.
ER  - 

TY  - CONF
TI  - Shape Sensing of Variable Stiffness Soft Robots using Electrical Impedance Tomography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9066
EP  - 9072
AU  - J. Avery
AU  - M. Runciman
AU  - A. Darzi
AU  - G. P. Mylonas
PY  - 2019
KW  - biological tissues
KW  - computerised tomography
KW  - electric impedance imaging
KW  - electric impedance measurement
KW  - image reconstruction
KW  - medical robotics
KW  - pneumatic actuators
KW  - surgery
KW  - tomography
KW  - reduced contact trauma
KW  - soft tissues
KW  - tortuous paths
KW  - minimally invasive surgery
KW  - intraoperative shape sensing
KW  - proprioceptive soft actuator
KW  - self-sensing
KW  - electrically conductive working fluid
KW  - tomographic reconstructions
KW  - two-degree-of-freedom designs
KW  - hydraulic hinged actuator
KW  - pneumatic finger actuator
KW  - EIT images
KW  - FDM-EIT
KW  - shape sensor
KW  - variable stiffness soft robots
KW  - electrical impedance tomography
KW  - deformability
KW  - electrical impedance measurements
KW  - frequency division multiplexed EIT system
KW  - temporal resolution
KW  - Electrodes
KW  - Tomography
KW  - Actuators
KW  - Welding
KW  - Shape
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793862
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robotic systems offer benefits over traditional rigid systems through reduced contact trauma with soft tissues and by enabling access through tortuous paths in minimally invasive surgery. However, the inherent deformability of soft robots places both a greater onus on accurate modelling of their shape, and greater challenges in realising intraoperative shape sensing. Herein we present a proprioceptive (self-sensing) soft actuator, with an electrically conductive working fluid. Electrical impedance measurements from up to six electrodes enabled tomographic reconstructions using Electrical Impedance Tomography (EIT). A new Frequency Division Multiplexed (FDM) EIT system was developed capable of measurements of 66 dB SNR with 20 ms temporal resolution. The concept was examined in two two-degree-of-freedom designs: a hydraulic hinged actuator and a pneumatic finger actuator with hydraulic beams. Both cases demonstrated that impedance measurements could be used to infer shape changes, and EIT images reconstructed during actuation showed distinct patterns with respect to each degree of freedom (DOF). Whilst there was some mechanical hysteresis observed, the repeatability of the measurements and resultant images was high. The results show the potential of FDM-EIT as a low-cost, low profile shape sensor in soft robots.
ER  - 

TY  - CONF
TI  - Adaptive Control of Sclera Force and Insertion Depth for Safe Robot-Assisted Retinal Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9073
EP  - 9079
AU  - A. Ebrahimi
AU  - N. Patel
AU  - C. He
AU  - P. Gehlbach
AU  - M. Kobilarov
AU  - I. Iordachita
PY  - 2019
KW  - adaptive control
KW  - biological tissues
KW  - eye
KW  - force feedback
KW  - force sensors
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - 1-dimensional adaptive control method
KW  - 3-dimensional control
KW  - sclera force components
KW  - tool insertion depth
KW  - velocity-controlled Johns Hopkins Steady-Hand Eye Robot
KW  - safe robot-assisted retinal surgery
KW  - surgical tools
KW  - force feedback
KW  - tool-to-eye interactions
KW  - robotic light pipe holding
KW  - Robot kinematics
KW  - Surgery
KW  - Force
KW  - Tools
KW  - Adaptive control
KW  - Retina
DO  - 10.1109/ICRA.2019.8793658
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the significant challenges of moving from manual to robot-assisted retinal surgery is the loss of perception of forces applied to the sclera (sclera forces) by the surgical tools. This damping of force feedback is primarily due to the stiffness and inertia of the robot. The diminished perception of tool-to-eye interactions might put the eye tissue at high risk of injury due to excessive sclera forces or extreme insertion of the tool into the eye. In the present study therefore a 1-dimensional adaptive control method is customized for 3-dimensional control of sclera force components and tool insertion depth and then implemented on the velocity-controlled Johns Hopkins Steady-Hand Eye Robot. The control method enables the robot to perform autonomous motions to make the sclera force and/or insertion depth of the tool tip to follow pre-defined desired and safe trajectories when they exceed safe bounds. A robotic light pipe holding application in retinal surgery is also investigated using the adaptive control method. The implementation results indicate that the adaptive control is able to achieve the imposed safety margins and prevent sclera forces and insertion depth from exceeding safe boundaries.
ER  - 

TY  - CONF
TI  - Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9080
EP  - 9086
AU  - H. Zhu
AU  - J. Juhl
AU  - L. Ferranti
AU  - J. Alonso-Mora
PY  - 2019
KW  - collision avoidance
KW  - distributed control
KW  - graph theory
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - distributed consensus
KW  - obstacle-free convex regions
KW  - distributed multirobot formation splitting
KW  - distributed multirobot formation merging
KW  - moving obstacles
KW  - static obstacles
KW  - intersection graph
KW  - quadrotors
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Merging
KW  - Navigation
KW  - Partitioning algorithms
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793765
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a distributed method for splitting and merging of multi-robot formations in dynamic environments with static and moving obstacles. Splitting and merging actions rely on distributed consensus and can be performed to avoid obstacles. Our method accounts for the limited communication range and visibility radius of the robots and relies on the communication of obstacle-free convex regions and the computation of an intersection graph. In addition, our method is able to detect and recover from (permanent and temporary) communication and motion faults. Finally, we demonstrate the applicability and scalability of the proposed method in simulations with up to sixteen quadrotors and real-world experiments with a team of four quadrotors.
ER  - 

TY  - CONF
TI  - Eagle Shoal: A new designed modular tactile sensing dexterous hand for domestic service robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9087
EP  - 9093
AU  - T. Wang
AU  - Z. Geng
AU  - B. Kang
AU  - X. Luo
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - feature extraction
KW  - object detection
KW  - service robots
KW  - tactile sensors
KW  - domestic service robots
KW  - control boards
KW  - tactile sensor unit
KW  - hand features
KW  - visual data
KW  - tactile data
KW  - Eagle Shoal
KW  - modular tactile sensing dexterous hand
KW  - fully-actuated hand
KW  - embedded tactile sensors
KW  - 2 degrees of freedom
KW  - DOFs
KW  - perceive continuous vibration data
KW  - grasp ability
KW  - consumer market
KW  - robotic manipulation research
KW  - Force
KW  - Tactile sensors
KW  - Piezoelectric transducers
KW  - Sensor arrays
DO  - 10.1109/ICRA.2019.8793842
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a new designed modular tactile sensing dexterous hand for domestic service robots. This fully-actuated hand consists of 1 palm and 3 fingers, with embedded tactile sensors, motors and control boards. The palm and each finger have 2 degrees of freedom (DOFs). The modular design makes it easy to attach and detach the hand, even by inexperienced users. The tactile sensor unit with new structure can help to decrease sensor number and keep a good sensing ability. A series of experiments to test the sensor unit and evaluated the hand performance with an object set was performed in this paper. The results show that the sensor unit can provide precise sensing result and perceive continuous vibration data, and the hand has excellent grasp ability. In addition to its good performance, the hand features a cost of $500 USD with a scale of one hundred sets. This hand is affordable for researchers and for domestic service robots in the consumer market. In future research, this hand will be used to promote the robotic manipulation research based on visual and tactile data.
ER  - 

TY  - CONF
TI  - Learning Scene Geometry for Visual Localization in Challenging Conditions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9094
EP  - 9100
AU  - N. Piasco
AU  - D. Sidibé
AU  - V. Gouet-Brunet
AU  - C. Demonceaux
PY  - 2019
KW  - feature extraction
KW  - image colour analysis
KW  - image retrieval
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - daytime images
KW  - learning scene geometry
KW  - visual localization
KW  - outdoor large scale image
KW  - cross-season
KW  - learned global image descriptor
KW  - scene geometry information
KW  - depth map
KW  - query image
KW  - localization accuracy
KW  - cross-weather
KW  - long-term localization scenario
KW  - night images
KW  - winter localization sequence
KW  - summer localization sequence
KW  - Training
KW  - Decoding
KW  - Feature extraction
KW  - Robots
KW  - Image reconstruction
KW  - Geometry
KW  - Visualization
DO  - 10.1109/ICRA.2019.8794221
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a new approach for outdoor large scale image based localization that can deal with challenging scenarios like cross-season, cross-weather, day/night and long-term localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We are able to increase recall@1 performances by 2.15% on cross-weather and long-term localization scenario and by 4.24% points on a challenging winter/summer localization sequence versus state-of-the-art methods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images.
ER  - 

TY  - CONF
TI  - Multi-Robot Region-of-Interest Reconstruction with Dec-MCTS
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9101
EP  - 9107
AU  - F. Sukkar
AU  - G. Best
AU  - C. Yoo
AU  - R. Fitch
PY  - 2019
KW  - manipulators
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - tree searching
KW  - motion planning
KW  - high-dimensional configuration space
KW  - multirobot region-of-interest reconstruction
KW  - dec-MCTS
KW  - multiple robot arms
KW  - RGB-D sensors
KW  - precision agriculture
KW  - infrastructure inspection
KW  - viewpoint evaluation function
KW  - nonmyopic planning algorithm
KW  - decentralised Monte Carlo tree search
KW  - navigation graph
KW  - fruit detection
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Manipulators
KW  - Planning
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793560
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of reconstructing regions of interest of a scene using multiple robot arms and RGB-D sensors. This problem is motivated by a variety of applications, such as precision agriculture and infrastructure inspection. A viewpoint evaluation function is presented that exploits predicted observations and the geometry of the scene. A recently proposed non-myopic planning algorithm, Decentralised Monte Carlo tree search, is used to coordinate the actions of the robot arms. Motion planning is performed over a navigation graph that considers the high-dimensional configuration space of the robot arms. Extensive simulated experiments are carried out using real sensor data and then validated on hardware with two robot arms. Our proposed targeted information gain planner is compared to state-of-the-art baselines and outperforms them in every measured metric. The robots quickly observe and accurately detect fruit in a trellis structure, demonstrating the viability of the approach for real-world applications.
ER  - 

TY  - CONF
TI  - Design and Control of a Passively Morphing Quadcopter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9116
EP  - 9122
AU  - N. Bucki
AU  - M. W. Mueller
PY  - 2019
KW  - aerospace components
KW  - design engineering
KW  - helicopters
KW  - hinges
KW  - nonlinear dynamical systems
KW  - position control
KW  - propellers
KW  - passively morphing quadcopter
KW  - passive rotary joints
KW  - rapid aerial morphing
KW  - sprung hinges
KW  - nonmorphing quadcopter
KW  - quadcopter controllers
KW  - trajectory generation algorithms
KW  - control inputs
KW  - gap traversal maneuvers
KW  - rigid connections
KW  - quadcopter design
KW  - propellers
KW  - nonlinear dynamics
KW  - Propellers
KW  - Vehicle dynamics
KW  - Springs
KW  - Force
KW  - Fasteners
KW  - Dynamics
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794373
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel quadcopter design that uses passive rotary joints to enable rapid aerial morphing without the use of additional actuators. The normally rigid connections between the arms of the quadcopter and the central body are replaced by sprung hinges that allow for the arms of the quadcopter to fold downward when low thrusts are produced by the propellers, resulting in a reduction of the largest dimension of the vehicle by approximately 50%. The ability of the vehicle to reduce its size during flight allows, e.g., for the traversal of gaps through which a non-morphing quadcopter could not pass. The vehicle is designed such that existing quadcopter controllers and trajectory generation algorithms can be used, provided that some additional constraints on the control inputs are met. The nonlinear dynamics of the system are presented, and design rules are given that minimize transition time between configurations and maximize the available range of control inputs. A method for performing gap traversal maneuvers is proposed and validated experimentally.
ER  - 

TY  - CONF
TI  - Search-based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight Under Sensor Visibility Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9123
EP  - 9129
AU  - M. Nieuwenhuisen
AU  - S. Behnke
PY  - 2019
KW  - aerospace safety
KW  - collision avoidance
KW  - graph theory
KW  - navigation
KW  - search problems
KW  - trajectory optimisation (aerospace)
KW  - trajectory optimization
KW  - sensor visibility constraints
KW  - obstacle-free flight paths
KW  - Velodyne Puck Lite 3D laser scanner
KW  - flight dynamics
KW  - navigation safety
KW  - allocentric complete planning
KW  - microaerial vehicle flight safety
KW  - search-based 3D planning
KW  - collision avoidance
KW  - graph search
KW  - Planning
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Trajectory optimization
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8794086
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Safe navigation of Micro Aerial Vehicles (MAVs) requires not only obstacle-free flight paths according to a static environment map, but also the perception of and reaction to previously unknown and dynamic objects. This implies that the onboard sensors cover the current flight direction. Due to the limited payload of MAVs, full sensor coverage of the environment has to be traded off with flight time. Thus, often only a part of the environment is covered. We present a combined allocentric complete planning and trajectory optimization approach taking these sensor visibility constraints into account. The optimized trajectories yield flight paths within the apex angle of a Velodyne Puck Lite 3D laser scanner enabling low-level collision avoidance to perceive obstacles in the flight direction. Furthermore, the optimized trajectories take the flight dynamics into account and contain the velocities and accelerations along the path. We evaluate our approach with a DJI Matrice 600 MAV and in simulation employing hardware-in-the-loop.
ER  - 

TY  - CONF
TI  - LineRanger: Analysis and Field Testing of an Innovative Robot for Efficient Assessment of Bundled High-Voltage Powerlines
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9130
EP  - 9136
AU  - P. -. Richard
AU  - N. Pouliot
AU  - F. Morin
AU  - M. Lepage
AU  - P. Hamelin
AU  - M. Lagac©
AU  - A. Sartor
AU  - G. Lambert
AU  - S. Montambault
PY  - 2019
KW  - inspection
KW  - maintenance engineering
KW  - mathematical analysis
KW  - power grids
KW  - power overhead lines
KW  - power transmission control
KW  - robots
KW  - field testing
KW  - innovative robot
KW  - bundled high-voltage powerlines
KW  - robotic platforms
KW  - power grid
KW  - Hydro-Québec
KW  - line maintenance technicians
KW  - passive obstacle-crossing system
KW  - large-scale inspection
KW  - bundled-type powerlines
KW  - mathematical analysis
KW  - LineRanger prototype
KW  - powerline inspection efficiency
KW  - LineScout prototype
KW  - Conductors
KW  - Wheels
KW  - Springs
KW  - Mobile robots
KW  - Blades
KW  - Rotors
DO  - 10.1109/ICRA.2019.8794397
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic platforms dedicated to powerline inspection are often complex to operate, take several minutes to cross any obstacle, and must be operated by highly trained specialists. To further its goal of massive inspection of its power grid, Hydro-Québec developed an innovative robot that is simple to operate and can be used directly by line maintenance technicians. LineRanger was developed following the field deployment of LineROVer and LineScout but aims at surpassing them in terms of inspection efficiency. With an ingenious and passive obstacle-crossing system, this new robot allows large-scale inspection of bundled-type powerlines, since the obstacle crossing time is considerably reduced. In this paper, details on the robot's key features are presented along with its mathematical analysis, which guarantees its stability on flexible bundles and directly influenced the design. Finally, the LineRanger prototype is presented, with insights about its first field deployments.
ER  - 

TY  - CONF
TI  - Adjustable Power Modulation For A Leg Mechanism Suitable For Running
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9137
EP  - 9142
AU  - M. Plecnik
AU  - K. Fearing
AU  - R. S. Fearing
PY  - 2019
KW  - actuators
KW  - legged locomotion
KW  - torque
KW  - kinetic power output
KW  - high power mode
KW  - low-power modes
KW  - adjustable power modulation
KW  - mechanical systems
KW  - robotic locomotor
KW  - actuator system
KW  - leg mechanism
KW  - terrestrial locomotion
KW  - energetic performance
KW  - force-torque ratio
KW  - flat terrain
KW  - finite root generation method
KW  - Legged locomotion
KW  - DC motors
KW  - Springs
KW  - Torque
KW  - Couplings
KW  - Foot
DO  - 10.1109/ICRA.2019.8794379
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent work in the design of mechanical systems for terrestrial locomotion has indicated successful strategies for increasing the energetic performance of a robotic locomotor without upgrading its actuator system. We apply one such strategy, termed power modulation, in a new way: for the design of a leg mechanism useful for running. Power modulation geometrically defines force/torque ratios between robot components to mechanically achieve certain energy transmission characteristics during fast stance dynamics that increase the kinetic power output of the overall system. Furthermore, we investigate the design of a leg mechanism that can adjust to exhibit power modulation. In this way, a leg mechanism would exhibit a low power mode for flat terrain, and can adjust to a high power mode for rough terrain. The latter makes jumping possible and extends the range of available footholds that can be accessed in a single step. To find a suitable leg mechanism, we leverage the Finite Root Generation method to compute a design. The design is advanced to a prototype and basic experiments are conducted to investigate its behavior as adjusted between high-and low-power modes.
ER  - 

TY  - CONF
TI  - Fast and In Sync: Periodic Swarm Patterns for Quadrotors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9143
EP  - 9149
AU  - X. Du
AU  - C. E. Luis
AU  - M. Vukosavljev
AU  - A. P. Schoellig
PY  - 2019
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - path planning
KW  - motion delays
KW  - drones
KW  - periodic swarm patterns
KW  - quadrotor swarm performances
KW  - integrated unit
KW  - coordinated unit
KW  - swarm motion primitives
KW  - flexible framework
KW  - choreography design
KW  - trajectory generation algorithms
KW  - periodic motion pattern
KW  - Drones
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Surface waves
KW  - Planning
KW  - Aerodynamics
DO  - 10.1109/ICRA.2019.8794017
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to design quadrotor swarm performances, where the swarm acts as an integrated, coordinated unit embodying moving and deforming objects. We divide the task of creating a choreography into three basic steps: designing swarm motion primitives, transitioning between those movements, and synchronizing the motion of the drones. The result is a flexible framework for designing choreographies comprised of a wide variety of motions. The motion primitives can be intuitively designed using a few parameters, providing a rich library for choreography design. Moreover, we combine and adapt existing goal assignment and trajectory generation algorithms to maximize the smoothness of the transitions between motion primitives. Finally, we propose a correction algorithm to compensate for motion delays and synchronize the motion of the drones to a desired periodic motion pattern. The proposed methodology was validated experimentally by generating and executing choreographies on a swarm of 25 quadrotors.
ER  - 

TY  - CONF
TI  - Transfer Learning for Surgical Task Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9166
EP  - 9172
AU  - Y. Tsai
AU  - B. Huang
AU  - Y. Guo
AU  - G. Yang
PY  - 2019
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - surgery
KW  - transfer learning
KW  - surgical task segmentation
KW  - segmentation points
KW  - manually labeled data
KW  - correlated features
KW  - segmentation rule
KW  - high segmentation rates
KW  - Task analysis
KW  - Motion segmentation
KW  - Trajectory
KW  - Feature extraction
KW  - Needles
KW  - Surgery
DO  - 10.1109/ICRA.2019.8794292
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel approach for surgical task segmentation. A segmentation policy learns the correlations between features and segmentation points from manually labeled data. The most correlated features and rules for segmenting them are identified and learned. These form a complete set of segmentation policy. The proposed approach is developed to segment new but similar tasks through transfer learning. It is verified through applying the segmentation rule learned from the labeled data to segment other tasks. The performance of the proposed algorithm was evaluated by comparing the results against the ground truths. Experimental results demonstrate that our approach can achieve high segmentation rates with an accuracy of between 68.8% - 81.8%.
ER  - 

TY  - CONF
TI  - Bayesian Optimization of Soft Exosuits Using a Metabolic Estimator Stopping Process
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9173
EP  - 9179
AU  - M. Kim
AU  - C. Liu
AU  - J. Kim
AU  - S. Lee
AU  - A. Meguid
AU  - C. J. Walsh
AU  - S. Kuindersma
PY  - 2019
KW  - Bayes methods
KW  - data acquisition
KW  - gradient methods
KW  - Kalman filters
KW  - legged locomotion
KW  - optimal control
KW  - parameter estimation
KW  - Kalman filter-based metabolic estimator
KW  - soft exosuits
KW  - metabolic estimator stopping process
KW  - human-in-the-loop optimization studies
KW  - wearable devices
KW  - improved average metabolic reduction
KW  - slow metabolic dynamics
KW  - Bayesian optimization
KW  - gradient descent optimization
KW  - Optimization
KW  - Bayes methods
KW  - Time measurement
KW  - Noise measurement
KW  - Estimation
KW  - Standards
KW  - Phase measurement
DO  - 10.1109/ICRA.2019.8793817
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent human-in-the-loop (HIL) optimization studies using wearable devices have shown an improved average metabolic reduction by optimizing a small number of control parameters during short-duration walking experiments. However, the slow metabolic dynamics, high measurement noise, and experimental time constraints create challenges for increasing the number of control parameters to be optimized. Prior work applying gradient descent and Bayesian optimization to this problem have decoupled metabolic estimation and control parameter selection using fixed estimation intervals, which imposes a hard limit on the number of parameter evaluations possible in a given time budget. In this work, we take a different approach that couples estimation and parameter selection, allowing the algorithm to spend less time on refining the metabolic estimates for parameters that are unlikely to improve performance over the best observed values. Our approach uses a Kalman filter-based metabolic estimator to formulate an optimal stopping problem during the data acquisition step of standard Bayesian optimization. Performance was analyzed in numerical simulations and in pilot human subject testing with two subjects that involved optimizing six control parameters of a single-joint exosuit and four parameters of a multi-joint exosuit.
ER  - 

TY  - CONF
TI  - Towards Semi-Autonomous and Soft-Robotics Enabled Upper-Limb Exoprosthetics: First Concepts and Robot-Based Emulation Prototype
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9180
EP  - 9186
AU  - J. Kuhn
AU  - J. Ringwald
AU  - M. Schappler
AU  - L. Johannsmeier
AU  - S. Haddadin
PY  - 2019
KW  - artificial limbs
KW  - biomechanics
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - orthopaedics
KW  - patient rehabilitation
KW  - 3D visual perception
KW  - semiautonomous coordinated motion strategies
KW  - app-based programming framework
KW  - established standard sequential strategies all joints
KW  - human embodied dynamics model
KW  - robot-based exoskeleton substitute
KW  - soft-robotics design
KW  - intelligent coordinated control concepts
KW  - upper body
KW  - gravity effects
KW  - residual limb
KW  - unnecessary interaction forces
KW  - central goal
KW  - prostheses
KW  - exoskeletons
KW  - robot-based emulation prototype
KW  - soft-robotics enabled upper-limb exoprosthetics
KW  - strategy goals
KW  - Prosthetics
KW  - Exoskeletons
KW  - Robot kinematics
KW  - Prototypes
KW  - Task analysis
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794332
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper the first robot-based prototype of a semi-autonomous upper-limb exoprosthesis is introduced, unifying exoskeletons and prostheses [1]. A central goal of this work is to minimize unnecessary interaction forces on the residual limb by compensating gravity effects via a upper body grounded exoskeleton. Furthermore, the exoskeleton provides the residual limb's kinematic data that allows to design more intelligent coordinated control concepts. The soft-robotics design of a prototype consisting of a transhumeral prosthesis and a robot-based exoskeleton substitute is outlined. For this class of hybrid systems a human embodied dynamics model and semi-autonomous coordinated motion strategies are derived. Here, in contrast to established standard sequential strategies all joints are moved simultaneously according to a desired task. In combination with an app-based programming framework the strategy goals are set either user-based via kinesthetic teaching or autonomously via 3D visual perception. This enables the user to execute tasks faster and more intuitive. First experimental evaluations show promising performance with a healthy subject.
ER  - 

TY  - CONF
TI  - A Miniature Suction-Gripper With Passive and Active Microneedle Arrays to Manipulate Peripheral Nerves
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9202
EP  - 9208
AU  - N. Jang
AU  - Y. S. Ihn
AU  - J. Jeong
AU  - S. Yang
AU  - S. Yim
AU  - S. Oh
AU  - K. Kim
AU  - D. Hwang
PY  - 2019
KW  - biological tissues
KW  - grippers
KW  - injuries
KW  - medical robotics
KW  - needles
KW  - neurophysiology
KW  - surgery
KW  - neurosurgical robot
KW  - nervous tissues
KW  - robotic surgical instrument
KW  - nerve damages
KW  - nerve bundles
KW  - flexible peripheral nerves
KW  - active microneedle arrays
KW  - passive microneedle arrays
KW  - miniature suction-gripper
KW  - peripheral nerve
KW  - suction mechanism
KW  - Force
KW  - Grippers
KW  - Instruments
KW  - Wires
KW  - Manipulators
KW  - Hoses
DO  - 10.1109/ICRA.2019.8794154
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We develop a miniature suction-gripper with the goal to realize the novel robotic surgical instrument that can grip slippery and flexible peripheral nerves. In developing the instrument, we place a priority on devising the method that can robustly grip the nerve bundles during the surgical operation for the peripheral nerve. Also, we concentrate to investigate the working principle being able to minimize nerve damages that might be caused when manipulating the nerve. In this study, as the most suitable method to achieve the goal, we scheme to utilize the suction mechanism. Because it can non-invasively grip the nerve based on negative pressure, no external force is applied to the nervous tissues. Therefore the peripheral nerve can be manipulated without serious nerve damage (e.g. crush injury and stretch injury). To improve the gripping ability of the proposed suction gripper, two different types of microneedle arrays are applied to the suction-tips: passive-microneedle (PMN) arrays and active-microneedle (AMN) arrays. Since the most outer membrane of the nerve can be anchored by the penetrated PMN and AMN, the gripper can grip the nerve more robustly. The designed suction-gripper is fabricated as a functional prototype, and its working performances are assessed with in-vitro and in-vivo animal experiments. The experimental results well demonstrate the practical effectiveness of the proposed method and its applicability to the neurosurgical robot for the peripheral nerve.
ER  - 

TY  - CONF
TI  - Robust 3D Distributed Formation Control With Collision Avoidance And Application To Multirotor Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9209
EP  - 9215
AU  - K. Fathian
AU  - S. Safaoui
AU  - T. H. Summers
AU  - N. R. Gans
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - distributed control
KW  - helicopters
KW  - mobile robots
KW  - position control
KW  - position measurement
KW  - robust control
KW  - distributed control strategy
KW  - local relative position measurements
KW  - collision avoidance strategy
KW  - robust 3D distributed formation control
KW  - 3D formation
KW  - multirotor aerial vehicles
KW  - quadrotors
KW  - Three-dimensional displays
KW  - Collision avoidance
KW  - Shape
KW  - Vehicle dynamics
KW  - Position measurement
KW  - Sensors
KW  - Topology
KW  - Multi-robot systems
KW  - distributed robotic systems
KW  - 3D formation control
KW  - distributed collision avoidance
DO  - 10.1109/ICRA.2019.8794349
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a distributed control strategy for a team of agents to autonomously achieve a desired 3D formation. Our approach is based on local relative position measurements and can be applied to multirotor aerial vehicles. We assume that agents have a common sense of direction, which is used to align the z-axes of their local coordinate frames. However, this assumption is not crucial, and our approach is provably robust to misalignments in the local coordinate frames or measurement inaccuracies. In particular, agents can move along any direction that projects positively onto the desired direction of motion. This property is exploited to design a fully-distributed collision avoidance strategy. We validate the proposed approach experimentally and show that a team of quadrotors can achieve a desired 3D formation without collisions.
ER  - 

TY  - CONF
TI  - Networked Operation of a UAV Using Gaussian Process-Based Delay Compensation and Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9216
EP  - 9222
AU  - D. Jang
AU  - J. Yoo
AU  - C. Y. Son
AU  - H. J. Kim
AU  - K. H. Johansson
PY  - 2019
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control nonlinearities
KW  - delays
KW  - Gaussian processes
KW  - mobile robots
KW  - networked control systems
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - stability
KW  - state estimation
KW  - state feedback
KW  - time-varying systems
KW  - Gaussian process-based delay compensation
KW  - model predictive control
KW  - time-varying network delay
KW  - UAV control system
KW  - delayed state feedback
KW  - multirotor-type UAVs
KW  - networked control system
KW  - UAV networked operation
KW  - path planning
KW  - state estimation
KW  - Delays
KW  - Servers
KW  - Uplink
KW  - Downlink
KW  - Predictive models
KW  - Unmanned aerial vehicles
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793472
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study addresses an operation of unmanned aerial vehicles (UAVs) in a network environment where there is time-varying network delay. The network delay entails undesirable effects on the stability of the UAV control system due to delayed state feedback and outdated control input. Although several networked control algorithms have been proposed to deal with the network delay, most existing studies have assumed that the plant dynamics is known and simple, or the network delay is constant. These assumptions are improper to multirotor-type UAVs because of their nonlinearity and time-sensitive characteristics. To deal with these problems, we propose a networked control system using model predictive control (MPC) designed under the consideration of multirotor characteristics. We also apply a Gaussian process (GP) to learn an unknown nonlinear model, which increases the accuracy of path planning and state estimation. Flight experiments show that the proposed algorithm successfully compensates the network delay and Gaussian process learning improves the UAV's path tracking performance.
ER  - 

TY  - CONF
TI  - Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing Robots and Animals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9223
EP  - 9229
AU  - F. Fei
AU  - Z. Tu
AU  - Y. Yang
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - control system synthesis
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - vehicle dynamics
KW  - flappy hummingbird
KW  - open source dynamic simulation
KW  - flapping Wing robots
KW  - hummingbirds
KW  - extraordinary flight performance
KW  - stable hovering maneuvering
KW  - aggressive maneuvering
KW  - conventional small scale man-made vehicles
KW  - FWMAVs
KW  - performance gap
KW  - open source high fidelity dynamic simulation
KW  - optimization
KW  - flight control
KW  - at-scale hummingbird robot
KW  - system identification
KW  - dynamic response
KW  - open-loop
KW  - loop systems
KW  - simulated flights
KW  - experimental flights
KW  - highly nonlinear flight dynamics
KW  - control problems
KW  - control algorithms
KW  - linear controller
KW  - control policy
KW  - simulation-to-real transfer
KW  - physical robot
KW  - flapping wing microair vehicles
KW  - Aerodynamics
KW  - Robots
KW  - Vehicle dynamics
KW  - Force
KW  - Torque
KW  - Animals
DO  - 10.1109/ICRA.2019.8794089
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Insects and hummingbirds exhibit extraordinary flight performance and can simultaneously master seemingly conflicting goals: stable hovering and aggressive maneuvering, which are unmatched by conventional small scale man-made vehicles. Flapping Wing Micro Air Vehicles (FWMAVs) hold great promise for closing this performance gap. However, design and control of such systems remain challenging. Here, we present an open source high fidelity dynamic simulation for FWMAVs. The simulator serves as a testbed for the design, optimization and flight control of FWMAVs. To validate the simulation, we recreated the at-scale hummingbird robot developed in our lab in the simulation. System identification was performed to obtain the model parameters. Force generation and dynamic response of open-loop and closed loop systems between simulated and experimental flights were compared. The unsteady aerodynamics and the highly nonlinear flight dynamics present challenging control problems for conventional and learning control algorithms such as Reinforcement Learning. The interface of the simulation is fully compatible with OpenAI Gym environment. As a benchmark study, we present a linear controller for hovering stabilization and a Deep Reinforcement Learning control policy for goal-directed maneuvering. Finally, we demonstrate direct simulation-to-real transfer of both control policies onto the physical robot, further demonstrating the fidelity of the simulation.
ER  - 

TY  - CONF
TI  - Visual Repetition Sampling for Robot Manipulation Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9236
EP  - 9242
AU  - E. Y. Puang
AU  - P. Lehner
AU  - Z. Marton
AU  - M. Durner
AU  - R. Triebel
AU  - A. Albu-Schäffer
PY  - 2019
KW  - collision avoidance
KW  - Gaussian processes
KW  - image sampling
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - trees (mathematics)
KW  - Gaussian mixture models
KW  - rapidly-exploring random tree
KW  - biased sampling methods
KW  - real-time applications
KW  - longer planning times
KW  - optimization-based methods
KW  - complex environments
KW  - sampling-based motion planners
KW  - robot manipulation
KW  - visual repetition sampling
KW  - RRT motion planner
KW  - sampling efficiency
KW  - visual input
KW  - GMM
KW  - Planning
KW  - Databases
KW  - Task analysis
KW  - Visualization
KW  - Robots
KW  - Probability distribution
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793942
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the main challenges in sampling-based motion planners is to find an efficient sampling strategy. While methods such as Rapidly-exploring Random Tree (RRT) have shown to be more reliable in complex environments than optimization-based methods, they often require longer planning times, which reduces their usability for real-time applications. Recently, biased sampling methods have shown to remedy this issue. For example Gaussian Mixture Models (GMMs) have been used to sample more efficiently in feasible regions of the configuration space. Once the GMM is learned, however, this approach does not adapt its biases to individual planning scene during inference. Hence, we propose in this work a more efficient sampling strategy to further bias the GMM based on visual input upon query. We employ an autoencoder trained entirely in simulation to extract features from depth images and use the latent representation to adjust the weights of each mixture components in the GMM. We show empirically that this improves the sampling efficiency of an RRT motion planner in both real and simulated scenes.
ER  - 

TY  - CONF
TI  - Contact-Driven Posture Behavior for Safe and Interactive Robot Operation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9243
EP  - 9249
AU  - M. Jorda
AU  - E. G. Herrero
AU  - O. Khatib
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - uncertain environments
KW  - unexpected contact
KW  - safe robot behavior
KW  - contact-driven approach
KW  - safe robot operation
KW  - interactive robot operation
KW  - unforeseen contact events
KW  - robot tasks
KW  - robot model
KW  - freedom robot arm
KW  - safe contact behavior
KW  - robot posture requirements
KW  - contact-driven posture behavior
KW  - Task analysis
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8793691
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When performing tasks in uncertain environments and around humans, robots are likely to collide unexpectedly with people or objects. In order to ensure safety, most approaches rely on collision avoidance and try to prevent any contact from happening, which may result in unnecessary interruption of a task that would be feasible in spite of the obstacle. On the one hand, when an unexpected contact occurs, a safe robot behavior is required. On the other hand, it might be interesting to exploit the contact instead of moving away from it. In this paper, we present a contact-driven approach for safe and interactive robot operation to react to unforeseen contact events. This approach offers the possibility to control the contact while minimizing its effects on the robot tasks. It relies exclusively on the robot model and proprioceptive sensors. It is tested in simulation and hardware experiments on a 7 degrees of freedom robot arm and shows a safe contact behavior that does not interfere with the task, and as little as possible with the robot posture requirements.
ER  - 

TY  - CONF
TI  - SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9250
EP  - 9256
AU  - S. Pillai
AU  - R. Ambruş
AU  - A. Gaidon
PY  - 2019
KW  - convolutional neural nets
KW  - image classification
KW  - image motion analysis
KW  - image resolution
KW  - image sampling
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - self-supervised monocular depth estimation
KW  - self-supervised monocular depth prediction
KW  - subpixel convolutional layer extension
KW  - depth super-resolution
KW  - high-resolution disparities
KW  - low-resolution convolutional features
KW  - flip-augmentation layer
KW  - single-image super-resolution
KW  - deep learning methods
KW  - super-resolved monocular depth estimation
KW  - public KITTI benchmark
KW  - pose estimation
KW  - Estimation
KW  - Convolutional codes
KW  - Cameras
KW  - Spatial resolution
KW  - Three-dimensional displays
KW  - Training
DO  - 10.1109/ICRA.2019.8793621
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent techniques in self-supervised monocular depth estimation are approaching the performance of supervised methods, but operate in low resolution only. We show that high resolution is key towards high-fidelity self-supervised monocular depth prediction. Inspired by recent deep learning methods for Single-Image Super-Resolution, we propose a subpixel convolutional layer extension for depth super-resolution that accurately synthesizes high-resolution disparities from their corresponding low-resolution convolutional features. In addition, we introduce a differentiable flip-augmentation layer that accurately fuses predictions from the image and its horizontally flipped version, reducing the effect of left and right shadow regions generated in the disparity map due to occlusions. Both contributions provide significant performance gains over the state-of-the-art in self-supervised depth and pose estimation on the public KITTI benchmark. A video of our approach can be found at https://youtu.be/jKNgBeBMx0I.
ER  - 

TY  - CONF
TI  - The Mechanics and Control of Leaning to Lift Heavy Objects with a Dynamically Stable Mobile Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9264
EP  - 9270
AU  - F. Sonnleitner
AU  - R. Shu
AU  - R. L. Hollis
PY  - 2019
KW  - feedback
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot dynamics
KW  - wheels
KW  - two-wheeled dynamically stable mobile manipulator robots
KW  - heavy object
KW  - ballbot
KW  - feedback control laws
KW  - dynamically stable mobile robot
KW  - spherical-wheel robots
KW  - unknown mass
KW  - quasistatic center of mass computation
KW  - feedforward control laws
KW  - mass 15.0 kg
KW  - mass 10.0 kg
KW  - Mobile robots
KW  - Task analysis
KW  - Payloads
KW  - Humanoid robots
KW  - Manipulators
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793620
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A control algorithm is developed to enable dynamically stable spherical-wheel robots (ballbots) with arms to detect a heavy object of unknown mass, navigate to it, lift it, transport it, and place it in a desired location semi-autonomously. Previous work has successfully demonstrated two-wheeled dynamically stable mobile manipulator robots transporting heavy objects. We report here the first ballbot to reliably achieve such a task. A successful semi-autonomous lift and transport of a 15 kg heavy box whose actual mass was unknown was achieved using a combination of feedforward and feedback control laws based on a quasi-static center of mass computation. The ballbot's pan and tilt sensor turret tracked fiducial markers on the box. Ballbot-to-human and human-to-ballbot exchanges of a 10 kg heavy object was achieved while dynamically balancing.
ER  - 

TY  - CONF
TI  - Improving Underwater Obstacle Detection using Semantic Image Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9271
EP  - 9277
AU  - B. Arain
AU  - C. McCool
AU  - P. Rigby
AU  - D. Cagara
AU  - M. Dunbabin
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - image enhancement
KW  - image matching
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stereo image processing
KW  - image-based underwater obstacle detection
KW  - sparse stereo point clouds
KW  - monocular semantic image segmentation
KW  - cluttered underwater environments
KW  - robust robotic path planning
KW  - feature-based stereo matching
KW  - learning-based segmentation
KW  - robust obstacle map
KW  - direct binary learning
KW  - underwater obstacles
KW  - multiclass learning approach
KW  - binary map
KW  - sparse stereo matching
KW  - 3D obstacle maps
KW  - coral reef environments
KW  - image-wide obstacle detection
KW  - dynamic objects
KW  - image-based obstacle maps
KW  - Image segmentation
KW  - Semantics
KW  - Cameras
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Training
KW  - Robots
DO  - 10.1109/ICRA.2019.8793588
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents two novel approaches for improving image-based underwater obstacle detection by combining sparse stereo point clouds with monocular semantic image segmentation. Generating accurate image-based obstacle maps in cluttered underwater environments, such as coral reefs, are essential for robust robotic path planning and navigation. However, these maps can be challenged by factors including visibility, lighting and dynamic objects (e.g. fish) that may lead to falsely identified free space or dynamic objects which trajectory planners may react to undesirably. We propose combining feature-based stereo matching with learning-based segmentation to produce a more robust obstacle map. This approach considers direct binary learning of the presence or absence of underwater obstacles, as well as a multiclass learning approach to classify their distance (near, mid and far) in the scene. An enhancement to the binary map is also shown by including depth information from sparse stereo matching to produce 3D obstacle maps of the scene. The performance is evaluated using field data collected in cluttered, and at times, visually degraded coral reef environments. The results show improved image-wide obstacle detection, rejection of transient objects (such as fish), and range estimation compared to feature-based sparse and dense stereo point clouds alone.
ER  - 

TY  - CONF
TI  - RCM-SLAM: Visual localisation and mapping under remote centre of motion constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9278
EP  - 9284
AU  - F. Vasconcelos
AU  - E. Mazomenos
AU  - J. Kelly
AU  - D. Stoyanov
PY  - 2019
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - medical robotics
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - surgery
KW  - laparoscopic camera motion
KW  - RCM constraints
KW  - minimal solver
KW  - absolute camera
KW  - 2D-3D point correspondences
KW  - bundle adjustment optimiser
KW  - RCM-constrained parameterisation
KW  - relative pose estimation
KW  - SLAM pipeline suitable
KW  - robotic surgery
KW  - RCM position
KW  - robotic prostatectomy show
KW  - RCM-SLAM
KW  - visual localisation
KW  - remote centre
KW  - motion constraints
KW  - insertion ports
KW  - Simultaneous Localisation and Mapping
KW  - mapping approach
KW  - RCM-PnP
KW  - Cameras
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Laparoscopes
KW  - Three-dimensional displays
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793931
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In robotic surgery the motion of instruments and the laparoscopic camera is constrained by their insertion ports, i. e. a remote centre of motion (RCM). We propose a Simultaneous Localisation and Mapping (SLAM) approach that estimates laparoscopic camera motion under RCM constraints. To achieve this we derive a minimal solver for the absolute camera pose given two 2D-3D point correspondences (RCM-PnP) and also a bundle adjustment optimiser that refines camera poses within an RCM-constrained parameterisation. These two methods are used together with previous work on relative pose estimation under RCM [1] to assemble a SLAM pipeline suitable for robotic surgery. Our simulations show that RCM-PnP outperforms conventional PnP for a wide noise range in the RCM position. Results with video footage from a robotic prostatectomy show that RCM constraints significantly improve camera pose estimation.
ER  - 

TY  - CONF
TI  - Comparing Physical and Simulated Performance of a Deterministic and a Bio-inspired Stochastic Foraging Strategy for Robot Swarms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9285
EP  - 9291
AU  - Q. Lu
AU  - A. D. Griego
AU  - G. M. Fricke
AU  - M. E. Moses
PY  - 2019
KW  - deterministic algorithms
KW  - multi-robot systems
KW  - stochastic processes
KW  - robot swarms
KW  - collective robot foraging
KW  - central-place foraging algorithm
KW  - CPFA
KW  - distributed deterministic spiral algorithm
KW  - DDSA
KW  - swarm robotic algorithms
KW  - bioinspired stochastic foraging strategy
KW  - resource-collection algorithms
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Spirals
KW  - Swarm robotics
KW  - Task analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794240
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Designing resource-collection algorithms for relatively simple robots that are effective given the noise and uncertainty of the real world is a challenge in swarm robotics. This paper describes the performance of two algorithms for collective robot foraging: the stochastic central-place foraging algorithm (CPFA) and the distributed deterministic spiral algorithm (DDSA). With the CPFA, robots mimic the foraging behaviors of ants; they stochastically search for targets and share information to recruit other robots to locations where they detect multiple targets. With the DDSA, robots travel along pre-planned spiral paths; robots detect the nearest targets first and, in theory, guarantee eventual complete coverage of the arena with minimal overlap. We implemented both algorithms and compared their performance in a Gazebo simulation and in physical robots in a large outdoor arena. In a realistic Gazebo simulation, the DDSA outperforms the CPFA. However, in real-world experiments with obstacles, collisions, and errors, the movement patterns of robots implementing the DDSA become visually indistinguishable from the CPFA. The CPFA is less affected by noise and error, and it performs as well as, or better than, the DDSA. Physical experiments change our conclusion about which algorithm has the best performance, emphasizing the importance of systematically comparing the performance of swarm robotic algorithms in the real world.
ER  - 

TY  - CONF
TI  - WheeLeR: Wheel-Leg Reconfigurable Mechanism with Passive Gears for Mobile Robot Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9292
EP  - 9298
AU  - C. Zheng
AU  - K. Lee
PY  - 2019
KW  - gears
KW  - legged locomotion
KW  - robot kinematics
KW  - wheels
KW  - mobile robotic platform
KW  - gear ratio
KW  - wheel-leg reconfigurable mechanism
KW  - passive gears
KW  - mobile robot applications
KW  - passive wheel-leg transformation mechanism
KW  - central gear
KW  - seamless circular wheel
KW  - leg mode
KW  - geared structure
KW  - obstacle climbing
KW  - locomotion capabilities
KW  - Legged locomotion
KW  - Wheels
KW  - Gears
KW  - Torque
KW  - Force
DO  - 10.1109/ICRA.2019.8793686
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new passive wheel-leg transformation mechanism and its embodiment in a small mobile robot. The mechanism is based on a unique geared structure, allowing the wheel to transform between two modes, i.e., wheel or leg, potentially adapting to varying ground conditions. It consists of a central gear and legs with partial gears that rotate around the central gear to open or close the legs. When fully closed, the mechanism forms a seamless circular wheel; when opened, it operates in the leg mode. The central gear actuated by the driving motor generates opening and closing motions of the legs without using an additional actuator. The number of legs, their physical size, and the gear ratio between the central gear and the partial gears on the legs are adjustable. This design is mechanically simple, customizable, and easy to fabricate. For physical demonstration and experiments, a mobile robotic platform was built and its terrainability was tested using five different sets of the transformable wheels with varying sizes and gear ratios. For each design, the performance with successful wheel-leg transformation, obstacle climbing, and locomotion capabilities was tested in different ground conditions.
ER  - 

TY  - CONF
TI  - Long-Term Occupancy Grid Prediction Using Recurrent Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9299
EP  - 9305
AU  - M. Schreiber
AU  - S. Hoermann
AU  - K. Dietmayer
PY  - 2019
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - neural net architecture
KW  - optical radar
KW  - recurrent neural nets
KW  - long-term occupancy grid prediction
KW  - recurrent neural networks
KW  - scene evolution
KW  - automated driving
KW  - Lidar grid fusion
KW  - birds eye view
KW  - RNNs
KW  - CNN architecture
KW  - convolutional long short-term memories
KW  - ConvLSTMs
KW  - Monte Carlo approach
KW  - Vehicle dynamics
KW  - Training
KW  - Predictive models
KW  - Task analysis
KW  - Computer architecture
KW  - Recurrent neural networks
KW  - Correlation
DO  - 10.1109/ICRA.2019.8793582
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We tackle the long-term prediction of scene evolution in a complex downtown scenario for automated driving based on Lidar grid fusion and recurrent neural networks (RNNs). A bird's eye view of the scene, including occupancy and velocity, is fed as a sequence to a RNN which is trained to predict future occupancy. The nature of prediction allows generation of multiple hours of training data without the need of manual labeling. Thus, the training strategy and loss function are designed for long sequences of real-world data (unbalanced, continuously changing situations, false labels, etc.). The deep CNN architecture comprises convolutional long short-term memories (ConvLSTMs) to separate static from dynamic regions and to predict dynamic objects in future frames. Novel recurrent skip connections show the ability to predict small occluded objects, i.e. pedestrians, and occluded static regions. Spatio-temporal correlations between grid cells are exploited to predict multimodal future paths and interactions between objects. Experiments also quantity improvements to our previous network, a Monte Carlo approach, and literature.
ER  - 

TY  - CONF
TI  - Guaranteed Globally Optimal Planar Pose Graph and Landmark SLAM via Sparse-Bounded Sums-of-Squares Programming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9306
EP  - 9312
AU  - J. G. Mangelson
AU  - J. Liu
AU  - R. M. Eustice
AU  - R. Vasudevan
PY  - 2019
KW  - graph theory
KW  - maximum likelihood estimation
KW  - mobile robots
KW  - navigation
KW  - nonlinear programming
KW  - path planning
KW  - polynomials
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous navigation
KW  - nonlinear optimization techniques
KW  - maximum likelihood estimate
KW  - robot trajectory
KW  - polynomial optimization programs
KW  - planar pose graph
KW  - landmark SLAM
KW  - sparse-bounded sums-of-squares programming
KW  - simultaneous localization and mapping
KW  - pose-graph SLAM problem
KW  - sum-of-squares convex
KW  - SOS convex
KW  - sparse bounded degree sum-of-squares optimization method
KW  - sparse-BSOS optimization method
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Maximum likelihood estimation
KW  - Position measurement
KW  - Noise measurement
KW  - Transmission line matrix methods
DO  - 10.1109/ICRA.2019.8794454
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous navigation requires an accurate model or map of the environment. While dramatic progress in the prior two decades has enabled large-scale simultaneous localization and mapping (SLAM), the majority of existing methods rely on non-linear optimization techniques to find the maximum likelihood estimate (MLE) of the robot trajectory and surrounding environment. These methods are prone to local minima and are thus sensitive to initialization. Several recent papers have developed optimization algorithms for the Pose-Graph SLAM problem that can certify the optimality of a computed solution. Though this does not guarantee a priori that this approach generates an optimal solution, a recent extension has shown that when the noise lies within a critical threshold that the solution to the optimization algorithm is guaranteed to be optimal. To address the limitations of existing approaches, this paper illustrates that the Pose-Graph SLAM and Landmark SLAM can be formulated as polynomial optimization programs that are sum-of-squares (SOS) convex. This paper then describes how the Pose-Graph and Landmark SLAM problems can be solved to a global minimum without initialization regardless of noise level using the sparse bounded degree sum-of-squares (Sparse-BSOS) optimization method. Finally, the superior performance of the proposed approach when compared to existing SLAM methods is illustrated on graphs with several hundred nodes.
ER  - 

TY  - CONF
TI  - Trust Regions for Safe Sampling-Based Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9313
EP  - 9319
AU  - M. Koch
AU  - M. Spies
AU  - M. Bürger
PY  - 2019
KW  - nonlinear dynamical systems
KW  - predictive control
KW  - robust control
KW  - sampling methods
KW  - stochastic systems
KW  - trust regions
KW  - safe sampling-based model predictive control
KW  - nonlinear control systems
KW  - complex dynamics
KW  - nonlinear dynamics
KW  - sampling-based MPC scheme
KW  - sampling based estimation
KW  - safe constraint satisfaction
KW  - probabilistic information
KW  - Monte Carlo methods
KW  - Trajectory
KW  - Predictive control
KW  - Optimization
KW  - Safety
KW  - Optimal control
DO  - 10.1109/ICRA.2019.8793846
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guaranteeing safe constraint satisfaction in nonlinear control systems with uncertainty remains a major challenge for control. The most successful control method handling constraints under uncertainty has without doubt been model predictive control (MPC). In particular, recent sampling-based MPC methods have shown success in controlling stochastic systems with complex, nonlinear dynamics. The sampling-based schemes are appealing since they do not need strong assumptions on the underlying model, except that it can be forward simulated. At the same time, the lack of major assumptions on the models make the statement of safety or robustness guarantees difficult. However, the samples drawn during the control process inherently contain probabilistic information about these properties. In this paper, we formally describe the problem that results by adding chance constraints to a sampling-based MPC scheme. Furthermore, based on a variant of the Chernoff bound, we derive trust regions, in which the sampling based estimation of the safety constraint satisfies a specified quality. Finally, we present a case study in the navigation domain to demonstrate the applicability of the proposed approach.
ER  - 

TY  - CONF
TI  - Removing Leaking Corners to Reduce Dimensionality in Hamilton-Jacobi Reachability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9320
EP  - 9326
AU  - D. Lee
AU  - M. Chen
AU  - C. J. Tomlin
PY  - 2019
KW  - collision avoidance
KW  - game theory
KW  - mobile robots
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - reachability analysis
KW  - safety
KW  - dimensionality reduction
KW  - HJ computation
KW  - Hamilton-Jacobi reachability
KW  - robotic systems
KW  - nonlinear system dynamics
KW  - safety-preserving controllers
KW  - computational scalability
KW  - continuous state dimensions
KW  - computational burden
KW  - system decomposition methods
KW  - coupled HJ formulation
KW  - leaking corners removal
KW  - safety verification
KW  - computational scalability limits
KW  - vehicle obstacle avoidance problem
KW  - 5D car model
KW  - Safety
KW  - Dimensionality reduction
KW  - Optimal control
KW  - Level set
KW  - Collision avoidance
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793890
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Hamilton-Jacobi (HJ) reachability provides a flexible framework for the verification of safety in robotic systems: it accounts for nonlinear system dynamics and provides safety-preserving controllers. However, computational scalability limits its direct application to systems of less than five continuous state dimensions. To alleviate this computational burden, system decomposition methods have been proposed; however, safety guarantees are lost in situations involving “leaking corners which arise when there are conflicting controls between subsystems. In this paper, a coupled HJ formulation is presented, which addresses leaking corners and guarantees safety, while incorporating dimensionality reduction. We demonstrate our method in two examples, one of which is a vehicle obstacle avoidance problem with a 5D car model, whose HJ computation was previously considered to be intractable.
ER  - 

TY  - CONF
TI  - Control from the Cloud: Edge Computing, Services and Digital Shadow for Automation Technologies*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9327
EP  - 9333
AU  - C. Brecher
AU  - M. Buchsbaum
AU  - S. Storms
PY  - 2019
KW  - agile manufacturing
KW  - cloud computing
KW  - embedded systems
KW  - product development
KW  - production engineering computing
KW  - edge computing
KW  - digital shadow
KW  - agile product development
KW  - production systems
KW  - automation pyramid
KW  - interconnected cyber physical systems
KW  - adaptive process control
KW  - life cycle data management
KW  - Cloud computing
KW  - Automation
KW  - Computer architecture
KW  - Edge computing
KW  - Production
KW  - Process control
KW  - Manufacturing
DO  - 10.1109/ICRA.2019.8793488
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to agile product development, production systems have to be flexible and adaptable to meet high quality standards and a high productivity. As a result, set-up processes has to be shorter and more resilient because of the increasing number of variants. To meet future requirements, the processes need to be self-adaptive and reconfigurable at any time. Nowadays, a shift of the automation pyramid to interconnected cyber physical systems can be observed as well as emerging technologies as cloud and edge computing are introduced to production systems. These technologies in combination with the Digital Shadow, which provides information about all production assets, open up potential for an adaptive process control and an overall life cycle data management. For this, the Digital Shadow has to be used not only for the aggregation of data, but also for pushing data back into the system and to control the process. As a result, services in regard to an architecture based on edge computing as an enabling technology for an adaptive production together with the Digital Shadow are presented, implemented and discussed on the basis of an industrial use case.
ER  - 

TY  - CONF
TI  - Improving the Performance of Auxiliary Null Space Tasks via Time Scaling-Based Relaxation of the Primary Task
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9342
EP  - 9348
AU  - N. Mansfeld
AU  - Y. Michel
AU  - T. Bruckmann
AU  - S. Haddadin
PY  - 2019
KW  - path planning
KW  - position control
KW  - redundant manipulators
KW  - auxiliary null space tasks
KW  - task achievement
KW  - null space task
KW  - multiple prioritized tasks
KW  - time scaling-based relaxation
KW  - primary task
KW  - kinematic redundancy
KW  - robot manipulators
KW  - safety criterion
KW  - optimization criterion
KW  - constraint relaxation
KW  - time scaling schemes
KW  - DLR lightweight robot
KW  - KUKA lightweight robot
KW  - Task analysis
KW  - Null space
KW  - Robot kinematics
KW  - Trajectory
KW  - Jacobian matrices
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794225
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Kinematic redundancy enhances the dexterity and flexibility of robot manipulators. By exploiting the redundant degrees of freedom, auxiliary null space tasks can be carried out in addition to the primary task. Such auxiliary tasks are often formulated in terms of a performance or safety criterion that shall be minimized. If the optimization criterion, however, is defined in global terms, then it is directly affected by the primary task. As a consequence, the task achievement of the auxiliary task may be unnecessarily detrimented by the main task. In addition to modifying the primary task via constraint relaxation, a possible solution for improving the performance of the auxiliary task is to relax the primary task temporarily via time scaling. This gives the null space task more time for achieving its objective. In this paper, we propose several such time scaling schemes and verify their performance for a DLR/KUKA Lightweight Robot with one redundant degree of freedom. Finally, we extend the concept to multiple prioritized tasks and provide a simulation example.
ER  - 

TY  - CONF
TI  - Shape Memory Structures-Automated Design of Monolithic Soft Robot Structures with Pre-defined End Poses
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9357
EP  - 9362
AU  - Y. S. Krieger
AU  - S. Schiele
AU  - S. Detzel
AU  - C. Dietz
AU  - T. C. Lueth
PY  - 2019
KW  - actuators
KW  - intelligent robots
KW  - manipulators
KW  - rapid prototyping (industrial)
KW  - shape memory effects
KW  - three-dimensional printing
KW  - soft robotic systems
KW  - automated design process
KW  - monolithic soft robotic structures
KW  - pre-defined end poses
KW  - shape memory structures-automated design
KW  - monolithic soft robot structures
KW  - additive manufacturing methods
KW  - 3D-printable
KW  - actuators
KW  - Fasteners
KW  - Soft robotics
KW  - Three-dimensional printing
KW  - Task analysis
KW  - Shape
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794035
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The particularly compliant and adaptable properties of soft robotic systems and structures offer enormous potential for use in unpredictable environments as well as for safe and interactive work in human environments. Therefore, new approaches for the design of soft robotic systems are constantly being introduced in this still emerging field of research. Through the use of additive manufacturing methods, it is possible to design systems specifically for an individual task. In this paper we present an approach for an automated design process for monolithic soft robotic structures that can assume pre-defined end poses. The idea thereby is to design simple individualizable systems that are 3D-printable and require a minimum number of actuators. Using the automated design process, we could already generate soft robotic systems for different applications which show promising properties.
ER  - 

TY  - CONF
TI  - A Novel Rotating Beam Link for Variable Stiffness Robotic Arms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9387
EP  - 9393
AU  - T. Morrison
AU  - C. Li
AU  - X. Pei
AU  - H. Su
PY  - 2019
KW  - actuators
KW  - beams (structures)
KW  - buckling
KW  - design engineering
KW  - elastic constants
KW  - industrial robots
KW  - servomotors
KW  - safety benefits
KW  - compact design
KW  - rotating beams
KW  - lateral stiffness ratio
KW  - parallel guided beams
KW  - beam roots
KW  - mechanics model
KW  - design concept
KW  - rotating beam link
KW  - variable stiffness robotic arms
KW  - servomotors
KW  - column buckling
KW  - Collision avoidance
KW  - Structural beams
KW  - Prototypes
KW  - Servomotors
KW  - Robot sensing systems
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793833
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel design concept for a robot arm link with variable stiffness. Variable stiffness links are intended to grant a robot the safety benefits of compliance and the performance benefits of stiffness. Our compact design actively modulates stiffness via parallel, rotating beams actuated by simple servomotors. It achieves a lateral stiffness ratio greater than ten with a minimum stiffness under 0.2 N/mm. Our novel design offers many benefits over existing variable stiffness link solutions in its compactness, simplicity, and speed of actuation. One challenge of this research lies in the mechanics modeling of variable stiffness. Here we propose a comprehensive mechanics model that considers mechanical compliances due to deflections of parallel guided beams, column buckling, and bearing at the beam roots. By comparing with experimental testing data, we show that our analytical model accurately predicts the lateral stiffness of the robotic link. This model can be used as a design tool in future iterations, including for scaling the design.
ER  - 

TY  - CONF
TI  - Mechanical Fourier Transform using an Array of Additively Manufactured Soft Whisker-like Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9410
EP  - 9415
AU  - A. Vaish
AU  - S. Y. Lee
AU  - P. V. y. Alvarado
PY  - 2019
KW  - damping
KW  - Fourier transforms
KW  - oscillators
KW  - polymers
KW  - rapid prototyping (industrial)
KW  - sensor arrays
KW  - three-dimensional printing
KW  - mixed-frequency signals
KW  - mechanical Fourier transform
KW  - damped oscillator system
KW  - additively manufactured soft whisker-like sensor array
KW  - single-step additive manufacturing approach
KW  - bioinspired soft whisker-like sensors
KW  - polymer based whisker-array
KW  - Sensor arrays
KW  - Resonant frequency
KW  - Fabrication
KW  - Robot sensing systems
KW  - Shafts
KW  - Power capacitors
DO  - 10.1109/ICRA.2019.8793957
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, a single-step additive manufacturing approach to fabricate an array of bio-inspired soft whisker-like sensors is presented. Each whisker is a damped oscillator system that is tuned to a different resonant frequency whose response is characterized through experimentation in an air medium. A 3 × 1 polymer based whisker-array is used to distinguish individual frequency components in mixed-frequency signals, achieving a form of “mechanical Fourier transform”.
ER  - 

TY  - CONF
TI  - Multi-Task Sensorization of Soft Actuators Using Prior Knowledge
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9416
EP  - 9421
AU  - V. Wall
AU  - O. Brock
PY  - 2019
KW  - deformation
KW  - dexterous manipulators
KW  - elastic constants
KW  - pneumatic actuators
KW  - sensors
KW  - sensorized actuators
KW  - soft actuators
KW  - multitask sensorization
KW  - sensor hardware
KW  - multitask method
KW  - RBO Hand 2
KW  - PneuFlex actuator
KW  - sensor placement
KW  - soft actuator
KW  - task-relevant deformations
KW  - soft robotic actuators
KW  - Task analysis
KW  - Actuators
KW  - Strain
KW  - Robot sensing systems
KW  - Layout
KW  - Capacitive sensors
DO  - 10.1109/ICRA.2019.8793697
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The space of all possible deformations of soft robotic actuators is extremely large. It is impossible to explicitly measure each internal degree of freedom, regardless of the number and types of sensors. It is, however, possible to measure a smaller subset of task-relevant deformations using only a few well-placed sensors. But for a different task, the soft actuator's deformation behavior might differ significantly. Instead of finding a new sensor placement for the new task, which would result in a separate hand for every task, we propose a method that maintains the original sensors and uses prior knowledge about each task to extend the applicability of the existing sensorized actuators to new tasks. We demonstrate our approach by the example of a PneuFlex actuator of the RBO Hand 2. When sensorizing the actuator for a single task, the sensor model does not transfer well to other tasks. Using our multi-task method, we train new sensor models that use prior knowledge about the tasks. The new models improve measurement accuracy for the new tasks without having to change the sensor hardware.
ER  - 

TY  - CONF
TI  - Self-Modifying Morphology Experiments with DyRET: Dynamic Robot for Embodied Testing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9446
EP  - 9452
AU  - T. F. Nygaard
AU  - C. P. Martin
AU  - J. Torresen
AU  - K. Glette
PY  - 2019
KW  - adaptive systems
KW  - legged locomotion
KW  - robot dynamics
KW  - self-reconfiguration
KW  - quadruped robots
KW  - DyRET
KW  - embodied testing
KW  - dynamic robot morphology
KW  - locomotion modes
KW  - self-reconfigurable morphology
KW  - servo supply voltage
KW  - four-legged robot
KW  - self-modifying morphology experiments
KW  - uncontrolled outdoor environments
KW  - Legged locomotion
KW  - Morphology
KW  - Servomotors
KW  - Computer architecture
KW  - Robot sensing systems
KW  - Switches
DO  - 10.1109/ICRA.2019.8793663
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - If robots are to become ubiquitous, they will need to be able to adapt to complex and dynamic environments. Robots that can adapt their bodies while deployed might be flexible and robust enough to meet this challenge. Previous work on dynamic robot morphology has focused on simulation, combining simple modules, or switching between locomotion modes. Here, we present an alternative approach: a self-reconfigurable morphology that allows a single four-legged robot to actively adapt the length of its legs to different environments. We report the design of our robot, as well as the results of a study that verifies the performance impact of self-reconfiguration. This study compares three different control and morphology pairs under different levels of servo supply voltage in the lab. We also performed preliminary tests in different uncontrolled outdoor environments to see if changes to the external environment supports our findings in the lab. Our results show better performance with an adaptable body, lending evidence to the value of self-reconfiguration for quadruped robots.
ER  - 

TY  - CONF
TI  - Experimental Validation of High-Efficiency Hydraulic Direct-Drive System for a Biped Humanoid Robot—Comparison with Valve-Based Control System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9453
EP  - 9458
AU  - J. Shimizu
AU  - T. Otani
AU  - H. Mizukami
AU  - K. Hashimoto
AU  - A. Takanishi
PY  - 2019
KW  - humanoid robots
KW  - hydraulic systems
KW  - legged locomotion
KW  - position control
KW  - robot dynamics
KW  - valves
KW  - high-efficiency hydraulic direct-drive system
KW  - biped humanoid robot-comparison
KW  - high-power large electrical motors
KW  - mechanical transmission systems
KW  - valve-based control system
KW  - position-following capability
KW  - energy consumption
KW  - Valves
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Actuators
KW  - Velocity control
DO  - 10.1109/ICRA.2019.8793787
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Biped robots require substantial amounts of power alternately on each leg while walking, hopping, and running. However, it is difficult to mount high-power large electrical motors in conventional mechanical transmission systems owing to spatial limitations. A hydraulic direct-drive system is proposed in which the size of the motor in each leg can be reduced by sharing the motor outputs between the legs. In this paper, the hydraulic direct-drive system is evaluated in an actual hydraulic system. Velocity followability, excellent energy saving, and virtually perfect position tracking are achieved with the proposed system. The results of performance comparison with a valve-based control system show that energy consumption is controlled and good position-following capability is achieved using the proposed system.
ER  - 

TY  - CONF
TI  - Experimental Demonstration of High-Performance Robotic Balancing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9459
EP  - 9465
AU  - J. J. M. Driessen
AU  - A. E. Gkikakis
AU  - R. Featherstone
AU  - B. R. P. Singh
PY  - 2019
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - wheels
KW  - balance control
KW  - fast movements
KW  - narrow support
KW  - reaction wheel pendulum
KW  - motion commands
KW  - high-performance robotic balancing
KW  - Mobile robots
KW  - Robot kinematics
KW  - Wheels
KW  - Robot sensing systems
KW  - Poles and zeros
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794447
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the first practical demonstration of a recently developed theory of balance control that aims to achieve high performance in the sense of allowing a robot to make large, fast movements while maintaining its balance on a narrow support. This theory includes a simple method of leaning in anticipation of future motion commands, which is largely responsible for the high performance. The experiments reported here use a robot acting as a reaction wheel pendulum, and they test only the 2-D version of the theory. The results show that the balance controller's performance in practice closely resembles its theoretical performance. This paper also presents a simple yet accurate balance offset observer that measures the difference between true and estimated balanced configurations.
ER  - 

TY  - CONF
TI  - OpenRoACH: A Durable Open-Source Hexapedal Platform with Onboard Robot Operating System (ROS)
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9466
EP  - 9472
AU  - L. Wang
AU  - Y. Yang
AU  - G. Correa
AU  - K. Karydis
AU  - R. S. Fearing
PY  - 2019
KW  - accelerometers
KW  - cameras
KW  - control engineering computing
KW  - gyroscopes
KW  - legged locomotion
KW  - operating systems (computers)
KW  - durable open-source hexapedal platform
KW  - hexapedal robot
KW  - onboard single-board computer
KW  - laser cutter
KW  - Beacon sensors
KW  - color vision sensors
KW  - linescan sensors
KW  - cameras
KW  - legged robot
KW  - continuous walking burn-ins
KW  - static payload
KW  - dynamic payload
KW  - robot operating system
KW  - Legged locomotion
KW  - DC motors
KW  - Sensors
KW  - Clamps
KW  - Laser beam cutting
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794042
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - OpenRoACH is a 15-cm 200-gram self-contained hexapedal robot with an onboard single-board computer. To our knowledge, it is the smallest legged robot with the capability of running the Robot Operating System (ROS) onboard. The robot is fully open sourced, uses accessible materials and off-the-shelf electronic components, can be fabricated with benchtop fast-prototyping machines such as a laser cutter and a 3D printer, and can be assembled by one person within two hours. Its sensory capacity has been tested with gyroscopes, accelerometers, Beacon sensors, color vision sensors, linescan sensors and cameras. It is low-cost within $150 including structure materials, motors, electronics, and a battery. The capabilities of OpenRoACH are demonstrated with multi-surface walking and running, 24-hour continuous walking burn-ins, carrying 200-gram dynamic payloads and 800-gram static payloads, and ROS control of steering based on camera feedback. Information and files related to mechanical design, fabrication, assembly, electronics, and control algorithms are all publicly available on https://wiki.eecs.berkeley.edu/biomimetics/Main/OpenRoACH.
ER  - 

TY  - CONF
TI  - Sensorless Force Control of Automated Grinding/Deburring Using an Adjustable force regulation mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9489
EP  - 9495
AU  - Y. Kuo
AU  - S. Huang
AU  - C. Lan
PY  - 2019
KW  - deburring
KW  - end effectors
KW  - feedback
KW  - force control
KW  - force sensors
KW  - geometry
KW  - grinding
KW  - grinding machines
KW  - industrial robots
KW  - machine tool spindles
KW  - polishing
KW  - position control
KW  - prototypes
KW  - quality control
KW  - sensorless force control
KW  - controller feedback
KW  - constant contact force
KW  - force regulation mechanism
KW  - grinding spindle tool
KW  - industrial grinding-deburring operations
KW  - multiaxis force sensor
KW  - polishing quality
KW  - geometry
KW  - grinder prototype
KW  - compliant mechanism
KW  - end-effector
KW  - industrial robots
KW  - Frequency modulation
KW  - Force
KW  - Conferences
KW  - Automation
KW  - Indexes
KW  - Deburring
KW  - Force control
KW  - Automated deburring and polishing
KW  - force control
KW  - constant force
KW  - zero stiffness
KW  - compliant mechanism
DO  - 10.1109/ICRA.2019.8794058
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Controlling the contact force on workpieces has been a challenging task for industrial grinding/deburring operations. Its realization often requires a grinding spindle with a multi-axis force sensor and controller feedback. The spindle needs to frequently vary its position in order to maintain a constant contact force. The use of sensors and control is costly and introduces extra complexity for grinding tools. To improve the polishing quality of handling workpieces of irregular contours, this paper presents a novel force regulation mechanism (FRM) to be installed on grinding tools. Without using additional sensors and control, the FRM can passively produce an adjusTable NORMAL Contact force between the tooltip and workpiece of various geometry. the spindle does not have to move to regulate the contact force. together with a simple grinder which is much less expensive, this approach offers a more attractive solution in terms of cost and complexity. in this paper, the design concept and simulation results are presented and discussed. a prototype of a grinder with the proposed FRM is illustrated to demonstrate the effectiveness and accuracy of force regulation. this novel mechanism is expected to serve as a reliable alternative for industrial grinding/deburring operation.
ER  - 

TY  - CONF
TI  - Constrained Feedback Control by Prioritized Multi-objective Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9496
EP  - 9501
AU  - L. Li
AU  - D. J. Braun
PY  - 2019
KW  - closed loop systems
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - position control
KW  - control inputs
KW  - operational space inverse dynamics control
KW  - constrained prioritized multiobjective optimization-base control formulation
KW  - dynamic-model-free prioritized feedback control formulation
KW  - combined inverse dynamics impedance controller
KW  - planar anthropometric biped robot
KW  - stable locomotion
KW  - Task analysis
KW  - Dynamics
KW  - Impedance
KW  - Optimization
KW  - Feedback control
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794376
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Prioritized multi-objective optimization has been widely used within the operational space inverse dynamics control framework. In this paper, we present a constrained prioritized multi-objective optimization-base control formulation that extends to impedance control, including the `simple' impedance controller, which does not require the dynamic model. The main contribution of this paper is the dynamic-model-free prioritized feedback control formulation which encompasses arbitrary number of priority levels and takes the saturation constraints on the control inputs rigorously into account. The utility of the proposed formulation is demonstrated by a combined inverse dynamics impedance controller used to simulate stable locomotion of a planar anthropometric biped robot.
ER  - 

TY  - CONF
TI  - Exploitation of Environment Support Contacts for Manipulation Effort Reduction of a Robot Arm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9502
EP  - 9508
AU  - C. Fang
AU  - N. Kashiri
AU  - G. F. Rigano
AU  - A. Ajoudani
AU  - N. G. Tsagarakis
PY  - 2019
KW  - compliance control
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - humanoid robots
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - optimal contact force control
KW  - support plane
KW  - contact control point
KW  - three-level hierarchical compliance controller
KW  - nonend-effector support contact
KW  - wrist level manipulation
KW  - upper arm
KW  - elbow joint
KW  - arm joints
KW  - loco-manipulation tasks
KW  - environment constraints
KW  - robot arm
KW  - manipulation effort reduction
KW  - environment support contacts
KW  - control scheme
KW  - interaction forces
KW  - impedance control
KW  - Task analysis
KW  - Robot kinematics
KW  - Manipulators
KW  - Optimization
KW  - Planning
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8794119
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans commonly exploit interaction with the environment constraints to assist the execution of the loco-manipulation tasks they perform. One particular example is the exploration of contacts during manipulation to relax the loading of those arm joints that are not directly involved in the generation of the manipulation motions and forces, e.g. establishing a contact with the elbow joint to reduce the effort of the upper arm while executing wrist level manipulation. In this paper, we shall explore the possibility of actively (a) utilizing the environment for a non-end-effector support contact towards reducing the joints efforts during manipulation tasks. This is achieved by our proposed control scheme with a three-level hierarchical compliance controller. The highest priority task is assigned to an impedance control that regulates the interaction at the contact control point on the arm in the normal direction of the support plane prior to contact, and is switched to an optimal contact force control for minimizing the joint effort after the contact is built. The second priority task is an impedance control at the same point in the tangential directions of the plane to stabilize the contact. In the end, an impedance behavior at the end-effector is designed to deal with the interaction forces required by the manipulation tasks. The efficacy of the proposed control scheme was corroborated by simulations and experiments, where significant joint effort reduction was observed.
ER  - 

TY  - CONF
TI  - A Coordinate-based Approach for Static Balancing and Walking Control of Compliantly Actuated Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9509
EP  - 9515
AU  - D. Lakatos
AU  - Y. Federigi
AU  - T. Gumpert
AU  - B. Henze
AU  - M. Hermann
AU  - F. Loeffl
AU  - F. Schmidt
AU  - D. Seidel
AU  - A. Albu-Schäffer
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - coordinate-based approach
KW  - static balancing
KW  - elastically actuated legged robots
KW  - motor positions
KW  - bijective relation
KW  - link positions
KW  - static external forces
KW  - fully determined system
KW  - vertical foot positions
KW  - walking task
KW  - imposed constraints
KW  - COM
KW  - compliantly actuated legged robots
KW  - Legged locomotion
KW  - Task analysis
KW  - Robot kinematics
KW  - Actuators
KW  - Elasticity
KW  - Force
DO  - 10.1109/ICRA.2019.8793920
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper addresses the static balancing and walking of elastically actuated legged robots. The control is realized by commanding the motor positions only and exploiting the bijective relation between motor and link positions at equilibrium under static external forces. The approach is formulated in a quite general framework first. The main implementation contribution is the definition of a body coordinate system and of an appropriate set of constraints, which leads to a fully determined system of equations. In addition to the desired COM and the vertical foot positions, which are defined by the walking task and the terrain, the imposed constraints are related to distances between individual legs. The controller is experimentally validated on a compliantly actuated quadruped.
ER  - 

TY  - CONF
TI  - Joint kinematic configuration influence on the passivity of an impedance-controlled robotic leg
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9516
EP  - 9522
AU  - F. Y. G. Higa
AU  - G. J. G. Lahr
AU  - G. A. P. Caurin
AU  - T. Boaventura
PY  - 2019
KW  - actuators
KW  - force control
KW  - legged locomotion
KW  - position control
KW  - robot kinematics
KW  - stability
KW  - joint kinematic configuration influence
KW  - impedance-controlled robotic leg
KW  - legged robots
KW  - impedance controller
KW  - inner force loop gains
KW  - passivity conditions
KW  - joint configurations
KW  - leg workspace
KW  - actuation bandwidth
KW  - passive impedance
KW  - Z-width diagram
KW  - Nyquist plot
KW  - Legged locomotion
KW  - Impedance
KW  - Jacobian matrices
KW  - Stability analysis
KW  - Damping
KW  - Torque
DO  - 10.1109/ICRA.2019.8794094
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Although the design of legged robots may be dependent on the application, all of them share the need to safely deal with physical interaction with the environment in every step they take. Impedance controllers have been applied with success to handle contact, and some authors applied the concept of passivity to guarantee stability during the interaction. Whereas previous studies on the passivity of legged robots considered aspects such as inner force loop gains and actuation bandwidth influence on the Z-width (i.e. the range of renderable passive impedances), they did not take into account the role of the kinematic configuration of the leg on the stability of the interaction. Thus, in this work we present a systematic analysis of the effects of joint positions on the passivity conditions of a robotic leg and show that this is a very relevant aspect that may seriously affect the stability and passivity of an impedance controller. By analyzing a linearized model of the leg via its Nyquist plots and the respective Z-width diagrams, we were able to determine what joint configurations within the leg workspace are more suitable to physically interact with the environment or people.
ER  - 

TY  - CONF
TI  - Towards Robot Interaction Autonomy: Explore, Identify, and Interact
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9523
EP  - 9529
AU  - P. Balatti
AU  - D. Kanoulas
AU  - N. G. Tsagarakis
AU  - A. Ajoudani
PY  - 2019
KW  - adaptive control
KW  - agricultural robots
KW  - damping
KW  - human-robot interaction
KW  - mobile robots
KW  - robot dynamics
KW  - self-adjusting systems
KW  - context-aware
KW  - adaptive interaction
KW  - self-tuning impedance controller
KW  - robot quasistatic parameters
KW  - robot sensory data
KW  - vision module
KW  - robot interaction autonomy
KW  - robot sensory vision
KW  - autonomous robot behaviours
KW  - stiffness
KW  - damping
KW  - agricultural task
KW  - Impedance
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Task analysis
KW  - Damping
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794428
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Nowadays, robots are expected to enter in various application scenarios and interact with unknown and dynamically changing environments. This highlights the need for creating autonomous robot behaviours to explore such environments, identify their characteristics and adapt, and build knowledge for future interactions. To respond to this need, in this paper we present a novel framework that integrates multiple components to achieve a context-aware and adaptive interaction between the robot and uncertain environments. The core of this framework is a novel self-tuning impedance controller that regulates robot quasi-static parameters, i.e., stiffness and damping, based on the robot sensory data and vision. The tuning of the parameters is achieved only in the direction(s) of interaction or movement, by distinguishing expected interactions from external disturbances. A vision module is developed to recognize the environmental characteristics and to associate them to the previously/newly identified interaction parameters, with the robot always being able to adapt to the new changes or unexpected situations. This enables a faster robot adaptability, starting from better initial interaction parameters. The framework is evaluated experimentally in an agricultural task, where the robot effectively interacts with various deformable environments.
ER  - 

TY  - CONF
TI  - Personalized Online Learning of Whole-Body Motion Classes using Multiple Inertial Measurement Units
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9530
EP  - 9536
AU  - V. Losing
AU  - T. Yoshikawa
AU  - M. Hasenjaeger
AU  - B. Hammer
AU  - H. Wersing
PY  - 2019
KW  - body sensor networks
KW  - feature extraction
KW  - image classification
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - personalized online learning
KW  - whole-body motion classes
KW  - online action classification
KW  - machine learning applications
KW  - personal behavior patterns
KW  - offline average user models
KW  - personalized models
KW  - motion sequences
KW  - inertial measuring units
KW  - Adaptation models
KW  - Task analysis
KW  - Sensors
KW  - Computational modeling
KW  - Data models
KW  - Hardware
KW  - Training
DO  - 10.1109/ICRA.2019.8794251
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Online action classification is an important field of research, enabling the particularly interesting application scenario of controlling wearable devices which actively support the user's motions. The majority of machine learning applications of real-world systems are based on pre-trained average-user models without any personalization. Our long-term goal is to provide a system that adapts to its user's personal behavior patterns on the fly and in real-time. Ideally, we want to initiate a continuous collaboration between the system and the user where both alternatively adjust to each other to maximize the system's utility. Such tasks are not feasible with static models. In this paper, we investigate the potential and benefits of personalized online learning in the task of online action classification. We record motion sequences of different subjects wearing the Xsens bodysuit, which incorporates multiple inertial measuring units, enabling a fine-grained discrimination of motions. On this basis, we first perform a feature selection, showing that only a few sensors are necessary to achieve a high classification performance. Subsequently, we compare the recognition capabilities of offline average user models against personalized models trained in an online way. Our experiments conclude that personalized models require only few data to outperform average user systems and are particularly valuable for applications with limited computational hardware which rely on the raw sensor inputs only.
ER  - 

TY  - CONF
TI  - Knowledge is Never Enough: Towards Web Aided Deep Open World Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9537
EP  - 9543
AU  - M. Mancini
AU  - H. Karaoguz
AU  - E. Ricci
AU  - P. Jensfelt
AU  - B. Caputo
PY  - 2019
KW  - data mining
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - deep learning architecture
KW  - deep network
KW  - deep extension
KW  - nonparametric model
KW  - autonomous mining
KW  - robot platform
KW  - deep open world recognition
KW  - visual knowledge gaps
KW  - open set recognition
KW  - visual modules
KW  - Robots
KW  - Visualization
KW  - Training
KW  - Feature extraction
KW  - Task analysis
KW  - Artificial neural networks
KW  - Semantics
DO  - 10.1109/ICRA.2019.8793803
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While today's robots are able to perform sophisticated tasks, they can only act on objects they have been trained to recognize. This is a severe limitation: any robot will inevitably see new objects in unconstrained settings, and thus will always have visual knowledge gaps. However, standard visual modules are usually built on a limited set of classes and are based on the strong prior that an object must belong to one of those classes. Identifying whether an instance does not belong to the set of known categories (i.e. open set recognition), only partially tackles this problem, as a truly autonomous agent should be able not only to detect what it does not know, but also to extend dynamically its knowledge about the world. We contribute to this challenge with a deep learning architecture that can dynamically update its known classes in an end-to-end fashion. The proposed deep network, based on a deep extension of a non-parametric model, detects whether a perceived object belongs to the set of categories known by the system and learns it without the need to retrain the whole system from scratch. Annotated images about the new category can be provided by an `oracle' (i.e. human supervision), or by autonomous mining of the Web. Experiments on two different databases and on a robot platform demonstrate the promise of our approach.
ER  - 

TY  - CONF
TI  - Inferring Robot Morphology from Observation of Unscripted Movement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9544
EP  - 9551
AU  - N. Bell
AU  - B. Seipp
AU  - J. Tim Oates
AU  - C. Matuszek
PY  - 2019
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - recurrent neural nets
KW  - robot vision
KW  - low-cost RGB-D camera output
KW  - task sharing
KW  - shared communication protocol
KW  - centralized planner
KW  - shared action
KW  - kinematic model
KW  - large-scale data
KW  - RNN-based methods
KW  - unscripted movement observation
KW  - robots morphological structure
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Morphology
KW  - Task analysis
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794211
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Task sharing between heterogeneous robots currently requires a priori capability knowledge, a shared communication protocol, or a centralized planner. However, in practice, when two robots are brought together, the effort required to construct shared action and structure models can be significant. In this paper, we describe our approach to determining the kinematic model of a robot based purely on observation of unscripted movement. We describe construction of large-scale data simulating low-cost RGB-D camera output, and application of two different RNN-based methods to the learning problem. Our results suggest that this is an efficient and effective way to determine a robot's morphological structure without requiring communication or pre-existing knowledge of its capabilities.
ER  - 

TY  - CONF
TI  - The H3D Dataset for Full-Surround 3D Multi-Object Detection and Tracking in Crowded Urban Scenes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9552
EP  - 9557
AU  - A. Patil
AU  - S. Malla
AU  - H. Gang
AU  - Y. Chen
PY  - 2019
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - optical scanners
KW  - road traffic
KW  - stereo image processing
KW  - large-scale 3D point cloud dataset
KW  - crowded urban scenes
KW  - Honda Research Institute 3D Dataset
KW  - tracking dataset
KW  - 3D LiDAR scanner
KW  - highly interactive traffic scenes
KW  - H3D dataset
KW  - Three-dimensional displays
KW  - Automobiles
KW  - Laser radar
KW  - Labeling
KW  - Robot sensing systems
KW  - Global Positioning System
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793925
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - 3D multi-object detection and tracking are crucial for traffic scene understanding. However, the community pays less attention to these areas due to the lack of a standardized benchmark dataset to advance the field. Moreover, existing datasets (e.g., KITTI [1]) do not provide sufficient data and labels to tackle challenging scenes where highly interactive and occluded traffic participants are present. To address the issues, we present the Honda Research Institute 3D Dataset (H3D), a large-scale full-surround 3D multi-object detection and tracking dataset collected using a 3D LiDAR scanner. H3D comprises of 160 crowded and highly interactive traffic scenes with a total of 1 million labeled instances in 27,721 frames. With unique dataset size, rich annotations, and complex scenes, H3D is gathered to stimulate research on full-surround 3D multi-object detection and tracking. To effectively and efficiently annotate a large-scale 3D point cloud dataset, we propose a labeling methodology to speed up the overall annotation cycle. A standardized benchmark is created to evaluate full-surround 3D multi-object detection and tracking algorithms. 3D object detection and tracking algorithms are trained and tested on H3D. Finally, sources of errors are discussed for the development of future algorithms.
ER  - 

TY  - CONF
TI  - Joint Learning of Instance and Semantic Segmentation for Robotic Pick-and-Place with Heavy Occlusions in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9558
EP  - 9564
AU  - K. Wada
AU  - K. Okada
AU  - M. Inaba
PY  - 2019
KW  - feature extraction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - image-level reasoning
KW  - joint learning model
KW  - visible region masks
KW  - occluded region masks
KW  - instance occlusion segmentation
KW  - semantic occlusion segmentation
KW  - instance segmentation model
KW  - feature extractor
KW  - robotic pick-and-place tasks
KW  - Feature extraction
KW  - Image segmentation
KW  - Semantics
KW  - Task analysis
KW  - Robots
KW  - Cognition
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793783
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present joint learning of instance and semantic segmentation for visible and occluded region masks. Sharing the feature extractor with instance occlusion segmentation, we introduce semantic occlusion segmentation into the instance segmentation model. This joint learning fuses the instance-and image-level reasoning of the mask prediction on the different segmentation tasks, which was missing in the previous work of learning instance segmentation only (instance-only). In the experiments, we evaluated the proposed joint learning comparing the instance-only learning on the test dataset. We also applied the joint learning model to 2 different types of robotic pick-and-place tasks (random and target picking) and evaluated its effectiveness to achieve real-world robotic tasks.
ER  - 

TY  - CONF
TI  - Weakly Supervised Recognition of Surgical Gestures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9565
EP  - 9571
AU  - B. v. Amsterdam
AU  - H. Nakawala
AU  - E. D. Momi
AU  - D. Stoyanov
PY  - 2019
KW  - feature extraction
KW  - Gaussian processes
KW  - gesture recognition
KW  - image classification
KW  - image motion analysis
KW  - image representation
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - robot kinematics
KW  - surgery
KW  - trajectory control
KW  - unsupervised learning
KW  - action recognition
KW  - surgical trajectories
KW  - ground truth annotations
KW  - gesture recognition
KW  - surgical demonstrations
KW  - kinematic trajectories
KW  - surgical robots
KW  - surgical gestures
KW  - automatic segmentation
KW  - surgical skill assessment
KW  - surgical automation
KW  - unsupervised learning methods
KW  - action units
KW  - supervised recognition approaches
KW  - GMM-based algorithm
KW  - task-agnostic initialization methods
KW  - Needles
KW  - Trajectory
KW  - Kinematics
KW  - Measurement
KW  - Tools
KW  - Task analysis
KW  - Robots
KW  - Classification
KW  - Gaussian Mixture Models
KW  - robotic surgery
KW  - kinematics
KW  - surgical gesture recognition
DO  - 10.1109/ICRA.2019.8793696
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Kinematic trajectories recorded from surgical robots contain information about surgical gestures and potentially encode cues about surgeon's skill levels. Automatic segmentation of these trajectories into meaningful action units could help to develop new metrics for surgical skill assessment as well as to simplify surgical automation. State-of-the-art methods for action recognition relied on manual labelling of large datasets, which is time consuming and error prone. Unsupervised methods have been developed to overcome these limitations. However, they often rely on tedious parameter tuning and perform less well than supervised approaches, especially on data with high variability such as surgical trajectories. Hence, the potential of weak supervision could be to improve unsupervised learning while avoiding manual annotation of large datasets. In this paper, we used at a minimum one expert demonstration and its ground truth annotations to generate an appropriate initialization for a GMM-based algorithm for gesture recognition. We showed on real surgical demonstrations that the latter significantly outperforms standard task-agnostic initialization methods. We also demonstrated how to improve the recognition accuracy further by redefining the actions and optimising the inputs.
ER  - 

TY  - CONF
TI  - Visual-Inertial Navigation: A Concise Review
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9572
EP  - 9582
AU  - G. Huang
PY  - 2019
KW  - augmented reality
KW  - image sensors
KW  - inertial navigation
KW  - mobile computing
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - inertial sensors
KW  - visual sensors
KW  - visual-inertial navigation systems
KW  - mobile augmented reality
KW  - aerial navigation
KW  - autonomous driving
KW  - VINS
KW  - SLAM
KW  - Cameras
KW  - Visualization
KW  - Navigation
KW  - Sensors
KW  - Acceleration
KW  - Noise measurement
KW  - Fuses
DO  - 10.1109/ICRA.2019.8793604
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As inertial and visual sensors are becoming ubiquitous, visual-inertial navigation systems (VINS) have prevailed in a wide range of applications from mobile augmented reality to aerial navigation to autonomous driving, in part because of the complementary sensing capabilities and the decreasing costs and size of the sensors. In this paper, we survey thoroughly the research efforts taken in this field and strive to provide a concise but complete review of the related work - which is unfortunately missing in the literature while being greatly demanded by researchers and engineers - in the hope to accelerate the VINS research and beyond in our society as a whole.
ER  - 

TY  - CONF
TI  - Building a Winning Self-Driving Car in Six Months
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9583
EP  - 9589
AU  - K. Burnett
AU  - A. Schimpe
AU  - S. Samavi
AU  - M. Gridseth
AU  - C. W. Liu
AU  - Q. Li
AU  - Z. Kroeze
AU  - A. P. Schoellig
PY  - 2019
KW  - automobiles
KW  - closed loop systems
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - basic autonomy features
KW  - robust algorithms
KW  - multisensor visual localization solution
KW  - winning self-driving car
KW  - SAE AutoDrive Challenge
KW  - Level 4 autonomous vehicle
KW  - Yuma
KW  - Arizona
KW  - Zeus' complete system architecture
KW  - CPU
KW  - closed-loop performance
KW  - Cameras
KW  - Real-time systems
KW  - Navigation
KW  - Computer architecture
KW  - Laser radar
KW  - Visualization
KW  - Systems architecture
DO  - 10.1109/ICRA.2019.8794029
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The SAE AutoDrive Challenge is a three-year competition to develop a Level 4 autonomous vehicle by 2020. The first set of challenges were held in April of 2018 in Yuma, Arizona. Our team (aUToronto/Zeus) placed first. In this paper, we describe Zeus' complete system architecture and specialized algorithms that enabled us to win. We show that it is possible to develop a vehicle with basic autonomy features in just six months relying on simple, robust algorithms. We do not make use of a prior map. Instead, we have developed a multi-sensor visual localization solution. All the algorithms in the paper run in real-time using CPUs only. We also highlight the closed-loop performance of the system in detail in several experiments.
ER  - 

TY  - CONF
TI  - Hierarchical Game-Theoretic Planning for Autonomous Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9590
EP  - 9596
AU  - J. F. Fisac
AU  - E. Bronstein
AU  - E. Stefansson
AU  - D. Sadigh
AU  - S. S. Sastry
AU  - A. D. Dragan
PY  - 2019
KW  - decision making
KW  - game theory
KW  - path planning
KW  - remotely operated vehicles
KW  - road traffic control
KW  - road vehicles
KW  - trajectory control
KW  - game-theoretic trajectory planning algorithm
KW  - trajectory optimization
KW  - dynamic games
KW  - autonomous driving technology
KW  - drivers
KW  - dynamic game theory
KW  - hierarchical game-theoretic planning
KW  - human driver
KW  - autonomous vehicle
KW  - planning horizon
KW  - simplified information structure
KW  - short-horizon tactical game
KW  - long-horizon strategic game
KW  - Vehicle dynamics
KW  - Autonomous vehicles
KW  - Planning
KW  - Games
KW  - Trajectory
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794007
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The actions of an autonomous vehicle on the road affect and are affected by those of other drivers, whether overtaking, negotiating a merge, or avoiding an accident. This mutual dependence, best captured by dynamic game theory, creates a strong coupling between the vehicle's planning and its predictions of other drivers' behavior, and constitutes an open problem with direct implications on the safety and viability of autonomous driving technology. Unfortunately, dynamic games are too computationally demanding to meet the real-time constraints of autonomous driving in its continuous state and action space. In this paper, we introduce a novel game-theoretic trajectory planning algorithm for autonomous driving, that enables real-time performance by hierarchically decomposing the underlying dynamic game into a long-horizon “strategic” game with simplified dynamics and full information structure, and a short-horizon “tactical” game with full dynamics and a simplified information structure. The value of the strategic game is used to guide the tactical planning, implicitly extending the planning horizon, pushing the local trajectory optimization closer to global solutions, and, most importantly, quantitatively accounting for the autonomous vehicle and the human driver's ability and incentives to influence each other. In addition, our approach admits non-deterministic models of human decision-making, rather than relying on perfectly rational predictions. Our results showcase richer, safer, and more effective autonomous behavior in comparison to existing techniques.
ER  - 

TY  - CONF
TI  - IceVisionSet: lossless video dataset collected on Russian winter roads with traffic sign annotations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9597
EP  - 9602
AU  - A. L. Pavlov
AU  - P. A. Karpyshev
AU  - G. V. Ovchinnikov
AU  - I. V. Oseledets
AU  - D. Tsetserukou
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - driver information systems
KW  - image recognition
KW  - road traffic
KW  - visual perception
KW  - camera settings
KW  - weather conditions
KW  - traffic sign images
KW  - Russian winter roads
KW  - Russian traffic code
KW  - IceVisionSet
KW  - lossless video dataset
KW  - traffic sign annotations
KW  - autonomous vehicles
KW  - traffic signs
KW  - image data
KW  - computer vision systems
KW  - Cameras
KW  - Image coding
KW  - Tools
KW  - Roads
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Computer vision
DO  - 10.1109/ICRA.2019.8794341
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Ability of autonomous vehicles to operate in complex dynamic environments requires, among other things, fast and accurate perception of surroundings, which includes recognition and tracking of traffic signs.For development and testing of modern sophisticated computer vision systems large and diverse datasets are of the major importance. To test the robustness of algorithms, image data with different moving speeds, camera settings, lighting and weather conditions are especially important.In this work we present a comprehensive, lifelike dataset of traffic sign images collected on the Russian winter roads in varying conditions, which include different weather, camera exposure, illumination and moving speeds. The dataset was annotated in accordance with the Russian traffic code. Annotation results and images are published under open CC BY 4.0 license and can be downloaded from the project website: http://oscar.skoltech.ru/.
ER  - 

TY  - CONF
TI  - Integrated UWB-Vision Approach for Autonomous Docking of UAVs in GPS-denied Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9603
EP  - 9609
AU  - T. Nguyen
AU  - T. H. Nguyen
AU  - M. Cao
AU  - Z. Qiu
AU  - L. Xie
PY  - 2019
KW  - autonomous aerial vehicles
KW  - computer vision
KW  - displacement measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - robot vision
KW  - unmanned aerial vehicles
KW  - ultrawideband ranging sensor
KW  - approaching phase
KW  - autonomous approaching landing capabilities
KW  - vision-based techniques
KW  - GPS-denied environments
KW  - autonomous docking
KW  - integrated UWB-vision approach
KW  - vision-derived poses
KW  - UWB measurements
KW  - onboard vision system
KW  - relative displacement measurements
KW  - UAV relative
KW  - Displacement measurement
KW  - Unmanned aerial vehicles
KW  - Distance measurement
KW  - Visualization
KW  - Optical variables measurement
KW  - Optical feedback
KW  - Optical saturation
DO  - 10.1109/ICRA.2019.8793851
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Though vision-based techniques have become quite popular for autonomous docking of Unmanned Aerial Vehicles (UAVs), due to limited field of view (FOV), the UAV must rely on other methods to detect and approach the target before vision can be used. In this paper we propose a method combining Ultra-wideband (UWB) ranging sensor with vision-based techniques to achieve both autonomous approaching and landing capabilities in GPS-denied environments. In the approaching phase, a robust and efficient recursive least-square optimization algorithm is proposed to estimate the position of the UAV relative to the target by using the distance and relative displacement measurements. Using this estimate, UAV is able to approach the target until the landing pad is detected by an onboard vision system, then UWB measurements and vision-derived poses are fused with onboard sensor of UAV to facilitate an accurate landing maneuver. Real-world experiments are conducted to demonstrate the efficiency of our method.
ER  - 

TY  - CONF
TI  - Online Vehicle Trajectory Prediction using Policy Anticipation Network and optimization-based Context Reasoning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9610
EP  - 9616
AU  - W. Ding
AU  - S. Shen
PY  - 2019
KW  - inference mechanisms
KW  - optimisation
KW  - regression analysis
KW  - road traffic control
KW  - traffic engineering computing
KW  - ubiquitous computing
KW  - online vehicle trajectory prediction
KW  - two-level vehicle trajectory prediction framework
KW  - urban autonomous driving
KW  - complex contextual factors
KW  - traffic regulations
KW  - moving agents
KW  - high-level policy anticipation
KW  - low-level context reasoning
KW  - short-term memory network
KW  - sequential history observations
KW  - low-level optimization-based context reasoning process
KW  - optimization-based reasoning process
KW  - two-level reasoning process
KW  - continuous trajectory
KW  - regression-based trajectory prediction methods
KW  - vehicle motions
KW  - Trajectory
KW  - Cognition
KW  - Optimization
KW  - Hidden Markov models
KW  - Predictive models
KW  - Geometry
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793568
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an online two-level vehicle trajectory prediction framework for urban autonomous driving where there are complex contextual factors, such as lane geometries, road constructions, traffic regulations and moving agents. Our method combines high-level policy anticipation with low-level context reasoning. We leverage a long short-term memory (LSTM) network to anticipate the vehicle's driving policy (e.g., forward, yield, turn left, turn right, etc.) using its sequential history observations. The policy is then used to guide a low-level optimization-based context reasoning process. We show that it is essential to incorporate the prior policy anticipation due to the multimodal nature of the future trajectory. Moreover, contrary to existing regression-based trajectory prediction methods, our optimization-based reasoning process can cope with complex contextual factors. The final output of the two-level reasoning process is a continuous trajectory that automatically adapts to different traffic configurations and accurately predicts future vehicle motions. The performance of the proposed framework is analyzed and validated in an emerging autonomous driving simulation platform (CARLA).
ER  - 

TY  - CONF
TI  - A Flexible Low-Cost Biologically Inspired Sonar Sensor Platform for Robotic Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9617
EP  - 9623
AU  - D. Laurijssen
AU  - R. Kerstens
AU  - G. Schouten
AU  - W. Daems
AU  - J. Steckel
PY  - 2019
KW  - bioacoustics
KW  - biomimetics
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - sonar
KW  - flexible low-cost biologically inspired sonar sensor
KW  - robotic applications
KW  - biomimetic sonar experiments
KW  - autonomous sonar navigation
KW  - ultrasound
KW  - subsumption architecture
KW  - autonomous navigation control system
KW  - P3DX robotics platform
KW  - big-eared bat
KW  - sonar sensor platform
KW  - biomimetic control mechanisms
KW  - Micronycteris microtis
KW  - echolocating animals
KW  - Robot sensing systems
KW  - Sonar
KW  - Microphones
KW  - Sonar navigation
KW  - Universal Serial Bus
KW  - Ultrasonic imaging
DO  - 10.1109/ICRA.2019.8794165
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present a flexible low-cost sonar sensor platform that can be used for a wide range of biomimetic sonar experiments and autonomous sonar navigation targeted at robotics applications. The navigation abilities of bats using ultrasound (sonar) in unknown cluttered environments are very effective and can be distilled into a sensor architecture and accompanying control methodology that lends itself to be implemented on cost efficient hardware. The sensor architecture and processing methodology of this sensing platform mimics that of bats. In this paper we specifically focused on the common big-eared bat (Micronycteris microtis) although this could be transferred to other bat species or even other echolocating animals since the experimental platform was designed for flexibility. Using this platform we were able to implement a control system using a subsumption architecture that features different behavior patterns based solely on the sonar sensor as a source of exteroceptive information. In order to validate the combination of our autonomous navigation control system and our developed sonar sensor platform, the hardware was mounted on the P3DX robotics platform that was introduced in an unknown testing environment and have it drive autonomously. These experiments were used to validate our assumption of the efficacy of these relatively simple biomimetic control mechanisms and thus alleviating the need for expensive sensing platforms for certain robotics applications.
ER  - 

TY  - CONF
TI  - ClusterNav: Learning-Based Robust Navigation Operating in Cluttered Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9624
EP  - 9630
AU  - G. S. Martins
AU  - R. P. Rocha
AU  - F. J. Pais
AU  - P. Menezes
PY  - 2019
KW  - assisted living
KW  - geriatrics
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robust control
KW  - service robots
KW  - telerobotics
KW  - nonexpert users
KW  - ClusterNav
KW  - cluttered environments
KW  - robust autonomous navigation
KW  - social robots
KW  - elderly users
KW  - traditional model-based navigation techniques
KW  - stable theoretical foundation
KW  - practical foundation
KW  - autonomous operation
KW  - domestic environments
KW  - acceptable behaviour
KW  - novel learning-based technique
KW  - geometric representation
KW  - acceptable manner
KW  - elderly care facility
KW  - traditional model-based approach
KW  - learning-based robust navigation
KW  - Trajectory
KW  - Navigation
KW  - Robot kinematics
KW  - Clustering algorithms
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8794262
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robust autonomous navigation is one of the most important aspects in the acceptance of social robots by elderly users. Traditional model-based navigation techniques provide a stable theoretical and practical foundation for autonomous operation in domestic environments, but fall short in achieving human-like, acceptable behaviour while still being able to robustly navigate cluttered environments. In this work, we propose ClusterNav, a novel learning-based technique for navigation. Our technique consists of teaching the robot how it should move in the environment in a human-like manner, capturing key features of this demonstration in a geometric representation of the environment. This representation is then used to generate new trajectories for execution, allowing the robot move in an acceptable manner. We have tested our technique in a real environment in an elderly care facility, comparing it with the traditional model-based approach. Tests involved both expert and non-expert users teleoperating the robot. Results show that ClusterNav is capable of navigating the environment, achieving better similarity with the reference trajectories and higher execution speed when compared to the model-based approach.
ER  - 


