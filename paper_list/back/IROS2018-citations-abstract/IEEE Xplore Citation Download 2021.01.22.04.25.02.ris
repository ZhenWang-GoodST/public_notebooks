TY  - CONF
TI  - Action Selection for Interactive Object Segmentation in Clutter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6297
EP  - 6304
AU  - T. Patten
AU  - M. Zillich
AU  - M. Vincze
PY  - 2018
KW  - image colour analysis
KW  - image motion analysis
KW  - image segmentation
KW  - RGB-D data
KW  - higher quality segmentation
KW  - probabilistic segmentation approach
KW  - segmentation uncertainty
KW  - probabilistic segmentation framework
KW  - scene motion
KW  - object existence
KW  - object models
KW  - nonprehensile actions
KW  - static object segmentation
KW  - scene representation
KW  - indoor human environments
KW  - complex surroundings
KW  - interactive object segmentation
KW  - Motion segmentation
KW  - Tracking
KW  - Probabilistic logic
KW  - Object segmentation
KW  - Octrees
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593918
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter.
ER  - 

TY  - CONF
TI  - Towards a Real-Time Environment Reconstruction for VR-Based Teleoperation Through Model Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Kohn
AU  - A. Blank
AU  - D. Puljiz
AU  - L. Zenkel
AU  - O. Bieber
AU  - B. Hein
AU  - J. Franke
PY  - 2018
KW  - control engineering computing
KW  - image reconstruction
KW  - image segmentation
KW  - industrial manipulators
KW  - man-machine systems
KW  - mobile robots
KW  - object recognition
KW  - real-time systems
KW  - robot vision
KW  - telerobotics
KW  - virtual reality
KW  - model segmentation
KW  - autonomous mobile robot systems
KW  - human-machine interfaces
KW  - virtual reality-technologies
KW  - mixed reality-technologies
KW  - multimodal teleoperation
KW  - real-time remote control
KW  - noise-reduced visualization
KW  - object recognition
KW  - operator-supporting teleoperation
KW  - real-time feedback
KW  - industrial articulated robotic arm
KW  - real-time environment reconstruction
KW  - VR-based teleoperation
KW  - known object segmentation
KW  - point-cloud visualization
KW  - long distance UDP/IP communication
KW  - Cameras
KW  - Calibration
KW  - Solid modeling
KW  - Robot vision systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594053
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Over the next few years, more and more autonomous mobile robot systems will find their way into modern shop floors. However, it will be necessary to provide human-machine interfaces for interventions in unexpected situations like system-deadlocks, algorithm failures or inabilities. Using virtual or mixed reality-technologies, multi-modal teleoperation offers potential for being a suitable human-machine interface. Essential challenges in this field are, among others, a real-time remote control, a time-efficient and holistic environment detection using multiple sensors, a noise-reduced visualization of sensor-data, and capabilities of object recognition. This paper summarizes research results regarding an architecture capable of a near realtime, interoperable, and operator-supporting teleoperation. The focus of this paper is on a method to efficiently process and visualize point-clouds to meet high frame rate demands of virtual reality applications. To provide near real-time feedback of the robot and its environment over large distances, the presented method is capable to segment known objects from unknown objects to reduce bandwidth requirements. The results of this paper were evaluated using a industrial articulated robotic arm for teleoperation via a long distance UDP/IP communication.
ER  - 

TY  - CONF
TI  - DROAN - Disparity-Space Representation for Obstacle Avoidance: Enabling Wire Mapping & Avoidance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6311
EP  - 6318
AU  - G. Dubey
AU  - R. Madaan
AU  - S. Scherer
PY  - 2018
KW  - collision avoidance
KW  - graph theory
KW  - image segmentation
KW  - image sensors
KW  - mobile robots
KW  - motion control
KW  - neural nets
KW  - robot vision
KW  - stereo image processing
KW  - multiple disparity images
KW  - C-space expansion
KW  - disparity space representation
KW  - generic obstacles
KW  - wire pixels
KW  - confidence map
KW  - semantic segmentation paradigm
KW  - convolutional neural network
KW  - monocular wire detection
KW  - generic obstacle avoidance
KW  - robust autonomous aerial vehicles
KW  - depth estimation
KW  - DROAN - disparity-space representation
KW  - Wires
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Cameras
KW  - Trajectory
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8593499
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wire detection, depth estimation and avoidance is one of the hardest challenges towards the ubiquitous presence of robust autonomous aerial vehicles. We present an approach and a system which tackles these three challenges along with generic obstacle avoidance as well. First, we perform monocular wire detection using a convolutional neural network under the semantic segmentation paradigm, and obtain a confidence map of wire pixels. Along with this, we also use a binocular stereo pair to detect other generic obstacles. We represent wires and generic obstacles using a disparity space representation and do a C-space expansion by using a non-linear sensor model we develop. Occupancy inference for collision checking is performed by maintaining a pose graph over multiple disparity images. For avoidance of wire and generic obstacles, we use a precomputed trajectory library, which is evaluated in an online fashion in accordance to a cost function over proximity to the goal. We follow this trajectory with a path tracking controller. Finally, we demonstrate the effectiveness of our proposed method in simulation for wire mapping, and on hardware by multiple runs for both wire and generic obstacle avoidance.
ER  - 

TY  - CONF
TI  - Robocentric Visual-Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6319
EP  - 6326
AU  - Z. Huai
AU  - G. Huang
PY  - 2018
KW  - distance measurement
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - Monte Carlo methods
KW  - motion estimation
KW  - nonlinear filters
KW  - position measurement
KW  - SLAM (robots)
KW  - robocentric EKF-based VINS
KW  - standard world-centric frameworks
KW  - R-VIO
KW  - real-world experiments
KW  - state-of-the-art VINS
KW  - robocentric visual-inertial odometry
KW  - visual-inertial navigation systems
KW  - consistent localization
KW  - challenging environments
KW  - monocular vision
KW  - moving local frame
KW  - standard world-centric VINS
KW  - global gravity vector
KW  - multistate constraint Kalman filter framework
KW  - visual-inertial odometry algorithm
KW  - global pose
KW  - high-accuracy relative motion
KW  - robocentric formulation
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Computational efficiency
KW  - Navigation
KW  - Standards
KW  - Gravity
KW  - Quaternions
DO  - 10.1109/IROS.2018.8593643
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel robocentric formulation of visual-inertial navigation systems (VINS)within a multi-state constraint Kalman filter (MSCKF)framework and develop an efficient, lightweight, robocentric visual-inertial odometry (R-VIO)algorithm for consistent localization in challenging environments using only monocular vision. The key idea of the proposed approach is to deliberately reformulate the 3D VINS with respect to a moving local frame (i.e., robocentric), rather than a fixed global frame of reference as in the standard world-centric VINS, and instead utilize high-accuracy relative motion estimates for global pose update. As an immediate advantage of using this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align its orientation with the global gravity vector. More importantly, we analytically show that the proposed robocentric EKF-based VINS does not undergo the observability mismatch issue as in the standard world-centric frameworks which was identified as the main cause of inconsistency of estimation. The proposed R-VIO is extensively tested through both Monte Carlo simulations and real-world experiments using different sensor platforms in different environments and shown to achieve competitive performance with the state-of-the-art VINS algorithms in terms of consistency, accuracy and efficiency.
ER  - 

TY  - CONF
TI  - Appearance-Based Along-Route Localization for Planetary Missions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6327
EP  - 6334
AU  - I. Grixa
AU  - P. Schulz
AU  - W. Stürzl
AU  - R. Triebel
PY  - 2018
KW  - image matching
KW  - image registration
KW  - image sequences
KW  - mobile robots
KW  - object recognition
KW  - planetary rovers
KW  - robot vision
KW  - SLAM (robots)
KW  - image preprocessing steps
KW  - recognition framework SeqSLAM
KW  - appearance-based along-route localization algorithm
KW  - planetary missions
KW  - direct sequence-based approach
KW  - Moon-analogue mission
KW  - planetary rover
KW  - image similarity metrics wrt
KW  - translational viewpoint differences
KW  - rotational viewpoint differences
KW  - route traversal conditions
KW  - matching locations
KW  - flexible mechanism
KW  - frame matches
KW  - homing mechanism
KW  - autonomous navigation
KW  - real-time localization
KW  - individual frames
KW  - image sequences
KW  - robust place recognition
KW  - Navigation
KW  - Lighting
KW  - Cameras
KW  - Moon
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - mobile robotics
KW  - field robotics
KW  - place-recognition
KW  - autonomous route navigation
DO  - 10.1109/IROS.2018.8594518
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose an appearance-based along-route localization algorithm that relies on robust place recognition by matching image sequences instead of individual frames. Our approach extends state of the art place recognition framework SeqSLAM in several aspects to realize real-time localization along routes for autonomous navigation. First, our method is online in that we only rely on the recently observed image frames. Second, we provide a homing mechanism based on rotations computed from frame matches. And third, we use a more flexible mechanism to search for matching locations, not restricting the search to straight lines in the cost matrix as in SeqSLAM, but allowing for a wide variety of route traversal conditions such as varying velocities or rotational and translational viewpoint differences. We investigate different image preprocessing steps as well as image similarity metrics wrt. their influence on illumination and viewpoint invariance for a more robust place recognition. On a new challenging dataset, recorded in real world experiments with a planetary rover, in the course of a Moon-analogue mission on Sicily's Mount Etna, we show the feasibility of our direct, sequence-based approach to along-route localization.
ER  - 

TY  - CONF
TI  - A Monocular Indoor Localiser Based on an Extended Kalman Filter and Edge Images from a Convolutional Neural Network
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Unicomb
AU  - R. Ranasinghe
AU  - L. Dantanarayana
AU  - G. Dissanayake
PY  - 2018
KW  - cameras
KW  - convolutional neural nets
KW  - edge detection
KW  - image fusion
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - camera location estimation
KW  - extended Kalman filter
KW  - 6 DOF pose estimation
KW  - visual simultaneous localisation-and-mapping algorithms
KW  - prebuilt map
KW  - ground plane edge image extraction
KW  - motion model
KW  - unsigned distance function
KW  - indoor environment
KW  - monocular images
KW  - monocular indoor localiser
KW  - EKF framework
KW  - CNN
KW  - convolutional neural network
KW  - Image edge detection
KW  - Cameras
KW  - Robot vision systems
KW  - Feature extraction
KW  - Convolution
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594337
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The main contribution of this paper is an extended Kalman filter (EKF)based algorithm for estimating the 6 DOF pose of a camera using monocular images of an indoor environment. In contrast to popular visual simultaneous localisation and mapping algorithms, the technique proposed relies on a pre-built map represented as an unsigned distance function of the ground plane edges. Images from the camera are processed using a Convolutional Neural Network (CNN)to extract a ground plane edge image. Pixels that belong to these edges are used in the observation equation of the EKF to estimate the camera location. Use of the CNN makes it possible to extract ground plane edges under significant changes to scene illumination. The EKF framework lends itself to use of a suitable motion model, fusing information from any other sensors such as wheel encoders or inertial measurement units, if available, and rejecting spurious observations. A series of experiments are presented to demonstrate the effectiveness of the proposed technique.
ER  - 

TY  - CONF
TI  - Automated Map Reading: Image Based Localisation in 2-D Maps Using Binary Semantic Descriptors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6341
EP  - 6348
AU  - P. Panphattarasap
AU  - A. Calway
PY  - 2018
KW  - cartography
KW  - image classification
KW  - image matching
KW  - image representation
KW  - visual databases
KW  - compact binary descriptors
KW  - localisation accuracy
KW  - 2-D map
KW  - location tagged descriptors
KW  - descriptor estimates
KW  - human-system interaction
KW  - human map reading
KW  - variable imaging conditions
KW  - semantic features
KW  - image database matching
KW  - 2-D cartographic map
KW  - semantic matching
KW  - binary semantic descriptors
KW  - image based localisation
KW  - automated map reading
KW  - Semantics
KW  - Buildings
KW  - Junctions
KW  - Roads
KW  - Databases
KW  - Feature extraction
KW  - Meters
DO  - 10.1109/IROS.2018.8594253
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We describe a novel approach to image based localisation in urban environments which uses semantic matching between images and a 2-D cartographic map. This contrasts with the majority of existing approaches which use image to image database matching. We use highly compact binary descriptors to represent locations, indicating the presence or not of semantic features, which significantly increases scalability and has the potential for greater invariance to variable imaging conditions. The approach is also more akin to human map reading, making it better suited to human-system interaction. In this initial study we use semantic features relating to buildings and road junctions in discrete viewing directions. CNN classifiers are used to detect the features in images and we match descriptor estimates with location tagged descriptors derived from the 2-D map to give localisation. The descriptors are not sufficiently discriminative on their own, but when concatenated sequentially along a route, their combination becomes highly distinctive and allows localisation even when using non-perfect classifiers. Performance is further improved by taking into account left or right turns over a route. Experimental results obtained using Google StreetView and OpenStreetMap data show that the approach has considerable potential, achieving localisation accuracy of around 85% using routes corresponding to approximately 200 meters.
ER  - 

TY  - CONF
TI  - Interval-Based Cooperative Uavs Pose Domain Characterization from Images and Ranges
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6349
EP  - 6356
AU  - I. Kenmogne
AU  - V. Drevelle
AU  - E. Marchand
PY  - 2018
KW  - autonomous aerial vehicles
KW  - constraint handling
KW  - control engineering computing
KW  - distance measurement
KW  - iterative methods
KW  - least squares approximations
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - tree searching
KW  - pose uncertainty domains
KW  - interval constraint propagation techniques
KW  - simulated two-robots configurations
KW  - unmanned aerial vehicles
KW  - bounded error measurements
KW  - distances measurements
KW  - ground station
KW  - camera images
KW  - UAV
KW  - cooperative localization
KW  - branch and bound algorithm
KW  - nonlinear iterative weighted least squares
KW  - Cameras
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Position measurement
KW  - Base stations
DO  - 10.1109/IROS.2018.8593742
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An interval-based approach to cooperative localization for a group of unmanned aerial vehicles (UAVs) is proposed. It computes a pose uncertainty domain for each robot, i.e., a set that contains the true robot pose, assuming bounded error measurements. The algorithm combines distances measurements to the ground station and between UAVs, with the tracking of known landmarks in camera images, and provides a guaranteed enclosure of the robots pose domains. Pose uncertainty domains are computed using interval constraint propagation techniques, thanks to a branch and bound algorithm. We show that the proposed method also provides a good point estimate, that can be further refined using nonlinear iterative weighted least squares. Results are presented for simulated two-robots configurations, for experimental data, and compared with a classical Extended Kalman Filter.
ER  - 

TY  - CONF
TI  - Joint Point Cloud and Image Based Localization for Efficient Inspection in Mixed Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6357
EP  - 6363
AU  - M. P. Das
AU  - Z. Dong
AU  - S. Scherer
PY  - 2018
KW  - augmented reality
KW  - calibration
KW  - cameras
KW  - human-robot interaction
KW  - image registration
KW  - image sensors
KW  - inspection
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - mixed-reality headsets
KW  - headset orientation
KW  - structure inspection
KW  - marker-free self-localization
KW  - onboard depth sensor
KW  - simple point cloud registration
KW  - camera image
KW  - inspection information
KW  - joint point cloud and image-based localization
KW  - JPIL
KW  - human-robot interaction
KW  - time 20.0 min
KW  - Three-dimensional displays
KW  - Headphones
KW  - Inspection
KW  - Cameras
KW  - Virtual reality
KW  - Solid modeling
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594318
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a method of structure inspection using mixed-reality headsets to reduce the human effort in reporting accurate inspection information such as fault locations in 3D coordinates. Prior to every inspection, the headset needs to be localized. While external pose estimation and fiducial marker based localization would require setup, maintenance, and manual calibration; marker-free self-localization can be achieved using the onboard depth sensor and camera. However, due to limited depth sensor range of portable mixed-reality headsets like Microsoft HoloLens, localization based on simple point cloud registration (sPCR) would require extensive mapping of the environment. Also, localization based on camera image would face same issues as stereo ambiguities and hence depends on viewpoint. We thus introduce a novel approach to Joint Point Cloud and Image-based Localization (JPIL) for mixed-reality headsets that uses visual cues and headset orientation to register small, partially overlapped point clouds and save significant manual labor and time in environment mapping. Our empirical results compared to sPCR show average 10 fold reduction of required overlap surface area that could potentially save on average 20 minutes per inspection. JPIL is not only restricted to inspection tasks but also can be essential in enabling intuitive human-robot interaction for spatial mapping and scene understanding in conjunction with other agents like autonomous robotic systems that are increasingly being deployed in outdoor environments for applications like structural inspection.
ER  - 

TY  - CONF
TI  - Probabilistic Dense Reconstruction from a Moving Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6364
EP  - 6371
AU  - Y. Ling
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - image sequences
KW  - probability
KW  - SLAM (robots)
KW  - stereo image processing
KW  - TUM RGB-D SLAM
KW  - ICL-NUIM dataset
KW  - spatial correlations
KW  - visual scale changes
KW  - insufficient parallaxes
KW  - motion stereo
KW  - spatial stereo
KW  - single monocular camera
KW  - online dense reconstruction
KW  - probabilistic approach
KW  - moving camera
KW  - probabilistic dense reconstruction
KW  - outdoor experiments
KW  - dense 3D models
KW  - inlier probability expectations
KW  - depth estimates
KW  - probabilistic scheme
KW  - monocular depth estimation
KW  - temporal correlations
KW  - Image reconstruction
KW  - Cameras
KW  - Estimation
KW  - Visualization
KW  - Robot vision systems
KW  - Probabilistic logic
KW  - Simultaneous localization and mapping
DO  - 10.1109/IROS.2018.8593618
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a probabilistic approach for online dense reconstruction using a single monocular camera moving through the environment. Compared to spatial stereo, depth estimation from motion stereo is challenging due to insufficient parallaxes, visual scale changes, pose errors, etc. We utilize both the spatial and temporal correlations of consecutive depth estimates to increase the robustness and accuracy of monocular depth estimation. An online, recursive, probabilistic scheme to compute depth estimates, with corresponding covariances and inlier probability expectations, is proposed in this work. We integrate the obtained depth hypotheses into dense 3D models in an uncertainty-aware way. We show the effectiveness and efficiency of our proposed approach by comparing it with state-of-the-art methods in the TUM RGB-D SLAM & ICL-NUIM dataset. Online indoor and outdoor experiments are also presented for performance demonstration.
ER  - 

TY  - CONF
TI  - Summarizing Large Scale 3D Mesh
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - I. B. Salah
AU  - S. Kramm
AU  - C. Demonceaux
AU  - P. Vasseur
PY  - 2018
KW  - mesh generation
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - vision-based summarizing process
KW  - HD 3D maps
KW  - large-scale 3D map
KW  - semantic information
KW  - geometric information
KW  - photometric information
KW  - autonomous navigation
KW  - semantic mapping
KW  - 3D sensor devices
KW  - Three-dimensional displays
KW  - Navigation
KW  - Entropy
KW  - Semantics
KW  - Visualization
KW  - Optimization
KW  - Robots
DO  - 10.1109/IROS.2018.8593372
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent progress in 3D sensor devices and in semantic mapping allows to build very rich HD 3D maps very useful for autonomous navigation and localization. However, these maps are particularly huge and require important memory capabilities as well computational resources. In this paper, we propose a new method for summarizing a 3D map (Mesh)as a set of compact spheres in order to facilitate its use by systems with limited resources (smartphones, robots, UAVs,...). This vision-based summarizing process is applied in a fully automatic way using jointly photometric, geometric and semantic information of the studied environment. The main contribution of this research is to provide a very compact map that maximizes the significance of its content while maintaining the full visibility of the environment. Experimental results in summarizing large-scale 3D map demonstrate the feasibility of our approach and evaluate the performance of the algorithm.
ER  - 

TY  - CONF
TI  - A Robust Control Method for the Elbow of the Humanoid Robot TEO Based on a Fractional Order Controller
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6378
EP  - 6383
AU  - J. Muñoz
AU  - C. A. Monje
AU  - F. Martín
AU  - C. Balaguer
PY  - 2018
KW  - humanoid robots
KW  - manipulators
KW  - PD control
KW  - robust control
KW  - robust control method
KW  - humanoid robot TEO
KW  - fractional order controller
KW  - elbow joint
KW  - fractional order PD controller
KW  - robust performance
KW  - humanoid right arm
KW  - Gain
KW  - Humanoid robots
KW  - Tuning
KW  - Robustness
KW  - Elbow
DO  - 10.1109/IROS.2018.8593732
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for the control of the elbow joint of the humanoid robot TEO, based on a fractional order PD controller. Due to the graphical nature of the proposed method, a few basic operations are enough to tune the controller, offering very competitive results compared to classic methods. The experiments show a robust performance of the system to mass changes at the tip of the humanoid right arm.
ER  - 

TY  - CONF
TI  - FPGA-Based Velocity Estimation for Control of Robots with Low-Resolution Encoders
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6384
EP  - 6389
AU  - J. Y. Wu
AU  - Z. Chen
AU  - A. Deguet
AU  - P. Kazanzides
PY  - 2018
KW  - closed loop systems
KW  - field programmable gate arrays
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - Cartesian impedance control
KW  - FPGA-based velocity estimation
KW  - low-resolution encoders
KW  - robot control algorithms
KW  - robot joint velocities
KW  - encoder edges
KW  - low velocities
KW  - low resolution encoders
KW  - measurement delay
KW  - closed-loop control
KW  - joint position control
KW  - frequent velocity updates
KW  - common encoder imperfections
KW  - Velocity measurement
KW  - Estimation
KW  - Delays
KW  - Silicon
KW  - Acceleration
KW  - Robots
DO  - 10.1109/IROS.2018.8594139
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot control algorithms often rely on measurements of robot joint velocities, which can be estimated by measuring the time between encoder edges. When encoder edges occur infrequently, such as at low velocities and/or with low resolution encoders, this measurement delay may affect the stability of closed-loop control. This is evident in both the joint position control and Cartesian impedance control of the da Vinci Research Kit (dVRK), which contains several low-resolution encoders. We present a hardware-based method that gives more frequent velocity updates and is not affected by common encoder imperfections such as non-uniform duty cycles and quadrature phase error. The proposed method measures the time between consecutive edges of the same type but, unlike prior methods, is implemented for the rising and falling edges of both channels. Additionally, it estimates acceleration to enable software compensation of the measurement delay. The method is shown to improve Cartesian impedance control of the dVRK.
ER  - 

TY  - CONF
TI  - Active Disturbance Rejection Control of a Flying-Wing Tailsitter in Hover Flight
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6390
EP  - 6396
AU  - Y. Yang
AU  - J. Zhu
AU  - X. Zhang
AU  - X. Wang
PY  - 2018
KW  - active disturbance rejection control
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - helicopters
KW  - motion control
KW  - observers
KW  - position control
KW  - active disturbance rejection control
KW  - flying-wing tailsitter
KW  - hover flight
KW  - tailsitter unmanned aerial vehicle
KW  - vehicle aerodynamics
KW  - accurate vertical flying
KW  - attitude controller
KW  - tracking differentiator
KW  - vertical takeoff and landing
KW  - tailsitter design
KW  - position controller
KW  - VTOL
KW  - six-degrees-of-freedom model
KW  - 6-DOF model
KW  - outdoor stationary hovering
KW  - ADRC
KW  - extended state observer
KW  - ESO
KW  - TD
KW  - Propellers
KW  - Aerodynamics
KW  - Attitude control
KW  - Aircraft
KW  - Earth
KW  - Unmanned aerial vehicles
KW  - Gravity
DO  - 10.1109/IROS.2018.8594470
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the development and hovering control of a tailsitter unmanned aerial vehicle (UAV) that merges long endurance and vertical takeoff and landing (VTOL) abilities. The designed tailsitter contains one flying-wing with two motors and two elevons. Vehicle aerodynamics and a six-degrees-of-freedom (6-DOF) model are especially developed for the tailsitter. To achieve a good performance in outdoor stationary hovering and accurate vertical flying, the active disturbance rejection control (ADRC) for attitude controller is proposed. With signals from extended state observer (ESO) and tracking differentiator (TD), ADRC decouples the system model into a controllable chain of integrators. Based on the decoupled system dynamics, the motion of tailsitter can be easily handled by developed position controller. Experimental results are presented to corroborate the effectiveness of the controller in disturbance rejection.
ER  - 

TY  - CONF
TI  - Underwater Modeling, Experiments and Control Strategies of FroBot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6397
EP  - 6403
AU  - Y. Yi
AU  - F. Zhenhui
AU  - Z. Zhongjing
AU  - Z. Jianqing
PY  - 2018
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - propulsion
KW  - robot dynamics
KW  - underwater vehicles
KW  - two-degree-of-freedom robotic swing-legs
KW  - 2DOF
KW  - Frobot model
KW  - Frobot underwater
KW  - caudal fins
KW  - Morison equation
KW  - control applications
KW  - CPGs control strategy
KW  - optimal control strategy
KW  - dynamic model
KW  - dual swing-legs propulsion mechanism
KW  - Legged locomotion
KW  - Mathematical model
KW  - Dynamics
KW  - Propulsion
KW  - Force
KW  - Acceleration
DO  - 10.1109/IROS.2018.8594455
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - FroBot can locomote both on land and underwater based on its dual swing-legs propulsion mechanism. This paper presents the dynamic model, experimental studies, and control strategies of FroBot underwater. In this work, an experimental setup consisting of two-degree-of-freedom(2DOF) robotic swing-legs is built to study the model of FroBot underwater. We first improve the dynamic model of caudal fins based on the Morison equation. Combined with experimental data, we optimize the model parameters and then obtain the optimal control strategy of uniform swing. In addition, we apply the CPGs control strategy and improve it based on the FroBot model. These two control strategies have their advantages and demonstrate the potential for future use in control applications.
ER  - 

TY  - CONF
TI  - Feedback Linearizing Controller for a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6404
EP  - 6410
AU  - J. C. Cambera
AU  - V. Feliu-Batlle
PY  - 2018
KW  - closed loop systems
KW  - compensation
KW  - flexible manipulators
KW  - friction
KW  - linearisation techniques
KW  - position control
KW  - springs (mechanical)
KW  - state feedback
KW  - vibration control
KW  - single link flexible arm
KW  - passive gravity compensation mechanism
KW  - flexible link robotics
KW  - input state feedback linearization controller
KW  - gravity compensation system
KW  - springs
KW  - double loop control scheme
KW  - motor position control
KW  - flexible link arm tip positioning
KW  - joint friction
KW  - vibration cancellation
KW  - Gravity
KW  - Springs
KW  - Torque
KW  - DC motors
KW  - Actuators
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594409
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Despite the benefits that the spring based gravity compensation mechanism has brought to the field of rigid robotic manipulators, there have been no substantial efforts toward transferring these developments to the field of flexible link robotics. In this paper, we present an input state feedback linearization controller for the tip positioning of a flexible link arm with a gravity compensation system based on springs. The controller is implemented into a double loop control scheme, in which the inner loop addresses the motor position control in presence of joint friction, and the outer loop deals with vibration cancellation and the tracking of fourth-order trajectories for the tip position of the flexible arm. Taking into considerations the interacting forces between the flexible link and the gravity compensation mechanism, and also the characteristics of the control law, we propose a sensory system to measure all the relevant signals. The proposed controller is tested on an experimental prototype built in our laboratory.
ER  - 

TY  - CONF
TI  - A Practical Method to Speed-Up the Experimental Procedure of Iterative Learning Controllers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6411
EP  - 6416
AU  - O. Koçan
AU  - A. Manecy
AU  - C. Poussot-Vassal
PY  - 2018
KW  - adaptive control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - iterative learning control
KW  - vehicle dynamics
KW  - traditional practice
KW  - ILC experiments
KW  - ILC signal
KW  - experimental data
KW  - accurate linear model
KW  - total experimental time
KW  - predicted system data
KW  - practical method
KW  - experimental procedure
KW  - iterative learning controllers
KW  - practical approach
KW  - lengthy experimentational processes
KW  - iterative learning control
KW  - low-order identified models
KW  - Trajectory
KW  - Data models
KW  - Optimization
KW  - Attitude control
KW  - Process control
KW  - Predictive models
KW  - Tracking
DO  - 10.1109/IROS.2018.8594025
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a practical approach for fastening the lengthy experimentational processes that may occur with iterative learning control (ILC) upto a certain level using simple low-order identified models. The traditional practice in ILC experiments is to update the ILC signal by directly using the experimental data after each run of the process which corresponds to one ILC update per one run. When considered from the point of experimental time, even conducting a moderate number of ILC updates can take quite long with this procedure. Since an accurate linear model can adequately represent the actual system upto a certain amplitude and/or frequency of the desired reference, we propose that the total experimental time can be reduced by updating the ILC signal via predicted system data until the limits of the linear model. This approach allows one to carry out large number of ILC updates while not needing to carry out the same amount of real experiments. Consequently, a significant number of experiments that would be needed for achieving the same results can be skipped with a simulation approach. The efficiency of the proposed method was tested through experimentation with three different UAV reference trajectories and the results demonstrated that it is possible to attain significant amount of tracking precision in several flight experiments.
ER  - 

TY  - CONF
TI  - System Identification and Closed-Loop Control of a Hydraulically Amplified Self-Healing Electrostatic (HASEL) Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6417
EP  - 6423
AU  - C. Schunk
AU  - L. Pearson
AU  - E. Acome
AU  - T. G. Morrissey
AU  - N. Correll
AU  - C. Keplinger
AU  - M. E. Rentschler
AU  - J. S. Humbert
PY  - 2018
KW  - closed loop systems
KW  - hydraulic actuators
KW  - PI control
KW  - robots
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - HASEL actuator
KW  - Proportional-Integral controller
KW  - closed-loop control
KW  - Hydraulically Amplified Self-healing Electrostatic actuator
KW  - system identification method
KW  - closed-loop controller
KW  - soft robotic actuators
KW  - high-speed videography based motion tracking
KW  - mass-spring-damper model
KW  - Actuators
KW  - Strain
KW  - Sensors
KW  - Data acquisition
KW  - Capacitance
KW  - Electrodes
KW  - Dielectric liquids
DO  - 10.1109/IROS.2018.8593797
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a system identification method and the development of a closed-loop controller for a Hydraulically Amplified Self-healing Electrostatic (HASEL) actuator. Our efforts focus on developing a reliable and consistent way to identify system models for these soft robotic actuators using high-speed videography based motion tracking. Utilizing a mass-spring-damper model we are able to accurately capture the behavior of a HASEL actuator. We use the resulting plant model to design a Proportional-Integral controller that demonstrates improved closed-loop tracking and steady-state error performance.
ER  - 

TY  - CONF
TI  - Motion Control of Piezo-Driven Stage via a Chattering-Free Sliding Mode Controller with Hysteresis Compensation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6424
EP  - 6430
AU  - Y. Fan
AU  - Y. He
AU  - D. Zhang
AU  - U. Tan
PY  - 2018
KW  - compensation
KW  - control nonlinearities
KW  - hysteresis
KW  - Lyapunov methods
KW  - motion control
KW  - nonlinear control systems
KW  - piezoelectric actuators
KW  - stability
KW  - trajectory control
KW  - uncertain systems
KW  - variable structure systems
KW  - hysteresis compensation
KW  - trajectory tracking
KW  - piezo-driven stage
KW  - hysteresis nonlinearity
KW  - hysteresis model
KW  - motion control
KW  - chattering-free sliding mode controller
KW  - disturbance estimator
KW  - Lyapunov analysis
KW  - Hysteresis
KW  - Uncertainty
KW  - Sliding mode control
KW  - Stability analysis
KW  - Feedforward systems
KW  - Integrated circuit modeling
DO  - 10.1109/IROS.2018.8593442
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel sliding mode controller for trajectory tracking of the piezo-driven stage. The tracking performance of piezoelectric actuator is mainly affected by the hysteresis nonlinearity. Sliding mode control is a possible solution to achieve better tracking performance. However, conventional sliding mode control generates discontinuous control signal which results in chattering. Hence, the hysteresis nonlinearity is first compensated with a hysteresis model, and an uncertainty and disturbance estimator is designed and included to devise a smooth control action. The stability of the proposed method is demonstrated via Lyapunov analysis. Both simulation and experiment are also conducted to verify the effectiveness of the proposed approach. The results are compared with a conventional sliding mode controller and a proportional-integral control with notch filter (PIC-NF).
ER  - 

TY  - CONF
TI  - A Universal Gripper Using Optical Sensing to Acquire Tactile Information and Membrane Deformation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Sakuma
AU  - F. Von Drigalski
AU  - M. Ding
AU  - J. Takamatsu
AU  - T. Ogasawara
PY  - 2018
KW  - deformation
KW  - grippers
KW  - jamming
KW  - membranes
KW  - refractive index
KW  - tactile sensors
KW  - granular-jamming-based gripper
KW  - semitransparent membrane
KW  - irregularly shaped objects
KW  - membrane deformation
KW  - acquire tactile information
KW  - optical sensing
KW  - rectangular objects
KW  - cylindrical objects
KW  - universal gripper
KW  - fully transparent filling
KW  - granular bodies
KW  - refractive index
KW  - Grippers
KW  - Cameras
KW  - Strain
KW  - Grasping
KW  - Prototypes
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8593697
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The universal gripper has attracted attention due to its simple structure and advanced grasping ability for irregularly shaped objects. In this research, we propose a novel design for a granular-jamming-based gripper which uses a transparent filling and a semi-transparent membrane to allow optical sensing to detect both deformation of the membrane and the object being grasped. By adjusting the refractive index of an oil mixture to the refractive index of the granular bodies, we produced a fully transparent filling that allows the use of a camera inside the universal gripper. In this paper, we present the materials and development of our prototype, and describe the experimental confirmation of the prototype's performance. We showed that our prototype was able to grasp cylindrical and rectangular objects between 10 to 70 mm length while also tracking the deformation of the gripper.
ER  - 

TY  - CONF
TI  - Towards a Soft Fingertip with Integrated Sensing and Actuation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6437
EP  - 6444
AU  - B. W. McInroe
AU  - C. L. Chen
AU  - K. Y. Goldberg
AU  - K. Y. Goldberg
AU  - R. Bajcsy
AU  - R. S. Fearing
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - haptic interfaces
KW  - manipulator dynamics
KW  - pneumatic actuators
KW  - tactile sensors
KW  - tactile data
KW  - SOFTcell
KW  - pneumatic actuation
KW  - optical sensing
KW  - novel controllable stiffness tactile device
KW  - soft robotics
KW  - high-dimensional nonlinear soft systems
KW  - complex coupling
KW  - shape changes
KW  - tactile sensing
KW  - environmental geometry
KW  - low intrinsic stiffness
KW  - unstructured environments
KW  - safe interaction
KW  - soft material robots
KW  - integrated sensing
KW  - soft fingertip
KW  - Cameras
KW  - Tactile sensors
KW  - Optical sensors
KW  - Strain
DO  - 10.1109/IROS.2018.8594032
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft material robots are attractive for safe interaction with humans and unstructured environments due to their compliance and low intrinsic stiffness and mass. These properties enable new capabilities such as the ability to conform to environmental geometry for tactile sensing and to undergo large shape changes for actuation. Due to the complex coupling between sensing and actuation in high-dimensional nonlinear soft systems, prior work in soft robotics has primarily focused on either sensing or actuation. This paper presents SOFTcell, a novel controllable stiffness tactile device that incorporates both optical sensing and pneumatic actuation. We report details on the device's design and implementation and analyze results from characterization experiments on sensitivity and performance, which show that SOFTcell can controllably increase its effective modulus from 4.4kPa to 46.1kPa. Additionally, we demonstrate the utility of SOFTcell for grasping in a reactive control task in which tactile data is used to detect fingertip shear as a grasped object slips, and cell pressurization is used to prevent the slip without the need to adjust fingertip position.
ER  - 

TY  - CONF
TI  - Learning Oscillator-Based Gait Controller for String-Form Soft Robots Using Parameter-Exploring Policy Gradients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6445
EP  - 6452
AU  - M. Ishige
AU  - T. Umedachi
AU  - T. Taniguchi
AU  - Y. Kawahara
PY  - 2018
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - mobile robots
KW  - actor-critic
KW  - oscillators
KW  - harness global entrainment
KW  - appropriate mechanosensor feedback
KW  - reinforcement learning technique
KW  - parameter-exploring policy gradients
KW  - string-form soft robots
KW  - oscillator-based gait controller
KW  - soft-bodied robots
KW  - appropriate learning method
KW  - episode based parameter updates
KW  - exploration noise
KW  - physical model
KW  - PEPG
KW  - simulation models
KW  - Robot sensing systems
KW  - Oscillators
KW  - Reinforcement learning
KW  - Force
KW  - Actuators
KW  - Springs
DO  - 10.1109/IROS.2018.8594338
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a methodology to design mechanosensor feedback to oscillator-based controller for worm-like soft-bodied robots. A reinforcement learning technique, i.e., PEPG, is employed to embed appropriate mechanosensor feedback to harness global entrainment among the controller, the body dynamics, and the environment without explicitly designing the interaction between the oscillators. Another reinforcement learning, actor-critic, was applied to train the controller for the simulation models to analyze the effectiveness of PEPG in the system. Furthermore, the gait controller was trained under different body dynamics, i.e., the physical model of a caterpillar and an earthworm. We found that PEPG is suitable for the system probably because it does not add exploration noise to actions and it conducts episode based parameter updates. The simulation results show the proposed method can acquire distinct behavior, i.e., caterpillars' crawling, inching and earthworms' crawling, under different body dynamics. The outcome implies, that by utilizing appropriate learning method, desired functionality can be achieved in soft-bodied robots without explicitly designing their behavior.
ER  - 

TY  - CONF
TI  - A Partially Filled Jamming Gripper for Underwater Recovery of Objects Resting on Soft Surfaces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6461
EP  - 6468
AU  - S. Licht
AU  - E. Collins
AU  - G. Badlissi
AU  - D. Rizzo
PY  - 2018
KW  - compliance control
KW  - end effectors
KW  - grippers
KW  - seawater
KW  - sediments
KW  - underwater vehicles
KW  - partially filled jamming gripper
KW  - soft surfaces
KW  - partially filled membrane
KW  - submerged objects
KW  - soft substrates
KW  - jamming grippers
KW  - particle jamming
KW  - end effector membrane
KW  - internal membrane pressure
KW  - deep sea shipwrecks
KW  - downward force
KW  - maximum lifting force
KW  - gripper membrane
KW  - soft sediment
KW  - irregular objects
KW  - grasping
KW  - fresh water tank experiment
KW  - seawater
KW  - compliant foam
KW  - fine loose sediment
KW  - waterlogged timbers
KW  - compliance control
KW  - underwater object recovery
KW  - Grippers
KW  - Jamming
KW  - Force
KW  - Manifolds
KW  - Solids
KW  - Substrates
KW  - Sediments
KW  - soft robotics
KW  - universal jamming grippers
KW  - marine archeology
DO  - 10.1109/IROS.2018.8593361
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we demonstrate a universal jamming gripper with a partially filled membrane that can pick up submerged objects resting on soft substrates. Jamming grippers take advantage of the phenomenon of particle jamming to control the compliance of an end effector membrane. Changes in internal membrane pressure are used to transition the membrane between hard and soft states. The effort was motivated by the need for tools to sample artifacts on deep sea shipwrecks, which are often found resting on waterlogged timbers, or partially buried in fine, loose sediment. Limiting downward force protects the target, and reduces the likelihood that it will be pushed down in to the substrate, which could lead to a failed grasp. In benchtop tests, the downward force, and the ratio of maximum lifting force to downward force, are shown to be strongly dependent on the initial volume of particles and fluid in the gripper membrane. The gripper achieves lifting forces 6.7 times the downward force on targets with high aspect ratios. Experiments in a fresh water tank demonstrate the ability to grasp objects resting on soft sediment, and compliant foam. Finally, experiments at sea demonstrate that the end effector functions at depths of more than 1000m seawater, successfully grasping a range of irregular objects.
ER  - 

TY  - CONF
TI  - CLASH: Compliant Low Cost Antagonistic Servo Hands
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6469
EP  - 6476
AU  - W. Friedl
AU  - H. Höppner
AU  - F. Schmidt
AU  - M. A. Roa
AU  - M. Grebenstein
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - grippers
KW  - actuators
KW  - grippers
KW  - hand-in-hand grasping
KW  - variable stiffness actuation
KW  - underactuated fingers
KW  - differential coupling mechanism
KW  - DLR Awiwi hand
KW  - lightweight hands
KW  - antagonistic modular hands
KW  - rapid prototyping
KW  - CLASH hands
KW  - compliant low cost antagonistic servo hands
KW  - Tendons
KW  - Thumb
KW  - Force
KW  - Servomotors
KW  - Grasping
KW  - Couplings
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593903
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the first two members of the new generation of CLASH hands, which exploit low cost actuation and rapid prototyping to create antagonistic modular and lightweight hands and grippers. The hands approach the robustness of the DLR Awiwi hand with a much lower complexity and cost. To reduce the number of required actuators, a differential coupling mechanism for underactuated fingers was developed, along with a new mechanism that uses variable stiffness actuation in order to increase the workspace of underactuated fingers. The hands provide a research platform for both hand-in-hand and robotic grasping. Design aspects are discussed, and an initial experimental validation verifies the hands' performance.
ER  - 

TY  - CONF
TI  - FBG-Based Control of a Continuum Manipulator Interacting with Obstacles*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6477
EP  - 6483
AU  - S. Sefati
AU  - R. J. Murphy
AU  - F. Alambeigi
AU  - M. Pozin
AU  - I. Iordachita
AU  - R. H. Taylor
AU  - M. Armand
PY  - 2018
KW  - bone
KW  - Bragg gratings
KW  - dexterous manipulators
KW  - feedback
KW  - fibre optic sensors
KW  - medical robotics
KW  - patient treatment
KW  - FBG feedback
KW  - FBG-based control
KW  - continuum dexterous manipulators
KW  - constraint environments
KW  - shape sensing methods
KW  - optimization-based control algorithm
KW  - FBG tip position feedback
KW  - feedback control algorithm
KW  - CDM interaction
KW  - CDM collisions
KW  - soft obstacles
KW  - hard obstacles
KW  - CDM tip
KW  - fiber Bragg grating shape sensing unit
KW  - CDM shape
KW  - bone degradation
KW  - osteolysis less-invasive treatment
KW  - hard lesions
KW  - soft lesions
KW  - jacobian information
KW  - Shape
KW  - Manipulators
KW  - Jacobian matrices
KW  - Robot sensing systems
KW  - Strain
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594407
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tracking and controlling the shape of continuum dexterous manipulators (CDM) in constraint environments is a challenging task. The imposed constraints and interaction with unknown obstacles may conform the CDM's shape and therefore demands for shape sensing methods which do not rely on direct line of sight. To address these issues, we integrate a novel Fiber Bragg Grating (FBG) shape sensing unit into a CDM, reconstruct the shape in real-time, and develop an optimization-based control algorithm using FBG tip position feedback. The CDM is designed for less-invasive treatment of osteolysis (bone degradation). To evaluate the performance of the feedback control algorithm when the CDM interacts with obstacles, we perform a set of experiments similar to the real scenario of the CDM interaction with soft and hard lesions during the treatment of osteolysis. In addition, we propose methods for identification of the CDM collisions with soft or hard obstacles using the jacobian information. Results demonstrate successful control of the CDM tip based on the FBG feedback and indicate repeatability and robustness of the proposed method when interacting with unknown obstacles.
ER  - 

TY  - CONF
TI  - Modeling and Trajectory Tracking Control of a New Parallel Flexible Link Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6484
EP  - 6489
AU  - M. Morlock
AU  - N. Meyer
AU  - M. Pick
AU  - R. Seifried
PY  - 2018
KW  - control system synthesis
KW  - elastic deformation
KW  - end effectors
KW  - finite element analysis
KW  - flexible manipulators
KW  - geometry
KW  - manipulator dynamics
KW  - tracking
KW  - trajectory control
KW  - arbitrary geometries
KW  - modal truncation
KW  - Component Mode Synthesis
KW  - underactuated robot
KW  - flexible model
KW  - trajectory tracking control
KW  - kinematic loop
KW  - elastic deformations
KW  - linear finite element models
KW  - parallel flexible link robot
KW  - compliant lightweight robot
KW  - end-effector
KW  - Robots
KW  - Strain
KW  - Finite element analysis
KW  - Trajectory tracking
KW  - Kinematics
KW  - Mathematical model
KW  - Shape
DO  - 10.1109/IROS.2018.8594008
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A completely new compliant lightweight robot is presented with a kinematic loop and a highly flexible link. It is explained how to model such parallel robots accurately but still computationally efficient. The elastic deformations are described with the floating frame of reference approach. For the flexible components this allows to use linear finite element models, which can represent arbitrary geometries. These models are further reduced by modal truncation and a Component Mode Synthesis minimizing the number of elastic degrees of freedom, which is necessary for real-time control purposes. The obtained model of the underactuated robot is non-minimum phase for the end-effector as output. Thus, for the applied trajectory tracking controller which is based on servo constraints, the concept of stable inversion is used. The performance is compared to a relocated minimum phase output. Corresponding simulations are validated by first experimental results showing the need for and high accuracy of the flexible model and the trajectory tracking control.
ER  - 

TY  - CONF
TI  - Deep Sequential Models for Sampling-Based Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6490
EP  - 6497
AU  - Y. Kuo
AU  - A. Barbu
AU  - B. Katz
PY  - 2018
KW  - collision avoidance
KW  - computational geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - sampling methods
KW  - deep sequential models
KW  - sequence model
KW  - sampling-based planner
KW  - efficient plans
KW  - planner state
KW  - neural-network-based models
KW  - fewer rejected samples
KW  - multiagent environments
KW  - graphical models
KW  - Hidden Markov models
KW  - Computational modeling
KW  - Planning
KW  - Adaptation models
KW  - Space exploration
KW  - Uncertainty
KW  - Sensors
DO  - 10.1109/IROS.2018.8593947
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.
ER  - 

TY  - CONF
TI  - A Topology-Based Path Similarity Metric and its Application to Sampling-Based Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6498
EP  - 6505
AU  - J. Denny
AU  - K. Chen
AU  - H. Zhou
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - topology
KW  - homotopic similarity
KW  - homotopy equivalence
KW  - naive application
KW  - local planning
KW  - sampling-based motion planning
KW  - topologically distinct portions
KW  - topologically distinct paths
KW  - robotic motion planning
KW  - homotopy classes
KW  - topology-based path similarity metric
KW  - path deformation roadmaps
KW  - multiple homotopically distinct paths
KW  - Measurement
KW  - Planning
KW  - Strain
KW  - Algorithms
KW  - Merging
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594325
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many applications of robotic motion planning benefit from considering multiple homotopically distinct paths rather than a single path from start to goal. However, determining whether paths represent different homotopy classes can be difficult to compute. We propose metrics for efficiently approximating the homotopic similarity of two paths are, instead of verifying homotopy equivalence directly. We propose two metrics: (1) a naive application of local planning, a common subroutine of sampling-based motion planning, and (2) a novel approach that reasons about the topologically distinct portions of the workspace that a path visits. We present three applications of our metric to demonstrate its use and effectiveness: extracting topologically distinct paths from an existing roadmap, comparing paths for robot manipulators, and improving the computational efficiency of an existing sampling-based method, Path Deformation Roadmaps (PDRs), by over two orders of magnitude. We explore the trade-off between quality and computational efficiency in the proposed metrics.
ER  - 

TY  - CONF
TI  - RG-Trees: Trajectory-Free Feedback Motion Planning Using Sparse Random Reference Governor Trees
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6506
EP  - 6511
AU  - F. Golbol
AU  - M. M. Ankarali
AU  - A. Saranli
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - mobile robots
KW  - motion control
KW  - robust control
KW  - sampling methods
KW  - trajectory control
KW  - trees (mathematics)
KW  - trajectory-free feedback motion planning
KW  - high dimensional configuration spaces
KW  - complex environments
KW  - open-loop trajectories
KW  - feedback control policies
KW  - dynamic robot
KW  - planned path
KW  - spatial constraints
KW  - statistical sampling techniques
KW  - control methods
KW  - feedback control theory perspective
KW  - constraint enforcement
KW  - feedback motion planner
KW  - trajectory-free novel feedback motion planning algorithm
KW  - random trees
KW  - tree part
KW  - collision-free region
KW  - connected simple polygonal regions
KW  - reference governor part
KW  - tree structure
KW  - RG-trees
KW  - sparse random reference governor
KW  - sampling based methods
KW  - Robots
KW  - Heuristic algorithms
KW  - Planning
KW  - Collision avoidance
KW  - Dynamics
KW  - Aerospace electronics
KW  - Navigation
DO  - 10.1109/IROS.2018.8594447
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling based methods resulted in feasible and effective motion planning algorithms for high dimensional configuration spaces and complex environments. A vast majority of such algorithms as well as their application rely on generating a set of open-loop trajectories first, which are then tracked by feedback control policies. However, controlling a dynamic robot to follow the planned path, while respecting the spatial constraints originating from the obstacles is still a challenging problem. There are some studies which combine statistical sampling techniques and feedback control methods which address this challenge using different approaches. From the feedback control theory perspective, Reference Governors proved to be a useful framework for constraint enforcement. Very recently, Arslan and Koditschek (2017) introduced a feedback motion planner that utilizes Reference Governors that provably solves the motion planning problem in simplified spherical worlds. In this context, here we propose a “trajectory-free” novel feedback motion planning algorithm which combines the two ideas: random trees and reference governors. Random tree part of the algorithm generates a collision-free region as a set of connected simple polygonal regions. Then, reference governor part navigates the dynamic robot from one region to the adjacent region in the tree structure, ensuring it stays inside the current region and asymptotically reaches to the connected region. Eventually, our algorithm robustly routes the robot from the start location to the goal location without collision. We demonstrate the validity and feasibility of the algorithm on simulation studies.
ER  - 

TY  - CONF
TI  - Real-Time Motion Planning in Changing Environments Using Topology-Based Encoding of Past Knowledge
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6512
EP  - 6517
AU  - R. Fisher
AU  - B. Rosman
AU  - V. Ivan
PY  - 2018
KW  - collision avoidance
KW  - encoding
KW  - graph theory
KW  - mobile robots
KW  - reachability analysis
KW  - topology
KW  - approximate Reeb graph
KW  - BKPIECE algorithms
KW  - topology-based encoding
KW  - trajectory planning
KW  - complex environments
KW  - DRM-connect algorithm
KW  - dynamic reachability maps
KW  - lazy collision checking
KW  - fallback strategy
KW  - RRT-connect algorithm
KW  - sparser roadmaps
KW  - motion planning
KW  - changing environments
KW  - Task analysis
KW  - Trajectory
KW  - Planning
KW  - Heuristic algorithms
KW  - Robots
KW  - Topology
KW  - Maintenance engineering
DO  - 10.1109/IROS.2018.8593879
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Trajectory planning and replanning in complex environments often reuses very little information from the previous solutions. This is particularly evident when the motion is repeated multiple times with only a limited amount of variation between each run. To address this issue, we propose the DRM-connect algorithm, a combination of dynamic reachability maps (DRM) with lazy collision checking and a fallback strategy based on the RRT-connect algorithm which is used to repair the roadmap through further exploration. This fallback allows us to use much sparser roadmaps. Furthermore, we investigate using an approximate Reeb graph to capture the topology-persistent features of the past solutions of the problem utilising this sparsity. We evaluate DRM-connect with a Reeb graph on reaching tasks, and we compare it to state-of-the-art methods. We show that the proposed method outperforms both RRT-connect and BKPIECE algorithms in the number of collision checks required and we show that our method has the potential to scale to systems with higher number degrees of freedom.
ER  - 

TY  - CONF
TI  - Distributionally Robust Sampling-Based Motion Planning Under Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6518
EP  - 6523
AU  - T. Summers
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - Gaussian distribution
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - stochastic processes
KW  - obstacle avoidance
KW  - unpredictable obstacle motion
KW  - uncertain obstacle location
KW  - kinodynamic motion planning
KW  - distributionally robust RRT
KW  - DR-RRT
KW  - Gaussian distributions
KW  - distributionally robust sampling
KW  - distributionally robust incremental sampling
KW  - Uncertainty
KW  - Planning
KW  - Trajectory
KW  - Robots
KW  - Feedback control
KW  - Probabilistic logic
KW  - Stochastic processes
DO  - 10.1109/IROS.2018.8593893
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a distributionally robust incremental sampling-based method for kinodynamic motion planning under uncertainty, which we call distributionally robust RRT (DR-RRT). In contrast to many approaches that assume Gaussian distributions for uncertain parameters, here we consider moment-based ambiguity sets of distributions with given mean and covariance. Chance constraints for obstacle avoidance and internal state bounds are then enforced under the worst-case distribution in the ambiguity set, which gives a coherent assessment of constraint violation risks. The method generates risk-bounded trajectories and feedback control laws for robots operating in dynamic, cluttered, and uncertain environments, explicitly incorporating localization error, stochastic process disturbances, unpredictable obstacle motion, and uncertain obstacle location. We show that the algorithm is probabilistically complete under mild assumptions. Numerical experiments illustrate the effectiveness of the algorithm.
ER  - 

TY  - CONF
TI  - Hierarchical Path Planner Using Workspace Decomposition and Parallel Task-Space RRTs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Mesesan
AU  - M. A. Roa
AU  - E. Icer
AU  - M. Althoff
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - trees (mathematics)
KW  - path planning problems
KW  - C-space planners
KW  - configuration space
KW  - robot end-effector
KW  - collision-free paths
KW  - workspace information
KW  - global planner
KW  - task-space RRTs
KW  - workspace decomposition
KW  - hierarchical path planner
KW  - Task analysis
KW  - Path planning
KW  - End effectors
KW  - Partitioning algorithms
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593870
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a hierarchical path planner consisting of two stages: a global planner that uses workspace information to create collision-free paths for the robot end-effector to follow, and multiple local planners running in parallel that verify the paths in the configuration space by expanding a task-space rapidly-exploring random tree (RRT). We demonstrate the practicality of our approach by comparing it with state-of-the-art planners in several challenging path planning problems. While using a single tree, our planner outperforms other single tree approaches in task-space or configuration space (C-space), while its performance and robustness are comparable to or better than that of parallelized bidirectional C-space planners.
ER  - 

TY  - CONF
TI  - Kinodynamic Comfort Trajectory Planning for Car-Like Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6532
EP  - 6539
AU  - H. Shin
AU  - D. Kim
AU  - S. Yoon
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - concave programming
KW  - force control
KW  - mobile robots
KW  - object detection
KW  - trajectory control
KW  - translational force
KW  - direct collocation method
KW  - smooth trajectory
KW  - kinodynamic comfort trajectory planning
KW  - car-like robots
KW  - personal autonomous mobility
KW  - comfortability
KW  - kinodynamic comfort path planning method
KW  - nonconvex objective function
KW  - bidirectional obstacle detection
KW  - obstacle avoidance
KW  - smooth trajectory generation
KW  - Robots
KW  - Acceleration
KW  - Planning
KW  - Trajectory optimization
KW  - System dynamics
KW  - Linear programming
DO  - 10.1109/IROS.2018.8593397
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As personal autonomous mobility is getting to be more widely adopted, it is more important to consider comfortability of stuffs and persons carried by such mobility. In this work, we define the comfort of a trajectory as forces, specifically, translational force, received to objects carried by a robot while following the trajectory by measuring impulse. To maximize such a comfort, we propose a novel, kinodynamic comfort path planning method based on our definition of comfort. Our work is based on direct collocation method for handling our nonconvex objective function. We also introduce Bidirectional Obstacle Detection(BOD)that identifies the distances along the perpendicular directions to the trajectory. This is mainly designed for avoiding obstacles while minimizing forces causing discomfort. Our experimental results show that our method can compute trajectories whose comfort measures can be up to 18 times higher than those computed by prior related objectives, e.g., squared velocity used for generating smooth trajectory.
ER  - 

TY  - CONF
TI  - Expert-Guided Kinodynamic RRT Path Planner for Non-Holonomic Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6540
EP  - 6545
AU  - J. M. Sanz
AU  - M. Hernando
AU  - G. Zaragoza
AU  - A. Brunete
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - nonholonomic robots
KW  - EGK-RRT
KW  - expert-guided kinodynamic RRT path planner
KW  - expert-guided kinodynamic RRT algorithm
KW  - deterministic control sequences
KW  - Robots
KW  - Navigation
KW  - Heuristic algorithms
KW  - Aerospace electronics
KW  - Path planning
KW  - Planning
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593924
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, an Expert-Guided Kinodynamic RRT algorithm (EGK-RRT) is presented. It aims to consider how a human pilot would navigate a kinodynamic robot. One of the characteristics of this algorithm is the fact that, unlike the original RRT for kinodynamic systems, it generates deterministic control sequences which can be reproduced as long as the sequence of references (sampled states) are known. Here, the performance of the proposed algorithm is tested against the basic RRT, showing that the EGK-RRT greatly improves in terms of execution speed. In addition to this, the influence of using a visibility check and an inertia estimation in order to select the nearest neighbor is also analyzed, demonstrating that a combination of both factors leads to a better overall performance, both in execution speed and in quality of the generated path.
ER  - 

TY  - CONF
TI  - Robot Imitation Through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - R. Fernandez-Fernandez
AU  - J. G. Victores
AU  - D. Estevez
AU  - C. Balaguer
PY  - 2018
KW  - evolutionary computation
KW  - humanoid robots
KW  - human-robot interaction
KW  - optimisation
KW  - robot vision
KW  - trajectory control
KW  - optimization problem
KW  - continuous goal-directed actions
KW  - robot joint trajectories
KW  - online evolved trajectories
KW  - force features
KW  - iron actions
KW  - TEO full-sized humanoid robot
KW  - motor execution
KW  - CGDA execution
KW  - online evolutionary strategies
KW  - evolutionary algorithms
KW  - robot imitation framework
KW  - Trajectory
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Force
KW  - Planning
KW  - Paints
DO  - 10.1109/IROS.2018.8593724
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Continuous Goal-Directed Actions (CGDA)is a robot imitation framework that encodes actions as the changes they produce on the environment. While it presents numerous advantages with respect to other robot imitation frameworks in terms of generalization and portability, final robot joint trajectories for the execution of actions are not necessarily encoded within the model. This is studied as an optimization problem, and the solution is computed through evolutionary algorithms in simulated environments. Evolutionary algorithms require a large number of evaluations, which had made the use of these algorithms in real world applications very challenging. This paper presents online evolutionary strategies, as a change of paradigm within CGDA execution. Online evolutionary strategies shift and merge motor execution into the planning loop. A concrete online evolutionary strategy, Online Evolved Trajectories (OET), is presented. OET drastically reduces computational times between motor executions, and enables working in real world dynamic environments and/or with human collaboration. Its performance has been measured against Full Trajectory Evolution (FTE)and Incrementally Evolved Trajectories (IET), obtaining the best overall results. Experimental evaluations are performed on the TEO full-sized humanoid robot with “paint” and “iron” actions that together involve vision, kinesthetic and force features.
ER  - 

TY  - CONF
TI  - Probabilistic Learning of Torque Controllers from Kinematic and Force Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Silvério
AU  - Y. Huang
AU  - L. Rozo
AU  - S. Calinon
AU  - D. G. Caldwell
PY  - 2018
KW  - control engineering computing
KW  - force control
KW  - Gaussian distribution
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - position control
KW  - torque control
KW  - kinematic constraints
KW  - task representation
KW  - task space
KW  - Gaussian distributions
KW  - 7- DoF torque-controlled manipulators
KW  - joint space
KW  - torque control commands
KW  - operational configuration space
KW  - force constraints
KW  - probabilistic learning
KW  - Task analysis
KW  - Torque
KW  - Aerospace electronics
KW  - Probabilistic logic
KW  - Force
KW  - End effectors
DO  - 10.1109/IROS.2018.8594103
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - When learning skills from demonstrations, one is often required to think in advance about the appropriate task representation (usually in either operational or configuration space). We here propose a probabilistic approach for simultaneously learning and synthesizing torque control commands which take into account task space, joint space and force constraints. We treat the problem by considering different torque controllers acting on the robot, whose relevance is learned probabilistically from demonstrations. This information is used to combine the controllers by exploiting the properties of Gaussian distributions, generating new torque commands that satisfy the important features of the task. We validate the approach in two experimental scenarios using 7- DoF torque-controlled manipulators, with tasks that require the consideration of different controllers to be properly executed.
ER  - 

TY  - CONF
TI  - Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6560
EP  - 6565
AU  - K. C. Mbanisi
AU  - H. Kimpara
AU  - T. Meier
AU  - M. Gennert
AU  - Z. Li
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - road vehicles
KW  - vehicle dynamics
KW  - human-vehicle interaction simulation framework
KW  - driving motions
KW  - vehicle maneuver motion primitives
KW  - driving decision-making
KW  - vehicle design
KW  - human demonstration
KW  - vehicle dynamics
KW  - motion control
KW  - motion primitive library
KW  - longitudinal vehicle control
KW  - motion reproduction
KW  - dynamic motion primitives
KW  - imitation learning methods
KW  - fixed-base driving simulation
KW  - vehicle maneuver motion planning
KW  - Vehicles
KW  - Computational modeling
KW  - Task analysis
KW  - Motion segmentation
KW  - Vehicle dynamics
KW  - Hidden Markov models
KW  - Dynamics
DO  - 10.1109/IROS.2018.8593976
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - High-fidelity computational human models provide a safe and cost-efficient method for studying driver experience in vehicle maneuvers and for validation of vehicle design. Compared to passive human models, active human models capable of reproducing the decision-making, as well as vehicle maneuver motion planning and control, will be able to support realistic simulation of human-vehicle interaction. In this paper, we propose an integrated human-vehicle interaction simulation framework which learns vehicle maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions. Specifically, we recruited six experienced drivers and recorded their vehicle maneuver motions on a fixed-base driving simulation testbed. We further segmented and classified the collected data based on their similarity in joint coordination. Using a combination of imitation learning methods, we extracted the regularity and variability of vehicle maneuver motions across subjects, and learned the dynamic motion primitives to be used for motion reproduction in simulation. We present an implementation of the framework on lower-extremity joint coordination in pedal activation for longitudinal vehicle control. Our research efforts lead to a motion primitive library which enables planning natural driver motions, and will be integrated with the driving decision-making, motion control, and vehicle dynamics in the proposed framework for simulating human-vehicle interaction.
ER  - 

TY  - CONF
TI  - Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6566
EP  - 6573
AU  - Y. S. Liang
AU  - D. Pellier
AU  - H. Fiorino
AU  - S. Pesty
AU  - M. Cakmak
PY  - 2018
KW  - human-robot interaction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - teaching
KW  - user interfaces
KW  - teaching strategies
KW  - end-user programming
KW  - learning task
KW  - human teachers
KW  - fetch mobile manipulator
KW  - warehouses
KW  - robotic shelf organization
KW  - online user study
KW  - goal inference approach
KW  - system implementation
KW  - grocery store shelf images
KW  - Task analysis
KW  - Programming
KW  - Manipulators
KW  - Shape
KW  - Packaging
KW  - Education
DO  - 10.1109/IROS.2018.8593518
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.
ER  - 

TY  - CONF
TI  - Incremental Skill Learning of Stable Dynamical Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6574
EP  - 6581
AU  - M. Saveriano
AU  - D. Lee
PY  - 2018
KW  - control engineering computing
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - regression analysis
KW  - robot programming
KW  - stability
KW  - trajectory control
KW  - control input
KW  - Gaussian process regression
KW  - incremental skill learning
KW  - online adaptation
KW  - assistive robotic applications
KW  - motion trajectories
KW  - dynamical systems
KW  - skill acquisition
KW  - autonomous DS
KW  - stability properties
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Training
KW  - Training data
KW  - Gaussian processes
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594474
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Efficient skill acquisition, representation, and online adaptation to different scenarios has become of fundamental importance for assistive robotic applications. In the past decade, dynamical systems (DS) have arisen as a flexible and robust tool to represent learned skills and to generate motion trajectories. This work presents a novel approach to incrementally modify the dynamics of a generic autonomous DS when new demonstrations of a task are provided. A control input is learned from demonstrations to modify the trajectory of the system while preserving the stability properties of the reshaped DS. Learning is performed incrementally through Gaussian process regression, increasing the robot's knowledge of the skill every time a new demonstration is provided. The effectiveness of the proposed approach is demonstrated with experiments on a publicly available dataset of complex motions.
ER  - 

TY  - CONF
TI  - Deeply Informed Neural Sampling for Robot Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6582
EP  - 6588
AU  - A. H. Qureshi
AU  - M. C. Yip
PY  - 2018
KW  - collision avoidance
KW  - computational complexity
KW  - feedforward neural nets
KW  - geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - sampling methods
KW  - obstacle geometry
KW  - computational complexity
KW  - configuration space
KW  - optimal path solution
KW  - hand-crafted heuristics
KW  - high-dimensional spaces
KW  - neural network-based adaptive sampler
KW  - raw point cloud data
KW  - workspace encoding
KW  - collision-free optimal paths
KW  - point-mass robot
KW  - 6-link robotic manipulator
KW  - dropout-based stochastic deep feedforward neural network
KW  - DeepSMPs neural architecture
KW  - deep sampling-based motion planner
KW  - robot motion planning
KW  - deeply informed neural sampling
KW  - contractive autoencoder
KW  - rigid-body
KW  - Planning
KW  - Robots
KW  - Encoding
KW  - Three-dimensional displays
KW  - Convergence
KW  - Switched mode power supplies
KW  - Transforms
DO  - 10.1109/IROS.2018.8593772
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling-based Motion Planners (SMPs) have become increasingly popular as they provide collision-free path solutions regardless of obstacle geometry in a given environment. However, their computational complexity increases significantly with the dimensionality of the motion planning problem. Adaptive sampling is one of the ways to speed up SMPs by sampling a particular region of a configuration space that is more likely to contain an optimal path solution. Although there are a wide variety of algorithms for adaptive sampling, they rely on hand-crafted heuristics; furthermore, their performance decreases significantly in high-dimensional spaces. In this paper, we present a neural network-based adaptive sampler for motion planning called Deep Sampling-based Motion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their overall speed significantly while exhibiting efficient scalability to higher-dimensional problems. DeepSMP's neural architecture comprises of a Contractive AutoEncoder which encodes given workspaces directly from a raw point cloud data, and a Dropout-based stochastic deep feedforward neural network which takes the workspace encoding, start and goal configuration, and iteratively generates feasible samples for SMPs to compute end-to-end collision-free optimal paths. DeepSMP is not only consistently computationally efficient in all tested environments but has also shown remarkable generalization to completely unseen environments. We evaluate DeepSMP on multiple planning problems including planning of a point-mass robot, rigid-body, 6-link robotic manipulator in various 2D and 3D environments. The results show that on average our method is at least 7 times faster in point-mass and rigid-body case and about 28 times faster in 6-link robot case than the existing state-of-the-art.
ER  - 

TY  - CONF
TI  - Inverse Learning of Robot Behavior for Collaborative Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Trivedi
AU  - P. Doshi
PY  - 2018
KW  - behavioural sciences computing
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - planning (artificial intelligence)
KW  - robots decision making
KW  - TurtleBots
KW  - Phantom X arms
KW  - line robots behavior
KW  - collaborative planning problem
KW  - colored-ball sorting task
KW  - unripe fruit
KW  - ripe fruit
KW  - IRL
KW  - inverse reinforcement learning
KW  - Task analysis
KW  - Planning
KW  - Robot kinematics
KW  - Sorting
KW  - Teamwork
DO  - 10.1109/IROS.2018.8593745
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Inverse reinforcement learning (IRL) is an important basis for learning from demonstrations. Observing an agent, human or robotic, perform a task provides information and facilitates learning the task. We show how the agent's preferences learned using IRL can be incorporated in a subject robot's decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. We prioritize a real-world application, where a line robot will autonomously collaborate with another robot in sorting ripe and unripe fruit such as oranges. Toward this, our evaluations utilize a colored-ball sorting task as an analog using simulated TurtleBots equipped with Phantom X arms. Our method is comprehensive providing first answers to questions such as how should the robot acquire the complete model for the collaborative planning problem and how should it solve the problem to obtain a plan that permits collaboration without disrupting the line robot's behavior.
ER  - 

TY  - CONF
TI  - Multi-Cable Rolling Locomotion with Spherical Tensegrities Using Model Predictive Control and Deep Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - B. Cera
AU  - A. M. Agogino
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - differential equations
KW  - feedback
KW  - learning (artificial intelligence)
KW  - open loop systems
KW  - predictive control
KW  - robust control
KW  - trajectory control
KW  - generated optimal MPC trajectories
KW  - supervised deep learning
KW  - contextual policy
KW  - benchmark single-cable policy performance
KW  - resulting multicable state-action trajectories
KW  - dynamic rolling
KW  - multicable actuation trajectories
KW  - Class-1 tensegrity systems
KW  - structured dynamics
KW  - spherical tensegrity topology
KW  - robust control policies
KW  - model-based approach
KW  - model predictive control
KW  - spherical tensegrities
KW  - multicable rolling locomotion
KW  - end-to-end feedback policy
KW  - Mathematical model
KW  - Predictive control
KW  - Topology
KW  - Robot kinematics
KW  - Dynamics
KW  - Optimization
DO  - 10.1109/IROS.2018.8594401
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a model-based approach for creating robust control policies for rolling locomotion with a spherical tensegrity topology. Utilizing the structured dynamics of Class-1 tensegrity systems, we turn to model predictive control (MPC) to generate optimal multi-cable actuation trajectories for dynamic rolling. Although the resulting multi-cable state-action trajectories successfully outperform the benchmark single-cable policy performance in speed, computational constraints prevent MPC from being applied in real-time. To address this, we demonstrate that a contextual policy trained using supervised deep learning on the generated optimal MPC trajectories can be used as an end-to-end feedback policy for real-time directed rolling locomotion.
ER  - 

TY  - CONF
TI  - Integrating Path Planning and Pivoting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6601
EP  - 6608
AU  - S. Cruciani
AU  - C. Smith
PY  - 2018
KW  - end effectors
KW  - path planning
KW  - manipulator
KW  - pivoting strategy
KW  - Baxter robot
KW  - path planning
KW  - motion planning
KW  - in-hand manipulation
KW  - end-effector
KW  - Grippers
KW  - Task analysis
KW  - Friction
KW  - End effectors
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593584
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we propose a method for integrating motion planning and in-hand manipulation. Commonly addressed as a separate step from the final execution, in-hand manipulation allows the robot to reorient an object within the end-effector for the successful outcome of the goal task. A joint achievement of repositioning the object and moving the manipulator towards its desired final pose saves time in the execution and introduces more flexibility in the system. We address this problem using a pivoting strategy (i.e. in-hand rotation)for repositioning the object and we integrate this strategy with a path planner for the execution of a complex task. This method is applied on a Baxter robot and its efficacy is shown by experimental results.
ER  - 

TY  - CONF
TI  - Rubik's Cube Handling Using a High-Speed Multi-Fingered Hand and a High-Speed Vision System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6609
EP  - 6614
AU  - R. Higo
AU  - Y. Yamakawa
AU  - T. Senoo
AU  - M. Ishikawa
PY  - 2018
KW  - dexterous manipulators
KW  - manipulator dynamics
KW  - robot vision
KW  - continuous high-speed operation
KW  - one-face turn motion
KW  - high-speed multifingered hand
KW  - high-speed vision system
KW  - Rubiks cube handling
KW  - robotic hand regrasping function
KW  - time 1.0 s
KW  - time 10.0 s
KW  - Gravity
KW  - Face
KW  - Robot sensing systems
KW  - Turning
KW  - Trajectory
KW  - Orbits
DO  - 10.1109/IROS.2018.8593538
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The regrasping function of a robotic hand and arm has been investigated by many studies. Dynamic regrasping is performed by accelerating objects and it has the advantage of being able to perform the regrasp function at high speed. However, the difficulty of increasing the success rate is a persistent problem. In this study, we aimed to realize this continuous high-speed operation by increasing the success rate of the regrasping function. The handling of the Rubik's cube was used as the specific task to be performed. The action that was required to handle the Rubik's cube consisted of two types of regrasping motion and one type of one-face turn motion. In this study, a Rubik's cube was placed in a plane and manipulated by combining these three types of motion. Continuous operation was realized with a robotic hand and high-speed vision by utilizing environmental constraints in order to minimize the error. As a result, we succeeded 3 times in turning and regrasping in 1 s. Additionally, we were able to succeed 30 times in turning and regrasping in 10 s, with a success rate of 70%.
ER  - 

TY  - CONF
TI  - Contingent Contact-Based Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6615
EP  - 6621
AU  - E. Páll
AU  - A. Sieverling
AU  - O. Brock
PY  - 2018
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robust control
KW  - POMDP-based planners
KW  - contingent contact-based motion planning
KW  - contact sensing capability
KW  - manipulation planner
KW  - conformant planners
KW  - high-dimensional configuration spaces
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Planning
KW  - Partitioning algorithms
KW  - Vegetation
DO  - 10.1109/IROS.2018.8594365
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A robot with contact sensing capability can reduce uncertainty relative to the environment by deliberately moving into contact and matching the resulting contact measurement to different possible states in the world. We present a manipulation planner that finds and sequences these actions by reasoning explicitly about the uncertainty over the robot's state. The planner incrementally constructs a policy that covers all possible contact states during a manipulation and finds contingencies for each of them. In contrast to conformant planners (without contingencies), the planned contingent policies are more robust. We demonstrate this in simulated and real-world manipulation experiments. In contrast to POMDP-based planners, we show that our planner can be directly applied to high-dimensional configuration spaces.
ER  - 

TY  - CONF
TI  - A Lightweight Redundant Manipulator with High Stable Wireless Communication and Compliance Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6622
EP  - 6627
AU  - L. Han
AU  - L. Yan
AU  - W. Xu
PY  - 2018
KW  - compliance control
KW  - control engineering computing
KW  - dexterous manipulators
KW  - force control
KW  - intelligent manufacturing systems
KW  - motion control
KW  - position control
KW  - production engineering computing
KW  - protocols
KW  - redundant manipulators
KW  - servomechanisms
KW  - wireless sensor networks
KW  - Zigbee
KW  - 7-DOF manipulator
KW  - application layer protocol
KW  - ZigBee
KW  - absolute magnetic encoder
KW  - incremental magnetic encoder
KW  - hall sensors
KW  - Industry 4.0
KW  - distributed networked-manufacturing system
KW  - joint servo controllers
KW  - intelligent manufacturing system
KW  - manipulator body
KW  - high stable wireless communication link
KW  - motion controller
KW  - lightweight redundant manipulator
KW  - wireless impedance control experiments
KW  - electrical cables
KW  - wireless compliance control frame
KW  - force control requirements
KW  - communication stability
KW  - wireless communication module
KW  - central controller
KW  - communication cables
KW  - Manipulators
KW  - ZigBee
KW  - Wireless communication
KW  - Servomotors
KW  - Wireless sensor networks
KW  - Impedance
KW  - Sensors
KW  - 7-DOF manipulator
KW  - Multilevel control system
KW  - ZigBee
KW  - Wireless compliance Control
DO  - 10.1109/IROS.2018.8593500
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For traditional manipulators, there is a large number of electrical cables between the motion controller and the joint servo controllers. It is very inconvenient for maintenance, update, and safe operation. In this paper, we develop a lightweight redundant manipulator with high stable wireless communication link and compliance control. The motion controller, servo controller, and communication link are taken as a whole system to be optimized. The manipulator body and the motion controller are physically separated. It is very helpful for building distributed networked-manufacturing system or intelligent manufacturing system for Industry 4.0. The control system can be quickly updated by changing the object's identification without reconnect the communication cables. The mechanical part of the manipulator contains modular joints and links. Each joint is integrated with hall sensors, an incremental magnetic encoder, an absolute magnetic encoder and current sensors. The electrical part includes a central controller, seven joint servo controllers, and a wireless communication module based on ZigBee. By designing the application layer protocol, the communication stability is improved. In order to achieve the force control requirements in fine operation like assembly. A wireless compliance control frame is then designed. The compliance control method is realized on the central controller, by which the generated control commands are sent to the joint servo controllers through a wireless link. The problems caused by large electrical cables are then solved. Finally, the prototype and the experimental system are developed. Some experiments are carried out, including wireless communication test, trajectory tracking experiments, load carrying experiments, and wireless impedance control experiments. Results verify the functions and performance of the developed 7-DOF manipulator.
ER  - 

TY  - CONF
TI  - A Cable-Driven Redundant Spatial Manipulator with Improved Stiffness and Load Capacity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6628
EP  - 6633
AU  - T. Liu
AU  - Z. Mu
AU  - H. Wang
AU  - W. Xu
AU  - Y. Li
PY  - 2018
KW  - control system synthesis
KW  - dexterous manipulators
KW  - end effectors
KW  - flexible manipulators
KW  - Jacobian matrices
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - redundant manipulators
KW  - cable transmission mechanisms
KW  - load capacity experiments
KW  - relatively high stiffness
KW  - cable-driven redundant spatial manipulator
KW  - flexible manipulability
KW  - revolute rigid manipulators
KW  - mechanism design
KW  - manipulator dexterity
KW  - end-effector accuracy
KW  - active-passive-linkage segments
KW  - active-passive segment
KW  - manipulator kinematic equations
KW  - motion planning
KW  - Jacobian matrix
KW  - Denavit-Hartenberg method
KW  - D-H method
KW  - CRSM
KW  - Couplings
KW  - Kinematics
KW  - Springs
KW  - Task analysis
KW  - End effectors
KW  - Cable-driven
KW  - Redundant manipulator
KW  - Stiffness
KW  - Load capacity
KW  - Kinematic
DO  - 10.1109/IROS.2018.8593679
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - With a light and slender body, a cable-driven redundant spatial manipulator (CRSM) has flexible manipulability and high maneuverability in confined environment. However, compared with revolute rigid manipulators, such type of manipulators generally has low stiffness and weak load capacity. In this paper, we propose a new mechanism design to improve the stiffness and load capacity without sacrificing the manipulator dexterity and the end-effector accuracy. The manipulator is composed of 3 active-passive-linkage segments and 1 active tool end-effector. Each active-passive segment has 2 degrees of freedom (DOFs) driven by three evenly distributed cables. Pretension mechanism and linkage cables are designed to keep strict equal angles of adjacent joints. A separable control box, which contains all the motors and cable transmission mechanisms is also designed with a quick release-and-lock mechanism. Therefore, the robotic arm can be easily removed and installed. Based on the equal angle characteristic, kinematic equations of manipulator are established with Denavit-Hartenberg (D-H) method and the Jacobian matrix is also simplified. Further analysis of the workspace supplies the guidance for the task design and motion planning. Finally, a prototype system is developed to perform the stiffness and load capacity experiments. Experimental results show that the developed CRSM has relatively high stiffness and load capacity.
ER  - 

TY  - CONF
TI  - Nonprehensile Pushing Manipulation Strategies for a Multi-Limb Robot*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - G. Zhang
AU  - S. Ma
AU  - Y. Li
PY  - 2018
KW  - legged locomotion
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - system states
KW  - system trajectory
KW  - nonprehensile
KW  - manipulation strategies
KW  - multilimb robot
KW  - control strategy
KW  - point contacts
KW  - contact velocity constraint
KW  - force constraint
KW  - system forces
KW  - system dynamic models
KW  - Robot kinematics
KW  - Force
KW  - Acceleration
KW  - Humanoid robots
KW  - Legged locomotion
KW  - Friction
DO  - 10.1109/IROS.2018.8593914
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper explores the control strategy for a multi-limb robot nonprehensilely pushing an object to slide on the floor. The robot's limb distals perform point contacts with the object and the floor. The contact velocity constraint and force constraint are proposed to prevent separation and restrict the system forces. Then the constraints are combined with the system dynamic models to obtain bounds on the system states. We solve the motion planning problem by selecting a feasible path in the reduced-dimensional space and generating the system trajectory along the selected path. An example is provided to illustrate the application of our technique on the physical platform.
ER  - 

TY  - CONF
TI  - Assisted Telemanipulation: A Stack-Of-Tasks Approach to Remote Manipulator Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Stoyanov
AU  - R. Krug
AU  - A. Kiselev
AU  - D. Sun
AU  - A. Loutfi
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - haptic interfaces
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - telerobotics
KW  - assisted telemanipulation
KW  - stack-of-tasks approach
KW  - remote manipulator control
KW  - assisted teleoperation
KW  - robot arm
KW  - hierarchical nature
KW  - SoT framework
KW  - operator commands
KW  - assistive tasks
KW  - joint limit
KW  - obstacle avoidance
KW  - automatic gripper alignment
KW  - teleoperation problem
KW  - assistive control
KW  - manual control
KW  - real-time stack-of-tasks whole-body motion control framework
KW  - teleoperated pick-and-place tasks
KW  - telemanipulation system
KW  - Task analysis
KW  - Grippers
KW  - Robot kinematics
KW  - Manipulators
KW  - Acceleration
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594457
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This article presents an approach for assisted teleoperation of a robot arm, formulated within a real-time stack-of-tasks (SoT)whole-body motion control framework. The approach leverages the hierarchical nature of the SoT framework to integrate operator commands with assistive tasks, such as joint limit and obstacle avoidance or automatic gripper alignment. Thereby some aspects of the teleoperation problem are delegated to the controller and carried out autonomously. The key contributions of this work are two-fold: the first is a method for unobtrusive integration of autonomy in a telemanip-ulation system; and the second is a user study evaluation of the proposed system in the context of teleoperated pick-and-place tasks. The proposed approach of assistive control was found to result in higher grasp success rates and shorter trajectories than achieved through manual control, without incurring additional cognitive load to the operator.
ER  - 

TY  - CONF
TI  - Adaptive Admittance Control in Task-Priority Framework for Contact Force Control in Autonomous Underwater Floating Manipulation* This work is part of a project titled “Force/position control system to enable compliant manipulation from a floating I-AUV”, which received funding from the European Union's Horizon 2020 research and innovation programme, under the Marie Sklodowska-Curie grant agreement no. 750063.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6646
EP  - 6651
AU  - P. Cieślak
AU  - P. Ridao
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cooperative systems
KW  - end effectors
KW  - force control
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - manipulators
KW  - mobile robots
KW  - position control
KW  - task-priority kinematic control algorithm
KW  - custom force control strategy
KW  - impedance control
KW  - TP algorithm
KW  - inequality tasks
KW  - singular configurations
KW  - force control part
KW  - impedance concept
KW  - exerted force
KW  - stable contact
KW  - control architecture
KW  - adaptive admittance control
KW  - task-priority framework
KW  - contact force control
KW  - underwater vehicle-manipulator system
KW  - end-effector configuration
KW  - floating-base manipulation
KW  - Force control
KW  - Task analysis
KW  - Force
KW  - Impedance
KW  - Robots
KW  - Heuristic algorithms
KW  - Inspection
DO  - 10.1109/IROS.2018.8593542
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a control architecture for an underwater vehicle-manipulator system (UVMS) to enable simultaneous tracking of end-effector configuration and contact force during floating-base manipulation. The main feature of the architecture is its combination of a task-priority (TP) kinematic control algorithm with a custom force control strategy, based on impedance (admittance) control. The TP algorithm used in the work includes recent treatment of equality and inequality tasks as well as original concepts to handle operation in singular configurations of the system. In the force control part the impedance concept is extended to allow for direct control over the value of exerted force and torque. Additional feed-forward signal is used to ensure stable contact. The performance of the control architecture is demonstrated by experiments in a test tank, with GIRONA500 I-AUV performing pipe inspection.
ER  - 

TY  - CONF
TI  - Optimizing Sensor Placement: A Mixture Model Framework Using Stable Poses and Sparsely Precomputed Pose Uncertainty Predictions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6652
EP  - 6659
AU  - T. M. Iversen
AU  - D. Kraft
PY  - 2018
KW  - image sensors
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - sensor placement
KW  - computer vision system
KW  - mixture model framework
KW  - sensor placement optimization
KW  - robotics tasks
KW  - pose estimation
KW  - probability distribution
KW  - primesense carmine
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Computational modeling
KW  - Task analysis
KW  - Optimization
KW  - Measurement
DO  - 10.1109/IROS.2018.8594121
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.
ER  - 

TY  - CONF
TI  - Robust 6D Object Pose Estimation in Cluttered Scenes Using Semantic Segmentation and Pose Regression Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6660
EP  - 6666
AU  - A. S. Periyasamy
AU  - M. Schwarz
AU  - S. Behnke
PY  - 2018
KW  - clutter
KW  - data acquisition
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - regression analysis
KW  - robot vision
KW  - pose regression networks
KW  - cluttered scenes
KW  - cropped object-centered
KW  - object poses
KW  - cluttered bin-picking scenes
KW  - semantic segmentation
KW  - synthetic data generation procedure
KW  - fast data acquisition method
KW  - estimation methods
KW  - real-world bin-picking settings
KW  - object pose estimation
KW  - Pose estimation
KW  - Semantics
KW  - Three-dimensional displays
KW  - Training
KW  - Image segmentation
KW  - Solid modeling
KW  - Robots
DO  - 10.1109/IROS.2018.8594406
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Object pose estimation is a crucial prerequisite for robots to perform autonomous manipulation in clutter. Real-world bin-picking settings such as warehouses present additional challenges, e.g., new objects are added constantly. Most of the existing object pose estimation methods assume that 3D models of the objects is available beforehand. We present a pipeline that requires minimal human intervention and circumvents the reliance on the availability of 3D models by a fast data acquisition method and a synthetic data generation procedure. This work builds on previous work on semantic segmentation of cluttered bin-picking scenes to isolate individual objects in clutter. An additional network is trained on synthetic scenes to estimate object poses from a cropped object-centered encoding extracted from the segmentation results. The proposed method is evaluated on a synthetic validation dataset and cluttered realworld scenes.
ER  - 

TY  - CONF
TI  - Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6667
EP  - 6674
AU  - P. D. H. Nguyen
AU  - T. Fischer
AU  - H. J. Chang
AU  - U. Pattacini
AU  - G. Metta
AU  - Y. Demiris
PY  - 2018
KW  - calibration
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - neural nets
KW  - robot vision
KW  - stereo image processing
KW  - robotic manipulation tasks
KW  - physical iCub robot
KW  - joint measurements
KW  - systematic error
KW  - accurate joint estimates
KW  - visuomotor predictor
KW  - image-to-image translation approach
KW  - physical robot
KW  - sensing error
KW  - unavoidable sources
KW  - underlying head configuration
KW  - stereo image pair
KW  - visuomotor deep neural network predictor
KW  - hand-eye coordination task
KW  - iCub humanoid
KW  - complex robots
KW  - accurate hand-eye coordination
KW  - visuomotor learning
KW  - Robot kinematics
KW  - Head
KW  - Task analysis
KW  - Robot sensing systems
KW  - Visualization
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594519
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.
ER  - 

TY  - CONF
TI  - Proprioception-Based Grasping for Unknown Objects Using a Series-Elastic-Actuated Gripper
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6675
EP  - 6681
AU  - T. Chen
AU  - M. Ciocarlie
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - grippers
KW  - mechanoception
KW  - MIMO systems
KW  - motion control
KW  - series-elastic-actuated gripper
KW  - stable fingertip grasps
KW  - proprioceptive gripper
KW  - proprioception-based grasping
KW  - multi-input-multi-output control
KW  - MIMO control
KW  - sensors
KW  - Robot sensing systems
KW  - Grippers
KW  - Grasping
KW  - Pulleys
KW  - Springs
KW  - Sea measurements
DO  - 10.1109/IROS.2018.8593787
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasping unknown objects has been an active research topic for decades. Approaches range from using various sensors (e.g. vision, tactile) to gain information about the object, to building passively compliant hands that react appropriately to contacts. In this paper, we focus on grasping unknown objects using proprioception (the combination of joint position and torque sensing). Our hypothesis is that proprioception alone can be the basis for versatile performance, including multiple types of grasps for objects with multiple shapes and sizes, and transitions between grasps. Using a series-elastic-actuated gripper, we propose a method for performing stable fingertip grasps for unknown objects with unknown contacts, formulated as multi-input-multi-output (MIMO) control. We also show that the proprioceptive gripper can perform enveloping grasps, as well as the transition from fingertip grasps to enveloping grasps.
ER  - 

TY  - CONF
TI  - Efficient State Estimation with Constrained Rao-Blackwellized Particle Filter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6682
EP  - 6689
AU  - S. Li
AU  - S. Lyu
AU  - J. Trinkle
PY  - 2018
KW  - Bayes methods
KW  - Kalman filters
KW  - manipulators
KW  - particle filtering (numerical methods)
KW  - quadratic programming
KW  - state estimation
KW  - RBPF
KW  - contact states
KW  - Kalman filters
KW  - constrained Rao-Blackwellized Particle Filter
KW  - robotic sensors
KW  - robotic manipulation task
KW  - multibody dynamic system
KW  - Bayesian filtering methods
KW  - state estimation
KW  - quadratic programming problem
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Kalman filters
KW  - State estimation
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594268
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Due to the limitations of the robotic sensors, during a robotic manipulation task, the acquisition of the object's state can be unreliable and noisy. Combining an accurate model of multi-body dynamic system with Bayesian filtering methods has been shown to be able to filter out noise from the object's observed states. However, efficiency of these filtering methods suffers from samples that violate the physical constraints, e.g., no penetration constraint. In this paper, we propose a Rao-Blackwellized Particle Filter (RBPF) that samples the contact states and updates the object's poses using Kalman filters. This RBPF also enforces the physical constraints on the samples by solving a quadratic programming problem. By comparing our method with methods that does not consider physical constraints, we show that our proposed RBPF is not only able to estimate the object's states, e.g., poses, more accurately but also able to infer unobserved states, e.g., velocities, with higher precision.
ER  - 

TY  - CONF
TI  - A Gripper for Object Search and Grasp Through Proximity Sensing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - N. Yamaguchi
AU  - S. Hasegawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - calibration
KW  - grippers
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - object grasp
KW  - object search
KW  - calibration method
KW  - proximity sensors
KW  - sensor reaction
KW  - robot motions
KW  - proximity sensing
KW  - sensor information
KW  - primitive motions
KW  - gripper
KW  - Robot sensing systems
KW  - Rubber
KW  - Grippers
KW  - Calibration
KW  - Search problems
DO  - 10.1109/IROS.2018.8593572
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots need to adapt themselves to various surroundings in order to achieve robust object search and grasp in unknown environments. For this adaptation, robot motions should be implemented as combination of primitive motions which are based on sensor reaction. Among various sensing methods, non contact sensing is required as a means of preventing operation failures such as pushing objects. Especially, proximity sensors have been proved effective in avoiding occlusion problems. In this paper, we first develop a gripper on which proximity sensors are mounted all around, and then calculate distance between the gripper and objects using proposed calibration method. This enables robots to recognize detailed shapes of objects surrounding the gripper. We also propose primitive motions for object search and grasp, and describe the contents of each motion. The motions are based on sensor information obtained from the gripper. We verify the effectiveness of our system through an experiment in which a real robot performs complex tasks by combination of the primitive motions.
ER  - 

TY  - CONF
TI  - Exploring Vestibulo-Ocular Adaptation in a Closed-Loop Neuro-Robotic Experiment Using STDP. A Simulation Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. Naveros
AU  - J. A. Garrido
AU  - A. Arleo
AU  - E. Ros
AU  - N. R. Luque
PY  - 2018
KW  - brain models
KW  - closed loop systems
KW  - control engineering computing
KW  - humanoid robots
KW  - neural nets
KW  - neural system
KW  - Neuro-robotic Platform
KW  - NRP
KW  - vestibulo ocular cerebellar adaptatIon
KW  - STDP mechanisms
KW  - cerebellar molecular layer
KW  - r-VOR adaptation
KW  - spiking cerebellar model
KW  - r-VOR task
KW  - perception-action closed-loop
KW  - vestibulo-ocular reflex
KW  - humanoid robot
KW  - iCub robot
KW  - cerebellar properties
KW  - Robot sensing systems
KW  - Neurons
KW  - Adaptation models
KW  - Transfer functions
KW  - Task analysis
KW  - Optical fiber networks
DO  - 10.1109/IROS.2018.8594019
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Studying and understanding the computational primitives of our neural system requires for a diverse and complementary set of techniques. In this work, we use the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar adaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms located at the cerebellar molecular layer and the vestibular nuclei respectively. This simulation study adopts an experimental setup (rotatory VOR)widely used by neuroscientists to better understand the contribution of certain specific cerebellar properties (i.e. distributed STDP, neural properties, coding cerebellar topology, etc.)to r-VOR adaptation. The work proposes and describes an embodiment solution for which we endow a simulated humanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and we face the humanoid to an r-VOR task. The results validate the adaptive capabilities of the spiking cerebellar model (with STDP)in a perception-action closed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.
ER  - 

TY  - CONF
TI  - Interspecies Retargeting of Homologous Body Posture Based on Skeletal Morphing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6712
EP  - 6719
AU  - K. Ayusawa
AU  - Y. Ikegami
AU  - A. Murai
AU  - Y. Yoshiyasu
AU  - E. Yoshida
AU  - S. Oota
AU  - Y. Nakamura
PY  - 2018
KW  - biomechanics
KW  - computerised tomography
KW  - image morphing
KW  - medical image processing
KW  - physiological models
KW  - skeletal morphing
KW  - bone geometry homology
KW  - mammalian species
KW  - biomechanical functions
KW  - human skeletal models
KW  - mouse skeletal models
KW  - human body posture
KW  - mammalian skeletal system
KW  - human musculoskeletal system
KW  - homologous body posture
KW  - Bones
KW  - Mice
KW  - Joints
KW  - Geometry
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594240
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper aims to develop a methodology of transferring the knowledge obtained from the experiments of laboratory animals to human musculoskeletal system. To achieve the goal, we propose a method for estimating the homologous posture of the mammalian skeletal system corresponding to the human body posture. We hypothesize the homology of bone geometry between mammalian species implies that of biomechanical functions. The method relies on this homology and determines the homologous postures according to the anatomical landmarks of bone geometry. This paper shows the results of the analysis on homologous postures between the human and mouse skeletal models to validate our hypothesis. A pilot study also introduces comparison of mechanical functions between the two models by using the homologous postures.
ER  - 

TY  - CONF
TI  - Neurorobotic Approach to Study Huntington Disease Based on a Mouse Neuromusculoskeletal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6720
EP  - 6727
AU  - S. Oota
AU  - Y. Okamura-Oho
AU  - K. Ayusawa
AU  - Y. Ikegami
AU  - A. Murai
AU  - E. Yoshida
AU  - Y. Nakamura
PY  - 2018
KW  - biomechanics
KW  - cognition
KW  - diseases
KW  - genetics
KW  - medical robotics
KW  - muscle
KW  - neurophysiology
KW  - altered genetic code
KW  - macroscopic neuro-musculoskeletal model
KW  - neurorobotic approach
KW  - mouse neuromusculoskeletal model
KW  - biological system
KW  - neurorobotics view
KW  - early onset symptoms
KW  - neurodegenerative disease
KW  - genetically engineered Huntington disease model mice
KW  - progressive impaired motor functions
KW  - crystalized motion profile
KW  - normal mice
KW  - abnormal mice
KW  - whole-body level motor coordination
KW  - long-term objective
KW  - human mind
KW  - cognitive functions
KW  - soft neurorobotic suit
KW  - HD model mice
KW  - molecular mechanisms
KW  - macroscopic neuromusculoskeletal model
KW  - Mice
KW  - Diseases
KW  - Joints
KW  - Robots
KW  - Kinematics
KW  - Bones
KW  - Biological system modeling
DO  - 10.1109/IROS.2018.8594491
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motor functions of the biological system has been forged through 4 billion years evolution. From a neurorobotics view, it is important not only to know how well it works, but also how it fails. To quantitatively describe early onset symptoms of a neurodegenerative disease, we analyzed phenotypes of genetically engineered Huntington disease (HD) model mice, which reveal progressive impaired motor functions. We devised a simple yet sensitive paradigm called the crystalized motion profile (CMP), by which we successfully detected subtle difference between normal and abnormal mice in terms of whole-body level motor coordination. Our long-term objective is to remodel human mind and body to regain impaired motor and cognitive functions with ageing. To do so, we are developing a soft neurorobotic suit that provides integrated cognitive and physical interventions to users. Our analysis on the HD model mice is important as the first step to bridge between molecular mechanisms (altered genetic code) and the macroscopic neuro-musculoskeletal model. With this, we can extrapolate from knowledge of non-human mammals to human to derive the remodeling.
ER  - 

TY  - CONF
TI  - Temporally Smooth Privacy-Protected Airborne Videos
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6728
EP  - 6733
AU  - O. Sarwar
AU  - A. Cavallaro
AU  - B. Rinner
PY  - 2018
KW  - data privacy
KW  - image restoration
KW  - spatiotemporal phenomena
KW  - video signal processing
KW  - recreational videography
KW  - drones
KW  - privacy filters
KW  - flicker
KW  - privacy-protected airborne videos
KW  - identification attacks
KW  - spatiotemporal hopping blur filter
KW  - Face
KW  - Privacy
KW  - Videos
KW  - Probes
KW  - Distortion
KW  - Detectors
KW  - Smoothing methods
DO  - 10.1109/IROS.2018.8594493
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recreational videography from small drones can capture bystanders who may be uncomfortable about appearing in those videos. Existing privacy filters, such as scrambling and hopping blur, address this issue through de-identification but generate temporal distortions that manifest themselves as flicker. To address this problem, we present a robust spatiotemporal hopping blur filter that protects privacy through de-identification of face regions. The proposed filter is meant for on-board installation and produces temporally smooth and pleasant videos. We apply hopping blur to protect each frame against identification attacks, and minimise artefacts and flicker introduced by the hopping blur. We evaluate the proposed filter against different identification attacks and by assessing the quality of the resulting videos using a subjective test and objective measures.
ER  - 

TY  - CONF
TI  - Impedance Based Force Control for Aerial Robot Peg-in-Hole Insertion Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6734
EP  - 6739
AU  - M. Car
AU  - A. Ivanovic
AU  - M. Orsag
AU  - S. Bogdan
PY  - 2018
KW  - aerospace robotics
KW  - force control
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - rotors
KW  - whole body locomotion
KW  - tactile perception
KW  - finite state automaton
KW  - aerial robot peg-in-hole insertion tasks
KW  - impedance based force control
KW  - dual arm multidegree of freedom manipulator
KW  - kinematic constraints
KW  - dual arm manipulator
KW  - multirotor base
KW  - multistage strategy
KW  - impedance control
KW  - peg-in-hole approach
KW  - multirotor platform
KW  - canonical peg-in-hole manipulation task
KW  - Force
KW  - Impedance
KW  - Task analysis
KW  - Manipulator dynamics
KW  - Rotors
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593808
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper demonstrates the experimental validation of canonical peg-in-hole manipulation task using an aerial robot. The robot consists of a multirotor platform equipped with a dual arm multi degree of freedom manipulator. The paper discusses the introduced kinematic constraints which make sure the robot holds a bolt with both arms. We build our peg-in-hole approach using impedance control which is the foundation of compliant interaction with the environment. We utilize a finite state automaton to plan a multi stage strategy which relies on tactile perception in order to pin point the target. Finally, the whole body locomotion is considered, meaning both the degrees of freedom of multirotor base and the dual arm manipulator are considered.
ER  - 

TY  - CONF
TI  - Flatness-Based Model Predictive Control for Quadrotor Trajectory Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6740
EP  - 6745
AU  - M. Greeff
AU  - A. P. Schoellig
PY  - 2018
KW  - control system synthesis
KW  - convex programming
KW  - feedback
KW  - feedforward
KW  - helicopters
KW  - nonlinear control systems
KW  - nonlinear programming
KW  - position control
KW  - predictive control
KW  - quadratic programming
KW  - stability
KW  - trajectory control
KW  - quadrotor trajectory tracking
KW  - trajectory tracking performance
KW  - constraint satisfaction
KW  - differentially flat nonlinear systems
KW  - FMPC couples feedback model predictive control
KW  - linear model predictive control
KW  - couple model predictive control
KW  - nonlinear model
KW  - control approaches
KW  - flatness-based model predictive control approach
KW  - Feedforward systems
KW  - Predictive control
KW  - Feedback linearization
KW  - Robustness
KW  - Computational modeling
KW  - Predictive models
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594012
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of model predictive control for quadro-tor applications requires balancing trajectory tracking performance and constraint satisfaction with fast computation. This paper proposes a Flatness-based Model Predictive Control (FMPC) approach that can be applied to quadrotors, and more generally, differentially flat nonlinear systems. Our proposed FMPC couples feedback model predictive control with feedforward linearization. The proposed approach has the computational advantage that, similar to linear model predictive control, it only requires solving a convex quadratic program instead of a nonlinear program. However, unlike linear model predictive control, we still account for the nonlinearity in the model through the use of an inverse term. In simulation, we demonstrate improved robustness over approaches that couple model predictive control with feedback linearization. In experiments using quadrotor vehicles, we also demonstrate improved trajectory tracking compared to classical linear and nonlinear model predictive control approaches.
ER  - 

TY  - CONF
TI  - Lightweight and Compliant Long Reach Aerial Manipulator for Inspection Operations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6746
EP  - 6752
AU  - A. Suarez
AU  - P. Sanchez-Cuevas
AU  - M. Fernandez
AU  - M. Perez
AU  - G. Heredia
AU  - A. Ollero
PY  - 2018
KW  - actuators
KW  - autonomous aerial vehicles
KW  - feedback
KW  - industrial manipulators
KW  - inspection
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - pendulums
KW  - position control
KW  - torque control
KW  - inspection operations
KW  - multirotor blades
KW  - environmental obstacles
KW  - inspection tasks
KW  - long reach aerial manipulator
KW  - hexarotor platform
KW  - compliant joint arm
KW  - one-meter-length link
KW  - passive pendulum configuration
KW  - force/torque estimation-control
KW  - joint deflection
KW  - visual inspection
KW  - wearable exoskeleton interface
KW  - aerial manipulator kinematics
KW  - aerial manipulator dynamics
KW  - Manipulator dynamics
KW  - Inspection
KW  - Robot sensing systems
KW  - Visualization
KW  - Exoskeletons
KW  - Cameras
DO  - 10.1109/IROS.2018.8593940
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The proximity between the multirotor blades and the environmental obstacles restricts the application of aerial manipulators in inspection tasks due to the risk of impacts, the limitation in the reach of the arm, and the physical interactions. This paper presents a long reach aerial manipulator consisting of a hexarotor platform equipped with a 2-DOF compliant joint arm attached at the tip of a one-meter-length link in passive pendulum configuration. The arm integrates magnetic encoders for force/torque estimation-control based on joint deflection, a range sensor in the forearm link for measuring the distance to the contact point, and a camera for visual inspection. A 2-DOF wearable exoskeleton interface has been developed, allowing the teleoperation of the arm with visual feedback in a more intuitive way. The paper also covers the kinematics and dynamics of the aerial manipulator, including the dynamics of the flexible long reach link. The developed system has been evaluated in test-bench and in outdoor flight tests.
ER  - 

TY  - CONF
TI  - Model Predictive Trajectory Tracking and Collision Avoidance for Reliable Outdoor Deployment of Unmanned Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6753
EP  - 6760
AU  - T. Baca
AU  - D. Hert
AU  - G. Loianno
AU  - M. Saska
AU  - V. Kumar
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - feedback
KW  - mobile robots
KW  - multi-robot systems
KW  - predictive control
KW  - state feedback
KW  - trajectory control
KW  - prediction horizon
KW  - decentralized collision avoidance system
KW  - fast nonlinear feedback
KW  - virtual UAV
KW  - translational dynamics
KW  - nonlinear state feedback
KW  - linear model predictive controller
KW  - optimal trajectory tracking
KW  - unmanned aerial vehicles
KW  - model predictive trajectory tracking
KW  - priority-based collision resolution strategy
KW  - tracking mechanism
KW  - in-advance collision-free planning
KW  - linear MPC
KW  - Trajectory
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Robot kinematics
KW  - Planning
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594266
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel approach for optimal trajectory tracking for unmanned aerial vehicles (UAV), using a linear model predictive controller (MPC) in combination with non-linear state feedback. The solution relies on fast onboard simulation of the translational dynamics of the UAV, which is guided by a linear MPC. By sampling the states of the virtual UAV, we create a control command for fast non-linear feedback, which is capable of performing agile maneuvers with high precision. In addition, the proposed pipeline provides an interface for a decentralized collision avoidance system for multi-UAY scenarios. Our solution makes use of the long prediction horizon of the linear MPC and allows safe outdoors execution of multi-UAV experiments without the need for in-advance collision-free planning. The practicality of the tracking mechanism is shown in combination with priority-based collision resolution strategy, which performs sufficiently in experiments with up to 5 UAVs. We present a statistical and experimental evaluation of the platform in both simulation and real-world examples, demonstrating the usability of the approach.
ER  - 

TY  - CONF
TI  - Distributed Pressure Sensing for Enabling Self-Aware Autonomous Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6769
EP  - 6775
AU  - D. Cellucci
AU  - N. Cramer
AU  - S. S. -. Swei
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - pressure control
KW  - pressure sensors
KW  - state estimation
KW  - wind tunnels
KW  - pressure sensors
KW  - NASA Langley Research Center
KW  - distributed algorithm
KW  - wind tunnel
KW  - commercial air transportation
KW  - self-aware autonomous aerial vehicles
KW  - lattice-based subcomponents
KW  - 14-foot wingspan
KW  - skin panels
KW  - flexible aerostructure
KW  - aerodynamic state estimation
KW  - modular distributed pressure sensing skin
KW  - autonomous systems
KW  - adaptable self-state estimation
KW  - robust self-state estimation
KW  - autonomous aerial transportation
KW  - pressure distribution
KW  - Robot sensing systems
KW  - Pressure sensors
KW  - Skin
KW  - Aerodynamics
KW  - NASA
DO  - 10.1109/IROS.2018.8593664
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous aerial transportation will be a fixture of future robotic societies, simultaneously requiring more stringent safety requirements and fewer resources for characterization than current commercial air transportation. More robust, adaptable, self-state estimation will be necessary to create such autonomous systems. We present a modular, scalable, distributed pressure sensing skin for aerodynamic state estimation of a large, flexible aerostructure. This skin used a network of 22 nodes that performed in situ computation and communication of data collected from 74 pressure sensors, which were embedded into the skin panels of an ultra-lightweight 14-foot wingspan made from commutable, lattice-based subcomponents, and tested at NASA Langley Research Center's 14X22 wind tunnel. The density of the pressure sensors allowed for the use of a novel distributed algorithm to generate estimates of the wing lift contribution that were more accurate than the direct integration of the pressure distribution over the wing surface.
ER  - 

TY  - CONF
TI  - Light-Weight Object Detection and Decision Making via Approximate Computing in Resource-Constrained Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6776
EP  - 6781
AU  - P. Pandey
AU  - Q. He
AU  - D. Pompili
AU  - R. Tron
PY  - 2018
KW  - decision making
KW  - Markov processes
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - light-weight object detection
KW  - approximate computing
KW  - resource-constrained mobile robots
KW  - autonomous flights
KW  - indoor environments
KW  - point clouds
KW  - computer vision algorithms
KW  - mobile autonomous platforms
KW  - video data
KW  - decision making
KW  - geometric maps
KW  - Markov decision process framework
KW  - Object detection
KW  - Proposals
KW  - Roads
KW  - Support vector machines
KW  - Computer vision
KW  - Cameras
DO  - 10.1109/IROS.2018.8594200
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most of the current solutions for autonomous flights in indoor environments rely on purely geometric maps (e.g., point clouds). There has been, however, a growing interest in supplementing such maps with semantic information (e.g., object detections) using computer vision algorithms. Unfortunately, there is a disconnect between the relatively heavy computational requirements of these computer vision solutions, and the limited computation capacity available on mobile autonomous platforms. In this paper, we propose to bridge this gap with a novel Markov Decision Process framework that adapts the parameters of the vision algorithms to the incoming video data rather than fixing them a priori. As a concrete example, we test our framework on a object detection and tracking task, showing significant benefits in terms of energy consumption without considerable loss in accuracy, using a combination of publicly available and novel datasets.
ER  - 

TY  - CONF
TI  - SOS: Stereo Matching in O(1) with Slanted Support Windows
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6782
EP  - 6789
AU  - V. Tankovich
AU  - M. Schoenberg
AU  - S. R. Fanello
AU  - A. Kowdle
AU  - C. Rhemann
AU  - M. Dzitsiuk
AU  - M. Schmidt
AU  - J. Valentin
AU  - S. Izadi
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image matching
KW  - image reconstruction
KW  - image texture
KW  - stereo image processing
KW  - stereo matching
KW  - slanted support windows
KW  - computer vision
KW  - triangulation-based depth cameras
KW  - structured light systems
KW  - active research topic
KW  - trade-off accuracy
KW  - fronto-parallel assumptions
KW  - search space
KW  - active stereo configuration
KW  - local methods
KW  - PatchMatch Stereo
KW  - computational cost
KW  - local smoothness
KW  - entire stereo pipeline
KW  - high quality depth maps
KW  - Microsoft Windows
KW  - Cameras
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Correlation
KW  - Image resolution
KW  - Optimization
DO  - 10.1109/IROS.2018.8593800
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Depth cameras have accelerated research in many areas of computer vision. Most triangulation-based depth cameras, whether structured light systems like the Kinect or active (assisted) stereo systems, are based on the principle of stereo matching. Depth from stereo is an active research topic dating back 30 years. Despite recent advances, algorithms usually trade-off accuracy for speed. In particular, efficient methods rely on fronto-parallel assumptions to reduce the search space and keep computation low. We present SOS (Slanted O(1) Stereo), the first algorithm capable of leveraging slanted support windows without sacrificing speed or accuracy. We use an active stereo configuration, where an illuminator textures the scene. Under this setting, local methods - such as PatchMatch Stereo - obtain state of the art results by jointly estimating disparities and slant, but at a large computational cost. We observe that these methods typically exploit local smoothness to simplify their initialization strategies. Our key insight is that local smoothness can in fact be used to amortize the computation not only within initialization, but across the entire stereo pipeline. Building on these insights, we propose a novel hierarchical initialization that is able to efficiently perform search over disparity and slants. We then show how this structure can be leveraged to provide high quality depth maps. Extensive quantitative evaluations demonstrate that the proposed technique yields significantly more precise results than current state of the art, but at a fraction of the computational cost. Our prototype implementation runs at 4000 fps on modern GPU architectures.
ER  - 

TY  - CONF
TI  - The RobotriX: An Extremely Photorealistic and Very-Large-Scale Indoor Dataset of Sequences with Robot Trajectories and Interactions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6790
EP  - 6797
AU  - A. Garcia-Garcia
AU  - P. Martinez-Gonzalez
AU  - S. Oprea
AU  - J. A. Castro-Vargas
AU  - S. Orts-Escolano
AU  - J. Garcia-Rodriguez
AU  - A. Jover-Alvarez
PY  - 2018
KW  - control engineering computing
KW  - image colour analysis
KW  - image resolution
KW  - learning (artificial intelligence)
KW  - rendering (computer graphics)
KW  - robot vision
KW  - trajectory control
KW  - virtual reality
KW  - RobotriX
KW  - extremely photorealistic indoor dataset
KW  - very-large-scale indoor dataset
KW  - robot trajectories
KW  - deep learning techniques
KW  - robotic vision problems
KW  - hyperrealistic indoor scenes
KW  - robot agents
KW  - Unreal Engine
KW  - virtual reality headset
KW  - robotic hands
KW  - ground truth labels
KW  - 3D robotic vision tasks
KW  - large-scale data-driven techniques
KW  - UnrealCV
KW  - full HD resolution
KW  - RGB-D
KW  - 2D robotic vision tasks
KW  - Robots
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Deep learning
KW  - Image resolution
KW  - Rendering (computer graphics)
KW  - Layout
DO  - 10.1109/IROS.2018.8594495
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Enter the RobotriX, an extremely photorealistic indoor dataset designed to enable the application of deep learning techniques to a wide variety of robotic vision problems. The RobotriX consists of hyperrealistic indoor scenes which are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline using UnrealCV to generate raw data and ground truth labels. By taking this approach, we were able to generate a dataset of 38 semantic classes across 512 sequences totaling 8M stills recorded at +60 frames per second with full HD resolution. For each frame, RGB-D and 3D information is provided with full annotations in both spaces. Thanks to the high quality and quantity of both raw information and annotations, the RobotriX will serve as a new milestone for investigating 2D and 3D robotic vision tasks with large-scale data-driven techniques.
ER  - 

TY  - CONF
TI  - Real-Time Object Pose Estimation with Pose Interpreter Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6798
EP  - 6805
AU  - J. Wu
AU  - B. Zhou
AU  - R. Russell
AU  - V. Kee
AU  - S. Wagner
AU  - M. Hebert
AU  - A. Torralba
AU  - D. M. S. Johnson
PY  - 2018
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image representation
KW  - image segmentation
KW  - object recognition
KW  - pose estimation
KW  - object pose estimation
KW  - CNN-based approaches
KW  - synthetic pose data
KW  - object masks
KW  - RGB images
KW  - 6-DoF object
KW  - pose interpreter network
KW  - Pose estimation
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Quaternions
KW  - Real-time systems
KW  - Training
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593662
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we introduce pose interpreter networks for 6-DoF object pose estimation. In contrast to other CNN-based approaches to pose estimation that require expensively annotated object pose data, our pose interpreter network is trained entirely on synthetic pose data. We use object masks as an intermediate representation to bridge real and synthetic. We show that when combined with a segmentation model trained on RGB images, our synthetically trained pose interpreter network is able to generalize to real data. Our end-to-end system for object pose estimation runs in real-time (20 Hz) on live RGB data, without using depth information or ICP refinement.
ER  - 

TY  - CONF
TI  - Coping with Context Change in Open-Ended Object Recognition without Explicit Context Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - S. Hamidreza Kasaei
AU  - L. Seabra Lopes
AU  - A. Maria Tomé
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - object category learning
KW  - learning recognition
KW  - evaluation approaches
KW  - recognition approaches
KW  - multicontext scenarios
KW  - recognition methods
KW  - unconstrained human environments
KW  - autonomous robots
KW  - object categories
KW  - human-centric environment
KW  - explicit context information
KW  - open-ended object recognition
KW  - context change
KW  - Robots
KW  - Visualization
KW  - Protocols
KW  - Histograms
KW  - Context modeling
KW  - Three-dimensional displays
KW  - Training
DO  - 10.1109/IROS.2018.8593922
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To deploy a robot in a human-centric environment, it is important that the robot is able to continuously acquire and update object categories while working in the environment. Therefore, autonomous robots must have the ability to continuously execute learning and recognition in a concurrent or interleaved fashion. One of the main challenges in unconstrained human environments is to cope with the effects of context change. This paper presents two main contributions: (i) an approach for evaluating open-ended object category learning and recognition methods in multi-context scenarios; (ii) evaluation of different object category learning and recognition approaches regarding their ability to cope with the effects of context change. Off-line evaluation approaches such as cross-validation do not comply with the simultaneous nature of learning and recognition. A teaching protocol, supporting context change, was therefore designed and used in this work for experimental evaluation. Seven learning and recognition approaches were evaluated and compared using the protocol. The best performance, in terms of number of learned categories, was obtained with a recently proposed local variant of Latent Dirichlet Allocation (LDA), closely followed by a Bag-of-Words (BoW) approach. In terms of adaptability, i.e. coping with context change, the best result was obtained with BoW, immediately followed by the local LDA variant.
ER  - 

TY  - CONF
TI  - Fast Cylinder and Plane Extraction from Depth Cameras for Visual Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6813
EP  - 6820
AU  - P. F. Proença
AU  - Y. Gao
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - pose estimation
KW  - cylinder and plane extraction
KW  - pose optimization residuals
KW  - probabilistic RGB-D odometry framework
KW  - curve-aware deteriorates performance
KW  - plane extraction approach
KW  - single CPU core
KW  - organized point clouds
KW  - cylinder segments
KW  - CAPE
KW  - visual odometry
KW  - Histograms
KW  - Eigenvalues and eigenfunctions
KW  - Cameras
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Probabilistic logic
KW  - Principal component analysis
DO  - 10.1109/IROS.2018.8593516
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents CAPE, a method to extract planes and cylinder segments from organized point clouds, which processes 640 × 480 depth images on a single CPU core at an average of 300 Hz, by operating on a grid of planar cells. While, compared to state-of-the-art plane extraction, the latency of CAPE is more consistent and 4-10 times faster, depending on the scene, we also demonstrate empirically that applying CAPE to visual odometry can improve trajectory estimation on scenes made of cylindrical surfaces (e.g. tunnels), whereas using a plane extraction approach that is not curve-aware deteriorates performance on these scenes. To use these geometric primitives in visual odometry, we propose extending a probabilistic RGB-D odometry framework based on points, lines and planes to cylinder primitives. Following this framework, CAPE runs on fused depth maps and the parameters of cylinders are modelled probabilistically to account for uncertainty and weight accordingly the pose optimization residuals.
ER  - 

TY  - CONF
TI  - Attention-Aware Cross-Modal Cross-Level Fusion Network for RGB-D Salient Object Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6821
EP  - 6826
AU  - H. Chen
AU  - Y. Li
AU  - D. Su
PY  - 2018
KW  - convolutional neural nets
KW  - feature extraction
KW  - image colour analysis
KW  - image fusion
KW  - object detection
KW  - geometric saliency cues
KW  - selection module
KW  - public datasets
KW  - attention-aware cross-modal cross-level fusion block
KW  - RGB-D fusion network
KW  - informative cross-modal cross-level combination
KW  - multimodal fusion stage
KW  - depth features/decisions
KW  - depth information
KW  - RGB-D sensors
KW  - convolutional neural networks
KW  - RGB-D salient object detection
KW  - attention-aware cross-modal cross-level fusion network
KW  - Object detection
KW  - Feature extraction
KW  - Fuses
KW  - Task analysis
KW  - Computer architecture
KW  - Visualization
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594373
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Convolutional neural networks have achieved wide success in RGB saliency detection. Recently, the advent of RGB-D sensors such as Kinect provide additional geometric saliency cues. However, the key challenge for RGB-D salient object detection that how to fuse RGB and depth information sufficiently is still under-studied. Traditional works mainly follow the two-stream architecture and combine RGB and depth features/decisions in an early or late point. The multi-modal fusion stage is performed by directly concatenating the features from two modalities without selection. In this work, we address this question by proposing a novel network with a distinguished insight: A selection module is significantly helpful for more informative and sufficient cross-modal cross-level combination. To this end, we introduce a top-down RGB-D fusion network which integrates an attention-aware cross-modal cross-level fusion block in each level to select discriminative features from each level and each modality. Extensive experiments on public datasets show that the proposed network is able to solve the key problems in RGB-D fusion and achieves state-of-the-art performance on RGB-D salient object detection.
ER  - 

TY  - CONF
TI  - Exploiting Points and Lines in Regression Forests for RGB-D Camera Relocalization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6827
EP  - 6834
AU  - L. Meng
AU  - F. Tung
AU  - J. J. Little
AU  - J. Valentin
AU  - C. W. de Silva
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - image texture
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - pose estimation
KW  - regression analysis
KW  - virtual reality
KW  - RGB-D
KW  - computer vision applications
KW  - self-driving cars
KW  - virtual reality
KW  - recent random forests
KW  - pixel comparison features
KW  - 3D world locations
KW  - 2D image locations
KW  - point features
KW  - geometric information
KW  - motion blur
KW  - line segments
KW  - uncertainty driven regression forests
KW  - Cameras
KW  - Forestry
KW  - Image segmentation
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Training
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593505
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Camera relocalization plays a vital role in many robotics and computer vision applications, such as self-driving cars and virtual reality. Recent random forests based methods exploit randomly sampled pixel comparison features to predict 3D world locations for 2D image locations to guide the camera pose optimization. However, these point features are only sampled randomly in images, without considering geometric information such as lines, leading to large errors with the existence of poorly textured areas or in motion blur. Line segments are more robust in these environments. In this work, we propose to jointly exploit points and lines within the framework of uncertainty driven regression forests. The proposed approach is thoroughly evaluated on three publicly available datasets against several strong state-of-the-art baselines in terms of several different error metrics. Experimental results prove the efficacy of our method, showing superior or on-par state-of-the-art performance.
ER  - 

TY  - CONF
TI  - Incremental Object Database: Building 3D Models from Multiple Partial Observations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6835
EP  - 6842
AU  - F. Furrer
AU  - T. Novkovic
AU  - M. Fehr
AU  - A. Gawel
AU  - M. Grinvald
AU  - T. Sattler
AU  - R. Siegwart
AU  - J. Nieto
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - mobile agents
KW  - object detection
KW  - solid modelling
KW  - multiple partial observations
KW  - incremental object database
KW  - indoor scenes
KW  - merged models
KW  - object model
KW  - observed instances
KW  - segmented RGB-D images
KW  - global segmentation map
KW  - 3D models
KW  - mobile agent
KW  - Image segmentation
KW  - Databases
KW  - Three-dimensional displays
KW  - GSM
KW  - Shape
KW  - Image reconstruction
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594391
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Collecting 3D object data sets involves a large amount of manual work and is time consuming. Getting complete models of objects either requires a 3D scanner that covers all the surfaces of an object or one needs to rotate it to completely observe it. We present a system that incrementally builds a database of objects as a mobile agent traverses a scene. Our approach requires no prior knowledge of the shapes present in the scene. Object-like segments are extracted from a global segmentation map, which is built online using the input of segmented RGB-D images. These segments are stored in a database, matched among each other, and merged with other previously observed instances. This allows us to create and improve object models on the fly and to use these merged models to reconstruct also unobserved parts of the scene. The database contains each (potentially merged) object model only once, together with a set of poses where it was observed. We evaluate our pipeline with one public dataset, and on a newly created Google Tango dataset containing four indoor scenes with some of the objects appearing multiple times, both within and across scenes.
ER  - 

TY  - CONF
TI  - Hybrid Bayesian Eigenobjects: Combining Linear Subspace and Deep Network Methods for 3D Robot Vision
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6843
EP  - 6850
AU  - B. Burchfiel
AU  - G. Konidaris
PY  - 2018
KW  - Bayes methods
KW  - eigenvalues and eigenfunctions
KW  - image representation
KW  - neural nets
KW  - regression analysis
KW  - robot vision
KW  - stereo image processing
KW  - linear subspace methods
KW  - deep convolutional prediction
KW  - nonlinear object representations
KW  - Hybrid Bayesian Eigenobjects
KW  - deep network methods
KW  - 3D robot vision
KW  - HBEO
KW  - 3D geometry
KW  - Three-dimensional displays
KW  - Robots
KW  - Bayes methods
KW  - Pose estimation
KW  - Databases
KW  - Principal component analysis
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593795
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We introduce Hybrid Bayesian Eigenobjects (HBEOs), a novel representation for 3D objects designed to allow a robot to jointly estimate the pose, class, and full 3D geometry of a novel object observed from a single viewpoint in a single practical framework. By combining both linear subspace methods and deep convolutional prediction, HBEOs efficiently learn nonlinear object representations without directly regressing into high-dimensional space. HBEOs also remove the onerous and generally impractical necessity of input data voxelization prior to inference. We experimentally evaluate the suitability of HBEOs to the challenging task of joint pose, class, and shape inference on novel objects and show that, compared to preceding work, HBEOs offer dramatically improved performance in all three tasks along with several orders of magnitude faster runtime performance.
ER  - 

TY  - CONF
TI  - Submap-Based Pose-Graph Visual SLAM: A Robust Visual Exploration and Localization System* The work in this paper is supported by the National Natural Science Foundation of China (61603103, 61673125), the Natural Science Foundation of Guangdong of China (2016A030310293), and the Major Scientific and Technological Special Project of Guangdong of China (2016B090910003).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6851
EP  - 6856
AU  - W. Chen
AU  - L. Zhu
AU  - Y. Guan
AU  - C. R. Kube
AU  - H. Zhang
PY  - 2018
KW  - graph theory
KW  - mean square error methods
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - VSLAM algorithms
KW  - robust visual exploration
KW  - visual simultaneous localization and mapping
KW  - submap-based pose-graph visual SLAM
KW  - robust exploration
KW  - visual front-end
KW  - submap-based VSLAM system
KW  - Image edge detection
KW  - Optimization
KW  - Robustness
KW  - Visualization
KW  - Merging
KW  - Robots
KW  - Tracking
KW  - Monocular VSLAM
KW  - Submap-based Backend
KW  - Robustness
DO  - 10.1109/IROS.2018.8594097
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For VSLAM (Visual Simultaneous Localization and Mapping), localization is a challenging task, especially for some challenging situations: textureless frames, motion blur, etc. To build a robust exploration and localization system in a given space, a submap-based VSLAM system is proposed in this paper. Our system uses a submap back-end and a visual front-end. The main advantage of our system is its robustness with respect to tracking failure, a common problem in current VSLAM algorithms. The robustness of our system is compared with the state-of-the-art in terms of average tracking percentage. The precision of our system is also evaluated in terms of ATE (absolute trajectory error) RMSE (root mean square error) comparing the state-of-the-art. The ability of our system in solving the “kidnapped” problem is demonstrated. Our system can improve the robustness of visual localization in challenging situations.
ER  - 

TY  - CONF
TI  - Active Object Perceiver: Recognition-Guided Policy Learning for Object Searching on Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6857
EP  - 6863
AU  - X. Ye
AU  - Z. Lin
AU  - H. Li
AU  - S. Zheng
AU  - Y. Yang
PY  - 2018
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - robot vision
KW  - AI2-THOR dataset
KW  - action prediction mechanism
KW  - deep reinforcement learning
KW  - visual navigation
KW  - indoor environment
KW  - mobile robots
KW  - recognition-guided policy learning
KW  - active object perceiver
KW  - object searching task
KW  - physical robot
KW  - object recognition module
KW  - deep neural network
KW  - Robots
KW  - Task analysis
KW  - Object recognition
KW  - Navigation
KW  - Search problems
KW  - Visualization
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593720
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR)and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.
ER  - 

TY  - CONF
TI  - Learning Monocular Visual Odometry with Dense 3D Mapping from Dense 3D Flow
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6864
EP  - 6871
AU  - C. Zhao
AU  - L. Sun
AU  - P. Purkait
AU  - T. Duckett
AU  - R. Stolkin
PY  - 2018
KW  - distance measurement
KW  - Gaussian processes
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion estimation
KW  - neural nets
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - learning monocular visual odometry
KW  - monocular SLAM
KW  - simultaneous localization
KW  - neural network
KW  - dual-stream L-VO network
KW  - 6DOF relative pose
KW  - bivariate Gaussian modeling
KW  - KITTI odometry
KW  - visual SLAM system
KW  - dense 2D flow
KW  - fully deep learning approach
KW  - dense 3D flow
KW  - dense 3D mapping
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Visual odometry
KW  - Two dimensional displays
KW  - Deep learning
KW  - Cameras
KW  - Training
DO  - 10.1109/IROS.2018.8594151
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a fully deep learning approach to monocular SLAM, which can perform simultaneous localization using a neural network for learning visual odometry (L-VO) and dense 3D mapping. Dense 2D flow and a depth image are generated from monocular images by sub-networks, which are then used by a 3D flow associated layer in the L-VO network to generate dense 3D flow. Given this 3D flow, the dual-stream L-VO network can then predict the 6DOF relative pose and furthermore reconstruct the vehicle trajectory. In order to learn the correlation between motion directions, the Bivariate Gaussian modeling is employed in the loss function. The L-VO network achieves an overall performance of 2.68 % for average translational error and 0.0143°/m for average rotational error on the KITTI odometry benchmark. Moreover, the learned depth is leveraged to generate a dense 3D map. As a result, an entire visual SLAM system, that is, learning monocular odometry combined with dense 3D mapping, is achieved.
ER  - 

TY  - CONF
TI  - Key-Frame Strategy During Fast Image-Scale Changes and Zero Motion in VIO Without Persistent Features
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6872
EP  - 6879
AU  - E. Allak
AU  - A. Hardt-Stremayr
AU  - S. Weiss
PY  - 2018
KW  - computational complexity
KW  - distance measurement
KW  - feature extraction
KW  - image sequences
KW  - inertial navigation
KW  - Kalman filters
KW  - motion estimation
KW  - robot vision
KW  - video signal processing
KW  - common special motion
KW  - feature displacement
KW  - fast motion
KW  - zero motion phases
KW  - frame selection approach
KW  - motion scenarios
KW  - motion case identification
KW  - subsequent case-specific heuristics
KW  - state vectoraltogether
KW  - persistent features
KW  - VIO algorithm
KW  - motion spectrum
KW  - fast scale change
KW  - frame strategy
KW  - fast image-scale changes
KW  - regular motion
KW  - special treatment
KW  - bad data
KW  - corrupted data
KW  - clean data
KW  - visual-inertial odometry frameworks
KW  - Computational complexity
KW  - Cameras
KW  - Computed tomography
KW  - Feature extraction
KW  - Kalman filters
KW  - Quaternions
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594170
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many of today's Visual-Inertial Odometry (VIO) frameworks work well under regular motion but have issues and need special treatment under special motion. Here, special does not imply bad or corrupted data but stands for increased difficulty to treat clean data. Common special motion for VIO are large feature displacement due to fast motion close to a scene and zero motion phases not providing sufficient baseline. In this paper we present a feature and frame selection approach which seamlessly handles all motion scenarios without the need of (error prone) motion case identification and subsequent case-specific heuristics. We further show that this approach allows to eliminate features in the state vector (persistent features)altogether while still being able to inherently handle zero motion phases. This reduces computational complexity while maintaining the ability to hover in place. We integrate our frame selection approach into our own VIO algorithm and compare its performance against three state-of-the-art algorithms with real data on a real platform. While our approach shows slightly higher global drift it is the only algorithm that can reliably estimate the pose over a large motion spectrum from fast scale change down to zero motion.
ER  - 

TY  - CONF
TI  - Unit Quaternion-Based Parameterization for Point Features in Visual Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6880
EP  - 6886
AU  - J. Maley
AU  - G. Huang
PY  - 2018
KW  - covariance matrices
KW  - geometry
KW  - image representation
KW  - recursive estimation
KW  - SLAM (robots)
KW  - point features
KW  - visual navigation
KW  - Cartesian 3D representation
KW  - homogeneous points
KW  - error state
KW  - unit-quaternion error covariance
KW  - initial feature observations
KW  - initial error-states
KW  - unit quaternion-based representation
KW  - unit quaternion-based parameterization
KW  - initial infinite depth uncertainty
KW  - Quaternions
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Navigation
KW  - Convergence
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594206
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose to use unit quaternions to represent point features in visual navigation. Contrary to the Cartesian 3D representation, the unit quaternion can well represent features at both large and small distances from the camera without suffering from convergence problems. Contrary to inverse-depth, homogeneous points, or anchored homogeneous points, the unit quaternion has error state of minimum dimension of three. In contrast to prior representations, the proposed method does not need to approximate an initial infinite depth uncertainty. In fact, the unit-quaternion error covariance can be initialized from the initial feature observations without prior information, and the initial error-states are not only bounded, but the bound is identical for all scene geometries. To the best of our knowledge, this is the first time bearing-only recursive estimation (in covariance form) of point features has been possible without using measurements to initialize error covariance. The proposed unit quaternion-based representation is validated on numerical examples.
ER  - 

TY  - CONF
TI  - Edge-Based Robust RGB-D Visual Odometry Using 2-D Edge Divergence Minimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Kim
AU  - P. Kim
AU  - S. Lee
AU  - H. J. Kim
PY  - 2018
KW  - edge detection
KW  - gradient methods
KW  - image colour analysis
KW  - image matching
KW  - image registration
KW  - image sequences
KW  - image texture
KW  - least squares approximations
KW  - minimisation
KW  - motion estimation
KW  - motion estimation
KW  - ICP-based optimization
KW  - edge matching criterion
KW  - edge registration problem
KW  - iterative re-weight least squares
KW  - IRLS
KW  - sub-sampling method
KW  - image sequences
KW  - VO algorithm
KW  - iterative closest points framework
KW  - image gradient vectors
KW  - image edge regions
KW  - edge-based robust RGB-D visual odometry
KW  - 2-D edge divergence minimization
KW  - Image edge detection
KW  - Cameras
KW  - Brightness
KW  - Motion estimation
KW  - Minimization
KW  - Visual odometry
KW  - Lighting
DO  - 10.1109/IROS.2018.8593594
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an edge-based robust RGB-D visual odometry (VO) using 2-D edge divergence minimization. Our approach focuses on enabling the VO to operate in more general environments subject to low texture and changing brightness, by employing image edge regions and their image gradient vectors within the iterative closest points (ICP) framework. For more robust and stable ICP-based optimization, we propose a robust edge matching criterion with image gradient vectors. In addition, to reduce a bad effect of outlier residuals, we propose an improved edge registration problem of 2-D edge divergence minimization in the manner of an iterative re-weight least squares (IRLS) motion estimation. To accelerate the proposed approach, a pixel sub-sampling method is employed. We evaluate estimation performance of our method in changing brightness conditions and low-textured scenes. Our approach shows more robust motion estimation than state-of-the-art methods while maintaining comparable accuracy in challenging image sequences at real-time (25 Hz) operation.
ER  - 

TY  - CONF
TI  - Event-Based Moving Object Detection and Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. Mitrokhin
AU  - C. Fermüller
AU  - C. Parameshwara
AU  - Y. Aloimonos
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image sensors
KW  - image sequences
KW  - motion compensation
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - dynamic component
KW  - temporal model inconsistencies
KW  - independent motion detection
KW  - feature tracking
KW  - motion-compensate
KW  - event stream representation
KW  - asynchronous cameras
KW  - asynchronous event stream
KW  - extremely low resolution
KW  - modern event-based vision sensors
KW  - high temporal resolution
KW  - real-time motion analysis
KW  - Dynamic Vision Sensor
KW  - object detection
KW  - Tracking
KW  - Three-dimensional displays
KW  - Cameras
KW  - Optical imaging
KW  - Motion compensation
KW  - Voltage control
KW  - Sensors
DO  - 10.1109/IROS.2018.8593805
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Event-based vision sensors, such as the Dynamic Vision Sensor (DVS), are ideally suited for real-time motion analysis. The unique properties encompassed in the readings of such sensors provide high temporal resolution, superior sensitivity to light and low latency. These properties provide the grounds to estimate motion efficiently and reliably in the most sophisticated scenarios, but these advantages come at a price - modern event-based vision sensors have extremely low resolution, produce a lot of noise and require the development of novel algorithms to handle the asynchronous event stream. This paper presents a new, efficient approach to object tracking with asynchronous cameras. We present a novel event stream representation which enables us to utilize information about the dynamic (temporal)component of the event stream. The 3D geometry of the event stream is approximated with a parametric model to motion-compensate for the camera (without feature tracking or explicit optical flow computation), and then moving objects that don't conform to the model are detected in an iterative process. We demonstrate our framework on the task of independent motion detection and tracking, where we use the temporal model inconsistencies to locate differently moving objects in challenging situations of very fast motion.
ER  - 

TY  - CONF
TI  - A Family of Iterative Gauss-Newton Shooting Methods for Nonlinear Optimal Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Giftthaler
AU  - M. Neunert
AU  - M. Stäuble
AU  - J. Buchli
AU  - M. Diehl
PY  - 2018
KW  - closed loop systems
KW  - computational complexity
KW  - iterative methods
KW  - linear quadratic control
KW  - nonlinear control systems
KW  - predictive control
KW  - iterative algorithms
KW  - unconstrained nonlinear optimal control
KW  - iLQR algorithm
KW  - closed-loop forward integration
KW  - linear complexity
KW  - multiple shooting algorithms
KW  - nonlinear model predictive control applications
KW  - computational complexity
KW  - high-dimensional underactuated robot
KW  - iterative Gauss-Newton shooting methods
KW  - Optimal control
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Prediction algorithms
KW  - Robots
KW  - System dynamics
KW  - Convergence
KW  - Numerical Optimal Control
KW  - Trajectory Optimization
KW  - Multiple Shooting
KW  - Quadrupedal Robots
KW  - Nonlinear Model Predictive Control
KW  - Differential Dynamic Programming
DO  - 10.1109/IROS.2018.8593840
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a family of iterative algorithms for unconstrained nonlinear optimal control. We generalize the well-known iLQR algorithm to different multiple shooting variants, combining advantages like straightforward initialization and a closed-loop forward integration. All algorithms have similar computational complexity, i.e. linear complexity in the time horizon, and can be derived in the same computational framework. We compare the full-step variants of our algorithms and present several simulation examples, including a high-dimensional underactuated robot subject to contact switches. Simulation results show that our multiple shooting algorithms can achieve faster convergence, better local contraction rates and much shorter runtimes than classical iLQR, which makes them a superior choice for nonlinear model predictive control applications.
ER  - 

TY  - CONF
TI  - Controller Synthesis for Discrete-Time Polynomial Systems via Occupation Measures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6911
EP  - 6918
AU  - W. Han
AU  - R. Tedrake
PY  - 2018
KW  - computational complexity
KW  - control system synthesis
KW  - convex programming
KW  - discrete time systems
KW  - linear programming
KW  - Liouville equation
KW  - multidimensional systems
KW  - nonlinear control systems
KW  - reachability analysis
KW  - set theory
KW  - stability
KW  - state feedback
KW  - discrete-time polynomial systems
KW  - occupation measures
KW  - discrete-time polynomial dynamical systems
KW  - occupation measure approach
KW  - discrete-time controlled Liouville equation
KW  - controller synthesis problem
KW  - infinite-dimensional linear programming problem
KW  - finite-dimensional semidefinite programming problems
KW  - sums-of-squares polynomials
KW  - nonlinear controllers
KW  - relaxed problems
KW  - convex problems
KW  - discrete-time autonomous polynomial systems
KW  - controllable set
KW  - nonlinear state feedback controllers
KW  - state feedback control laws
KW  - controller design
KW  - computational complexity
KW  - backward reachable set
KW  - Volume measurement
KW  - Trajectory
KW  - State feedback
KW  - Mathematical model
KW  - Topology
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594400
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we design nonlinear state feedback controllers for discrete-time polynomial dynamical systems via the occupation measure approach. We propose the discrete-time controlled Liouville equation, and use it to formulate the controller synthesis problem as an infinite-dimensional linear programming problem on measures, which is then relaxed as finite-dimensional semidefinite programming problems on moments of measures and their duals on sums-of-squares polynomials. Nonlinear controllers can be extracted from the solutions to the relaxed problems. The advantage of the occupation measure approach is that we solve convex problems instead of generally non-convex problems, and the computational complexity is polynomial in the state and input dimensions, and hence the approach is more scalable. In addition, we show that the approach can be applied to over-approximating the backward reachable set of discrete-time autonomous polynomial systems and the controllable set of discrete-time polynomial systems under known state feedback control laws. We illustrate our approach on several dynamical systems.
ER  - 

TY  - CONF
TI  - Minimax Iterative Dynamic Game: Application to Nonlinear Robot Control Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6919
EP  - 6925
AU  - O. Ogunmolu
AU  - N. Gans
AU  - T. Summers
PY  - 2018
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - minimax techniques
KW  - mobile robots
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - model mismatch
KW  - model uncertainties
KW  - high-risk scenarios
KW  - robustness capacity
KW  - minimax iterative dynamic game
KW  - robust policies
KW  - carefully designed deep neural network policy
KW  - policy robustness
KW  - adversarial disturbances
KW  - ocally robust optimal multistage policy
KW  - nonlinear robot control tasks
KW  - multistage decision policies
KW  - high-dimensional state spaces
KW  - complex control tasks
KW  - meta-learning-deep policies
KW  - Robustness
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Games
KW  - Task analysis
KW  - Uncertainty
KW  - Approximation algorithms
DO  - 10.1109/IROS.2018.8594037
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multistage decision policies provide useful control strategies in high-dimensional state spaces, particularly in complex control tasks. However, they exhibit weak performance guarantees in the presence of disturbance, model mismatch, or model uncertainties. This brittleness limits their use in high-risk scenarios. We present how to quantify the sensitivity of such policies in order to inform of their robustness capacity. We also propose a minimax iterative dynamic game framework for designing robust policies in the presence of disturbance/uncertainties. We test the quantification hypothesis on a carefully designed deep neural network policy; we then pose a minimax iterative dynamic game (iDG) framework for improving policy robustness in the presence of adversarial disturbances. We evaluate our iDG framework on a mecanum-wheeled robot, whose goal is to find a ocally robust optimal multistage policy that achieve a given goal-reaching task. The algorithm is simple and adaptable for designing meta-learning/deep policies that are robust against disturbances, model mismatch, or model uncertainties, up to a disturbance bound. Videos of the results are on the author's website: https://goo.gl/JhshTB, while the codes for reproducing our experiments are on github: https://goo.gl/3G2VBy. A self-contained environment for reproducing our results is on docker: https://goo.gl/Bo7MBe.
ER  - 

TY  - CONF
TI  - Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - H. Kim
AU  - J. Kwon
AU  - Y. Oh
AU  - B. J. You
AU  - W. Yang
PY  - 2018
KW  - biomechanics
KW  - control engineering computing
KW  - elastic constants
KW  - haptic interfaces
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - vibrations
KW  - human intention based stiffness estimation
KW  - HRI device
KW  - frequency analysis
KW  - input response simulation
KW  - vibration magnitude
KW  - virtual wall collision
KW  - control distribution ratios
KW  - physical collaboration operations
KW  - human-robot interaction device
KW  - weighted hybrid admittance-impedance control
KW  - Impedance
KW  - Admittance
KW  - Force
KW  - Manipulators
KW  - Stability analysis
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594435
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.
ER  - 

TY  - CONF
TI  - Multimodal Environment Dynamics for Interactive Robots: Towards Fault Detection and Task Monitoring
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6932
EP  - 6937
AU  - K. Haninger
AU  - D. Surdilovic
PY  - 2018
KW  - end effectors
KW  - fault diagnosis
KW  - fault tolerant control
KW  - force control
KW  - industrial manipulators
KW  - robotic assembly
KW  - trajectory control
KW  - multimodal environment dynamics
KW  - interactive robots
KW  - environmental uncertainty
KW  - contact force
KW  - subtask completion
KW  - task monitoring approach
KW  - complex assembly tasks
KW  - discrete environment dynamic modes
KW  - semistructured environments
KW  - interactive tasks
KW  - impedance control
KW  - admittance controlled robots
KW  - force/position measurements
KW  - admittance controlled robot
KW  - gear assembly task
KW  - fault detection
KW  - force trajectories
KW  - position trajectories
KW  - end-effector physical compliance
KW  - Dynamics
KW  - Task analysis
KW  - Force
KW  - Robot sensing systems
KW  - Admittance
KW  - Estimation
DO  - 10.1109/IROS.2018.8593650
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interactive robots offer improved performance in tasks with environmental uncertainty, but accommodating environment input weakens predictions of contact force or position trajectories, making the identification of subtask completion or faults difficult. This paper develops a task monitoring approach for complex assembly tasks that involve transitions between discrete environment dynamic modes. In semi-structured environments, these dynamic modes and their transitions are approximately known a priori, allowing task monitoring through estimation of the current mode and fault detection as a deviation from expected, desired dynamic mode transitions. This allows a more natural description of many interactive tasks, improving robustness to variations in force or position trajectories that impedance control seeks to address. The ability of impedance and admittance controlled robots to identify their environment is investigated, making consideration of joint and end-effector physical compliance. Prior information on environment dynamics and mode transitions allow recursive estimates of dynamic mode suitable for online use, under both full state knowledge and only force/position measurements. Experiments with an admittance controlled robot in a gear assembly task validate the approach.
ER  - 

TY  - CONF
TI  - Estimating an Articulated Tool's Kinematics via Visuo-Tactile Based Robotic Interactive Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6938
EP  - 6944
AU  - Q. Li
AU  - A. Ückermann
AU  - R. Haschke
AU  - H. Ritter
PY  - 2018
KW  - dexterous manipulators
KW  - feedback
KW  - haptic interfaces
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - sensor fusion
KW  - tactile sensors
KW  - visuo-tactile based robotic interactive manipulation
KW  - autonomous robots
KW  - single passive observation
KW  - articulated toy
KW  - dual arm robotic setup
KW  - tactile finger
KW  - visuo-tactile servoing controller
KW  - flipping task
KW  - tactile feedback
KW  - compact control loop
KW  - kinematic parameters
KW  - vision feedback
KW  - articulated tools kinematics
KW  - data fusion method
KW  - fingertips motion trajectory
KW  - Tools
KW  - Robot kinematics
KW  - Kinematics
KW  - Task analysis
KW  - End effectors
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594295
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The usage of articulated tools for autonomous robots is still a challenging task. One of the difficulties is to automatically estimate the tool's kinematics model. This model cannot be obtained from a single passive observation, because some information, such as a rotation axis (hinge), can only be detected when the tool is being used. Inspired by a baby using its hands while playing with an articulated toy, we employ a dual arm robotic setup and propose an interactive manipulation strategy based on visual-tactile servoing to estimate the tool's kinematics model. In our proposed method, one hand is holding the tool's handle stably, and the other arm equipped with tactile finger flips the movable part of the articulated tool. An innovative visuo-tactile servoing controller is introduced to implement the flipping task by integrating the vision and tactile feedback in a compact control loop. In order to deal with the temporary invisibility of the movable part in camera, a data fusion method which integrates the visual measurement of the movable part and the fingertip's motion trajectory is used to optimally estimate the orientation of the tool's movable part. The important tool's kinematic parameters are estimated by geometric calculations while the movable part is flipped by the finger. We evaluate our method by flipping a pivoting cleaning head (flap) of a wiper and estimating the wiper's kinematic parameters. We demonstrate that the flap of the wiper is flipped robustly, even the flap is shortly invisible. The orientation of the flap is tracked well compared to the ground truth data. The kinematic parameters of the wiper are estimated correctly.
ER  - 

TY  - CONF
TI  - Algorithmization of Constrained Motion for Car-Like Robots Using the VFO Control Strategy with Parallelized Planning of Admissible Funnels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6945
EP  - 6951
AU  - T. Gawron
AU  - M. M. Michalek
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - motion control
KW  - robust control
KW  - input constraints
KW  - control input signals
KW  - admissible funnels
KW  - planning process
KW  - constrained motion
KW  - car-like robots
KW  - VFO control strategy
KW  - parallelized planning
KW  - car-like kinematics
KW  - mobile robotics
KW  - intelligent vehicles
KW  - feedback control algorithms
KW  - motion execution
KW  - VFO control law
KW  - state constraints
KW  - motion planning algorithms
KW  - robot actuation
KW  - open loop control signals
KW  - parallelized deterministic sampling-based algorithm
KW  - vector field orientation
KW  - steering dynamics
KW  - modeling uncertainties
KW  - Robots
KW  - Planning
KW  - Kinematics
KW  - Electron tubes
KW  - Vehicle dynamics
KW  - Uncertainty
KW  - Feedback control
DO  - 10.1109/IROS.2018.8594402
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Vehicles with car-like kinematics are ubiquitous, therefore an ability to algorithmize (i.e., how to plan and effectively execute) complex maneuvers in the presence of obstacles is vital to mobile robotics and intelligent vehicles. Traditionally, this problem is solved using the well known motion planning algorithms, which generate the open-loop control signals neglecting the effects of measurement noises, modeling uncertainties and imperfect robot actuation. While such effects can be compensated to some extent by online replanning, the application of feedback control algorithms to motion execution is unavoidable if robustness of the system is desired. Consequently, the recent works focus on integration of both motion planning and control algorithms to obtain motion plans robust to uncertainty of the initial conditions. In accordance with this trend, we propose a modified VFO (Vector Field Orientation) control law, which is designed to satisfy the state and input constraints resulting from the presence of obstacles in the environment, respect the steering angle limits in conjunction with steering dynamics of the car-like robot, and preserve continuity of the control input signals. Thanks to analytic characterization of admissible funnels (i.e. positively invariant subsets of the configuration space) developed from an analysis of the VFO control law, we guarantee satisfaction of all the mentioned constraints in the continuous domains of time and configuration space of the robot without sacrificing computational efficiency of the planning process. A specific funnel is planned with a highly parallelized deterministic sampling-based algorithm achieving quasi-real-time performance.
ER  - 

TY  - CONF
TI  - ASPiC: An Acting System Based on Skill Petri Net Composition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6952
EP  - 6958
AU  - C. Lesire
AU  - F. Pommereau
PY  - 2018
KW  - path planning
KW  - Petri nets
KW  - robots
KW  - ASPiC
KW  - acting system
KW  - skill Petri net composition
KW  - high-level action
KW  - executable commands
KW  - autonomous robots
KW  - formal model
KW  - robot skills
KW  - control-flow Petri net model
KW  - autonomous surface vehicle
KW  - area protection mission
KW  - Petri nets
KW  - Robots
KW  - Analytical models
KW  - Adaptation models
KW  - Tools
KW  - Planning
KW  - Inductors
DO  - 10.1109/IROS.2018.8594328
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Acting systems aim at refining high-level actions into executable commands, while managing access to resources, possible failures, or any other unpredictable situation. Improving the trust on autonomous robots also requires to have a formal model of acting, and the capability to perform some analysis on this model. In this paper, we present ASPiC, an acting system based on the modeling of robot's skills using a specific control-flow Petri net model. The skills can then be combined using well-defined operators to build a complete plan that refines a high-level action. Some properties are guaranteed by construction, while others can be verified on the resulting plan model. ASPiC is finally applied to an area protection mission by an autonomous surface vehicle.
ER  - 

TY  - CONF
TI  - Static Kinematics for an Antagonistically Actuated Robot Based on a Beam-Mechanics-Based Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6959
EP  - 6964
AU  - A. Stilli
AU  - E. Kolokotronis
AU  - J. Fraś
AU  - A. Ataka
AU  - K. Althoefer
AU  - H. A. Wurdemann
PY  - 2018
KW  - manipulator kinematics
KW  - pneumatic actuators
KW  - static kinematics
KW  - beam-mechanics-based model
KW  - soft robotic structures
KW  - industrial revolution
KW  - soft robotics
KW  - traditional robots
KW  - rigid links
KW  - joints
KW  - soft robots
KW  - stiffness mechanism embodies
KW  - pneumatic air actuation
KW  - variable stiffness values
KW  - soft stiffness controllable robot
KW  - mathematical model
KW  - stiffness levels
KW  - soft robotic manipulator
KW  - interaction forces
KW  - analytical model
KW  - robotic actuation system
KW  - actuated robot
KW  - Manipulators
KW  - Tendons
KW  - Force
KW  - Soft robotics
KW  - Mathematical model
KW  - Service robots
DO  - 10.1109/IROS.2018.8593674
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft robotic structures might play a major role in the 4th industrial revolution. Researchers have successfully demonstrated advantages of soft robotics over traditional robots made of rigid links and joints in several application areas including manufacturing, healthcare and surgical interventions. However, soft robots have limited ability to exert higher forces when it comes to interaction with the environment, hence, change their stiffness on demand over a wide range. One stiffness mechanism embodies tendon-driven and pneumatic air actuation in an antagonistic way achieving variable stiffness values. In this paper, we apply a beam-mechanics-based model to this type of soft stiffness controllable robot. This mathematical model takes into account the various stiffness levels of the soft robotic manipulator as well as interaction forces with the environment at the tip of the manipulator. The analytical model is implemented into a robotic actuation system made of motorised linear rails with load cells (obtaining applied forces to the tendons) and a pressure regulator. Here, we present and analyse the performance and limitations of our model.
ER  - 

TY  - CONF
TI  - A Novel Soft Elbow Exosuit to Supplement Bicep Lifting Capacity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6965
EP  - 6971
AU  - C. M. Thalman
AU  - Q. P. Lam
AU  - P. H. Nguyen
AU  - S. Sridar
AU  - P. Polygerinos
PY  - 2018
KW  - bending
KW  - biomechanics
KW  - electromyography
KW  - medical robotics
KW  - pneumatic actuators
KW  - torque
KW  - measurable assistance
KW  - bicep lifting capacity
KW  - supplemental lifting assistance
KW  - muscle activity
KW  - bicep muscle
KW  - repetitive lifting
KW  - pneumatically pressurized soft actuators
KW  - high force-to-weight ratio
KW  - analytical model
KW  - bending behavior
KW  - consecutive actuators
KW  - theoretical model
KW  - elbow joint torque value
KW  - surface electromyography sensors
KW  - active assistance
KW  - soft elbow exosuit
KW  - nylon fabrics
KW  - motion capture system
KW  - concentric contractions
KW  - isometric contractions
KW  - pressure 300.0 kPa
KW  - SN
KW  - Actuators
KW  - Elbow
KW  - Torque
KW  - Shape
KW  - Force
KW  - Injuries
KW  - Muscles
DO  - 10.1109/IROS.2018.8594403
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates the design of a soft elbow exosuit capable of providing supplemental lifting assistance by reducing muscle activity of the bicep muscle. The aim is to improve the efficiency and endurance of workers who are tasked with repetitive lifting. The design consists of an array of pneumatically pressurized soft actuators, which are encased in nylon fabric that allows for a high force-to-weight ratio of 211.SN/g. An analytical model governing the bending behavior of two consecutive actuators and torque generated by the exosuit is developed, with test results showing less than 10% error from the theoretical model. An elbow joint torque value of 27.6N.m is achieved at 300kPa, which is comparable to the 30N.m maximum set by OSHA requirements in the USA. Further testing with a healthy participant is performed using surface electromyography (sEMG) sensors and a motion capture system to assess the capabilities of the exosuit to provide active assistance to the bicep during isometric and concentric contractions. Measurable assistance to lifting is observed with minimal obstruction to the user's range of motion for all experiments.
ER  - 

TY  - CONF
TI  - Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6972
EP  - 6979
AU  - E. Misimi
AU  - A. Olofsson
AU  - A. Eilertsen
AU  - E. R. Øye
AU  - J. R. Mathiassen
PY  - 2018
KW  - grippers
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - solid modelling
KW  - complex processing tasks
KW  - current robot learning policies
KW  - consistent learning policy
KW  - skilled operators
KW  - robotic automation
KW  - variable outcomes
KW  - tedious nature
KW  - laborious nature
KW  - human operators
KW  - food industries
KW  - ocean space
KW  - huge demand
KW  - mechanical structures
KW  - complex geometrical 3D shapes
KW  - high biological variation
KW  - deformable food raw materials
KW  - compliant food raw materials
KW  - robotic handling
KW  - complex 3D shapes
KW  - compliant food objects
KW  - inconsistent demonstrations
KW  - LfD learning policy
KW  - effective robot handling
KW  - gripper finger configuration
KW  - RGB-D images
KW  - food compliant objects
KW  - robotic grasping
KW  - robust learning policy
KW  - Grasping
KW  - Visualization
KW  - Service robots
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Compliant food objects
KW  - Learning from Demonstration
KW  - Robotic handling
KW  - Multifingered gripper
DO  - 10.1109/IROS.2018.8594368
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.
ER  - 

TY  - CONF
TI  - Closed-Loop Temperature Control of Nylon Artificial Muscles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6980
EP  - 6985
AU  - C. S. Haines
AU  - G. Niemeyer
PY  - 2018
KW  - closed loop systems
KW  - coils
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - polymer fibres
KW  - temperature control
KW  - temperature measurement
KW  - temperature measurement
KW  - electrothermal heating
KW  - muscle temperature monitoring
KW  - overheat protection
KW  - nested controller
KW  - wire resistance
KW  - metal wire
KW  - coiled polymer fibers
KW  - coiled actuators
KW  - nylon artificial muscles
KW  - closed-loop temperature control
KW  - Muscles
KW  - Temperature measurement
KW  - Wires
KW  - Force
KW  - Heating systems
KW  - Resistance
DO  - 10.1109/IROS.2018.8593599
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Coiled actuators made from polymer fibers are fast becoming popular due to their low-cost and ease of fabrication. Unfortunately, reliable real-time temperature measurement has been frustrated by the small fiber diameter of typical actuators. By using coiled polymer fibers wrapped with a metal wire, we demonstrate the ability to concurrently drive a muscle by electrothermal heating, and monitor muscle temperature through the wire resistance. This simple method enables convenient overheat protection for these muscles, as well as the possibility for closed-loop temperature control. Using this platform, we demonstrate a nested controller using temperature and position feedback to improve contraction speed, and investigate the cooling rates of various configurations that increase total force output.
ER  - 

TY  - CONF
TI  - Acoustic Sensing for Soft Pneumatic Actuators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6986
EP  - 6991
AU  - G. Zöller
AU  - V. Wall
AU  - O. Brock
PY  - 2018
KW  - microphones
KW  - pneumatic actuators
KW  - sensors
KW  - microphone-based sensor solution
KW  - PneuFlex actuator
KW  - soft pneumatic actuators
KW  - acoustic sensing
KW  - contacted material
KW  - sensing method
KW  - sound signature
KW  - contact locations
KW  - contact force
KW  - Robot sensing systems
KW  - Microphones
KW  - Pneumatic actuators
KW  - Force
DO  - 10.1109/IROS.2018.8594396
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel sensing method for soft pneumatic actuators. The method uses a single microphone, embedded into the actuator's air chamber. Contact with the environment induces sound (vibration) in the actuator. The materials and the shape of the actuator reflect, refract, and attenuate the sound as it propagates inside the actuator. This produces a unique sound signature for different types of events, enabling the sensing of contact locations, contact force, and the type of contacted material. Sensing is insensitive to the inflation state of the actuator and to background noise. We demonstrate the robustness and versatility of the microphone-based sensor solution in experiments with a PneuFlex actuator. The proposed sensorization avoids the fundamental challenges of sensorizing soft pneumatic actuators, because the placement of a microphone does not negatively affect the compliance of the actuator and because a single microphone suffices for sensorization of the entire actuator, eliminating the need for an application-specific sensor layout.
ER  - 

TY  - CONF
TI  - Flexible Fabric Actuator Realizing 3D Movements Like Human Body Surface for Wearable Devices
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6992
EP  - 6997
AU  - Y. Funabora
PY  - 2018
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - muscle
KW  - pneumatic actuators
KW  - wearable computers
KW  - wearable devices
KW  - continuous control system
KW  - human body surface
KW  - rubber swath
KW  - fabric actuator
KW  - 3D movements
KW  - motions
KW  - McKibben artificial muscles
KW  - Muscles
KW  - Actuators
KW  - Fabrics
KW  - Rubber
KW  - Weaving
KW  - Regulators
DO  - 10.1109/IROS.2018.8594359
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new flexible fabric actuator realizing three dimensional movements for wearable devices is proposed in this paper. Such actuators must be lightweight and highly flexible, producing movements with high degree of freedom to assist/follow human natural motions. Improving the structure and control system of a fabric actuator from the previous research, the flexible fabric actuator with continuous control is developed. This paper presents new configuration of thin artificial muscles on a flexible rubber swath, a continuous control system to control the fabric actuator smoothly, and control methods to realize six basic movements of human body (forward and backward bends, left and right bends, left and right twists)with less number of muscles. The experiment results indicate the possibility that the proposed fabric actuator woven thin McKibben artificial muscles is a viable technology for use in wearable devices.
ER  - 

TY  - CONF
TI  - Soft Biomimetic Prosthetic Hand: Design, Manufacturing and Preliminary Examination
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - J. Fras
AU  - K. Althoefer
PY  - 2018
KW  - artificial limbs
KW  - biomechanics
KW  - biomimetics
KW  - manipulators
KW  - human hand
KW  - complex mechanical structure
KW  - prosthetic devices
KW  - handled object
KW  - mechanical compliance
KW  - synergistic finger movement
KW  - current control system
KW  - soft biomimetic prosthetic hand
KW  - Actuators
KW  - Exoskeletons
KW  - Manufacturing
KW  - Shape
KW  - Thumb
KW  - Joints
KW  - Sensors
DO  - 10.1109/IROS.2018.8593666
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The human hand is a complex structure. It is strong but precise. It consists of a very complex mechanical structure that enables the hand to adapt and efficiently handle objects of various shapes, weights and textures. Today's prosthetic devices, struggling to provide similar functions, become overly complex and expensive. They are composed of multiple, precise parts, including miniaturised actuators and sensors as well as complex control, to satisfy the manipulation tasks required. In this paper we propose a soft pneumatic hand that adapts passively to the handled object due to its mechanical compliance. It is pressure driven and enables individual fingers to be controlled independently for dexterity or in groups when a synergistic finger movement is needed. The hand has a truly anatomical shape, is easy to replace and cheap in production. The design can be easily adjusted in terms of shape and size in order to fit each individual user. The paper presents the design, manufacturing technology, current control system and preliminary tests of the hand's capabilities.
ER  - 

TY  - CONF
TI  - A Novel All-in-One Manufacturing Process for a Soft Sensor System and its Application to a Soft Sensing Glove
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7004
EP  - 7009
AU  - S. Kim
AU  - D. Jeong
AU  - J. Oh
AU  - W. Park
AU  - J. Bae
PY  - 2018
KW  - biomechanics
KW  - data gloves
KW  - gallium alloys
KW  - manufacturing processes
KW  - sensors
KW  - virtual reality
KW  - wearable computers
KW  - manufacturing process
KW  - soft sensor system
KW  - soft sensing glove
KW  - attractive application
KW  - wearable devices
KW  - soft sensors
KW  - rigid sensing units
KW  - wearable sensor systems
KW  - assembly process
KW  - bulky electrode part
KW  - novel fabrication process
KW  - Fabrication
KW  - Robot sensing systems
KW  - Electrodes
KW  - Sensor systems
KW  - Writing
KW  - Wiring
DO  - 10.1109/IROS.2018.8594389
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A sensing glove is an attractive application of wearable devices. Soft sensors are emerging to replace rigid sensing units, especially for wearable sensor systems, due to its inherent softness, flexibility, and stretchability. However, the fabrication process for the soft sensors is usually complex, time-consuming, labor-intensive, and has low production rate. To integrate a sensor system, an assembly process is essential, which may make the system bulky. Moreover, a solution for the electrode parts has rarely been suggested, although a bulky electrode part may obstruct the user's movement and degrade performance of the sensor. Thus, in this study, a novel fabrication process is suggested based on direct ink writing (DIW) of eutectic gallium-indium (EGaIn), which forms all the items in the sensor system from the sensing units, wiring, and the electrode part. A sensing glove for 2D finger motions was fabricated, and its performance was verified in terms of linearity, dynamic response, and accuracy. The sensing glove can be used as an easily-wearable and an intuitive interface to the virtual reality environment.
ER  - 

TY  - CONF
TI  - On the Orientation Planning with Constrained Angular Velocity and Acceleration at Endpoints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7033
EP  - 7038
AU  - M. Shahbazi
AU  - N. Kashiri
AU  - D. Caldwell
AU  - N. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - interpolation
KW  - path planning
KW  - polynomials
KW  - position control
KW  - splines (mathematics)
KW  - spline trajectories
KW  - time curves
KW  - quaternion coefficients
KW  - unitariness condition
KW  - quaternion representation
KW  - on-line update mechanism
KW  - anthropomorphic robot upper-body
KW  - real-time compatibility
KW  - constrained angular velocity
KW  - orientation planning algorithms
KW  - task space trajectory generation
KW  - robotics applications
KW  - continuous acceleration profiles
KW  - realtime implementation
KW  - Quaternions
KW  - Interpolation
KW  - Acceleration
KW  - Robots
KW  - Splines (mathematics)
KW  - Trajectory
KW  - Planning
DO  - 10.1109/IROS.2018.8593657
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents orientation planning algorithms respecting the requirements of task space trajectory generation, particularly in robotics applications. The proposed algorithms fulfill the following conditions: (i) permitting to impose constraints at angular velocity and acceleration in addition to orientation at endpoints; (ii) rendering continuous acceleration profiles even when interpolating multiple orientations; and (iii) being computationally fast enough for realtime implementation. The generated spline trajectories are essentially a concatenation of polynomial in time curves parameterized by quaternion coefficients. To impose the unitariness condition critically required for quaternion representation of orientation, we develop an on-line update mechanism which successively reparameterizes the polynomials constructing the spline, towards suppressing distortions that the normalization operation might incur. Experiments on an anthropomorphic robot upper-body are carried out to demonstrate the efficacy and real-time compatibility of the proposed algorithms in comparison with a standard spherical interpolation method.
ER  - 

TY  - CONF
TI  - Coverage Path Planning with Adaptive Viewpoint Sampling to Construct 3D Models of Complex Structures for the Purpose of Inspection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7047
EP  - 7054
AU  - R. Almadhoun
AU  - T. Taha
AU  - D. Gan
AU  - J. Dias
AU  - Y. Zweiri
AU  - L. Seneviratne
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image sampling
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - search problems
KW  - adaptive search space coverage path planner
KW  - unmanned aerial vehicle
KW  - coverage path planning
KW  - adaptive sampling
KW  - onboard sensors
KW  - reference model
KW  - accurate 3D models
KW  - complex structure
KW  - adaptive viewpoint sampling
KW  - Sensors
KW  - Adaptation models
KW  - Path planning
KW  - Solid modeling
KW  - Entropy
KW  - Clustering algorithms
KW  - Octrees
DO  - 10.1109/IROS.2018.8593719
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a coverage path planning algorithm with adaptive viewpoint sampling to construct accurate 3D models of complex large structures using Unmanned Aerial Vehicle (UAV). The developed algorithm, Adaptive Search Space Coverage Path Planner (ASSCPP), utilizes an existing 3D reference model of the complex structure and the onboard sensors' noise models to generate paths that are evaluated based on the traveling distance and the quality of the model. The algorithm generates a set of viewpoints by performing adaptive sampling that directs the search towards areas with low accuracy and low coverage. The algorithm predicts the coverage percentage obtained by following the generated coverage path using the reference model. A set of experiments were conducted in real and simulated environments with structures of different complexities to test the validity of the proposed algorithm.
ER  - 


