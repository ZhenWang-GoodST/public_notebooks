TY  - CONF
TI  - Robust Optimization-Based Calculation of Invariant Trajectory Representations for Point and Rigid-body Motion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5598
EP  - 5605
AU  - M. Vochten
AU  - T. De Laet
AU  - J. De Schutter
PY  - 2018
KW  - image motion analysis
KW  - image recognition
KW  - image reconstruction
KW  - image representation
KW  - optimisation
KW  - smoothing methods
KW  - standard smoothing methods
KW  - measurement noise
KW  - motion trajectories
KW  - robust optimization-based calculation
KW  - invariant trajectory representations
KW  - motion experiments
KW  - motion recognition
KW  - context-independent motion models
KW  - rigid-body motion
KW  - Trajectory
KW  - Sensitivity
KW  - Smoothing methods
KW  - Context modeling
KW  - Fasteners
KW  - Noise measurement
KW  - Programming
DO  - 10.1109/IROS.2018.8593540
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Invariant representations of demonstrated motion trajectories provide context-independent motion models that can be used in motion recognition and generalization applications such as robot programming by demonstration. In practice, the use of invariant representations is still limited because their numerical calculation from a demonstrated trajectory is complicated by sensitivity to measurement noise and singularities, yielding inaccurate invariant functions that do not correspond well with the original trajectory. This paper improves the calculation of invariant representations for point and rigid-body motions by reformulating their calculation as an optimization problem that minimizes the error between the trajectory reconstructed from the invariant representation and the measured trajectory. Robustness against noise and singularities is ensured through the addition of regularization terms on the invariants. Simulations and real motion experiments show that the accuracy of the calculated invariant representations greatly improves with respect to standard smoothing methods. These results encourage future developments of motion recognition and generalization applications based on invariant trajectory representations.
ER  - 

TY  - CONF
TI  - Reducing the Computational Complexity of Mass-Matrix Calculation for High DOF Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5614
EP  - 5619
AU  - M. Safeea
AU  - R. Bearee
AU  - P. Neto
PY  - 2018
KW  - computational complexity
KW  - manipulator dynamics
KW  - matrix algebra
KW  - position control
KW  - high DOF robots
KW  - geometric dynamics algorithm for high number of robot joints
KW  - GDAHJ
KW  - JSIM
KW  - joint space inertia matrix
KW  - dynamics computations
KW  - degrees of freedom
KW  - mass-matrix calculation
KW  - computational complexity
KW  - Acceleration
KW  - Mathematical model
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Dynamics
KW  - Computational complexity
KW  - mass-matrix
KW  - dynamics
KW  - Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ)
KW  - high DOF robots
DO  - 10.1109/IROS.2018.8593775
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Increasingly, robots have more degrees of freedom (DOF), imposing a need for calculating more complex dynamics. As a result, better efficiency in carrying out dynamics computations is becoming more important. In this study, an efficient method for computing the joint space inertia matrix (JSIM) for high DOF serially linked robots is addressed. We call this method the Geometric Dynamics Algorithm for High number of robot Joints (GDAHJ). GDAHJ is non-symbolic, preserve simple formulation, and it is convenient for numerical implementation. This is achieved by simplifying the way to recursively derive the mass-matrix exploiting the unique property of each column of the JSIM and minimizing the number of operations with O(n2) complexity. Results compare favorably with existing methods, achieving better performance over state-of-the-art by Featherstone when applied for robots with more than 13 DOF.
ER  - 

TY  - CONF
TI  - Position-Based Time-Integrator for Frictional Articulated Body Dynamics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - Z. Pan
AU  - D. Manocha
PY  - 2018
KW  - friction
KW  - graphics processing units
KW  - Newton method
KW  - optimisation
KW  - robot dynamics
KW  - Newton-Euler-based simulator
KW  - Newton-type optimization scheme
KW  - friction forces
KW  - position variables
KW  - frictional dynamics
KW  - frictional articulated body dynamics
KW  - position-based time-integrator
KW  - Mathematical model
KW  - Friction
KW  - Dynamics
KW  - Heuristic algorithms
KW  - Optimization
KW  - Linear programming
KW  - Robots
DO  - 10.1109/IROS.2018.8593817
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a new time-integrator for modeling the frictional dynamics of articulated bodies. Our formulation represents the configuration of the articulated body using position variables and then uses those variables to model the friction forces between the articulated body and the environment. Our approach corresponds to a Newton-type optimization scheme that is guaranteed to converge so that it is stable with large timestep sizes. We evaluate the accuracy and stability of our time-integrator by comparing it with a conventional formulations based on the Newton-Euler equation and demonstrate the benefits on standard controller-optimization applications. We achieve 3-5 times speedup over a Newton-Euler-based simulator on a CPU. Our approach can be easily parallelized on a GPU and results in additional 4-15 times performance improvement.
ER  - 

TY  - CONF
TI  - Hydrodynamics Parameter Identification of Submerged Bodies: Numerical Methods Comparison and Friction Model Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5628
EP  - 5633
AU  - N. Gartner
AU  - M. Richier
AU  - V. Hugel
PY  - 2018
KW  - friction
KW  - hydrodynamics
KW  - integration
KW  - numerical analysis
KW  - parameter estimation
KW  - pendulums
KW  - hydrodynamics parameter
KW  - numerical methods
KW  - friction model analysis
KW  - free decay pendulum
KW  - single friction coefficient
KW  - numerical integration method
KW  - dynamical model
KW  - estimation methods
KW  - quadratic friction coefficients
KW  - submerged bodies
KW  - Hydrodynamics
KW  - Friction
KW  - Numerical models
KW  - Damping
KW  - Acceleration
KW  - Cutoff frequency
KW  - Estimation
DO  - 10.1109/IROS.2018.8593770
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper focuses on numerical methods that can be used to identify hydrodynamic parameters of submerged bodies, namely added mass, linear and quadratic friction coefficients. The mechanical setup is a free decay pendulum that is equipped with an encoder. The first contribution of this paper deals with the comparison of two estimation methods: one method that fits the acceleration of the dynamical model with the acceleration obtained from derivatives of the measured angular position, and another method that fits this position with the angle obtained by numerical integration. The second contribution consists of investigating to what extent estimated added mass and friction coefficient parameters of the dynamical model match the empirical or theoretical values in the case of a spherical object. The results obtained show that the numerical integration method allows to determine the added mass with a good accuracy and a single friction coefficient could be used for the dynamic model without loosing validity.
ER  - 

TY  - CONF
TI  - Actuator and Friction Dynamics Formulation in Control of PKMs: From Design to Real-Time Experiments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5634
EP  - 5639
AU  - H. Saied
AU  - A. Chemori
AU  - M. E. Rafei
AU  - C. Francis
AU  - F. Pierret
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - feedforward
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - position control
KW  - real-time experiments
KW  - dynamic formulation
KW  - parallel manipulators
KW  - actuator
KW  - friction dynamics
KW  - model-based controller
KW  - computed feedforward
KW  - formulated dynamics
KW  - control performance
KW  - high-speed motions
KW  - feedforward part
KW  - computational efforts
KW  - PKM
KW  - four-degree-of-freedom parallel robot
KW  - unfavourable nonlinearity abundant extensively
KW  - Friction
KW  - Actuators
KW  - Dynamics
KW  - Manipulator dynamics
KW  - Computational modeling
KW  - Torque
DO  - 10.1109/IROS.2018.8594329
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper deals with a new dynamic formulation of parallel manipulators incorporating the actuator and friction dynamics to be utilized in control. A model-based controller, PD with computed feedforward, is implemented for a parallel robot taking into consideration the formulated dynamics. The motivation behind this contribution is to enhance the control performance by compensating the unfavourable nonlinearities abundant extensively in PKMs. Those nonlinearities may increase considerably when operating at high-speed motions. The proposed feedforward part relies on the reference trajectories instead of the measured ones improving the control performance and the computational efforts. To validate our contribution, real-time experiments are conducted on a four degree-of-freedom parallel robot named VELOCE in different operating conditions.
ER  - 

TY  - CONF
TI  - A Robust Time-Stepping Scheme for Quasistatic Rigid Multibody Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5640
EP  - 5647
AU  - T. Pang
AU  - R. Tedrake
PY  - 2018
KW  - grippers
KW  - integer programming
KW  - manipulator kinematics
KW  - quadratic programming
KW  - robust control
KW  - torque
KW  - robust time-stepping scheme
KW  - quasistatic rigid multibody systems
KW  - quasistatic physics
KW  - linear complementarity problems
KW  - grasping velocity command
KW  - small-to-medium-sized systems
KW  - manipulation
KW  - motion primitive
KW  - LCP
KW  - optimization problem
KW  - mixed-integer quadratic program
KW  - torque
KW  - Grippers
KW  - Friction
KW  - Force
KW  - Kinematics
KW  - Grasping
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594378
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An effective scheme to simulate low-speed, contact-rich manipulation tasks is to assume quasistatic physics and advance system states by solving linear complementarity problems (LCPs). However, the existing LCP-based quasistatic time-stepping scheme fails to simulate grasping-an essential motion primitive in manipulation-due to two drawbacks specific to quasistatic systems. Firstly, inputs to quasistatic systems are velocity commands instead of torques. This can lead to penetration, and thus an infeasible LCP, when two rigid bodies in contact are commanded to push against each other. Secondly, as multiple force solutions exist for a given velocity command, a grasping velocity command is not guaranteed to generate sufficient grasping forces. In this paper, we reformulate the quasistatic time-stepping scheme as an optimization problem with complementarity constraints and a quadratic objective. By minimizing the difference between actual and commanded velocities, linearized non-penetration constraints can always be satisfied. Moreover, undesirable solutions with insufficient normal forces can be removed by considering elasticity, which is modeled by comparing actual and commanded velocities. The resulting optimization problem is a mixed-integer quadratic program, which can be solved reasonably quickly for small-to-medium-sized systems. The effectiveness of the proposed reformulation is validated by simulation results of systems with different levels of complexity.
ER  - 

TY  - CONF
TI  - Design and Development of a Slender Dual-Structure Continuum Robot for In-Situ Aeroengine Repair
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5648
EP  - 5653
AU  - M. Wang
AU  - D. Palmer
AU  - X. Dong
AU  - D. Alatorre
AU  - D. Axinte
AU  - A. Norton
PY  - 2018
KW  - aerodynamics
KW  - aircraft maintenance
KW  - end effectors
KW  - industrial robots
KW  - inspection
KW  - mechatronics
KW  - suspensions (mechanical components)
KW  - slender dual-structure continuum robot
KW  - In-Situ Aeroengine Repair
KW  - in-situ aeroengine maintenance works
KW  - end-effector
KW  - aeroengine combustion chamber
KW  - configuration-cable kinematics
KW  - Maintenance engineering
KW  - Kinematics
KW  - Inspection
KW  - Shape
KW  - End effectors
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594142
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In-situ aeroengine maintenance works (e.g. inspection, repair) are highly beneficial as it can significantly reduce currently accepted maintenance cycle which is extensive and costly due to the need to remove engines from the wing of an aircraft. However, feeding in/out via inspection ports and performing a multi-axis movement of an end-effector in a very constrained environment such as aeroengine combustion chamber is a fairly challenging task. This paper presents the design and development of a highly slender (i.e., low diameter-to-length ratio) dual-structure continuum robot with 16 degrees of freedom (DoFs) to provide the feeding motion needed to navigate into confined environments and then perform a required configuration shape for further repair operation. This continuum robot is a compact system and presents a set of innovative mechatronic solutions such as: (i) two-stage tendon-driven structure with bevelled disk design to perform required configuration shape and to provide selective stiffness for the ability of taking high payloads; (ii) various compliant joints to enable different flexibility requirement in each stage; (iii) three commanding cables for each 2-DoF section to minimise the number of actuators with a precise actuation. To be able to achieve the desired configuration shape, a kinematic model has been established and the configuration-cable kinematics has been implemented. Finally, the continuum robot has been built and tested for performing the predefined configuration shape.
ER  - 

TY  - CONF
TI  - Reasoning Systems for Semantic Navigation in Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5654
EP  - 5659
AU  - J. Crespo
AU  - R. Barber
AU  - O. M. Mozos
AU  - D. BeBler
AU  - M. Beetz
PY  - 2018
KW  - control engineering computing
KW  - inference mechanisms
KW  - mobile robots
KW  - navigation
KW  - ontologies (artificial intelligence)
KW  - path planning
KW  - semantic navigation paradigm
KW  - mobile robot
KW  - environmental semantic concepts
KW  - ontological model
KW  - KnowRob
KW  - relational database
KW  - reasoning system
KW  - semantic representation
KW  - semantic navigation system
KW  - Navigation
KW  - Ontologies
KW  - Semantics
KW  - Cognition
KW  - Mobile robots
KW  - Relational databases
DO  - 10.1109/IROS.2018.8594271
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.
ER  - 

TY  - CONF
TI  - Hybrid Approach for Human Activity Recognition by Ubiquitous Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5660
EP  - 5665
AU  - R. Mojarad
AU  - F. Attal
AU  - A. Chibani
AU  - S. R. Fiorini
AU  - Y. Amirat
PY  - 2018
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - ontologies (artificial intelligence)
KW  - ubiquitous computing
KW  - human activity recognition
KW  - ubiquitous robots
KW  - context-aware intelligent services
KW  - humans
KW  - professional living activities
KW  - daily living activities
KW  - consistent description
KW  - correct description
KW  - human context
KW  - Ontologies
KW  - Activity recognition
KW  - Machine learning
KW  - Dairy products
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594173
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the main objectives of ubiquitous robots is to proactively provide context-aware intelligent services to assist humans in their professional or daily living activities. One of the main challenges is how to automatically obtain a consistent and correct description of human context such as location, activities, emotions, etc. In this paper, a new hybrid approach for reasoning on the context is proposed. This approach focuses on human activity recognition and consists of machine-learning algorithms, an expressive ontology representation, and a reasoning system. The latter allows detecting the inconsistencies that may appear during the machine learning phase. The proposed approach can also correct automatically these inconsistencies by considering the context of the ongoing activity. The obtained results on the Opportunity dataset demonstrate the feasibility of the proposed method to enhance the performance of human activity recognition.
ER  - 

TY  - CONF
TI  - Approaches for Action Sequence Representation in Robotics: A Review
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5666
EP  - 5671
AU  - H. Nakawala
AU  - P. J. S. Goncalves
AU  - P. Fiorini
AU  - G. Ferringo
AU  - E. D. Momi
PY  - 2018
KW  - reviews
KW  - robots
KW  - robotics
KW  - action sequences representation
KW  - robots
KW  - action sequence representation
KW  - complex robotic tasks
KW  - robot task
KW  - Task analysis
KW  - Planning
KW  - Calculus
KW  - Strips
KW  - Service robots
KW  - Proposals
DO  - 10.1109/IROS.2018.8594256
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust representation of actions and its sequences for complex robotic tasks would transform robot's understanding to execute robotic tasks efficiently. The challenge is to understand action sequences for highly unstructured environments and to represent and construct action and action sequences. In this manuscript, we present a review of literature dealing with representation of action and action sequences for robot task planning and execution. The methodological review was conducted using Google Scholar and IEEE Xplore, searching the specific keywords. This manuscript gives an overview of current approaches for representing action sequences in robotics. We propose a classification of different methodologies used for action sequences representation and describe the most important aspects of the reviewed publications. This review allows the reader to understand several options that do exist in the research community, to represent and deploy such action representations in real robots.
ER  - 

TY  - CONF
TI  - Ontology-Based Knowledge Representation for Increased Skill Reusability in Industrial Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5672
EP  - 5678
AU  - E. A. Topp
AU  - M. Stenmark
AU  - A. Ganslandt
AU  - A. Svensson
AU  - M. Haage
AU  - J. Malec
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - ontologies (artificial intelligence)
KW  - production engineering computing
KW  - robot programming
KW  - ontology-based knowledge representation
KW  - dual-arm robotic system
KW  - industrial applications
KW  - end-user programming
KW  - robot arms
KW  - intuitive programming
KW  - task transfer
KW  - kinematics
KW  - robot-agnostic skills
KW  - industrial robots skill reusability
KW  - Robot kinematics
KW  - Synchronization
KW  - Service robots
KW  - Ontologies
KW  - Manipulators
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593566
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We assume that an intuitive means for the specification, re-use, modification and transfer of synchronized motions-both regarding the two arms of a dual-arm robotic system, as well as regarding the coordination of a user and a robot-is key in interactive and collaborative settings as they are currently targeted for industrial applications. We show, how our knowledge based approach to end-user programming of synchronized motions and other generalizable, robot-agnostic skills can support such specification of coordinated actions between two robot arms and explain how that could be extended to include coordination with a human user. We describe the underlying ontologies and possibilities to populate those with an interface for intuitive programming, and show the generality of our approach through a task transfer between different kinematics (different robots), where the user is supported through underlying reasoning about the fulfillment of certain parameters or constraints for the involved skills.
ER  - 

TY  - CONF
TI  - Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5679
EP  - 5684
AU  - F. Ramos
AU  - C. O. Scrob
AU  - A. S. Vázquez
AU  - R. Fernández
AU  - A. Olivares-Alarcos
PY  - 2018
KW  - control engineering computing
KW  - ontologies (artificial intelligence)
KW  - robots
KW  - ontology
KW  - robotic skills
KW  - structural part
KW  - base configuration
KW  - abstract structure
KW  - modular robotic platform
KW  - skill-oriented designer
KW  - conceptual robotic structures
KW  - Robot sensing systems
KW  - Ontologies
KW  - Legged locomotion
KW  - Semantics
KW  - Taxonomy
KW  - Morphology
DO  - 10.1109/IROS.2018.8593856
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.
ER  - 

TY  - CONF
TI  - Integration of a Canine Agent in a Wireless Sensor Network for Information Gathering in Search and Rescue Missions*This work was partially funded by the Spanish project DPI2015-65186-R. The publication has received support from Universidad de Málaga Campus de Excelencia Andalucía Tech.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5685
EP  - 5690
AU  - J. J. Fernández-Lozano
AU  - A. Mandow
AU  - M. Martín-Guzmán
AU  - J. Martín-Ávila
AU  - J. Serón
AU  - J. L. Martínez
AU  - J. A. Gornez-Ruiz
AU  - C. Socarras-Bertiz
AU  - J. Miranda-Páez
AU  - A. García-Cerezo
PY  - 2018
KW  - disasters
KW  - emergency management
KW  - emergency services
KW  - multi-agent systems
KW  - rescue robots
KW  - wireless sensor networks
KW  - search and rescue missions
KW  - wireless sensor networks
KW  - robots
KW  - mobile node
KW  - heterogeneous agents
KW  - multiagent team
KW  - natural disasters
KW  - human disasters
KW  - emergency response
KW  - information gathering
KW  - wireless sensor network
KW  - canine agent
KW  - Dogs
KW  - Wireless sensor networks
KW  - Receivers
KW  - Mobile nodes
KW  - Transmitters
KW  - Databases
DO  - 10.1109/IROS.2018.8593849
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Search and rescue operations in the context of emergency response to human or natural disasters have the major goal of finding potential victims in the shortest possible time. Multi-agent teams, which can include specialized human respondents, robots and canine units, complement the strengths and weaknesses of each agent, like all-terrain mobility or capability to locate human beings. However, efficient coordination of heterogeneous agents requires specific means to locate the agents, and to provide them with the information they require to complete their mission. The major contribution of this work is an application of Wireless Sensor Networks (WSN) to gather information from a multi-agent team and to make it available to the rest of the agents while keeping coverage. In particular, a canine agent has been equipped with a mobile node installed on a harness, providing information about the dog's location as well as gas levels. The configuration of the mobile node allows for flexible arrangement of the system, being able to integrate static as well as mobile nodes. The gathered information is available at an external database, so that the rest of the agents and the control center can use it in real time. The proposed scheme has been tested in realistic scenarios during search and rescue exercises.
ER  - 

TY  - CONF
TI  - Any-Time Trajectory Planning for Safe Emergency Landing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5691
EP  - 5696
AU  - P. Váňa
AU  - J. Sláma
AU  - J. Faigl
AU  - P. Pačes
PY  - 2018
KW  - aerospace components
KW  - aerospace engineering
KW  - aircraft control
KW  - aircraft landing guidance
KW  - path planning
KW  - trajectory control
KW  - landing site selection
KW  - safest emergency landing trajectory
KW  - multiple landing sites
KW  - any-time property
KW  - time trajectory planning
KW  - safe emergency landing
KW  - critical situation
KW  - human pilots
KW  - landing trajectories
KW  - aircraft
KW  - Trajectory
KW  - Aircraft
KW  - Planning
KW  - Turning
KW  - Drag
KW  - Atmospheric modeling
KW  - Force
DO  - 10.1109/IROS.2018.8594225
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Loss of thrust is a critical situation for human pilots of fixed-wing aircraft which force them to select a landing site in the nearby range and perform an emergency landing. The time for the landing site selection is limited by the actual altitude of the aircraft, and it may be fatal if the correct decision is not chosen fast enough. Therefore, we propose a novel RRT* -based planning algorithm for finding the safest emergency landing trajectory towards a given set of possible landing sites. Multiple landing sites are evaluated simultaneously during the flight even before any mechanical issue occurs, and the roadmap of possible landing trajectories is updated permanently. Thus, the proposed algorithm has the any-time property and provides the best emergency landing trajectory almost instantly.
ER  - 

TY  - CONF
TI  - PiDrone: An Autonomous Educational Drone Using Raspberry Pi and Python
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - I. Brand
AU  - J. Roy
AU  - A. Ray
AU  - J. Oberlin
AU  - S. Oberlix
PY  - 2018
KW  - aerospace robotics
KW  - cameras
KW  - computer aided instruction
KW  - control engineering education
KW  - educational courses
KW  - mobile robots
KW  - Python
KW  - remotely operated vehicles
KW  - robot programming
KW  - robot vision
KW  - state estimation
KW  - three-term control
KW  - high-level planning
KW  - PiDrone
KW  - autonomous educational drone
KW  - Python
KW  - compelling robotics course
KW  - low-cost aerial educational platform
KW  - associated college-level introductory robotics course
KW  - autonomous aircraft
KW  - downward facing RGB camera
KW  - distance sensor
KW  - onboard Raspberry Pi
KW  - accessible platform
KW  - inexpensive platform
KW  - SSH capable computer
KW  - base station
KW  - programming platform
KW  - robotics operating system framework
KW  - ROS framework
KW  - PID control
KW  - state estimation
KW  - Drones
KW  - Educational robots
KW  - Robot sensing systems
KW  - Python
KW  - Service robots
KW  - Hardware
DO  - 10.1109/IROS.2018.8593943
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A compelling robotics course begins with a compelling robot. We introduce a new low-cost aerial educational platform, the PiDrone, along with an associated college-level introductory robotics course. In a series of projects, students incrementally build, program, and test their own drones to create an autonomous aircraft capable of using a downward facing RGB camera and infrared distance sensor to visually localize and maintain position. The PiDrone runs Python and the Robotics Operating System (ROS) framework on an onboard Raspberry Pi, providing an accessible and inexpensive platform for introducing students to robotics. Students can use any web and SSH capable computer as a base station and programming platform. The projects and supplementary homeworks introduce PID control, state estimation, and high-level planning, giving students the opportunity to exercise their new skills in an exciting long-term project.
ER  - 

TY  - CONF
TI  - State Estimate Recovery for Autonomous Quadcopters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - L. Beffa
AU  - A. Ledergerber
AU  - R. D'Andrea
PY  - 2018
KW  - acceleration measurement
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - channel bank filters
KW  - helicopters
KW  - Kalman filters
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - state estimate recovery
KW  - autonomous quadcopters
KW  - aerodynamic force model
KW  - extended Kalman filters
KW  - linear acceleration measurements
KW  - complete recovery logic
KW  - quadcopter platform
KW  - IMU
KW  - Aerodynamics
KW  - Gravity
KW  - Mathematical model
KW  - Accelerometers
KW  - Propellers
KW  - Data models
KW  - Position measurement
DO  - 10.1109/IROS.2018.8594332
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A method for recovery from the complete loss of the state estimate is presented for autonomous quadcopters. Given an aerodynamic force model, the only measurements used to reinitialize the state estimate by means of a bank of extended Kalman filters are the angular rate and linear acceleration measurements of an IMU. The method is integrated within a complete recovery logic on a quadcopter platform and experimentally evaluated.
ER  - 

TY  - CONF
TI  - A Revisited Approach to Lateral Acceleration Modeling for Quadrotor UAVs State Estimation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5711
EP  - 5718
AU  - D. Sartori
AU  - D. Zou
AU  - L. Pei
AU  - W. Yu
PY  - 2018
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - blades
KW  - drag
KW  - helicopters
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - lateral acceleration modeling
KW  - quadrotor UAVs state estimation
KW  - rotors angular speeds
KW  - quadrotor drag
KW  - lateral accelerations
KW  - flight test data
KW  - attitude state estimator
KW  - EKF-based estimator
KW  - velocity state estimator
KW  - vehicle aerodynamics modeling
KW  - blade element theory
KW  - Rotors
KW  - Blades
KW  - Acceleration
KW  - Optical sensors
KW  - Data models
KW  - Atmospheric modeling
KW  - Aerodynamics
DO  - 10.1109/IROS.2018.8593600
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quadrotor state estimation generally relies on the vehicle aerodynamics modeling to achieve improved performance. In this paper the effects of the rotors angular speeds on the quadrotor drag, and therefore on the lateral accelerations, are investigated. While these effects are usually disregarded, we analyze their modeling starting from the Blade Element Theory and flight test data. Two lateral acceleration formulations are proposed. They are adopted within a velocity and attitude state estimator and validated in real-world flights. The EKF-based estimator fuses measurements from low-cost sensors present in the majority of quadrotors (IMU, magnetometer, ultrasonic sensor, optical flow) with the accelerations of the vehicle predicted from the revisited models. Experimental results show the benefits of adopting these innovative models in the estimator when compared with the existing modeling approach.
ER  - 

TY  - CONF
TI  - Assisted Control for Semi-Autonomous Power Infrastructure Inspection Using Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5719
EP  - 5726
AU  - A. McFadyen
AU  - F. Dayoub
AU  - S. Martin
AU  - J. Ford
AU  - P. Corke
PY  - 2018
KW  - aerospace robotics
KW  - collision avoidance
KW  - inspection
KW  - optical sensors
KW  - power overhead lines
KW  - sensor placement
KW  - collision avoidance
KW  - optical sensors
KW  - sensor placement
KW  - fixed energy infrastructure
KW  - aerial inspection
KW  - multirotor platform
KW  - assisted control technology
KW  - aerial vehicles
KW  - semiautonomous power infrastructure inspection
KW  - proximity inspection tasks
KW  - assisted control approach
KW  - Inspection
KW  - Wires
KW  - Measurement
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Unmanned aerial vehicles
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593529
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.
ER  - 

TY  - CONF
TI  - Bidirectional Thrust for Multirotor MAVs with Fixed-Pitch Propellers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Maier
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - helicopters
KW  - propellers
KW  - fixed-pitch propellers
KW  - multirotor MicroAerial Vehicles
KW  - bidirectional thrust vector
KW  - dedicated motor controllers
KW  - controller design
KW  - control allocation approach
KW  - static thrust test
KW  - inverted flight
KW  - multirotor MAV
KW  - unidirectional thrust vehicles
KW  - Propellers
KW  - Rotors
KW  - Torque
KW  - Resource management
KW  - Force
KW  - Attitude control
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593836
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper is devoted to the study of multirotor Micro Aerial Vehicles (MAVs) with fixed-pitch propellers and bidirectional thrust vector. The latter is realized by using dedicated motor controllers, which allow to invert the propellers' direction of rotation during flight (so-called 3D mode), and almost or fully symmetric propellers. We present a unified modeling, controller design, and control allocation approach that accounts for bidirectional thrust. Suitable propellers with the ability to produce thrust and torque in both directions are compared and their parameters are identified through a static thrust test. Furthermore, we discuss applications of bidirectional thrust, like inverted flight or surface slip reduction, which are impossible to realize with common unidirectional thrust vehicles. We generate suitable flight trajectories and evaluate our unified approach in experiments with a custom-built quadrotor.
ER  - 

TY  - CONF
TI  - DREGON: Dataset and Methods for UAV-Embedded Sound Source Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - M. Strauss
AU  - P. Mordel
AU  - V. Miguet
AU  - A. Deleforge
PY  - 2018
KW  - acoustic noise
KW  - acoustic signal processing
KW  - aerospace computing
KW  - audio signal processing
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - microphone arrays
KW  - broad-band source localization
KW  - microphone array
KW  - noisy in-flight audio recordings
KW  - 3D position
KW  - rotor rotational speed
KW  - loud noise conditions
KW  - extreme noise levels
KW  - accurate motion capture system
KW  - target sound source
KW  - UAV-embedded sound source localization
KW  - DREGON
KW  - Microphone arrays
KW  - Propellers
KW  - Drones
KW  - Robots
KW  - White noise
DO  - 10.1109/IROS.2018.8593581
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces DREGON, a novel publicly-available dataset that aims at pushing research in sound source localization using a microphone array embedded in an unmanned aerial vehicle (UAV). The dataset contains both clean and noisy in-flight audio recordings continuously annotated with the 3D position of the target sound source using an accurate motion capture system. In addition, various signals of interests are available such as the rotational speed of individual rotors and inertial measurements at all time. Besides introducing the dataset, this paper sheds light on the specific properties, challenges and opportunities brought by the emerging task of UAV-embedded sound source localization. Several baseline methods are evaluated and compared on the dataset, with real-time applicability in mind. Very promising results are obtained for the localization of a broad-band source in loud noise conditions, while speech localization remains a challenge under extreme noise levels.
ER  - 

TY  - CONF
TI  - Incremental Semi-Supervised Learning from Streams for Object Classification
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5743
EP  - 5749
AU  - I. Chiotellis
AU  - F. Zimmermann
AU  - D. Cremers
AU  - R. Triebel
PY  - 2018
KW  - graph theory
KW  - image classification
KW  - nearest neighbour methods
KW  - supervised learning
KW  - object classification
KW  - Zhu
KW  - transductive learning scenarios
KW  - LP algorithm
KW  - data samples
KW  - autonomous driving
KW  - nearest-neighbor graph
KW  - labeled nodes
KW  - unlabeled nodes
KW  - harmonic solution
KW  - KITTI benchmark data stream
KW  - label propagation algorithm
KW  - Ghahramani
KW  - formal convergence
KW  - incremental semisupervised learning
KW  - Harmonic analysis
KW  - Convergence
KW  - Approximation algorithms
KW  - Semisupervised learning
KW  - Benchmark testing
KW  - Training data
KW  - Clustering algorithms
DO  - 10.1109/IROS.2018.8593901
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The Label Propagation (LP) algorithm, first introduced by Zhu and Ghahramani [1], is a semi-supervised method used in transductive learning scenarios, where all data are available already in the beginning. In this work, we present a novel extension of the LP algorithm for applications where data samples are observed sequentially - as is the case in autonomous driving. Specifically, our “Incremental Label Propagation” algorithm efficiently approximates the so called harmonic solution on a nearest-neighbor graph that is regularly updated by new labeled and unlabeled nodes. We achieve this by reformulating the original algorithm based on an active set of nodes and by introducing a threshold to decide whether the label of a given node should be updated or not. Our method can also deal with graphs that are not fully connected, and we give a formal convergence proof for this general case. In experiments on the challenging KITTI benchmark data stream, we show superior performance in terms of both test accuracy and number of required training labels compared to state-of-the-art online learning methods.
ER  - 

TY  - CONF
TI  - Joint 3D Proposal Generation and Object Detection from View Aggregation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - J. Ku
AU  - M. Mozifian
AU  - J. Lee
AU  - A. Harakeh
AU  - S. L. Waslander
PY  - 2018
KW  - image classification
KW  - image colour analysis
KW  - image fusion
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - radar detection
KW  - regression analysis
KW  - road vehicle radar
KW  - robot vision
KW  - high resolution feature maps
KW  - reliable 3D object proposals
KW  - multiple object classes
KW  - category classification
KW  - second stage detection network
KW  - AVOD
KW  - KITTI 3D object detection
KW  - autonomous vehicles
KW  - 3D bounding box regression
KW  - multimodal feature fusion
KW  - RPN
KW  - region proposal network
KW  - RGB images
KW  - LIDAR point clouds
KW  - neural network architecture
KW  - autonomous driving scenarios
KW  - Aggregate View Object Detection network
KW  - joint 3D proposal generation
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Proposals
KW  - Computer architecture
KW  - Agriculture
KW  - Object detection
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594049
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present AVOD, an Aggregate View Object Detection network for autonomous driving scenarios. The proposed neural network architecture uses LIDAR point clouds and RGB images to generate features that are shared by two subnetworks: a region proposal network (RPN) and a second stage detector network. The proposed RPN uses a novel architecture capable of performing multimodal feature fusion on high resolution feature maps to generate reliable 3D object proposals for multiple object classes in road scenes. Using these proposals, the second stage detection network performs accurate oriented 3D bounding box regression and category classification to predict the extents, orientation, and classification of objects in 3D space. Our proposed architecture is shown to produce state of the art results on the KITTI 3D object detection benchmark [1] while running in real time with a low memory footprint, making it a suitable candidate for deployment on autonomous vehicles. Code is available at: https://github.com/kujason/avod.
ER  - 

TY  - CONF
TI  - TSSD: Temporal Single-Shot Detector Based on Attention and LSTM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - X. Chen
AU  - Z. Wu
AU  - J. Yu
PY  - 2018
KW  - feature extraction
KW  - object detection
KW  - robot vision
KW  - video signal processing
KW  - convolutional long short-term memory
KW  - creative temporal analysis unit
KW  - multiscale feature maps
KW  - high-level ConvLSTM unit
KW  - pyramidal feature hierarchy
KW  - attention mechanism
KW  - real-time online approaches
KW  - video detection task
KW  - robotic vision
KW  - rich temporal information
KW  - temporal object detection
KW  - temporal single-shot detector
KW  - developed TSSD
KW  - attention-aware features
KW  - scale suppression
KW  - background suppression
KW  - ConvLSTM-based attention
KW  - attention-based ConvLSTM
KW  - Feature extraction
KW  - Detectors
KW  - Robots
KW  - Task analysis
KW  - Visualization
KW  - Lenses
KW  - Proposals
DO  - 10.1109/IROS.2018.8593963
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Temporal object detection has attracted significant attention, but most popular methods can not leverage the rich temporal information in video or robotic vision. Although many different algorithms have been developed for video detection task, real-time online approaches are frequently deficient. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)for robotic vision. Distinct from previous methods, we aim to temporally integrate pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a high-level ConvLSTM unit as well as a low-level one (HL-LSTM)for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, ConvLSTM-based attention and attention-based ConvLSTM (A&CL), in which the ConvLSTM-based attention is specially tailored for background suppression and scale suppression while the attention-based ConvLSTM temporally integrates attention-aware features. Finally, our method is evaluated on ImageNet VID dataset. Extensive comparisons on detection performance confirm the superiority of the proposed approach, and the developed TSSD achieves a considerably enhanced accuracy vs. speed trade-off, i.e., 64.8% mAP vs. 27 FPS.
ER  - 

TY  - CONF
TI  - Real-Time Clustering and Multi-Target Tracking Using Event-Based Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5764
EP  - 5769
AU  - F. Barranco
AU  - C. Fermuller
AU  - E. Ros
PY  - 2018
KW  - computer vision
KW  - image segmentation
KW  - image sensors
KW  - Kalman filters
KW  - object detection
KW  - pattern clustering
KW  - target tracking
KW  - event-based sensors
KW  - computer vision applications
KW  - robust tracking
KW  - object detection
KW  - segmentation
KW  - real-time clustering technique
KW  - event-based vision sensors
KW  - mean-shift clustering method
KW  - asynchronous events
KW  - multitarget tracking application
KW  - clustering accuracy
KW  - frame-based method
KW  - Sensors
KW  - Shape
KW  - Real-time systems
KW  - Kalman filters
KW  - Target tracking
KW  - Robots
DO  - 10.1109/IROS.2018.8593380
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Clustering is crucial for many computer vision applications such as robust tracking, object detection and segmentation. This work presents a real-time clustering technique that takes advantage of the unique properties of event-based vision sensors. Since event-based sensors trigger events only when the intensity changes, the data is sparse, with low redundancy. Thus, our approach redefines the well-known mean-shift clustering method using asynchronous events instead of conventional frames. The potential of our approach is demonstrated in a multi-target tracking application using Kalman filters to smooth the trajectories. We evaluated our method on an existing dataset with patterns of different shapes and speeds, and a new dataset that we collected. The sensor was attached to the Baxter robot in an eye-in-hand setup monitoring real-world objects in an action manipulation task. Clustering accuracy achieved an F-measure of 0.95, reducing the computational cost by 88% compared to the frame-based method. The average error for tracking was 2.5 pixels and the clustering achieved a consistent number of clusters along time.
ER  - 

TY  - CONF
TI  - Speeding-Up Object Detection Training for Robotics with FALKON
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5770
EP  - 5776
AU  - E. Maiettini
AU  - G. Pasquale
AU  - L. Rosasco
AU  - L. Natale
PY  - 2018
KW  - computer vision
KW  - data mining
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robots
KW  - sampling methods
KW  - stochastic processes
KW  - end-to-end learning
KW  - deep feature extractor
KW  - bootstrapping approach
KW  - object detection training
KW  - deep learning methods
KW  - robotic applications
KW  - back-propagation
KW  - region proposal network
KW  - hard negatives mining
KW  - FALKON algorithm
KW  - kernel-based method
KW  - stochastic subsampling
KW  - computer vision dataset
KW  - Training
KW  - Feature extraction
KW  - Pipelines
KW  - Object detection
KW  - Robots
KW  - Task analysis
KW  - Proposals
DO  - 10.1109/IROS.2018.8593990
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Latest deep learning methods for object detection provide remarkable performance, but have limits when used in robotic applications. One of the most relevant issues is the long training time, which is due to the large size and imbalance of the associated training sets, characterized by few positive and a large number of negative examples (i.e. background). Proposed approaches are based on end-to-end learning by back-propagation [22] or kernel methods trained with Hard Negatives Mining on top of deep features [8]. These solutions are effective, but prohibitively slow for on-line applications. In this paper we propose a novel pipeline for object detection that overcomes this problem and provides comparable performance, with a 60x training speedup. Our pipeline combines (i) the Region Proposal Network and the deep feature extractor from [22] to efficiently select candidate RoIs and encode them into powerful representations, with (ii) the FALKON [23] algorithm, a novel kernel-based method that allows fast training on large scale problems (millions of points). We address the size and imbalance of training data by exploiting the stochastic subsampling intrinsic into the method and a novel, fast, bootstrapping approach. We assess the effectiveness of the approach on a standard Computer Vision dataset (PASCAL VOC 2007 [5]) and demonstrate its applicability to a real robotic scenario with the iCubWorld Transformations [18] dataset.
ER  - 

TY  - CONF
TI  - Disparity Sliding Window: Object Proposals from Disparity Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5777
EP  - 5784
AU  - J. Müller
AU  - A. Fregin
AU  - K. Dietmayer
PY  - 2018
KW  - convolutional neural nets
KW  - image classification
KW  - object detection
KW  - object recognition
KW  - stereo image processing
KW  - object proposals
KW  - disparity images
KW  - object recognition tasks
KW  - deep neural networks
KW  - convolutional neural networks
KW  - sliding window technique
KW  - object candidates
KW  - object size
KW  - disparity sliding window approach
KW  - pedestrian detection
KW  - KITTI object detection benchmark
KW  - object detection
KW  - classifier
KW  - depth information
KW  - stereo camera
KW  - Microsoft Windows
KW  - Proposals
KW  - Computational efficiency
KW  - Task analysis
KW  - Cameras
KW  - Real-time systems
KW  - Image edge detection
DO  - 10.1109/IROS.2018.8593390
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sliding window approaches have been widely used for object recognition tasks in recent years [19], [4], [5], [18]. They guarantee an investigation of the entire input image for the object to be detected and allow a localization of that object. Despite the current trend towards deep neural networks, sliding window methods are still used in combination with convolutional neural networks [22]. The risk of overlooking an object is clearly reduced compared to alternative detection approaches which detect objects based on shape, edges or color. Nevertheless, the sliding window technique strongly increases the computational effort as the classifier has to verify a large number of object candidates. This paper proposes a sliding window approach which also uses depth information from a stereo camera. This leads to a greatly decreased number of object candidates without significantly reducing the detection accuracy. A theoretical investigation of the conventional sliding window approach is presented first. Other publications to date only mentioned rough estimations of the computational cost. A mathematical derivation clarifies the number of object candidates with respect to parameters such as image and object size. Subsequently, the proposed disparity sliding window approach is presented in detail. The approach is evaluated on pedestrian detection with annotations and images from the KITTI [10] object detection benchmark. Furthermore, a comparison with two state-of-the-art methods is made. Code is available in C++ and Python https://github.com/julimueller/disparity-sliding-window.
ER  - 

TY  - CONF
TI  - Semantic Segmentation from Sparse Labeling Using Multi-Level Superpixels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5785
EP  - 5792
AU  - I. Alonso
AU  - A. C. Murillo
PY  - 2018
KW  - image annotation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - image modalities
KW  - sparse labeling data
KW  - human interaction reduction
KW  - environment monitoring data
KW  - sparse annotation augmentation
KW  - dense ground-truth
KW  - label augmentation
KW  - adaptive superpixel segmentation propagation
KW  - dense semantic segmentation models
KW  - pixel level labeling
KW  - life applicability
KW  - common deep learning models
KW  - deep learning approaches
KW  - image pixel
KW  - multilevel superpixels
KW  - effective learning
KW  - Image segmentation
KW  - Semantics
KW  - Labeling
KW  - Training
KW  - Biological system modeling
KW  - Monitoring
KW  - Deep learning
DO  - 10.1109/IROS.2018.8594185
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Semantic segmentation is a challenging problem that can benefit numerous robotics applications, since it provides information about the content at every image pixel. Solutions to this problem have recently witnessed a boost on performance and results thanks to deep learning approaches. Unfortunately, common deep learning models for semantic segmentation present several challenges which hinder real life applicability in many domains. A significant challenge is the need of pixel level labeling on large amounts of training images to be able to train those models, which implies a very high cost. This work proposes and validates a simple but effective approach to train dense semantic segmentation models from sparsely labeled data. Labeling only a few pixels per image reduces the human interaction required. We find many available datasets, e.g., environment monitoring data, that provide this kind of sparse labeling. Our approach is based on augmenting the sparse annotation to a dense one with the proposed adaptive superpixel segmentation propagation. We show that this label augmentation enables effective learning of state-of-the-art segmentation models, getting similar results to those models trained with dense ground-truth. We demonstrate the applicability of the presented approach to different image modalities in real domains (underwater, aerial and urban scenarios) with publicly available datasets.
ER  - 

TY  - CONF
TI  - Real-Time Segmentation with Appearance, Motion and Geometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5793
EP  - 5800
AU  - M. Siam
AU  - S. Eikerdawy
AU  - M. Gamal
AU  - M. Abdel-Razek
AU  - M. Jagersand
AU  - H. Zhang
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - distance measurement
KW  - Global Positioning System
KW  - image motion analysis
KW  - image segmentation
KW  - mobile robots
KW  - motion estimation
KW  - object detection
KW  - remotely operated vehicles
KW  - robot vision
KW  - domain knowledge
KW  - planar scenes
KW  - high altitude unmanned aerial vehicles
KW  - homography compensated flow
KW  - urban scenes
KW  - autonomous driving
KW  - depth estimates
KW  - segmentation accuracy
KW  - geometric priors
KW  - UAV imagery
KW  - baseline network
KW  - sparse depth
KW  - motion segmentation solution
KW  - assisted systems
KW  - traffic monitoring
KW  - unmanned aerial vehicles imagery
KW  - two-stream convolutional network
KW  - geometric cues
KW  - computational efficiency trade-offs
KW  - real-time segmentation
KW  - GPS-IMU sensory data
KW  - KITTI-MoSeg
KW  - Motion segmentation
KW  - Computer vision
KW  - Real-time systems
KW  - Convolutional codes
KW  - Autonomous vehicles
KW  - Unmanned aerial vehicles
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594088
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Real-time Segmentation is of crucial importance to robotics related applications such as autonomous driving, driving assisted systems, and traffic monitoring from unmanned aerial vehicles imagery. We propose a novel two-stream convolutional network for motion segmentation, which exploits flow and geometric cues to balance the accuracy and computational efficiency trade-offs. The geometric cues take advantage of the domain knowledge of the application. In case of mostly planar scenes from high altitude unmanned aerial vehicles (UAVs), homography compensated flow is used. While in the case of urban scenes in autonomous driving, with GPS/IMU sensory data available, sparse projected depth estimates and odometry information are used. The network provides 4.7× speedup over the state of the art networks in motion segmentation from 153ms to 36ms, at the expense of a reduction in the segmentation accuracy in terms of pixel boundaries. This enables the network to perform real-time on a Jetson T×2. In order to recuperate some of the accuracy loss, geometric priors is used while still achieving a much improved computational efficiency with respect to the state-of-the-art. The usage of geometric priors improved the segmentation in UAV imagery by 5.2 % using the metric of IoU over the baseline network. While on KITTI-MoSeg the sparse depth estimates improved the segmentation by 12.5 % over the baseline. Our proposed motion segmentation solution is verified on the popular KITTI and VIVID datasets, with additional labels we have produced. The code for our work is publicly available at1.
ER  - 

TY  - CONF
TI  - VarNet: Exploring Variations for Unsupervised Video Prediction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5801
EP  - 5806
AU  - B. Jin
AU  - Y. Hu
AU  - Y. Zeng
AU  - Q. Tang
AU  - S. Liu
AU  - J. Ye
PY  - 2018
KW  - image motion analysis
KW  - image sequences
KW  - object detection
KW  - video signal processing
KW  - VarNet
KW  - video frame prediction
KW  - inter-frame variations
KW  - adjacent frames
KW  - long-term video prediction
KW  - KITTI dataset
KW  - unsupervised video prediction framework-variation network
KW  - PSNR
KW  - SSIM
KW  - KTH
KW  - Generators
KW  - Training
KW  - Predictive models
KW  - Decoding
KW  - Video sequences
KW  - Neural networks
KW  - Generative adversarial networks
DO  - 10.1109/IROS.2018.8594264
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised video prediction is a very challenging task due to the complexity and diversity in natural scenes. Prior works directly predicting pixels or optical flows either have the blurring problem or require additional assumptions. We highlight that the crux for video frame prediction lies in precisely capturing the inter-frame variations which encompass the movement of objects and the evolution of the surrounding environment. We then present an unsupervised video prediction framework - Variation Network (VarNet) to directly predict the variations between adjacent frames which are then fused with current frame to generate the future frame. In addition, we propose an adaptively re-weighting mechanism for loss function to offer each pixel a fair weight according to the amplitude of its variation. Extensive experiments for both short-term and long-term video prediction are implemented on two advanced datasets - KTH and KITTI with two evaluating metrics - PSNR and SSIM. For the KTH dataset, the VarNet outperforms the state-of-the-art works up to 11.9% on PSNR and 9.5% on SSIM. As for the KITTI dataset, the performance boosts are up to 55.1% on PSNR and 15.9% on SSIM. Moreover, we verify that the generalization ability of our model excels other state-of-the-art methods by testing on the unseen CalTech Pedestrian dataset after being trained on the KITTI dataset. Source code and video are available at https://github.com/jinbeibei/VarNet.
ER  - 

TY  - CONF
TI  - Obstacle Detection for USVs by Joint Stereo-View Semantic Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5807
EP  - 5812
AU  - B. Bovcon
AU  - M. Kristan
PY  - 2018
KW  - cameras
KW  - collision avoidance
KW  - control engineering computing
KW  - convolutional neural nets
KW  - edge detection
KW  - image segmentation
KW  - mobile robots
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - water edge
KW  - stereo extensions
KW  - joint stereo-view semantic segmentation
KW  - unmanned surface vehicles
KW  - scene semantic segmentation problem
KW  - single-view model
KW  - consistent class labels assignment
KW  - monocular CNN
KW  - class-label posterior map
KW  - stereo-based obstacle detection
KW  - Semantics
KW  - Image segmentation
KW  - Cameras
KW  - Image edge detection
KW  - Sea surface
KW  - Graphical models
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594238
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a stereo-based obstacle detection approach for unmanned surface vehicles. Obstacle detection is cast as a scene semantic segmentation problem in which pixels are assigned a probability of belonging to water or non-water regions. We extend a single-view model to a stereo system by adding a constraint which prefers consistent class labels assignment to pixels in the left and right camera images corresponding to the same parts of a 3D scene. Our approach jointly fits a semantic model to both images, leading to an improved class-label posterior map from which obstacles and water edge are extracted. In overall F-measure, our approach outperforms the current state-of-the-art monocular approach by 0.495, a monocular CNN by 0.798 and their stereo extensions by 0.059 and 0.515, respectively on the task of obstacle detection while running real-time on a single CPU.
ER  - 

TY  - CONF
TI  - Efficient Absolute Orientation Revisited
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5813
EP  - 5818
AU  - M. Lourakis
AU  - G. Terzakis
PY  - 2018
KW  - attitude measurement
KW  - computer vision
KW  - matrix decomposition
KW  - optimisation
KW  - singular value decomposition
KW  - fast optimal attitude matrix algorithm
KW  - optimal linear attitude estimator method
KW  - 3D point sets
KW  - OLAE method
KW  - computer vision
KW  - similarity transformation
KW  - absolute orientation estimation
KW  - attitude estimation techniques
KW  - FOAM-based solution
KW  - singular-value matrix decompositions
KW  - absolute orientation algorithm
KW  - robotics
KW  - Quaternions
KW  - Estimation
KW  - Symmetric matrices
KW  - Eigenvalues and eigenfunctions
KW  - Matrix decomposition
KW  - Covariance matrices
KW  - Computer vision
DO  - 10.1109/IROS.2018.8594296
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding 3D points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigenand singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.
ER  - 

TY  - CONF
TI  - Active Structure-from-Motion for 3d Straight Lines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5819
EP  - 5825
AU  - A. Mateus
AU  - O. Tahri
AU  - P. Miraldo
PY  - 2018
KW  - mobile robots
KW  - observability
KW  - robot vision
KW  - visual servoing
KW  - Active Structure-from-Motion
KW  - planning
KW  - Image-Based Visual Servoing
KW  - control scheme
KW  - straight lines
KW  - control law
KW  - control effort
KW  - 3D straight lines
KW  - convergence rate
KW  - 3D parameter estimation
KW  - Three-dimensional displays
KW  - Cameras
KW  - Convergence
KW  - Eigenvalues and eigenfunctions
KW  - Robots
KW  - Observers
DO  - 10.1109/IROS.2018.8593793
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A reliable estimation of 3D parameters is a must for several applications like planning and control, in which is included Image-Based Visual Servoing. This control scheme depends directly on 3D parameters, e.g. depth of points, and/or depth and direction of 3D straight lines. Recently, a framework for Active Structure-from-Motion was proposed, addressing the former feature type. However, straight lines were not addressed. These are 1D objects, which allow for more robust detection, and tracking. In this work, the problem of Active Structure-from-Motion for 3D straight lines is addressed. An explicit representation of these features is presented, and a change of variables is proposed. The latter allows the dynamics of the line to respect the conditions for observability of the framework. A control law is used with the purpose of keeping the control effort reasonable, while achieving a desired convergence rate. The approach is validated first in simulation for a single line, and second using a real robot setup. The latter set of experiments are conducted first for a single line, and then for three lines.
ER  - 

TY  - CONF
TI  - Stereo Camera Localization in 3D LiDAR Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Kim
AU  - J. Jeong
AU  - A. Kim
PY  - 2018
KW  - cameras
KW  - Global Positioning System
KW  - image matching
KW  - image reconstruction
KW  - mobile robots
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - stereo disparity map
KW  - average localization error
KW  - stereo camera localization
KW  - Global Positioning System
KW  - 3D LiDAR maps
KW  - simultaneous localization and mapping techniques
KW  - SLAM techniques
KW  - 3D light detection and ranging sensors
KW  - visual positioning algorithm
KW  - GPS signal
KW  - visual tracking
KW  - six degree of freedom
KW  - DOF
KW  - camera pose estimation
KW  - KITTI dataset
KW  - Cameras
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Global Positioning System
DO  - 10.1109/IROS.2018.8594362
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As simultaneous localization and mapping (SLAM) techniques have flourished with the advent of 3D Light Detection and Ranging (LiDAR) sensors, accurate 3D maps are readily available. Many researchers turn their attention to localization in a previously acquired 3D map. In this paper, we propose a novel and lightweight camera-only visual positioning algorithm that involves localization within prior 3D LiDAR maps. We aim to achieve the consumer level global positioning system (GPS) accuracy using vision within the urban environment, where GPS signal is unreliable. Via exploiting a stereo camera, depth from the stereo disparity map is matched with 3D LiDAR maps. A full six degree of freedom (DOF) camera pose is estimated via minimizing depth residual. Powered by visual tracking that provides a good initial guess for the localization, the proposed depth residual is successfully applied for camera pose estimation. Our method runs online, as the average localization error is comparable to ones resulting from state-of-the-art approaches. We validate the proposed method as a stand-alone localizer using KITTI dataset and as a module in the SLAM framework using our own dataset.
ER  - 

TY  - CONF
TI  - Vision-Based Terrain Classification and Solar Irradiance Mapping for Solar-Powered Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5834
EP  - 5840
AU  - N. Kingry
AU  - M. Jung
AU  - E. Derse
AU  - R. Dai
PY  - 2018
KW  - cameras
KW  - energy harvesting
KW  - feature extraction
KW  - Haar transforms
KW  - image classification
KW  - image colour analysis
KW  - image texture
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - solar power
KW  - terrain mapping
KW  - wavelet transforms
KW  - outdoor mobile robots
KW  - feature extraction
KW  - visual-spectrum images
KW  - on-board camera
KW  - Haar wavelet transform
KW  - color information
KW  - textural information
KW  - ANN
KW  - high dynamic range imagery
KW  - energy consumption
KW  - traversability criteria
KW  - energy harvesting capabilities
KW  - vision-based artificial neural network
KW  - sequential methodology
KW  - solar irradiance map
KW  - terrain classes
KW  - solar-powered mobile robots
KW  - real-time terrain classification
KW  - solar irradiance mapping
KW  - vision-based terrain classification
KW  - Image color analysis
KW  - Feature extraction
KW  - Neural networks
KW  - Training
KW  - Image segmentation
KW  - Wavelet transforms
KW  - Sensors
KW  - Field Robotics
KW  - Image Processing
KW  - Solar Mapping
KW  - Terrain Classification
KW  - Solar Robotics
DO  - 10.1109/IROS.2018.8593635
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper examines techniques for real-time terrain classification and solar irradiance mapping for outdoor, solar-powered mobile robots using a vision-based Artificial Neural Network (ANN). This process is completed sequentially. First, terrain classification is completed by extracting key features from visual-spectrum images captured from an on-board camera using Haar wavelet transform to identify both color and textural information. These features are then classified using an ANN to identify grass, concrete, asphalt, gravel, and mulch. Using the terrain classes, the image is then analyzed using concepts from high dynamic range imagery to establish the solar irradiance map of the area. In this way, our sequential methodology presented allows unmanned vehicles to classify the terrain and map the irradiance of a given area with no prior knowledge. Whereas, the terrain classification can be used in determining energy consumption or traversability criteria and the irradiance map can be used to estimate the energy harvesting capabilities.
ER  - 

TY  - CONF
TI  - Structured Skip List: A Compact Data Structure for 3D Reconstruction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - S. Li
AU  - M. Cheng
AU  - Y. Liu
AU  - S. Lu
AU  - Y. Wang
AU  - V. Adrian Prisacariu
PY  - 2018
KW  - data reduction
KW  - data structures
KW  - image reconstruction
KW  - data management methods
KW  - Structured Skip List
KW  - Structured Skip List
KW  - high storage efficiency
KW  - storage efficiency analysis
KW  - hash allocation list
KW  - voxel allocation
KW  - data collision
KW  - storage space
KW  - structured information
KW  - semiordered method
KW  - SSL
KW  - real-time indoor 3D reconstruction
KW  - data management method
KW  - store nonempty voxels
KW  - massive index data
KW  - low storage efficiency
KW  - data order
KW  - unordered methods
KW  - ordered methods
KW  - 3D reconstruction algorithm
KW  - compact data structure
KW  - Three-dimensional displays
KW  - Indexes
KW  - Data structures
KW  - Image reconstruction
KW  - Resource management
KW  - Solid modeling
KW  - Pipelines
DO  - 10.1109/IROS.2018.8594075
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The model produced by 3D reconstruction algorithm is usually represented by voxels. The management of these voxels is usually divided into two categories: ordered and unordered methods. The ordered method holds too many empty voxels to maintain data order which leads to a low storage efficiency. On the contrary, the unordered method keeps massive index data to only store nonempty voxels. In this paper, we design a new data management method for real-time indoor 3D reconstruction, called Structured Skip List (SSL). The SSL can be treated as a semi-ordered method, because the advantages of both the ordered and unordered methods are taken into account: 1) it only holds nonempty voxels similar to the unordered method; 2) the structured information is introduced to reduce the storage space of index data. By these designs, the SSL has a better performance on storage efficiency. To handle the data collision in voxel allocation, a hash allocation list (HAL) is proposed. The length of each Skip List is kept balanced by fusing the IMU (Inertial Measurement Unit) information for a high operation efficiency. The storage efficiency analysis of different data management methods is shown in this paper. What's more, exhaustive investigation is carried out on several datasets with these methods. The experimental result demonstrates that our design can achieve a high storage efficiency with little time loss compared to the state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Towards Real-Time Unsupervised Monocular Depth Estimation on CPU
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5848
EP  - 5854
AU  - M. Poggi
AU  - F. Aleotti
AU  - F. Tosi
AU  - S. Mattoccia
PY  - 2018
KW  - embedded systems
KW  - estimation theory
KW  - feature extraction
KW  - image reconstruction
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - microprocessor chips
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - stereo image processing
KW  - robotic navigation
KW  - autonomous navigation
KW  - deep learning
KW  - low-power constraints
KW  - embedded system
KW  - single input image
KW  - image reconstruction problem
KW  - KITTI image
KW  - depth map
KW  - CPU
KW  - unsupervised monocular depth estimation
KW  - features extraction
KW  - time 1.7 s
KW  - frequency 8.0 Hz
KW  - frequency 40.0 Hz
KW  - Estimation
KW  - Feature extraction
KW  - Computer architecture
KW  - Training
KW  - Decoding
KW  - Image resolution
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593814
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised depth estimation from a single image is a very attractive technique with several implications in robotic, autonomous navigation, augmented reality and so on. This topic represents a very challenging task and the advent of deep learning enabled to tackle this problem with excellent results. However, these architectures are extremely deep and complex. Thus, real-time performance can be achieved only by leveraging power-hungry GPUs that do not allow to infer depth maps in application fields characterized by low-power constraints. To tackle this issue, in this paper we propose a novel architecture capable to quickly infer an accurate depth map on a CPU, even of an embedded system, using a pyramid of features extracted from a single input image. Similarly to state-of-the-art, we train our network in an unsupervised manner casting depth estimation as an image reconstruction problem. Extensive experimental results on the KITTI dataset show that compared to the top performing approach our network has similar accuracy but a much lower complexity (about 6% of parameters) enabling to infer a depth map for a KITTI image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard CPU. Moreover, by trading accuracy for efficiency, our network allows to infer maps at about 2 Hz and 40 Hz respectively, still being more accurate than most state-of-the-art slower methods. To the best of our knowledge, it is the first method enabling such performance on CPUs paving the way for effective deployment of unsupervised monocular depth estimation even on embedded systems.
ER  - 

TY  - CONF
TI  - A Plug-In Feed-Forward Control for Sloshing Suppression in Robotic Teleoperation Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5855
EP  - 5860
AU  - L. Biagiotti
AU  - D. Chiaravalli
AU  - L. Moriello
AU  - C. Melchiorri
PY  - 2018
KW  - compensation
KW  - containers
KW  - end effectors
KW  - feedforward
KW  - industrial robots
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - sloshing
KW  - telerobotics
KW  - trajectory control
KW  - position-orientation trajectory
KW  - dynamic filter design
KW  - sloshing dynamics suppression
KW  - lateral accelerations
KW  - active compensation
KW  - liquid oscillations
KW  - filtering technique
KW  - design philosophy
KW  - robot end-effector
KW  - liquid container
KW  - liquid handling robotic systems
KW  - robotic teleoperation tasks
KW  - feed-forward control
KW  - motion capture system
KW  - harmonic smoother
KW  - Liquids
KW  - Containers
KW  - Robots
KW  - Acceleration
KW  - Trajectory
KW  - Mathematical model
KW  - Vibrations
DO  - 10.1109/IROS.2018.8593962
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, the problem of suppressing sloshing dynamics in liquid handling robotic systems has been faced by designing a dynamic filter that starting from the desired motion of the liquid container calculates the complete position/orientation trajectory for the robot end-effector. Specifically, a design philosophy mixing a filtering technique that suppresses the frequency contributions of the reference motion that may cause liquid oscillations and an active compensation of lateral accelerations by a proper container re-orientation has been adopted. In principle, the latter contribution requires the knowledge of acceleration of the reference trajectory, but because of the use of an harmonic smoother that performs a shaping of the original motion, it is possible to obtain the value of the acceleration in runtime. In this way, the proposed methods can be applied also to reference motions that are not known in advance, e.g. commands directly provided by a human operator. This possibility has been demonstrated by means of a number of experimental tests in which the user teleoperates the robot carrying the container with the liquid by simply moving in the free space its hand, whose 3D position is detected by a motion capture system.
ER  - 

TY  - CONF
TI  - Elastic Structure Preserving Impedance (ESπ)Control for Compliantly Actuated Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5861
EP  - 5868
AU  - M. Keppler
AU  - D. Lakatos
AU  - C. Ott
AU  - A. Albu-Schaffer
PY  - 2018
KW  - closed loop systems
KW  - damping
KW  - end effectors
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - stability
KW  - compliantly actuated robots
KW  - possibly nonlinear spring characteristics
KW  - damping range
KW  - end-effector interaction behavior
KW  - external loads approach
KW  - classical Cartesian impedance control
KW  - closed-loop dynamics
KW  - elastic structure preserving impedance control
KW  - stability analysis
KW  - Lyapunov function
KW  - Robot kinematics
KW  - Impedance
KW  - Springs
KW  - Damping
KW  - Dynamics
KW  - Actuators
DO  - 10.1109/IROS.2018.8593415
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a new approach for Cartesian impedance control of compliantly actuated robots with possibly nonlinear spring characteristics. It reveals a remarkable stiffness and damping range in the experimental evaluation. The most interesting contribution, is the way the desired closed-loop dynamics is designed. Our control concept allows to add a desired stiffness and damping directly on the end-effector, while leaving the system structure intact. The intrinsic inertial and elastic properties of the system are preserved. This is achieved by introducing new motor coordinates that reflect the desired spring and damper terms. Theoretically, by means of additional motor inertia shaping it is possible to make the end-effector interaction behavior with respect to external loads approach, arbitrarily close, the interaction behavior that is achievable by classical Cartesian impedance control on rigid robots. The physically motivated design approach allows for an intuitive understanding of the resulting closed-loop dynamics. We perform a passivity and stability analysis on the basis of al physically motivated storage and Lyapunov function.
ER  - 

TY  - CONF
TI  - An Efficient and Time-Optimal Trajectory Generation Approach for Waypoints Under Kinematic Constraints and Error Bounds
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5869
EP  - 5876
AU  - J. Lin
AU  - N. Somani
AU  - B. Hu
AU  - M. Rickert
AU  - A. Knoll
PY  - 2018
KW  - manipulator kinematics
KW  - nonlinear programming
KW  - path planning
KW  - time optimal control
KW  - trajectory control
KW  - motion planners
KW  - optimization scale
KW  - trajectory results
KW  - seven-segment acceleration profile
KW  - nonlinear constraint optimization problem
KW  - robot manipulator
KW  - error bounds
KW  - kinematic constraints
KW  - time-optimal trajectory generation approach
KW  - Trajectory
KW  - Splines (mathematics)
KW  - Optimization
KW  - Manipulators
KW  - Acceleration
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593577
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an approach to generate the time-optimal trajectory for a robot manipulator under certain kinematic constraints such as joint position, velocity, acceleration, and jerk limits. This problem of generating a trajectory that takes the minimum time to pass through specified waypoints is formulated as a nonlinear constraint optimization problem. Unlike prior approaches that model the motion of consecutive waypoints as a Cubic Spline, we model this motion with a seven-segment acceleration profile, as this trajectory results in a shorter overall motion time while staying within the bounds of the robot manipulator's constraints. The optimization bottleneck lies in the complexity that increases exponentially with the number of waypoints. To make the optimization scale well with the number of waypoints, we propose an approach that has linear complexity. This approach first divides all waypoints to consecutive batches, each with an overlap of two waypoints. The overlapping waypoints then act as a bridge to concatenate the optimization results of two consecutive batches. The whole trajectory is effectively optimized by successively optimizing every batch. We conduct experiments on practical scenarios and trajectories generated by motion planners to evaluate the effectiveness of our proposed approach over existing state-of-the-art approaches.
ER  - 

TY  - CONF
TI  - Leveraging Precomputation with Problem Encoding for Warm-Starting Trajectory Optimization in Complex Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5877
EP  - 5884
AU  - W. Merkt
AU  - V. Ivan
AU  - S. Vijayakumar
PY  - 2018
KW  - collision avoidance
KW  - convergence
KW  - humanoid robots
KW  - mobile robots
KW  - Newton method
KW  - trajectory control
KW  - problem encoding
KW  - warm-starting trajectory optimization
KW  - motion planner
KW  - local minima
KW  - motion planning
KW  - near-optimal warm-start initializations
KW  - global convergence
KW  - quasiNewton solvers
KW  - probabilistic inference solvers
KW  - NASA Valkyrie robot
KW  - Task analysis
KW  - Collision avoidance
KW  - Planning
KW  - Robots
KW  - Trajectory optimization
DO  - 10.1109/IROS.2018.8593977
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning through optimization is largely based on locally improving the cost of a trajectory until an optimal solution is found. Choosing the initial trajectory has therefore a significant effect on the performance of the motion planner, especially when the cost landscape contains local minima. While multiple heuristics and approximations may be used to efficiently compute an initialization online, they are based on generic assumptions that do not always match the task at hand. In this paper, we exploit the fact that repeated tasks are similar according to some metric. We store solutions of the problem as a library of initial seed trajectories offline and employ a problem encoding to retrieve near-optimal warm-start initializations on-the-fly. We compare how different initialization strategies affect the global convergence and runtime of quasi-Newton and probabilistic inference solvers. Our analysis on the 38-DoF NASA Valkyrie robot shows that efficient and optimal planning in high-dimensional state spaces is possible despite the presence of globally non-smooth and discontinuous constraints, such as the ones imposed by collisions.
ER  - 

TY  - CONF
TI  - A Self-Tuning Impedance Controller for Autonomous Robotic Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5885
EP  - 5891
AU  - P. Balatti
AU  - D. Kanoulas
AU  - G. F. Rigano
AU  - L. Muratore
AU  - N. G. Tsagarakis
AU  - A. Ajoudani
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot programming
KW  - robot vision
KW  - appropriate restoring forces
KW  - unstructured environments
KW  - complex interactions
KW  - autonomous robotic manipulation
KW  - self-tuning impedance controller
KW  - debris removal task
KW  - selective Cartesian axes
KW  - impedance parameters
KW  - autonomous tuning
KW  - robot state machine
KW  - interaction values
KW  - interaction expectancy value
KW  - novel self-regulating impedance controller
KW  - task-dependent regulation
KW  - task conditions
KW  - robot programmers
KW  - damping
KW  - stiffness
KW  - quasistatic performance
KW  - impedance control techniques
KW  - imposed displacements
KW  - Impedance
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Grasping
KW  - Damping
DO  - 10.1109/IROS.2018.8593860
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Complex interactions with unstructured environments require the application of appropriate restoring forces in response to the imposed displacements. Impedance control techniques provide effective solutions to achieve this, however, their quasi-static performance is highly dependent on the choice of parameters, i.e. stiffness and damping. In most cases, such parameters are previously selected by robot programmers to achieve a desired response, which limits the adaptation capability of robots to varying task conditions. To improve the generality of interaction planning through task-dependent regulation of the parameters, this paper introduces a novel self-regulating impedance controller. The regulation of the parameters is achieved based on the robot's local sensory data, and on an interaction expectancy value. This value combines the interaction values from the robot state machine and visual feedback, to authorize the autonomous tuning of the impedance parameters in selective Cartesian axes. The effectiveness of the proposed method is validated experimentally in a debris removal task.
ER  - 

TY  - CONF
TI  - Robust Fixed-Wing UAV Guidance with Circulating Artificial Vector Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5892
EP  - 5899
AU  - A. M. C. Rezende
AU  - V. M. Gonçalves
AU  - G. V. Raffo
AU  - L. C. A. Pimenta
PY  - 2018
KW  - aircraft control
KW  - asymptotic stability
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - Lyapunov methods
KW  - robust control
KW  - vectors
KW  - constrained input controls
KW  - asymptotic stability
KW  - control law
KW  - robust fixed-wing UAV guidance
KW  - guidance vector field strategy
KW  - unmanned aerial vehicle
KW  - closed curve
KW  - control system
KW  - aircraft model
KW  - artificial vector fields
KW  - Convergence
KW  - Uncertainty
KW  - Atmospheric modeling
KW  - Aircraft
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Shape
DO  - 10.1109/IROS.2018.8594371
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a guidance vector field strategy to control a fixed-wing UAV (unmanned aerial vehicle)subject to uncertainty in order to converge to and circulate a closed curve in ℝ3. The control system is designed based on a reference model of the airplane with constrained input controls. The law is independent of the vector field's structure, however, some analysis considers a consolidated vector field approach. Asymptotic stability is proven with Lyapunov Theory and ultimate bounds are found when bounded uncertainties are taken into account. The control law is continuous except in the surroundings of the unavoidable field's singularities. A theorem ensures asymptotic convergence when a switch is made. Simulations with a 6 DOF, 12 states realistic aircraft model demonstrate the efficiency of the strategy and its advantages.
ER  - 

TY  - CONF
TI  - Development of MR Clutch for a Prospective 5 DOF Robot* This work was supported in part by Canada Foundation for Innovation (CFI) and Natural Sciences and Engineering Research Council (NSERC) of Canada under grant No.25031 and RGPIN-346166.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5900
EP  - 5905
AU  - S. Pisetskiy
AU  - M. R. Kermani
PY  - 2018
KW  - clutches
KW  - design engineering
KW  - Hall effect transducers
KW  - intelligent sensors
KW  - machine control
KW  - magnetorheology
KW  - torque control
KW  - intrinsic torque control
KW  - mechanical design
KW  - prospective 5 DOF robot
KW  - MR clutch
KW  - magneto-rheological clutch
KW  - prospective 5 degrees of freedom robot
KW  - embedded Hall sensors
KW  - Torque
KW  - Magnetic sensors
KW  - Stators
KW  - Rotors
KW  - Robots
KW  - Wires
DO  - 10.1109/IROS.2018.8593582
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an improved design approach for the construction of a Magneto-Rheological (MR) clutch intended to be used in a prospective 5 degrees of freedom robot. The MR clutch features embedded Hall sensors for intrinsic torque control. After a brief description of the MR clutch principles, the details of the mechanical design are discussed. Simulation and preliminary experimental results demonstrate the main characteristics and advantages of the proposed MR clutch.
ER  - 

TY  - CONF
TI  - Real-Time Quad-Rotor Path Planning for Mobile Obstacle Avoidance Using Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Szmuk
AU  - C. A. Pascucci
AU  - B. AÇikmeşe
PY  - 2018
KW  - attitude control
KW  - collision avoidance
KW  - convex programming
KW  - helicopters
KW  - propellers
KW  - mobile obstacle avoidance
KW  - on-board convex-optimization-based path planning
KW  - multirotors
KW  - fixed-pitch propellers
KW  - fixed-pitch actuators
KW  - uni-directional thrust
KW  - commanded total thrust
KW  - sufficient independent attitude control authority
KW  - indoor flight demonstration
KW  - second-order cone programming problems
KW  - real-time quad-rotor path planning
KW  - real-time 3-dimensional path planning
KW  - Trajectory
KW  - Real-time systems
KW  - Software
KW  - Acceleration
KW  - Vehicle dynamics
KW  - Attitude control
DO  - 10.1109/IROS.2018.8594351
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we employ convex optimization to perform real-time 3-dimensional path planning on-board a quad-rotor and demonstrate its real-time capabilities. Building on our previous work, we make the following modifications: (1)we assume the obstacles are mobile, and (2)we introduce a simple framework to continuously recompute and update the trajectory. The contribution of this paper is to demonstrate the feasibility of real-time on-board convex-optimization-based path planning. For multi-rotors with fixed-pitch propellers, this path planning problem has two sources of non-convexity. First, since fixed-pitch actuators produce uni-directional thrust, the commanded total thrust must be maintained above a non-zero minimum in order to retain sufficient independent attitude control authority. The second source of non-convexity is due to the keep-out zones that envelop each obstacle. To circumvent the non-convexities introduced by these control and state constraints, we employ lossless and successive con-vexification, respectively. Consequently, we cast the original problem as a sequence of Second-Order Cone Programming problems, which can be solved quickly and reliably on-board. We conclude by presenting indoor flight demonstration and timing results of a scenario with three mobile obstacles. In this scenario, our algorithm assumes that the obstacles move with constant acceleration, and is re-executed regularly to account for uncertainties in the motion of the obstacles. The results show that new trajectories can be computed at rates in excess of 10 Hz, quickly enough to adapt to the uncertainty introduced in our flight demonstration.
ER  - 

TY  - CONF
TI  - Embedded and controllable shape morphing with twisted-and-coiled actuators*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5912
EP  - 5917
AU  - J. Sun
AU  - B. Pawlowski
AU  - J. Zhao
PY  - 2018
KW  - actuators
KW  - muscle
KW  - prosthetics
KW  - robot designs
KW  - adaptive morphology
KW  - soft materials
KW  - steady-state shape
KW  - embedded shape morphing
KW  - controllable shape morphing
KW  - twisted-and-coiled actuators
KW  - thermoplastic material
KW  - variable stiffness
KW  - mechanical design
KW  - artificial muscle
KW  - Shape
KW  - Programmable logic arrays
KW  - Actuators
KW  - Strain
KW  - Force
KW  - Mathematical model
KW  - Robots
DO  - 10.1109/IROS.2018.8593651
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Shape morphing, meaning a structure can first morph and then lock into another shape, can be applied to robot designs to endow robots with adaptive morphology for increased functionality and adaptivity. In this paper, we introduce a novel shape morphing scheme enabled by a new artificial muscle: twisted and coiled actuators (TCAs). This new actuator is purely soft, low cost, and electrically driven. Embedding a TCA and a thermoplastic material with variable stiffness into soft materials, we create a miniature shape-morphing link. We also establish a general model to predict the steady-state shape of the link given an input power applied to the TCA. Experiments are conducted to characterize parameters and verify the proposed model. Finally, we demonstrate this shape-morphing link can serve as a link in a mechanism to change the trajectory of its foot or endpoint. We envision that such a new shape-morphing scheme can enable robots to leverage the same mechanical design for different functions.
ER  - 

TY  - CONF
TI  - Soft Robotic Burrowing Device with Tip-Extension and Granular Fluidization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5918
EP  - 5923
AU  - N. D. Naclerio
AU  - C. M. Hubicki
AU  - Y. O. Aydin
AU  - D. I. Goldman
AU  - E. W. Hawkes
PY  - 2018
KW  - fluidisation
KW  - granular materials
KW  - mobile robots
KW  - sand
KW  - underground equipment
KW  - granular fluidization
KW  - soft robotic burrowing device
KW  - mobile robots
KW  - interaction forces
KW  - pressure-driven thin film body
KW  - tip-extension
KW  - pressurized fluid
KW  - Electron tubes
KW  - Force
KW  - Robots
KW  - Strips
KW  - Fluidization
KW  - Pneumatic systems
KW  - Fabrics
DO  - 10.1109/IROS.2018.8593530
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robots of all shapes and sizes move through the air, water, and over ground. However, few robots can move through the ground. Not only are the forces resisting movement much greater than in air or water, but the interaction forces are more complicated. Here we propose a soft robotic device that burrows through dry sand while requiring an order of magnitude less force than a similarly sized intruding body. The device leverages the principles of both tip-extension and granular fluidization. Like roots, the device extends from its tip; the principle of tip-extension eliminates skin drag on the sides of the body, because the body is stationary with respect to the medium. We implement this with an everting, pressure-driven thin film body. The second principle, granular fluidization, enables a granular medium to adopt a dynamic fluid-like state when pressurized fluid is passed through it, reducing the forces acting on an object moving through it. We realize granular fluidization with a flow of air through the core of the body that mixes with the medium at the tip. The proposed device could lead to applications such as search and rescue in mudslides or shallow subterranean exploration. Further, because it creates a physical conduit with its body, electrical lines, fluids, or even tools could be passed through this channel.
ER  - 

TY  - CONF
TI  - Liquid Metal-Microelectronics Integration for a Sensorized Soft Robot Skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5924
EP  - 5929
AU  - T. Hellebrekers
AU  - K. B. Ozutemiz
AU  - J. Yin
AU  - C. Majidi
PY  - 2018
KW  - actuators
KW  - elastomers
KW  - flexible electronics
KW  - gallium alloys
KW  - grippers
KW  - indium alloys
KW  - integrated circuits
KW  - liquid metals
KW  - microsensors
KW  - robots
KW  - sensors
KW  - shape memory effects
KW  - skin
KW  - tactile sensors
KW  - temperature sensors
KW  - robot arm
KW  - sensorized soft gripper
KW  - shape-memory actuated soft gripper
KW  - microelectronic skin
KW  - individual sensors
KW  - mechanical loading
KW  - room temperature liquid metal alloy
KW  - eutectic gallium indium
KW  - temperature sensing
KW  - solid-state electronics
KW  - stretchable skin
KW  - elastomeric skin
KW  - integrated circuits
KW  - microelectronic sensors
KW  - natural mechanics
KW  - signal processing
KW  - power regulation
KW  - sensorized soft robot skin
KW  - liquid metal-microelectronics integration
KW  - temperature 293 K to 298 K
KW  - Grippers
KW  - Robot sensing systems
KW  - Temperature sensors
KW  - Skin
KW  - Liquids
KW  - Metals
DO  - 10.1109/IROS.2018.8593944
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Progress in soft robotics depends on the integration of electronics for sensing, power regulation, and signal processing. Commercially available microelectronics satisfy these functions and are small enough to preserve the natural mechanics of the host system. Here, we present a method for incorporating microelectronic sensors and integrated circuits (ICs) into the elastomeric skin of a soft robot. The thin stretchable skin contains various solid-state electronics for orientation, pressure, proximity, and temperature sensing, and a microprocessor. The components are connected by thin-film copper traces wetted with eutectic gallium indium (EGaIn), a room temperature liquid metal alloy that allows the circuit to maintain conductivity as it deforms under mechanical loading. In this paper, we characterize the function of the individual sensors in air and water, discuss the integration of the microelectronic skin with a shape-memory actuated soft gripper, and demonstrate the sensorized soft gripper in conjunction with a 4 degree-of-freedom (DOF) robot arm.
ER  - 

TY  - CONF
TI  - Development of a Hybrid Gripper with Soft Material and Rigid Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5930
EP  - 5935
AU  - W. Park
AU  - S. Seo
AU  - J. Bae
PY  - 2018
KW  - bending
KW  - finite element analysis
KW  - grippers
KW  - manipulators
KW  - motion control
KW  - pneumatic actuators
KW  - hybrid gripper
KW  - robotic manipulators
KW  - conventional robotic grippers
KW  - rigid components
KW  - gripping motion
KW  - soft grippers
KW  - bending motion
KW  - fingertip force
KW  - morphological structure
KW  - soft pneumatic actuators
KW  - underactuated mechanism
KW  - finite element methods
KW  - FEM
KW  - SPAs
KW  - three-fingered gripper
KW  - soft components
KW  - Grippers
KW  - Force
KW  - Shape
KW  - Strain
KW  - Robots
KW  - Actuators
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594232
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For decades, various robotic grippers have been developed due to its necessity for the robotic manipulators. In case of the conventional robotic grippers with rigid components, an underactuated mechanism was required to satisfy gripping motion. Recently, soft grippers have been studied actively, which have realize bending motion with a simple morphological structure itself and inherent compliance to the environment. In this field of study, it has been rarely investigated to improve the fingertip force and actuation speed with specified design parameters. Thus, in this study, a hybrid gripper, which consists of both soft and rigid components, was suggested based on the key design principles: 1) the ratio of rigid parts against the soft chamber, 2) the cross-sectional shape of the chamber. The suggested principles were verified using the finite element methods (FEMs). As a result, the improved performance of the hybrid gripper was verified in terms of the fingertip force and the actuation speed, compared with the performance of the previously developed soft pneumatic actuators (SPAs). As an application, the three-fingered gripper was manufactured and tested by grasping different types of objects.
ER  - 

TY  - CONF
TI  - Design for Control of a Soft Bidirectional Bending Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - R. A. Bilodeau
AU  - M. C. Yuen
AU  - J. C. Case
AU  - T. L. Buckner
AU  - R. Kramer-Bottiglio
PY  - 2018
KW  - bending
KW  - capacitive sensors
KW  - closed loop systems
KW  - finite element analysis
KW  - pneumatic actuators
KW  - strain sensors
KW  - sensor effectiveness
KW  - design evaluation process
KW  - simple control strategies
KW  - closed-loop control
KW  - soft bidirectional bending actuator
KW  - SCAPAs
KW  - controllable design
KW  - antagonistic actuators
KW  - embedded capacitive strain sensors
KW  - sensor-controlled antagonistic pneumatic actuators
KW  - soft robotic actuators
KW  - manufacturing processes
KW  - finite element analysis
KW  - state reconstruction
KW  - single conductive fabric sheet
KW  - Actuators
KW  - Capacitive sensors
KW  - Fabrics
KW  - Strain
KW  - Robot sensing systems
KW  - Sensor systems
KW  - soft material robotics
KW  - hydraulic/pneumatic actuators
KW  - sensor-based control
DO  - 10.1109/IROS.2018.8594293
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present sensor-controlled antagonistic pneumatic actuators (SCAPAs) that integrate proven soft robotic actuators and sensors into a simplified, controllable design. The antagonistic actuators together compose a bidirectional bending actuator with embedded capacitive strain sensors. By designing the SCAPAs from the ground-up for closed-loop control, we are able to minimize both the number of constituent components and the types of materials used, and further streamline the manufacturing processes. These improvements are embodied in the multipurpose use of a single conductive fabric sheet for both actuation and sensing, integrated into an otherwise all-silicone device. Such reduced material complexity allows us to use simple finite element analysis (FEA) models to predict the performance of a given design. We compare various designs to maximize sensor effectiveness using FEA and experimentally verify the suitability of select designs for state reconstruction. After converging on our final design, we demonstrate that this design evaluation process enables the use of simple control strategies to achieve closed-loop control.
ER  - 

TY  - CONF
TI  - Sliding-Layer Laminates: A Robotic Material Enabling Robust and Adaptable Undulatory Locomotion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5944
EP  - 5951
AU  - M. Jiang
AU  - N. Gravish
PY  - 2018
KW  - elasticity
KW  - hydrodynamics
KW  - marine control
KW  - mobile robots
KW  - motion control
KW  - sliding-layer laminates
KW  - robotic material enabling robust
KW  - adaptable undulatory locomotion
KW  - continuum robots
KW  - undulatory actuation
KW  - body materials
KW  - flexible movement
KW  - resistive forces
KW  - surrounding fluid
KW  - solid environments
KW  - robot designs
KW  - passive propulsive elements
KW  - wings
KW  - laminate design paradigm
KW  - f1exible-yet-stiff robotic materials
KW  - SLLs
KW  - design principles
KW  - morphable materials
KW  - swimming robot
KW  - passive tail
KW  - water swimming
KW  - steady swimming
KW  - robot tail
KW  - locomotion modes
KW  - confined swimming
KW  - confined environments
KW  - high stiffness
KW  - stiff tail designs
KW  - soft tail designs
KW  - complex underwater environments
KW  - robot locomotor
KW  - flexible-yet-stiff materials
KW  - Laminates
KW  - Structural beams
KW  - Springs
KW  - Jamming
KW  - Service robots
KW  - Laser beams
DO  - 10.1109/IROS.2018.8594421
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Continuum robots that move through undulatory actuation must be composed of body materials that can enable flexible movement yet also provide resistive forces to the surrounding fluid, granular, or solid environments. This need for “f1exible-yet-stiff” materials is notably important in robot designs that use passive propulsive elements such as tails and wings. Here we explore a laminate design paradigm for “f1exible-yet-stiff” robotic materials through sliding layer laminates (SLLs). We present design principles motivated by theory and experiment and illustrate a taxonomy of SLL enabled morphable materials capable of up to 7 fold change in stiffness. Lastly, we demonstrate the applicability of SLLs to undulatory continuum robots: a swimming robot with a passive tail. We target two desired robot locomotor behaviors: fast open water swimming, and steady swimming through narrow channels emulating underwater caverns and pipes. We demonstrate how tuning the stiffness of the robot tail maximizes thrust generation in these two locomotion modes. Soft tails are optimal in confined swimming because they generate short amplitude high wavenumber oscillations, while stiff tails in confined environments either collide with the walls or do not generate sufficient thrust. However, stiff tails are far better in unconfined environments which enable large stroke amplitudes requiring high stiffness. Through this demonstration we show that stiff or soft tail designs alone are incapable of effective locomotion in complex underwater environments challenge.
ER  - 

TY  - CONF
TI  - Development of a Pneumatically Driven Flexible Finger with Feedback Control of a Polyurethane Bend Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5952
EP  - 5957
AU  - Y. Mori
AU  - M. Zhu
AU  - H. Kim
AU  - A. Wada
AU  - M. Mitsuzuka
AU  - Y. Tajitsu
AU  - S. Kawamura
PY  - 2018
KW  - bending
KW  - dexterous manipulators
KW  - feedback
KW  - medical robotics
KW  - pipelines
KW  - pneumatic control equipment
KW  - pneumatic systems
KW  - position control
KW  - sensors
KW  - tactile sensors
KW  - vibrations
KW  - flexible material
KW  - flexible angle estimation sensor
KW  - flexible sensor
KW  - pneumatically driven flexible finger
KW  - Robot sensing systems
KW  - Optical sensors
KW  - Cameras
KW  - Optical fiber amplifiers
KW  - Voltage measurement
KW  - Three-dimensional displays
KW  - Printers
DO  - 10.1109/IROS.2018.8594081
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A pneumatically-driven flexible finger equipped with a flexible sensor is realized for improving the performance of the soft robotic hand. First, we propose a flexible angle estimation sensor. This sensor measures the change in the amount of light passing through polyurethane material and estimates the angle with high repeatability. Next, we design a flexible finger that makes this sensor easy to incorporate. The flexible fingers are produced with a multi-material 3D printer that can use flexible material. The flexible finger can accommodate the proposed flexible sensor within it. It is possible to place the sensor's signal line in the air pressure pipeline. Because the flexible finger is produced with a 3D printer, variations in each model's characteristics are small as compared with manufacturing through molding. In this paper, we show an improvement of positional accuracy in the proposed flexible finger using angle feedback control from the proposed sensor. The effectiveness of this sensor is also shown to solve the problem of vibration problems for the flexible finger during high speed motion.
ER  - 

TY  - CONF
TI  - Modelling an Actuated Large Deformation Soft Continuum Robot Surface Undergoing External Forces Using a Lumped-Mass Approacb* Research supported by UK Engineering and Physical Sciences Research Council (EPSRC).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5958
EP  - 5963
AU  - H. Habibi
AU  - C. Yang
AU  - R. Kang
AU  - I. D. Walker
AU  - I. S. Godage
AU  - X. Dong
AU  - D. T. Branson
PY  - 2018
KW  - compliant mechanisms
KW  - continuum mechanics
KW  - finite element analysis
KW  - manipulator dynamics
KW  - shear modulus
KW  - large deformation continuum surfaces
KW  - soft continuum robotic arms
KW  - 3D integrated surface-arm model
KW  - lumped-mass methodology
KW  - soft robotics
KW  - Mathematical model
KW  - Robots
KW  - Load modeling
KW  - Deformable models
KW  - Strain
KW  - Actuators
KW  - Springs
DO  - 10.1109/IROS.2018.8594033
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precise actuation of continuum surfaces in combination with continuum robotic arms that undergo large deformation is of high interest in soft robotics but of limited model-based study to date. This work develops this area towards enabling the robust design and control of large deformation continuum surfaces (LDCS) across multiple industrial applications in the healthcare, aerospace, manufacturing, and automotive domains. It introduces an actuation based dynamic model of LDCSs to accurately determine their deflection due to application of concentrated external forces while maintaining many physical characteristics and constraints on actuation elements and surface structure such as gravity, inertia, damping, elasticity, and interactive forces between actuators and LDCS. Using the lumped-mass methodology, a 3D integrated surface-arm model is developed, simulated and then validated experimentally where a pair of parallel arms are attached to the surface to actuate and deform it. The surface is then simultaneously subjected to a concentrated constant external force at its top center between the two arms. Comparing measured displacements between the experimental and modelling results over actuation time yielded the maximum error is less than 1% of the length of the surface's side at its final deflected profile despite the limited number of nodes (masses) used in the LDCS model while it is exposed to a significant external force.
ER  - 

TY  - CONF
TI  - Motion Generators Combined with Behavior Trees: A Novel Approach to Skill Modelling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5964
EP  - 5971
AU  - F. Rovida
AU  - D. Wuthier
AU  - B. Grossmann
AU  - M. Fumagalli
AU  - V. Krüger
PY  - 2018
KW  - control engineering computing
KW  - industrial robots
KW  - motion control
KW  - robot programming
KW  - trees (mathematics)
KW  - programming complexity
KW  - industrial robots
KW  - complex motions
KW  - self-contained primitive blocks
KW  - semantic skill
KW  - concurrent motion primitives
KW  - modeling skills
KW  - motion generators
KW  - behavior trees
KW  - task level programming
KW  - Task analysis
KW  - Generators
KW  - Robot kinematics
KW  - Force
KW  - Planning
KW  - Grippers
KW  - industrial robots
KW  - skills
KW  - reactive system
KW  - behavior tress
KW  - motio generators
KW  - assembly
DO  - 10.1109/IROS.2018.8594319
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Task level programming based on skills has often been proposed as a mean to decrease programming complexity of industrial robots. Several models are based on encapsulating complex motions into self-contained primitive blocks. A semantic skill is then defined as a deterministic sequence of these primitives. A major limitation is that existing frameworks do not support the coordination of concurrent motion primitives with possible interference. This decreases their reusability and scalability in unstructured environments where a dynamic and reactive adaptation of motions is often required. This paper presents a novel framework that generates adaptive behaviors by modeling skills as concurrent motion primitives activated dynamically when conditions trigger. The approach exploits the additive property of motion generators to superpose multiple contributions. We demonstrate the applicability on a real assembly use-case and discuss the gained benefits.
ER  - 

TY  - CONF
TI  - Enhanced Explosive Motion for Torque Controlled Actuators Through Field Weakening Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - W. Roozing
AU  - N. Kashiri
AU  - N. G. Tsagarakis
PY  - 2018
KW  - actuators
KW  - machine control
KW  - motor drives
KW  - permanent magnet motors
KW  - robots
KW  - synchronous motors
KW  - torque control
KW  - surface permanent magnet synchronous machine motor drives
KW  - operating modes
KW  - constraints
KW  - system dynamics
KW  - reference torque
KW  - robotics applications
KW  - motor torque reference
KW  - motor drives
KW  - field weakening control
KW  - torque controlled actuators
KW  - enhanced explosive motion
KW  - peak velocity
KW  - Torque
KW  - Robots
KW  - Permanent magnet motors
KW  - Actuators
KW  - Synchronous motors
KW  - AC motors
KW  - Voltage control
DO  - 10.1109/IROS.2018.8593608
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents a method to increase the peak output speed of surface permanent magnet synchronous machine (SPMSM) motor drives with application in robotics using field weakening control. Contrary to most existing works, the strategy is stateless and operates using only a motor torque reference as input, making it suitable for robotics applications in which reference torque and speed are continuously and rapidly changing. Based on the system dynamics and constraints, we obtain four different operating modes. The strategy is extensively validated using three different experiments, which show an increase in peak velocity of up to 33%. The results demonstrate that the proposed strategy is effective in extending the dynamic performance and explosive motion capabilities of robots.
ER  - 

TY  - CONF
TI  - Ground Disturbance Rejection Approach for Mobile Robotic Manipulators with Hydraulic Actuators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5980
EP  - 5986
AU  - M. Rigotti-Thompson
AU  - M. Torres-Torriti
AU  - F. A. Cheein
AU  - G. Troni
PY  - 2018
KW  - active disturbance rejection control
KW  - end effectors
KW  - feedforward
KW  - H∞ control
KW  - hydraulic actuators
KW  - loading equipment
KW  - mining
KW  - mobile robots
KW  - PD control
KW  - vehicle dynamics
KW  - wheels
KW  - active disturbance rejection control
KW  - skid-steer loader
KW  - H∞ control
KW  - PD control
KW  - ADRC
KW  - inertial sensors
KW  - hydraulic arm dynamics
KW  - wheels
KW  - end-effector
KW  - front-end loaders
KW  - robotic mining mobile manipulators
KW  - material spillage
KW  - hydraulic actuators
KW  - autonomous machines
KW  - feedforward action
KW  - proportional-derivative control
KW  - Manipulator dynamics
KW  - Force
KW  - Dynamics
KW  - Mathematical model
KW  - Hydraulic actuators
KW  - Wheels
DO  - 10.1109/IROS.2018.8594172
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reducing material spillage by robotic mining mobile manipulators, such as front-end loaders, is necessary to improve mining operations. To this end, the present work proposes an approach to reduce disturbances on the end-effector induced by the terrain and propagated through the wheels and arm links of the machine. The proposed approach is based on an H∞ control strategy that includes a feedforward action, computed using the pitch rate of the mobile base, and considers the hydraulic arm dynamics, as well as the reaction forces in the contact points of the mobile base, which is modeled as a floating body with non-permanent ground contacts. Alternative control schemes based on the classic proportional-derivative (PD) control, and the Active Disturbance Rejection Control (ADRC), with and without feedforward action, were also implemented and experimentally evaluated using a semiautonomous Cat® 262C compact skid-steer loader equipped with inclination and inertial sensors. The proposed method reduces disturbances by at least 70% when climbing ramps at 25% of the machine's maximum speed, and by at least 20% when driving over speed bumps which produce disturbances similar to that caused by stones. The proposed disturbance attenuation strategy should help reducing the spillage of material when driving over mounds, inclines or spilled rocks, especially considering that even if existing autonomous machines are able to drive with little operator supervision along mining galleries, they are often unable to avoid disturbing material on the ground or the characteristic unevenness of mining terrains.
ER  - 

TY  - CONF
TI  - Computationally-Robust and Efficient Prioritized Whole-Body Controller with Contact Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - D. Kim
AU  - J. Lee
AU  - J. Ahn
AU  - O. Campbell
AU  - H. Hwang
AU  - L. Sentis
PY  - 2018
KW  - force control
KW  - friction
KW  - humanoid robots
KW  - legged locomotion
KW  - mechanical contact
KW  - quadratic programming
KW  - robot dynamics
KW  - robust control
KW  - centroidal momentum dynamics
KW  - computationally-robust whole-body controller
KW  - quadratic program
KW  - passive-ankle bipedal robot
KW  - dynamic locomotion behaviors
KW  - smooth contact transitions
KW  - friction cone constraints
KW  - task accelerations
KW  - computational robustness
KW  - floating base dynamics
KW  - internal force constraints
KW  - contact reaction forces
KW  - operational task priorities
KW  - algorithmic computations
KW  - prioritized whole-body controllers
KW  - humanoid robots
KW  - multiobjective control
KW  - contact constraints
KW  - Task analysis
KW  - Null space
KW  - Dynamics
KW  - Acceleration
KW  - Robots
KW  - Force
KW  - Torque
DO  - 10.1109/IROS.2018.8593767
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we devise methods for the multiobjective control of humanoid robots, a.k.a. prioritized whole-body controllers, that achieve efficiency and robustness in the algorithmic computations. We use a form of whole-body controllers that is very general via incorporating centroidal momentum dynamics, operational task priorities, contact reaction forces, and internal force constraints. First, we achieve efficiency by solving a quadratic program that only involves the floating base dynamics and the reaction forces. Second, we achieve computational robustness by relaxing task accelerations such that they comply with friction cone constraints. Finally, we incorporate methods for smooth contact transitions to enhance the control of dynamic locomotion behaviors. The proposed methods are demonstrated both in simulation and in real experiments using a passive-ankle bipedal robot.
ER  - 

TY  - CONF
TI  - Continuously Shaping Projections and Operational Space Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 5995
EP  - 6002
AU  - N. Dehio
AU  - D. Kubus
AU  - J. J. Steil
PY  - 2018
KW  - least squares approximations
KW  - robots
KW  - projection operators
KW  - multiobjective robot control
KW  - dynamic task priority rearrangement
KW  - projection shaping
KW  - damped least squares
KW  - idempotent projectors
KW  - shaping operators
KW  - stack-of-tasks prioritization scheme
KW  - single task dimensions continuous priority rearrangement
KW  - Task analysis
KW  - Aerospace electronics
KW  - Jacobian matrices
KW  - Robots
KW  - Interference
KW  - Torque
KW  - Nickel
DO  - 10.1109/IROS.2018.8593400
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Projection operators are widely employed in multi-objective robot control. It is an open research question how to achieve continuous transitions between different idempotent projectors which is required for dynamic task priority rearrangement. We formalize projection shaping, providing a solution to deal with rank changes in a smooth fashion. Furthermore, we derive meaningful shaping operators and show that damped least squares is a special case of our general formulation. Finally, we extend the Stack-of-Tasks prioritization scheme for continuous priority rearrangement of single task dimensions. Simulation results validate our approach.
ER  - 

TY  - CONF
TI  - Dual-Arm Relative Tasks Performance Using Sparse Kinematic Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6003
EP  - 6009
AU  - S. Tarbouriech
AU  - B. Navarro
AU  - P. Fraisse
AU  - A. Crosnier
AU  - A. Cherubini
AU  - D. Sallé
PY  - 2018
KW  - manipulator kinematics
KW  - mobile robots
KW  - robotic assembly
KW  - dual-arm relative tasks performance
KW  - standard controllers
KW  - hierarchical sparse QP architecture
KW  - coordinated task
KW  - sparse kinematic control strategy
KW  - autonomous assembly units
KW  - dual-arm robots
KW  - production lines
KW  - Task analysis
KW  - Kinematics
KW  - Robot kinematics
KW  - Jacobian matrices
KW  - Manipulators
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8594320
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To make production lines more flexible, dual-arm robots are good candidates to be deployed in autonomous assembly units. In this paper, we propose a sparse kinematic control strategy, that minimizes the number of joints actuated for a coordinated task between two arms. The control strategy is based on a hierarchical sparse QP architecture. We present experimental results that highlight the capability of this architecture to produce sparser motions (for an assembly task) than those obtained with standard controllers.
ER  - 

TY  - CONF
TI  - Jet-HR1: Stepping Posture Optimization for Bipedal Robot Over Large Ditch Based on a Ducted-fan Propulsion System*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6010
EP  - 6015
AU  - B. Liu
AU  - Z. Huang
AU  - J. Wei
AU  - C. Shi
AU  - J. Ota
AU  - Y. Zhang
PY  - 2018
KW  - aerospace propulsion
KW  - ducts
KW  - fans
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - optimisation
KW  - ducted-fan propulsion system
KW  - prototype robot
KW  - stepping posture optimization
KW  - bipedal robot
KW  - two-dimensional gaits
KW  - Jet-HRl
KW  - jet humanoid robot
KW  - Legged locomotion
KW  - Foot
KW  - Fans
KW  - Propulsion
KW  - Gravity
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594055
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper reports the latest progress of an ongoing project utilizing a ducted-fan propulsion system to improve a humanoid robot's ability to step over a broad ditch with a height difference between the two sides. This work focuses on the methods of calculating the boundary and optimizing stepping posture to use less thrust and keep the robot balanced while stepping over the ditch. With the proposed methods and new two-dimensional gaits, the prototype robot, named Jet-HRl (Jet Humanoid Robot ver.l) was able to completely step over a broad ditch with 450mm in width (up to 97% of the robot's leg's length), and a height difference of 100mm between two sides.
ER  - 

TY  - CONF
TI  - User-Adaptive Human-Robot Formation Control for an Intelligent Robotic Walker Using Augmented Human State Estimation and Pathological Gait Characterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6016
EP  - 6022
AU  - G. Chalvatzaki
AU  - X. S. Papageorgiou
AU  - P. Maragos
AU  - C. S. Tzafestas
PY  - 2018
KW  - assisted living
KW  - gait analysis
KW  - geriatrics
KW  - human-robot interaction
KW  - intelligent robots
KW  - laser ranging
KW  - medical robotics
KW  - multi-robot systems
KW  - stability
KW  - state estimation
KW  - on-line gait characterization
KW  - robotic MAD
KW  - IMM-PDA-PF
KW  - intelligent robotic mobility assistive device
KW  - human-robot formation controller
KW  - gait cycle
KW  - pathological gait parametrization
KW  - human gait phases
KW  - on-line estimation
KW  - single laser-range-finder
KW  - user-adaptive human-robot system
KW  - pathological gait characterization
KW  - augmented human state estimation
KW  - intelligent robotic walker
KW  - user-adaptive human-robot formation control
KW  - Legged locomotion
KW  - Pathology
KW  - State estimation
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594360
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we describe a control strategy for a user-adaptive human-robot system for an intelligent robotic Mobility Assistive Device (MAD)using raw data from a single laser-range-finder (LRF)mounted on the MAD and scanning the walking area. The proposed control architecture consists of three modules. In the first module, a previously proposed methodology (termed IMM-PDA-PF)delivers the augmented human state estimation of the user by providing robust leg tracking and on-line estimation of the human gait phases. This information is processed at the next module for providing the pathological gait parametrization and characterization, by computing specific gait parameters for each gait cycle. These gait parameters form the feature vector that classifies the user in a certain class related to risk of fall. Those are of particular significance to the system, since the gait parameters and the respective class are used in the third module, i.e. the human-robot formation controller, in order to adapt the desired formation of the human-robot system, by selecting the appropriate control variables. The experimental evaluation comprises gait data from real patients, and demonstrates the stability of the human-robot formation control, indicating the importance of incorporating an on-line gait characterization of the user, using non-wearable and non-invasive methods, in the context of a robotic MAD.
ER  - 

TY  - CONF
TI  - Passivity Based Iterative Learning of Admittance-Coupled Dynamic Movement Primitives for Interaction with Changing Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6023
EP  - 6028
AU  - A. Kramberger
AU  - E. Shahriari
AU  - A. Gams
AU  - B. Nemec
AU  - A. Ude
AU  - S. Haddadin
PY  - 2018
KW  - adaptive control
KW  - feedback
KW  - iterative learning control
KW  - learning systems
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - admittance-coupled dynamic movement primitives
KW  - compact task representations
KW  - sensor-based goal adaptations
KW  - adaptive motion capabilities
KW  - learning process
KW  - environmental changes
KW  - contact wrench feedback dynamics
KW  - iterative learning approach
KW  - system passivity analysis
KW  - Kuka LWR robot
KW  - nonrigid contact
KW  - passivity based iterative learning
KW  - reference power tracking
KW  - Robots
KW  - Impedance
KW  - Trajectory
KW  - Force feedback
KW  - Dynamics
KW  - Task analysis
KW  - Admittance
DO  - 10.1109/IROS.2018.8593647
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Encoding desired motions into dynamic movement primitives (DMPs) is a common way for generating compact task representations that are able to handle sensor-based goal adaptations. At the same time, a robot should not only express adaptive motion capabilities at planning level, but use also contact wrench feedback in the adaptation and learning process of the DMP. Despite first approaches exist in this direction, no fully integrated approach has been proposed so far. In this paper, we introduce a new class of admittance-coupled DMPs that addresses environmental changes by including contact wrench feedback dynamics into the DMP formalism. Moreover, a novel iterative learning approach is devised that is based on monitoring the overall system passivity analysis in terms of reference power tracking. Simulations and experimental results with the Kuka LWR robot maintaining a non-rigid contact with the environment (wiping a surface) are shown for supporting the validity of our approach.
ER  - 

TY  - CONF
TI  - Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6029
EP  - 6036
AU  - C. Mueller
AU  - J. Venicx
AU  - B. Hayes
PY  - 2018
KW  - learning (artificial intelligence)
KW  - robots
KW  - concept constrained learning from demonstration
KW  - robust robot learning
KW  - constrained learning
KW  - LfD process
KW  - conceptually-grounded constraints
KW  - robust skill learning
KW  - CC-LfD
KW  - conceptual constraints
KW  - skill repair
KW  - Trajectory
KW  - Maintenance engineering
KW  - Task analysis
KW  - Training
KW  - Service robots
KW  - Planning
DO  - 10.1109/IROS.2018.8594133
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning from demonstration (LfD) has enabled robots to rapidly gain new skills and capabilities by leveraging examples provided by novice human operators. While effective, this training mechanism presents the potential for sub-optimal demonstrations to negatively impact performance due to unintentional operator error. In this work we introduce Concept Constrained Learning from Demonstration (CC-LfD), a novel algorithm for robust skill learning and skill repair that incorporates annotations of conceptually-grounded constraints (in the form of planning predicates) during live demonstrations into the LfD process. Through our evaluation, we show that CC-LfD can be used to quickly repair skills with as little as a single annotated demonstration without the need to identify and remove low-quality demonstrations. We also provide evidence for potential applications to transfer learning, whereby constraints can be used to adapt demonstrations from a related task to achieve proficiency with few new demonstrations required.
ER  - 

TY  - CONF
TI  - Kernel-Based Human-Dynamics Inversion for Precision Robot Motion-Primitives
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6037
EP  - 6042
AU  - R. B. Warrier
AU  - S. Devasia
PY  - 2018
KW  - augmented reality
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - regression analysis
KW  - robot dynamics
KW  - robot programming
KW  - telerobotics
KW  - human motor dynamics
KW  - kernel-based regression approach
KW  - inverse human-dynamics response
KW  - human-in-the-loop demonstrator
KW  - kernel-based human-dynamics inversion
KW  - precision robot motion-primitives
KW  - human demonstrator
KW  - robot controller
KW  - multiple iterations
KW  - assisted teleoperation
KW  - augmented reality display
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Gaussian processes
KW  - Biological system modeling
KW  - Kernel
KW  - Estimation
DO  - 10.1109/IROS.2018.8594164
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning motion primitives from demonstration requires the human demonstrator to effectively relay the task intent to the robot controller. When the task intent is not reflected sufficiently by the demonstration, multiple iterations are required to recover the underlying intent of the demonstrations. However, a large number of iterations can be expensive and might not be practical for each new task. A challenge is that human-in-the-loop demonstrations can be affected by the human motor dynamics (e.g., from visual observation to hand motion), which can lead to differences between the demonstration and intent. The main contribution of this article is to correct for the human motor dynamics and infer the intended action (motion primitive) from the human demonstrations. The proposed approach uses a kernel-based regression approach to learn the inverse human-dynamics response. These models are then used to correct for human-motor-dynamics and infer the intent of the human-in-the-loop demonstrator. Experimental validation is performed with an assisted teleoperation setup where the underlying intent is specified using an augmented reality display. Results indicate that the proposed approach leads to more precise intent estimation as compared to the actual human demonstrations.
ER  - 

TY  - CONF
TI  - Associative Skill Memory Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6043
EP  - 6048
AU  - H. Girgin
AU  - E. Ugur
PY  - 2018
KW  - force feedback
KW  - Gaussian processes
KW  - grippers
KW  - haptic interfaces
KW  - hidden Markov models
KW  - humanoid robots
KW  - mobile robots
KW  - neurophysiology
KW  - regression analysis
KW  - perturbed movements
KW  - torque trajectories
KW  - Parametric Hidden Markov Models
KW  - force feedback model
KW  - associative skill memory models
KW  - ASMs
KW  - stereotypical movements
KW  - stereotypical sensory events
KW  - dynamic movement primitives
KW  - noisy perception
KW  - stored sensory trajectories
KW  - haptic measurements
KW  - tactile measurements
KW  - perturbed movement deviates
KW  - stored single sensory trajectory instances
KW  - sensory event models
KW  - Hidden Markov models
KW  - Robot sensing systems
KW  - Trajectory
KW  - Task analysis
KW  - Force feedback
KW  - Force
DO  - 10.1109/IROS.2018.8593450
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Associative Skill Memories (ASMs) were formulated to encode stereotypical movements along with their stereotypical sensory events to increase the robustness of underlying dynamic movement primitives (DMPs) against noisy perception and perturbations. In ASMs, the stored sensory trajectories, such as the haptic and tactile measurements, are used to compute how much a perturbed movement deviates from the desired one, and to correct the movement if possible. In our work, we extend ASMs: rather than using stored single sensory trajectory instances, our system generates sensory event models and exploits those models to correct the perturbed movements during executions with the aim of generalizing to novel configurations. In particular, measured force and the torque trajectories are modelled using Parametric Hidden Markov Models, and then reproduced by Gaussian Mixture Regression. With Baxter robot, we demonstrate that our proposed force feedback model can be used to correct a trajectory while pushing an object with a mass never experienced before, and which otherwise slips away from the gripper because of noise. In the end, we discuss how far this skill can be generalized using the force model and possible future improvements.
ER  - 

TY  - CONF
TI  - Towards Intelligent Arbitration of Diverse Active Learning Queries
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6049
EP  - 6056
AU  - K. Bullard
AU  - A. L. Thomaz
AU  - S. Chernova
PY  - 2018
KW  - decision theory
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - query processing
KW  - diverse active learning queries
KW  - optimal queries
KW  - learning agent
KW  - active learner
KW  - decision-theoretic arbitration strategies
KW  - decision-theoretic strategy
KW  - intelligent arbitration
KW  - rule-based arbitration strategies
KW  - passive learning
KW  - Task analysis
KW  - Training
KW  - Grounding
KW  - Robots
KW  - Feature extraction
KW  - Hafnium
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8594279
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Active learning literature has explored the selection of optimal queries by a learning agent with respect to given criteria, but prior work in classification has focused only on obtaining labels for queried samples. In contrast, proficient learners, like humans, integrate multiple forms of information during learning. This work seeks to enable an active learner to reason about multiple query types concurrently, aimed at soliciting both instance and feature information from the teacher, and to autonomously arbitrate between queries of different types. We contribute the design of rule-based and decision-theoretic arbitration strategies and evaluate all against baselines of more traditional passive and active learning. Our findings show that all arbitration strategies lead to more efficient learning, compared to the baselines. Moreover, given a dynamically changing environment and constrained questioning budget (typical in human settings), the decision-theoretic strategy statistically outperforms all other methods since it reasons about both what query to make and when to make a query, in order to most effectively utilize its questioning budget.
ER  - 

TY  - CONF
TI  - Segmenting and Sequencing of Compliant Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. M. Hagos
AU  - M. Suomalainen
AU  - V. Kyrki
PY  - 2018
KW  - end effectors
KW  - expectation-maximisation algorithm
KW  - force sensors
KW  - hidden Markov models
KW  - human-robot interaction
KW  - motion control
KW  - probability
KW  - nonhomogeneous hidden Markov model
KW  - expectation-maximization algorithm
KW  - cartesian impedance controller parameter
KW  - KUKA LWR4+ arm
KW  - parameter estimation
KW  - HMM model
KW  - hidden phase transition probabilities
KW  - segmented phase
KW  - compliant motions
KW  - Hidden Markov models
KW  - Task analysis
KW  - Motion segmentation
KW  - Adaptation models
KW  - Computational modeling
KW  - Impedance
DO  - 10.1109/IROS.2018.8593710
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an approach for segmenting a task consisting of compliant motions into phases, learning a primitive for each segmented phase of the task, and reproducing the task by sequencing primitives online based on the learned model. As compliant motions can “probe” the environment, using the interaction between the robot and the environment to detect phase transitions can make the transitions less prone to positional errors. This intuition leads us to model a task with a non-homogeneous Hidden Markov Model (HMM), wherein hidden phase transition probabilities depend on the interaction with the environment (wrench measured by an F/T sensor). Expectation-maximization algorithm is employed in estimating the parameters of the HMM model. During reproduction, the phase changes of a task are detected online using the forward algorithm, with the parameters learned from demonstrations. Cartesian impedance controller parameters are learned from the demonstrations to reproduce each phase of the task. The proposed approach is studied with a KUKA LWR4+ arm in two setups. Experiments show that the method can successfully segment and reproduce a task consisting of compliant motions with one or more demonstrations, even when demonstrations do not have the same starting position and external forces occur from different directions. Finally, we demonstrate that the method can also handle rotational motions.
ER  - 

TY  - CONF
TI  - An Uncertainty-Aware Minimal Intervention Control Strategy Learned from Demonstrations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6065
EP  - 6071
AU  - J. Silvério
AU  - Y. Huang
AU  - L. Rozo
AU  - D. G. caldwell
PY  - 2018
KW  - learning (artificial intelligence)
KW  - motion control
KW  - robots
KW  - robots
KW  - human environments
KW  - active compliance
KW  - minimal intervention control principle
KW  - task demonstrations
KW  - proper gain estimation
KW  - unpredictable robot motions
KW  - robot compliant
KW  - data-efficient strategy
KW  - torque-controlled robot
KW  - uncertainty-aware minimal intervention control strategy
KW  - Robots
KW  - Uncertainty
KW  - Hidden Markov models
KW  - Task analysis
KW  - Impedance
KW  - Probabilistic logic
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594220
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motivated by the desire to have robots physically present in human environments, in recent years we have witnessed an emergence of different approaches for learning active compliance. Some of the most compelling solutions exploit a minimal intervention control principle, correcting deviations from a goal only when necessary, and among those who follow this concept, several probabilistic techniques have stood out from the rest. However, these approaches are prone to requiring several task demonstrations for proper gain estimation and to generating unpredictable robot motions in the face of uncertainty. Here we present a Programming by Demonstration approach for uncertainty-aware impedance regulation, aimed at making the robot compliant - and safe to interact with - when the uncertainty about its predicted actions is high. Moreover, we propose a data-efficient strategy, based on the energy observed during demonstrations, to achieve minimal intervention control, when the uncertainty is low. The approach is validated in an experimental scenario, where a human collaboratively moves an object with a 7-DoF torque-controlled robot.
ER  - 

TY  - CONF
TI  - Generative Low-Shot Network Expansion
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6072
EP  - 6077
AU  - A. Hayat
AU  - M. Kliger
AU  - S. Fleishman
AU  - D. Cohen-Or
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pattern classification
KW  - conventional deep learning classifiers
KW  - pre-trained deep network
KW  - base network
KW  - low-shot training scenarios
KW  - compact generative model
KW  - generative low-shot network expansion
KW  - hard distillation method
KW  - memory footprint
KW  - Training
KW  - Training data
KW  - Data models
KW  - Memory management
KW  - Task analysis
KW  - Robots
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8594004
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Conventional deep learning classifiers are static in the sense that they are trained on a predefined set of classes and learning to classify a novel class typically requires re-training. In this work, we address the problem of Low-Shot network-expansion learning. We introduce a learning framework which enables expanding a pre-trained (base) deep network to classify novel classes when the number of examples for the novel classes is particularly small. We present a simple yet powerful hard distillation method where the base network is augmented with additional weights to classify the novel classes, while keeping the weights of the base network unchanged. We show that since only a small number of weights needs to be trained, the hard distillation excels in low-shot training scenarios. Furthermore, hard distillation avoids detriment to classification performance on the base classes. Finally, we show that low-shot network expansion can be done with a very small memory footprint by using a compact generative model of the base classes training data with only a negligible degradation relative to learning with the full training set.
ER  - 

TY  - CONF
TI  - Sensor Selection and Stage & Result Classifications for Automated Miniature Screwdriving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6078
EP  - 6085
AU  - X. Cheng
AU  - Z. Jia
AU  - A. Bhatia
AU  - R. M. Aronson
AU  - M. T. Mason
PY  - 2018
KW  - control engineering computing
KW  - decision trees
KW  - fasteners
KW  - industrial robots
KW  - pattern classification
KW  - production engineering computing
KW  - robotic assembly
KW  - sensors
KW  - support vector machines
KW  - technical challenges
KW  - affordable intelligent screwdriving system
KW  - online stage
KW  - result classification
KW  - state transition graph
KW  - labeled screwdriving dataset
KW  - multiple sensor signals
KW  - classification algorithms
KW  - sensor reduction
KW  - accurate result classifiers
KW  - linear discriminant analysis
KW  - feature subset selection
KW  - optimal feature subset
KW  - corresponding sensor signals
KW  - stage classifier
KW  - optimal sensor subset
KW  - sensor selection
KW  - stage & result classifications
KW  - automated miniature screwdriving
KW  - consumer electronics industry every year
KW  - screwdriving process
KW  - challenging tasks
KW  - robotic threaded fastening systems
KW  - system cost
KW  - Robot sensing systems
KW  - Fasteners
KW  - Joining processes
KW  - Fault detection
KW  - Torque
KW  - Reliability
DO  - 10.1109/IROS.2018.8593520
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hundreds of billions of small screws are assembled in consumer electronics industry every year, yet reliably automating the screwdriving process remains one of the most challenging tasks. Two barriers to further adoption of robotic threaded fastening systems are system cost and technical challenges, especially for small screws. An affordable intelligent screwdriving system that can support online stage and result classification is the first step to bridge the gap. To this end, starting from a state transition graph of screwdriving processes and a labeled screwdriving dataset (1862 runs of M1.4 screws) on multiple sensor signals, we develop classification algorithms and perform sensor reduction. Fast and accurate result classifiers are developed using linear discriminant analysis, while a wrapper method for feature subset selection is used to identify the optimal feature subset and corresponding sensor signals to reduce cost. A stage classifier based on decision tree is developed using the optimal sensor subset. The stage classifier achieves high accuracy in realtime prediction of various stages when augmented with the state transition graph.
ER  - 

TY  - CONF
TI  - Evaluating Methods for End-User Creation of Robot Task Plans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6086
EP  - 6092
AU  - C. Paxton
AU  - F. Jonathan
AU  - A. Hundt
AU  - B. Mutlu
AU  - G. D. Hager
PY  - 2018
KW  - manipulators
KW  - multi-robot systems
KW  - path planning
KW  - end-user creation
KW  - perception-driven task plans
KW  - collaborative robots
KW  - generalizable robot task plans
KW  - behavior tree-based CoSTAR system
KW  - pick-and-place assembly tasks
KW  - SmartMove
KW  - Task analysis
KW  - Planning
KW  - User interfaces
KW  - Service robots
KW  - Grippers
KW  - Collaboration
DO  - 10.1109/IROS.2018.8594127
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - How can we enable users to create effective, perception-driven task plans for collaborative robots? We conducted a 35-person user study with the Behavior Tree-based CoSTAR system to determine which strategies for end user creation of generalizable robot task plans are most usable and effctive. CoSTAR allows domain experts to author complex, perceptually grounded task plans for collaborative robots. As a part of CoSTAR's wide range of capabilities, it allows users to specify SmartMoves: abstract goals such as “pick up component A from the right side of the table.” Users were asked to perform pick-and-place assembly tasks with either SmartMoves or one of three simpler baseline versions of CoSTAR. Overall, participants found CoSTAR to be highly usable, with an average System Usability Scale score of 73.4 out of 100. SmartMove also helped users perform tasks faster and more effectively; all SmartMove users completed the first two tasks, while not all users completed the tasks using the other strategies. SmartMove users showed better performance for incorporating perception across all three tasks.
ER  - 

TY  - CONF
TI  - A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6093
EP  - 6098
AU  - H. Nakamoto
AU  - M. Ohtake
AU  - K. Komoda
AU  - A. Sugahara
AU  - A. Ogawa
PY  - 2018
KW  - force control
KW  - grippers
KW  - motion control
KW  - robust control
KW  - trajectory control
KW  - vacuum pumps
KW  - robust pinching
KW  - Amazon Robotics Challenge 2017
KW  - suction air
KW  - vacuum pump
KW  - pad characteristics
KW  - gripper system
KW  - trajectory planning
KW  - trajectory control
KW  - suction force
KW  - passive linear motion mechanism
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593887
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Suction is an effective method for picking various objects because it makes trajectory planning and control easy. However, suction has not been used due to misalignment and leakage of suction air when handling a variety of shapes. We therefore develop a hand to handle these characteristics. First, we model the vacuum pump and pad characteristics to allow evaluation of momentum and suction force in the case of leakage. Utilizing this, we select a configuration suitable for the items in the Amazon Robotics Challenge 2017. In addition, we design a mechanism for switching from suction to pinching for grasping items that cannot be sucked. Moreover, robust pinching is made possible by equipping the fingertips with a passive linear motion mechanism. In the Amazon Robotics Challenge 2017, it was shown possible to stably grasp items with irregularities and items with large moments. Furthermore, items that cannot be grasped by suction can also be grasped robustly by switching to the pinching mechanism.
ER  - 

TY  - CONF
TI  - Mass Manufacturing of Self-Actuating Robots: Integrating Sensors and Actuators Using Flexible Electronics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6099
EP  - 6104
AU  - A. Dementyev
AU  - J. Qi
AU  - J. Ou
AU  - J. Paradiso
PY  - 2018
KW  - actuators
KW  - bending
KW  - flexible electronics
KW  - microcontrollers
KW  - piezoelectric actuators
KW  - printed circuits
KW  - shape memory effects
KW  - air-pouch actuators
KW  - maximum bend angle
KW  - supporting electronics
KW  - flexible printed circuit
KW  - self-sensing robots
KW  - mass manufacturing
KW  - self-actuating robots
KW  - integrating sensors
KW  - nonstandard manufacturing techniques
KW  - electrical systems
KW  - mechanical systems
KW  - novel manufacturing technique
KW  - flexible electronics factory
KW  - standard industrial machines
KW  - air pouches
KW  - shape memory alloy
KW  - polyamide-based flexible circuit
KW  - Actuators
KW  - Robot sensing systems
KW  - Manufacturing
KW  - Shape memory alloys
KW  - Shape
DO  - 10.1109/IROS.2018.8593631
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Currently, the manufacturing of self-actuating and self-sensing robots requires non-standard manufacturing techniques and assembly steps to integrate electrical and mechanical systems. In this work, we developed a novel manufacturing technique, where such robots can be produced at a flexible electronics factory. We developed the technique using standard industrial machines, processes, and materials. Using a lamination process, we were able to integrate air pouches or shape memory alloy (SMA) inside a polyamide-based flexible circuit to produce bending actuators. The bend angle of the actuators is sensed with a chain of inertial measurement units integrated on the actuator. Air-pouch actuators can produce a force of a 2.24N, and a maximum bend angle of 74 degrees. To demonstrate, we manufactured a five-legged robot with the developed actuators and bend sensors, with all the supporting electronics (e.g., microcontrollers, radio) directly integrated into the flexible printed circuit. Such robots are flat and lightweight (15 grams) and thus conveniently compact for transportation and storage. We believe that our technique can allow inexpensive and fast prototyping and deployment of self-actuating and self-sensing robots.
ER  - 

TY  - CONF
TI  - Achieving Flexible Assembly Using Autonomous Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Gilday
AU  - J. Hughes
AU  - F. Iida
PY  - 2018
KW  - mobile robots
KW  - recycling
KW  - robotic assembly
KW  - single shot pre-fabrication methods
KW  - assembling
KW  - dis-assembly processes
KW  - agile development
KW  - resource usage
KW  - build process
KW  - robotic platform
KW  - assembly method
KW  - cost function
KW  - alternative fabrication methods
KW  - flexible assembly
KW  - autonomous robotic systems
KW  - prefabrication
KW  - speed advantages
KW  - autonomous flexible reassembly
KW  - simple Lego bricks
KW  - Robots
KW  - Grippers
KW  - Fabrication
KW  - Morphology
KW  - Robotic assembly
KW  - Optimization
KW  - Force
DO  - 10.1109/IROS.2018.8593852
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Prefabrication of structures is currently used in a limited capacity, due to the lack of flexibility, despite the potential cost and speed advantages. Autonomous flexible reassembly enables structures to be developed which can be continuously and iteratively dis-assembled and re-assembled providing far more flexibility in comparison to single shot pre-fabrication methods. Dis-assembly of structures should be considered when assembling, due to the asymmetry of assembly and dis-assembly processes, to ensure structures can be recycled and re-assembled. This allows for agile development, significantly reducing the time and resource usage during the build process. In this work, a framework for flexible re-assembly is developed and a robotic platform is developed to implement and test this framework with simple Lego bricks. The tradeoffs in terms of time, resource use and probability of success of this new assembly method can be understood by using a cost function to compare to alternative fabrication methods.
ER  - 

TY  - CONF
TI  - Human Pose Estimation in Presence of Occlusion Using Depth Camera Sensors, in Human-Robot Coexistence Scenarios
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - A. Casalino
AU  - S. Guzman
AU  - A. Maria Zanchettin
AU  - P. Rocco
PY  - 2018
KW  - cameras
KW  - human-robot interaction
KW  - image filtering
KW  - image sensors
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - robot vision
KW  - human-robot coexistence scenario
KW  - collaborative robotics
KW  - industrial scenario
KW  - vision sensors
KW  - cognitive software layers
KW  - human intentions
KW  - human pose estimation algorithms
KW  - partial occlusion
KW  - dual arm robot
KW  - depth camera sensors
KW  - particle filter techniques
KW  - Pose estimation
KW  - Kinematics
KW  - Service robots
KW  - Mathematical model
KW  - Collaboration
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593816
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Collaborative robotics over the last few years has gained increasing interest in the industrial scenario. Co-bots can be equipped with vision sensors and cognitive software layers, allowing the robot to figure out human intentions. To make this level of perception possible, human pose estimation algorithms are required. Several techniques have been already proposed to tackle this problem, which however present some weaknesses in particular when occlusions occur. This work proposes an algorithm for human pose estimation in the situations of partial occlusion, based on particle filter techniques. We have proved its validity in a realistic human-robot coexistence scenario, where a human and a dual arm robot have to perform tasks in a shared workspace.
ER  - 

TY  - CONF
TI  - Feasibility of the UR5 Industrial Robot for Robotic Rehabilitation of the Upper Limbs After Stroke
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - E. Kyrkjebø
AU  - M. Johan Laastad
AU  - Ø. Stavdahl
PY  - 2018
KW  - human-robot interaction
KW  - industrial robots
KW  - injuries
KW  - medical robotics
KW  - motion control
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - human-robot collaboration
KW  - upper limbs
KW  - robot-assisted therapy
KW  - rehabilitation treatment
KW  - robotic rehabilitation devices
KW  - high-effort one-to-one interactions
KW  - physical rehabilitation
KW  - stroke patients
KW  - UR5 collaborative industrial robot
KW  - therapeutic treatment
KW  - rehabilitation exercises
KW  - high-intensity movements
KW  - neurological injuries
KW  - Service robots
KW  - Robot sensing systems
KW  - Training
KW  - Task analysis
KW  - Safety
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594413
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robot-assisted therapy is an emerging form of rehabilitation treatment for motor recovery of the upper limbs after neurological injuries such as stroke or spinal cord injury. Robotic rehabilitation devices have the potential to reduce the physical strain put on therapists due to the high-effort one-to-one interactions between the therapist and patient involving repetitive high-intensity movements to restore arm and hand functions. Numerous custom robotic devices have been developed in recent years to aid in physical rehabilitation of stroke patients, but most commercially available systems are high-cost devices because of low production volumes and high development costs. In this paper, we analyse the safety and functionality of the UR5 collaborative industrial robot from universal Robots equipped with an external force/torque sensor in a real-time control system for typical rehabilitation exercises. The aim of the paper is to show that a new class of general-purpose industrial robots designed for human-robot collaboration may prove a viable alternative to custom designs. Experiments show that robotic rehabilitation of the upper limbs using a standard industrial robot manipulator UR5 may be feasible. Results have the potential to make robotic rehabilitation more available as a high-quality therapeutic treatment for more patients.
ER  - 

TY  - CONF
TI  - Safety-Related Tasks Within the Set-Based Task-Priority Inverse Kinematics Framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6130
EP  - 6135
AU  - P. Di Lillo
AU  - F. Arrichiello
AU  - G. Antonelli
AU  - S. Chiaverini
PY  - 2018
KW  - collision avoidance
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - equality-based task
KW  - task-priority inverse kinematics algorithm
KW  - set-based task-priority inverse kinematics framework
KW  - Jaco2 manipulator
KW  - RGB-D sensor
KW  - obstacle detection
KW  - obstacle avoidance tasks
KW  - joint-limits
KW  - set-based tasks
KW  - operational space
KW  - robotic arm
KW  - motion control
KW  - safety-related tasks
KW  - Task analysis
KW  - Manipulators
KW  - Robot sensing systems
KW  - Kinematics
KW  - Collision avoidance
KW  - Safety
DO  - 10.1109/IROS.2018.8593884
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a framework that allows the motion control of a robotic arm automatically handling different kinds of safety-related tasks. The developed controller is based on a Task-Priority Inverse Kinematics algorithm that allows the manipulator's motion while respecting constraints defined either in the joint or in the operational space in the form of equality-based or set-based tasks. This gives the possibility to define, among the others, tasks as joint-limits, obstacle avoidance or limiting the workspace in the operational space. Additionally, an algorithm for the real-time computation of the minimum distance between the manipulator and other objects in the environment using depth measurements has been implemented, effectively allowing obstacle avoidance tasks. Experiments with a Jaco2 manipulator, operating in an environment where an RGB-D sensor is used for the obstacles detection, show the effectiveness of the developed system.
ER  - 

TY  - CONF
TI  - Model-Based Engineering, Safety Analysis and Risk Assessment for Personal Care Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6136
EP  - 6141
AU  - N. Yakymets
AU  - M. Sango
AU  - S. Dhouib
AU  - R. Gelin
PY  - 2018
KW  - control engineering computing
KW  - fault trees
KW  - humanoid robots
KW  - risk management
KW  - safety
KW  - safety-critical software
KW  - service robots
KW  - specification languages
KW  - Unified Modeling Language
KW  - model-based engineering
KW  - risk assessment
KW  - personal care robots
KW  - couple model-based system engineering
KW  - robotic system life-cycle
KW  - Papyrus UML modeler
KW  - Safety Architect
KW  - failure mode
KW  - effects analysis
KW  - fault tree analysis
KW  - safety artefacts
KW  - modeling environment
KW  - humanoid personal care robot
KW  - safety analysis
KW  - Safety
KW  - Unified modeling language
KW  - Tools
KW  - Analytical models
KW  - Risk management
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8594115
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a method and associate platform to couple model-based system engineering and safety analysis at the early phases of robotic system (RS) life-cycle. The method is compatible with IEC12100 and ISO13482. The platform is based on Papyrus UML modeler and supports RobotML, a domain specific language for RSs, as well as tools for safety analysis and risk assessment, Sophia and Safety Architect. It includes an ability (a) to model architecture of RSs; (b) to automatically run safety analysis (e.g. failure mode and effects analysis, fault tree analysis, etc.); (c) to save and reuse safety artefacts; (d) to represent safety analysis results in the modeling environment. We illustrate the proposed method by considering a humanoid personal care robot from SoftBank Robotics developed in the scope of the ROMEO2 project.
ER  - 

TY  - CONF
TI  - Computation of Safe Path Velocity for Collaborative Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6142
EP  - 6148
AU  - C. Sloth
AU  - H. G. Petersen
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - industrial robots
KW  - ISO standards
KW  - manufacturing systems
KW  - motion control
KW  - occupational safety
KW  - velocity control
KW  - safe path velocity
KW  - collaborative robot
KW  - safety requirements
KW  - collaborative method
KW  - safe collisions
KW  - point-wise maximal path velocity
KW  - post impact safety
KW  - ISO/TS 15066
KW  - power and force limiting
KW  - industrial manufacturing
KW  - Robots
KW  - Collision avoidance
KW  - Force
KW  - Safety
KW  - Collaboration
KW  - Effective mass
KW  - Limiting
DO  - 10.1109/IROS.2018.8594217
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a method for numerically computing the highest path velocity that a collaborative robot can attain, while complying with safety requirements. The safety requirements are obtained from ISO/TS 15066 that describes a collaborative method called power and force limiting, which specifies safe collisions between humans and robots. In particular, we assume that a path is given and compute the point-wise maximal path velocity that ensures a safe impact, i.e., the paper provides no considerations on the post impact safety.
ER  - 

TY  - CONF
TI  - Adversarial Learning-Based On-Line Anomaly Monitoring for Assured Autonomy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6149
EP  - 6154
AU  - N. Patel
AU  - A. Nandini Saridena
AU  - A. Choromanska
AU  - P. Krishnamurthy
AU  - F. Khorrami
PY  - 2018
KW  - learning (artificial intelligence)
KW  - object detection
KW  - remotely operated vehicles
KW  - indoor environments
KW  - Udacity dataset
KW  - image conditioned energy based generative adversarial network
KW  - on-line monitoring framework
KW  - assured autonomy
KW  - Adversarial Learning-Based On-Line Anomaly Monitoring
KW  - autonomous ground vehicle
KW  - sensor data
KW  - action condition video prediction framework
KW  - anomalous actuator commands
KW  - proper actuator commands
KW  - generative adversarial network
KW  - SFAM
KW  - system-focused anomaly detection
KW  - CFAM
KW  - controller-focused anomaly detection
KW  - sensor inputs
KW  - unmanned ground vehicle
KW  - learning-based control systems
KW  - Generators
KW  - Convolution
KW  - Actuators
KW  - Monitoring
KW  - Anomaly detection
KW  - Robot sensing systems
KW  - Computer architecture
DO  - 10.1109/IROS.2018.8593375
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper proposes an on-line monitoring framework for continuous real-time safety/security in learning-based control systems (specifically application to a unmanned ground vehicle). We monitor validity of mappings from sensor inputs to actuator commands, controller-focused anomaly detection (CFAM), and from actuator commands to sensor inputs, system-focused anomaly detection (SFAM). CFAM is an image conditioned energy based generative adversarial network (EBGAN) in which the energy based discriminator distinguishes between proper and anomalous actuator commands. SFAM is based on an action condition video prediction framework to detect anomalies between predicted and observed temporal evolution of sensor data. We demonstrate the effectiveness of the approach on our autonomous ground vehicle for indoor environments and on Udacity dataset for outdoor environments.
ER  - 

TY  - CONF
TI  - Inspection System for Automatic Measurement of Level Differences in Belt Conveyors Using Inertial Measurement Unit
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6155
EP  - 6161
AU  - A. Y. Yasutomi
AU  - H. Enoki
AU  - S. Yamaguchi
AU  - K. Tamura
PY  - 2018
KW  - belts
KW  - conveyors
KW  - inspection
KW  - maintenance engineering
KW  - sensors
KW  - transportation
KW  - belt conveyor inspection system
KW  - liquid container
KW  - conveyor maintenance
KW  - sensor progressing
KW  - cost-effective
KW  - human errors
KW  - automatic inspection
KW  - system disassembly
KW  - spillage
KW  - belt lines
KW  - transport systems
KW  - inertial measurement unit
KW  - automatic measurement
KW  - Belts
KW  - Inspection
KW  - Angular velocity
KW  - Batteries
KW  - Containers
KW  - Fixtures
KW  - Event detection
DO  - 10.1109/IROS.2018.8593906
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Belt conveyors are transport systems composed by a plurality of belt lines. When those systems are used to transport fragile materials or liquid containers, it is necessary to minimize the oscillations of the transported objects in order to avoid damage, spillage and particle degradation. Those oscillations are regularly caused by steps (i.e. differences in level) at the joints of the belt lines, and for that reason, it is necessary to inspect those steps during installation and maintenance. Regular inspections involve the visual verification of the steps, which stops production, takes significant time, occasionally requires system disassembly and is subjected to human errors. In this paper, a novel belt conveyor inspection system which is able to detect and measure the steps at the joints of the belt lines is presented. This system consists in the acquirement of data of the belt conveyor with an inertial measurement unit (IMU), and the processing of this data with original algorithms for zero offset filtering, sensor progressing direction detection, step event detection and step height calculation. The presented system had successfully detected and measured the steps of a complex belt conveyor with an accuracy of ±0.3 mm. It is demonstrated that this cost-effective and ready to use system enables an automatic and prompt inspection of the whole belt conveyor system at once, thus reducing the workload, time and errors of the belt conveyor inspection.
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning on Autonomous Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - D. Isele
AU  - A. Nakhaei
AU  - K. Fujimura
PY  - 2018
KW  - learning (artificial intelligence)
KW  - remotely operated vehicles
KW  - road traffic control
KW  - road vehicles
KW  - intersection handling behaviors
KW  - autonomous vehicle
KW  - safety critical applications
KW  - learning process
KW  - safe reinforcement learning
KW  - Safety
KW  - Autonomous vehicles
KW  - Trajectory
KW  - Games
KW  - Pipelines
KW  - Noise measurement
KW  - Standards
DO  - 10.1109/IROS.2018.8593420
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There have been numerous advances in reinforcement learning, but the typically unconstrained exploration of the learning process prevents the adoption of these methods in many safety critical applications. Recent work in safe reinforcement learning uses idealized models to achieve their guarantees, but these models do not easily accommodate the stochasticity or high-dimensionality of real world systems. We investigate how prediction provides a general and intuitive framework to constraint exploration, and show how it can be used to safely learn intersection handling behaviors on an autonomous vehicle.
ER  - 

TY  - CONF
TI  - Distributed Direction of Arrival Estimation-Aided Cyberattack Detection in Networked Multi-Robot Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Lee
AU  - B. Min
PY  - 2018
KW  - control engineering computing
KW  - direction-of-arrival estimation
KW  - multi-robot systems
KW  - networked control systems
KW  - security of data
KW  - statistical analysis
KW  - networked multirobot systems
KW  - parametric statistical tool
KW  - wireless network
KW  - DoA-aided attack detection scheme
KW  - multirobot testbed
KW  - distributed direction of arrival estimation-aided cyberattack detection
KW  - Direction-of-arrival estimation
KW  - Robot sensing systems
KW  - Multi-robot systems
KW  - Antenna measurements
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594465
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study proposes a Direction of Arrival (DoA)-aided attack detection scheme to identify cyberattacks on networked multi-robot systems. For each agent, a local estimator is designed to generate robust residuals, and a parametric statistical tool corresponding to the residuals is elaborated to build sensitive decision rules. These locally stored residuals and thresholds are shared between robots via a wireless network, allowing a multi-robot system to complete its mission in the presence of one or more compromised agents. The proposed DoA-aided attack detection scheme is tested on a multi-robot testbed with a team of 10 robots. Experimental results demonstrate that the proposed detection scheme enables each robot to identify malicious activities without shearing the global coordination.
ER  - 

TY  - CONF
TI  - Evaluating Robotic Devices of Non-Wearable Transferring Aids Using Whole-Body Robotic Simulator of the Elderly
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Matsumoto
AU  - K. Ogata
AU  - I. Kajitani
AU  - K. Homma
AU  - Y. Wakita
PY  - 2018
KW  - assisted living
KW  - geriatrics
KW  - handicapped aids
KW  - medical robotics
KW  - patient care
KW  - service robots
KW  - quantitative physical evaluation
KW  - whole-body robotic system
KW  - assistive robotic devices
KW  - physical assistance
KW  - nursing care
KW  - elderly person
KW  - whole-body robotic simulator
KW  - nonwearable transferring aids
KW  - Safety
KW  - Legged locomotion
KW  - Receivers
KW  - Senior citizens
KW  - Medical services
DO  - 10.1109/IROS.2018.8594022
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes the development of a whole-body robotic simulator of an elderly person for evaluating robotics devices for nursing care. To improve the quality of life of the elderly persons, physical assistance such as transfer, movement, and bathroom assistance is important. It is also important to reduce the workload of caregivers in an aging society. In recent years, assistive robotic devices for nursing care have been developed and commercialized for such purposes. However, such devices have not become popular in the care facilities yet. One of the reasons is that it is still difficult to evaluate the effects of the devices on the care receivers and caregivers. In particular, it is necessary to quantitatively evaluate the effect of the devices on the human body from the viewpoint of safety and comfort. We have developed a whole-body robotic system to simulate the pose and motion of the elderly persons. The purpose of this system is to realize quantitative physical evaluation of robotics devices for nursing care of the human body. The experimental results of the preliminary evaluation of assistive robotic devices are also presented.
ER  - 

TY  - CONF
TI  - Automated Control of Multifunctional Magnetic Spores Using Fluorescence Imaging for Microrobotic Cargo Delivery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - L. Yang
AU  - Y. Zhang
AU  - C. Vong
AU  - L. Zhang
PY  - 2018
KW  - cellular transport
KW  - collision avoidance
KW  - fluorescence
KW  - goods distribution
KW  - microrobots
KW  - mobile robots
KW  - nanoparticles
KW  - particle swarm optimisation
KW  - path planning
KW  - position control
KW  - quantum dots
KW  - tracking
KW  - trajectory control
KW  - Mag-Spore
KW  - fluorescence microscopy
KW  - fluorescence imaging
KW  - observer-based trajectory tracking controller
KW  - multifunctional magnetic Spores
KW  - microrobotic cargo delivery possesses
KW  - complex environmental conditions
KW  - obstructed optical feedback
KW  - automated control approach
KW  - microrobotic cargo carrier
KW  - multifunctional magnetic spore
KW  - Magnetic resonance imaging
KW  - Automation
KW  - Magnetic multilayers
KW  - Carbon
KW  - Stem cells
KW  - Optimization
DO  - 10.1109/IROS.2018.8593790
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Microrobotic cargo delivery possesses promising perspective for precision medicine, and has attracted much attention recently. However, its automation remains challenging, especially with complex environmental conditions, such as obstacles and obstructed optical feedback. In this paper, we propose an automated control approach for a new microrobotic cargo carrier, i. e. the multifunctional magnetic spore (Mag-Spore). By surface functionalization of the spore with Fe3O4 nanoparticles and carbon quantum dots, it can be remotely actuated and tracked by an electromagnetic coil system and the fluorescence microscopy, respectively. Our strategy utilizes fluorescence imaging for vision feedback, which enhances the recognition and tracking of Mag-Spores and cells. Then, information of the cells and Mag-Spores for planning and control is identified via image processing, and an optimal path planner with obstacle avoidance capability is designed based on the Particle Swarm Optimization (PSO)algorithm. To make the Mag-Spore follow the planed path accurately, an observer-based trajectory tracking controller is synthesized. Simulations and experiments are conducted to demonstrate the effectiveness of the proposed control approach.
ER  - 

TY  - CONF
TI  - Collectives of Spinning Mobile Microrobots for Navigation and Object Manipulation at the Air-Water Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - W. Wang
AU  - V. Kishore
AU  - L. Koens
AU  - E. Lauga
AU  - M. Sitti
PY  - 2018
KW  - microrobots
KW  - mobile robots
KW  - microchannels
KW  - pairwise interactions
KW  - local interactions
KW  - collective behaviors
KW  - mobile microrobot collectives
KW  - multiple spinning microrafts
KW  - air-water interface
KW  - object manipulation
KW  - spinning mobile microrobots
KW  - size 100.0 mum
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8593519
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We use multiple spinning micro-rafts at the air-water interface as mobile microrobot collectives and present here their collective behaviors, including navigating around anchored obstacles, and trapping and transporting floating objects. The 3D-printed micro-rafts are circular disKS of 100 μm in diameter and have parametrically defined undulating edge profile. The study of their local interactions, manifested by the pairwise interactions between micro-rafts, reveals competing magnetic and capillary interactions that keep the collectives in their dynamic state. Using collectives of 7, 19, and 36 micro-rafts and micro-channels between millimeter-sized posts, we demonstrate the effects of the size of the collectives, the size of the obstacles, and maneuver strategies on the collective navigation. Employing methods from information theory, we show that the pairwise mutual information of the collectives increases significantly during the channel-crossing as a result of the additional constraints of the channel walls on the collectives. Finally, we demonstrate the trapping of 1-mm-diameter polystyrene bead and the trapping and transporting of 600~μm-wide pm.
ER  - 

TY  - CONF
TI  - Fabrication and Locomotion of Flexible Nanoswimmers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6193
EP  - 6198
AU  - B. Jang
AU  - A. Aho
AU  - B. J. Nelson
AU  - S. Pané
PY  - 2018
KW  - hinges
KW  - magnetic fields
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - 1-link swimmer
KW  - semisoft tail
KW  - nanoscale swimmers
KW  - sophisticated locomotion mechanisms
KW  - hinges
KW  - soft joints
KW  - small-scale robots
KW  - flexible nanoswimmers
KW  - magnetic fields
KW  - oscillating magnetic field frequency
KW  - undulatory locomotion
KW  - 2-link swimmer
KW  - soft hinge
KW  - rigid magnetic head
KW  - Nickel
KW  - Magnetic fields
KW  - Gold
KW  - Resonant frequency
KW  - Magnetosphere
KW  - Fabrication
KW  - Fasteners
DO  - 10.1109/IROS.2018.8594047
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Small-scale robots with soft joints and hinges have recently attracted interest because these components allow for more sophisticated locomotion mechanisms. Here, we investigate two different types of nanoscale swimmers as depicted in Figure 1. One consists of a rigid magnetic head linked to a semi-soft tail (1-link swimmer). Another consists of a rigid magnetic head and tail connected by a soft hinge (2-link swimmer). Both swimmers exhibit undulatory locomotion under an applied oscillating magnetic field. The speeds of the swimmers are assessed as a function of the oscillating magnetic field frequency and the sweeping angle. We find that a resonance-like frequency increases as the length decreases, and, in general, the speed increases as the sweeping angle increases. Last, we show that 2-link swimmers can also swim in a corkscrew-like pattern under rotating magnetic fields.
ER  - 

TY  - CONF
TI  - Gait Learning for Soft Microrobots Controlled by Light Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6199
EP  - 6206
AU  - A. von Rohr
AU  - S. Trimpe
AU  - A. Marco
AU  - P. Fischer
AU  - S. Palagi
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - control system synthesis
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - microrobots
KW  - optimisation
KW  - self-adaptive microrobotic systems
KW  - light-controlled soft microrobots
KW  - probabilistic learning control
KW  - gait learning
KW  - light fields
KW  - analytical control design
KW  - gait optimization
KW  - locomotion models
KW  - data-driven approaches
KW  - Bayesian optimization
KW  - Gaussian processes
KW  - BO
KW  - GPs
KW  - Robots
KW  - Cost function
KW  - Kernel
KW  - Strain
KW  - Laser beams
KW  - Tuning
DO  - 10.1109/IROS.2018.8594092
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft microrobots based on photoresponsive materials and controlled by light fields can generate a variety of different gaits. This inherent flexibility can be exploited to maximize their locomotion performance in a given environment and used to adapt them to changing conditions. Albeit, because of the lack of accurate locomotion models, and given the intrinsic variability among microrobots, analytical control design is not possible. Common data-driven approaches, on the other hand, require running prohibitive numbers of experiments and lead to very sample-specific results. Here we propose a probabilistic learning approach for light-controlled soft microrobots based on Bayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach results in a learning scheme that is data-efficient, enabling gait optimization with a limited experimental budget, and robust against differences among microrobot samples. These features are obtained by designing the learning scheme through the comparison of different GP priors and BO settings on a semi-synthetic data set. The developed learning scheme is validated in microrobot experiments, resulting in a 115% improvement in a microrobot's locomotion performance with an experimental budget of only 20 tests. These encouraging results lead the way toward self-adaptive microrobotic systems based on light-controlled soft microrobots and probabilistic learning control.
ER  - 

TY  - CONF
TI  - A Novel Monocular-Based Navigation Approach for UAV Autonomous Transmission-Line Inspection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - J. Bian
AU  - X. Hui
AU  - X. Zhao
AU  - M. Tan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - image registration
KW  - inspection
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - path planning
KW  - poles and towers
KW  - power overhead lines
KW  - robot vision
KW  - UAV autonomous navigation approach
KW  - pan-tilt monocular-based navigation scheme
KW  - neural network
KW  - homography matrix
KW  - distance variation
KW  - point set registration model
KW  - tower detection
KW  - overhead transmission lines
KW  - UAV autonomous transmission-line inspection
KW  - Poles and towers
KW  - Inspection
KW  - Navigation
KW  - Power transmission lines
KW  - Kernel
KW  - Cameras
KW  - Safety
DO  - 10.1109/IROS.2018.8593926
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a unique and robust UAV autonomous navigation approach along one side of overhead transmission lines for inspection. To this end, we establish a perspective model and develop a novel Pan/Tilt monocular-based navigation scheme. Simultaneously, the following three key issues are addressed. First, to locate the effective landmark - transmission tower timely and reliably, we customize a neural network for tower detection and combine it with a fast and smooth tracking. Second, to provide UAV with a robust and precise heading, we detect the transmission lines and compute and optimize their vanishing point. Third, to keep a safe distance from transmission lines, we optimize a homography matrix to restore the parallel nature of transmission lines and perceive the distance variation by a point set registration model. Finally, by the designed UAV platform, we test the whole system in a real-world transmission-line inspection scenario under different weather condition and achieve an encouraging result. Our approach provides great flexibility for refined inspection and effectively improves inspection safety.
ER  - 

TY  - CONF
TI  - Ceiling Effects for Surface Locomotion of Small Rotorcraft
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6214
EP  - 6219
AU  - Y. H. Hsiao
AU  - P. Chirarattananon
PY  - 2018
KW  - aerodynamics
KW  - aerospace robotics
KW  - helicopters
KW  - mobile robots
KW  - propellers
KW  - small rotorcraft
KW  - ceiling effects
KW  - surface locomotion
KW  - energy saving strategy
KW  - flying robots
KW  - spinning propeller
KW  - classical momentum theory
KW  - blade element method
KW  - bimodal aerial locomotion
KW  - Propellers
KW  - Robots
KW  - Blades
KW  - Rotors
KW  - Aerodynamics
KW  - Spinning
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593726
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motivated by the potential of bimodal aerial and surface locomotion as an energy saving strategy for small flying robots, we investigate the effects of a flat overhang surface in the vicinity of a spinning propeller. We employ the classical momentum theory and the blade element method to describe the “ceiling effects” in regards to the generated thrust, power, and rotational speed of the propeller in terms of a normalized distance between the ceiling and the propeller. Validating experiments were performed on a benchtop setup, and the results are in agreement with the proposed models. The presence of a ceiling was found to reduce the power consumption by more than a factor of three for the same thrust force. Overall, our findings show promise, paving the way for the use of perching maneuvers by small rotorcraft to extend their missions.
ER  - 

TY  - CONF
TI  - Autonomous Grasping Robotic Aerial System for Perching (AGRASP)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. M. Popek
AU  - M. S. Johannes
AU  - K. C. Wolfe
AU  - R. A. Hegeman
AU  - J. M. Hatch
AU  - J. L. Moore
AU  - K. D. Katyal
AU  - B. Y. Yeh
AU  - R. J. Bamberger
PY  - 2018
KW  - autonomous aerial vehicles
KW  - biomimetics
KW  - control system synthesis
KW  - helicopters
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - sensors
KW  - AGRASP
KW  - multirotor aerial vehicles
KW  - robotics perception
KW  - vision-based path planning
KW  - highly-constrained sensor
KW  - autonomous grasping robotic aerial system for perching
KW  - biomimetically-inspired manipulation
KW  - perch structures
KW  - innovative manipulator design
KW  - active grasp
KW  - passive grip
KW  - quadrotor autonomously detection
KW  - onboard sensing
KW  - onboard processing
KW  - Manipulators
KW  - Tendons
KW  - Robot sensing systems
KW  - Bars
KW  - Grasping
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593669
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an autonomous perching concept for multirotor aerial vehicles. The Autonomous Grasping Robotic Aerial System for Perching (AGRASP)represents a novel integration of robotics perception, vision-based path planning, and biomimetically-inspired manipulation on a small, lightweight aerial robot with highly-constrained sensor and processing capacity. Computationally lightweight perception algorithms pull candidate perch structures out of a complex environment with no a priori knowledge of the operational space. The innovative manipulator design combines both active grasp and passive grip enabling it to maintain hold on the perch even with all power off. We experimentally demonstrate, for the first time, a quadrotor autonomously detecting and landing on a perch relying solely on onboard sensing and processing.
ER  - 

TY  - CONF
TI  - Energy-Efficient Trajectory Generation for a Hexarotor with Dual- Tilting Propellers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6226
EP  - 6232
AU  - F. Morbidi
AU  - D. Bicego
AU  - M. Ryll
AU  - A. Franchi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - matrix algebra
KW  - optimal control
KW  - propellers
KW  - trajectory control
KW  - hexarotor
KW  - maneuverability
KW  - control allocation matrix
KW  - brushless motors
KW  - angular accelerations
KW  - optimal control problem
KW  - underactuation degree
KW  - dual- tilting propellers
KW  - energy-efficient trajectory generation
KW  - Propellers
KW  - Trajectory
KW  - Brushless motors
KW  - Batteries
KW  - Silicon
KW  - Force
KW  - Resource management
DO  - 10.1109/IROS.2018.8594419
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we consider a non-conventional hexarotor whose propellers can be simultaneously tilted about two orthogonal axes: in this way, its underactuation degree can be easily adapted to the task at hand. For a given tilt profile, the minimum-energy trajectory between two prescribed boundary states is explicitly determined by solving an optimal control problem with respect to the angular accelerations of the six brushless motors. We also perform, for the first time, a systematic study of the singularities of the control allocation matrix of the hexarotor, showing the presence of subtle singular configurations that should be carefully avoided in the design phase. Numerical experiments conducted with the FAST-Hex platform illustrate the theory and delineate the pros and cons of dual-tilting paradigm in terms of maneuverability and energy efficiency.
ER  - 

TY  - CONF
TI  - Towards Autonomous Stratospheric Flight: A Generic Global System Identification Framework for Fixed-Wing Platforms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6233
EP  - 6240
AU  - J. Lee
AU  - T. Muskardin
AU  - C. R. Pacz
AU  - P. Oettershagen
AU  - T. Stastny
AU  - I. Sa
AU  - R. Siegwart
AU  - K. Kondak
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - error analysis
KW  - interpolation
KW  - Mach number
KW  - parameter estimation
KW  - Mach numbers
KW  - parameter identification techniques
KW  - fixed-wing platforms
KW  - flight test data
KW  - aerodynamic model
KW  - autonomous stratospheric flight
KW  - generic global system identification
KW  - high altitude long endurance fixed-wing aerial vehicles
KW  - extrapolation analysis
KW  - error analysis
KW  - autonomous missions
KW  - time efficient model
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Aircraft
KW  - Mathematical model
KW  - Databases
KW  - Data models
KW  - Unmanned aerial vehicles
DO  - 10.1109/IROS.2018.8594126
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - System identification of High Altitude Long Endurance fixed-wing aerial vehicles is challenging as its operating flight envelope covers wide ranges of altitudes and Mach numbers. We present a new global system identification framework geared towards such fixed-wing aerial platforms where the aim is to build a global aerodynamic model without many repetitions of local system identification procedures or the use of any aerodynamic database. Instead we apply parameter identification techniques to virtually created system identification data and update the identified parameters with available flight test data. The proposed framework was evaluated using data set outside the flight envelope of the available flight test data, i.e. at different airspeeds considering both interpolation and extrapolation scenarios. The error analysis has shown that the obtained longitudinal aerodynamic model can accurately predict the pitch rate and pitch angle, mostly within a tolerance of +1.5 degrees/s and +2 degrees respectively. Such a cost and time efficient model development framework enables high fidelity simulation and precise control which ultimately leads to higher success rates in autonomous missions.
ER  - 

TY  - CONF
TI  - Design and Implementation of Cloud-Like Soft Drone S-Cloud
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Hwan Song
AU  - H. Wook Shon
AU  - G. Yang Yeon
AU  - H. Ryeol Choi
PY  - 2018
KW  - aerodynamics
KW  - airships
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - flow control
KW  - helium
KW  - prototypes
KW  - rotors (mechanical)
KW  - soft blimp part
KW  - center-pierced torus-shaped part
KW  - flow control mechanism
KW  - co-axial rotors
KW  - 2-axis crossed flaps
KW  - cloud-like soft drone S-cloud
KW  - translational motion
KW  - helium gas
KW  - collision damage
KW  - altitude control
KW  - attitude control
KW  - vehicle translational movements
KW  - Newton-Euler formulation
KW  - prototypes
KW  - He
KW  - Rotors
KW  - Force
KW  - Drones
KW  - Helium
KW  - Vehicle dynamics
KW  - Buoyancy
DO  - 10.1109/IROS.2018.8593601
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study presents a new drone, called S-CLOUD, developed for safe and long flight time. It provides 3-axial (x, y, and z)translational motion and stable hovering for more than an hour after takeoff. S-CLOUD consists of two parts; soft blimp part and driving one. The soft blimp is a center-pierced torus-shaped part filled with Helium gas. Thus, it is safe to fly near people because it is light and soft, and all its rotating parts are at the center of the vehicle, which does not get damaged on collision. The driving part is plugged into the center of the soft blimp and includes the flow control mechanism, which consists of co-axial rotors and 2-axis crossed flaps. It controls the altitude, attitude, and translational movements of the vehicle. Its dynamic and reaction features against disturbances are derived using Newton-Euler formulation, and the simulation results are discussed. Finally, a prototype of S-CLOUD is fabricated and its feasibility is experimentally validated with practical applications.
ER  - 

TY  - CONF
TI  - Recovery Control for Quadrotor UAV Colliding with a Pole
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6247
EP  - 6254
AU  - G. Dicker
AU  - I. Sharf
AU  - P. Rustagi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - collision avoidance
KW  - helicopters
KW  - mobile robots
KW  - robot dynamics
KW  - robot vision
KW  - telerobotics
KW  - inertial onboard sensing
KW  - propeller-protected quadrotor UAV
KW  - collision recovery control solutions
KW  - poles
KW  - operator error
KW  - wind gusts
KW  - onboard cameras
KW  - microUAVs
KW  - air quality measurement
KW  - civil infrastructure inspection
KW  - police surveillance
KW  - disaster response
KW  - postcollision dynamics
KW  - onboard vision failure
KW  - Force
KW  - Collision avoidance
KW  - Mathematical model
KW  - Geometry
KW  - Drones
KW  - Aerodynamics
KW  - Propellers
DO  - 10.1109/IROS.2018.8594512
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Small quadrotor UAVs are projected to fly increasingly in urban environments for a wide variety of applications such as disaster response, police surveillance, civil infrastructure inspection, and air quality measurement. Micro UAVs can detect and avoid obstacles using onboard cameras; nevertheless, disturbances such as wind gusts, operator error, or failure of onboard vision can still result in dangerous collisions with objects. In the urban setting, the most predominant obstacles are walls and poles. With the aim of developing collision recovery control solutions for quadrotor UAVs, this paper investigates the collision dynamics between a propeller-protected quadrotor UAV and a vertical pole. Simulations provide insight into a quadrotor's post-collision dynamics and experimental trials demonstrate the feasibility of autonomously recovering to stable flight using only inertial onboard sensing in real-time.
ER  - 

TY  - CONF
TI  - ArduSoar: An Open-Source Thermalling Controller for Resource-Constrained Autopilots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6255
EP  - 6262
AU  - S. Tabor
AU  - I. Guilliard
AU  - A. Kolobov
PY  - 2018
KW  - aerospace components
KW  - aerospace simulation
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - resource-constrained autopilots
KW  - autonomous soaring capability
KW  - soaring controller
KW  - autopilot software suite
KW  - algorithmic standpoint
KW  - ArduPlane autopilot
KW  - parameter tuning
KW  - open-source thermalling controller
KW  - fixed-wing UAV
KW  - ArduSoars robustness
KW  - Aircraft
KW  - Atmospheric modeling
KW  - Computational modeling
KW  - Kalman filters
KW  - Mathematical model
KW  - Heating systems
KW  - Earth
DO  - 10.1109/IROS.2018.8593510
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous soaring capability has the potential to significantly increase time aloft for fixed-wing UAVs. In this paper, we introduce ArduSoar, the first soaring controller integrated into a major autopilot software suite for small UAVs. We describe ArduSoar from the algorithmic standpoint, outline its integration with the ArduPlane autopilot, discuss parameter tuning for it, and conduct a series of flight tests on real sUAVs that show ArduSoar's robustness even in highly nonideal atmospheric conditions.
ER  - 

TY  - CONF
TI  - Incremental Learning-Based Adaptive Object Recognition for Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6263
EP  - 6268
AU  - M. O. Turkoglu
AU  - F. B. Ter Haar
AU  - N. van der Stap
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - incremental learning-based adaptive object recognition
KW  - autonomous navigation
KW  - general object interaction
KW  - human-robot teaming
KW  - robot assists
KW  - localization system
KW  - deep learning
KW  - robotic perception
KW  - mobile robotic tasks
KW  - Three-dimensional displays
KW  - Object recognition
KW  - Image segmentation
KW  - Mobile robots
KW  - Training
KW  - Semantics
DO  - 10.1109/IROS.2018.8593810
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D visual understanding of the surrounding environment is vital for successful mobile robotic tasks such as autonomous navigation or general object interaction. However, current systems have limited perceptual capabilities in the sense that they are not very well adaptable to unknown environments. Human operators, on the other hand, are experts in adapting to previously unknown information. Hence, human-robot teaming in which the human helps the robot to adapt to new environments and the robot assists in automated object recognition to efficiently feed the control environment of the operator is advantageous. In this work, we propose an object recognition and localization system for mobile robots, based on deep learning, and we study the adaptation of the resulting robotic perception to a new environment. We propose two methods to teach the robot a new object category: using prior knowledge and using limited operator input. We conducted several experiments to show the feasibility of proposed methods.
ER  - 

TY  - CONF
TI  - Object Detection and Pose Estimation Based on Convolutional Neural Networks Trained with Synthetic Data
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6269
EP  - 6276
AU  - J. Josifovski
AU  - M. Kerzel
AU  - C. Pregizer
AU  - L. Posniak
AU  - S. Wermter
PY  - 2018
KW  - convolutional neural nets
KW  - image resolution
KW  - image texture
KW  - object detection
KW  - object recognition
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - robot vision
KW  - solid modelling
KW  - instance-based object detection
KW  - fine pose estimation
KW  - robotic tasks
KW  - CNN-based approaches
KW  - general object recognition tasks
KW  - fully-annotated training images
KW  - neural models
KW  - interest-point-based approaches
KW  - category-based coarse pose estimation
KW  - fine-resolution instance-based 3D pose estimation
KW  - convolutional neural networks
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Pose estimation
KW  - Training
KW  - Data models
KW  - Training data
DO  - 10.1109/IROS.2018.8594379
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Instance-based object detection and fine pose estimation is an active research problem in computer vision. While the traditional interest-point-based approaches for pose estimation are precise, their applicability in robotic tasks relies on controlled environments and rigid objects with detailed textures. CNN-based approaches, on the other hand, have shown impressive results in uncontrolled environments for more general object recognition tasks like category-based coarse pose estimation, but the need of large datasets of fully-annotated training images makes them unfavourable for tasks like instance-based pose estimation. We present a novel approach that combines the robustness of CNNs with a fine-resolution instance-based 3D pose estimation, where the model is trained with fully-annotated synthetic training data, generated automatically from the 3D models of the objects. We propose an experimental setup in which we can carefully examine how the model trained with synthetic data performs on real images of the objects. Results show that the proposed model can be trained only with synthetic renderings of the objects' 3D models and still be successfully applied on images of the real objects, with precision suitable for robotic tasks like object grasping. Based on the results, we present more general insights about training neural models with synthetic images for application on real-world images.
ER  - 

TY  - CONF
TI  - Towards Event-Driven Object Detection with Off-the-Shelf Deep Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Iacono
AU  - S. Weber
AU  - A. Glover
AU  - C. Bartolozzi
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - data compression
KW  - data visualisation
KW  - humanoid robots
KW  - image colour analysis
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - data compression
KW  - visual algorithms
KW  - event-driven object detection
KW  - iCub robotic platform
KW  - mature frame-based algorithms
KW  - bootstraps event-based dataset annotation
KW  - temporal integration
KW  - visual events
KW  - off-the-shelf deep-learning
KW  - compressed event-camera data
KW  - recognition algorithms
KW  - visual technologies
KW  - dense arrays
KW  - moving objects
KW  - contrast changes
KW  - pixel data
KW  - dynamic range
KW  - computer vision
KW  - Cameras
KW  - Robot vision systems
KW  - Visualization
KW  - Training
KW  - Object detection
DO  - 10.1109/IROS.2018.8594119
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Event cameras are an emerging technology in computer vision, offering extremely low latency and bandwidth, as well as a high temporal resolution and dynamic range. Inherent data compression is achieved as pixel data is only produced by contrast changes at the edges of moving objects. However, current trends in state-of-the-art visual algorithms rely on deep-learning with networks designed to process colour and intensity information contained in dense arrays, but are notoriously computationally heavy. While the combination of these visual technologies could lead to fast, efficient, and accurate detection and recognition algorithms, it is uncertain whether the compressed event-camera data actually contain the required information for these techniques to discriminate between objects and a cluttered background. This paper presents a pilot study in which off-the-shelf deep-learning is applied to visual events for object detection on the iCub robotic platform, and analyses the impact of temporal integration of the event data. We also present a novel pipeline that bootstraps event-based dataset annotation from mature frame-based algorithms, in order to more quickly generate the required datasets.
ER  - 

TY  - CONF
TI  - Material Recognition Using a Capacitive Proximity Sensor with Flexible Spatial Resolution
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 6284
EP  - 6290
AU  - H. Alagi
AU  - A. Heiligl
AU  - S. E. Navarro
AU  - T. Kroegerl
AU  - B. Hein
PY  - 2018
KW  - capacitive sensors
KW  - dielectric materials
KW  - mobile robots
KW  - neural nets
KW  - tactile sensors
KW  - conductive dielectric materials
KW  - artificial neural network
KW  - data frames
KW  - electrode combinations
KW  - flexible spatial resolution
KW  - capacitive proximity sensor
KW  - nonconductive dielectric materials
KW  - data sets
KW  - material recognition
KW  - exciter frequency
KW  - capacitive tactile
KW  - Electrodes
KW  - Robot sensing systems
KW  - Permittivity
KW  - Spatial resolution
KW  - Permittivity measurement
KW  - Shape
DO  - 10.1109/IROS.2018.8593789
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present an approach for material recognition using capacitive tactile and proximity sensors. By variating the spatial resolution and the exciter frequency during the measurement in mutual capacitive mode, information about the dielectrical properties of different objects was captured and provided as data frames. For material recognition an artificial neural network was set up and fed with various data sets of different electrode combinations and exciter frequencies. The influence of the electrode combinations and shapes on the recognition accuracy was investigated. It is shown that seven objects of conductive and non-conductive dielectric materials have been ranged with an overall accuracy of about 71%-94%.
ER  - 

TY  - CONF
TI  - Interactive Training of Object Detection Without ImageNet
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - E. Martinson
PY  - 2018
KW  - human computer interaction
KW  - interactive systems
KW  - object detection
KW  - robot vision
KW  - service robots
KW  - ImageNet
KW  - robotic tasks
KW  - service robots operating
KW  - robot perception
KW  - interactive training process
KW  - zero hand labeling
KW  - object detection
KW  - Robots
KW  - Training
KW  - Labeling
KW  - Object detection
KW  - Task analysis
KW  - Image segmentation
KW  - Cameras
DO  - 10.1109/IROS.2018.8593614
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For many robotic tasks, particularly those of service robots operating in human environments, the scope of object detection needs is greater than the available data. Either public datasets do not contain the entire set of objects needed for the task, and/or it is a commercial application that cannot use public datasets for training. Instead of hiring people to hand-label more data to support the integration of new objects into robot perception, we propose an interactive training process requiring zero hand labeling. With as little as 4 minutes of interaction with the robot per object, we demonstrate 99% precision and 57% recall in stationary object detection tasks.
ER  - 


