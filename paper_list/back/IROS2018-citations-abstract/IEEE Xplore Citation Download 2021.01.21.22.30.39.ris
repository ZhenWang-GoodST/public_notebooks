TY  - CONF
TI  - Estimating Achievable Range of Ground Robots Operating on Single Battery Discharge for Operational Efficacy Amelioration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3991
EP  - 3998
AU  - K. Tiwari
AU  - X. Xiao
AU  - N. Y. Chong
PY  - 2018
KW  - mobile robots
KW  - estimation error
KW  - single battery discharge
KW  - operational efficacy
KW  - mobile robots
KW  - active pursuit
KW  - law enforcement
KW  - plausible traversal velocity
KW  - energy utilization
KW  - consumers
KW  - ancillary robotic functions
KW  - Robot sensing systems
KW  - Batteries
KW  - Mobile robots
KW  - Energy consumption
KW  - Discharges (electric)
DO  - 10.1109/IROS.2018.8593845
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.
ER  - 

TY  - CONF
TI  - Interaction-Aware Probabilistic Behavior Prediction in Urban Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3999
EP  - 4006
AU  - J. Schulz
AU  - C. Hubmann
AU  - J. LÃ¶chner
AU  - D. Burschka
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - control engineering computing
KW  - driver information systems
KW  - inference mechanisms
KW  - Markov processes
KW  - mobile robots
KW  - Monte Carlo methods
KW  - probability
KW  - road vehicles
KW  - traffic engineering computing
KW  - combinatorial scene developments
KW  - road layouts
KW  - future scenes
KW  - probabilistic forward simulation
KW  - sequential Monte Carlo inference
KW  - single agents
KW  - context-dependent motion models
KW  - complete scene
KW  - dynamic Bayesian network
KW  - probabilistic prediction framework
KW  - mutual interaction
KW  - traffic rules
KW  - road-geometry
KW  - route intentions
KW  - traffic participants
KW  - urban scenarios
KW  - complex scenarios
KW  - autonomous driving
KW  - urban environments
KW  - interaction-aware probabilistic behavior prediction
KW  - interaction-unaware physics
KW  - real-world scenarios
KW  - Trajectory
KW  - Estimation
KW  - Vehicles
KW  - Probabilistic logic
KW  - Hidden Markov models
KW  - Predictive models
KW  - Bayes methods
DO  - 10.1109/IROS.2018.8594095
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Planning for autonomous driving in complex, urban scenarios requires accurate prediction of the trajectories of surrounding traffic participants. Their future behavior depends on their route intentions, the road-geometry, traffic rules and mutual interaction, resulting in interdependencies between their trajectories. We present a probabilistic prediction framework based on a dynamic Bayesian network, which represents the state of the complete scene including all agents and respects the aforementioned dependencies. We propose Markovian, context-dependent motion models to define the interaction-aware behavior of drivers. At first, the state of the dynamic Bayesian network is estimated over time by tracking the single agents via sequential Monte Carlo inference. Secondly, we perform a probabilistic forward simulation of the network's estimated belief state to generate the different combinatorial scene developments. This provides the corresponding trajectories for the set of possible, future scenes. Our framework can handle various road layouts and number of traffic participants. We evaluate the approach in online simulations and real-world scenarios. It is shown that our interaction-aware prediction outperforms interaction-unaware physics- and map-based approaches.
ER  - 

TY  - CONF
TI  - FEM-Based Deformation Control for Dexterous Manipulation of 3D Soft Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4007
EP  - 4013
AU  - F. Ficuciello
AU  - A. Migliozzi
AU  - E. Coevoet
AU  - A. Petit
AU  - C. Duriez
PY  - 2018
KW  - control engineering computing
KW  - dexterous manipulators
KW  - elasticity
KW  - finite element analysis
KW  - force sensors
KW  - mobile robots
KW  - robot vision
KW  - solid modelling
KW  - finite element method
KW  - Lagrange multipliers
KW  - elasticity parameters
KW  - 3D soft objects
KW  - dexterous manipulation
KW  - FEM-based deformation control
KW  - soft cylindrical object
KW  - manipulation task
KW  - underactuated anthropomorphic hand
KW  - force sensor
KW  - contact points
KW  - in-hand manipulation
KW  - anthropomorphic device
KW  - Strain
KW  - Finite element analysis
KW  - Robots
KW  - Deformable models
KW  - Three-dimensional displays
KW  - Biological system modeling
KW  - Estimation
DO  - 10.1109/IROS.2018.8593512
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a method for dexterous manipulation of 3D soft objects for real-time deformation control is presented, relying on Finite Element modelling. The goal is to generate proper forces on the fingertips of an anthropomorphic device during in-hand manipulation to produce desired displacements of selected control points on the object. The desired motions of the fingers are computed in real-time as an inverse solution of a Finite Element Method (FEM), the forces applied by the fingertips at the contact points being modelled by Lagrange multipliers. The elasticity parameters of the model are preliminarly estimated using a vision system and a force sensor. Experimental results are shown with an underactuated anthropomorphic hand that performs a manipulation task on a soft cylindrical object.
ER  - 

TY  - CONF
TI  - An Adaptive Robotic Gripper with L-Shape Fingers for Peg-in-Hole Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4022
EP  - 4028
AU  - K. Nie
AU  - W. Wan
AU  - K. Harada
PY  - 2018
KW  - force sensors
KW  - grippers
KW  - mobile robots
KW  - adaptive robotic gripper
KW  - L-shape finger
KW  - peg-in-hole process
KW  - force sensor
KW  - IREX
KW  - international robotic exhibition 2017
KW  - Grippers
KW  - Task analysis
KW  - Uncertainty
KW  - Manufacturing processes
KW  - Robot sensing systems
KW  - Planning
DO  - 10.1109/IROS.2018.8594370
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper develops an adaptive gripper for peg-in-hole tasks. Conventional grippers require complicated compliant mechanisms or complicated control strategy and force sensing to successfully insert pegs into holes. Different from them, this paper proposes a simple gripper with an L-shape finger as a low-cost peg-in-hole solution. The basic idea is to divide a peg-in-hole process into a preparation phase and an execution phase, and eliminate uncertainty step-by-step by pushing using the L-shape finger in the preparation phase. The robustness of the gripper for peg-in-hole tasks is examined by repeated executions for different pegs in the International Robotic Exhibition 2017 (IREX) in Tokyo. The experimental section presents details of the executions, and qualitatively shows the high performance of the proposed gripper.
ER  - 

TY  - CONF
TI  - Real-Time Grasp Planning for Multi-Fingered Hands by Finger Splitting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4045
EP  - 4052
AU  - Y. Fan
AU  - T. Tang
AU  - H. Lin
AU  - M. Tomizuka
PY  - 2018
KW  - grippers
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - time grasp planning
KW  - multifingered hands
KW  - traditional planning methods
KW  - optimal parallel grasps
KW  - dual-stage iterative optimization
KW  - contact point optimization
KW  - finger splitting
KW  - Optimization
KW  - Planning
KW  - Grippers
KW  - Search problems
KW  - Grasping
KW  - Databases
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8594369
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasp planning for multi-fingered hands is computationally expensive due to the joint-contact coupling, surface nonlinearities and high dimensionality, thus is generally not affordable for real-time implementations. Traditional planning methods by optimization, sampling or learning work well in planning for parallel grippers but remain challenging for multi-fingered hands. This paper proposes a strategy called finger splitting, to plan precision grasps for multi-fingered hands starting from optimal parallel grasps. The finger splitting is optimized by a dual-stage iterative optimization including a contact point optimization (CPO) and a palm pose optimization (PPO), to gradually split fingers and adjust both the contact points and the palm pose. The dual-stage optimization is able to consider both the object grasp quality and hand manipulability, address the nonlinearities and coupling, and achieve efficient convergence within one second. Simulation results demonstrate the effectiveness of the proposed approach. The simulation video is available at [1].
ER  - 

TY  - CONF
TI  - Interleaving Hierarchical Task Planning and Motion Constraint Testing for Dual-Arm Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4061
EP  - 4066
AU  - A. SuÃ¡rez-HernÃ¡ndez
AU  - G. AlenyÃ 
AU  - C. Torras
PY  - 2018
KW  - control engineering computing
KW  - geometry
KW  - inference mechanisms
KW  - manipulators
KW  - path planning
KW  - planning (artificial intelligence)
KW  - dual-arm manipulation
KW  - symbolic planning
KW  - reasoning capabilities
KW  - robotic manipulators
KW  - geometric constraint verification
KW  - Barrett WAM robots
KW  - geometric puzzle
KW  - hierarchical task network planner
KW  - hierarchical task planning
KW  - motion constraint testing
KW  - motion planning
KW  - Task analysis
KW  - Planning
KW  - Uncertainty
KW  - Shape
KW  - Manipulators
KW  - Cameras
DO  - 10.1109/IROS.2018.8593847
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In recent years the topic of combining motion and symbolic planning to perform complex tasks in the field of robotics has received a lot of attention. The underlying idea is to have access at once to the reasoning capabilities of a task planner and to the ability of the motion planner to verify that the plan is feasible from a physical and geometrical point of view. The present work describes a framework to perform manipulation tasks that require the use of two robotic manipulators. To do so we employ a Hierarchical Task Network (HTN) planner interleaved with geometric constraint verification. In this framework we also consider observation actions and handle noisy perceptions from a probabilistic perspective. These ideas are put into practice by means of an experimental set-up in which two Barrett WAM robots have to cooperatively solve a geometric puzzle. Our findings provide further evidence that considering explicitly physical constraints during task planning, rather than deferring their validation to the moment of execution, is advantageous in terms of execution time and breadth of situations that can be handled.
ER  - 

TY  - CONF
TI  - Sequence Pattern Extraction by Segmenting Time Series Data Using GP-HSMM with Hierarchical Dirichlet Process
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4067
EP  - 4074
AU  - M. Nagano
AU  - T. Nakamura
AU  - T. Nagai
AU  - D. Mochihashi
AU  - I. Kobayashi
AU  - M. Kaneko
PY  - 2018
KW  - Bayes methods
KW  - feature extraction
KW  - Gaussian processes
KW  - hidden Markov models
KW  - image motion analysis
KW  - image sampling
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - nonparametric statistics
KW  - time series
KW  - continuous time-series data
KW  - semiMarkov model
KW  - Gaussian processes
KW  - nonparametric models
KW  - unit motion patterns
KW  - complicated continuous motion
KW  - nonparametric Bayesian model
KW  - hierarchical Dirichlet process
KW  - hierarchical Dirichlet processes-Gaussian process
KW  - HDP-GP-HSMM
KW  - motion-capture data
KW  - sequence pattern extraction
KW  - time series data
KW  - continuous information
KW  - unit motions
KW  - unsupervised segmentation
KW  - Hidden Markov models
KW  - Motion segmentation
KW  - Gaussian processes
KW  - Bayes methods
KW  - Data models
KW  - Trajectory
KW  - Kernel
DO  - 10.1109/IROS.2018.8594029
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humans recognize perceived continuous information by dividing it into significant segments such as words and unit motions. We believe that such unsupervised segmentation is also an important ability that robots need to learn topics such as language and motions. Hence, in this paper, we propose a method for dividing continuous time-series data into segments in an unsupervised manner. To this end, we proposed a method based on a hidden semi-Markov model with Gaussian process (GP-HSMM). If Gaussian processes, which are nonparametric models, are used, unit motion patterns can be extracted from complicated continuous motion. However, this approach requires the number of classes of segments in the time-series data in advance. To overcome this problem, in this paper, we extend GP-HSMM to a nonparametric Bayesian model by introducing a hierarchical Dirichlet process (HDP) and propose the hierarchical Dirichlet processes-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). In the nonparametric Bayesian model, an infinite number of classes is assumed and it becomes difficult to estimate the parameters naively. Instead, the parameters of the proposed HDP-GP-HSMM are estimated by applying slice sampling. In the experiments, we use various synthetic and motion-capture data to show that our proposed model can estimate a more correct number of classes and achieve more accurate segmentation than baseline methods.
ER  - 

TY  - CONF
TI  - Persistent Anytime Learning of Objects from Unseen Classes
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4075
EP  - 4082
AU  - M. Denninger
AU  - R. Triebel
PY  - 2018
KW  - image classification
KW  - random forests
KW  - random forest classifier
KW  - semantic mapping
KW  - object classification
KW  - standard offline methods
KW  - incremental approach
KW  - robotic applications
KW  - data samples
KW  - Training
KW  - Vegetation
KW  - Robots
KW  - Semantics
KW  - Standards
KW  - Training data
KW  - Uncertainty
KW  - Learning and Adaptive Systems
KW  - Object Detection
KW  - Segmentation and Categorization
KW  - Online Learning
DO  - 10.1109/IROS.2018.8594165
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a fast and very effective method for object classification that is particularly suited for robotic applications such as grasping and semantic mapping. Our approach is based on a Random Forest classifier that can be trained incrementally. This has the major benefit that semantic information from new data samples can be incorporated without retraining the entire model. Even if new samples from a previously unseen class are presented, our method is able to perform efficient updates and learn a sustainable representation for this new class. Further features of our method include a very fast and memory-efficient implementation, as well as the ability to interrupt the learning process at any time without a significant performance degradation. Experiments on benchmark data for robotic applications show the clear benefits of our incremental approach and its competitiveness with standard offline methods in terms of classification accuracy.
ER  - 

TY  - CONF
TI  - Adaptive Robot Body Learning and Estimation Through Predictive Coding
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4083
EP  - 4090
AU  - P. Lanillos
AU  - G. Cheng
PY  - 2018
KW  - actuators
KW  - adaptive control
KW  - Bayes methods
KW  - Gaussian processes
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - mobile robots
KW  - regression analysis
KW  - sensor fusion
KW  - nonlinear actuators
KW  - noisy sensory information
KW  - computational perceptual model
KW  - predictive processing
KW  - arbitrary sensors
KW  - Gaussian additive noise
KW  - Gaussian process regression
KW  - robot body configuration belief
KW  - sensory prediction errors
KW  - multisensory robotic arm
KW  - additive errors
KW  - adaptive robot body learning
KW  - predictive coding
KW  - predictive functions
KW  - sensorimotor integration
KW  - human-robot interaction
KW  - sensor modalities contributions
KW  - sensory visuo-tactile perturbations
KW  - Robot sensing systems
KW  - Visualization
KW  - Estimation
KW  - Computational modeling
KW  - Adaptation models
KW  - Bio-inspired perception
KW  - body-schema
KW  - predictive processing
KW  - embodied artificial intelligence
KW  - learning and adaptive systems
KW  - humanoid robotics
DO  - 10.1109/IROS.2018.8593684
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The predictive functions that permit humans to infer their body state by sensorimotor integration are critical to perform safe interaction in complex environments. These functions are adaptive and robust to non-linear actuators and noisy sensory information. This paper introduces a computational perceptual model based on predictive processing that enables any multisensory robot to learn, infer and update its body configuration when using arbitrary sensors with Gaussian additive noise. The proposed method integrates different sources of information (tactile, visual and proprioceptive) to drive the robot belief to its current body configuration. The motivation is to provide robots with the embodied perception needed for self-calibration and safe physical human-robot interaction. We formulate body learning as obtaining the forward model that encodes the sensor values depending on the body variables, and we solve it by Gaussian process regression. We model body estimation as minimizing the discrepancy between the robot body configuration belief and the observed posterior. We minimize the variational free energy using the sensory prediction errors (sensed vs expected). In order to evaluate the model we test it on a real multi-sensory robotic arm. We show how different sensor modalities contributions, included as additive errors, improve the refinement of the body estimation and how the system adapts itself to provide the most plausible solution even when injecting strong sensory visuo-tactile perturbations. We further analyse the reliability of the model when different sensor modalities are disabled. This provides grounded evidence about the correctness of the perceptual model and shows how the robot estimates and adjusts its body configuration just by means of sensory information.
ER  - 

TY  - CONF
TI  - Online Learning of Body Orientation Control on a Humanoid Robot Using Finite Element Goal Babbling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4091
EP  - 4098
AU  - P. Loviken
AU  - N. Hemion
AU  - A. LaflaquiÃ¨re
AU  - M. Spranger
AU  - A. Cangelosi
PY  - 2018
KW  - control engineering computing
KW  - finite element analysis
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - position control
KW  - robust control
KW  - finite element goal babbling
KW  - utility function maximization
KW  - Nao humanoid robot
KW  - robust control
KW  - online learning method
KW  - FEGB
KW  - body orientation control
KW  - time 20.0 min to 30.0 min
KW  - Task analysis
KW  - Aerospace electronics
KW  - Finite element analysis
KW  - Space exploration
KW  - Humanoid robots
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593762
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - How can high dimensional robots learn general sets of skills from experience in the real world? Many previous approaches focus on maximizing a single utility function and require large datasets of experience to do this, something that is not possible to collect outside of simulation as every data point is expensive both in time and in a potential wear down of the robot. This paper addresses this question using a newly developed framework called Finite Element Goal Babbling (FEGB). FEGB is an online learning method that aims at providing general control over some measurable feature, in contrast to optimizing it to some given utility function. It generalizes standard goal babbling by breaking down the full learning problem into local sub-problems, and combining it with a planner that learns how to navigate between these subproblems. We test FEGB using a real humanoid robot Nao, and find that it could quickly learn to robustly control its body orientation. After only 20-30 minutes of training, the robot could freely move into any body orientation between lying on either side and on its back. Rapid learning of body orientation control in high dimensional real robots is largely an unexplored field of robotics, and although many challenges remain, FEGB shows a feasible approach to the problem.
ER  - 

TY  - CONF
TI  - Cost Adaptation for Robust Decentralized Swarm Behaviour
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4099
EP  - 4106
AU  - P. Henderson
AU  - M. Vertescher
AU  - D. Meger
AU  - M. Coates
PY  - 2018
KW  - computer games
KW  - control engineering computing
KW  - decentralised control
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - robot dynamics
KW  - cost adaptation
KW  - decentralized receding horizon control
KW  - multiagent settings
KW  - meta-learning process
KW  - mesh-networked swarm agents
KW  - adaptation mechanism
KW  - safer task completion
KW  - Unity3D game engine
KW  - D-RHC
KW  - robust decentralized swarm behaviour
KW  - Task analysis
KW  - Delays
KW  - Decision making
KW  - Cost function
KW  - Mesh networks
KW  - Control systems
DO  - 10.1109/IROS.2018.8594283
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Decentralized receding horizon control (D-RHC) provides a mechanism for coordination in multiagent settings without a centralized command center. However, combining a set of different goals, costs, and constraints to form an efficient optimization objective for D-RHC can be difficult. To allay this problem, we use a meta-learning process - cost adaptation - which generates the optimization objective for D-RHC to solve based on a set of human-generated priors (cost and constraint functions) and an auxiliary heuristic. We use this adaptive D-RHC method for control of mesh-networked swarm agents. This formulation allows a wide range of tasks to be encoded and can account for network delays, heterogeneous capabilities, and increasingly large swarms through the adaptation mechanism. We leverage the Unity3D game engine to build a simulator capable of introducing artificial networking failures and delays in the swarm. Using the simulator we validate our method on an example coordinated exploration task. We demonstrate that cost adaptation allows for more efficient and safer task completion under varying environment conditions and increasingly large swarm sizes. We release our simulator and code to the community for future work.
ER  - 

TY  - CONF
TI  - Active Model Learning and Diverse Action Sampling for Task and Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4107
EP  - 4114
AU  - Z. Wang
AU  - C. R. Garrett
AU  - L. P. Kaelbling
AU  - T. Lozano-PÃ©rez
PY  - 2018
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - complex domains
KW  - flexible generative planning
KW  - state-of-the-art methods
KW  - active learning
KW  - Gaussian process methods
KW  - operator effectiveness
KW  - adaptive sampling methods
KW  - diverse elements
KW  - robot configurations
KW  - object poses
KW  - newly learned models
KW  - long horizon problems
KW  - active model learning
KW  - action sampling
KW  - motion planning
KW  - sensorimotor primitives
KW  - complex long-horizon problems
KW  - continuous-space robot task
KW  - Planning
KW  - Task analysis
KW  - Level set
KW  - Robot sensing systems
KW  - Gaussian processes
KW  - Training
DO  - 10.1109/IROS.2018.8594027
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world. In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world? We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.
ER  - 

TY  - CONF
TI  - Improving Reinforcement Learning Pre-Training with Variational Dropout
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4115
EP  - 4122
AU  - T. Blau
AU  - L. Ott
AU  - F. Ramos
PY  - 2018
KW  - control engineering computing
KW  - Gaussian processes
KW  - legged locomotion
KW  - supervised learning
KW  - reinforcement learning pre-training
KW  - control policies
KW  - robotic agents
KW  - bipedal locomotion
KW  - data points
KW  - Gaussian dropout networks
KW  - variational inference
KW  - policy parameters
KW  - standard supervised learning
KW  - optimal policies
KW  - variational dropout
KW  - regularization term
KW  - RL algorithm
KW  - high-dimensional continuous control problems
KW  - Task analysis
KW  - Training
KW  - Reinforcement learning
KW  - Training data
KW  - Cloning
KW  - Supervised learning
KW  - Robots
DO  - 10.1109/IROS.2018.8594341
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning has been very successful at learning control policies for robotic agents in order to perform various tasks, such as driving around a track, navigating a maze, and bipedal locomotion. One significant drawback of reinforcement learning methods is that they require a large number of data points in order to learn good policies, a trait known as poor data efficiency or poor sample efficiency. One approach for improving sample efficiency is supervised pre-training of policies to directly clone the behavior of an expert, but this suffers from poor generalization far from the training data. We propose to improve this by using Gaussian dropout networks with a regularization term based on variational inference in the pre-training step. We show that this initializes policy parameters to significantly better values than standard supervised learning or random initialization, thus greatly reducing sample complexity compared with state-of-the-art methods, and enabling an RL algorithm to learn optimal policies for high-dimensional continuous control problems in a practical time frame.
ER  - 

TY  - CONF
TI  - A Framework for Dexterous Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4131
EP  - 4138
AU  - L. Y. Ku
AU  - J. Rogers
AU  - P. Strawser
AU  - J. Badger
AU  - E. Learned-Mille
AU  - R. Grupen
PY  - 2018
KW  - dexterous manipulators
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - dexterous manipulation
KW  - humanoid robot Robonaut-2
KW  - anthropomorphic Robonaut-2 hand
KW  - manipulation tasks
KW  - hand fan
KW  - IROS2018 fan robotic challenge
KW  - phase I modality A competition
KW  - Robots
KW  - Task analysis
KW  - Neurons
KW  - Brain modeling
KW  - Fans
KW  - Computational modeling
KW  - Grasping
DO  - 10.1109/IROS.2018.8594497
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we introduce a framework for performing dexterous manipulations on the humanoid robot Robonaut-2. This framework memorizes how actions change perceptions and can learn a sequence of actions based on demonstrations. With the anthropomorphic Robonaut-2 hand and arm, a variety of manipulation tasks such as grasping novel objects, rotating a drill for grasping, and tightening a bolt with a ratchet can be accomplished. This framework was also used to compete in the IROS2018 Fan Robotic Challenge that requires manipulating a hand fan and was a winner of the phase I modality A competition.
ER  - 

TY  - CONF
TI  - An Extrinsic Dexterity Approach to the IROS 2018 Fan Robotic Challenge
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4139
EP  - 4144
AU  - J. Kwiatkowski
AU  - J. Roberge
AU  - N. A. Nadeau
AU  - L. L'Ãcuyer-Lapierre
AU  - V. Duchaine
PY  - 2018
KW  - dexterous manipulators
KW  - grippers
KW  - motion control
KW  - tactile sensors
KW  - vibrations
KW  - extrinsic dexterity approach
KW  - IROS 2018 fan robotic challenge
KW  - Spanish folding fan
KW  - dexterous manipulation
KW  - robotic systems
KW  - external dexterity
KW  - high DoF grippers
KW  - 3D-printed adaptation
KW  - multimodal tactile sensor
KW  - Fans
KW  - Grippers
KW  - Robot kinematics
KW  - Service robots
KW  - Task analysis
KW  - End effectors
DO  - 10.1109/IROS.2018.8594224
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The 2018 IROS Fan Robotic Challenge tasked participants with programming a robot to autonomously open and close a Spanish folding fan, highlighting the obstacles still associated with the dexterous manipulation of objects for robotic systems. Since high DoFs grippers are complex to coordinate and overkill for many industrial processes, our approach used an under-actuated parallel gripper with a 3D-printed adaptation to precisely grasp the fan in such a manner that gravity could be leveraged to act on the fan to produce an extrinsic, or external, dexterity. With our approach, we completed the challenge in 12.38 seconds, resulting in a top three finish. Furthermore, using a multi-modal tactile sensor, we analyzed the vibrations in the grasp during the manipulation and were able to distinguish the opening and closing of the fan from the motion of the robot with a 83% accuracy.
ER  - 

TY  - CONF
TI  - Development of Low-Inertia High-Stiffness Manipulator LIMS2 for High-Speed Manipulation of Foldable Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4145
EP  - 4151
AU  - H. Song
AU  - Y. Kim
AU  - J. Yoon
AU  - S. Yun
AU  - J. Seo
AU  - Y. Kim
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - dexterous manipulators
KW  - elastic constants
KW  - fans
KW  - grippers
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - operating systems (computers)
KW  - protocols
KW  - low-inertia high-stiffness manipulator
KW  - high-speed manipulation
KW  - foldable objects
KW  - dual-arm robot system
KW  - LIMS2-AMBIDEX
KW  - IROS2018 Robotic Challenge
KW  - seven-degrees-of-freedom
KW  - foldable fan
KW  - Fan Robotic Challenge Phase
KW  - high-speed communication protocol
KW  - tension-amplification mechanisms
KW  - gripper
KW  - robot operating system
KW  - Xenomai
KW  - real-time development framework
KW  - EtherCAT
KW  - software framework
KW  - mass 2.63 kg
KW  - Wrist
KW  - Fans
KW  - Robots
KW  - Elbow
KW  - Shoulder
KW  - Grippers
KW  - Actuators
DO  - 10.1109/IROS.2018.8594005
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a dual-arm robot system for high-speed manipulations, which is named LIMS2-AMBIDEX and is developed to compete in the IROS2018 Robotic Challenge, is presented. It has two seven-degrees-of-freedom (DO F) lightweight arms, a three-DOF head, and a one-DOF gripper to manipulate foldable objects. Because all the heavy actuators are placed at the shoulder, it has remarkably low mass beyond the shoulder (2.63 kg), which guarantees an inherent safety at high speeds. Utilizing tension-amplification mechanisms, the high stiffness and strength are achieved, and thus it has the control performance comparable to conventional industrial manipulators. A unique three-DOF wrist mechanism, whose motions directly represent the quaternion values of the joint orientation, can manipulate objects without singular points in the entire range of motion. In order to utilize the object's inertia during rapid manipulation, the gripper was specially designed: it has a one-DOF finger to grasp the upper rib of the foldable fan and two supporting forks to grasp the bottom rib stably. For real-time performance and increased scalability, a software framework was developed based on Robot Operating System (ROS). The real-time capability is achieved by using the real-time development framework Xenomai and the high-speed communication protocol EtherCAT. As most of the algorithms are implemented in the distributed nodes using ROS, it is convenient to expand, improve, and replace the algorithms. Consequentially, the entire motion of the Fan Robotic Challenge Phase I Modality B required 1.05 s, which is substantially faster than a similar manipulation by most humans.
ER  - 

TY  - CONF
TI  - Flamen â 7 DOF Robotic Arm to Manipulate a Spanish Fan
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4152
EP  - 4157
AU  - M. Harikrishnan Nair
AU  - T. Ghanshsyam Singh
AU  - G. Chourasia
AU  - A. Das
AU  - A. Shrivastava
AU  - Z. S. Bhatt
PY  - 2018
KW  - control engineering computing
KW  - fans
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - 7-DOF robotic arm
KW  - Flamen
KW  - Flamenco dancers
KW  - manipulation
KW  - traditional fan
KW  - Spanish fan
KW  - Fans
KW  - Manipulators
KW  - Robot kinematics
KW  - Actuators
KW  - Grasping
KW  - Cameras
KW  - Actuation
KW  - Automation
KW  - Background subtraction
KW  - Contour Detection
KW  - Coordinate extraction
KW  - Filtering
KW  - Mapping
KW  - Masking
KW  - Robotic Arm
KW  - Spanish Fan
DO  - 10.1109/IROS.2018.8594129
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A Spanish fan is a hand held traditional fan which is used as an accessory and also by Flamenco dancers. The manipulation of the fan is quite difficult as it involves dynamic motion which includes opening, flapping and closing the fan along a pivotal point. The key points include the motion to be quick and the fan to be opened to the maximum degree possible without human intervention. A robotic arm with 7 Degrees of Freedom (DOF) is used to manipulate the autonomous motion. The fan placed on the table is localized and detected using a camera by background subtraction, masking and filtering; post which the contour of the fan is detected. The pixels obtained is then transformed into real life coordinates. The Dynamixel motors then traverses to the coordinates of the fan's position to grasp, open, flap, close and put the fan down.
ER  - 

TY  - CONF
TI  - IROS 2018 Fan Challenge - Team DLR Augsburg
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4158
EP  - 4163
AU  - M. SchÃ¶nheits
AU  - A. Schuster
AU  - P. GÃ¤nswÃ¼rger
AU  - L. Larsen
PY  - 2018
KW  - human-robot interaction
KW  - service robots
KW  - hot summer
KW  - blistering sun
KW  - Madrid
KW  - scorching heat
KW  - simple gesture
KW  - robotic assistant
KW  - relaxing shade
KW  - team DLR Augsburg
KW  - IROS 2018 fan challenge
KW  - tinto de verano
KW  - Fans
KW  - Grippers
KW  - Robot kinematics
KW  - End effectors
KW  - Cameras
KW  - Servomotors
DO  - 10.1109/IROS.2018.8593792
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - It's a hot summer in 2021 and the blistering sun is shining upon Madrid. You are enjoying some tinto de verano on your terraza. Sizzling in the scorching heat, you are trying to relax. With a simple gesture you call your robotic assistant to help you cool down a little bit. Without further ado, your robot provides some relaxing shade holding a parasol for you, picks up a fan autonomously and starts waving it and the gentle breeze brings you some light relief.
ER  - 

TY  - CONF
TI  - Improved Quadcopter Disturbance Rejection Using Added Angular Momentum
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4164
EP  - 4170
AU  - N. Bucki
AU  - M. W. Mueller
PY  - 2018
KW  - attitude control
KW  - control system synthesis
KW  - helicopters
KW  - position control
KW  - stability
KW  - torque control
KW  - vehicle dynamics
KW  - wheels
KW  - quadcopter disturbance rejection
KW  - added angular momentum
KW  - novel quadcopter design
KW  - added momentum wheel
KW  - enhanced stability
KW  - torque disturbance rejection capabilities
KW  - standard quadcopter
KW  - vehicle dynamics
KW  - torque disturbances
KW  - torque impulses
KW  - Wheels
KW  - Vehicle dynamics
KW  - Propellers
KW  - Torque
KW  - Attitude control
KW  - Angular velocity
KW  - State feedback
DO  - 10.1109/IROS.2018.8594109
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel quadcopter design with an added momentum wheel for enhanced stability. The novel vehicle has improved torque disturbance rejection capabilities compared to a standard quadcopter. An analysis of the vehicle dynamics shows that the effect of torque disturbances decreases monotonically with increasing angular momentum of the momentum wheel. A framework for choosing the mass moment of inertia and speed of the momentum wheel is given based on an upper bound on the allowable energy stored in the wheel. Theoretical results are experimentally validated by comparing responses to torque impulses applied to the vehicle with and without the momentum wheel spinning.
ER  - 

TY  - CONF
TI  - A Universal Controller for Unmanned Aerial Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4171
EP  - 4176
AU  - E. Bulka
AU  - M. Nahon
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - UAVs
KW  - agile fixed-wing aircraft
KW  - control logic
KW  - unmanned aerial vehicles
KW  - tilt-rotor
KW  - vehicle flight envelope
KW  - single physics-based controller
KW  - multicopters
KW  - autonomous flight
KW  - quadrotor
KW  - Force
KW  - Aircraft
KW  - Quaternions
KW  - Attitude control
KW  - Actuators
DO  - 10.1109/IROS.2018.8593878
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State of the art control strategies for these vehicles are typically limited to a portion of the vehicle's flight envelope, and are tailored to a specific type of platform. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, flying-wing with two thrusters, most tailsitters, and some tilt-rotor/wing platforms. We demonstrate autonomous flight for a quadrotor and agile fixed-wing aircraft in a simulation environment. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and an aggressive turnaround with the fixed-wing aircraft, all using a single controller with a single set of gains.
ER  - 

TY  - CONF
TI  - Passive Compliance Control of Aerial Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4177
EP  - 4184
AU  - M. J. Kim
AU  - R. Balachandran
AU  - M. De Stefano
AU  - K. Kondak
AU  - C. Ott
PY  - 2018
KW  - aerospace components
KW  - compliance control
KW  - end effectors
KW  - force control
KW  - manipulators
KW  - position control
KW  - time domain passivity technique
KW  - passive compliance control
KW  - aerial manipulators
KW  - stable environmental interactions
KW  - body-planar directions
KW  - aerial vehicle
KW  - manipulator
KW  - Manipulator dynamics
KW  - End effectors
KW  - Dynamics
KW  - Unmanned aerial vehicles
KW  - Mathematical model
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593718
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a passive compliance control for aerial manipulators to achieve stable environmental interactions. The main challenge is the absence of actuation along body-planar directions of the aerial vehicle which might be required during the interaction to preserve passivity. The controller proposed in this paper guarantees passivity of the manipulator through a proper choice of end-effector coordinates, and that of vehicle fuselage is guaranteed by exploiting time domain passivity technique. Simulation studies validate the proposed approach.
ER  - 

TY  - CONF
TI  - Guidance Laws for Partially-Observable Interception Based on Linear Covariance Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4185
EP  - 4191
AU  - J. Arneberg
AU  - E. Tal
AU  - S. Karaman
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - covariance analysis
KW  - differential games
KW  - optimal control
KW  - differential game
KW  - linear covariance analysis
KW  - maneuvers
KW  - resulting guidance law
KW  - guidance laws
KW  - pursuit-evasion games
KW  - partial measurements
KW  - visual sensing
KW  - bearing measurements
KW  - partially-observable interception problem
KW  - observability
KW  - Observability
KW  - Games
KW  - Uncertainty
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Extraterrestrial measurements
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593929
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider pursuit-evasion games in which the pursuer is tasked with intercepting the evader using only partial measurements. Motivated by the utilization of visual sensing on board the pursuer, we focus on the case when only bearing measurements are available to the pursuer. The resulting partially-observable interception problem is computationally challenging, and the separation principle does not hold in general. In this paper, we identify a set of maneuvers that improve observability, and we propose an algorithm that utilizes these maneuvers to move the pursuer so that the expected payoff of the differential game is maximized. The algorithm uses in-the-loop uncertainty propagation based on linear covariance analysis to assess the effect of the maneuvers. We evaluate the resulting guidance law in experiments involving a quadcopter in flight representing the pursuer, and a simulated evader.
ER  - 

TY  - CONF
TI  - MMAC Height Control System of a Quadrotor for Constant Unknown Load Transportation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4192
EP  - 4197
AU  - P. Outeiro
AU  - C. Cardeira
AU  - P. Oliveira
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - helicopters
KW  - Kalman filters
KW  - linear quadratic control
KW  - motion sensors
KW  - quadrotor
KW  - multimodel adaptive controller
KW  - LQR
KW  - IMU
KW  - motion sensors
KW  - state variables
KW  - constant unknown load transportation
KW  - MMAC height control system
KW  - ultrasound height sensor
KW  - Kalman filter
KW  - Gravity
KW  - Estimation
KW  - Sensors
KW  - Kalman filters
KW  - Computational modeling
KW  - Control systems
KW  - Transportation
DO  - 10.1109/IROS.2018.8594215
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a methodology for height control of a quadrotor that transports a constant unknown load, given the estimates on both weight and state variables, based on measurements from motion sensors installed on-board. The proposed control and estimation framework is a Multi-Model Adaptive Controller using LQR with integrative action and Kalman filter with integrative component. The control system obtained is validated both in simulation and experimentally, resorting to an off-the-shelf commercially available quadrotor equipped with an IMU, an ultrasound height sensor, and a barometer, among other sensors.
ER  - 

TY  - CONF
TI  - Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4198
EP  - 4203
AU  - K. Mohammadi
AU  - M. Jafarinasab
AU  - S. Sirouspour
AU  - E. Dyer
PY  - 2018
KW  - aerospace robotics
KW  - decentralised control
KW  - helicopters
KW  - Lyapunov methods
KW  - materials handling
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - optical tracking
KW  - stability
KW  - energetic passivity property
KW  - drone on-board IMUs
KW  - Lyapunov analysis
KW  - optical tracking systems
KW  - three-drone payload transport system
KW  - motion stability
KW  - cable-suspended payload
KW  - multiple conventional quadcopters
KW  - cabled-based multidrone load transport system
KW  - decentralized motion control
KW  - Payloads
KW  - Drones
KW  - Force
KW  - Stability analysis
KW  - Trajectory
DO  - 10.1109/IROS.2018.8593952
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A provably stable decentralized control scheme is proposed to allow multiple conventional quadcopters carry a cable-suspended payload. The method exploits a fundamental energetic passivity property of the combined drones, cables, and payload system to stably move the payload from its origin to destination. This is achieved without making any assumption about the status of the cables tension during the flight, and any measurement from the payload. The controller is decentralized in the sense that inter-drone communication of feedback measurements is not required. Motion stability is demonstrated via a Lyapunov analysis. The proposed controller is successfully implemented on a three-drone payload transport system in an indoor environment, using measurement from an optical tracking systems and the drones on-board IMUs.
ER  - 

TY  - CONF
TI  - SwarmTouch: Tactile Interaction of Human with Impedance Controlled Swarm of Nano-Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4204
EP  - 4209
AU  - E. Tsykunov
AU  - L. Labazanova
AU  - A. Tleugazy
AU  - D. Tsetserukou
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - human-robot interaction
KW  - microrobots
KW  - multi-robot systems
KW  - path planning
KW  - tactile sensors
KW  - trajectory control
KW  - impedance controlled swarm
KW  - nanoquadrotors
KW  - novel interaction strategy
KW  - human-swarm communication
KW  - human operator guides
KW  - quadrotors
KW  - impedance control
KW  - human hand velocity
KW  - formation shape
KW  - Crazyflie 2.0 quadrotor platform
KW  - control algorithm
KW  - tactile patterns
KW  - controllability
KW  - complex life-like formation
KW  - tactile sensation
KW  - drone formation
KW  - human-swarm interaction
KW  - swarm navigation
KW  - Impedance
KW  - Drones
KW  - Robots
KW  - Mathematical model
KW  - Shape
KW  - Force
KW  - Safety
DO  - 10.1109/IROS.2018.8594424
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel interaction strategy for a human-swarm communication when a human operator guides a formation of quadrotors with impedance control and receives vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a life-like swarm behavior. Experimental results with Crazyflie 2.0 quadrotor platform validate the proposed control algorithm. The tactile patterns representing dynamics of the swarm (extension or contraction) are proposed. The user feels the state of the swarm at his fingertips and receives valuable information to improve the controllability of the complex life-like formation. The user study revealed the patterns with high recognition rates. Subjects stated that tactile sensation improves the ability to guide the drone formation and makes the human-swarm communication much more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and immersion into the swarm navigation.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Novel Aerial Manipulator with Tandem Ducted Fans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4210
EP  - 4217
AU  - Y. Zhang
AU  - C. Xiang
AU  - B. Xu
AU  - Y. Wang
AU  - X. Wang
PY  - 2018
KW  - aerospace testing
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control system synthesis
KW  - fans
KW  - feedforward
KW  - helicopters
KW  - manipulator dynamics
KW  - stability
KW  - vehicle dynamics
KW  - aerial vehicle dynamics
KW  - manipulator dynamics
KW  - tandem ducted fans
KW  - trafficability
KW  - comprehensive integrated dynamic model
KW  - aerial manipulator
KW  - loading
KW  - multirotor
KW  - multilayer composite controller
KW  - feedforward compensation
KW  - flight tests
KW  - Manipulator dynamics
KW  - Fans
KW  - Payloads
KW  - Helicopters
KW  - Ducts
DO  - 10.1109/IROS.2018.8593868
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a novel aerial manipulator with tandem ducted fans, which takes both trafficability and effective loading into account. The aerial manipulator is particularly suitable for grasping in complex and narrow environment, in which traditional multi-rotor and helicopter would be inaccessible. The comprehensive integrated dynamic model is established by taking the aerial vehicle dynamics and manipulator dynamics as a whole. On this basis, a multilayer composite controller with feedforward compensation is designed, considering the mutual reactive influence between the aerial vehicle and the manipulator to improve the stability of the system under the motion of the manipulator. The simulation and actual flight tests verify the effectiveness of the design and show good stability and tracking performance of the system.
ER  - 

TY  - CONF
TI  - Real-Time Light Field Processing for Autonomous Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4218
EP  - 4225
AU  - A. Bajpayee
AU  - A. H. Techet
AU  - H. Singh
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image sensors
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - telerobotics
KW  - autonomous robotics systems
KW  - LIDAR sensors
KW  - time light field processing
KW  - simple linear arrays
KW  - high frequency vibrations
KW  - light fields
KW  - autonomous cars
KW  - light field imaging system
KW  - field-of-view
KW  - software framework
KW  - Cameras
KW  - Robot vision systems
KW  - Vibrations
KW  - Calibration
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594477
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical autonomous robotics systems incorporate multiple cameras, LIDAR sensors and sophisticated computing resources. In this paper we present a software framework for utilizing any array of multiple cameras with sufficient field-of-view (FOV) overlap as a light field imaging system. We show that the typical linear arrays that exist on autonomous cars are sufficient to capture stable time resolved light fields even when moving at highway speeds. We elaborate on the potential pitfalls associated with such a technique namely loss of calibration between cameras due to high frequency vibrations and sudden shocks associated with driving over potholes and highlight a method that can compensate for such effects. We demonstrate that the light fields collected by simple linear arrays can be processed in real time for a wide variety of useful applications including occlusion removal, for signal enhancement in featureless images captured in very low light, for reflection removal and for improved visibility in extreme conditions associated with snow and heavy rain.
ER  - 

TY  - CONF
TI  - Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4226
EP  - 4231
AU  - T. Ohashi
AU  - Y. Ikegami
AU  - K. Yamamoto
AU  - W. Takano
AU  - Y. Nakamura
PY  - 2018
KW  - cameras
KW  - image filtering
KW  - image motion analysis
KW  - image reconstruction
KW  - image sequences
KW  - spatiotemporal phenomena
KW  - video signal processing
KW  - video motion capture
KW  - part confidence maps
KW  - inverted motions
KW  - two-time inverse kinematics computations
KW  - human skeleton
KW  - human motion analysis
KW  - human motion data
KW  - spatiotemporal filter
KW  - camera image
KW  - human skeletal model
KW  - spatiotemporal filtering
KW  - multicamera images
KW  - Phase change materials
KW  - Three-dimensional displays
KW  - Cameras
KW  - Computational modeling
KW  - Optical imaging
KW  - Adaptive optics
KW  - Spatiotemporal phenomena
DO  - 10.1109/IROS.2018.8593867
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper discusses video motion capture, namely, 3D reconstruction of human motion from multi-camera images. After the Part Confidence Maps are computed from each camera image, the proposed spatiotemporal filter is applied to deliver the human motion data with accuracy and smoothness for human motion analysis. The spatiotemporal filter uses the human skeleton and mixes temporal smoothing in two-time inverse kinematics computations. The experimental results show that the mean per joint position error was 26.1mm for regular motions and 38.8mm for inverted motions.
ER  - 

TY  - CONF
TI  - Development of Wide Angle Fovea Lens for High-Definition Imager Over 3 Mega Pixels
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4232
EP  - 4237
AU  - S. Shimizu
AU  - R. Murakami
AU  - M. Tominaga
AU  - Y. Akamine
AU  - N. Kawasaki
AU  - O. Shimomura
AU  - K. Ishimaru
AU  - S. Mita
PY  - 2018
KW  - image sensors
KW  - lenses
KW  - photodetectors
KW  - robot vision
KW  - stereo image processing
KW  - visual perception
KW  - WAF lens
KW  - wide angle fovea lens
KW  - high-definition imager
KW  - autonomous robot
KW  - vehicle supersensing vision system
KW  - robotic vision
KW  - field of view
KW  - FOV
KW  - high-resolution photosensitive imaging chip
KW  - stereo vision system
KW  - optical performance
KW  - aspherical surface
KW  - projection testing
KW  - Lenses
KW  - Prototypes
KW  - Spatial resolution
KW  - Cameras
KW  - Robots
KW  - Optical imaging
DO  - 10.1109/IROS.2018.8594194
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a high-quality wide-angle fovea lens, i.e., the WAF lens, for the autonomous robot's and vehicle's super-sensing vision system. The WAF lens is well-known in the field of robotic vision with respect to its unique design concept, biologically-inspired from a visual system of the primates. The WAF lens achieves the following two conflicting properties in imaging simultaneously: (1) wide field of view (FOV) and (2) high magnification factor (although only the central FOV achieves it partially). In this paper, the authors designs the WAF lens for the high-resolution photosensitive imaging chip more than 3M pixels. For this design, we decide the following targets on the assumption of applying this WAF lens for the stereo vision system: (1) The WAF lens can measure a very far distance over 100m ahead from the imager accurately. (2) The WAF lens can observe approximately 100-degree wide FOV on the same time. We produce a prototype of this WAF lens with much higher optical performance than our previous developments. The compound system of the prototype includes four aspherical surfaces in its front part to project enough bright images so that the WAF lens is available not only at daytime but also in dark situations at night. The authors experiment and demonstrate the projection tests using the prototype, and discuss about the results as the inspection of this challenging development.
ER  - 

TY  - CONF
TI  - Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4238
EP  - 4245
AU  - A. Zeng
AU  - S. Song
AU  - S. Welker
AU  - J. Lee
AU  - A. Rodriguez
AU  - T. Funkhouser
PY  - 2018
KW  - convolutional neural nets
KW  - end effectors
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neurocontrollers
KW  - learning synergies
KW  - self-supervised deep reinforcement learning
KW  - cluttered objects
KW  - pushing movements
KW  - model-free deep reinforcement learning
KW  - fully convolutional networks
KW  - end-effector orientations
KW  - Q-learning framework
KW  - pushing motions
KW  - grasping success rates
KW  - picking efficiencies
KW  - skilled robotic manipulation
KW  - grasping
KW  - prehensile action
KW  - pixel-wise sampling
KW  - Grasping
KW  - Training
KW  - Three-dimensional displays
KW  - Reinforcement learning
KW  - Planning
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593986
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/
ER  - 

TY  - CONF
TI  - Towards Material Classification of Scenes Using Active Thermography
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4262
EP  - 4269
AU  - H. Bai
AU  - T. Bhattacharjee
AU  - H. Chen
AU  - A. Kapusta
AU  - C. C. Kemp
PY  - 2018
KW  - image classification
KW  - infrared imaging
KW  - learning (artificial intelligence)
KW  - temperature measurement
KW  - multimaterial scene
KW  - varying distances
KW  - multiclass classification
KW  - heating intensity
KW  - material classification
KW  - variable distances
KW  - relatively large surface areas
KW  - modern machine learning methods
KW  - data-driven approach
KW  - signal variations
KW  - thermal camera
KW  - heat lamp
KW  - size 20.0 cm
KW  - size 40.0 cm
KW  - size 30.0 cm
KW  - time 4.0 s
KW  - time 5.0 s
KW  - time 1.0 s
KW  - Heating systems
KW  - Cameras
KW  - Heat transfer
KW  - Robot sensing systems
KW  - Surface treatment
DO  - 10.1109/IROS.2018.8594469
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - By briefly heating the local environment with a heat lamp and observing what happens with a thermal camera, robots could potentially infer properties of their surroundings. However, this form of active thermography introduces large signal variations compared to traditional active thermography, which has typically been used to characterize small regions of materials in carefully controlled settings. We demonstrate that a data-driven approach with modern machine learning methods can be used to classify material samples over relatively large surface areas and variable distances. We also introduce the use of z-normalization to improve material classification and reduce variation due to distance and heating intensity. Our best performing algorithm achieved an overall accuracy of 77.7% for multi-class classification among 12 materials placed at varying distances (20 cm, 30 cm, and 40 cm). The observations were made for 5 seconds with 1s of heating and 4s of cooling. We also provide a demonstration of performance with a multi-material scene.
ER  - 

TY  - CONF
TI  - Vision-Based State Estimation and Trajectory Tracking Control of Car-Like Mobile Robots with Wheel Skidding and Slipping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4270
EP  - 4275
AU  - S. Zhou
AU  - Z. Miao
AU  - Z. Liu
AU  - H. Zhao
AU  - H. Wang
AU  - H. Chen
AU  - Y. Liu
PY  - 2018
KW  - automobiles
KW  - control system synthesis
KW  - estimation theory
KW  - Lyapunov methods
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - stability
KW  - state estimation
KW  - trajectory control
KW  - wheels
KW  - car-like mobile robots
KW  - wheel slipping
KW  - Lyapunov method
KW  - system stability
KW  - visual estimation algorithm
KW  - vision-based approach
KW  - wheel skidding
KW  - trajectory tracking control
KW  - vision-based state estimation
KW  - Mobile robots
KW  - Wheels
KW  - Perturbation methods
KW  - Visualization
KW  - Estimation
KW  - Trajectory tracking
DO  - 10.1109/IROS.2018.8593982
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Most existing trajectory tracking controllers are based on non-skidding and non-slipping assumptions, also assume that full states are accessible, which is unrealistic for real-world applications due to tire-road interaction. This paper presents a novel vision-based approach to achieve high performance tracking control of a Car-Like Mobile Robot (CLMR) with wheel skidding and slippage. A visual estimation algorithm is proposed to provide reliable position, velocity, skidding and slipping information to close the control loop. The stability of the proposed system can be guaranteed by Lyapunov method since the position tracking error and the estimation error converge to zero simultaneously. Simulation is made to validate the effectiveness of the developed controller in the presence of skidding and slipping with online visual estimator.
ER  - 

TY  - CONF
TI  - Recruitment Near Worksites Facilitates Robustness of Foraging E-Puck Swarms to Global Positioning Noise
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4276
EP  - 4281
AU  - L. Pitonakova
AU  - A. Winfield
AU  - R. Crowder
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - position control
KW  - worksites facilitates robustness
KW  - foraging e-puck swarms
KW  - global positioning noise
KW  - collective foraging
KW  - robot global positioning data
KW  - broadcast messages
KW  - e-puck robots
KW  - semivirtual environment
KW  - VICON positioning system
KW  - robot positioning data
KW  - pseudorandom environments
KW  - important physical aspects
KW  - inherent noise
KW  - robot infra-red sensors
KW  - robot controllers
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Servers
KW  - Task analysis
KW  - Recruitment
DO  - 10.1109/IROS.2018.8593788
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We compare the ability of two different robot controllers for collective foraging to cope with noise in robot global positioning data and show how recruitment, in the form of broadcast messages near worksites, can make swarms more robust. Swarms of five e-puck robots are used in a semi-virtual environment, facilitated by the VICON positioning system. This setup allows us to control the amount of noise in the robot positioning data and to generate pseudo-random environments, while retaining important physical aspects of the experiment. The effect of inherent noise in the robot infra-red sensors, used for obstacle avoidance, is noted and the importance of modelling such noise in agent-based simulations is highlighted.
ER  - 

TY  - CONF
TI  - Robust and Adaptive Robot Self-Assembly Based on Vascular Morphogenesis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4282
EP  - 4287
AU  - M. Divband Soorati
AU  - J. Ghofrani
AU  - P. Zahadat
AU  - H. Hamann
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - self-adjusting systems
KW  - self-assembly
KW  - trees (mathematics)
KW  - complex patterns
KW  - programmable systems
KW  - similar complexity
KW  - role model
KW  - natural plants
KW  - environmental conditions
KW  - dynamic environments
KW  - patterned formation
KW  - vascular tissue
KW  - aggregated robots
KW  - dynamic environment
KW  - robot swarm experiments
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Self-assembly
KW  - Shape
KW  - Resource management
DO  - 10.1109/IROS.2018.8594093
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Self-assembly is the aggregation of simple parts into complex patterns as frequently observed in nature. Following this inspiration, creating programmable systems of self-assembly that achieve similar complexity and robustness with robots is challenging. As a role model we pick the growth of natural plants that adapts to environmental conditions and is robust enough to withstand disturbances such as changes due to dynamic environments and cut parts. We program a robot swarm to self-assemble into tree-like shapes and to adapt efficiently to the environment. Our approach is inspired by the vascular morphogenesis of plants, the patterned formation of vascular tissue to transport fluids and nutrients internally. The aggregated robots establish an internal network of resource sharing, allowing them to make rational decisions collectively about where to add and where to remove robots. As a result, the growth is adaptive to an environmental feature (here, light) and robust to changes in a dynamic environment. The robot swarm is able to self-repair by regrowing lost parts. We successfully validate and benchmark our approach in a number of robot swarm experiments showing adaptivity, robustness, and self-repair.
ER  - 

TY  - CONF
TI  - $\Phi$ Clust: Pheromone-Based Aggregation for Robotic Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4288
EP  - 4294
AU  - F. Arvin
AU  - A. E. Turgut
AU  - T. KrajnÃ­k
AU  - S. Rahimi
AU  - Ä°. E. Okay
AU  - S. Yue
AU  - S. Watson
AU  - B. Lennox
PY  - 2018
KW  - aggregation
KW  - fuzzy control
KW  - fuzzy set theory
KW  - image colour analysis
KW  - mobile robots
KW  - multi-robot systems
KW  - pheromone diffusion
KW  - BEECLUST algorithm
KW  - pheromone-based communication
KW  - pheromone-based aggregation method
KW  - Î¦Clust
KW  - artificial pheromone
KW  - BEECLUST method
KW  - pheromone evaporation
KW  - robotic swarms
KW  - Robot sensing systems
KW  - Biological system modeling
KW  - Aggregates
KW  - Swarm robotics
KW  - Temperature sensors
KW  - Swarm Robotics
KW  - Aggregation
KW  - Pheromone
KW  - Bio-inspired
DO  - 10.1109/IROS.2018.8593961
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we proposed a pheromone-based aggregation method based on the state-of-the-art BEECLUST algorithm. We investigated the impact of pheromone-based communication on the efficiency of robotic swarms to locate and aggregate at areas with a given cue. In particular, we evaluated the impact of the pheromone evaporation and diffusion on the time required for the swarm to aggregate. In a series of simulated and real-world evaluation trials, we demonstrated that augmenting the BEECLUST method with artificial pheromone resulted in faster aggregation times.
ER  - 

TY  - CONF
TI  - Decentralized Connectivity-Preserving Deployment of Large-Scale Robot Swarms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4295
EP  - 4302
AU  - N. Majcherczyk
AU  - A. Jayabalan
AU  - G. Beltrame
AU  - C. Pinciroli
PY  - 2018
KW  - collision avoidance
KW  - decentralised control
KW  - mobile robots
KW  - multi-robot systems
KW  - robots
KW  - trees (mathematics)
KW  - physics-based simulations
KW  - logical tree
KW  - robot network
KW  - spatially distributed targets
KW  - robot swarm
KW  - large-scale robot
KW  - decentralized connectivity-preserving deployment
KW  - real-robot experiments
KW  - tree root
KW  - connectivity constraints
KW  - physical network
KW  - logical tree topology
KW  - Robot kinematics
KW  - Topology
KW  - Heuristic algorithms
KW  - Network topology
KW  - Switches
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594422
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a decentralized and scalable approach for deployment of a robot swarm. Our approach tackles scenarios in which the swarm must reach multiple spatially distributed targets, and enforce the constraint that the robot network cannot be split. The basic idea behind our work is to construct a logical tree topology over the physical network formed by the robots. The logical tree acts as a backbone used by robots to enforce connectivity constraints. We study and compare two algorithms to form the logical tree: outwards and inwards. These algorithms differ in the order in which the robots join the tree: the outwards algorithm starts at the tree root and grows towards the targets, while the inwards algorithm proceeds in the opposite manner. Both algorithms perform periodic reconfiguration, to prevent suboptimal topologies from halting the growth of the tree. Our contributions are (i) The formulation of the two algorithms; (ii) A comparison of the algorithms in extensive physics-based simulations; (iii) A validation of our findings through real-robot experiments.
ER  - 

TY  - CONF
TI  - A Distributed Swarm Aggregation Algorithm for Bar Shaped Multi-Agent Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4303
EP  - 4308
AU  - R. F. Carpio
AU  - L. Di Giulio
AU  - E. Garone
AU  - G. Ulivi
AU  - A. Gasparri
PY  - 2018
KW  - collision avoidance
KW  - logistics
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - control scheme
KW  - collaborative transportation
KW  - bar-like shaped loads
KW  - robot-teams
KW  - collaborative object transportation task
KW  - precision farming setting
KW  - distributed swarm aggregation algorithm
KW  - bar shaped multiagent systems
KW  - state space
KW  - aggregate state
KW  - collision avoidance
KW  - angular consensus
KW  - segment-to-segment distance definition
KW  - control law
KW  - autonomous tractors
KW  - Bars
KW  - Multi-agent systems
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Aggregates
KW  - Load modeling
DO  - 10.1109/IROS.2018.8594236
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we consider a swarm of agents shaped as bars with a certain orientation in the state space. Members of the swarm have to reach an aggregate state, while guaranteeing the collision avoidance and possibly achieving an angular consensus. By relying on a segment-to-segment distance definition, we propose a control law, which guides the agents towards this goal. A theoretical analysis of the proposed control scheme along with simulations and experimental results is provided. The proposed framework can be used to model several application scenarios ranging from collaborative transportation to precision farming, where each agent may represent either a large robot or a group of robots intent to carry bar-like shaped loads. Representative examples include: a fleet of robot-teams performing a collaborative object transportation task in an automated logistic setting, or a fleet of autonomous tractors each carrying a large atomizer to spray chemical products for pest and disease control in a precision farming setting.
ER  - 

TY  - CONF
TI  - Resilient Active Information Gathering with Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4309
EP  - 4316
AU  - B. Schlotfeldt
AU  - V. Tzoumas
AU  - D. Thakur
AU  - G. J. Pappas
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - information acquisition tasks
KW  - failure-prone
KW  - resilient design problems
KW  - submodular approximation algorithms
KW  - active robots
KW  - mobile robots
KW  - resilient active information gathering
KW  - multirobot target tracking
KW  - active information gathering scenario
KW  - denial-of-service attacks
KW  - system-wide resiliency
KW  - minimal communication
KW  - Robot sensing systems
KW  - Target tracking
KW  - Mobile robots
KW  - Robot kinematics
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593630
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Applications of safety, security, and rescue in robotics, such as multi-robot target tracking, involve the execution of information acquisition tasks by teams of mobile robots. However, in failure-prone or adversarial environments, robots get attacked, their communication channels get jammed, and their sensors may fail, resulting in the withdrawal of robots from the collective task, and consequently the inability of the remaining active robots to coordinate with each other. As a result, traditional design paradigms become insufficient and, in contrast, resilient designs against system-wide failures and attacks become important. In general, resilient design problems are hard, and even though they often involve objective functions that are monotone or submodular, scalable approximation algorithms for their solution have been hitherto unknown. In this paper, we provide the first algorithm, enabling the following capabilities: minimal communication, i.e., the algorithm is executed by the robots based only on minimal communication between them; system-wide resiliency, i.e., the algorithm is valid for any number of denial-of-service attacks and failures; and provable approximation performance, i.e., the algorithm ensures for all monotone (and not necessarily submodular) objective functions a solution that is finitely close to the optimal. We quantify our algorithms approximation performance using a notion of curvature for monotone set functions. We support our theoretical analyses with simulated and real-world experiments, by considering an active information gathering scenario, namely, multi-robot target tracking.
ER  - 

TY  - CONF
TI  - Generation of Context-Dependent Policies for Robot Rescue Decision-Making in Multi-Robot Teams
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4317
EP  - 4324
AU  - S. Al-Hussaini
AU  - J. M. Gregory
AU  - S. K. Gupta
PY  - 2018
KW  - decision making
KW  - multi-robot systems
KW  - probability
KW  - rescue robots
KW  - robust control
KW  - state estimation
KW  - computationally-efficient manner
KW  - feasible baseline approaches
KW  - context-dependent policies
KW  - robot rescue decision-making
KW  - multirobot teams
KW  - scalable policy synthesis framework
KW  - parallelizable policy synthesis framework
KW  - time-varying
KW  - stochastic mission conditions
KW  - physics-based simulations
KW  - probability minimization
KW  - state estimation
KW  - Robots
KW  - Task analysis
KW  - Computational modeling
KW  - State estimation
KW  - Probabilistic logic
KW  - Switches
KW  - Navigation
DO  - 10.1109/IROS.2018.8594114
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a scalable, parallelizable policy synthesis framework intended for a robot presented with the decision of exploration or rescue, given some time-varying, stochastic mission conditions, referred to as context. We demonstrate the feasibility of such a solution using physics-based simulations to synthesize a policy in a computationally-efficient manner and exhibit superior performance with regards to the minimization of probability of mission failure when compared to two feasible baseline approaches. Furthermore, we present preliminary results that suggest our approach is robust to errors in the state estimation used to build mission context, which further supports the notion of real-world applicability.
ER  - 

TY  - CONF
TI  - Reach-Avoid Problems via Sum-or-Squares Optimization and Dynamic Programming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4325
EP  - 4332
AU  - B. Landry
AU  - M. Chen
AU  - S. Hemley
AU  - M. Pavone
PY  - 2018
KW  - dynamic programming
KW  - reachability analysis
KW  - state-space methods
KW  - reach-avoid problem
KW  - dynamic programming
KW  - sum-of-squares optimization
KW  - polynomial system dynamics
KW  - mathematical guarantees
KW  - Optimization
KW  - Dynamic programming
KW  - System dynamics
KW  - Games
KW  - Planning
KW  - Automobiles
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594078
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reach-avoid problems involve driving a system to a set of desirable configurations while keeping it away from undesirable ones. Providing mathematical guarantees for such scenarios is challenging but have numerous potential practical applications. Due to the challenges, analysis of reach-avoid problems involves making trade-offs between generality of system dynamics, generality of problem setups, optimality of solutions, and computational complexity. In this paper, we combine sum-of-squares optimization and dynamic programming to address the reach-avoid problem, and provide a conservative solution that maintains reaching and avoidance guarantees. Our method is applicable to polynomial system dynamics and to general problem setups, and is more computationally scalable than previous related methods. Through a numerical example involving two single integrators, we validate our proposed theory and compare our method to Hamilton-Jacobi reachability. Having validated our theory, we demonstrate the computational scalability of our method by computing the reach-avoid set of a system involving two kinematic cars.
ER  - 

TY  - CONF
TI  - Development of Rimless Wheel with Controlled Wobbling Mass
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4333
EP  - 4339
AU  - Y. Hanazawa
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - numerical analysis
KW  - robot dynamics
KW  - wheels
KW  - controlled wobbling mass
KW  - rimless wheel
KW  - level-ground walking
KW  - propulsive effects
KW  - physical parameters
KW  - control parameters
KW  - numerical simulation
KW  - robots
KW  - Legged locomotion
KW  - Wheels
KW  - Trajectory
KW  - Torso
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593812
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for generating level-ground walking for a rimless wheel with a controlled wobbling mass. Our rimless wheel achieves level-ground walking by simply controlling the wobbling mass attached to the wheel. We mathematically demonstrate that the controlled wobbling mass generates propulsive effects for the rimless wheel. The walking speed of the rimless wheel can be changed by varying the amplitude of the wobbling mass: thus slow walking to high-speed walking can be realized for the wheel. Moreover, we have developed a robot based on a rimless wheel to show effectiveness of our proposed methods. We then analyze the walking properties with respect to the physical parameters and control parameters of our robot through numerical simulation.
ER  - 

TY  - CONF
TI  - Maneuverability in Dynamic Vertical Climbing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4340
EP  - 4347
AU  - J. M. Brown
AU  - M. P. Austin
AU  - B. Kanwar
AU  - T. E. Jonas
AU  - J. E. Clark
PY  - 2018
KW  - legged locomotion
KW  - robot dynamics
KW  - distinct dynamic gait identification
KW  - dynamic climbing platform
KW  - prescribed body roll
KW  - reduced order pendular dynamic climbing model
KW  - dynamic vertical climbing
KW  - dynamic maneuverability
KW  - dynamic downward climbing
KW  - Legged locomotion
KW  - Dynamics
KW  - Foot
KW  - Mathematical model
KW  - Force
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594074
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we examine the reduced order pendular dynamic climbing model with the addition of attachment windows based on prescribed body roll. With this model and on the new dynamic climbing platform, TAILS, we demonstrate dynamic downward climbing as well as identify distinct dynamic gaits within downward climbing. This, combined with the application of an asymmetric configuration of the rear legs enables strafing motions and thus dynamic maneuverability on walls in the vertical domain.
ER  - 

TY  - CONF
TI  - Design of Extra Robotic Legs for Augmenting Human Payload Capabilities by Exploiting Singularity and Torque Redistribution
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4348
EP  - 4354
AU  - D. J. Gonzalez
AU  - H. H. Asada
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - design engineering
KW  - force control
KW  - gears
KW  - industrial robots
KW  - legged locomotion
KW  - manipulator kinematics
KW  - motion control
KW  - torque control
KW  - wearable robots
KW  - force control
KW  - PPE loads
KW  - extra robotic legs system
KW  - hazardous material emergency
KW  - gear reductions
KW  - XRL system
KW  - power systems
KW  - closed-loop kinematic chain
KW  - actuator loads
KW  - personal protective equipment
KW  - robotic human augmentation system
KW  - torque redistribution
KW  - Legged locomotion
KW  - Payloads
KW  - Kinematics
KW  - Force
KW  - Torque
KW  - Actuators
KW  - Human Augmentation
KW  - Supernumerary Robotic Limbs
KW  - Exoskeletons
KW  - Mechanism Design
KW  - Industrial Robotics
DO  - 10.1109/IROS.2018.8593506
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the design of a new robotic human augmentation system that will assist the operator in carrying a heavy payload, reaching and maintaining difficult postures, and ultimately better performing their job. The Extra Robotic Legs (XRL) system is worn by the operator and consists of two articulated robotic legs that move with the operator to bear a heavy payload. The design was driven by a need to increase the effectiveness of hazardous material emergency response personnel who are encumbered by their personal protective equipment (PPE). The legs will ultimately walk, climb stairs, crouch down, and crawl with the operator while eliminating all external PPE loads on the operator. The forces involved in the most extreme loading cases were analyzed to find an effective strategy for reducing actuator loads. The analysis reveals that the maximum torque is exerted during the transition from the crawling to standing mode of motion. Peak torques are significantly reduced by leveraging redundancy in force application resulting from a closed-loop kinematic chain formed by a particular posture of the XRL. The actuators, power systems, and transmission elements were designed from the results of these analyses. Using differential mechanisms to combine the inputs of multiple actuators into a single degree of freedom, the gear reductions needed to bear the heavy loads could be kept at a minimum, enabling high bandwidth force control due to the near-direct-drive transmission. A prototype was fabricated utilizing the insights gained from these analyses and initial tests indicate the feasibility of the XRL system.
ER  - 

TY  - CONF
TI  - Multi-Limbed Robot Vertical Two Wall Climbing Based on Static Indeterminacy Modeling and Feasibility Region Analysis
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4355
EP  - 4362
AU  - X. Lin
AU  - H. Krishnan
AU  - Y. Su
AU  - D. W. Hong
PY  - 2018
KW  - end effectors
KW  - friction
KW  - legged locomotion
KW  - climbing region
KW  - feasibility region analysis
KW  - multilimbed climbing robots
KW  - slide failure mode
KW  - over-torque failure mode
KW  - pure friction end effectors
KW  - walls
KW  - hexapod robot
KW  - robot deformation
KW  - climbing failure
KW  - robots
KW  - stiffness matrices
KW  - statically indeterminate forces
KW  - static indeterminacy modeling
KW  - multilimbed robot vertical two wall climbing
KW  - Strain
KW  - Mathematical model
KW  - Friction
KW  - Force
KW  - Robot kinematics
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593734
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a technique to model statically indeterminate forces based on stiffness matrices for multi-limbed climbing robots. Current wall climbing robots in literature overlook statically indeterminate forces, causing an incapability to estimate climbing failure under certain circumstances. Accounting for these forces, robot deformation can be approximated, paving the way for the proposed two-wall climbing approach. During a wall climb, two failure modes, slide and over-torque, are identified to compute feasible climbing region. A hexapod robot is used to verify the proposed technique by climbing between walls with pure friction end effectors.
ER  - 

TY  - CONF
TI  - Fast Walking with Rhythmic Sway of Torso in a 2D Passive Ankle Walker
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4363
EP  - 4368
AU  - R. Bao
AU  - T. Geng
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - 2D passive ankle walker
KW  - biped robots
KW  - rhythmic sway
KW  - torso-swaying optimization
KW  - optimal trajectories
KW  - fast walking speed
KW  - un-actuated ankles
KW  - Legged locomotion
KW  - Torso
KW  - Trajectory
KW  - Optimization
KW  - Mathematical model
KW  - Foot
KW  - Biped robots
KW  - legged locomotion
DO  - 10.1109/IROS.2018.8593665
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There is a category of biped robots that are equipped with passive or un-actuated ankles, which we call Passive-Ankle Walkers (PAWs). Lack of actuation at ankles is a disadvantage in the fast walking of PAWs. We started this study with an intuitive hypothesis that rhythmic sway of torso may enable faster walking in PAWs. To test this hypothesis, firstly, we optimized the rhythmic sway of torso of a simulated PAW model for fast walking speed, and analyzed the robustness of the optimal trajectories. Then we implemented the optimal trajectories on a real robot. Both the simulation analysis and the experimental results indicated that optimized torso-swaying can greatly increase the walking speed by 40%. By analyzing the walking patterns of the simulated model and the real robot, we identified the reason for the faster walking with swaying-torso: The rhythmic sway of torso enables the robot to walk with a relatively large step-length while still keeninu a hizh sten-frenuencv.
ER  - 

TY  - CONF
TI  - Torque Controlled Biped Model Through a Bio-Inspired Controller Using Adaptive Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4369
EP  - 4374
AU  - C. Ferreira
AU  - T. Cunha
AU  - C. P. Santos
AU  - L. P. Reis
PY  - 2018
KW  - biomimetics
KW  - legged locomotion
KW  - motion control
KW  - oscillators
KW  - robot dynamics
KW  - torque control
KW  - flat terrain
KW  - impedance control
KW  - adaptive frequency oscillator
KW  - biomimetic controller
KW  - torque adjustment
KW  - walking behavior
KW  - joint stiffness
KW  - adaptable stiffness
KW  - bipedal robots
KW  - motion control
KW  - biomimetic solutions
KW  - slopes
KW  - holes
KW  - obstacles
KW  - unstructured terrains
KW  - human beings
KW  - harmonious locomotion
KW  - efficient locomotion
KW  - biped robots
KW  - adaptive learning
KW  - bio-inspired controller
KW  - torque controlled biped model
KW  - Legged locomotion
KW  - Oscillators
KW  - Biological system modeling
KW  - Adaptation models
KW  - Torque
KW  - Robot kinematics
KW  - Biped
KW  - Central Pattern Generator
KW  - Hopf
KW  - AFO
KW  - torque
KW  - stiffness
DO  - 10.1109/IROS.2018.8594160
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Biped robots have not achieved the efficient and harmonious locomotion of the human beings, capable of walking and running on unstructured terrains, with obstacles, holes and slopes. With this in mind, researchers started the development of biomimetic solutions to control the locomotion of biped models. This work presents a new solution of motion control of bipedal robots with adaptable stiffness, by exploring effects of joint stiffness in modulating walking behavior. Further, torque adjustment is achieved through a biomimetic controller that mimics and adjusts the natural dynamics of the robot to the environment. Specifically, the torque adjustment is made using AFOs (adaptive frequency oscillator) to generate the correct equilibrium positions that will be applied to the impedance control that computes the torque of each joint. Results show that the biped model is capable of walking in several types of terrain, including flat terrain, ramps, stairs and flat terrain with obstacles.
ER  - 

TY  - CONF
TI  - High-Speed Stealth Walking of Underactuated Biped Utilizing Effects of Upper-Body Control and Semicircular Feet
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4375
EP  - 4380
AU  - F. Asano
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - high-speed stealth walking
KW  - upper-body control
KW  - semicircular feet
KW  - stable legged locomotion
KW  - underactuated robotic walkers
KW  - double-limb support phase
KW  - gait properties
KW  - typical stealth walking gaits
KW  - upper body motion
KW  - underactuated biped
KW  - Legged locomotion
KW  - Foot
KW  - Mathematical model
KW  - Trajectory
KW  - Numerical models
KW  - Stability analysis
KW  - Analytical models
DO  - 10.1109/IROS.2018.8593821
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Stealth walking is a way of walking carefully and noiselessly, and is an approach to stable legged locomotion of underactuated robotic walkers on irregular terrains. This paper proposes a method for generating a high-speed stealth walking gait without including double-limb support phase, and discusses the effect of upper-body control and semicircular feet on the gait properties. First, we introduce a model of a 3-link planar underactuated biped with an upper body and semicircular feet, and derive the approximate target initial state of the upper body by using the linearized equation of motion. Second, we conduct numerical simulations of the nonlinear model to observe the typical stealth walking gaits, and analyze the changing tendency of the upper body motion with respect to the foot radius. Furthermore, we discuss the advantage of semicircular feet through parametric studies of the gait efficiencies.
ER  - 

TY  - CONF
TI  - A Comparison of Assistive Methods for Suturing in MIRS
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4389
EP  - 4395
AU  - G. A. Fontanelli
AU  - G. Yang
AU  - B. Siciliano
PY  - 2018
KW  - dexterous manipulators
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - human-in-the-Ioop
KW  - vision-free
KW  - telemanipulation paradigm
KW  - surgeons control
KW  - minimally invasive robotic surgery
KW  - robotic systems
KW  - laparoscopic interventions
KW  - assistive methods
KW  - da Vinci Research Kit robot
KW  - robot behaviour
KW  - MIRS
KW  - cognitive load
KW  - dexterity
KW  - surgical site
KW  - Robots
KW  - Needles
KW  - Surgery
KW  - Force
KW  - Trajectory
KW  - Force measurement
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593607
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In Minimally Invasive Robotic Surgery (MIRS) a robot is interposed between the surgeon and the surgical site to increase the precision, dexterity, and to reduce surgeon's effort and cognitive load with respect to the standard laparoscopic interventions. However, the modern robotic systems for MIRS are still based on the traditional telemanipulation paradigm, e.g. the robot behaviour is fully under surgeon's control, and no autonomy or assistance is implemented. In this work, supervised and shared controllers have been developed in a vision-free, human-in-the-Ioop, control framework to help surgeon during a surgical suturing procedure. Experiments conducted on the da Vinci Research Kit robot proves the effectiveness of the method indicating also the guidelines for improving results.
ER  - 

TY  - CONF
TI  - External Force/Torque Estimation on a Dexterous Parallel Robotic Surgical Instrument Wrist
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4396
EP  - 4403
AU  - N. Yilmaz
AU  - M. Bazman
AU  - U. Tumerdem
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - force control
KW  - force sensors
KW  - linear motors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - medical robotics
KW  - motion control
KW  - observers
KW  - position control
KW  - surgery
KW  - torque control
KW  - sensorless force estimation algorithm
KW  - rigid link parallel wrist mechanism
KW  - reaction force observers
KW  - back-drivable rigid-link wrist mechanism
KW  - force sensors
KW  - robotic surgical wrist mechanism
KW  - estimation method
KW  - dexterous parallel robotic surgical instrument wrist
KW  - RMS force-torque estimation error values
KW  - external force-torque estimation
KW  - Wrist
KW  - Force
KW  - Robot sensing systems
KW  - Estimation
KW  - Jacobian matrices
KW  - Kinematics
DO  - 10.1109/IROS.2018.8594326
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a novel sensorless force estimation algorithm for the rigid link parallel wrist mechanism of a robotic surgical instrument. The method utilizes novel reaction force observers (RFOB) in joint space, which are modified disturbance observers (DOB) combined with Neural Networks (NN) for inverse dynamics calculations, to estimate external forces acting on the motors. External force/torque estimation in Cartesian space is achieved by the use of the robot Jacobian. The proposed algorithm is applicable to any back-drivable rigid-link wrist mechanism without the need for force sensors. In this paper, the method is implemented on a novel 3 degree-of-freedom (DOF) parallel robotic surgical wrist mechanism that is designed for high dexterity (Â±90 degrees pitch-yaw rotations, thrust motion) and force/torque estimation. The wrist is actuated extracorporally with 3 rigid push-pull rods and 3 linear motors. With a rigid transmission and high back-drivability, external force/torque estimation can be achieved from the motor position readings utilizing the proposed method. Several experiments were performed on the manufactured prototype of the instrument and results validate the efficacy of the wrist and estimation method with RMS force/torque estimation error values of 0.0024 Nm in pitch axis, 0.0043 Nm in yaw axis and 0.1866 N in thrust axis.
ER  - 

TY  - CONF
TI  - Hand-Impedance Measurement During Laparoscopic Training Coupled with Robotic Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4404
EP  - 4410
AU  - H. Tugal
AU  - B. Gautier
AU  - M. Kircicek
AU  - M. S. Erden
PY  - 2018
KW  - end effectors
KW  - force sensors
KW  - medical robotics
KW  - position control
KW  - surgery
KW  - end-effector position information
KW  - impedance measurement
KW  - human hand-impedance
KW  - laparoscopic training program
KW  - physically interactive robotic manipulators
KW  - robotic assistants
KW  - needle
KW  - variable admittance controlled robots
KW  - step vice velocity disturbances
KW  - force sensor
KW  - minimally invasive surgery training box
KW  - Robots
KW  - Force
KW  - Laparoscopes
KW  - Training
KW  - Admittance
KW  - Frequency measurement
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8593560
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents measurements of human hand-impedance during a laparoscopic training program with physically interactive robotic manipulators. The knowledge of how the hand-impedance changes due to training might be useful to inform better training programs and to introduce co-manipulated robotic assistants for effective trainings. Ten novice subjects participated in a three weeks training program for a suturing activity in laparoscopy. The subjects have been instructed to set the needle, enter the skin, and tie knots by using laparoscopic tools within a Minimally Invasive Surgery training box. Variable admittance controlled robots, attached to the tools with force sensors, applied step vice velocity disturbances while subjects were trying to set the needle. Based on the interaction force and end-effector position information, impedances of the left and right hands were computed in four different directions. The computed results were compared with respect to the participants skill progression.
ER  - 

TY  - CONF
TI  - Comparison of 3D Surgical Tool Segmentation Procedures with Robot Kinematics Prior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4411
EP  - 4418
AU  - Y. Su
AU  - I. Huang
AU  - K. Huang
AU  - B. Hannaford
PY  - 2018
KW  - biological tissues
KW  - biomedical MRI
KW  - computerised tomography
KW  - image reconstruction
KW  - image registration
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - robot kinematics
KW  - surgery
KW  - robot-assisted laparoscopic surgery
KW  - surgical guidance
KW  - local 3D reconstruction
KW  - tool-tissue interaction region
KW  - 3D reconstructed model
KW  - Raven II surgical robot system
KW  - 3D surgical tool segmentation procedure
KW  - robot kinematics
KW  - vision-based force estimation
KW  - medical image registration
KW  - preoperative data
KW  - patient anatomy
KW  - surgical task space
KW  - Tools
KW  - Three-dimensional displays
KW  - Cameras
KW  - Image segmentation
KW  - Robot vision systems
KW  - Force
KW  - Image reconstruction
DO  - 10.1109/IROS.2018.8594428
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - 3D reconstruction and surgical tool segmentation are necessary for several advanced tasks in robot-assisted laparoscopic surgery. These tasks include vision-based force estimation, surgical guidance, and medical image registration where pre-operative data (CT or MRI scan image slices) are overlaid on patient anatomy in real-time during surgery [1] to name a few. In this work, two main strategies were considered: (1) initialize with surgical tool segmentation from 2D images, then proceed to local 3D reconstruction near the tool-tissue interaction region by projecting the segmented result into 3D space, and (2) initialize with 3D reconstruction of the entire surgical task space, followed by surgical tool segmentation from within the 3D reconstructed model. Both methods were implemented on the Raven II surgical robot system, and accuracy and time complexity for both methods were comparatively analyzed while considering various task parameters. Finally, based on the results of this work, guidelines for selecting reconstruction and segmentation strategies and procedure for particular situations are outlined in Section V.
ER  - 

TY  - CONF
TI  - Real-Time Tumor Tracking for Pencil Beam Scanning Proton Therapy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4434
EP  - 4440
AU  - S. Vemprala
AU  - S. Saripalli
AU  - C. Vargas
AU  - M. Bues
AU  - Y. Hu
AU  - J. Shen
PY  - 2018
KW  - biological organs
KW  - cancer
KW  - diagnostic radiography
KW  - image motion analysis
KW  - medical image processing
KW  - pneumodynamics
KW  - proton beams
KW  - radiation therapy
KW  - tumours
KW  - tumor locations
KW  - ceramic-metallic fiducials
KW  - surgical clips
KW  - correlation filters
KW  - cross-correlation matching
KW  - advanced cancer treatment system
KW  - pencil beam scanning proton therapy system
KW  - real-time tumor tracking system
KW  - PBS therapy
KW  - organ motion
KW  - normal breathing movement
KW  - X-ray fluoroscopy system
KW  - visicoil markers
KW  - real-time image guidance
KW  - proton beam
KW  - cancer tumors
KW  - fiducial markers
KW  - Tumors
KW  - Real-time systems
KW  - X-ray imaging
KW  - Particle beams
KW  - Target tracking
KW  - Correlation
DO  - 10.1109/IROS.2018.8593861
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe the method and implementation of a real-time tumor tracking system for a pencil beam scanning (PBS) proton therapy system. PBS is an advanced cancer treatment system that can benefit from precise localization of the tumors through motion. We utilize techniques such as cross-correlation matching, correlation filters and small object saliency, creating an array of methods that can detect and track fiducial markers implanted in the cancer tumors. The final aim is to control the proton beam using real-time image guidance. Our technique works robustly on various types of markers such as ceramic/metallic fiducials, visicoil markers and surgical clips. Left and right views of an X-ray fluoroscopy system were utilized to also triangulate the marker positions in full 3D as they are tracked through normal breathing movement and organ motion. We have tested our detection system on data from several patients with different tumor locations both offline and in real-time and wish to implement it within a full treatment system soon. To the best of the authors knowledge, this is the first real time tracking system for PBS therapy that is applicable for various types of fiducials and tumor locations.
ER  - 

TY  - CONF
TI  - Preference-Based Assistance Prediction for Human-Robot Collaboration Tasks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4441
EP  - 4448
AU  - E. C. Grigore
AU  - A. Roncone
AU  - O. Mangin
AU  - B. Scassellati
PY  - 2018
KW  - control engineering computing
KW  - hidden Markov models
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - human-robot collaboration tasks
KW  - learning supportive behavior preferences
KW  - human-level prediction
KW  - personalized supportive behavior model
KW  - observed human workers
KW  - hidden Markov model
KW  - training data
KW  - human peer
KW  - physical tasks
KW  - human worker
KW  - robots
KW  - preference-based assistance prediction
KW  - Task analysis
KW  - Hidden Markov models
KW  - Service robots
KW  - Collaboration
KW  - Legged locomotion
KW  - Data models
DO  - 10.1109/IROS.2018.8593716
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-Robot Collaboration (HRC) aims to develop robots that provide assistance to human workers while performing physical tasks. Such assistance comes in the form of supportive behaviors that are different from the actions part of the task, and that are meant to help a human worker more effectively accomplish the task. Learning how to provide useful behaviors that are tailored to a human peer represents a difficult challenge. This is due to the need of large amounts of training data in the form of real world observations that include information about such preferences. This data needs to encode not only the structure and progression of the task, but also the different workers' preferences with respect to when and what assistance the robot should provide. Our work separates the challenge of learning a model of the task (which requires a large amount of training data) from that of learning supportive behavior preferences for the interaction (which has obvious restrictions for the number of user-provided demonstrations to which we have access). We first learn a hidden Markov model (HMM) from a training set consisting of observed human workers performing the considered task in simulation. We then use this model to predict, while observing the human peer, what supportive behaviors a robot should offer throughout the task. Building upon the hidden state representation, our system is able to learn the supportive behaviors based on as few as five user-annotated demonstrations, learning a personalized supportive behavior model. We evaluate our system on a user study with 14 participants, and show results on par with human-level prediction for the task.
ER  - 

TY  - CONF
TI  - Collaborative Planning for Mixed-Autonomy Lane Merging
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4449
EP  - 4455
AU  - S. Bansal
AU  - A. Cosgun
AU  - A. Nakhaei
AU  - K. Fujimura
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - driver information systems
KW  - game theory
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - road traffic
KW  - road vehicles
KW  - collaborative planning
KW  - social activity
KW  - mixed-autonomy traffic
KW  - Human-driven Vehicle
KW  - HV
KW  - Autonomous Vehicle drive
KW  - AV
KW  - planning framework
KW  - two-lane highway
KW  - double lane merging
KW  - collaborative decision making
KW  - mixed-autonomy lane merging
KW  - Automobiles
KW  - Planning
KW  - Merging
KW  - Collaboration
KW  - Robots
KW  - Autonomous vehicles
DO  - 10.1109/IROS.2018.8594197
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Driving is a social activity: drivers often indicate their intent to change lanes via motion cues. We consider mixed-autonomy traffic where a Human-driven Vehicle (HV) and an Autonomous Vehicle (AV) drive together. We propose a planning framework where the degree to which the AV considers the other agent's reward is controlled by a selfishness factor. We test our approach on a simulated two-lane highway where the AV and HV merge into each other's lanes. In a user study with 21 subjects and 6 different selfishness factors, we found that our planning approach was sound and that both agents had less merging times when a factor that balances the rewards for the two agents was chosen. Our results on double lane merging suggest it to be a non-zero-sum game and encourage further investigation on collaborative decision making algorithms for mixed-autonomy traffic.
ER  - 

TY  - CONF
TI  - Adaptive Modality Selection Algorithm in Robot-Assisted Cognitive Training
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4456
EP  - 4461
AU  - A. TaranoviÄ
AU  - A. JevtiÄ
AU  - C. Torras
PY  - 2018
KW  - cognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - patient rehabilitation
KW  - robot programming
KW  - service robots
KW  - robotic system
KW  - robot-assisted cognitive training
KW  - socially assistive robots
KW  - therapy
KW  - Alzheimer's disease
KW  - mild cognitive impairment
KW  - dementia
KW  - adaptive modality selection algorithm
KW  - interaction modalities
KW  - AMS algorithm
KW  - Shape
KW  - Training
KW  - Service robots
KW  - Manipulators
KW  - Task analysis
KW  - Market research
DO  - 10.1109/IROS.2018.8593730
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interaction of socially assistive robots with users is based on social cues coming from different interaction modalities, such as speech or gestures. However, using all modalities at all times may be inefficient as it can overload the user with redundant information and increase the task completion time. Additionally, users may favor certain modalities over the other as a result of their disability or personal preference. In this paper, we propose an Adaptive Modality Selection (AMS) algorithm that chooses modalities depending on the state of the user and the environment, as well as user preferences. The variables that describe the environment and the user state are defined as resources, and we posit that modalities are successful if certain resources possess specific values during their use. Besides the resources, the proposed algorithm takes into account user preferences which it learns while interacting with users. We tested our algorithm in simulations, and we implemented it on a robotic system that provides cognitive training, specifically Sequential memory exercises. Experimental results show that it is possible to use only a subset of available modalities without compromising the interaction. Moreover, we see a trend for users to perform better when interacting with a system with implemented AMS algorithm.
ER  - 

TY  - CONF
TI  - Continuous Shared Control for Robotic Arm Reaching Driven by a Hybrid Gaze-Brain Machine Interface
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4462
EP  - 4467
AU  - Y. Wang
AU  - G. Xu
AU  - A. Song
AU  - B. Xu
AU  - H. Li
AU  - C. Hu
AU  - H. Zeng
PY  - 2018
KW  - brain-computer interfaces
KW  - continuous systems
KW  - electroencephalography
KW  - end effectors
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical control systems
KW  - medical robotics
KW  - motion control
KW  - shared control paradigm
KW  - human-robot interface
KW  - robot autonomy
KW  - gaze-BMI control
KW  - hybrid gaze-BMI
KW  - robotic arm end-effector
KW  - continuous shared control
KW  - hybrid gaze-brain machine interface
KW  - brain-machine interface
KW  - assistive robot
KW  - motor impaired people
KW  - motion intention strength
KW  - obstacle avoidance
KW  - Robot kinematics
KW  - End effectors
KW  - Task analysis
KW  - Electroencephalography
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594367
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The brain-machine interface (BMI) has been reported to offer the potential for controlling the assistive robot for the motor impaired people, using the non-invasively obtained electroencephalogram (EEG) signals. However, the EEG based BMI may not be sufficient and stable to drive the robot moving freely in its 2D or 3D workspace. The robot autonomy may provide assistance for the BMI users with the shared control paradigm. Nevertheless, users suffers from several limitations of the current shared control paradigms applied on BMI, e.g., loss of sense of control, high mental workload due to unintuitive control with the human-robot interface and fixed level of assistance. To overcome these drawbacks, we propose a new control paradigm for the robotic arm reaching task where the robot autonomy is dynamically blended with the gaze-BMI control from a user. In this paradigm, the hybrid gaze-BMI constitutes an intuitive and effective input to continuously control the robotic arm end-effector moving freely in its 2D workspace, with an adjustable speed proportional to the motion intention strength. Furthermore, the adjustable level of assistance by our paradigm allows the system to balance the user's capabilities and feelings of control while compensating for the reaching task's difficulty. The proposed paradigm is verified in the task where a healthy subject utilizes the hybrid gaze-BMI to control the robotic arm end-effector reaching for a target object while avoiding the obstacle in the path. The experimental results demonstrate that the movements with our shared control paradigm are safer, more efficient and less difficult than those without shared control.
ER  - 

TY  - CONF
TI  - The Socially Invisible Robot Navigation in the Social World Using Robot Entitativity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4468
EP  - 4475
AU  - A. Bera
AU  - T. Randhavane
AU  - E. Kubin
AU  - A. Wang
AU  - K. Gray
AU  - D. Manocha
PY  - 2018
KW  - human-robot interaction
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - simulated robot-human interaction scenarios
KW  - entitative robots
KW  - strong emotional reactions
KW  - socially invisible robot navigation
KW  - robot entitativity
KW  - data-driven algorithm
KW  - navigational algorithms
KW  - trajectory computation
KW  - multirobot systems
KW  - Trajectory
KW  - Navigation
KW  - Psychology
KW  - Computational modeling
KW  - Surveillance
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593411
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a real-time, data-driven algorithm to enhance the social-invisibility of robots within crowds. Our approach is based on prior psychological research, which reveals that people notice and-importantly-react negatively to groups of social actors when they have high entitativity, moving in a tight group with similar appearances and trajectories. In order to evaluate that behavior, we performed a user study to develop navigational algorithms that minimize entitativity. This study establishes mapping between emotional reactions and multi-robot trajectories and appearances, and further generalizes the finding across various environmental conditions. We demonstrate the applicability of our entitativity modeling for trajectory computation for active surveillance and dynamic intervention in simulated robot-human interaction scenarios. Our approach empirically shows that various levels of entitative robots can be used to both avoid and influence pedestrians while not eliciting strong emotional reactions, giving multi-robot systems socially-invisibility.
ER  - 

TY  - CONF
TI  - Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4476
EP  - 4482
AU  - T. Chakraborti
AU  - S. Sreedharan
AU  - A. Kulkarni
AU  - S. Kambhampati
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - planning (artificial intelligence)
KW  - virtual reality
KW  - mixed-reality technologies
KW  - human-robot interaction
KW  - HoloLens
KW  - human-in-the-loop operation
KW  - projection-aware task planning capabilities
KW  - Robots
KW  - Task analysis
KW  - Planning
KW  - Virtual reality
KW  - Observers
KW  - Vocabulary
KW  - Natural languages
DO  - 10.1109/IROS.2018.8593830
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent advances in mixed-reality technologies have renewed interest in alternative modes of communication for human-robot interaction. However, most of the work in this direction has been confined to tasks such as teleoperation, simulation or explication of individual actions of a robot. In this paper, we will discuss how the capability to project intentions affect the task planning capabilities of a robot. Specifically, we will start with a discussion on how projection actions can be used to reveal information regarding the future intentions of the robot at the time of task execution. We will then pose a new planning paradigm - projection-aware planning - whereby a robot can trade off its plan cost with its ability to reveal its intentions using its projection actions. We will demonstrate each of these scenarios with the help of a joint human-robot activity using the HoloLens.
ER  - 

TY  - CONF
TI  - KnowRobSIM â Game Engine-Enabled Knowledge Processing Towards Cognition-Enabled Robot Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4491
EP  - 4498
AU  - A. Haidu
AU  - D. BeÃler
AU  - A. K. BozcuoÄlu
AU  - M. Beetz
PY  - 2018
KW  - cognitive systems
KW  - computer games
KW  - control engineering computing
KW  - data structures
KW  - decision making
KW  - inference mechanisms
KW  - knowledge representation
KW  - manipulators
KW  - motion control
KW  - rendering (computer graphics)
KW  - action simulation
KW  - physics engine
KW  - AI knowledge representation
KW  - decision making capabilities
KW  - robotic agents
KW  - motion parameterization
KW  - symbolic reasoning methods
KW  - modern game engine technology
KW  - game engine-enabled knowledge processing
KW  - cognition-enabled robot control
KW  - KnowRobSIM
KW  - reasoning methods
KW  - manipulation tasks
KW  - data structures
KW  - world scene rendering
KW  - object manipulation
KW  - Cognition
KW  - Games
KW  - Engines
KW  - Robots
KW  - Force
KW  - Data structures
DO  - 10.1109/IROS.2018.8593935
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - AI knowledge representation and reasoning methods consider actions to be blackboxes that abstract away from how they are executed. This abstract view does not suffice for the decision making capabilities required by robotic agents that are to accomplish manipulation tasks. Such robots have to reason about how to pour without spilling, where to grasp a pot, how to open different containers, and so on. To enable such reasoning it is necessary to consider how objects are perceived, how motions can be executed and parameterized, and how motion parameterization affects the physical effects of actions. To this end, we propose to complement and extend symbolic reasoning methods with KnowRobSIM, an additional reasoning infrastructure based on modern game engine technology, including the subsymbolic world modeling through data structures, action simulation based on physics engine, and world scene rendering. We demonstrate how KnowRobSIM can perform powerful reasoning, prediction, and learning tasks that are required for informed decision making in object manipulation.
ER  - 

TY  - CONF
TI  - Probabilistic Collision Threat Assessment for Autonomous Driving at Road Intersections Inclusive of Vehicles in Violation of Traffic Rules
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4499
EP  - 4506
AU  - S. Noh
PY  - 2018
KW  - belief networks
KW  - collision avoidance
KW  - decision making
KW  - mobile robots
KW  - probability
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - traffic rules violation
KW  - vehicles road intersections inclusive
KW  - Bayesian networks
KW  - time window filtering
KW  - decision-making
KW  - in-vehicle testing
KW  - nonviolation vehicles
KW  - closed urban test road
KW  - violation vehicles
KW  - autonomous vehicle
KW  - probabilistic collision threat assessment algorithm
KW  - autonomous driving
KW  - Roads
KW  - Reliability
KW  - Principal component analysis
KW  - Probabilistic logic
KW  - Prediction algorithms
KW  - Autonomous vehicles
DO  - 10.1109/IROS.2018.8593645
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a probabilistic collision threat assessment algorithm for autonomous driving at road intersections that assesses a given traffic situation at an intersection reliably and robustly for an autonomous vehicle to cross the intersection safely, even in the face of violation vehicles (that is, vehicles in violation of traffic rules at the intersection). To this end, the proposed algorithm employs a detailed digital map to predict future paths of observed vehicles and then utilizes the predicted future paths to identify potential threats (vehicles) and potential collision areas, regardless of whether observed vehicles are obeying traffic rules at the intersection. Next, by means of Bayesian networks and time window filtering under an independent and distributed reasoning structure, it assesses the potential threats regarding the possibility of collision reliably and robustly, even under uncertain and incomplete noise data. Then, it has been tested and evaluated through in-vehicle testing on a closed urban test road under traffic conditions inclusive of non-violation and violation vehicles. In-vehicle testing results show that the performance of the proposed algorithm is sufficiently reliable to be used in decision-making for autonomous driving at intersections in terms of reliability and robustness, even in the face of violation vehicles.
ER  - 

TY  - CONF
TI  - LiDAR-Based Object Tracking and Shape Estimation Using Polylines and Free-Space Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4515
EP  - 4522
AU  - S. Kraemer
AU  - C. Stiller
AU  - M. E. Bouzouraa
PY  - 2018
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - traffic engineering computing
KW  - tracking framework targets
KW  - simultaneous estimation
KW  - free-space information
KW  - accurate dynamic estimates
KW  - consistent shape reconstructions
KW  - polylines
KW  - reliable object perception
KW  - automated driving
KW  - precise contour measurements
KW  - object geometry
KW  - bounding boxes
KW  - public traffic
KW  - box assumption
KW  - object contours
KW  - object poses
KW  - 2D polylines
KW  - tracking systems
KW  - Shape
KW  - Estimation
KW  - Laser modes
KW  - Measurement by laser beam
KW  - Radar tracking
KW  - Geometry
KW  - Shape measurement
DO  - 10.1109/IROS.2018.8593385
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable object perception is a vital requirement for automated driving. Despite the availability of precise contour measurements, most state-of-the-art tracking systems still represent object geometry as bounding boxes. However, there are objects operating in public traffic for which the box assumption is highly inappropriate. We therefore propose to represent object contours using 2D polylines. Taking into account the mutual dependence of object poses and shape, our tracking framework targets at a simultaneous estimation of both states. Moreover, we propose to augment scan segments with free-space information at their boundaries and show how this knowledge can be incorporated into the tracking framework and beyond. Evaluation with real scan data shows that our method produces accurate dynamic estimates and consistent shape reconstructions.
ER  - 

TY  - CONF
TI  - Search-Based Optimal Motion Planning for Automated Driving
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4523
EP  - 4530
AU  - Z. Ajanovic
AU  - B. Lacevic
AU  - B. Shyrokau
AU  - M. Stolz
AU  - M. Horn
PY  - 2018
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - road vehicles
KW  - search problems
KW  - trajectory control
KW  - automated driving
KW  - fast motion planning
KW  - robust motion planning
KW  - real-time computation
KW  - urban conditions
KW  - convenient geometrical representation
KW  - search space
KW  - driving constraints
KW  - classical path planning approach
KW  - exact cost-to-go map
KW  - optimal motion trajectory
KW  - time horizons
KW  - fast driving conditions
KW  - slow driving conditions
KW  - search-based optimal motion planning
KW  - Planning
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Dynamics
KW  - Roads
KW  - Search problems
KW  - Automation
KW  - motion planning
KW  - automated driving
KW  - lane change
KW  - multi-lane driving
KW  - traffic lights
KW  - A* search
KW  - MPC
DO  - 10.1109/IROS.2018.8593813
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a framework for fast and robust motion planning designed to facilitate automated driving. The framework allows for real-time computation even for horizons of several hundred meters and thus enabling automated driving in urban conditions. This is achieved through several features. Firstly, a convenient geometrical representation of both the search space and driving constraints enables the use of classical path planning approach. Thus, a wide variety of constraints can be tackled simultaneously (other vehicles, traffic lights, etc.). Secondly, an exact cost-to-go map, obtained by solving a relaxed problem, is then used by A*-based algorithm with model predictive flavour in order to compute the optimal motion trajectory. The algorithm takes into account both distance and time horizons. The approach is validated within a simulation study with realistic traffic scenarios. We demonstrate the capability of the algorithm to devise plans both in fast and slow driving conditions, even when full stop is required.
ER  - 

TY  - CONF
TI  - Visual Vehicle Tracking Through Noise and Occlusions Using Crowd-Sourced Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4531
EP  - 4538
AU  - S. M.S.
AU  - H. Grimmett
AU  - L. PlatinskÃ½
AU  - P. OndrÃºÅ¡ka
PY  - 2018
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - traffic engineering computing
KW  - video signal processing
KW  - video surveillance
KW  - camera phones
KW  - performed city-scale structure-from-motion
KW  - high-accuracy localisation
KW  - unsupervised motion prediction
KW  - real-time visual tracking pipeline
KW  - monocular camera
KW  - large-scale datasets
KW  - New York City
KW  - perception system
KW  - large-scale crowd-sourced maps
KW  - visual vehicle tracking
KW  - location-specific method
KW  - Automobiles
KW  - Trajectory
KW  - Tracking
KW  - Three-dimensional displays
KW  - Cameras
KW  - Pipelines
KW  - Hidden Markov models
DO  - 10.1109/IROS.2018.8593378
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a location-specific method to visually track the positions of observed vehicles based on large-scale crowd-sourced maps. We equipped a large fleet of cars that drive around cities with camera phones mounted on the dashboard, and performed city-scale structure-from-motion to accurately reconstruct the trajectories taken by the vehicles. We show that these data can be used to first create a system enabling high-accuracy localisation, and then to accurately predict the future motion of newly observed cars in the camera view. As a basis for the method we use a recently proposed system [1] for unsupervised motion prediction and extend it to a real-time visual tracking pipeline which can track vehicles through noise and extended occlusions using only a monocular camera. The system is tested using two large-scale datasets of San Francisco and New York City containing millions of frames. We demonstrate the performance of the system in a variety of traffic, time, and weather conditions. The presented system requires no manual annotation or knowledge of road infrastructure. To our knowledge, this is the first time a perception system based on a large-scale crowd-sourced maps has been evaluated at this scale.
ER  - 

TY  - CONF
TI  - Vehicle Rebalancing for Mobility-on-Demand Systems with Ride-Sharing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4539
EP  - 4546
AU  - A. Wallar
AU  - M. Van Der Zee
AU  - J. Alonso-Mora
AU  - D. Rus
PY  - 2018
KW  - integer programming
KW  - linear programming
KW  - road traffic
KW  - road vehicles
KW  - scheduling
KW  - vehicle routing
KW  - historical taxi data
KW  - integer linear programming
KW  - idle vehicle redistribution
KW  - MoD systems
KW  - urban transportation
KW  - mobility-on-demand systems
KW  - real-time demand estimate
KW  - fleet operating area
KW  - MoD fleet
KW  - vehicle routes
KW  - road vehicles
KW  - ride-sharing
KW  - vehicle rebalancing
KW  - average waiting time
KW  - rebalancing regions
KW  - time 13.7 s
KW  - Schedules
KW  - Real-time systems
KW  - Delays
KW  - Partitioning algorithms
KW  - Public transportation
KW  - Automobiles
DO  - 10.1109/IROS.2018.8593743
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recent developments in Mobility-on-Demand (MoD) systems have demonstrated the potential of road vehicles as an efficient mode of urban transportation Newly developed algorithms can compute vehicle routes in real-time for batches of requests and allow for multiple requests to share vehicles. These algorithms have primarily focused on optimally producing vehicle schedules to pick up and drop off requests. The redistribution of idle vehicles to areas of high demand, known as rebalancing, on the contrary has received little attention in the context of ride-sharing. In this paper, we present a method to rebalance idle vehicles in a ride-sharing enabled MoD fleet. This method consists of an algorithm to optimally partition the fleet operating area into rebalancing regions, an algorithm to determine a real-time demand estimate for every region using incoming requests, and an algorithm to optimize the assignment of idle vehicles to these rebalancing regions using an integer linear program. Evaluation with historical taxi data from Manhattan shows that we can service 99.8% of taxi requests in Manhattan using 3000 vehicles with an average waiting time of 57.4 seconds and an average in-car delay of 13.7 seconds. Moreover, we can achieve a higher service rate using 2000 vehicles than prior work achieved with 3000. Furthermore, with a fleet of 3000 vehicles, we reduce the average travel delay by 86%, the average waiting time by 37%, and the amount of ignored requests by 95% compared to earlier work at the expense of an increased distance travelled by the fleet.
ER  - 

TY  - CONF
TI  - Transferable Pedestrian Motion Prediction Models at Intersections
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4547
EP  - 4553
AU  - M. Shen
AU  - G. Habibi
AU  - J. P. How
PY  - 2018
KW  - automobiles
KW  - feature selection
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pedestrians
KW  - road safety
KW  - statistical analysis
KW  - trajectory control
KW  - autonomous cars
KW  - transfer learning algorithms
KW  - pedestrian trajectories
KW  - transferable pedestrian motion prediction algorithm
KW  - trajectory planning
KW  - inverse reinforcement learning
KW  - feature selection
KW  - IRL
KW  - augmented seminonnegative sparse coding
KW  - ASNSC
KW  - Trajectory
KW  - Hidden Markov models
KW  - Semantics
KW  - Predictive models
KW  - Prediction algorithms
KW  - Feature extraction
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593783
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One desirable capability of autonomous cars is to accurately predict the pedestrian motion near intersections for safe and efficient trajectory planning. We are interested in developing transfer learning algorithms that can be trained on the pedestrian trajectories collected at one intersection and yet still provide accurate predictions of the trajectories at another, previously unseen intersection. We first discussed the feature selection for transferable pedestrian motion models in general. Following this discussion, we developed one transferable pedestrian motion prediction algorithm based on Inverse Reinforcement Learning (IRL) that infers pedestrian intentions and predicts future trajectories based on observed trajectory. We evaluated our algorithm at three intersections. We used the accuracy of augmented semi-nonnegative sparse coding (ASNSC), trained and tested at the same intersection as a baseline. The result shows that the proposed algorithm improves the baseline accuracy by a statistically significant percentage in both non-transfer task and transfer task.
ER  - 

TY  - CONF
TI  - Model-Free Grasp Planning for Configurable Vacuum Grippers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4554
EP  - 4561
AU  - F. You
AU  - M. Mende
AU  - D. Å togl
AU  - B. Hein
AU  - T. KrÃ¶ger
PY  - 2018
KW  - data acquisition
KW  - dexterous manipulators
KW  - grippers
KW  - path planning
KW  - robot vision
KW  - model-free grasp planning
KW  - adequate sensor-based surface acquisition
KW  - two-step 3D data acquisition approach
KW  - action execution
KW  - iterative grasp planning
KW  - visual detection
KW  - arbitrary suction cups
KW  - contact surfaces
KW  - formalized aspects
KW  - arbitrary positions
KW  - robustly grasp unknown objects
KW  - grasp planner
KW  - robot arm
KW  - visual sensor
KW  - dynamically configurable vacuum gripper
KW  - robot system
KW  - optimal grasp configurations
KW  - configurable vacuum gripper system
KW  - Grippers
KW  - Three-dimensional displays
KW  - Planning
KW  - Grasping
KW  - Robot sensing systems
KW  - Force
DO  - 10.1109/IROS.2018.8594227
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A concept consisting of a new configurable vacuum gripper system and a corresponding method for determining optimal grasp configurations solely based on 3D vision is introduced. The robot system consists of a dynamically configurable vacuum gripper, a visual sensor, and a robot arm that are used in combination with a new grasp planner to robustly grasp unknown objects in arbitrary positions. For this purpose, formalized aspects of selecting contact surfaces for arbitrary suction cups are described; the concept involves visual detection of the objects, segmentation, iterative grasp planning, and action execution. The approach allows for a fast and efficient, yet precise execution of grasps. The core idea is a two-step 3D data acquisition approach and grasp point computation that takes advantage of the fact that the suction cups of the gripper can all be aligned axis-parallel. Therefore, an adequate sensor-based surface acquisition is done from a single viewpoint with respect to the gripper. Results of realworld experiments show that the proposed concept is suitable for a wide range of different and unknown objects in our setup.
ER  - 

TY  - CONF
TI  - Five-Fingered Hand with Wide Range of Thumb Using Combination of Machined Springs and Variable Stiffness Joints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4562
EP  - 4567
AU  - S. Makino
AU  - K. Kawaharazuka
AU  - A. Fujii
AU  - M. Kawamura
AU  - T. Makabe
AU  - M. Onitsuka
AU  - Y. Asano
AU  - K. Okada
AU  - K. Kawasaki
AU  - M. Inaba
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - dexterous manipulators
KW  - shear modulus
KW  - springs (mechanical)
KW  - grasping
KW  - fingered hand
KW  - machined spring
KW  - variable stiffness
KW  - human hands
KW  - gripping force
KW  - robot hands
KW  - thumb CM joint
KW  - MP joints
KW  - fingers
KW  - variable rigidity mechanism
KW  - joint mechanism
KW  - Springs
KW  - Joints
KW  - Thumb
KW  - Muscles
KW  - Actuators
KW  - Force
KW  - Wires
DO  - 10.1109/IROS.2018.8594316
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human hands can not only grasp objects of various shape and size and manipulate them in hands but also exert such a large gripping force that they can support the body in the situations such as dangling a bar and climbing a ladder. On the other hand, it is difficult for most robot hands to manage both. Therefore in this paper we developed the hand which can grasp various objects and exert large gripping force. To develop such hand, we focused on the thumb CM joint with wide range of motion and the MP joints of four fingers with the DOF of abduction and adduction. Based on the hand with large gripping force and flexibility using machined spring, we applied above mentioned joint mechanism to the hand. The thumb CM joint has wide range of motion because of the combination of three machined springs and MP joints of four fingers have variable rigidity mechanism instead of driving each joint independently in order to move joint in limited space and by limited actuators. Using the developed hand, we achieved the grasping of various objects, supporting a large load and several motions with an arm.
ER  - 

TY  - CONF
TI  - VARO-Fi: A Variable Orientable Gripper to Obtain In-Hand Manipulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4568
EP  - 4575
AU  - N. Rahman
AU  - D. Caldwell
AU  - F. Cannella
PY  - 2018
KW  - control engineering computing
KW  - design engineering
KW  - end effectors
KW  - grippers
KW  - variable orientable gripper
KW  - obtain in-hand manipulation
KW  - variable orientable fingers
KW  - VARO-fi
KW  - gripper platform
KW  - in-hand manipulation tasks
KW  - Payloads
KW  - Grippers
KW  - Grasping
KW  - Kinematics
KW  - Fasteners
KW  - End effectors
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594380
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a novel gripper or end-effector named VARO-fi (VARiable Orientable fingers with translation), with the aim of obtaining human like prehensile manoeuvre such as, in-hand manipulation. The 4 fingered VARO-fi consists of 9 degrees of freedom and it can perform several in-hand manipulation tasks which have been described in this paper. Moreover, the gripper is a simplification of previously proposed gripper platform called Dexclar. The derivation of VARO-fi has been presented and its capabilities have been demonstrated by experiments. Although a generic convex payload is considered as a primitive in the design of VARO-fi however, it is capable to address manipulation for other regular shaped payloads, which has been proven by experiments. A comparison is also illustrated in order to underline the strength of the novel gripper with respect to the state of the art.
ER  - 

TY  - CONF
TI  - The Co-Gripper: A Wireless Cooperative Gripper for Safe Human Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4576
EP  - 4581
AU  - G. Salvietti
AU  - Z. Iqbal
AU  - I. Hussain
AU  - D. Prattichizzo
AU  - M. Malvezzi
PY  - 2018
KW  - grippers
KW  - human-robot interaction
KW  - robust control
KW  - safe human robot interaction
KW  - intuitive control
KW  - industrial service applications
KW  - robotic device
KW  - manipulation tasks
KW  - modular underactuated structure
KW  - robotic arms
KW  - wearable wireless control interface
KW  - human operator
KW  - gripper performance
KW  - human-robot cooperation tasks
KW  - co-gripper
KW  - Grippers
KW  - Collaboration
KW  - Robot kinematics
KW  - Manipulators
KW  - Service robots
KW  - Wireless communication
DO  - 10.1109/IROS.2018.8593877
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce a set of guidelines for the design of grippers suitable for a safe human robot/interaction in cooperative tasks. Modularity, adaptability, robustness, intuitive control, limited weight are some of the key elements that could allow to effectively spread these devices in industrial and service applications. Following such guidelines, we present the prototype of the Co-Gripper: a robotic device for cooperative manipulation tasks with humans. The gripper is composed of two pairs of fingers, actuated with two motors, that can be controlled in a coordinated way or independently. Each finger has a modular underactuated structure, composed of three phalanges connected by passive joints. The gripper is wireless, so it can be easily connected both to the robotic arms and on passive structures. We designed a wearable wireless control interface composed of a ring and a bracelet allowing a simple and intuitive activation of the gripper without limiting human operator's manipulation capabilities. We performed a set of tests to quantify gripper performance and to exploit its potentialities in human-robot cooperation tasks.
ER  - 

TY  - CONF
TI  - The KIT Swiss Knife Gripper for Disassembly Tasks: A Multi-Functional Gripper for Bimanual Manipulation with a Single Arm
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4590
EP  - 4597
AU  - J. BorrÃ s
AU  - R. Heudorfer
AU  - S. Rader
AU  - P. Kaiser
AU  - T. Asfour
PY  - 2018
KW  - assembling
KW  - design engineering
KW  - dexterous manipulators
KW  - grippers
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - bimanual manipulation
KW  - electromechanical devices
KW  - classic dual arm manipulation
KW  - classic industrial robotic arms kinematics
KW  - general purpose grasping
KW  - KIT swiss knife gripper
KW  - disassembly tasks
KW  - robotic gripper design
KW  - dexterous in-hand manipulation
KW  - Grippers
KW  - Tools
KW  - Task analysis
KW  - Grasping
KW  - Manipulators
KW  - Service robots
DO  - 10.1109/IROS.2018.8593567
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents the concept of a robotic gripper designed for the disassembly of electromechanical devices that comprises several innovative ideas. Novel concepts include the ability to interchange built-in tools without the need to grasp them, the ability to reposition grasped objects in-hand, the capability of performing classic dual arm manipulation within the gripper and the utilization of classic industrial robotic arms kinematics within a robotic gripper. We analyze state of the art grippers and robotic hands designed for dexterous in-hand manipulation and extract common characteristics and weak points. The presented concept is obtained from the task requirements for disassembly of electromechanical devices and it is then evaluated for general purpose grasping, in-hand manipulation and operations with tools. We further present the CAD design for a first prototype.
ER  - 

TY  - CONF
TI  - Learning Image-Conditioned Dynamics Models for Control of Underactuated Legged Millirobots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4606
EP  - 4613
AU  - A. Nagabandi
AU  - G. Yang
AU  - T. Asmar
AU  - R. Pandya
AU  - G. Kahn
AU  - S. Levine
AU  - R. S. Fearing
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - microrobots
KW  - mobile robots
KW  - neural nets
KW  - robot dynamics
KW  - underactuated legged systems
KW  - hand-engineered controllers
KW  - dynamic maneuvers
KW  - complex terrains
KW  - real-world legged millirobot
KW  - learned neural network models
KW  - predictive model
KW  - expressive capacity neural network models
KW  - high-capacity neural network models
KW  - effective learning
KW  - dynamic legged millirobot
KW  - image-conditioned dynamics models
KW  - underactuated legged millirobots
KW  - low manufacturing costs
KW  - complex environments
KW  - highly dynamic systems
KW  - Vehicle dynamics
KW  - Legged locomotion
KW  - Neural networks
KW  - Adaptation models
KW  - Predictive models
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594193
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Millirobots are a promising robotic platform for many applications due to their small size and low manufacturing costs. Legged millirobots, in particular, can provide increased mobility in complex environments and improved scaling of obstacles. However, controlling these small, highly dynamic, and underactuated legged systems is difficult. Hand-engineered controllers can sometimes control these legged millirobots, but they have difficulties with dynamic maneuvers and complex terrains. We present an approach for controlling a real-world legged millirobot that is based on learned neural network models. Using less than 17 minutes of data, our method can learn a predictive model of the robot's dynamics that can enable effective gaits to be synthesized on the fly for following user-specified waypoints on a given terrain. Furthermore, by leveraging expressive, high-capacity neural network models, our approach allows for these predictions to be directly conditioned on camera images, endowing the robot with the ability to predict how different terrains might affect its dynamics. This enables sample-efficient and effective learning for locomotion of a dynamic legged millirobot on various terrains, including gravel, turf, carpet, and styrofoam. Videos and further details can be found at https://sites.google.com/view/imageconddyn.
ER  - 

TY  - CONF
TI  - Online Adaptation of Robot Pushing Control to Object Properties
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4614
EP  - 4621
AU  - S. Krivic
AU  - J. Piater
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - unknown objects
KW  - data-driven approach
KW  - local inverse models
KW  - robot-object interaction
KW  - push manipulation
KW  - object behaviour
KW  - maximum a posteriori estimation
KW  - pushing objects
KW  - holonomic mobile robot base
KW  - diverse object set
KW  - learned inverse models
KW  - object properties
KW  - online adaptation
KW  - robot pushing control
KW  - robotic scenarios
KW  - real-world environments
KW  - MAP
KW  - Inverse problems
KW  - Adaptation models
KW  - Robot kinematics
KW  - Friction
KW  - Feedforward systems
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594192
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pushing is a common task in robotic scenarios. In real-world environments, robots need to manipulate various unknown objects without previous experience. We propose a data-driven approach for learning local inverse models of robot-object interaction for push manipulation. The robot makes observations of the object behaviour on the fly and adapts its movement direction. The proposed model is probabilistic, and we update it using maximum a posteriori (MAP) estimation. We test our method by pushing objects with a holonomic mobile robot base. Validation of results over a diverse object set demonstrates a high degree of robustness and a high success rate in pushing objects towards a fixed target and along a path compared to previous methods. Moreover, based on learned inverse models, the robot can learn object properties and distinguish between different object behaviours when they are pushed from different sides.
ER  - 

TY  - CONF
TI  - Composable Learning with Sparse Kernel Representations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4622
EP  - 4628
AU  - E. Tolstaya
AU  - E. Stump
AU  - A. Koppel
AU  - A. Ribeiro
PY  - 2018
KW  - collision avoidance
KW  - Hilbert spaces
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - sparse matrices
KW  - stochastic processes
KW  - obstacle-avoidance policies
KW  - Reproducing kernel Hilbert space
KW  - NAF
KW  - 2D environment
KW  - sparse kernel representations
KW  - normalized advantage function
KW  - state-action function
KW  - nonparametric controllers
KW  - reinforcement learning algorithm
KW  - composable learning
KW  - Kernel
KW  - Stochastic processes
KW  - Hilbert space
KW  - Data models
KW  - Training
KW  - Complexity theory
KW  - Robots
DO  - 10.1109/IROS.2018.8594065
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a reinforcement learning algorithm for learning sparse non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve the sample complexity of this approach by imposing a structure of the state-action function through a normalized advantage function (NAF). This representation of the policy enables efficiently composing multiple learned models without additional training samples or interaction with the environment. We demonstrate the performance of this algorithm on learning obstacle-avoidance policies in multiple simulations of a robot equipped with a laser scanner while navigating in a 2D environment. We apply the composition operation to various policy combinations and test them to show that the composed policies retain the performance of their components. We also transfer the composed policy directly to a physical platform operating in an arena with obstacles in order to demonstrate a degree of generalization.
ER  - 

TY  - CONF
TI  - Compensating for Context by Learning Local Models of Perception Performance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4629
EP  - 4634
AU  - H. Hu
AU  - G. Kantor
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - probability
KW  - robot vision
KW  - stereo image processing
KW  - perception performance
KW  - perception system performance
KW  - environmental geometry
KW  - probabilistic performance
KW  - monocular odometry systems
KW  - stereo visual odometry systems
KW  - system failures
KW  - ground robot
KW  - Context modeling
KW  - Visual odometry
KW  - Data models
KW  - Training data
KW  - Predictive models
KW  - Prediction algorithms
DO  - 10.1109/IROS.2018.8593778
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Perception system performance can vary dramatically with contextual factors such as environmental geometry, appearance, and other phenomena. In this work we present a theoretical framework for understanding the role of context in perception and discuss three approaches for predicting probabilistic performance from observations by efficiently learning local performance models. We compare these approaches with experiments on the monocular and stereo visual odometry systems for a ground robot, and show that they can effectively predict system failures in a wide variety of environments.
ER  - 

TY  - CONF
TI  - Setting up a Reinforcement Learning Task with a Real-World Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4635
EP  - 4640
AU  - A. Rupam Mahmood
AU  - D. Korenkevych
AU  - B. J. Komer
AU  - J. Bergstra
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - multi-robot systems
KW  - hard-to-engineer adaptive solutions
KW  - complex tasks
KW  - diverse robotic tasks
KW  - reinforcement learning research
KW  - learning task
KW  - real-world robot
KW  - effective learning
KW  - learning performance
KW  - task setup
KW  - UR5 robotic arm
KW  - Task analysis
KW  - Robot sensing systems
KW  - Instruction sets
KW  - Delays
KW  - Reinforcement learning
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593894
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning is a promising approach to developing hard-to-engineer adaptive solutions for complex and diverse robotic tasks. However, learning with real-world robots is often unreliable and difficult, which resulted in their low adoption in reinforcement learning research. This difficulty is worsened by the lack of guidelines for setting up learning tasks with robots. In this work, we develop a learning task with a UR5 robotic arm to bring to light some key elements of a task setup and study their contributions to the challenges with robots. We find that learning performance can be highly sensitive to the setup, and thus oversights and omissions in setup details can make effective learning, reproducibility, and fair comparison hard. Our study suggests some mitigating steps to help future experimenters avoid difficulties and pitfalls. We show that highly reliable and repeatable experiments can be performed in our setup, indicating the possibility of reinforcement learning research extensively based on real-world robots.
ER  - 

TY  - CONF
TI  - CINet: A Learning Based Approach to Incremental Context Modeling in Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4641
EP  - 4646
AU  - F. Irmak DoÄan
AU  - Ä°. Bozcan
AU  - M. Ãelik
AU  - S. Kalkan
PY  - 2018
KW  - learning (artificial intelligence)
KW  - recurrent neural nets
KW  - robots
KW  - incremental context modeling
KW  - robots
KW  - rule-based approach
KW  - recurrent neural network
KW  - CINet
KW  - learning based approach
KW  - scene reasoning tasks
KW  - Context modeling
KW  - Training
KW  - Robots
KW  - Computational modeling
KW  - Resource management
KW  - Recurrent neural networks
KW  - Testing
DO  - 10.1109/IROS.2018.8593633
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There have been several attempts at modeling context in robots. However, either these attempts assume a fixed number of contexts or use a rule-based approach to determine when to increment the number of contexts. In this paper, we pose the task of when to increment as a learning problem, which we solve using a Recurrent Neural Network. We show that the network successfully (with 98% testing accuracy) learns to predict when to increment, and demonstrate, in a scene modeling problem (where the correct number of contexts is not known), that the robot increments the number of contexts in an expected manner (i.e., the entropy of the system is reduced). We also present how the incremental model can be used for various scene reasoning tasks.
ER  - 

TY  - CONF
TI  - Learning Generalizable Robot Skills from Demonstrations in Cluttered Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4655
EP  - 4660
AU  - M. Asif Rana
AU  - M. Mukadam
AU  - S. Reza Ahmadzadeh
AU  - S. Chernova
AU  - B. Boots
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - trajectory control
KW  - learning from demonstration
KW  - LfD approach
KW  - reaching skills
KW  - placing skills
KW  - 7-DOF JACO2 manipulator
KW  - clutter-free environments
KW  - human demonstrations
KW  - cluttered environments
KW  - generalizable robot skills
KW  - salient human behavior
KW  - recent inference-based technique
KW  - incremental skill learning approach
KW  - importance weighted batch
KW  - Trajectory
KW  - Robots
KW  - Clamps
KW  - Covariance matrices
KW  - Collision avoidance
KW  - Stochastic processes
KW  - Clutter
DO  - 10.1109/IROS.2018.8593624
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning from Demonstration (LfD) is a popular approach to endowing robots with skills without having to program them by hand. Typically, LfD relies on human demonstrations in clutter-free environments. This prevents the demonstrations from being affected by irrelevant objects, whose influence can obfuscate the true intention of the human or the constraints of the desired skill. However, it is unrealistic to assume that the robot's environment can always be restructured to remove clutter when capturing human demonstrations. To contend with this problem, we develop an importance weighted batch and incremental skill learning approach, building on a recent inference-based technique for skill representation and reproduction. Our approach reduces unwanted environmental influences on the learned skill, while still capturing the salient human behavior. We provide both batch and incremental versions of our approach and validate our algorithms on a 7-DOF JACO2 manipulator with reaching and placing skills.
ER  - 

TY  - CONF
TI  - Interacting with a âTransparentâ Upper-Limb Exoskeleton: A Human Motor Control Approach
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4661
EP  - 4666
AU  - S. Bastide
AU  - N. Vignais
AU  - F. Geffard
AU  - B. Berret
PY  - 2018
KW  - biomechanics
KW  - human-robot interaction
KW  - medical robotics
KW  - motion control
KW  - neurophysiology
KW  - optimal control
KW  - patient rehabilitation
KW  - robot dynamics
KW  - robot kinematics
KW  - transparent upper-limb exoskeleton
KW  - human motor control approach
KW  - human-exoskeleton interaction
KW  - exoskeleton device
KW  - motor adaptation
KW  - human motor control research
KW  - as-transparent-as-possible contact/interaction forces
KW  - motor control laws
KW  - human movement
KW  - optimal control simulations
KW  - motor control features
KW  - Exoskeletons
KW  - Motor drives
KW  - Robots
KW  - Torque
KW  - Task analysis
KW  - Perturbation methods
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593991
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Establishing a symbiotic relationship between a human and a exoskeleton is the end goal in many applications in order to provide benefits to the user. However, the literature focusing on the human side of human-exoskeleton interaction has remained less exhaustive than the literature focusing on the design (hardware/software) of the exoskeleton device itself. It is, though, essential to understand how a human adapts his motor control when interacting with an exoskeleton. Motor adaptation is an implicit process carried out by the central nervous system when the body encounters a perturbation, a paradigm that has been extensively studied in the field of human motor control research. When wearing an exoskeleton, even âas-transparent-as-possibleâ, contact/interaction forces may impact well-known motor control laws in a way that may be detrimental to the user, and even compromise usability in real applications. The present paper investigates how interaction with a backdrivable upper-limb exoskeleton (ABLE) set in âtransparentâ mode of control affects the kinematics/dynamics of human movement in a simple task. We find that important motor control features are preserved when moving with ABLE but an overall movement slowness occurs, likely as a response to increased inertia according to optimal control simulations. Such a human motor control approach illustrates one possible way to assess the degree of symbiosis between human and exoskeleton, i.e. by grounding on well-known findings in motor control research.
ER  - 

TY  - CONF
TI  - Wearable Pediatric Gait Exoskeleton - A Feasibility Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4667
EP  - 4672
AU  - A. Ganguly
AU  - D. Sanz-Merodio
AU  - G. Puyuelo
AU  - A. GoÃ±i
AU  - E. Garces
AU  - E. Garcia
PY  - 2018
KW  - gait analysis
KW  - medical robotics
KW  - muscle
KW  - orthotics
KW  - paediatrics
KW  - patient rehabilitation
KW  - metabolic degeneration
KW  - SMA patient rehabilitation
KW  - sit-to-stand movements
KW  - degrees-of-freedom
KW  - flexion-extension
KW  - adduction-abduction
KW  - muscle strength
KW  - wearable exoskeleton
KW  - gait assistance
KW  - feasibility test
KW  - ATLAS exoskeleton
KW  - Spinal Muscular Atrophy patients
KW  - wearable pediatric gait exoskeleton
KW  - Exoskeletons
KW  - Pediatrics
KW  - Diseases
KW  - Force
KW  - Torque
KW  - Hip
KW  - Biomimetics
DO  - 10.1109/IROS.2018.8594211
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study reports the initial testing of a gait exoskeleton for Spinal Muscular Atrophy (SMA) patients having variable muscle strength with no balance or ambulation capabilities. To improve the quality of life of such patients, a pediatric gait exoskeleton was developed. The ATLAS exoskeleton has 8 active degrees of freedom (DOF): 2 at the hip (adduction/abduction and flexion/extension), 1 at the knee and ankle joint for flexion and extension. A feasibility test was performed to gauge the initial response of the patients. This study demonstrates that the exoskeleton was able to provide gait assistance and sit-to-stand movements effectively to the subjects. This kind of wearable exoskeleton will play a key role in the rehabilitation of SMA patients and delay further metabolic degeneration in the future.
ER  - 

TY  - CONF
TI  - Verification of a Robotic Ankle Exoskeleton Control Scheme for Gait Assistance in Individuals with Cerebral Palsy
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4673
EP  - 4678
AU  - G. M. Gasparri
AU  - M. O. Bair
AU  - R. P. Libby
AU  - Z. F. Lerner
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - muscle
KW  - orthopaedics
KW  - orthotics
KW  - paediatrics
KW  - patient rehabilitation
KW  - wearable robots
KW  - robotic ankle exoskeleton control scheme
KW  - gait assistance
KW  - cerebral palsy
KW  - walking ability
KW  - pediatric health
KW  - pediatric physical disability
KW  - pathological gait patterns
KW  - CP
KW  - ankle-foot-orthoses
KW  - clinically relevant improvement
KW  - gait mechanics
KW  - orthopedic surgery
KW  - muscle injections
KW  - physical therapy
KW  - wearable exoskeletons
KW  - gait rehabilitation
KW  - initial clinical verification
KW  - instrumented gait analysis
KW  - positive ankle power
KW  - powered plantar-flexion assistance
KW  - reduced muscle function
KW  - powered assistance magnitude
KW  - powered assistance timing
KW  - net metabolic rate
KW  - locomotion
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Torque
KW  - DC motors
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Muscles
DO  - 10.1109/IROS.2018.8593904
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Walking ability is critically important for pediatric health, well-being, and independence. Children with cerebral palsy (CP), the most prevalent cause of pediatric physical disability, often present pathological gait patterns that negatively impact walking capacity. Reduced function of the muscles surrounding the ankle joint in those with CP also greatly increases the energy cost of transport leading to reduce mobility. Ankle-foot-orthoses show limited effectiveness for clinically relevant improvement in gait mechanics, while orthopedic surgery, muscle injections and physical therapy are unable to completely restore gait function. While wearable exoskeletons hold promise for gait rehabilitation, appropriately controlling the timing and magnitude of powered assistance across individuals and conditions remains a considerable challenge. This work seeks to address this challenge through the design and initial clinical verification of a simple ankle exoskeleton control scheme designed to reduce the metabolic cost of transport during walking in an individual with CP. Preliminary experimental results from instrumented gait analysis following 5 training visits demonstrated a 45% increase in positive ankle power and a 16% reduction in net metabolic rate during walking with the exoskeleton providing powered plantar-flexion assistance compared to walking without the exoskeleton. Future work will expand this investigation to a larger cohort of individuals with CP and across additional modes of locomotion.
ER  - 

TY  - CONF
TI  - Robot-Supported Multiplayer Rehabilitation: Feasibility Study of Haptically Linked Patient-Spouse Training
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4679
EP  - 4684
AU  - K. Baur
AU  - P. Wolf
AU  - V. Klamroth-Marganska
AU  - W. Bierbauer
AU  - U. Scholz
AU  - R. Riener
AU  - J. E. Duarte
PY  - 2018
KW  - computer games
KW  - control engineering computing
KW  - haptic interfaces
KW  - medical computing
KW  - medical robotics
KW  - patient rehabilitation
KW  - user experience
KW  - virtual reality
KW  - game experience
KW  - Haptic Kitchen game
KW  - haptic guidance
KW  - haptic interaction
KW  - haptic performance balancing algorithm
KW  - spouse-controlled haptic support
KW  - patients post-stroke
KW  - robot-supported multiplayer rehabilitation
KW  - haptically linked patient-spouse training
KW  - robot-aided rehabilitation
KW  - multiplayer games
KW  - Air Hockey game
KW  - Games
KW  - Haptic interfaces
KW  - Training
KW  - Robots
KW  - Damping
KW  - Trajectory
KW  - Sports
DO  - 10.1109/IROS.2018.8593769
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multiplayer environments are thought to increase and prolongate active participation in robot-aided rehabilitation. We expect that environments linking patients with their spouses will particularly foster active participation. Thus, we developed two multiplayer games to link the game experience of two players: an Air Hockey game and a Haptic Kitchen game. In the competitive Air Hockey game, differences in skill levels between players were balanced by individualizing haptic guidance or damping forces. In the Haptic Kitchen game, a healthy player could support the patient's movements using a virtual force field. The two players could control the haptic interaction since both the force field and the point of application were visualized. We tested the haptic performance balancing algorithm of the Air Hockey game and the spouse-controlled haptic support of the Kitchen game with patients post-stroke who trained both single- (i.e., alone) and multiplayer training (i.e., with spouse) in eight therapy sessions lasting 45 min each. Mean total rating in Intrinsic Motivation Inventory was 46.9 points (out of 63 points) for multiplayer modes, and 42.7 points for single player modes, respectively. The spouses applied the haptic support in the Haptic Kitchen game during 42 % of the total game duration. We are currently testing more patient-spouse couples to better understand the effects of using these haptic approaches on the behavior and recovery of patients. We foresee this approach can improve the motivation during training and positively influence the at-home behavior of patients, an important goal of rehabilitation training efforts.
ER  - 

TY  - CONF
TI  - A Soft-Exosuit Enables Multi-Scale Analysis of Wearable Robotics in a Bipedal Animal Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4685
EP  - 4691
AU  - S. M. Cox
AU  - J. Rubenson
AU  - G. S. Sawicki
PY  - 2018
KW  - actuators
KW  - biocontrol
KW  - biomechanics
KW  - bone
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - mobile robots
KW  - muscle
KW  - springs (mechanical)
KW  - underlying biological mechanisms
KW  - wearable robot
KW  - wearable robotic device
KW  - human locomotion mechanics
KW  - wearable robotics
KW  - soft-exosuit enables multiscale analysis
KW  - bipedal animal model
KW  - biological system interface
KW  - Kinematics
KW  - Springs
KW  - Tendons
KW  - Robots
KW  - Birds
KW  - Fixtures
DO  - 10.1109/IROS.2018.8593911
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wearable robotics offers a unique opportunity to explore how biological systems interface with engineered parts. But, due to a gap in understanding of the underlying biological mechanisms at work, the state of the art in design and development is a sophisticated form of automated trial and error. Progress is hampered by the difficulty of assessing the direct impact of wearable robots on underlying muscles, tendons and bones during human experimentation. While animal models have provided an experimental platform to explore other biological mechanisms, as of yet, no animal model of a wearable robot during locomotion has been developed. To fill this gap, we have built the first ever wearable robotic device for a freely-Iocomoting, non-human, bipedal animal (Numida melaegris = Guinea fowl), a species whose gait closely mirrors human locomotion mechanics. We found that a spring-loaded soft-exosuit that passively augments the energy stored in distal tendons was both well tolerated and provided consistent torques. Preliminary data showed birds systematically change their kinematics in response to changes to exo-suit spring stiffness, adjusting the timing but not magnitude of the assistive torques. This animal model for wearable robotics allows experiments up and down the broader spatiotemporal scale that are not currently possible in humans. With it we can address questions from short-term adaptations in musculoskeletal dynamics within a single step to broader behavioral and physical changes that come with long term use.
ER  - 

TY  - CONF
TI  - Through-the-Lens Drone Filming
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4692
EP  - 4699
AU  - C. Huang
AU  - Z. Yang
AU  - Y. Kong
AU  - P. Chen
AU  - X. Yang
AU  - K. Cheng
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - feature extraction
KW  - Global Positioning System
KW  - image motion analysis
KW  - image sensors
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - video signal processing
KW  - image composition
KW  - monocular 3D human pose estimation
KW  - drone control system
KW  - drone filming system
KW  - wearable GPS-based sensors
KW  - wearable infrared-based sensors
KW  - through-the-lens drone filming
KW  - aerial filming
KW  - camera control
KW  - drone hardware
KW  - human actions
KW  - drone camera system
KW  - through-the-lens camera planning
KW  - flight control
KW  - through-the-lens drone
KW  - wearable-sensor-based solutions
KW  - drone platform
KW  - outdoor environments
KW  - human movement
KW  - remote controller
KW  - action scenes
KW  - Cameras
KW  - Drones
KW  - Three-dimensional displays
KW  - Sensors
KW  - Pose estimation
KW  - Solid modeling
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594333
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Aerial filming in action scenes using a drone is difficult for inexperienced flyers because manipulating a remote controller and meeting the desired image composition are two independent, while concurrent, tasks. Existing systems attempt to utilize wearable GPS-based or infrared-based sensors to track the human movement and to assist in capturing footage. However, these sensors work only in either indoor (infrared-based) or outdoor environments (GPS-based), but not both. In this paper, we introduce a novel drone filming system which integrates monocular 3D human pose estimation and localization into a drone platform to remove the constraints imposed by wearable-sensor-based solutions. Meanwhile, given the estimated position, we propose a novel drone control system, called âthrough-the-lens drone filmingâ, to allow a cameraman to conveniently control the drone by manipulating a 3D model in the preview, which closes the gap between the flight control and the viewpoint design. Our system includes two key enabling techniques: 1) subject localization based on visual-inertial fusion, and 2) through-the-lens camera planning. This is the first drone camera system which allows users to capture human actions by manipulating the camera in a virtual environment. From the drone hardware, we integrate a gimbal camera and two GPUs into the limited space of a drone and demonstrate the feasibility of running the entire system onboard with insignificant delays, which are sufficient for filming in our real-time application. Experimental results, in both simulation and real-world scenarios, demonstrate that our techniques can greatly ease camera control and capture better videos.
ER  - 

TY  - CONF
TI  - Towards Aerial Recovery of Parachute-Deployed Payloads
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4700
EP  - 4707
AU  - A. Shankar
AU  - S. Elbaum
AU  - C. Detweiler
PY  - 2018
KW  - aerospace robotics
KW  - aircraft control
KW  - mobile robots
KW  - position control
KW  - parachute-deployed payloads
KW  - sensor payloads
KW  - atmospheric profiling applications
KW  - inaccessible regions
KW  - multirotor unmanned aerial system
KW  - parachute-payload system
KW  - long-term payload transportation systems
KW  - aerial recovery
KW  - Payloads
KW  - Target tracking
KW  - Cameras
KW  - Robot sensing systems
KW  - Vehicle dynamics
KW  - Aerodynamics
DO  - 10.1109/IROS.2018.8594082
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensor payloads suspended from parachutes are often used in atmospheric profiling applications. They drift freely and often end up landing in inaccessible regions that make their retrieval challenging or impossible. In this paper, we develop and evaluate an approach using a multirotor unmanned aerial system to autonomously retrieve the parachute while it is still in the air. The system relies only on the initial conditions of the parachute-payload system and feedback from the vehicle's onboard cameras to track and then intercept the parachute mid-air in under 40 seconds on average. We present the results from our field experiments where we demonstrate the feasibility of the system and discuss its applicability to long-term payload transportation systems.
ER  - 

TY  - CONF
TI  - Airborne Docking for Multi-Rotor Aerial Manipulations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4708
EP  - 4714
AU  - R. Miyazaki
AU  - R. Jiang
AU  - H. Paul
AU  - K. Ono
AU  - K. Shimonomura
PY  - 2018
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multirotor aerial robots
KW  - transport multirotor UAV
KW  - winch mechanism
KW  - onboard locolization
KW  - mobile manipulation system
KW  - airborne docking method
KW  - IMU data
KW  - multirotor aerial manipulations
KW  - Winches
KW  - Bars
KW  - Cameras
KW  - Robot vision systems
KW  - DC motors
KW  - Propellers
DO  - 10.1109/IROS.2018.8594513
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We have proposed airborne docking using two multi-rotor aerial robots. This paper presents a transport multi-rotor UAV with winch mechanism and a small multi-rotor with onboard locolization and mobile manipulation system. The winch mechanism enables the UAV to lower and raise a bar to transport another UAV attached to it. The airborne docking method used in our work is chosen in order to avoid the effect of downwash generated by the multi-rotors. With experiments we have verified the possibility of airborne docking, and evaluated how it influences the transport multi-rotor UAV as the load is changed, using the IMU data of UAV.
ER  - 

TY  - CONF
TI  - Optimal Time Allocation for Quadrotor Trajectory Generation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4715
EP  - 4722
AU  - F. Gao
AU  - W. Wu
AU  - J. Pan
AU  - B. Zhou
AU  - S. Shen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - convex programming
KW  - helicopters
KW  - mobile robots
KW  - optimal control
KW  - polynomials
KW  - robot dynamics
KW  - trajectory control
KW  - optimal time allocation
KW  - quadrotor flights
KW  - quadrotor trajectory generation problem
KW  - spatial trajectory
KW  - time optimization
KW  - polynomial trajectories
KW  - quadrotor platform
KW  - kinodynamic limits
KW  - autonomous flights
KW  - open-source ROS-package
KW  - temporal trajectory
KW  - convex program
KW  - mapping function
KW  - Trajectory
KW  - Resource management
KW  - Safety
KW  - Optimization
KW  - Acceleration
KW  - Time-domain analysis
KW  - Shape
DO  - 10.1109/IROS.2018.8593579
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a framework to do optimal time allocation for quadrotor trajectory generation. Using this method, we can generate minimum-time piecewise polynomial trajectories for quadrotor flights. We decouple the quadrotor trajectory generation problem into two folds. Firstly we generate a smooth and safe curve which is parameterized by a virtual variable. This curve named spatial trajectory is independent of time and has fixed spatial properties. Then a mapping function which decides how the quadrotor moves along the spatial trajectory respecting kinodynamic limits is found by minimizing total trajectory time. The mapping function maps the virtual variable to time is named temporal trajectory. We formulate the minimum-time temporal trajectory generation problem as a convex program which can be efficiently solved. We show that the proposed method can corporate with various types of previous trajectory generation method to obtain the optimal time allocation. The proposed method is integrated into a customized light-weight quadrotor platform and is validated by presenting autonomous flights in indoor and outdoor environments. We release our code for time optimization as an open-source ros-package.
ER  - 

TY  - CONF
TI  - Aerial Radio-Based Telemetry for Tracking Wildlife
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4723
EP  - 4728
AU  - H. Bayram
AU  - N. Stefas
AU  - V. Isler
PY  - 2018
KW  - autonomous aerial vehicles
KW  - directive antennas
KW  - mobile radio
KW  - mobile robots
KW  - radio tracking
KW  - telemetry
KW  - aerial radio-based telemetry
KW  - measurement locations
KW  - radio collar
KW  - low-cost directional antenna
KW  - USB receiver
KW  - wedges
KW  - online strategy
KW  - measurement noise
KW  - autonomous aerial robot
KW  - wildlife tracking
KW  - localization uncertainty
KW  - Antenna measurements
KW  - Animals
KW  - Measurement uncertainty
KW  - Uncertainty
KW  - Time measurement
KW  - Sensors
KW  - Robots
DO  - 10.1109/IROS.2018.8594503
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers the problem of choosing measurement locations of an aerial robot in an online manner in order to localize an animal with a radio collar. The aerial robot has a commercial, low-cost directional antenna and USB receiver to capture the signal. It uses its own movement to obtain a bearing measurement. The uncertainty in these measurements is assumed to be bounded and represented as wedges. The measurements are then merged by intersecting the wedges. The localization uncertainty is quantified by the area of the resulting intersection. The goal is to reduce the localization uncertainty to a value below a given threshold in minimum time. We present an online strategy to choose measurement locations during execution based on previous readings and analyze its performance with competitive analysis. The time required to localize a target is upper-bounded by the function of measurement noise, desired localization uncertainty and minimum step length. We also validate the strategy in extensive simulations and show its applicability through field experiments over a 5 hectare area using an autonomous aerial robot equipped with a directional antenna.
ER  - 

TY  - CONF
TI  - Planning to Monitor Wildfires with a Fleet of UAVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4729
EP  - 4734
AU  - R. Bailon-Ruiz
AU  - S. Lacroix
AU  - A. Bit-Monnot
PY  - 2018
KW  - autonomous aerial vehicles
KW  - emergency management
KW  - fires
KW  - path planning
KW  - search problems
KW  - wildfires
KW  - fire propagation process
KW  - observation trajectories
KW  - fire model
KW  - wildfire monitoring
KW  - variable neighborhood search method
KW  - fixed-wing UAV fleet
KW  - Trajectory
KW  - Monitoring
KW  - Cameras
KW  - Ignition
KW  - Planning
KW  - Fuels
KW  - Shape
DO  - 10.1109/IROS.2018.8593859
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind. The approach tailors a generic Variable Neighborhood Search method to these models and associated constraints. Simulation results show ability to plan observation trajectories for a small fleet of UAVs, and to update the plans when new information on the fire are incorporated in the fire model.
ER  - 

TY  - CONF
TI  - Flight Motion of Passing Through Small Opening by DRAGON: Transformable Multilinked Aerial Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4735
EP  - 4742
AU  - M. Zhao
AU  - F. Shi
AU  - T. Anzai
AU  - K. Chaudhary
AU  - X. Chen
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - aerospace control
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - stability
KW  - multilinked model
KW  - near-hover condition
KW  - motion sequence
KW  - improved dynamics derivation
KW  - flight control method
KW  - flight stability
KW  - small opening
KW  - flight motion
KW  - transformable multilinked aerial robot
KW  - multilinked robot
KW  - transformable aerial robot
KW  - under-actuated multirotors
KW  - aggressive maneuvering
KW  - necessary condition
KW  - crucial problems
KW  - unknown obstacle
KW  - multirotor
KW  - robot body
KW  - Unmanned aerial vehicles
KW  - Rotors
KW  - Collision avoidance
KW  - Path planning
KW  - Stability analysis
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593368
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce the achievement of the flight motion to pass through small opening by the multilinked and transformable aerial robot. Previous works about such motion are based on under-actuated multirotors, indicating that aggressive maneuvering is necessary condition. This involves two crucial problems: i) enough free space for deceleration is necessary, otherwise the robot would collide with unknown obstacle after exiting opening; ii) the multirotor can not traverse the openings that are smaller than the robot body. The proposed transformable aerial robot in our work can solve these problems, since the multilinked model can not only guarantee the near-hover condition during the whole motion sequence, but also slowly traverse relative small openings by changing its form like a snake. We first propose an improved dynamics derivation and flight control method for this multilinked aerial robot based on our previous work. Then, we present the path planning method which takes the flight stability in the near-hover condition into account. Finally we demonstrate the experimental results of the motion to pass through a horizontal and small opening which also involves the borders (the floor and the ceiling).
ER  - 

TY  - CONF
TI  - Optimal Constrained Trajectory Generation for Quadrotors Through Smoothing Splines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4743
EP  - 4750
AU  - S. Lai
AU  - M. Lan
AU  - B. M. Chen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - optimisation
KW  - path planning
KW  - splines (mathematics)
KW  - time optimal control
KW  - trajectory control
KW  - vehicles physical limits
KW  - large-scale fitting problem
KW  - human sketching
KW  - optimal constrained trajectory generation
KW  - inequality constraints
KW  - closed-form solution
KW  - safe flying zones
KW  - interval-wise constraints
KW  - axes-coupled
KW  - time optimal control techniques
KW  - polynomial splines
KW  - optimal smoothing B-spline
KW  - quadrotors
KW  - Trajectory
KW  - Splines (mathematics)
KW  - Optimization
KW  - Smoothing methods
KW  - Closed-form solutions
KW  - Space vehicles
KW  - Safety
DO  - 10.1109/IROS.2018.8594357
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a trajectory generation method for quadrotors based on the optimal smoothing B-spline. Compared to existing methods which rely on polynomial splines or time optimal control techniques, our method systematically addresses the issue of axes-coupled and interval-wise constraints. These constraints can be used to construct safe flying zones and satisfy vehicle's physical limits. The proposed approach has also been extended to generate trajectories from the nominal plan which consists of not only points but also lines and planes, opening a door for new improvements and applications. Moreover, a closed-form solution can be obtained for cases without inequality constraints. Such a solution is numerically stable for the large-scale fitting problem, which allows us to directly fit the human sketching input from the touch device and capture all subtle details. Our approach is verified by various real flight experiments..
ER  - 

TY  - CONF
TI  - FarSight: Long-Range Depth Estimation from Outdoor Images
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4751
EP  - 4757
AU  - M. A. Reza
AU  - J. Kosecka
AU  - P. David
PY  - 2018
KW  - convolutional neural nets
KW  - image reconstruction
KW  - image sensors
KW  - rendering (computer graphics)
KW  - stereo image processing
KW  - unsupervised learning
KW  - long-range depth estimation
KW  - outdoor images
KW  - long-range monocular depth estimation
KW  - outdoor urban environments
KW  - range sensors
KW  - outdoor settings
KW  - outdoor single view methods
KW  - synthetic long-range ground truth depth data
KW  - long-range depth renderings
KW  - depth prediction
KW  - depth estimation algorithms
KW  - Generative Adversarial Network
KW  - GAN
KW  - size 10.0 m
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Estimation
KW  - Image reconstruction
KW  - Urban areas
KW  - Google
KW  - Meters
DO  - 10.1109/IROS.2018.8593971
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces the problem of long-range monocular depth estimation for outdoor urban environments. Range sensors and traditional depth estimation algorithms (both stereo and single view) predict depth for distances of less than 100 meters in outdoor settings and 10 meters in indoor settings. The shortcomings of outdoor single view methods that use learning approaches are, to some extent, due to the lack of long-range ground truth training data, which in turn is due to limitations of range sensors. To circumvent this, we first propose a novel strategy for generating synthetic long-range ground truth depth data. We utilize Google Earth images to reconstruct large-scale 3D models of different cities with proper scale. The acquired repository of 3D models and associated RGB views along with their long-range depth renderings are used as training data for depth prediction. We then train two deep neural network models for long-range depth estimation: i) a Convolutional Neural Network (CNN) and ii) a Generative Adversarial Network (GAN). We found in our experiments that the GAN model predicts depth more accurately. We plan to open-source the database and the baseline models for public use.
ER  - 

TY  - CONF
TI  - LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4758
EP  - 4765
AU  - T. Shan
AU  - B. Englot
PY  - 2018
KW  - embedded systems
KW  - feature extraction
KW  - image segmentation
KW  - optical radar
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM framework
KW  - edge features
KW  - feature extraction
KW  - point cloud segmentation
KW  - lightweight and ground-optimized lidar odometry
KW  - real-time six degree-of-freedom pose estimation
KW  - low-power embedded system
KW  - ground plane
KW  - two-step Levenberg-Marquardt optimization method
KW  - optimization steps
KW  - ground vehicles
KW  - LeGO-LOAM
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Image segmentation
KW  - Pose estimation
KW  - Real-time systems
KW  - Iterative closest point algorithm
DO  - 10.1109/IROS.2018.8594299
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a lightweight and ground-optimized lidar odometry and mapping method, LeGO-LOAM, for realtime six degree-of-freedom pose estimation with ground vehicles. LeGO-LOAM is lightweight, as it can achieve realtime pose estimation on a low-power embedded system. LeGO-LOAM is ground-optimized, as it leverages the presence of a ground plane in its segmentation and optimization steps. We first apply point cloud segmentation to filter out noise, and feature extraction to obtain distinctive planar and edge features. A two-step Levenberg-Marquardt optimization method then uses the planar and edge features to solve different components of the six degree-of-freedom transformation across consecutive scans. We compare the performance of LeGO-LOAM with a state-of-the-art method, LOAM, using datasets gathered from variable-terrain environments with ground vehicles, and show that LeGO-LOAM achieves similar or better accuracy with reduced computational expense. We also integrate LeGO-LOAM into a SLAM framework to eliminate the pose estimation error caused by drift, which is tested using the KITTI dataset.
ER  - 

TY  - CONF
TI  - A Maximum Likelihood Approach to Extract Polylines from 2-D Laser Range Scans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4766
EP  - 4773
AU  - A. Schaefer
AU  - D. BÃ¼scher
AU  - L. Luft
AU  - W. Burgard
PY  - 2018
KW  - image reconstruction
KW  - image registration
KW  - laser ranging
KW  - maximum likelihood estimation
KW  - probability
KW  - simulated laser scans
KW  - maximum likelihood approach
KW  - 2-D laser range scans
KW  - man-made environments
KW  - factory floors
KW  - linear structures
KW  - probabilistic method
KW  - polylines extraction
KW  - Feature extraction
KW  - Sensors
KW  - Lasers
KW  - Probabilistic logic
KW  - Optimization
KW  - Measurement by laser beam
KW  - Laser radar
DO  - 10.1109/IROS.2018.8593844
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Man-made environments such as households, offices, or factory floors are typically composed of linear structures. Accordingly, polylines are a natural way to accurately represent their geometry. In this paper, we propose a novel probabilistic method to extract polylines from raw 2-D laser range scans. The key idea of our approach is to determine a set of polylines that maximizes the likelihood of a given scan. In extensive experiments carried out on publicly available real-world datasets and on simulated laser scans, we demonstrate that our method substantially outperforms existing state-of-the-art approaches in terms of accuracy, while showing comparable computational requirements. Our implementation is available under https://github.com/acschaefer/ple.
ER  - 

TY  - CONF
TI  - Learning a Local Feature Descriptor for 3D LiDAR Scans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4774
EP  - 4780
AU  - A. Dewan
AU  - T. Caselitz
AU  - W. Burgard
PY  - 2018
KW  - convolutional neural nets
KW  - feature extraction
KW  - image matching
KW  - image representation
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - SLAM (robots)
KW  - learned feature descriptor
KW  - 3D local descriptors
KW  - local feature descriptor
KW  - 3D LiDAR scans
KW  - robust data association
KW  - scan alignment algorithms
KW  - handcrafted feature descriptors
KW  - metric learning network
KW  - local surface patches
KW  - convolutional neural network
KW  - ground-truth correspondences
KW  - SLAM system
KW  - CNN
KW  - Siamese network
KW  - Three-dimensional displays
KW  - Measurement
KW  - Laser radar
KW  - Feature extraction
KW  - Streaming media
KW  - Task analysis
KW  - Gray-scale
DO  - 10.1109/IROS.2018.8594420
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust data association is necessary for virtually every SLAM system and finding corresponding points is typically a preprocessing step for scan alignment algorithms. Traditionally, handcrafted feature descriptors were used for these problems but recently learned descriptors have been shown to perform more robustly. In this work, we propose a local feature descriptor for 3D LiDAR scans. The descriptor is learned using a Convolutional Neural Network (CNN). Our proposed architecture consists of a Siamese network for learning a feature descriptor and a metric learning network for matching the descriptors. We also present a method for estimating local surface patches and obtaining ground-truth correspondences. In extensive experiments, we compare our learned feature descriptor with existing 3D local descriptors and report highly competitive results for multiple experiments in terms of matching accuracy and computation time.
ER  - 

TY  - CONF
TI  - Hallucinating Robots: Inferring Obstacle Distances from Partial Laser Measurements
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4781
EP  - 4787
AU  - J. Lundell
AU  - F. Verdoja
AU  - V. Kyrki
PY  - 2018
KW  - collision avoidance
KW  - distance measurement
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - optical scanners
KW  - hallucinating robots
KW  - obstacle distances
KW  - partial laser measurements
KW  - mobile robots
KW  - 2D laser scanners
KW  - glass panels
KW  - richer sensor readings
KW  - RGBD sensors
KW  - raw 2D laser data
KW  - raw 2D laser distances
KW  - partial 2D laser readings
KW  - Lasers
KW  - Two dimensional displays
KW  - Measurement by laser beam
KW  - Robot sensing systems
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594399
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many mobile robots rely on 2D laser scanners for localization, mapping, and navigation. However, those sensors are unable to correctly provide distance to obstacles such as glass panels and tables whose actual occupancy is invisible at the height the sensor is measuring. In this work, instead of estimating the distance to obstacles from richer sensor readings such as 3D lasers or RGBD sensors, we present a method to estimate the distance directly from raw 2D laser data. To learn a mapping from raw 2D laser distances to obstacle distances we frame the problem as a learning task and train a neural network formed as an autoencoder. A novel configuration of network hyperparameters is proposed for the task at hand and is quantitatively validated on a test set. Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the trained network can successfully infer obstacle distances from partial 2D laser readings.
ER  - 

TY  - CONF
TI  - Optimizing Scan Homogeneity for Building Full-3D Lidars Based on Rotating a Multi-Beam Velodyne Range-Finder
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4788
EP  - 4793
AU  - A. Mandow
AU  - J. Morales
AU  - J. A. Gomez-Ruiz
AU  - A. J. GarcÃ­a-Cerezo
PY  - 2018
KW  - image sensors
KW  - object detection
KW  - optical radar
KW  - optical scanners
KW  - scan homogeneity
KW  - 3D sensor homogeneity
KW  - spherical formulation
KW  - HDL-32 sensors
KW  - building full-3D lidars
KW  - robotics research
KW  - constant pitch angles
KW  - rolling DOF
KW  - RMBLs
KW  - complex 3D scan measurement distributions
KW  - spherical FOV
KW  - high-resolution scans
KW  - rotating multibeam lidars
KW  - degree-of-freedom
KW  - vertical resolution
KW  - high data rates
KW  - accessible 3D sensors
KW  - MBL
KW  - multibeam lidar scanners
KW  - multibeam Velodyne range-finder
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Indexes
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593916
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Multi-beam lidar (MBL) scanners are compact, light, and accessible 3D sensors with high data rates, but they offer limited vertical resolution and field of view (FOV). Some recent robotics research has profited from the addition of a degree-of-freedom (DOF) to an MBL to build rotating multibeam lidars (RMBL) that can achieve high-resolution scans with full spherical FOV. In a previous work, we offered a methodology to analyze the complex 3D scan measurement distributions produced by RMBLs with a rolling DOF and no pitching. In this paper, we investigate the effect of introducing constant pitch angles in the construction of the RMBLs with the purpose of finding a kinematic configuration that optimizes scan homogeneity with a spherical FOV. To this end, we propose a scalar index of 3D sensor homogeneity that is based on the spherical formulation of Ripley's K function. The optimization is performed for the widely used Puck (VLP-16) and HDL-32 sensors by Velodyne.
ER  - 

TY  - CONF
TI  - Laser Map Aided Visual Inertial Localization in Changing Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4794
EP  - 4801
AU  - X. Ding
AU  - Y. Wang
AU  - D. Li
AU  - L. Tang
AU  - H. Yin
AU  - R. Xiong
PY  - 2018
KW  - cameras
KW  - geometry
KW  - optical radar
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - map optimization
KW  - changing environment
KW  - bi-directional tasks
KW  - LiDAR-built map
KW  - online visual inertial odometry system
KW  - laser map aided visual inertial localization
KW  - geometry information
KW  - crossmodal data association
KW  - multisession laser
KW  - Visualization
KW  - Lasers
KW  - Bundle adjustment
KW  - Laser radar
KW  - Robots
KW  - Cameras
DO  - 10.1109/IROS.2018.8593846
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Long-term visual localization in outdoor environment is a challenging problem, especially faced with the cross-seasonal, bi-directional tasks and changing environment. In this paper we propose a novel visual inertial localization framework that localizes against the LiDAR-built map. Based on the geometry information of the laser map, a hybrid bundle adjustment framework is proposed, which estimates the poses of the cameras with respect to the prior laser map as well as optimizes the state variables of the online visual inertial odometry system simultaneously. For more accurate crossmodal data association, the laser map is optimized using multisession laser and visual data to extract the salient and stable subset for visual localization. To validate the efficiency of the proposed method, we collect data in south part of our campus in different seasons, along the same and opposite-direction route. In all sessions of localization data, our proposed method gives satisfactory results, and shows the superiority of the hybrid bundle adjustment and map optimization1.
ER  - 

TY  - CONF
TI  - Scan Context: Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4802
EP  - 4809
AU  - G. Kim
AU  - A. Kim
PY  - 2018
KW  - feature extraction
KW  - optical radar
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - simultaneous localization and mapping
KW  - scan context performance
KW  - Light Detection and Ranging scans
KW  - visual scenes
KW  - two-phase search algorithm
KW  - 3D LiDAR scans
KW  - loop-detection invariant
KW  - nonhistogram-based global descriptor
KW  - global localization
KW  - diverse sensors
KW  - dense 3D maps
KW  - structural information
KW  - diverse feature detectors
KW  - 3D point cloud map
KW  - place recognition
KW  - Three-dimensional displays
KW  - Sensors
KW  - Laser radar
KW  - Histograms
KW  - Shape
KW  - Visualization
KW  - Encoding
DO  - 10.1109/IROS.2018.8593953
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Compared to diverse feature detectors and descriptors used for visual scenes, describing a place using structural information is relatively less reported. Recent advances in simultaneous localization and mapping (SLAM) provides dense 3D maps of the environment and the localization is proposed by diverse sensors. Toward the global localization based on the structural information, we propose Scan Context, a non-histogram-based global descriptor from 3D Light Detection and Ranging (LiDAR) scans. Unlike previously reported methods, the proposed approach directly records a 3D structure of a visible space from a sensor and does not rely on a histogram or on prior training. In addition, this approach proposes the use of a similarity score to calculate the distance between two scan contexts and also a two-phase search algorithm to efficiently detect a loop. Scan context and its search algorithm make loop-detection invariant to LiDAR viewpoint changes so that loops can be detected in places such as reverse revisit and corner. Scan context performance has been evaluated via various benchmark datasets of 3D LiDAR scans, and the proposed method shows a sufficiently improved performance.
ER  - 

TY  - CONF
TI  - Decentralised Mission Monitoring with Spatiotemporal Optimal Stopping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4810
EP  - 4817
AU  - G. Best
AU  - S. Huang
AU  - R. Fitch
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - probability
KW  - decentralised mission monitoring
KW  - spatiotemporal optimal stopping
KW  - multirobot variant
KW  - mission monitoring problem
KW  - multiple tracker robots
KW  - single target robot
KW  - multirobot systems
KW  - task performance
KW  - marine robotics missions
KW  - single-robot paths
KW  - probabilistic representation
KW  - decentralised scheme
KW  - useful analytical properties
KW  - planned trajectories
KW  - probabilistic motion
KW  - observation models
KW  - mission monitoring systems
KW  - Monitoring
KW  - Trajectory
KW  - Target tracking
KW  - Robot kinematics
KW  - Probabilistic logic
KW  - Predictive models
DO  - 10.1109/IROS.2018.8593663
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider a multi-robot variant of the mission monitoring problem. This problem arises in tasks where a robot observes the progress of another robot that is stochastically following a known trajectory, among other applications. We formulate and solve a variant where multiple tracker robots must monitor a single target robot, which is important because it enables the use of multi-robot systems to improve task performance in practice, such as in marine robotics missions. Our algorithm coordinates the behaviour of the trackers by computing optimal single-robot paths given a probabilistic representation of the other robots' paths. We employ a decentralised scheme that optimises over probability distributions of plans and has useful analytical properties. The planned trajectories collectively maximise the probability of observing the target throughout the mission with respect to probabilistic motion and observation models. We report simulation results for up to 8 robots that support our analysis and indicate that our algorithm is a feasible solution for improving the performance of mission monitoring systems.
ER  - 

TY  - CONF
TI  - Uncertain Local Leader Selection in Distributed Formations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 4818
EP  - 4824
AU  - D. Rovinsky
AU  - N. Agmon
PY  - 2018
KW  - collision avoidance
KW  - control engineering computing
KW  - mobile robots
KW  - multi-robot systems
KW  - virtual local leader
KW  - accurate local leader
KW  - formation accuracy
KW  - individual robot
KW  - sensory uncertainty
KW  - distributed setting
KW  - optimal multirobot formation control
KW  - uncertain environment
KW  - desired formation
KW  - specific formation
KW  - desired destination
KW  - single robot
KW  - local leaders
KW  - specific predefined angle
KW  - hierarchical form
KW  - Leader-Follower
KW  - distributed formations
KW  - uncertain local leader selection
KW  - visible robots
KW  - Robot sensing systems
KW  - Reliability
KW  - Shape
KW  - Uncertainty
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594307
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Leader-Follower is a hierarchical form of multi-robot formation control, where each robot aims to maintain specific predefined angle and distance from one or more robots in the team (referred to as its local leaders), while a single robot is selected to lead the entire formation to a desired destination. When the robots are given a specific formation to maintain, their goal is usually to minimize the deviation from this desired formation (maximizing the accuracy) during their journey. Previous work has considered optimality in an uncertain environment only in centralized setting (or using perfect, or almost perfect communication). In this paper we examine the problem of optimal multi-robot formation control in a distributed setting, while accounting for two challenges: sensory uncertainty and absence of communication. Specifically, we present an algorithm that allows each individual robot to estimate the overall formation accuracy of the other robots in their field of view via a tree reconstruction algorithm. The algorithm is used to select the most accurate local leader, or to generate virtual local leader via a weighted average of all visible robots. We provide both theoretical analysis and an extensive empirical evaluation (in ROS/Gazebo simulated environment) showing the effectiveness of the two approaches.
ER  - 


