TY  - CONF
TI  - Human-in-the-loop Augmented Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3190
EP  - 3195
AU  - A. Sidaoui
AU  - I. H. Elhajj
AU  - D. Asmar
PY  - 2018
KW  - inertial systems
KW  - mobile robots
KW  - operating systems (computers)
KW  - optical radar
KW  - path planning
KW  - robot programming
KW  - user interfaces
KW  - 2D map building
KW  - user interface
KW  - human map augmentation
KW  - LIDAR
KW  - Gmapping ROS package
KW  - Unity software
KW  - online editing capabilities
KW  - user-friendly system
KW  - traditional offline post processing
KW  - real-time human augmented mapping system
KW  - human-in-the-loop
KW  - mapping errors
KW  - Two dimensional displays
KW  - Laser radar
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Corporate acquisitions
DO  - 10.1109/IROS.2018.8594494
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we develop a real-time human augmented mapping system. This approach replaces the traditional offline post processing of maps by a user-friendly system allowing for online editing capabilities. A wide number of applications that acquire accurate mapping of the environment could benefit from such a solution. The proposed framework consists of two main parts: 2D map building using LIDAR, encoders, and IMU; and a user interface for human map augmentation. The first part is built over Gmapping ROS package, while the second is developed in Unity software. Realworld experiments validated the ability of our system to correct for sensor noise and various mapping errors, thus increasing the accuracy of the obtained maps without additional computational costs.
ER  - 

TY  - CONF
TI  - VLASE: Vehicle Localization by Aggregating Semantic Edges
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3196
EP  - 3203
AU  - X. Yu
AU  - S. Chaturvedi
AU  - C. Feng
AU  - Y. Taguchi
AU  - T. Lee
AU  - C. Fernandes
AU  - S. Ramalingam
PY  - 2018
KW  - feature extraction
KW  - geographic information systems
KW  - image retrieval
KW  - image segmentation
KW  - road vehicles
KW  - traffic information systems
KW  - semantic edge features
KW  - edge contours
KW  - building-sky
KW  - state-of-the-art localization algorithms
KW  - individual prominent features
KW  - VLASE
KW  - vehicle localization
KW  - on-road localization
KW  - semantic classes
KW  - VLAD framework
KW  - image retrieval
KW  - SIFT-VLAD
KW  - NetVLAD
KW  - SLC Marathon dataset
KW  - Salt Lake city
KW  - lighting variations
KW  - Semantics
KW  - Image edge detection
KW  - Feature extraction
KW  - Buildings
KW  - Databases
KW  - Visualization
KW  - Urban areas
DO  - 10.1109/IROS.2018.8594358
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose VLASE, a framework to use semantic edge features from images to achieve on-road localization. Semantic edge features denote edge contours that separate pairs of distinct objects such as building-sky, road-sidewalk, and building-ground. While prior work has shown promising results by utilizing the boundary between prominent classes such as sky and building using skylines, we generalize this to consider 19 semantic classes. We extract semantic edge features using CASENet architecture and utilize VLAD framework to perform image retrieval. We achieve improvement over state-of-the-art localization algorithms such as SIFT-VLAD and its deep variant NetVLAD. Ablation study shows the importance of different semantic classes, and our unified approach achieves better performance compared to individual prominent features such as skylines. We also introduce SLC Marathon dataset, a challenging dataset covering most of Salt Lake City with sufficient lighting variations.
ER  - 

TY  - CONF
TI  - A B-Spline Mapping Framework for Long-Term Autonomous Operations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3204
EP  - 3209
AU  - R. T. Rodrigues
AU  - A. P. Aguiar
AU  - A. Pascoal
PY  - 2018
KW  - image representation
KW  - image sensors
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - splines (mathematics)
KW  - landmark-based maps
KW  - robotics community
KW  - high frequency sensor
KW  - B-spline curves
KW  - B-spline maps
KW  - mapping algorithm
KW  - 2D B-spline mapping framework
KW  - outdoor long-term autonomous operations
KW  - simultaneous localization and mapping
KW  - SLAM algorithm
KW  - software-in-the-loop simulations
KW  - Splines (mathematics)
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8594456
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.
ER  - 

TY  - CONF
TI  - Building Dense Reflectance Maps of Indoor Environments Using an RGB-D Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3210
EP  - 3217
AU  - M. Krawez
AU  - T. Caselitz
AU  - D. Büscher
AU  - M. Van Loock
AU  - W. Burgard
PY  - 2018
KW  - brightness
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - lighting conditions
KW  - light emitters
KW  - high dynamic range radiosity estimation
KW  - reflectance estimate
KW  - diffuse reflectance
KW  - specific lighting condition
KW  - colored models
KW  - extensive progress
KW  - RGB-D cameras
KW  - dense surface geometry
KW  - robotic applications
KW  - indoor environments
KW  - building dense reflectance maps
KW  - Cameras
KW  - Lighting
KW  - Image reconstruction
KW  - Robots
KW  - Geometry
KW  - Indoor environments
KW  - Surface treatment
DO  - 10.1109/IROS.2018.8594107
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The ability to build models of the environment is an essential prerequisite for many robotic applications. In recent years, mapping of dense surface geometry using RGB-D cameras has seen extensive progress. Many approaches build colored models, typically directly using the intensity values provided by the camera. Unfortunately, these intensities are inherently affected by illumination. Therefore, the resulting maps only represent the environment for one specific lighting condition. To overcome this limitation, we propose to build reflectance maps that are invariant against changes in lighting. Our approach estimates the diffuse reflectance of a surface by recovering its radiosity and the corresponding irradiance. As imperfections in this process can significantly degrade the reflectance estimate, we remove outliers in the high dynamic range radiosity estimation and propose a method to refine the reflectance estimate. Our system implements the whole pipeline for offline reconstruction of dense reflectance maps including the segmentation of light emitters in the scene. We demonstrate the applicability of our approach in real-world experiments under varying lighting conditions.
ER  - 

TY  - CONF
TI  - 3D Underground Mapping with a Mobile Robot and a GPR Antenna
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3218
EP  - 3224
AU  - G. Kouros
AU  - I. Kotavelis
AU  - E. Skartados
AU  - D. Giakoumis
AU  - D. Tzovaras
AU  - A. Simi
AU  - G. Manacorda
PY  - 2018
KW  - feature extraction
KW  - ground penetrating radar
KW  - image matching
KW  - image segmentation
KW  - mobile robots
KW  - radar imaging
KW  - underground robotic applications
KW  - image processing techniques
KW  - subsurface 3D map
KW  - Ground Penetrating Radar
KW  - construction services
KW  - automatic subsurface mapping
KW  - GPR antenna
KW  - mobile robot
KW  - underground mapping
KW  - Ground penetrating radar
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Mobile antennas
KW  - Mobile robots
KW  - Antenna measurements
DO  - 10.1109/IROS.2018.8593848
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Automatic subsurface mapping is essential in the construction services, as it is anticipated to become the main operational environment of the future robots to be realized in the respective domain. Towards this direction, the paper at hand, introduces for the first time herein, an integrated framework for subsurface mapping by exploiting a surface operating mobile robot with a Ground Penetrating Radar (GPR). The mobile robot tows the GPR antenna, which is mounted on a specifically designed trailer, and is utilized as the mean to cover the surface area, while at the same time the antenna scans the subsurface by emitting electromagnetic pulses. The gathered data are processed for the construction of a subsurface 3D map. Specifically, image processing techniques, that involve background segmentation, HOG [1] feature extraction, hypothesis verification and matching are applied on the 2D radargram (B-Scan) for the detection of the salient points that correspond to buried utilities. By employing the pulse propagation velocity into the subsurface and the soil utilities, the salient points are expressed in world coordinates and used for the composition of the 3D subsurface map. Our method has been evaluated on a real test site, accompanied by ground-truth annotation data of experts and revealed remarkable performance, exhibiting not only the feasibility of underground mapping but also the capacity to obtain exploitable results for underground robotic applications.
ER  - 

TY  - CONF
TI  - Adaptive Baseline Monocular Dense Mapping with Inter-Frame Depth Propagation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3225
EP  - 3232
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - image matching
KW  - image reconstruction
KW  - image sequences
KW  - stereo image processing
KW  - monocular dense mapping methods
KW  - frame-to-frame propagated depth filter
KW  - wide-baseline observations
KW  - sequential input images
KW  - adaptive baseline matching cost computation
KW  - sequential depth estimation
KW  - multibaseline observations
KW  - separate multiview stereo problems
KW  - image sequence
KW  - inter-frame depth propagation
KW  - adaptive baseline monocular dense mapping
KW  - Estimation
KW  - Cameras
KW  - Probabilistic logic
KW  - Adaptive systems
KW  - Image sequences
KW  - Real-time systems
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593936
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - State-of-the-art monocular dense mapping methods usually divide the image sequence into several separate multi-view stereo problems thus have limited utilization of the information in multi-baseline observations and sequential depth estimations. In this paper, two core contributions are proposed to improve the mapping performance by exploiting the information. The first is an adaptive baseline matching cost computation that uses the sequential input images to provide each pixel with wide-baseline observations. The second is a frame-to-frame propagated depth filter which integrates the sequential depth estimation of the same physical point in a robust probabilistic manner. Two contributions are integrated into a monocular dense mapping system that generates the depth maps in real-time for both pinhole and fisheye cameras. Our system is fully parallelized and can run at more than 25 fps on a Nvidia Jetson TX2. We compare our work with state-of-the-art methods on the public dataset. Onboard UAV mapping and handhold experiments are also used to demonstrate the performance of our method. For the benefit of the community, we make the implementation open source.
ER  - 

TY  - CONF
TI  - Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3233
EP  - 3240
AU  - A. Kumar
AU  - J. R. McBride
AU  - G. Pandey
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image reconstruction
KW  - image resolution
KW  - image texture
KW  - mesh generation
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - scan matching techniques
KW  - end-to-end real time framework
KW  - real time incremental foveal texture mapping
KW  - real time incremental foveal texture mapping
KW  - precise localization
KW  - detailed map
KW  - urban environment
KW  - high resolution graphics grade
KW  - texture mapping error
KW  - texture error
KW  - output map
KW  - computation time
KW  - ray-filtering
KW  - sparse input LIDAR scan
KW  - high resolution 3D
KW  - camera image information
KW  - pose-refinement procedure
KW  - color texture
KW  - coherent 3D surface
KW  - computer games
KW  - background map
KW  - planning algorithms
KW  - virtual test bed
KW  - autonomous vehicles
KW  - navigation
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Cameras
KW  - Real-time systems
KW  - Image color analysis
KW  - Global Positioning System
DO  - 10.1109/IROS.2018.8593998
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose an end-to-end real time framework to generate high resolution graphics grade textured 3D map of urban environment. The generated detailed map finds its application in the precise localization and navigation of autonomous vehicles. It can also serve as a virtual test bed for various vision and planning algorithms as well as a background map in the computer games. In this paper, we focus on two important issues: (i) incrementally generating a map with coherent 3D surface, in real time and (ii) preserving the quality of color texture. To handle the above issues, firstly, we perform a pose-refinement procedure which leverages camera image information, Delaunay triangulation and existing scan matching techniques to produce high resolution 3D map from the sparse input LIDAR scan. This 3D map is then texturized and accumulated by using a novel technique of ray-filtering which handles occlusion and inconsistencies in pose-refinement. Further, inspired by human fovea, we introduce foveal-processing which significantly reduces the computation time and also assists ray-filtering to maintain consistency in color texture and coherency in 3D surface of the output map. Moreover, we also introduce texture error (TE) and mean texture mapping error (MTME), which provides quantitative measure of texturing and overall quality of the textured maps.
ER  - 

TY  - CONF
TI  - Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3241
EP  - 3248
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - probability
KW  - directional grid maps
KW  - occupancy map
KW  - mobile robot
KW  - robotic arm
KW  - static environments
KW  - dynamic objects
KW  - safer navigation
KW  - human-robot interaction
KW  - directional statistics
KW  - robotic mapping
KW  - model circular data
KW  - angular motion
KW  - probability measure-field
KW  - angular variations
KW  - indoor environments
KW  - outdoor environments
KW  - dynamic environments
KW  - grid maps
KW  - multimodal angular uncertainty
KW  - Vehicle dynamics
KW  - Robot sensing systems
KW  - Data models
KW  - Uncertainty
KW  - Navigation
DO  - 10.1109/IROS.2018.8594041
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments.
ER  - 

TY  - CONF
TI  - The Effect of Swing Leg Retraction on Biped Walking Stability is Influenced by the Walking Speed and Step-Length
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3257
EP  - 3262
AU  - R. Bao
AU  - T. Geng
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - mechanical stability
KW  - mechanical variables control
KW  - walking speed
KW  - swing leg retraction
KW  - human-preferred walking patterns
KW  - human walking speeds/step-lengths
KW  - simple biped model
KW  - SLR effects
KW  - human walking patterns
KW  - biped walking stability
KW  - Legged locomotion
KW  - Mathematical model
KW  - Analytical models
KW  - Stability criteria
KW  - Foot
KW  - Biped robots
KW  - Swing leg retraction
KW  - Human walking
DO  - 10.1109/IROS.2018.8593932
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Swing Leg Retraction (SLR) is observed in human walking and running. Previous studies have concluded that SLR improves the stability and robustness of biped walking. But this conclusion was based on analysis of robot models that can only walk at a very small range of step-lengths and slow or fixed speeds. By contrast, humans can walk with a large range of speeds and step-lengths. Moreover, human walking patterns have a special feature that has not been considered in the previous studies on SLR effects: At a given walking speed, v, humans prefer a step-length, s, which satisfies the power law, s-vβ. Therefore, previous studies on SLR can't tell us whether their conclusion will still hold in the full range of human walking patterns (i.e., various walking speeds and step-lengths). This is the question we want to answer in this paper. In this study, using a simple biped model, we studied how the SLR affects the walking stability in the full range of human walking speeds/step-lengths. Preliminary analysis of both models suggests the same conclusion: (1) SLR improves the stability more evidently in human-preferred walking patterns than in other walking patterns. (2) In walking patterns that are very unlike human-preferred ones, the SLR improves the stability very little, or even deteriorates it drastically. Therefore, the new finding of our study is that how the SLR affects the biped walking stability depends on the walking speed and step-length. SLR does not always improve the stability of biped walking.
ER  - 

TY  - CONF
TI  - An Analytical Study on Trotting at Constant Velocity and Height
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3279
EP  - 3284
AU  - K. Machairas
AU  - E. Papadopoulos
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - body height
KW  - quadrupedal trotting gaits
KW  - single-legged model
KW  - point mass
KW  - actuated rotational joints
KW  - robot mass
KW  - actuator properties
KW  - robot body feasible trajectories
KW  - forward velocity
KW  - leg properties
KW  - Legged locomotion
KW  - Actuators
KW  - Trajectory
KW  - Knee
KW  - Torque
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593686
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quadrupedal trotting gaits of constant forward velocity and body height are studied. A method is developed, which is structured upon analytical expressions derived from the dynamics of a reduced single-legged model comprised of a point mass, and two actuated rotational joints. The inputs of the method include the robot mass, the leg and actuator properties, and the desired forward velocity, yielding all robot body feasible trajectories and their energy footprints. Thus, the method predicts the maximum forward velocity of a trotting quadruped; it also suggests energetically optimal combinations of body height and step length for a given forward velocity.
ER  - 

TY  - CONF
TI  - Development of a Musculoskeletal Humanoid Robot as a Platform for Biomechanical Research on the Underwater Dolphin Kick
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3285
EP  - 3291
AU  - Y. Ishii
AU  - S. Nishikawa
AU  - R. Niiyama
AU  - Y. Kuniyoshi
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - humanoid robots
KW  - kinematics
KW  - mobile robots
KW  - motion control
KW  - muscle
KW  - swimming style
KW  - musculoskeletal humanoid robot
KW  - Triton
KW  - flexible spine
KW  - erector spinae muscles
KW  - stiffness adjustment system
KW  - lumbar joints
KW  - musculoskeletal body
KW  - multijoint coordination
KW  - pneumatic muscles
KW  - lightweight properties
KW  - inherently waterproof properties
KW  - human swimming
KW  - musculoskeletal swimming robot
KW  - joint angle
KW  - thrust force
KW  - biomechanical research
KW  - underwater dolphin kick
KW  - Muscles
KW  - Dolphins
KW  - Force
KW  - Legged locomotion
KW  - Sports
DO  - 10.1109/IROS.2018.8593912
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dolphin kick is a swimming style characterized by undulation of the body. As a platform for swimming research, we have developed a musculoskeletal humanoid robot called Triton. Triton has a flexible spine with erector spinae muscles and a stiffness adjustment system for lumbar joints. The musculoskeletal body includes biarticular and polyarticular muscles, providing multi-joint coordination. The robot is actuated by pneumatic muscles, yielding lightweight and inherently waterproof properties. The compliance of the joints allows interactions between body and fluid similar to those of human swimming. This study presents the design concept of Triton and experimental results from a water tank test. We compare the results with simulation and human movements reported in literature. The results show that the musculoskeletal swimming robot has similar cycle trends in joint angle and thrust force.
ER  - 

TY  - CONF
TI  - Design and Experiments of a Novel Hydraulic Wheel-Legged Robot (WLR)
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3292
EP  - 3297
AU  - X. Li
AU  - H. Zhou
AU  - H. Feng
AU  - S. Zhang
AU  - Y. Fu
PY  - 2018
KW  - humanoid robots
KW  - hydraulic control equipment
KW  - hydraulic systems
KW  - legged locomotion
KW  - magnetorheology
KW  - robust control
KW  - vibration control
KW  - wheels
KW  - magnetorheological fluid-based damper
KW  - hydraulic wheel-legged robot
KW  - terrain environments
KW  - direct-drive wheels
KW  - hydraulic system
KW  - environmental adaptability
KW  - mobile abilities
KW  - innovative design
KW  - robustness
KW  - humanoid structural design
KW  - multimodal locomotion
KW  - wheel-legged hybrid robot
KW  - WLR
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8594484
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Wheel-legged hybrid robot with multi-modal locomotion can efficiently adapt to different terrain environments, as well as realize rapid maneuver on flat ground. We have developed a novel hydraulic wheel-legged robot (WLR) combined with a humanoid structural design. This robot can assist to emergency scenarios where the high mobility, adaptability and robustness are required. The paper introduces the details of the WLR, highlighting the innovative design and optimization of physical construction which is considered to maximize the mobile abilities, enhance the environmental adaptability and improve the reliability of hydraulic system. Firstly, maximizing the mobile abilities includes optimizing the configuration of each actuator and integrating them with the structure, so as to achieve a large range of movement and also reduce the mass and inertia of the legs. Secondly, the environmental adaptability can be ensured with a magnetorheological (MR) fluid-based damper and direct-drive wheels. Thirdly, improving the reliability of hydraulic system involves using the selective laser melting (SLM) technology to integrate hydraulic system and reducing the number of exposed tubes. The maneuverability of the WLR is demonstrated with a series of experiments. At present, the WLR can perform the following operations, including moving on the flat ground, squatting, and picking up a heavy load.
ER  - 

TY  - CONF
TI  - Sensor-Based Reactive Execution of Symbolic Rearrangement Plans by a Legged Mobile Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3298
EP  - 3305
AU  - V. Vasilopoulos
AU  - T. T. Topping
AU  - W. Vega-Brown
AU  - N. Roy
AU  - D. E. Koditschek
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - legged locomotion
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - torque control
KW  - motion planner
KW  - reactive layer
KW  - reference output
KW  - deliberative layer
KW  - unanticipated obstacles
KW  - gait layer
KW  - abstract unicycle commands
KW  - reactive module
KW  - appropriately coordinated joint level torque feedback loops
KW  - empirical demonstration
KW  - sensor-based reactive execution
KW  - symbolic rearrangement plans
KW  - legged mobile manipulator
KW  - physical rearrangement
KW  - wheeled stools
KW  - moderately cluttered indoor environment
KW  - quadrupedal robot
KW  - layer hierarchical architecture
KW  - offline symbolic task
KW  - Task analysis
KW  - Grippers
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Mobile robots
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594342
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We demonstrate the physical rearrangement of wheeled stools in a moderately cluttered indoor environment by a quadrupedal robot that autonomously achieves a user's desired configuration. The robot's behaviors are planned and executed by a three layer hierarchical architecture consisting of: an offline symbolic task and motion planner; a reactive layer that tracks the reference output of the deliberative layer and avoids unanticipated obstacles sensed online; and a gait layer that realizes the abstract unicycle commands from the reactive module through appropriately coordinated joint level torque feedback loops. This work also extends prior formal results about the reactive layer to a broad class of nonconvex obstacles. Our design is verified both by formal proofs as well as empirical demonstration of various assembly tasks.
ER  - 

TY  - CONF
TI  - An Assist-as-Needed Velocity Field Control Scheme for Rehabilitation Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3322
EP  - 3327
AU  - H. J. Asl
AU  - T. Narikiyo
AU  - M. Kawanishi
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - medical robotics
KW  - neural nets
KW  - patient rehabilitation
KW  - stability
KW  - velocity control
KW  - rehabilitation robots
KW  - neural network term
KW  - dead-zone function
KW  - feedback control term
KW  - bounded control command
KW  - AAN scheme
KW  - controller design
KW  - assist-as-needed velocity field control scheme
KW  - proportional-like feedback term
KW  - forgetting factor
KW  - lower-limb exoskeleton
KW  - NN component
KW  - system stability
KW  - Artificial neural networks
KW  - Timing
KW  - Aerospace electronics
KW  - Rehabilitation robotics
KW  - Stability analysis
KW  - Exoskeletons
KW  - Rehabilitation robots
KW  - assist-as-need control
KW  - neural network
KW  - exoskeleton
DO  - 10.1109/IROS.2018.8594244
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the problem of assist-as-needed (AAN) control for rehabilitation robots. To achieve a motion which is not explicitly a function of time, the velocity field control is considered in this paper. The proposed new controller consists of a proportional-like feedback term and a neural network (NN) term, where the later is exploited to compensate for the dynamic uncertainties of the system. The AAN property is facilitated by means of a dead-zone function in the feedback control term and a forgetting factor in the adaptation law of NN component. The designed controller guarantees the stability of the system with a bounded control command. The performance of the proposed AAN scheme is validated through the simulation and experiment conducted on a lower-limb exoskeleton.
ER  - 

TY  - CONF
TI  - The KIT Prosthetic Hand: Design and Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3328
EP  - 3334
AU  - P. Weiner
AU  - J. Starke
AU  - F. Hundhausen
AU  - J. Beil
AU  - T. Asfour
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - cameras
KW  - colour displays
KW  - dexterous manipulators
KW  - embedded systems
KW  - mechatronics
KW  - medical robotics
KW  - prosthetics
KW  - three-dimensional printing
KW  - mechatronics
KW  - kinematic parameters
KW  - RGB camera
KW  - colour display
KW  - innovative control
KW  - sensor integration
KW  - hand closing time
KW  - percentile male hand
KW  - underactuated TUAT/Karlsruhe mechanism
KW  - hand mechanics
KW  - embedded control system
KW  - underactuated mechanism
KW  - five-finger 3D printed hand prosthesis
KW  - KIT prosthetic hand
KW  - Embedded systems
KW  - Grasping
KW  - Tendons
KW  - Robot sensing systems
KW  - Thumb
KW  - Prosthetic hand
DO  - 10.1109/IROS.2018.8593851
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The development and control of prosthetic hands is an active research area and recently progress in mechatronics, sensor integration and innovative control has been made. However, integration of different components into a prosthetic hand remains challenging due to space constraints, the requirements regarding holistic integration and the need for a user interface. In this paper, we present the KIT prosthetic hand, a novel five-finger 3D printed hand prosthesis, with its underactuated mechanism, sensors and embedded control system. The hand mechanics is based on the underactuated TUAT/Karlsruhe mechanism with two motors actuating 10 degrees of freedom. The mechanism has been realized in 3D printing technologies to facilitate a personalization of the prosthetic hand in terms of size and kinematic parameters. The prosthesis has been designed as a 50th percentile male hand. It integrates an advanced embedded system as well as an RGB camera in the base of the palm and a colour display in the back of the hand. Experiments indicate a finger tip force of 7.48 N to 11.82 N, a hook grasp force of 120 N and a hand closing time of ~ 1.3 s.
ER  - 

TY  - CONF
TI  - Robot Controllers Compatible with Human Beam Balancing Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3335
EP  - 3341
AU  - J. Lee
AU  - M. E. Huber
AU  - D. Sternad
AU  - N. Hogan
PY  - 2018
KW  - angular momentum
KW  - biocontrol
KW  - biomechanics
KW  - legged locomotion
KW  - mechanoception
KW  - motion control
KW  - pendulums
KW  - stability
KW  - human beam balancing behavior
KW  - challenging motor skill
KW  - upright balance
KW  - stability
KW  - humans
KW  - narrow beam
KW  - lower-body angular momentum
KW  - interlimb coordination
KW  - balance controller
KW  - robotics literature
KW  - robot controllers
KW  - balancing controllers
KW  - Robot kinematics
KW  - Foot
KW  - Task analysis
KW  - Legged locomotion
KW  - Correlation
KW  - Exoskeletons
DO  - 10.1109/IROS.2018.8593549
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Standing on a beam is a challenging motor skill that requires the regulation of upright balance and stability. In this paper, we analyzed the behavior of humans balancing on a narrow beam without footwear. The results revealed high anti-correlation between lumped upper- and lower-body angular momentum. Despite differences in gross measures of balance, interlimb coordination was consistent between the novice and expert subjects, suggesting that both performances could be described with the same balance controller. By simulating a double inverted pendulum model utilizing different balancing controllers described in the robotics literature, we identified that the whole behavior observed from humans standing on a beam was best replicated with controllers that predominantly utilized hip actuation.
ER  - 

TY  - CONF
TI  - Shock Absorbing Exoskeleton for Vertical Mobility System: Concept and Feasibility Study
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3342
EP  - 3349
AU  - J. Ueda
AU  - M. Turkseven
AU  - E. Kim
AU  - Q. Lowery
AU  - C. Bivens
AU  - M. Mayo
PY  - 2018
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - shock absorbers
KW  - viscoelasticity
KW  - wearable robots
KW  - lower-extremity wearable link mechanism
KW  - exoskeleton robot
KW  - shock absorbing exoskeleton
KW  - human skeletal system
KW  - human-exoskeleton coupled system
KW  - vertical mobility system
KW  - dynamic models
KW  - kinematic models
KW  - multielement viscoelastic model
KW  - Exoskeletons
KW  - Electric shock
KW  - Muscles
KW  - Joints
KW  - Bones
KW  - Force
KW  - Injuries
DO  - 10.1109/IROS.2018.8593820
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The goal of this research is to develop a lower-extremity wearable link mechanism (i.e., exoskeleton robot) that is capable of reducing load against targeted body parts such as bones, joints and muscles, for shock absorption that help to support exploration of extreme environments. One of the applications of such exoskeleton is to protect a pilot of a personal vertical mobility system, or JetPack, when landing. The shock absorbing exoskeleton is to introduce series and parallel viscoelasticity to the human skeletal system. The paper presents a pilot study to validate this body-protective exoskeleton concept by analyzing kinematic and dynamic models of a human-exoskeleton coupled system based on a multi-element viscoelastic model in rheology. A proof-of-concept prototype is developed and experimental data is presented.
ER  - 

TY  - CONF
TI  - Prediction of Manipulation Action Classes Using Semantic Spatial Reasoning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3350
EP  - 3357
AU  - F. Ziaeetabar
AU  - T. Kulvicius
AU  - M. Tamosiunaite
AU  - F. Wörgötter
PY  - 2018
KW  - hidden Markov models
KW  - human-robot interaction
KW  - image sequences
KW  - manipulators
KW  - spatial reasoning
KW  - video signal processing
KW  - trajectory-based HMM method
KW  - simple robot demonstration
KW  - dynamic spatial relations
KW  - static relations
KW  - temporal sequence
KW  - Enriched Semantic Event Chain framework
KW  - video sequences
KW  - predictive action recognition
KW  - human-robot interaction
KW  - Semantic spatial reasoning
KW  - manipulation action classes
KW  - Robots
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Semantics
KW  - Human-robot interaction
KW  - Prediction algorithms
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8593717
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-robot interaction strongly benefits from fast, predictive action recognition. For us this is relatively easy but difficult for a robot. To address this problem, here we present a novel prediction algorithm for manipulation action classes in video sequences. Manipulations are first represented using the Enriched Semantic Event Chain (ESEC) framework. This creates a temporal sequence of static and dynamic spatial relations between the objects that take part in the manipulation by which an action can be quickly recognized. We measured performance on 32 ideal as well as real manipulations and compared our method also against a state of the art trajectory-based HMM method for action recognition. We observe that manipulations can be correctly predicted after only (on average) 45% of action's total time and that we are almost twice as fast as the HMM-based method. Finally, we demonstrate the advantage of this framework in a simple robot demonstration comparing two different approaches.
ER  - 

TY  - CONF
TI  - Human Motion Prediction Under Social Grouping Constraints
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3358
EP  - 3364
AU  - A. Rudenko
AU  - L. Palmieri
AU  - A. J. Lilienthal
AU  - K. O. Arras
PY  - 2018
KW  - Markov processes
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - planning (artificial intelligence)
KW  - probability
KW  - random processes
KW  - human motion prediction
KW  - social grouping constraints
KW  - long-term prediction
KW  - social relations
KW  - social norms
KW  - surrounding agents
KW  - MDP planning problem
KW  - social forces
KW  - social grouping information
KW  - prediction process
KW  - soft formation constraints
KW  - mobile robots
KW  - Force
KW  - Task analysis
KW  - Trajectory
KW  - Predictive models
KW  - Computational modeling
KW  - Tracking
KW  - Planning
DO  - 10.1109/IROS.2018.8594258
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate long-term prediction of human motion in populated spaces is an important but difficult task for mobile robots and intelligent vehicles. What makes this task challenging is that human motion is influenced by a large variety of factors including the person's intention, the presence, attributes, actions, social relations and social norms of other surrounding agents, and the geometry and semantics of the environment. In this paper, we consider the problem of computing human motion predictions that account for such factors. We formulate the task as an MDP planning problem with stochastic policies and propose a weighted random walk algorithm in which each agent is locally influenced by social forces from other nearby agents. The novelty of this paper is that we incorporate social grouping information into the prediction process reflecting the soft formation constraints that groups typically impose to their members' motion. We show that our method makes more accurate predictions than three state-of-the-art methods in terms of probabilistic and geometrical performance metrics.
ER  - 

TY  - CONF
TI  - Risk-Based Human-Aware Multi-Robot Coordination in Dynamic Environments Shared with Humans
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3365
EP  - 3372
AU  - Z. Talebpour
AU  - A. Martinoli
PY  - 2018
KW  - human-robot interaction
KW  - Kalman filters
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - risk analysis
KW  - trajectory control
KW  - risk-based human-aware multirobot coordination
KW  - dynamic environments
KW  - human-populated environments
KW  - Kalman filter
KW  - position estimation
KW  - MRTA problem
KW  - human trajectory prediction
KW  - multirobot task allocation problem
KW  - human-aware navigation
KW  - risk-based bids
KW  - risk-based human-aware planning
KW  - human-agnostic planning
KW  - prediction error
KW  - Robot kinematics
KW  - Task analysis
KW  - Navigation
KW  - Planning
KW  - Uncertainty
KW  - Estimation
DO  - 10.1109/IROS.2018.8593586
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a risk-based coordination method for the Multi-Robot Task Allocation (MRTA) problem in human-populated environments. We introduce risk-based bids that incorporate human trajectory prediction uncertainties and furthermore, social costs in their formulation. We demonstrate the effectiveness of including a predictive component in the risk formulation despite the lack of accurate position estimation for humans through an extensive suite of experiments. This is done by means of testing different levels of prediction error for known human trajectories and in a separate approach, using a Kalman filter for human trajectory estimation. Furthermore, we propose different risk formulations and evaluate their performance in a high-fidelity simulator. Additionally, a comparative study targeting human-agnostic planning at both navigation and planning levels, human-aware navigation and planning based on deterministic costs, and risk-based human-aware planning with no individual human-aware navigation has been conducted. Results confirm that risk-based bids lead to more socially acceptable team plans that reduce the need for the lower level individual human-aware navigation to be activated. Risk-based plans accounting for social costs prevent difficult social situations that can lead to less effective human-aware navigation, such as traversing narrow passages occupied by humans.
ER  - 

TY  - CONF
TI  - Modeling Social Interaction Based on Joint Motion Significance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3373
EP  - 3380
AU  - N. J. Cho
AU  - S. H. Lee
AU  - T. Kwon
AU  - I. H. Suh
AU  - H. Kim
PY  - 2018
KW  - avatars
KW  - entropy
KW  - feature extraction
KW  - Gaussian processes
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - principal component analysis
KW  - regression analysis
KW  - modeling social interaction
KW  - joint motion significance
KW  - human performers
KW  - human demonstrations
KW  - relative joints
KW  - human joints
KW  - Gaussian mixture model
KW  - Entropy
KW  - Hidden Markov models
KW  - Motion segmentation
KW  - Motion measurement
KW  - Trajectory
KW  - Shoulder
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8594436
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a method to model social interaction between a human and a virtual avatar. To this end, two human performers fist perform social interactions according to the Learning from Demonstration paradigm. Then, the relative relevance of all joints of both performers should be reasonably modeled based on human demonstrations. However, among all possible combinations of relative joints, it is necessary to select only some of the combinations that play key roles in social interaction. We select such significant features based on the joint motion significance, which is a metric to measure the significance degree by calculating both temporal entropy and spatial entropy of all human joints from a Gaussian mixture model. To evaluate our proposed method, we performed experiments on five social interactions: hand shaking, hand slapping, shoulder holding, object passing, and target kicking. In addition, we compared our method to existing modeling methods using different metrics, such as principal component analysis and information gain.
ER  - 

TY  - CONF
TI  - Effects of Integrated Intent Recognition and Communication on Human-Robot Collaboration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3381
EP  - 3386
AU  - M. Lee Chang
AU  - R. A. Gutierrez
AU  - P. Khante
AU  - E. Schaertl Short
AU  - A. Lockerd Thomaz
PY  - 2018
KW  - human-robot interaction
KW  - image motion analysis
KW  - mobile robots
KW  - human-robot interaction
KW  - human partners hand motion intent
KW  - communication system
KW  - bi-directional intent system
KW  - predictable motion
KW  - legible motion
KW  - motion planner system
KW  - intent recognition system
KW  - collaborative physical task
KW  - intentional motion
KW  - human-robot collaboration
KW  - integrated intent recognition
KW  - Collaboration
KW  - Task analysis
KW  - Trajectory
KW  - Motion segmentation
KW  - Containers
KW  - Manipulators
DO  - 10.1109/IROS.2018.8593359
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human-robot interaction research to date has investigated intent recognition and communication separately. In this paper, we explore the effects of integrating both the robot's ability to generate intentional motion and predict the human's motion in a collaborative physical task. We implemented an intent recognition system to recognize the human partner's hand motion intent and a motion planner system to enable the robot to communicate its intent by using legible and predictable motion. We tested this bi-directional intent system in a 2-way within-subjects user study. Results suggest that an integrated intent recognition and communication system may facilitate more collaborative behavior among team members.
ER  - 

TY  - CONF
TI  - After You: Doorway Negotiation for Human-Robot and Robot-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3387
EP  - 3394
AU  - J. Thomas
AU  - R. Vaughan
PY  - 2018
KW  - human-robot interaction
KW  - path planning
KW  - doorway negotiation
KW  - robot-robot interaction
KW  - autonomous robot behavior
KW  - aggressive interaction
KW  - navigation deadlocks
KW  - assertive robot
KW  - common navigation sensors
KW  - naive human participants
KW  - human users
KW  - robot-robot experiments
KW  - human-robot interaction study
KW  - Navigation
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - System recovery
KW  - Autonomous robots
KW  - Safety
DO  - 10.1109/IROS.2018.8594034
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose and test an autonomous robot behavior for socially-compliant navigation of doorways with both human and robot interlocutors. Building on previous work for “aggressive” interaction between robots to resolve navigation deadlocks in corridors, we demonstrate an “assertive” robot that negotiates right-of-way when faced with a human or other robot. The negotiation is implemented using only motion and common navigation sensors, without explicit message-passing. Our goal is for the correct agent to take priority, as decided both by time-efficiency and as judged subjectively by naive human participants. Our contribution is a practical method for doorway negotiation, and a study of human users' responses to a robot that appears to participate in existing social customs surrounding doors. Our method is evaluated with robot-robot experiments and a human-robot interaction study with nonexpert users.
ER  - 

TY  - CONF
TI  - The Power of Color: A Study on the Effective Use of Colored Light in Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3395
EP  - 3402
AU  - A. Pörtner
AU  - L. Schröder
AU  - R. Rasch
AU  - D. Sprute
AU  - M. Hoffmann
AU  - M. König
PY  - 2018
KW  - human computer interaction
KW  - human-robot interaction
KW  - mobile robots
KW  - service robots
KW  - mobile robot
KW  - color preference
KW  - appropriate colors
KW  - cheap feedback mechanism
KW  - complex interaction techniques
KW  - human-robot interaction
KW  - colored light
KW  - Color
KW  - Videos
KW  - Animation
KW  - Mobile robots
KW  - Task analysis
KW  - Human-robot interaction
DO  - 10.1109/IROS.2018.8594231
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In times of more and more complex interaction techniques, we point out the powerfulness of colored light as a simple and cheap feedback mechanism. Since it is visible over a distance and does not interfere with other modalities, it is especially interesting for mobile robots. In an online survey, we asked 56 participants to choose the most appropriate colors for scenarios that were presented in the form of videos. In these scenarios a mobile robot accomplished tasks, in some with success, in others it failed because the task is not feasible, in others it stopped because it waited for help. We analyze in what way the color preferences differ between these three categories. The results show a connection between colors and meanings and that it depends on the participants' technical affinity, experience with robots and gender how clear the color preference is for a certain category. Finally, we found out that the participants' favorite color is not related to color preferences.
ER  - 

TY  - CONF
TI  - Neuroscientifically-Grounded Research for Improved Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3403
EP  - 3408
AU  - K. Kompatsiari
AU  - J. Pérez-Osorio
AU  - D. De Tommaso
AU  - G. Metta
AU  - A. Wykowska
PY  - 2018
KW  - cognition
KW  - electroencephalography
KW  - humanoid robots
KW  - human-robot interaction
KW  - man-machine systems
KW  - neurophysiology
KW  - psychology
KW  - objective neuroscientific methods
KW  - experimental psychology research
KW  - well-controlled experimental designs
KW  - improved human-robot interaction
KW  - experimentation tapping
KW  - robot design
KW  - human social cognition
KW  - humanoid robot
KW  - robotics community
KW  - enhanced event-related potentials
KW  - faster response times
KW  - gaze-cueing research
KW  - documented results
KW  - iCub robot
KW  - HRI protocol
KW  - gaze cueing
KW  - joint attention
KW  - attentional cueing
KW  - human-robot interaction research
KW  - Cognition
KW  - Psychology
KW  - Humanoid robots
KW  - Protocols
KW  - Electroencephalography
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594441
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The present study highlights the benefits of using well-controlled experimental designs, grounded in experimental psychology research and objective neuroscientific methods, for generating progress in human-robot interaction (HRI) research. More specifically, we aimed at implementing a well-studied paradigm of attentional cueing through gaze (the so-called “joint attention” or “gaze cueing”) in an HRI protocol involving the iCub robot. Similarly to documented results in gaze-cueing research, we found faster response times and enhanced event-related potentials of the EEG signal for discrimination of cued, relative to uncued, targets. These results are informative for the robotics community by showing that a humanoid robot with mechanistic eyes and human-like characteristics of the face is in fact capable of engaging a human in joint attention to a similar extent as another human would do. More generally, we propose that the methodology of combining neuroscience methods with an HRI protocol, contributes to understanding mechanisms of human social cognition in interactions with robots and to improving robot design, thanks to systematic and well-controlled experimentation tapping onto specific cognitive mechanisms of the human, such as joint attention.
ER  - 

TY  - CONF
TI  - Robust LIDAR Localization for Autonomous Driving in Rain
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3409
EP  - 3415
AU  - C. Zhang
AU  - M. H. Ang
AU  - D. Rus
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - optical radar
KW  - particle filtering (numerical methods)
KW  - stereo image processing
KW  - traffic engineering computing
KW  - 3D LIDAR scans
KW  - histogram filter
KW  - particle filter
KW  - posterior distributions
KW  - vehicle poses
KW  - complex urban environments
KW  - fair weather
KW  - rainy weather
KW  - robust LIDAR localization
KW  - autonomous driving
KW  - map-based localization method
KW  - rainy conditions
KW  - ground reflectivity features
KW  - vertical features extraction
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Histograms
KW  - Rain
KW  - Measurement by laser beam
KW  - Two dimensional displays
DO  - 10.1109/IROS.2018.8593703
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a map-based localization method aiming to increase robustness in rainy conditions. This method utilizes two types of features: ground reflectivity features and vertical features extracted from 3D LIDAR scans and builds vehicle pose belief with two filters: a histogram filter and a particle filter. The posterior distributions from the two filters are integrated to estimate vehicle poses. This method exploits advantages of both features and filters, compensating respective weakness to deal with complex urban environments. Testing was performed in the fair and rainy weather. Road test results prove robustness and reliability of the proposed method.
ER  - 

TY  - CONF
TI  - Move Base Flex A Highly Flexible Navigation Framework for Mobile Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3416
EP  - 3421
AU  - S. Pütz
AU  - J. Santos Simón
AU  - J. Hertzberg
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - path planning
KW  - MBF
KW  - path planning
KW  - motion control
KW  - robot tasks
KW  - complex navigation tasks
KW  - Move Base Flex
KW  - highly flexible navigation framework
KW  - modular navigation
KW  - map-independent navigation
KW  - open-source navigation
KW  - Navigation
KW  - Robots
KW  - Computer architecture
KW  - Task analysis
KW  - Flexible printed circuits
KW  - Servers
KW  - Planning
DO  - 10.1109/IROS.2018.8593829
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present Move Base Flex (MBF), a highly flexible, modular, map-independent, open-source navigation framework for use in ROS. MBF provides modular actions for executing plugins for path planning, motion control, and recovery. These actions define interfaces for external executives to allow highly flexible navigation strategies, which can be intertwined with other robot tasks. MBF has been successfully deployed in a professional setting at customer facilities to control robots in highly dynamic environments. We compare MBF with the well-known move_base and present the architecture as well as different deployment approaches, including how MBF can be used with different executives to perform complex navigation tasks interleaved with other robot operations.
ER  - 

TY  - CONF
TI  - Just-in-Time Emergency Trajectories: A Formulation Towards Safety in Autonomous Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3422
EP  - 3429
AU  - G. Todoran
AU  - M. Bader
PY  - 2018
KW  - collision avoidance
KW  - emergency management
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - trajectory control
KW  - safe navigation
KW  - safe motion controls
KW  - emergency trajectory candidates
KW  - just-in-time emergency trajectories
KW  - autonomous navigation
KW  - vehicle operation
KW  - safe system state
KW  - MHTP
KW  - moving horizon trajectory planner
KW  - safety requirements
KW  - vehicle's local control system
KW  - differential-drive mobile agent
KW  - nonstatic environment
KW  - robot
KW  - Trajectory
KW  - Safety
KW  - Navigation
KW  - Robots
KW  - Vehicle dynamics
KW  - Planning
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593721
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Emergency trajectories enable one to move faster through an environment while still moving safely. Having an emergency trajectory within an observed vacant space makes it possible to safely navigate through unknown territory or through a door without slowing down. Emergency trajectories allow for safe navigation of a vehicle into a safe system state, e.g. a stop, in the event of recognition of an obstacle. This work formally proves the benefit of using emergency trajectories to generate safe and faster motion controls as compared to vehicle operation without such trajectories. Furthermore, this work also presents a working integration of this formalism into a vehicle's low level control system in a Moving Horizon Trajectory Planner (MHTP) with an update rate of 10Hz. Using an MHTP along with a dynamic model of the environment and the proposed constraints, the system is able to derive emergency trajectory candidates which fulfill our safety requirements. This distinguishes the approach from that of others, which replans discrete paths that are then followed by the vehicle's local control system. This approach was implemented on a differential-drive mobile agent and tested using non-static environment assumptions. Simulated and real-robot experimental results illustrate the quality of our approach.
ER  - 

TY  - CONF
TI  - PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3430
EP  - 3437
AU  - P. Egger
AU  - P. V. K. Borges
AU  - G. Catt
AU  - A. Pfrunder
AU  - R. Siegwart
AU  - R. Dubé
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - local views
KW  - sliding window fashion
KW  - matching current
KW  - old features
KW  - map representation
KW  - local maps
KW  - off-road environments
KW  - single localization failure
KW  - distinctive features
KW  - coined PoseMap
KW  - dynamic environments
KW  - robotic systems
KW  - long-term localization
KW  - multienvironment 3D LiDAR localization
KW  - frequency 8.0 Hz
KW  - time 18.0 month
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Optimization
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593854
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.
ER  - 

TY  - CONF
TI  - Personal Mobility Vehicle Autonomous Navigation Through Pedestrian Flow: A Data Driven Approach for Parameter Extraction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3438
EP  - 3444
AU  - Y. Morales
AU  - N. Akai
AU  - H. Murase
PY  - 2018
KW  - collision avoidance
KW  - human computer interaction
KW  - mobile robots
KW  - navigation
KW  - pedestrians
KW  - road vehicles
KW  - vehicles
KW  - personal mobility vehicle autonomous navigation
KW  - pedestrian flow
KW  - data driven approach
KW  - parameter extraction
KW  - safe navigation
KW  - moving obstacles
KW  - public pedestrian paths
KW  - robotic PMV
KW  - human-driven smooth navigation
KW  - PMV-Human interaction
KW  - Navigation
KW  - Legged locomotion
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Wheelchairs
KW  - Bicycles
DO  - 10.1109/IROS.2018.8593902
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a data driven approach for safe and smooth autonomous navigation of a personal mobility vehicle (PMV) when facing moving obstacles such as people and bicycles in public pedestrian paths. In a period of three months, data from five different persons driving the robotic PMV in an outdoor environment while facing pedestrians were collected. 2465 clean tracks around the vehicle together with PMVs trajectories were collected. We performed an analysis of the parameters involved for human-driven smooth navigation. Relevant parameters regarding PMV-Human interaction included distance to moving objects, passing side and velocities. Moreover, data suggests the existence of a social navigational distance for the PWv. For autonomous navigation we implemented a Frenet planner to achieve safe and smooth navigation for the passenger and pedestrians around. Experimental results in real pedestrian paths show that the PMV is capable of smoothly following its path while facing pedestrians and bicycles.
ER  - 

TY  - CONF
TI  - Identifying Driver Behaviors Using Trajectory Features for Vehicle Navigation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3445
EP  - 3452
AU  - E. Cheung
AU  - A. Bera
AU  - E. Kubin
AU  - K. Gray
AU  - D. Manocha
PY  - 2018
KW  - automobiles
KW  - behavioural sciences computing
KW  - driver information systems
KW  - feature extraction
KW  - Internet
KW  - mobile robots
KW  - vehicle trajectories
KW  - autonomous vehicles
KW  - car trajectories
KW  - data-driven mapping
KW  - vehicle navigation simulation system
KW  - driver behavior identification
KW  - Web-based user study
KW  - Trajectory
KW  - Navigation
KW  - Automobiles
KW  - Feature extraction
KW  - Measurement
KW  - Acceleration
DO  - 10.1109/IROS.2018.8594348
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel approach to automatically identify driver behaviors from vehicle trajectories and use them for safe navigation of autonomous vehicles. We propose a novel set of features that can be easily extracted from car trajectories. We derive a data-driven mapping between these features and six driver behaviors using an elaborate web-based user study. We also compute a summarized score indicating a level of awareness that is needed while driving next to other vehicles. We also incorporate our algorithm into a vehicle navigation simulation system and demonstrate its benefits in terms of safer realtime navigation, while driving next to aggressive or dangerous drivers.
ER  - 

TY  - CONF
TI  - Preliminary Evaluation of Null-Space Dynamic Process Model Identification with Application to Cooperative Navigation of Underwater Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3453
EP  - 3459
AU  - Z. J. Harris
AU  - T. M. Paine
AU  - L. L. Whitcomb
PY  - 2018
KW  - least squares approximations
KW  - marine communication
KW  - parameter estimation
KW  - position control
KW  - underwater vehicles
KW  - vehicle dynamics
KW  - UV model parameters
KW  - control-surface parameters
KW  - thruster-model parameters
KW  - preliminary evaluation
KW  - null-space dynamic process model identification
KW  - underactuated underwater vehicle
KW  - control-input parameters
KW  - UV nonlinear plant-model parameters
KW  - nonlinear model identification
KW  - underwater communication
KW  - cooperative navigation
KW  - null-space least-squares parameter identification method
KW  - Navigation
KW  - Vehicle dynamics
KW  - Acoustics
KW  - Underwater vehicles
KW  - Heuristic algorithms
KW  - Kinematics
KW  - Kalman filters
DO  - 10.1109/IROS.2018.8594257
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper reports a method and preliminary evaluation of a novel null-space least-squares parameter identification method for a fully nonlinear second -order 6-degree-of-freedom (DOF) dynamic process model of an underactuated underwater vehicle (UV) for which both the model parameters and the control-input parameters are unknown. This paper further reports the application of the identified plant models in combined underwater communication and navigation (cooperative navigation) of UVs. We report an approach to model identification that simultaneously identifies 6-DOF UV nonlinear plant-model parameters, control-surface parameters, and thruster-model parameters. We believe this approach is suitable for identifying plant model parameters from data obtained in full-scale experimental trials of UVs in controlled motion. The reported approach to nonlinear model identification of UVs is evaluated in simulation studies. The resulting identified UV plant models are further evaluated in simulated cooperative navigation missions of the UV that are representative of high-precision survey missions. To the best of our knowledge, this paper reports the first method to identify 6-DOF UV model parameters, control-surface parameters, and thruster-model parameters simultaneously.
ER  - 

TY  - CONF
TI  - Autonomous Acquisition of Behavior Trees for Robot Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3460
EP  - 3467
AU  - B. Banerjee
PY  - 2018
KW  - computer games
KW  - feedback
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - trees (mathematics)
KW  - robot control
KW  - learned control policy
KW  - RL control policies
KW  - optimal behavior permutation
KW  - intelligent agents
KW  - autonomous acquisition
KW  - computer game industry
KW  - intelligent robots
KW  - reinforcement learning
KW  - decanonicalization algorithm
KW  - canonical behavior tree
KW  - combinatorial search
KW  - Task analysis
KW  - Computer architecture
KW  - Reinforcement learning
KW  - Robot control
KW  - Games
KW  - Industries
DO  - 10.1109/IROS.2018.8594083
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Behavior trees (BT) are a popular control architecture in the computer game industry, and have been more recently applied in robotics. One open question is how can intelligent agents/robots autonomously acquire their behavior trees for task level control? In contrast with existing approaches that either refine an initially given BT, or directly build the BT based on human feedback/demonstration, we leverage reinforcement learning (RL) that allows robots to autonomously learn control policies by repeated task interaction, but often expressed in a language more difficult to interpret than BTs. The learned control policy is then converted to a behavior tree via our proposed decanonicalization algorithm. The feasibility of this idea is based on a proposed notion of canonical behavior trees (CBT). In particular, we show (1) CBTs are sufficiently expressive to capture RL control policies, and (2) that RL can be independent of an optimal behavior permutation, despite the BT convention of left-to-right priority, thus obviating the need for a combinatorial search. Two evaluation domains help illustrate our approach.
ER  - 

TY  - CONF
TI  - Learning-Based Modular Task-Oriented Grasp Stability Assessment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3468
EP  - 3475
AU  - J. Xu
AU  - A. Bhardwaj
AU  - G. Sun
AU  - T. Aykut
AU  - N. Alt
AU  - M. Karimi
AU  - E. Steinbach
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - stability
KW  - tactile sensors
KW  - modular task-oriented stability assessment
KW  - stability prediction
KW  - relevant modular tasks
KW  - unnecessary grasp adaptations
KW  - manipulation actions
KW  - trained model
KW  - individual stability demands
KW  - specific task
KW  - underlying model
KW  - learning-based approach
KW  - object uncertainties
KW  - sensory data
KW  - robotic manipulation tasks
KW  - modular task-oriented grasp stability assessment
KW  - manipulation task
KW  - unnecessary grasp force adaptations
KW  - Task analysis
KW  - Stability analysis
KW  - Force
KW  - Tactile sensors
KW  - Feature extraction
KW  - Friction
KW  - Adaptation models
DO  - 10.1109/IROS.2018.8594412
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Assessing grasp stability is essential to prevent the failure of robotic manipulation tasks due to sensory data and object uncertainties. Learning-based approaches are widely deployed to infer the success of a grasp. Typically, the underlying model used to estimate the grasp stability is trained for a specific task, such as lifting, hand-over, or pouring. Since every task has individual stability demands, it is important to adapt the trained model to new manipulation actions. If the same trained model is directly applied to a new task, unnecessary grasp adaptations might be triggered, or in the worst case, the manipulation might fail. To address this issue, we divide the manipulation task used for training into seven sub-tasks, defined as modular tasks. We deploy a learning-based approach and assess the stability for each modular task separately. We further propose analytical features to reduce the dimensionality and the redundancy of the tactile sensor readings. A main task can thereby be represented as a sequence of relevant modular tasks. The stability prediction of the main task is computed based on the inferred success labels of the modular tasks. Our experimental evaluation shows that the proposed feature set lowers the prediction error up to 5.69% compared to other sets used in state-of-the-art methods. Robotic experiments demonstrate that our modular task-oriented stability assessment avoids unnecessary grasp force adaptations and regrasps for various manipulation tasks.
ER  - 

TY  - CONF
TI  - Interactive Robotic Manipulation of Elastic Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3476
EP  - 3481
AU  - S. Duenser
AU  - J. M. Bern
AU  - R. Poranne
AU  - S. Coros
PY  - 2018
KW  - collision avoidance
KW  - elastic deformation
KW  - finite element analysis
KW  - force control
KW  - manipulators
KW  - robot kinematics
KW  - sensitivity analysis
KW  - simulation
KW  - interactive simulation-based control methodology
KW  - interactive robotic manipulation
KW  - finite element method
KW  - sensitivity analysis
KW  - mathematical model
KW  - robots configuration
KW  - collision avoidance
KW  - elastic deformation objects
KW  - quasistatic assumption
KW  - Robots
KW  - Computational modeling
KW  - Shape
KW  - Collision avoidance
KW  - Mathematical model
KW  - Strain
KW  - Finite element analysis
DO  - 10.1109/IROS.2018.8594291
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we address the challenge of robotic manipulation of elastically deforming objects. To this end, we model elastic objects using the Finite Element Method. Through a quasi-static assumption, we leverage sensitivity analysis to mathematically model how changes in the robot's configuration affect the deformed shape of the object being manipulated. This enables an interactive, simulation-based control methodology, wherein user-specified deformations for the elastic objects are automatically mapped to joint angle commands. The optimization formulation we introduce is general, operates directly within a robot's workspace and can readily incorporate joint limits as well as collision avoidance between the links. We validate our control methodology on a YuMi® IRB 14000, which we use to manipulate a variety of elastic objects.
ER  - 

TY  - CONF
TI  - Domain Randomization and Generative Models for Robotic Grasping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3482
EP  - 3489
AU  - J. Tobin
AU  - L. Biewald
AU  - R. Duan
AU  - M. Andrychowicz
AU  - A. Handa
AU  - V. Kumar
AU  - B. McGrew
AU  - A. Ray
AU  - J. Schneider
AU  - P. Welinder
AU  - W. Zaremba
AU  - P. Abbeel
PY  - 2018
KW  - grippers
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - probability
KW  - domain randomization
KW  - generative models
KW  - deep learning-based robotic grasping
KW  - significant progress thanks
KW  - algorithmic improvements
KW  - increased data availability
KW  - state-of-the-art models
KW  - unique object instances
KW  - result generalization
KW  - novel data generation pipeline
KW  - deep neural network
KW  - successful grasps
KW  - autoregressive grasp planning model
KW  - probability distribution
KW  - possible grasps
KW  - sample grasps
KW  - test time
KW  - model architecture
KW  - unseen realistic objects
KW  - random objects
KW  - real-world grasp
KW  - random simulated objects
KW  - Grasping
KW  - Training
KW  - Data models
KW  - Computational modeling
KW  - Robot sensing systems
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593933
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep learning-based robotic grasping has made significant progress thanks to algorithmic improvements and increased data availability. However, state-of-the-art models are often trained on as few as hundreds or thousands of unique object instances, and as a result generalization can be a challenge. In this work, we explore a novel data generation pipeline for training a deep neural network to perform grasp planning that applies the idea of domain randomization to object synthesis. We generate millions of unique, unrealistic procedurally generated objects, and train a deep neural network to perform grasp planning on these objects. Since the distribution of successful grasps for a given object can be highly multimodal, we propose an autoregressive grasp planning model that maps sensor inputs of a scene to a probability distribution over possible grasps. This model allows us to sample grasps efficiently at test time (or avoid sampling entirely). We evaluate our model architecture and data generation pipeline in simulation and the real world. We find we can achieve a >90% success rate on previously unseen realistic objects at test time in simulation despite having only been trained on random objects. We also demonstrate an 80% success rate on real-world grasp attempts despite having only been trained on random simulated objects.
ER  - 

TY  - CONF
TI  - Improving Grasping Forces During the Manipulation of Unknown Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3490
EP  - 3495
AU  - A. Montaño
AU  - R. Suárez
PY  - 2018
KW  - dexterous manipulators
KW  - manipulator kinematics
KW  - object recognition
KW  - simple geometrical approach
KW  - kinematic information
KW  - local object curvature
KW  - object manipulation problem
KW  - tactile information
KW  - object shape recognition
KW  - grasping forces
KW  - Schunk dexterous hand
KW  - SDH2
KW  - Shape
KW  - Tactile sensors
KW  - Force
KW  - Kinematics
KW  - Grasping
DO  - 10.1109/IROS.2018.8593655
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many of the solutions proposed for the object manipulation problem are based on the knowledge of the object features. The approach proposed in this paper intends to provide a simple geometrical approach to securely manipulate an unknown object based only on tactile and kinematic information. The tactile and kinematic data obtained during the manipulation is used to recognize the object shape (at least the local object curvature), allowing to improve the grasping forces when this information is added to the manipulation strategy. The approach has been fully implemented and tested using the Schunk Dexterous Hand (SDH2). Experimental results are shown to illustrate the efficiency of the approach.
ER  - 

TY  - CONF
TI  - Intrinsically Motivated Self-Supervised Deep Sensorimotor Learning for Grasping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3496
EP  - 3502
AU  - T. Takahashi
AU  - M. W. Lanighan
AU  - R. A. Grupen
PY  - 2018
KW  - closed loop systems
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - high-dimensional state spaces
KW  - object recognition
KW  - video games
KW  - machine translation
KW  - deep neural networks
KW  - training datasets
KW  - deep learning
KW  - robot systems
KW  - closed-loop control states
KW  - motivated self-supervised deep sensorimotor learning
KW  - intrinsic motivators
KW  - Robot sensing systems
KW  - Entropy
KW  - Training
KW  - Uncertainty
KW  - Deep learning
KW  - Biological neural networks
DO  - 10.1109/IROS.2018.8593424
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep learning has been successful in a variety of applications that have high-dimensional state spaces such as object recognition, video games, and machine translation. Deep neural networks can automatically learn important features from high-dimensional state given large training datasets. However, the success of deep learning in robot systems in the realworld is limited due to the cost of obtaining these large datasets. To overcome this problem, we propose an information-theoretic, intrinsically motivated, self-labeling mechanism using closed-loop control states. Taking this approach biases exploration to informative interactions-as such, a robot requires much less training to achieve reliable performance. In this paper, we explore the impact such an approach has on learning how to grasp objects. We evaluate different intrinsic motivators present in the literature applied appropriately in our framework and discuss the benefits and drawbacks of each.
ER  - 

TY  - CONF
TI  - Manipulation Planning Under Changing External Forces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3503
EP  - 3510
AU  - L. Chen
AU  - L. F. C. Figueredo
AU  - M. Dogar
PY  - 2018
KW  - grippers
KW  - path planning
KW  - position control
KW  - stability
KW  - bimanual regrasp planning
KW  - bimanual robot
KW  - external forces
KW  - manipulation planning algorithm
KW  - forceful operations
KW  - subsequent grasps
KW  - single gripper
KW  - stability
KW  - Planning
KW  - Grippers
KW  - Manifolds
KW  - Manipulators
KW  - Task analysis
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593555
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a manipulation planning algorithm for a robot to keep an object stable under changing external forces. We particularly focus on the case where a human may be applying forceful operations, e.g. cutting or drilling, on an object that the robot is holding. The planner produces an efficient plan by intelligently deciding when the robot should change its grasp on the object as the human applies the forces. The planner also tries to choose subsequent grasps such that they will minimize the number of regrasps that will be required in the long-term. Furthermore, as it switches from one grasp to the other, the planner solves the problem of bimanual regrasp planning, where the object is not placed on a support surface, but instead it is held by a single gripper until the second gripper moves to a new position on the object. This requires the planner to also reason about the stability of the object under gravity. We provide an implementation on a bimanual robot and present experiments to show the performance of our planner.
ER  - 

TY  - CONF
TI  - Jacquard: A Large Scale Dataset for Robotic Grasp Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3511
EP  - 3516
AU  - A. Depierre
AU  - E. Dellandréa
AU  - L. Chen
PY  - 2018
KW  - belief networks
KW  - CAD
KW  - computer vision
KW  - grippers
KW  - image classification
KW  - image representation
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - robot vision
KW  - solid modelling
KW  - robotic grasp detection
KW  - grasping skill
KW  - real-life applications
KW  - state-of-the-art robotic
KW  - deep neural networks
KW  - robotics
KW  - scale synthetic dataset
KW  - ground truth
KW  - Jacquard grasping dataset
KW  - CAD models dataset
KW  - successful grasping positions
KW  - grasp attempts
KW  - grasping robot trials
KW  - generalization skills
KW  - Jacquard dataset
KW  - grasping position detections
KW  - human labeled dataset
KW  - CNN
KW  - RGB-D images
KW  - ShapeNet
KW  - Solid modeling
KW  - Grippers
KW  - Robot kinematics
KW  - Grasping
KW  - Data models
KW  - Neural networks
DO  - 10.1109/IROS.2018.8593950
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Grasping skill is a major ability that a wide number of real-life applications require for robotisation. State-of-the-art robotic grasping methods perform prediction of object grasp locations based on deep neural networks. However, such networks require huge amount of labeled data for training making this approach often impracticable in robotics. In this paper, we propose a method to generate a large scale synthetic dataset with ground truth, which we refer to as the Jacquard grasping dataset. Jacquard is built on a subset of ShapeNet, a large CAD models dataset, and contains both RGB-D images and annotations of successful grasping positions based on grasp attempts performed in a simulated environment. We carried out experiments using an off-the-shelf CNN, with three different evaluation metrics, including real grasping robot trials. The results show that Jacquard enables much better generalization skills than a human labeled dataset thanks to its diversity of objects and grasping positions. For the purpose of reproducible research in robotics, we are releasing along with the Jacquard dataset a web interface for researchers to evaluate the successfulness of their grasping position detections using our dataset.
ER  - 

TY  - CONF
TI  - Planning Hand-Arm Grasping Motions with Human-Like Appearance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3517
EP  - 3522
AU  - N. García
AU  - R. Suárez
AU  - J. Rosell
PY  - 2018
KW  - humanoid robots
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - planning hand-arm grasping motions
KW  - hand-arm robotic systems
KW  - grasping actions
KW  - coordinated movements
KW  - robotic arm
KW  - anthropomorphic mechanical hand
KW  - human movements
KW  - human hand synergies
KW  - planning phase
KW  - motion planning
KW  - state-of-the-art planning algorithm
KW  - human-like appearance
KW  - search space
KW  - sampling-based planner
KW  - Planning
KW  - Grasping
KW  - Robot kinematics
KW  - Trajectory
KW  - Complexity theory
KW  - Manipulators
DO  - 10.1109/IROS.2018.8594432
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the problem of obtaining human-like motions on hand-arm robotic systems performing grasping actions. The focus is set on the coordinated movements of the robotic arm and the anthropomorphic mechanical hand, with which the arm is equipped. For this, human movements performing different grasps are captured and mapped to the robot in order to compute the human hand synergies. These synergies are used to both obtain human-like movements and to reduce the complexity of the planning phase by reducing the dimension of the search space. In addition, the paper proposes a sampling-based planner, which guides the motion planning following the synergies and considering different types of grasps. The introduced approach is tested in an application example and thoroughly compared with a state-of-the-art planning algorithm, obtaining better results.
ER  - 

TY  - CONF
TI  - Efficient Computation of Invariably Safe States for Motion Planning of Self-Driving Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3523
EP  - 3530
AU  - C. Pek
AU  - M. Althoff
PY  - 2018
KW  - collision avoidance
KW  - Markov processes
KW  - road vehicles
KW  - stochastic systems
KW  - self-driving vehicles
KW  - planning horizon
KW  - infinite time horizon
KW  - time-to-react metric
KW  - motion planning
KW  - Trajectory
KW  - Planning
KW  - Safety
KW  - Dynamics
KW  - Vehicle dynamics
KW  - Measurement
KW  - Reachability analysis
DO  - 10.1109/IROS.2018.8593597
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Safe motion planning requires that a vehicle reaches a set of safe states at the end of the planning horizon. However, safe states of vehicles have not yet been systematically defined in the literature, nor does a computationally efficient way to obtain them for online motion planning exist. To tackle the aforementioned issues, we introduce invariably safe sets. These are regions that allow vehicles to remain safe for an infinite time horizon. We show how invariably safe sets can be computed and propose a tight under-approximation which can be obtained efficiently in linear time with respect to the number of traffic participants. We use invariably safe sets to lift safety verification from finite to infinite time horizons. In addition, our sets can be used to determine the existence of feasible evasive maneuvers and the criticality of scenarios by computing the time-to-react metric.
ER  - 

TY  - CONF
TI  - Improving Offline Value-Function Approximations for POMDPs by Reducing Discount Factors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3531
EP  - 3536
AU  - Y. Chen
AU  - M. J. Kochenderfer
AU  - M. T. J. Spaan
PY  - 2018
KW  - decision theory
KW  - function approximation
KW  - Markov processes
KW  - exponentially discounted rewards
KW  - state space
KW  - observation model
KW  - offline value-function approximations
KW  - partially observable Markov decision processes
KW  - POMDP
KW  - discount factor reduction
KW  - Planning
KW  - Observability
KW  - Approximation error
KW  - Markov processes
KW  - Memory management
KW  - Benchmark testing
DO  - 10.1109/IROS.2018.8594418
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A common solution criterion for partially observable Markov decision processes (POMDPs) is to maximize the expected sum of exponentially discounted rewards, for which a variety of approximate methods have been proposed. Those that plan in the belief space typically provide tighter performance guarantees, but those that plan over the state space (e.g., QMDP and FIB) often require much less memory and computation. This paper presents an encouraging result that shows that reducing the discount factor while planning in the state space can actually improve performance significantly when evaluated on the original problem. This phenomenon is confirmed by both a theoretical analysis as well as a series of empirical studies on benchmark problems. As predicted by the theory and confirmed empirically, the phenomenon is most prominent when the observation model is noisy or rewards are sparse.
ER  - 

TY  - CONF
TI  - Robust Exploration with Multiple Hypothesis Data Association
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3537
EP  - 3544
AU  - J. Wang
AU  - B. Englot
PY  - 2018
KW  - image fusion
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - target tracking
KW  - tree searching
KW  - joint compatibility branch
KW  - simultaneous localization and mapping
KW  - map accuracy
KW  - diverse hypotheses
KW  - multiple hypothesis tracking
KW  - robust back-ends
KW  - catastrophic failure
KW  - single false positive assignment
KW  - rich features
KW  - autonomous exploration
KW  - SLAM
KW  - ambiguous data association problem
KW  - multiple hypothesis data association
KW  - robust exploration
KW  - Simultaneous localization and mapping
KW  - Trajectory
KW  - Noise measurement
KW  - State estimation
KW  - Optimization
KW  - Measurement uncertainty
DO  - 10.1109/IROS.2018.8593753
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We study the ambiguous data association problem confronting simultaneous localization and mapping (SLAM), specifically for the autonomous exploration of environments lacking rich features. In such environments, a single false positive assignment might lead to catastrophic failure, which even robust back-ends may be unable to resolve. Inspired by multiple hypothesis tracking, we present a novel approach to effectively manage multiple hypotheses (MH) of data association inherited from traditional joint compatibility branch and bound (JCBB), which entails the generation, ordering and elimination of hypotheses. We analyze the performance of MHJCBB in two particular situations, one applying it to SLAM over a predefined trajectory and the other showing its applicability in exploring unknown environments. Statistical results demonstrate that MHJCBB's maintenance of diverse hypotheses under ambiguous conditions significantly improves map accuracy.
ER  - 

TY  - CONF
TI  - Reactive Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3545
EP  - 3550
AU  - A. Dhawale
AU  - X. Yang
AU  - N. Michael
PY  - 2018
KW  - cameras
KW  - collision avoidance
KW  - Gaussian processes
KW  - geometry
KW  - helicopters
KW  - mobile robots
KW  - probability
KW  - trajectory control
KW  - collision avoidance
KW  - discrete map
KW  - GMM local mapping algorithm
KW  - gaussian mixture model maps
KW  - robots
KW  - CPU
KW  - quadrotor navigation
KW  - depth camera processing
KW  - time-parameterized trajectory
KW  - geometric properties
KW  - probabilistic approach
KW  - cluttered environments
KW  - Trajectory
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Current measurement
KW  - Gaussian mixture model
DO  - 10.1109/IROS.2018.8593723
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.
ER  - 

TY  - CONF
TI  - Integrating Human-Provided Information into Belief State Representation Using Dynamic Factorization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3551
EP  - 3558
AU  - R. Chitnis
AU  - L. P. Kaelbling
AU  - T. Lozano-Pérez
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - 3D continuous cooking task
KW  - 2D discrete gridworld task
KW  - open-domain planning problems
KW  - complex partially observed tasks
KW  - efficient planning
KW  - static factoring
KW  - possible objects
KW  - open domains
KW  - appropriate factoring
KW  - efficient belief state representation
KW  - raw sensory information
KW  - internal knowledge
KW  - sensory observations
KW  - probabilistic relational constraints
KW  - declarative information
KW  - partially observed environments
KW  - dynamic factorization
KW  - Planning
KW  - Robot sensing systems
KW  - Task analysis
KW  - Markov processes
KW  - Intelligent robots
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594468
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In partially observed environments, it can be useful for a human to provide the robot with declarative information that represents probabilistic relational constraints on properties of objects in the world, augmenting the robot's sensory observations. For instance, a robot tasked with a search-and-rescue mission may be informed by the human that two victims are probably in the same room. An important question arises: how should we represent the robot's internal knowledge so that this information is correctly processed and combined with raw sensory information? In this paper, we provide an efficient belief state representation that dynamically selects an appropriate factoring, combining aspects of the belief when they are correlated through information and separating them when they are not. This strategy works in open domains, in which the set of possible objects is not known in advance, and provides significant improvements in inference time over a static factoring, leading to more efficient planning for complex partially observed tasks. We validate our approach experimentally in two open-domain planning problems: a 2D discrete gridworld task and a 3D continuous cooking task. A supplementary video can be found at http://tinyurl.com/chitnis-iros-18.
ER  - 

TY  - CONF
TI  - Simultaneous Task Allocation and Planning Under Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3559
EP  - 3564
AU  - F. Faruq
AU  - D. Parker
AU  - B. Laccrda
AU  - N. Hawes
PY  - 2018
KW  - control engineering computing
KW  - formal verification
KW  - iterative methods
KW  - Markov processes
KW  - mobile robots
KW  - multi-robot systems
KW  - operating systems (computers)
KW  - path planning
KW  - resource allocation
KW  - robot programming
KW  - temporal logic
KW  - simultaneous task allocation
KW  - uncertain environments
KW  - individual robot behaviour
KW  - linear temporal logic
KW  - multirobot policies
KW  - simultaneous task planning
KW  - Markov decision processes
KW  - formal verification
KW  - multirobot operating systems
KW  - Task analysis
KW  - Planning
KW  - Robot kinematics
KW  - Resource management
KW  - Uncertainty
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594404
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.
ER  - 

TY  - CONF
TI  - Strategic-Tactical Planning for Autonomous Underwater Vehicles over Long Horizons
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3565
EP  - 3572
AU  - D. Buksz
AU  - M. Cashmore
AU  - B. Krarup
AU  - D. Magazzeni
AU  - B. Ridder
PY  - 2018
KW  - autonomous underwater vehicles
KW  - control engineering computing
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - robot dynamics
KW  - vehicle dynamics
KW  - strategic-tactical planning
KW  - autonomous underwater vehicles
KW  - long horizons
KW  - persistent autonomy
KW  - AI Planners
KW  - long-term autonomous behaviour
KW  - abstraction planning techniques
KW  - two-level hierarchical structure
KW  - hierarchical decompositions
KW  - Task analysis
KW  - Planning
KW  - Manifolds
KW  - Batteries
KW  - Inspection
KW  - Robots
KW  - Valves
DO  - 10.1109/IROS.2018.8594347
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In challenging environments where human intervention is expensive, robust and persistent autonomy is a key requirement. AI Planners can efficiently construct plans to achieve this long-term autonomous behaviour. However, in plans which are expected to last over days, or even weeks, the size of the state-space becomes too large for current planners to solve as a single problem. These problems are well-suited to decomposition and abstraction planning techniques. We present a novel approach in the context of persistent autonomy in autonomous underwater vehicles, in which tasks are complex and diverse and plans cannot be precomputed. Our approach performs a decomposition into a two-level hierarchical structure, which dynamically constructs planning problems at the upper level of the hierarchy using solution plans from the lower level. Solution plans are then executed and monitored simultaneously at both levels. We evaluate the approach, showing that compared to strictly top-down hierarchical decompositions, our approach leads to more robust solution plans of higher quality.
ER  - 

TY  - CONF
TI  - Grid-Based Motion Planning Using Advanced Motions for Hexapod Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3573
EP  - 3578
AU  - W. Cheah
AU  - H. H. Khalili
AU  - S. Watson
AU  - P. Green
AU  - B. Lennox
PY  - 2018
KW  - graph theory
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - grid-based motion planning
KW  - advanced motions
KW  - hexapod robots
KW  - motion planning framework
KW  - chimney walking
KW  - robot motion
KW  - hierarchical planning framework
KW  - custom-designed Corin hexapod
KW  - environment surfaces
KW  - Legged locomotion
KW  - Planning
KW  - Trajectory
KW  - Collision avoidance
KW  - Robot motion
DO  - 10.1109/IROS.2018.8593964
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the motion planning framework for a hexapod, based on advanced motions, for accessing challenging spaces, namely narrow pathways and large holes, both of which are surrounded by walls. The advanced motions, wall and chimney walking, utilise environment surfaces that are perpendicular to the ground plane to support the robot motion. Such techniques have not yet been studied in the literature. The hierarchical planning framework proposed here is an extension to existing approaches which have only considered ground walking where foothold contacts are confined to the ground plane. During the pre-processing phase of the 2.5D grid map, the motion primitives employed are assessed for each cell and stacked to the graph if valid. The A* algorithm is then used to find a path to the goal position. Following that, the path is post-processed to smoothen the motions and generate a continuous path. Footholds are then selected along the path. The framework has been evaluated in simulation on the custom-designed Corin hexapod. The resulting path enables access to areas that are previously thought to be inaccessible and reduces the travelling distance compared to previous studies.
ER  - 

TY  - CONF
TI  - Learning from Demonstration for Hydraulic Manipulators
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3579
EP  - 3586
AU  - M. Suomalainen
AU  - J. Koivumäki
AU  - S. Lampinen
AU  - V. Kyrki
AU  - J. Mattila
PY  - 2018
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - force sensors
KW  - friction
KW  - hydraulic systems
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - manipulators
KW  - motion control
KW  - position control
KW  - stability
KW  - telerobotics
KW  - fragile force-torque sensor
KW  - heavy-duty hydraulic manipulators
KW  - teleoperated human demonstrations
KW  - novel VDC-based impedance control method
KW  - sliding motion
KW  - learning method
KW  - manipulator actuators
KW  - contact force
KW  - hydraulic slave manipulator
KW  - slave manipulators
KW  - teleoperation system
KW  - stability-guaranteed controller
KW  - virtual decomposition control
KW  - advanced subsystem-dynamic-based control design framework
KW  - human demonstration
KW  - reasonable method
KW  - force-reflected bilateral teleoperation
KW  - extremely powerful hydraulic manipulator
KW  - teleoperated demonstration
KW  - in-contact tasks
KW  - Hydraulic systems
KW  - Force
KW  - Task analysis
KW  - Manipulator dynamics
KW  - Impedance
KW  - Control design
DO  - 10.1109/IROS.2018.8594285
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents, for the first time, a method for learning in-contact tasks from a teleoperated demonstration with a hydraulic manipulator. Due to the use of extremely powerful hydraulic manipulator, a force-reflected bilateral teleoperation is the most reasonable method of giving a human demonstration. An advanced subsystem-dynamic-based control design framework, virtual decomposition control (VDC), is used to design a stability-guaranteed controller for the teleoperation system, while taking into account the full nonlinear dynamics of the master and slave manipulators. The use of fragile force/torque sensor at the tip of the hydraulic slave manipulator is avoided by estimating the contact forces from the manipulator actuators' chamber pressures. In the proposed learning method, it is observed that a surface-sliding tool has a friction-dependent range of directions (between the actual direction of motion and the contact force) from which the manipulator can apply force to produce the sliding motion. By this intuition, an intersection of these ranges can be taken over a motion to robustly find a desired direction for the motion from one or more demonstrations. The compliant axes required to reproduce the motion can be found by assuming that all motions outside the desired direction is caused by the environment, signalling the need for compliance. Finally, the learning method is incorporated to a novel VDC-based impedance control method to learn compliant behaviour from teleoperated human demonstrations. Experiments with 2-DOF hydraulic manipulator with a 475kg payload demonstrate the suitability and effectiveness of the proposed method to perform learning from demonstration (LfD) with heavy-duty hydraulic manipulators.
ER  - 

TY  - CONF
TI  - Development and Error Compensation of a Flexible Multi-Joint Manipulator Applied in Nuclear Fusion Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3587
EP  - 3592
AU  - S. Shi
AU  - Y. Cheng
AU  - H. Pan
AU  - W. Zhao
AU  - H. Wu
PY  - 2018
KW  - backpropagation
KW  - collision avoidance
KW  - error compensation
KW  - fusion reactor design
KW  - fusion reactor instrumentation
KW  - high energy physics instrumentation computing
KW  - manipulator kinematics
KW  - neural nets
KW  - physical instrumentation control
KW  - plasma toroidal confinement
KW  - Tokamak devices
KW  - nuclear fusion environment
KW  - Experimental Advanced Superconducting Tokamak
KW  - noncircular cross-section
KW  - real-time detection
KW  - plasma discharges
KW  - EAMA system design
KW  - vacuum-available design scheme
KW  - error prediction
KW  - EAST articulated maintenance arm
KW  - repair operations
KW  - internal components
KW  - high temperature environments
KW  - flexible robot arms
KW  - error compensation
KW  - flexible multijoint manipulator
KW  - EAST ultrahigh vacuum condition
KW  - inverse kinematics
KW  - obstacle avoidance strategy
KW  - back-propagation neural network
KW  - integrated control strategy
KW  - temperature 80.0 degC to 120.0 degC
KW  - Manipulators
KW  - Kinematics
KW  - Predictive models
KW  - Load modeling
KW  - Error compensation
KW  - Strain
DO  - 10.1109/IROS.2018.8593621
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Experimental Advanced Superconducting Tokamak (EAST) is the world's first fully superconducting tokamak fusion device with non-circular cross-section which was built in China The EAST articulated maintenance arm (EAMA) system is developed for real-time detection and rapid repair operations to damaged internal components during plasma discharges without breaking the EAST ultra-high vacuum (UHV) condition. To achieve the desired objectives, the EAMA system design should guarantee that the robot can stably run in the harsh environments of high temperature (80-120 °C) and high vacuum (~ 10-5Pa). Meanwhile, the errors caused by the deformation of long flexible robot arms should also be predicted and compensated in real-time to obtain high accuracy for maintenance operations. In this paper, the vacuum-available design scheme of the manipulator system was firstly introduced. Secondly, inverse kinematics and obstacle avoidance strategy of the highly redundant EAMA robot was built. Then, flexible errors were predicted utilizing a back-propagation neural network (BPNN) model which was established on the basis of real experimental data. Finally, an integrated control strategy for error prediction and compensation was developed.
ER  - 

TY  - CONF
TI  - Progress and Prospects of EAST Remote Maintenance System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3593
EP  - 3598
AU  - H. Pan
AU  - S. Shi
AU  - Y. Cheng
AU  - W. Zhao
PY  - 2018
KW  - automatic optical inspection
KW  - edge detection
KW  - fusion reactor instrumentation
KW  - grippers
KW  - inspection
KW  - maintenance engineering
KW  - nuclear power stations
KW  - object detection
KW  - plasma toroidal confinement
KW  - power system control
KW  - robot vision
KW  - service robots
KW  - Tokamak devices
KW  - light maintenance capability
KW  - tokamak condition
KW  - EAST remote maintenance system
KW  - grasping tasks
KW  - EAMA robot
KW  - EAST articulated maintenance arm
KW  - EAMA control system
KW  - EAST tokamak
KW  - CIVIS
KW  - CFETR in-vessel inspection system
KW  - Maintenance engineering
KW  - Inspection
KW  - Solid modeling
KW  - Manipulators
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594000
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fast inspection and light maintenance capability is already a clear demand to control the tokamak condition and improve the efficiency of the experimental campaigns. EAST remote maintenance system has been developed to implement inspection and grasping tasks during plasma. The paper presents design description of EAMA (EAST articulated maintenance arm) robot, the gripper and the CASK. The field commissioning was performed both in mockup and EAST tokamak to demonstrate the availability and functionalities of EAMA system. To be able to realize fully routine operation on EAST, improvement of EAMA control system was proposed with integration developed algorithm, such as the robot flexible model modeling, vision servo, motion planning, etc. Finally, thoughts for CFETR In-Vessel Inspection System (CIVIS) are given.
ER  - 

TY  - CONF
TI  - Pose Estimation for Mobile Robots to Maximise Data Quality of Fixed-Focus Laser Diagnostics in Hazardous Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3599
EP  - 3604
AU  - A. West
AU  - S. Watson
AU  - B. Lennox
PY  - 2018
KW  - collision avoidance
KW  - laser beam effects
KW  - mobile robots
KW  - pose estimation
KW  - sensor placement
KW  - service robots
KW  - spectroscopy
KW  - pose estimation
KW  - mobile robots
KW  - data quality
KW  - fixed-focus laser diagnostic
KW  - hazardous environments
KW  - nuclear environments
KW  - decommissioning
KW  - LIBS
KW  - scientific instrument
KW  - optical emission
KW  - arbitrary diagnostic mounting
KW  - obstacle avoidance
KW  - diagnostic mounting
KW  - sensor placement
KW  - high intensity pulsed laser
KW  - laser induced breakdown spectroscopy
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Data integrity
KW  - Lasers
KW  - Instruments
KW  - Plasmas
DO  - 10.1109/IROS.2018.8593367
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Characterisation of nuclear environments is critical for long term operation and decommissioning. Laser Induced Breakdown Spectroscopy (LIBS) is an example of a scientific instrument that could be deployed to aid in characterisation of unknown environments. LIBS consists of a high intensity pulsed laser being focussed down onto a target to create a plasma, and optical emission from the plasma is then used to determine elemental composition of unknown materials. For robots deployed with these instruments in extreme environments, mission time can be limited by hazards present such as radiation. Once deployed a robot must be able to collect the best data possible whilst maximising operational runtime. We present a data quality based probabilistic approach to robot pose estimation to maximise data quality, by considering optimum sensor placement whilst avoiding harmful environmental features such as radiation for a fixed-focus laser diagnostic such as LIBS. This approach is able to determine optimum robot poses for arbitrary targets in 3D for arbitrary diagnostic mounting with respect to the robot. The approach is able to avoid obstacles and avoid occlusion of the target by said obstacles. This can be used as part of autonomous investigation and characterisation performed by mobile robots in hazardous environments.
ER  - 

TY  - CONF
TI  - A Variational Feature Encoding Method of 3D Object for Probabilistic Semantic SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3605
EP  - 3612
AU  - H. W. Yu
AU  - B. H. Lee
PY  - 2018
KW  - Bayes methods
KW  - belief networks
KW  - feature extraction
KW  - maximum likelihood estimation
KW  - object recognition
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - object recognition methods
KW  - true generative model
KW  - semantic simultaneous localization and mapping
KW  - maximum likelihood estimation
KW  - shape retrieval
KW  - Bayesian inference
KW  - Bayesian networks
KW  - approximated distributions
KW  - variational auto-encoder
KW  - complex distributions
KW  - observation likelihood
KW  - tractable distributions
KW  - 3D object shapes
KW  - view-independent loop closure
KW  - object shape
KW  - range sensor
KW  - mobile robot
KW  - complex probability distribution
KW  - probabilistic observation model
KW  - high-level semantic features
KW  - complex 3D objects
KW  - probabilistic semantic SLAM
KW  - variational feature encoding method
KW  - Shape
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Semantics
KW  - Solid modeling
KW  - Bayes methods
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593831
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a feature encoding method of complex 3D objects for high-level semantic features. Recent approaches to object recognition methods become important for semantic simultaneous localization and mapping (SLAM). However, there is a lack of consideration of the probabilistic observation model for 3D objects, as the shape of a 3D object basically follows a complex probability distribution. Furthermore, since the mobile robot equipped with a range sensor observes only a single view, much information of the object shape is discarded. These limitations are the major obstacles to semantic SLAM and view-independent loop closure using 3D object shapes as features. In order to enable the numerical analysis for the Bayesian inference, we approximate the true observation model of 3D objects to tractable distributions. Since the observation likelihood can be obtained from the generative model, we formulate the true generative model for 3D object with the Bayesian networks. To capture these complex distributions, we apply a variational auto-encoder. To analyze the approximated distributions and encoded features, we perform classification with maximum likelihood estimation and shape retrieval.
ER  - 

TY  - CONF
TI  - End to End Vehicle Lateral Control Using a Single Fisheye Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3613
EP  - 3619
AU  - M. Toromanoff
AU  - E. Wirbel
AU  - F. Wilhelm
AU  - C. Vejarano
AU  - X. Perrotton
AU  - F. Moutarde
PY  - 2018
KW  - automobiles
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - mobile robots
KW  - robot vision
KW  - steering systems
KW  - label augmentation
KW  - short range fisheye camera
KW  - open road driving
KW  - single fisheye camera
KW  - convolutional neural networks
KW  - steering angle
KW  - autonomous cars
KW  - end-to-end control evaluation
KW  - end-to-end vehicle lateral control
KW  - urban road
KW  - sharp turns
KW  - obstacle avoidance
KW  - data augmentation
KW  - Automobiles
KW  - Cameras
KW  - Roads
KW  - Training
KW  - Neural networks
KW  - Testing
DO  - 10.1109/IROS.2018.8594090
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.
ER  - 

TY  - CONF
TI  - Learning Trajectories for Real- Time Optimal Control of Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3620
EP  - 3625
AU  - G. Tang
AU  - W. Sun
AU  - K. Hauser
PY  - 2018
KW  - control engineering computing
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - optimal control
KW  - quadratic programming
KW  - optimal trajectories
KW  - learning trajectories
KW  - quadrotors
KW  - agile movement
KW  - machine learning
KW  - trajectory optimization approach
KW  - nonlinear optimal control problems
KW  - fly-to-target movement problem
KW  - sparse quadratic programming solver
KW  - neural network
KW  - quadratic optimization
KW  - Trajectory
KW  - Neural networks
KW  - Optimal control
KW  - Training
KW  - Cost function
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593536
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Nonlinear optimal control problems are challenging to solve efficiently due to non-convexity. This paper introduces a trajectory optimization approach that achieves realtime performance by combining machine learning to predict optimal trajectories with refinement by quadratic optimization. First, a library of optimal trajectories is calculated offline and used to train a neural network. Online, the neural network predicts a trajectory for a novel initial state and cost function, and this prediction is further optimized by a sparse quadratic programming solver. We apply this approach to a fly-to-target movement problem for an indoor quadrotor. Experiments demonstrate that the technique calculates near-optimal trajectories in a few milliseconds, and generates agile movement that can be tracked more accurately than existing methods.
ER  - 

TY  - CONF
TI  - A Novel OCR-RCNN for Elevator Button Recognition
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3626
EP  - 3631
AU  - D. Zhu
AU  - T. Li
AU  - D. Ho
AU  - T. Zhou
AU  - M. Q. Meng
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - optical character recognition
KW  - path planning
KW  - recurrent neural nets
KW  - robot vision
KW  - service robots
KW  - autonomous elevator operation
KW  - inter-floor navigation problem
KW  - elevator button recognition
KW  - severe class imbalance problem
KW  - optical character recognition network
KW  - Faster RCNN architecture
KW  - elevator panels
KW  - OCR-RCNN architecture
KW  - service robots
KW  - image conditions
KW  - Elevators
KW  - Optical character recognition software
KW  - Proposals
KW  - Task analysis
KW  - Feature extraction
KW  - Training
KW  - Pipelines
DO  - 10.1109/IROS.2018.8594071
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Autonomous elevator operation is considered an intelligent solution in handling the inter-floor navigation problem of service robots. As one of the most fundamental steps, elevator button recognition starts to receive more and more attention. However, due to the challenging image conditions and severe class imbalance problem, the performance of existing results is unsatisfying. In this paper, we propose to combine an optical character recognition (OCR) network and the Faster RCNN architecture into a single neural network, called OCR-RCNN to facilitate an end-to-end training and elevator button recognition procedure. To verify our method, we collect a large dataset of elevator panels and carry out extensive comparative experiments. The experiment results show that our method can greatly outperform the traditional recognition pipelines, yielding an accurate and robust performance on recognizing untrained elevator buttons.
ER  - 

TY  - CONF
TI  - Cost Functions for Robot Motion Style
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3632
EP  - 3639
AU  - A. Zhou
AU  - A. D. Dragan
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - task constraints
KW  - nominal task cost
KW  - task types
KW  - task instances
KW  - robot motion style
KW  - nuanced costs
KW  - featurized costs
KW  - nominal motion
KW  - cost type
KW  - raw trajectory input
KW  - neural network parameterization operating
KW  - hand-designed features
KW  - weighted linear combination
KW  - cost functions
KW  - trajectory optimization process
KW  - Task analysis
KW  - Robots
KW  - Cost function
KW  - Neural networks
KW  - Trajectory optimization
DO  - 10.1109/IROS.2018.8594433
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We focus on autonomously generating robot motion for day to day physical tasks that is expressive of a certain style or emotion. Because we seek generalization across task instances and task types, we propose to capture style via cost functions that the robot can use to augment its nominal task cost and task constraints in a trajectory optimization process. We compare two approaches to representing such cost functions: a weighted linear combination of hand-designed features, and a neural network parameterization operating on raw trajectory input. For each cost type, we learn weights for each style from user feedback. We contrast these approaches to a nominal motion across different tasks and for different styles in a user study, and find that they both perform on par with each other, and significantly outperform the baseline. Each approach has its advantages: featurized costs require learning fewer parameters and can perform better on some styles, but neural network representations do not require expert knowledge to design features and could even learn more complex, nuanced costs than an expert can easily design.
ER  - 

TY  - CONF
TI  - Game-Theoretic Cooperative Lane Changing Using Data-Driven Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3640
EP  - 3647
AU  - G. Ding
AU  - S. Aghli
AU  - C. Heckman
AU  - L. Chen
PY  - 2018
KW  - game theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - multi-agent systems
KW  - road traffic
KW  - data-driven models
KW  - self-driving vehicles
KW  - autonomous driving
KW  - road-bound multivehicle systems
KW  - DRL
KW  - game theory
KW  - proactive-passive lane changing framework
KW  - Markov game
KW  - multiagent autonomous vehicle tasks
KW  - deep reinforcement learning
KW  - single-agent RL setting
KW  - Games
KW  - Markov processes
KW  - Merging
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Neural networks
KW  - Space vehicles
DO  - 10.1109/IROS.2018.8593725
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.
ER  - 

TY  - CONF
TI  - Imitation Learning for Object Manipulation Based on Position/Force Information Using Bilateral Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3648
EP  - 3653
AU  - T. Adachi
AU  - K. Fujimoto
AU  - S. Sakaino
AU  - T. Tsuji
PY  - 2018
KW  - control engineering computing
KW  - force control
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - position control
KW  - bilateral control
KW  - imitation learning method
KW  - position information
KW  - precise object manipulation
KW  - neural networks
KW  - robots
KW  - position-force information
KW  - Force
KW  - Torque
KW  - Predictive models
KW  - Manipulators
KW  - Angular velocity
KW  - Control systems
DO  - 10.1109/IROS.2018.8594489
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This study proposes an imitation learning method based on force and position information. Force information is required for precise object manipulation but is difficult to obtain because the acting and reaction forces cannot be separated. To separate the forces, we proposed to introduce bilateral control, in which the acting and reaction forces are divided using two robots. In the proposed method, two models of neural networks learn a task; to draw a line along a ruler. We verify the possibility that force information is essential to imitate the human skill of object manipulation.
ER  - 

TY  - CONF
TI  - Learning Implicit Sampling Distributions for Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3654
EP  - 3661
AU  - C. Zhang
AU  - J. Huh
AU  - D. D. Lee
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - search problems
KW  - implicit sampling distributions
KW  - motion planning
KW  - sampling-based motion planners
KW  - state space
KW  - sampling distribution
KW  - hand selected heuristics
KW  - policy-search based method
KW  - sampling-based planners
KW  - 7DOF robot arm
KW  - Planning
KW  - Task analysis
KW  - Probability distribution
KW  - Manipulators
KW  - Space exploration
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8594028
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sampling-based motion planners have experienced much success due to their ability to efficiently and evenly explore the state space. However, for many tasks, it may be more efficient to not uniformly explore the state space, especially when there is prior information about its structure. Previous methods have attempted to modify the sampling distribution using hand selected heuristics that can work well for specific environments but not universally. In this paper, a policy-search based method is presented as an adaptive way to learn implicit sampling distributions for different environments. It utilizes information from past searches in similar environments to generate better distributions in novel environments, thus reducing overall computational cost. Our method can be incorporated with a variety of sampling-based planners to improve performance. Our approach is validated on a number of tasks, including a 7DOF robot arm, showing marked improvement in number of collision checks as well as number of nodes expanded compared with baseline methods.
ER  - 

TY  - CONF
TI  - Online Temporal Calibration for Monocular Visual-Inertial Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3662
EP  - 3669
AU  - T. Qin
AU  - S. Shen
PY  - 2018
KW  - calibration
KW  - cameras
KW  - inertial systems
KW  - motion estimation
KW  - optimisation
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - monocular visual-inertial systems
KW  - accurate state estimation
KW  - intelligent applications
KW  - robot navigation
KW  - autonomous driving
KW  - virtual reality
KW  - augmented reality
KW  - visual fusion
KW  - inertial fusion
KW  - sensor fusion
KW  - visual measurements
KW  - inertial measurements
KW  - IMU states
KW  - SLAM system
KW  - feature-based optimization frameworks
KW  - Cameras
KW  - Sensors
KW  - Delays
KW  - Calibration
KW  - Visualization
KW  - Clocks
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593603
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Accurate state estimation is a fundamental module for various intelligent applications, such as robot navigation, autonomous driving, virtual and augmented reality. Visual and inertial fusion is a popular technology for 6-DOF state estimation in recent years. Time instants at which different sensors' measurements are recorded are of crucial importance to the system's robustness and accuracy. In practice, timestamps of each sensor typically suffer from triggering and transmission delays, leading to temporal misalignment (time offsets) among different sensors. Such temporal offset dramatically influences the performance of sensor fusion. To this end, we propose an online approach for calibrating temporal offset between visual and inertial measurements. Our approach achieves temporal offset calibration by jointly optimizing time offset, camera and IMU states, as well as feature locations in a SLAM system. Furthermore, the approach is a general model, which can be easily employed in several feature-based optimization frameworks. Simulation and experimental results demonstrate the high accuracy of our calibration approach even compared with other state-of-art offline tools. The VIO comparison against other methods proves that the online temporal calibration significantly benefits visual-inertial systems. The source code of temporal calibration is integrated into our public project, VINS-Mono1.
ER  - 

TY  - CONF
TI  - Modular Sensor Fusion for Semantic Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3670
EP  - 3677
AU  - H. Blum
AU  - A. Gawel
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - sensor fusion
KW  - statistical analysis
KW  - training sets
KW  - single modality segmentation results
KW  - statistical models
KW  - competitive performance
KW  - statistical fusion approaches
KW  - aligned multisensor training data
KW  - specific architecture
KW  - semantic segmentation approaches
KW  - current multisensor deep learning
KW  - real-world operations
KW  - perceptual range
KW  - robotic systems
KW  - fundamental process
KW  - modular sensor fusion
KW  - Semantics
KW  - Image segmentation
KW  - Robot sensing systems
KW  - Training
KW  - Fuses
KW  - Computer architecture
DO  - 10.1109/IROS.2018.8593786
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensor fusion is a fundamental process in robotic systems as it extends the perceptual range and increases robustness in real-world operations. Current multi-sensor deep learning based semantic segmentation approaches do not provide robustness to under-performing classes in one modality, or require a specific architecture with access to the full aligned multi-sensor training data. In this work, we analyze statistical fusion approaches for semantic segmentation that overcome these drawbacks while keeping a competitive performance. The studied approaches are modular by construction, allowing to have different training sets per modality and only a much smaller subset is needed to calibrate the statistical models. We evaluate a range of statistical fusion approaches and report their performance against state-of-the-art baselines on both realworld and simulated data. In our experiments, the approach improves performance in IoU over the best single modality segmentation results by up to 5%. We make all implementations and configurations publicly available.
ER  - 

TY  - CONF
TI  - Robust Sensor Fusion with Self-Tuning Mixture Models
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3678
EP  - 3685
AU  - T. Pfeifer
AU  - P. Protzel
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - least squares approximations
KW  - mixture models
KW  - nonlinear control systems
KW  - optimisation
KW  - robots
KW  - robust control
KW  - self-adjusting systems
KW  - sensor fusion
KW  - state estimation
KW  - robust sensor fusion
KW  - self-tuning mixture models
KW  - nonlinear state estimation
KW  - robotics
KW  - robust cost functions
KW  - nonGaussian error models
KW  - environmental changes
KW  - ageing
KW  - error distribution
KW  - state estimation process
KW  - Gaussian mixture
KW  - sensor model
KW  - standard state estimation
KW  - implicit expectation-maximization approach
KW  - distribution parameters
KW  - self-tuning algorithm
KW  - least-squares optimization framework
KW  - parameter tuning
KW  - Estimation
KW  - Robot sensing systems
KW  - Optimization
KW  - Tuning
KW  - Biological system modeling
KW  - Heuristic algorithms
KW  - Standards
DO  - 10.1109/IROS.2018.8594459
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A fundamental problem of non-linear state estimation in robotics is the violation of assumptions about the sensors' error distribution. State of the art approaches reduce the impact of these violations with robust cost functions or predefined non-Gaussian error models. Both require extensive parameter tuning and fail if the sensors' error characteristic changes over time, due to environmental changes, ageing or sensor malfunctions. We demonstrate how the error distribution itself can be part of the state estimation process. Based on an efficient approximation of a Gaussian mixture, we optimize the sensor model simultaneously during the standard state estimation. Due to an implicit expectation-maximization approach, we achieve a fast convergence without prior knowledge of the true distribution parameters. We implement this self-tuning algorithm in a least-squares optimization framework and demonstrate its real time capability on a real world dataset for satellite localization of a driving vehicle. The resulting estimation quality is superior to previous robust algorithms.
ER  - 

TY  - CONF
TI  - Trifo-VIO: Robust and Efficient Stereo Visual Inertial Odometry Using Points and Lines
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3686
EP  - 3693
AU  - F. Zheng
AU  - G. Tsai
AU  - Z. Zhang
AU  - S. Liu
AU  - C. Chu
AU  - H. Hu
PY  - 2018
KW  - computer graphics
KW  - distance measurement
KW  - filtering theory
KW  - graph theory
KW  - image matching
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - efficient stereo Visual Inertial Odometry
KW  - stereo VIO system
KW  - line features
KW  - system robustness
KW  - point features
KW  - low-texture environment
KW  - lightweight filtering-based loop closing technique
KW  - global bundle adjustment
KW  - graph optimization
KW  - current sliding window
KW  - Trifo Ironsides dataset
KW  - visual-inertial dataset
KW  - high-quality synchronized stereo camera
KW  - Cameras
KW  - Optimization
KW  - Visualization
KW  - Feature extraction
KW  - Image edge detection
KW  - Three-dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594354
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present the Trifo Visual Inertial Odometry (Trifo-VIO), a tightly-coupled filtering-based stereo VIO system using both points and lines. Line features help improve system robustness in challenging scenarios when point features cannot be reliably detected or tracked, e.g. low-texture environment or lighting change. In addition, we propose a novel lightweight filtering-based loop closing technique to reduce accumulated drift without global bundle adjustment or pose graph optimization. We formulate loop closure as EKF updates to optimally relocate the current sliding window maintained by the filter to past keyframes. We also present the Trifo Ironsides dataset, a new visual-inertial dataset, featuring high-quality synchronized stereo camera and IMU data from the Ironsides sensor [3] with various motion types and textures and millimeter-accuracy groundtruth. To validate the performance of the proposed system, we conduct extensive comparison with state-of-the-art approaches (OKVIS, VINS-MONO and S-MSCKF) using both the public EuRoC dataset and the Trifo Ironsides dataset.
ER  - 

TY  - CONF
TI  - Scale Correct Monocular Visual Odometry Using a LiDAR Altimeter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3694
EP  - 3700
AU  - R. Giubilato
AU  - S. Chiodini
AU  - M. Pertile
AU  - S. Debei
PY  - 2018
KW  - distance measurement
KW  - image sequences
KW  - mobile robots
KW  - optical radar
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - stereo visual SLAM
KW  - monocular vision
KW  - inherent scale ambiguity
KW  - LiDAR altimeter
KW  - scale correct monocular visual odometry
KW  - RGB-D methods
KW  - scale drift
KW  - keyframe basis
KW  - scale constraint
KW  - mapping algorithm
KW  - keyframe based tracking
KW  - Visual Odometry method
KW  - laser altimeter
KW  - range data
KW  - exploration vehicles
KW  - power requirements
KW  - computational load
KW  - metrological accuracy
KW  - RGB-D sensors
KW  - 3D LiDARs
KW  - metric references
KW  - sensory sources
KW  - Cameras
KW  - Laser radar
KW  - Measurement
KW  - Three-dimensional displays
KW  - Visual odometry
KW  - Visualization
KW  - Sensors
DO  - 10.1109/IROS.2018.8594096
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The inherent scale ambiguity in monocular vision is a well known issue that forces the integration of other sensory sources to obtain metric references. However, 2D or 3D LiDARs and RGB-D sensors, while guaranteeing metrological accuracy, impose a non negligible burden both in terms of computational load and power requirements limiting the feasibility of being implemented on small exploration vehicles. This paper presents a scale aware monocular Visual Odometry framework that fuses range data from a laser altimeter in order to recover and maintain a correct metric scale. The proposed Visual Odometry method consists of a keyframe based tracking and mapping algorithm using optical flow where range data serves as a scale constraint on a keyframe to keyframe basis. An optimization backend based on iSAM2 is employed in order to refine the trajectory and map estimates eliminating the scale drift without the need of performing loop closures. We demonstrate that our algorithm can obtain very similar performances to state of the art stereo visual SLAM and RGB-D methods.
ER  - 

TY  - CONF
TI  - Robust Visual-Inertial State Estimation with Multiple Odometries and Efficient Mapping on an MAV with Ultra-Wide FOV Stereo Vision
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3701
EP  - 3708
AU  - M. G. Miiller
AU  - F. Steidle
AU  - M. J. Schuster
AU  - P. Lutz
AU  - M. Maier
AU  - S. Stoneman
AU  - T. Tomic
AU  - W. Stürzl
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - distance measurement
KW  - estimation theory
KW  - image fusion
KW  - image sensors
KW  - inertial navigation
KW  - motion estimation
KW  - motion measurement
KW  - state estimation
KW  - stereo image processing
KW  - visual perception
KW  - wide-angle stereo cameras
KW  - multicopter system
KW  - inertial measurement unit
KW  - virtual pinhole cameras
KW  - independent visual odometry
KW  - vision system
KW  - sensor fusion
KW  - robust visual-inertial state estimation
KW  - ultrawide FOV stereo vision
KW  - MAV
KW  - IMU
KW  - robust visual-inertial navigation
KW  - omnidirectional 3D mapping pipeline experiment
KW  - field of view
KW  - synthesized pinhole stereo systems
KW  - motion estimation fusion
KW  - image processing
KW  - multiVO approach
KW  - Cameras
KW  - Distortion
KW  - Image resolution
KW  - Computational modeling
KW  - Navigation
KW  - Visual odometry
KW  - Hardware
DO  - 10.1109/IROS.2018.8594117
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The here presented flying system uses two pairs of wide-angle stereo cameras and maps a large area of interest in a short amount of time. We present a multicopter system equipped with two pairs of wide-angle stereo cameras and an inertial measurement unit (IMU) for robust visual-inertial navigation and time-efficient omni-directional 3D mapping. The four cameras cover a 240 degree stereo field of view (FOV) vertically, which makes the system also suitable for cramped and confined environments like caves. In our approach, we synthesize eight virtual pinhole cameras from four wide-angle cameras. Each of the resulting four synthesized pinhole stereo systems provides input to an independent visual odometry (VO). Subsequently, the four individual motion estimates are fused with data from an IMU, based on their consistency with the state estimation. We describe the configuration and image processing of the vision system as well as the sensor fusion and mapping pipeline on board the MAV. We demonstrate the robustness of our multi-VO approach for visual-inertial navigation and present results of a 3D-mapping experiment.
ER  - 

TY  - CONF
TI  - Plugo: A Scalable Visible Light Communication System Towards Low-Cost Indoor Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3709
EP  - 3714
AU  - Q. Liang
AU  - L. Wang
AU  - Y. Li
AU  - M. Liu
PY  - 2018
KW  - free-space optical communication
KW  - indoor communication
KW  - photodiodes
KW  - Plugo
KW  - novel VLC system
KW  - cheap photodiode receiver
KW  - VLC-based localization techniques
KW  - location-aware applications
KW  - scalable visible light communication system
KW  - preliminary localization result
KW  - VLC signals
KW  - low-cost offthe-shelf components
KW  - compact VLC-compatible
KW  - dedicated wireless access points
KW  - conventional RF-based approaches
KW  - low-cost indoor localization
KW  - random multiple access
KW  - Light emitting diodes
KW  - Receivers
KW  - Wireless communication
KW  - Optical transmitters
KW  - Encoding
KW  - Frequency modulation
DO  - 10.1109/IROS.2018.8594287
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor localization is critical to many location-aware applications, however, a low-cost solution with guaranteed accuracies has not yet come. Visible Light Communication (VLC-) based localization techniques are very promising to fill this gap. In this paper, we propose Plugo, a novel VLC system with random multiple access towards low-cost indoor localization. Compared to conventional RF-based approaches that rely on dedicated wireless access points as location beacons, the proposed system has the potential to deliver better accuracies with reduced cost. Specifically, we build a handful of compact VLC-compatible LED bulbs out of low-cost offthe-shelf components (around $10 total cost for each assembly) and recover VLC signals using a cheap photodiode receiver. The basic framed slotted Additive Links On-line Hawaii Area (ALOHA) is exploited to achieve random multiple access over the shared optical medium. We show its effectiveness in beacon broadcasting by experiments, and further, demonstrate a preliminary localization result with sound accuracy by using fingerprinting-based methods in a customized testbed.
ER  - 

TY  - CONF
TI  - Formally Correct Composition of Coordinated Behaviors Using Control Barrier Certificates
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3723
EP  - 3729
AU  - A. Li
AU  - L. Wang
AU  - P. Pierpaoli
AU  - M. Egerstedt
PY  - 2018
KW  - convergence
KW  - mobile robots
KW  - multi-robot systems
KW  - composition strategy
KW  - mobile robots
KW  - multirobot systems
KW  - efficient solution
KW  - low-level tasks
KW  - high-level missions
KW  - single behavior
KW  - requisite expressiveness
KW  - provably correct composition
KW  - terminal configuration
KW  - valid initial configuration
KW  - nominal control inputs
KW  - control barrier certificates
KW  - finite-time convergence control barrier functions
KW  - information-exchange network
KW  - Convergence
KW  - Robot kinematics
KW  - Task analysis
KW  - Multi-robot systems
KW  - Mobile robots
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594302
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In multi-robot systems, although the idea of behaviors allows for an efficient solution to low-level tasks, high-level missions can rarely be achieved by the execution of a single behavior. In contrast to this, a sequence of behaviors would provide the requisite expressiveness, but there are no a priori guarantees that the sequence is composable in the sense that the robots can actually execute it. In order to guarantee a provably correct composition of behaviors, Finite-Time Convergence Control Barrier Functions are introduced in this paper to guarantee the terminal configuration of one behavior is a valid initial configuration for the following one. Nominal control inputs prescribed by the behaviors are modified in a minimally invasive fashion, in order to establish the information-exchange network required by the following behavior. The effectiveness of the proposed composition strategy is validated on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Approximate Distributed Spatiotemporal Topic Models for Multi-Robot Terrain Characterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3730
EP  - 3737
AU  - K. Doherty
AU  - G. Flaspohler
AU  - N. Roy
AU  - Y. Girdhar
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - oceanographic equipment
KW  - optimisation
KW  - underwater equipment
KW  - unsupervised learning
KW  - distributed spatiotemporal topic models
KW  - real seabed imagery
KW  - multirobot underwater terrain characterization
KW  - local robot topic distributions
KW  - local topic model
KW  - multirobot distributed learning
KW  - marine robots
KW  - multirobot teams
KW  - multiple robots
KW  - single-robot topic models
KW  - learned models
KW  - unsupervised models
KW  - raw data
KW  - latent structure
KW  - Bayesian topic models
KW  - unsupervised learning techniques
KW  - multirobot terrain characterization
KW  - Adaptation models
KW  - Robot sensing systems
KW  - Spatiotemporal phenomena
KW  - Data models
KW  - Visualization
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594442
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Unsupervised learning techniques, such as Bayesian topic models, are capable of discovering latent structure directly from raw data. These unsupervised models can endow robots with the ability to learn from their observations without human supervision, and then use the learned models for tasks such as autonomous exploration, adaptive sampling, or surveillance. This paper extends single-robot topic models to the domain of multiple robots. The main difficulty of this extension lies in achieving and maintaining global consensus among the unsupervised models learned locally by each robot. This is especially challenging for multi-robot teams operating in communication-constrained environments, such as marine robots. We present a novel approach for multi-robot distributed learning in which each robot maintains a local topic model to categorize its observations and model parameters are shared to achieve global consensus. We apply a combinatorial optimization procedure that combines local robot topic distributions into a globally consistent model based on topic similarity, which we find mitigates topic drift when compared to a baseline approach that matches topics naïvely, We evaluate our methods experimentally by demonstrating multi-robot underwater terrain characterization using simulated missions on real seabed imagery. Our proposed method achieves similar model quality under bandwidth-constraints to that achieved by models that continuously communicate, despite requiring less than one percent of the data transmission needed for continuous communication.
ER  - 

TY  - CONF
TI  - On the Use of Energy Tanks for Multi-Robot Interconnection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3738
EP  - 3743
AU  - G. Riggio
AU  - C. Fantuzzi
AU  - C. Secchi
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - robust control
KW  - energy tank
KW  - multirobot systems passive interconnections
KW  - robustly stable cooperative behavior
KW  - passivity constraint
KW  - novel generalized interconnection
KW  - passive systems
KW  - coupled system
KW  - Couplings
KW  - Damping
KW  - Robots
KW  - Multi-robot systems
KW  - Robust stability
KW  - Buildings
KW  - Nonlinear dynamical systems
DO  - 10.1109/IROS.2018.8594262
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In multi-robot systems passive interconnections among agents are often exploited to achieve a desired and robustly stable cooperative behavior. Nevertheless, the passivity constraint limits the kinds of behaviors that can be achieved. In this paper, we exploit the concept of energy tank for building a novel generalized interconnection that allows to impose any kind of dynamic coupling between two passive systems in a flexible way while preserving the passivity of the overall coupled system. The proposed strategy is validated by simulations and experiments.
ER  - 

TY  - CONF
TI  - A Workbench for Quantitative Comparison of Databases in Multi-Robot Applications
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3744
EP  - 3750
AU  - R. Ravichandran
AU  - E. Prassler
AU  - N. Huebel
AU  - S. Blumenthal
PY  - 2018
KW  - database management systems
KW  - multi-robot systems
KW  - multirobot applications
KW  - robots
KW  - log files
KW  - querying features
KW  - scaling capabilities
KW  - modern databases
KW  - multirobot systems
KW  - robotic use cases
KW  - benchmarking scenarios
KW  - networked multirobot architectures
KW  - extensible workbench
KW  - benchmarking databases
KW  - Databases
KW  - Robot sensing systems
KW  - Benchmark testing
KW  - Containers
KW  - Systems architecture
DO  - 10.1109/IROS.2018.8594241
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots generate large amounts of data which need to be stored in a meaningful way such that they can be used and interpreted later. Such data can be written into log files, but these files lack the querying features and scaling capabilities of modern databases - especially when dealing with multi-robot systems, where the trade-off between availability and consistency has to be resolved. However, there is a plethora of existing databases, each with its own set of features, but none designed with robotic use cases in mind. This work presents three main contributions: (a) structures for benchmarking scenarios with a focus on networked multi-robot architectures, (b) an extensible workbench for benchmarking databases for different scenarios that makes use of Docker containers and (c) a comparison of existing databases given a set of multi-robot use cases to showcase the usage of the framework. The comparison gives indications for choosing an appropriate database.
ER  - 

TY  - CONF
TI  - Self-Assembly of a Class of Infinitesimally Shape-Similar Frameworks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3751
EP  - 3756
AU  - I. Buckley
AU  - M. Egerstedt
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - self-assembly
KW  - robots measure
KW  - frame-work
KW  - infinitesimally shape-similar frameworks
KW  - shape-similarity matrix
KW  - differential-drive robots
KW  - formation control strategies
KW  - multirobot team
KW  - infinitesimal shape-similarity
KW  - Robot sensing systems
KW  - Transmission line matrix methods
KW  - Self-assembly
KW  - Shape
KW  - Trajectory
KW  - Multi-Robot Systems
DO  - 10.1109/IROS.2018.8594381
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Formation control strategies are fundamentally impacted by the sensing modalities present in the multi-robot team. Infinitesimal shape-similarity describes frameworks for which maintaining the relative angles between robots in formation also maintains the shape up to translation, rotation, and uniform scaling; however, ensuring invariance of the formation to these motions requires that the robots measure a sufficient number of angles, which means that the topology of the frame-work must be carefully designed. In this paper, we investigate the self-assembly of a class of infinitesimally shape-similar frameworks by robots equipped with bearing-only sensors. To accomplish self-assembly, we introduce a rank condition on the shape-similarity matrix for analyzing frameworks; we then use this rank condition to show that triangulations are infinitesimally shape-similar. A graph grammar is presented to assemble triangulations, and a controller is designed to achieve self-assembly of a team of differential-drive robots.
ER  - 

TY  - CONF
TI  - Optimal Redeployment of Multirobot Teams for Communication Maintenance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3757
EP  - 3764
AU  - J. Banfi
AU  - N. Basilico
AU  - S. Carpin
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - human-robot interaction
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal redeployment
KW  - multirobot teams
KW  - communication maintenance
KW  - mobile robots
KW  - communication relays
KW  - computational complexity
KW  - Integer Linear Programming formulation
KW  - approximation hardness
KW  - Maintenance engineering
KW  - Relays
KW  - Task analysis
KW  - Complexity theory
KW  - Linear programming
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593532
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we consider the problem of maintaining and restoring connectivity among a set of agents (humans or robots) by incrementally redeploying a team of mobile robots acting as communication relays. This problem is relevant in numerous scenarios where humans and robots are jointly deployed for tasks like urban search and rescue, surveillance, and the like. In this case, as the humans move in the environment, connectivity may be broken, and consequently, robots need to reposition themselves to restore it. We study the computational complexity of the problem, also in terms of approximation hardness, and present an Integer Linear Programming formulation to compute optimal solutions. We then analyze the performance of the proposed resolution approach against a heuristic algorithm taken from the literature, and we demonstrate how our method favorably compares in terms of solution quality and scalability.
ER  - 

TY  - CONF
TI  - Visibility-Based Monitoring of a Path Using a Heterogeneous Robot Team
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3765
EP  - 3770
AU  - P. Maini
AU  - G. Gupta
AU  - P. Tokekar
AU  - P. B. Sujit
PY  - 2018
KW  - aerospace robotics
KW  - dynamic programming
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - visibility-based monitoring
KW  - heterogeneous robot team
KW  - terrain path
KW  - aerial robots
KW  - route planning
KW  - dynamic programming approach
KW  - integer linear programming solution
KW  - ground robots
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
KW  - Educational robots
KW  - Monitoring
KW  - Dynamic programming
KW  - Integrated circuits
DO  - 10.1109/IROS.2018.8593960
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of visually monitoring a terrain path using ground and aerial robots. This is a coupled problem that involves computation of a guard set for the environment and route planning for a heterogeneous group of robots through the points in the guard set. A terrain path that needs to be monitored can be transformed to generate a 1.5D terrain and robot paths can be modeled as chain visible curves to the terrain to ensure visibility. To efficiently monitor this 1.5D terrain, we present two solutions - a dynamic programming approach that finds the optimal solution but is slower and a integer linear programming solution that is faster in practice and that can take more constraints into account. We perform extensive simulations and do a comparative analysis of the two solution techniques.
ER  - 

TY  - CONF
TI  - Algorithms for Task Allocation in Homogeneous Swarm of Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3771
EP  - 3776
AU  - D. K. Jha
PY  - 2018
KW  - control system synthesis
KW  - decentralised control
KW  - feedback
KW  - Markov processes
KW  - mobile robots
KW  - multi-robot systems
KW  - task allocation
KW  - homogeneous swarm
KW  - homogeneous robots
KW  - Markov chain
KW  - agent converges
KW  - local-decentralized controllers
KW  - controller design
KW  - local-feedback
KW  - Task analysis
KW  - Markov processes
KW  - Robot kinematics
KW  - Kernel
KW  - Probabilistic logic
KW  - Q measurement
DO  - 10.1109/IROS.2018.8594052
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present algorithms for synthesizing controllers to distribute a swarm of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. Swarm is modeled as a homogeneous collection of irreducible Markov chains. States of the Markov chain represent the tasks performed by the swarm. The target state is a pre-defined distribution of agents over the states of the Markov chain (and thus the tasks). We make use of ergodicity property of irreducible Markov chains to ensure that as an individual agent converges to the desired behavior in time, the swarm converges to the target state. To circumvent the problems faced by a global controller and local/decentralized controllers alone, we design a controller by combining global supervision with local-feedback-based state level decisions. Some numerical experiments are shown to illustrate the performance of the proposed algorithms.
ER  - 

TY  - CONF
TI  - Implementation of a Versatile 3D ZMP Trajectory Optimization Algorithm on a Multi-Modal Legged Robotic Platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3777
EP  - 3782
AU  - J. Hooks
AU  - D. Hong
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulators
KW  - robot dynamics
KW  - autonomous legged personal helper robot
KW  - enhanced dynamics
KW  - multimodal legged robotic platform
KW  - versatile 3D ZMP trajectory optimization algorithm
KW  - stable locomotion
KW  - multimodal robotic platform
KW  - 2D zero moment point trajectory optimization
KW  - manipulation
KW  - light weight robotic system
KW  - Legged locomotion
KW  - Foot
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Task analysis
DO  - 10.1109/IROS.2018.8593968
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a multi-functioning light weight robotic system, the Autonomous Legged Personal Helper Robot with Enhanced Dynamics (ALPHRED), capable of both locomotion and manipulation. In addition, we extended a 2D zero moment point (ZMP) trajectory optimization (TO) algorithm to a 3D implementation. As well as adding the acceleration of the center of mass to the TO cost in order to smooth out the motion of the robot during trajectories with support polygons that do not intersect. By implementing this versatile TO algorithm on a multi-modal robotic platform we showed that many different forms of stable locomotion and manipulation were possible including a dynamic 0.7 m/s trot gait.
ER  - 

TY  - CONF
TI  - Hybrid Contact Preintegration for Visual-Inertial-Contact State Estimation Using Factor Graphs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3783
EP  - 3790
AU  - R. Hartley
AU  - M. G. Jadidi
AU  - L. Gan
AU  - J. Huang
AU  - J. W. Grizzle
AU  - R. M. Eustice
PY  - 2018
KW  - distance measurement
KW  - graph theory
KW  - inertial navigation
KW  - legged locomotion
KW  - motion estimation
KW  - optimisation
KW  - sensor fusion
KW  - state estimation
KW  - factor graphs
KW  - robotic state estimation
KW  - sensor fusion framework
KW  - legged robots
KW  - visual encoder
KW  - inertial encoder
KW  - visual-inertial odometry
KW  - visual-inertial navigation systems
KW  - cassie-series robot
KW  - nonlinear optimization
KW  - motion capture system
KW  - preintegration theory
KW  - Kinematics
KW  - Legged locomotion
KW  - Optimization
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593801
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The factor graph framework is a convenient modeling technique for robotic state estimation where states are represented as nodes, and measurements are modeled as factors. When designing a sensor fusion framework for legged robots, one often has access to visual, inertial, joint encoder, and contact sensors. While visual-inertial odometry has been studied extensively in this framework, the addition of a preintegrated contact factor for legged robots has been only recently proposed. This allowed for integration of encoder and contact measurements into existing factor graphs, however, new nodes had to be added to the graph every time contact was made or broken. In this work, to cope with the problem of switching contact frames, we propose a hybrid contact preintegration theory that allows contact information to be integrated through an arbitrary number of contact switches. The proposed hybrid modeling approach reduces the number of required variables in the nonlinear optimization problem by only requiring new states to be added alongside camera or selected keyframes. This method is evaluated using real experimental data collected from a Cassie-series robot where the trajectory of the robot produced by a motion capture system is used as a proxy for ground truth. The evaluation shows that inclusion of the proposed preintegrated hybrid contact factor alongside visual-inertial navigation systems improves estimation accuracy as well as robustness to vision failure, while its generalization makes it more accessible for legged platforms.
ER  - 

TY  - CONF
TI  - Stable, Autonomous, Unknown Terrain Locomotion for Quadrupeds Based on Visual Feedback and Mixed-Integer Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3791
EP  - 3798
AU  - M. S. Ahn
AU  - H. Chae
AU  - D. W. Hong
PY  - 2018
KW  - convex programming
KW  - integer programming
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - quadratic programming
KW  - robot vision
KW  - visual feedback
KW  - mixed-integer convex optimization
KW  - complete motion planning approach
KW  - quadruped locomotion
KW  - convex polygons
KW  - potentially feasible foothold regions
KW  - feasible destination planner
KW  - extracted polygons
KW  - footstep planner
KW  - mass trajectory planner
KW  - path planner
KW  - stable terrain locomotion
KW  - autonomous terrain locomotion
KW  - unknown terrain locomotion
KW  - quadrupeds
KW  - feasible goal position
KW  - ALPHRED
KW  - Optimization
KW  - Trajectory
KW  - Legged locomotion
KW  - Planning
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594015
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a complete motion planning approach for quadruped locomotion across an unknown terrain using a framework based on mixed-integer convex optimization and visual feedback. Vision data is used to find convex polygons in the surrounding environment, which acts as potentially feasible foothold regions. Then, a goal position is initially provided, which the best feasible destination planner uses to solve for an actual feasible goal position based on the extracted polygons. Next, a footstep planner uses the feasible goal position to plan a fixed number of footsteps, which may or may not result in the robot reaching the position. The center of mass (COM) trajectory planner using quadratic programming is extended to solve for a trajectory in 3D space while maintaining convexity, which reduces the computation time, allowing the robot to plan and execute motions online. The suggested method is implemented as a policy rather than a path planner, but its performance as a path planner is also shown. The approach is verified on both simulation and on a physical robot, ALPHRED, walking on various unknown terrains.
ER  - 

TY  - CONF
TI  - Leg Design to Enable Dynamic Running and Climbing on BOBCAT
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3799
EP  - 3806
AU  - M. P. Austin
AU  - J. M. Brown
AU  - C. A. Young
AU  - J. E. Clark
PY  - 2018
KW  - legged locomotion
KW  - manipulator dynamics
KW  - robot kinematics
KW  - design tool
KW  - leg configuration
KW  - multimodal platform BOBCAT
KW  - leg design
KW  - design process
KW  - leg morphology
KW  - manipulator community
KW  - dynamic workspace
KW  - template dynamics
KW  - dynamic climbing
KW  - dynamic running
KW  - Legged locomotion
KW  - Dynamics
KW  - Couplings
KW  - Force
KW  - Kinematics
KW  - Foot
DO  - 10.1109/IROS.2018.8594355
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The design process for leg morphology has taken much of its inspiration from the manipulator community, including the concept of maximizing the workspace of a design. In this paper, we define the concept of Effective Dynamic Workspace, which examines the subset of the overall workspace capable of achieving the desired template dynamics. With this new design tool, the leg configuration of a new multi-modal platform BOBCAT is examined and refined. With the refined design, BOBCAT is able to achieve speeds of 2m/s while running and 0.17m/s while climbing a vertical wall.
ER  - 

TY  - CONF
TI  - Learning Hardware Dynamics Model from Experiments for Locomotion Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3807
EP  - 3814
AU  - K. Chen
AU  - S. Ha
AU  - K. Yamane
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - locomotion optimization
KW  - hardware compatibility
KW  - hardware-compatible motion plan
KW  - linear inverted pendulum
KW  - ZMP
KW  - hardware dynamics model learning
KW  - zero moment point
KW  - LIP
KW  - center of mass
KW  - quadruped
KW  - Hardware
KW  - Optimization
KW  - Dynamics
KW  - Legged locomotion
KW  - Data models
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8593804
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The hardware compatibility of legged locomotion is often illustrated by Zero Moment Point (ZMP) that has been extensively studied for decades. One of the most popular models for computing the ZMP is the linear inverted pendulum (LIP) model that expresses ZMP as a linear function of the center of mass(COM) and its acceleration. In the real world, however, it may not accurately predict the true ZMP of hardware due to various reasons such as unmodeled dynamics and differences between simulation model and hardware. In this paper, we aim to improve the theoretical ZMP model by learning the real hardware dynamics from experimental data. We first optimize the motion plan using the theoretical ZMP model and collect COP data by executing the motion on a force plate. We then train a new ZMP model that maps the motion plan variable to the actual ZMP and use the learned model for finding a new hardware-compatible motion plan. Through various locomotion tasks of a quadruped, we demonstrate that motions planned for the learned ZMP model are compatible on hardware when those for the theoretical ZMP model are not. Furthermore, experiments using ZMP models with different complexities reveal that overly complex models may suffer from over-fitting even though they can potentially represent more complex, unmodeled dynamics.
ER  - 

TY  - CONF
TI  - Iterative Learning of Energy-Efficient Dynamic Walking Gaits
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3815
EP  - 3820
AU  - F. H. Kong
AU  - I. R. Manchester
PY  - 2018
KW  - iterative methods
KW  - learning systems
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - energy-efficient dynamic walking gaits
KW  - dynamic walking robots
KW  - lifelike locomotion
KW  - efficient gaits
KW  - Iterative Learning Control
KW  - control signal
KW  - periodic reference
KW  - terminal ILC
KW  - dynamic walking robot gaits
KW  - final foot placement
KW  - energy efficiency
KW  - phase-indexed TILC
KW  - energy-efficient walking motion
KW  - time-indexed TILC
KW  - Legged locomotion
KW  - Computational modeling
KW  - Data models
KW  - Foot
KW  - Planning
KW  - Convergence
DO  - 10.1109/IROS.2018.8593548
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic walking robots have the potential for efficient and lifelike locomotion, but computing efficient gaits and tracking them is difficult in the presence of under-modeling. Iterative Learning Control (ILC) is a method to learn the control signal to track a periodic reference over several attempts, augmenting a model with online data. Terminal ILC (TILC), a variant of ILC, allows other performance objectives to be addressed at the cost of ignoring parts of the reference. However, dynamic walking robot gaits are not necessarily periodic in time. In this paper, we adapt TILC to jointly optimize final foot placement and energy efficiency on dynamic walking robots by indexing by a phase variable instead of time, yielding “phase-indexed TILC” (θ - TILC). When implemented on a five-link walker in simulation, θ- TILC learns a more energy-efficient walking motion compared to traditional time-indexed TILC.
ER  - 

TY  - CONF
TI  - Bipedal Hopping: Reduced-Order Model Embedding via Optimization-Based Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3821
EP  - 3828
AU  - X. Xiong
AU  - A. D. Ames
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - legged locomotion
KW  - Lyapunov methods
KW  - nonlinear control systems
KW  - quadratic programming
KW  - robot dynamics
KW  - robot kinematics
KW  - springs (mechanical)
KW  - stability
KW  - bipedal hopping
KW  - reduced-order model embedding
KW  - optimization-based control
KW  - spring-mass model
KW  - spring stiffness
KW  - damping
KW  - trajectory optimization
KW  - control Lyapunov function
KW  - CLF-QP
KW  - nonlinear feedback control law
KW  - dynamic jumping behaviors
KW  - bipedal robots
KW  - 3D bipedal robot Cassie
KW  - quadratic program
KW  - Legged locomotion
KW  - Springs
KW  - Robot kinematics
KW  - Kinematics
KW  - Hip
KW  - Jacobian matrices
DO  - 10.1109/IROS.2018.8593547
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design and validation of controlling hopping on the 3D bipedal robot Cassie. A spring-mass model is identified from the kinematics and compliance of the robot. The spring stiffness and damping are encapsulated by the leg length, thus actuating the leg length can create and control hopping behaviors. Trajectory optimization via direct collocation is performed on the spring-mass model to plan jumping and landing motions. The leg length trajectories are utilized as desired outputs to synthesize a control Lyapunov function based quadratic program (CLF-QP). Centroidal angular momentum, taking as an addition output in the CLF-QP, is also stabilized in the jumping phase to prevent whole body rotation in the underactuated flight phase. The solution to the CLF-QP is a nonlinear feedback control law that achieves dynamic jumping behaviors on bipedal robots with compliance. The framework presented in this paper is verified experimentally on the bipedal robot Cassie.
ER  - 

TY  - CONF
TI  - An Actuator Design Criterion to Maximize Physical Balance Recovery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2829
EP  - 2836
AU  - J. J. M. Driessen
AU  - R. Featherstone
AU  - A. E. Gkikakis
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - gears
KW  - legged locomotion
KW  - mechanical stability
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - wheels
KW  - legged robot
KW  - hip joint
KW  - balance recovery motion
KW  - actuator design
KW  - physical balance recovery
KW  - electric motor
KW  - gear reduction
KW  - wheel pendulum
KW  - robot design
KW  - Actuators
KW  - Torque
KW  - Robot kinematics
KW  - Friction
KW  - Electrical resistance measurement
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8593729
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper first presents a formula to predict the largest balance disturbance from which a legged robot can recover without taking a step. It then presents an actuator design criterion derived from this formula that maximizes the robot's ability to recover. In this study, it is assumed that the robot is using a single major joint (e.g, a hip joint) to perform its balance recovery movement, and that the actuator consists of an electric motor and reduction gear. It is also assumed that the robot's support polygon is sufficiently small that it can be approximated as a point, and that the balance recovery motion is essentially planar, so that a 2-D analysis remains valid in 3-D. Finally, it is assumed that, for the purpose of studying balance recovery motion, the robot can be approximated by a reaction wheel pendulum. The theory has been tested experimentally on a robot designed to be good at balancing, and was found to agree closely with experimental results.
ER  - 

TY  - CONF
TI  - Vessel Pose Estimation for Obstacle Avoidance in Needle Steering Surgery Using Multiple Forward Looking Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3845
EP  - 3852
AU  - V. Virdyawan
AU  - F. R. Y Baena
PY  - 2018
KW  - biomedical optical imaging
KW  - blood vessels
KW  - brain
KW  - collision avoidance
KW  - Doppler measurement
KW  - image motion analysis
KW  - laser applications in medicine
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - pose estimation
KW  - steering systems
KW  - surgery
KW  - percutaneous procedures
KW  - hemorrhage
KW  - vessel motion
KW  - tissue bulk motion
KW  - Doppler signals
KW  - multiple forward looking sensors
KW  - preoperative imaging modalities
KW  - vessel pose estimation
KW  - needle steering systems
KW  - robotic assisted needle insertion process
KW  - vessel detection
KW  - biologically inspired steerable needle
KW  - laser Doppler flowmetry
KW  - life threatening complications
KW  - percutaneous interventions
KW  - needle steering surgery
KW  - obstacle avoidance
KW  - Needles
KW  - Probes
KW  - Phantoms
KW  - Sensors
KW  - Doppler effect
KW  - Gold
KW  - Grey matter
DO  - 10.1109/IROS.2018.8594198
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - During percutaneous interventions in the brain, puncturing a vessel can cause life threatening complications. To avoid such a risk, current research has been directed towards the development of steerable needles. However, there is a risk that vessels of a size which is close to or smaller than the resolution of commonly used preoperative imaging modalities (0.59 × 0.59 × 1 mm) would not be detected during procedure planning, with a consequent increase in risk to the patient. In this work, we present a novel ensemble of forward looking sensors based on laser Doppler flowmetry, which are embedded within a biologically inspired steerable needle to enable vessel detection during the insertion process. Four Doppler signals are used to classify the pose of a vessel in front of the advancing needle with a high degree of accuracy (2° and 0.1 mm RMS errors), where relative measurements between sensors are used to correct for ambiguity. By using a robotic assisted needle insertion process, and thus a precisely controlled insertion speed, we also demonstrate how the setup can be used to discriminate between tissue bulk motion and vessel motion. In doing so, we describe a sensing apparatus applicable to a variety of needle steering systems, with the potential to eliminate the risk of hemorrhage during percutaneous procedures.
ER  - 

TY  - CONF
TI  - Trajectory Optimization of Robot-Assisted Endovascular Catheterization with Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3875
EP  - 3881
AU  - W. Chi
AU  - J. Liu
AU  - M. E. M. K. Abdelaziz
AU  - G. Dagnino
AU  - C. Riga
AU  - C. Bicknell
AU  - G. Yang
PY  - 2018
KW  - blood vessels
KW  - cardiovascular system
KW  - catheters
KW  - diagnostic radiography
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - path planning
KW  - patient treatment
KW  - surgery
KW  - telerobotics
KW  - catheter manipulation
KW  - learning-based robotic catheterization platform
KW  - dynamic movement primitives
KW  - catheterization tasks
KW  - customized robotic manipulator
KW  - robotic trajectories
KW  - catheter tip
KW  - hands-on robotic navigation platforms
KW  - trajectory optimization
KW  - robot-assisted endovascular catheterization
KW  - flow simulations
KW  - X-ray radiation reduction
KW  - path integral RL
KW  - path integral reinforcement learning
KW  - Robots
KW  - Catheters
KW  - Task analysis
KW  - Catheterization
KW  - Surgery
KW  - Trajectory
KW  - Navigation
DO  - 10.1109/IROS.2018.8593421
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Emerging robot-assisted endovascular intervention has the potential to reduce X-ray radiations to the operator while enhancing the stability and dexterity of catheter manipulation. Supervised and shared autonomy of endovascular procedures could add further improvements in reduced fatigue and cognitive workloads of the operator, higher success rates of cannulation and improved surgical outcomes. However, robotic path planning for endovascular procedure is challenging due to complex and non-linear flow dynamics inside the vasculature. This paper presents a learning-based robotic catheterization platform addressing those challenges, this approach incorporates path integral reinforcement learning (RL) framework based on dynamic movement primitives (DMP) to enhance catheterization tasks by a customized robotic manipulator. The robotic trajectories were optimized through RL in order to avoid unwanted contacts between the catheter tip and the vessel wall. The proposed methods can adapt to different flow simulations, vascular models, and catheterization tasks. The quality of the catheterization was evaluated with performance metrics. The results show significant refinement of catheter paths by the proposed approach, resulting in shorter overall lengths and fewer contact forces, which can potentially reduce risks in endothelial wall damages, embolization, and stroke. The results support the development of robotic path planning for endovascular procedures as well as designing intelligent, hands-on robotic navigation platforms.
ER  - 

TY  - CONF
TI  - ArthroSLAM: Multi-Sensor Robust Visual Localization for Minimally Invasive Orthopedic Surgery
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3882
EP  - 3889
AU  - A. Marmol
AU  - P. Corke
AU  - T. Peynot
PY  - 2018
KW  - biomedical optical imaging
KW  - cameras
KW  - endoscopes
KW  - image sensors
KW  - Kalman filters
KW  - medical image processing
KW  - medical robotics
KW  - orthopaedics
KW  - SLAM (robots)
KW  - surgery
KW  - image feedback
KW  - ArthroSLAM
KW  - Simultaneous Localisation and Mapping system
KW  - SLAM system
KW  - external camera
KW  - robotic arm
KW  - minimally invasive arthroscopic surgery
KW  - minimally invasive orthopedic surgery
KW  - robotic orthopedic surgical assistant
KW  - knee section
KW  - human cadaver knee joint
KW  - Extended Kalman Filter framework
KW  - arthroscope holder
KW  - intraarticular space
KW  - Cameras
KW  - Robot vision systems
KW  - Visualization
KW  - Reliability
DO  - 10.1109/IROS.2018.8593501
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Minimally invasive arthroscopic surgery is a very challenging procedure that requires the manipulation of instruments in limited intraarticular space using distorted and sometimes uninformative images. Localizing the arthroscope reliably and at all times w.r.t. surrounding tissue is of fundamental importance to prevent unintended injury to patients. However, even highly-trained surgeons can struggle to localize the arthro-scope using poor image feedback. In this paper, we propose and demonstrate for the first time a visual Simultaneous Localisation and Mapping (SLAM) system, termed ArthroSLAM, capable of robustly and reliably localizing an arthroscope inside a human knee joint. The proposed system fuses the information obtained from the arthroscope, an external camera mounted on an arthroscope holder, and the odometry of a robotic arm manipulating the scope, in an Extended Kalman Filter framework. Also for the first time, we implement five alternative strategies for localization and compare them to our method in a realistic setup with a human cadaver knee joint. ArthroSLAM is shown to outperform the alternative strategies under various challenging conditions, localizing reliably and at all times with a mean Relative Pose Error of up to 1.4mm and 0.7°. Additional experiments conducted with degraded odometry data also validate the robustness of the method. An initial evaluation of the sparse map of a knee section computed by our method exhibits good morphological agreement. All results suggest that ArthroSLAM is a viable component for the robotic orthopedic surgical assistant of the future.
ER  - 

TY  - CONF
TI  - I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3897
EP  - 3904
AU  - J. Stolzenwald
AU  - W. W. Mayol-Cuevas
PY  - 2018
KW  - gaze tracking
KW  - human-robot interaction
KW  - mobile robots
KW  - robot vision
KW  - robot autonomy
KW  - attention model
KW  - user attention
KW  - handheld robot collaboration
KW  - handheld tool
KW  - task knowledge
KW  - tool-mounted gaze tracking system
KW  - video game setup
KW  - cooperative handheld robot
KW  - Task analysis
KW  - Robot kinematics
KW  - Tools
KW  - Tracking
KW  - Gaze tracking
KW  - Estimation
DO  - 10.1109/IROS.2018.8594184
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users.
ER  - 

TY  - CONF
TI  - Recursive Bayesian Human Intent Recognition in Shared-Control Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3905
EP  - 3912
AU  - S. Jain
AU  - B. Argall
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - human-robot interaction
KW  - inference mechanisms
KW  - mobile robots
KW  - telerobotics
KW  - recursive Bayesian human intent recognition
KW  - shared-control robotics
KW  - human-robot collaboration
KW  - mathematical formulation
KW  - assistive teleoperation
KW  - recursive Bayesian filtering approach models
KW  - nonverbal observations
KW  - contextual observations
KW  - goal-directed actions
KW  - human inference
KW  - robot motion
KW  - autonomy intent inference performance
KW  - shared-control operation
KW  - probabilistic reasoning
KW  - human intent recognition
KW  - human agents behavior
KW  - probabilistic fusion
KW  - Robots
KW  - Bayes methods
KW  - Task analysis
KW  - Hidden Markov models
KW  - Uncertainty
KW  - Mathematical model
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593766
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Effective human-robot collaboration in shared control requires reasoning about the intentions of the human user. In this work, we present a mathematical formulation for human intent recognition during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user. In addition to contextual observations, we model and incorporate the human agent's behavior as goal-directed actions with adjustable rationality to inform the underlying intent. We examine human inference on robot motion and furthermore validate our approach with a human subjects study that evaluates autonomy intent inference performance under a variety of goal scenarios and tasks, by novice subjects. Results show that our approach outperforms existing solutions and demonstrates that the probabilistic fusion of multiple observations improves intent inference and performance for shared-control operation.
ER  - 

TY  - CONF
TI  - A Novel Shared Position Control Method for Robot Navigation Via Low Throughput Human-Machine Interfaces
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3913
EP  - 3920
AU  - D. A. Sinyukov
AU  - T. Padır
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - user interfaces
KW  - wheelchairs
KW  - shared position control method
KW  - inference parallelization
KW  - low throughput human-machine interfaces
KW  - robot navigation
KW  - robotic wheelchair
KW  - circular massless holonomic robot
KW  - robot motion
KW  - single switch interface
KW  - brain-computer interface
KW  - Navigation
KW  - Wheelchairs
KW  - Mobile robots
KW  - Position control
KW  - Linear systems
KW  - Throughput
DO  - 10.1109/IROS.2018.8593921
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we analyze systems with low throughput human-machine interfaces (such as a brain-computer interface, single switch interface) from the controls perspective. We develop some principles for performance improvement in such systems based on the parallelization of inference and robot motion. The proposed principles are used to design a novel shared position control to navigate a circular massless holonomic robot in a known environment. The system is implemented in simulation and integrated with a real robotic wheelchair. Robot experiments demonstrated the viability of the proposed navigation method in various modes of operation.
ER  - 

TY  - CONF
TI  - Robot Identification and Localization with Pointing Gestures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3921
EP  - 3928
AU  - B. Gromov
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2018
KW  - distance measurement
KW  - gesture recognition
KW  - mobile robots
KW  - multi-robot systems
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - mobile robot
KW  - multirobot scenarios
KW  - robot identification and localization
KW  - gesture pointing
KW  - robot odometry frame
KW  - inertial measurement unit
KW  - IMU
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Solid modeling
KW  - Manipulators
KW  - Drones
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594174
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a novel approach to establish the relative pose of a mobile robot with respect to an operator that wants to interact with it; we focus on scenarios in which the robot is in the same environment as the operator, and is visible to them. The approach is based on comparing the trajectory of the robot, which is known in the robot's odometry frame, to the motion of the arm of the operator, who, for a short time, keeps pointing at the robot they want to interact with. In multi-robot scenarios, the same approach can be used to simultaneously identify which robot the operator wants to interact with. The main advantage over alternatives is that our system only relies on the robot's odometry, on a wearable inertial measurement unit (IMU), and, crucially, on the operator's own perception. We experimentally show the feasibility of our approach using real-world robots.
ER  - 

TY  - CONF
TI  - Establishing Appropriate Trust via Critical States
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3929
EP  - 3936
AU  - S. H. Huang
AU  - K. Bhatia
AU  - P. Abbeel
AU  - A. D. Dragan
PY  - 2018
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robots
KW  - trusted computing
KW  - appropriate trust
KW  - critical states
KW  - learned neural network policies
KW  - end-users
KW  - mental model
KW  - robot learning
KW  - Autonomous automobiles
KW  - Cognitive science
KW  - Task analysis
KW  - Automobiles
KW  - Reinforcement learning
KW  - Entropy
DO  - 10.1109/IROS.2018.8593649
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.
ER  - 

TY  - CONF
TI  - Learned Hand Gesture Classification Through Synthetically Generated Training Samples
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3937
EP  - 3942
AU  - K. Lindgren
AU  - N. Kalavakonda
AU  - D. E. Caballero
AU  - K. Huang
AU  - B. Hannaford
PY  - 2018
KW  - gesture recognition
KW  - human computer interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - user input mechanism
KW  - intuitive control
KW  - physical constraints
KW  - ambient electrical interference
KW  - light interference
KW  - sound interference
KW  - semantic information
KW  - logical information
KW  - communication channel
KW  - human-machine interfaces
KW  - hand gesture recognition
KW  - synthetic hand gesture dataset generation
KW  - physical data collection
KW  - real-world hand gesture classifier
KW  - learned hand gesture classification
KW  - synthetically generated training samples
KW  - natural component
KW  - human-human communication
KW  - rule-based classification schemes
KW  - data-driven deep learning approaches
KW  - Training
KW  - Gesture recognition
KW  - Training data
KW  - Real-time systems
KW  - Engines
KW  - Task analysis
KW  - Computer vision
DO  - 10.1109/IROS.2018.8593433
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Hand gestures are a natural component of human-human communication. Simple hand gestures are intuitive and can exhibit great lexical variety. It stands to reason that such a user input mechanism can have many benefits, including seamless interaction, intuitive control and robustness to physical constraints and ambient electrical, light and sound interference. However, while semantic and logical information encoded via hand gestures is readily decoded by humans, leveraging this communication channel in human-machine interfaces remains a challenge. Recent data-driven deep learning approaches are promising towards uncovering abstract and complex relationships that manual and direct rule-based classification schemes fail to discover. Such an approach is amenable towards hand gesture recognition, but requires myriad data which can be collected physically via user experiments. This process, however, is onerous and tedious. A streamlined approach with less overhead is sought. To that end, this work presents a novel method of synthetic hand gesture dataset generation that leverages modern gaming engines. Furthermore, preliminary results indicate that the dataset, despite being synthetic and requiring no physical data collection, is both accurate and rich enough to train a real-world hand gesture classifier that operates in real-time.
ER  - 

TY  - CONF
TI  - Interaction System Based on an Avatar Projected on a Pyramidal Display
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3943
EP  - 3948
AU  - D. Loza Matovelle
AU  - S. Marcos
AU  - E. Zalama
AU  - J. Gómez García Bermejo
PY  - 2018
KW  - avatars
KW  - computer animation
KW  - control engineering computing
KW  - emotion recognition
KW  - face recognition
KW  - human computer interaction
KW  - human-robot interaction
KW  - middleware
KW  - mobile robots
KW  - operating systems (computers)
KW  - telerobotics
KW  - pyramidal structure
KW  - expression generator subsystem
KW  - avatar animations
KW  - avatar teleoperation
KW  - emotion displaying ability
KW  - interaction system
KW  - pyramidal display
KW  - social robot behavioral architecture
KW  - back projection subsystem
KW  - three-dimensional avatar
KW  - robotic operating system
KW  - three dimensional virtual head
KW  - 3D avatar
KW  - facial action coding system
KW  - ROS middleware
KW  - user interface
KW  - avatars gestural ability
KW  - Avatars
KW  - Animation
KW  - Robots
KW  - Solid modeling
KW  - Face
KW  - Shape
KW  - Bones
DO  - 10.1109/IROS.2018.8593740
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper an interaction system based on a three dimensional virtual head projected onto a pyramidal display is proposed. The proposed system makes use of a social robot behavioral architecture already developed in our lab, which allows us to interchange developments between our robotic realizations and the 3D avatar. The overall system is divided into two parts: back projection subsystem and expression generator subsystem. The back projection subsystem projects a three-dimensional avatar onto a pyramidal structure in order to achieve a sensation of depth and realism. The expression generator subsystem carries out the avatar animations using shape keys and bones, following the Facial Action Coding System (FACS). The system consists in several nodes that are integrated in ROS middleware (Robotic Operating System), and includes a user interface that makes the avatar teleoperation easier (the package is avaible in github public respository). In order to evaluate the expressiveness of the system, two sets of experiments have been performed: one to analyze the avatar's gestural ability, that is, its capability to perform expressions that can be identified by an observer, and a second experiment to measure the emotion displaying ability in terms of valence and arousal.
ER  - 

TY  - CONF
TI  - Multimotion Visual Odometry (MVO): Simultaneous Estimation of Camera and Third-Party Motions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3949
EP  - 3956
AU  - K. M. Judd
AU  - J. D. Gammell
AU  - P. Newman
PY  - 2018
KW  - cameras
KW  - computer vision
KW  - image motion analysis
KW  - image segmentation
KW  - image sensors
KW  - image sequences
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - stereo image processing
KW  - dynamic scene
KW  - multimotion visual odometry pipeline
KW  - MVO
KW  - dynamic objects
KW  - motion capture system
KW  - simultaneous estimation
KW  - third-party motions
KW  - computer vision
KW  - previous work
KW  - moving camera
KW  - largely static environment
KW  - segment
KW  - tracking-by-detection
KW  - motion constraints
KW  - planar motion
KW  - SE motion
KW  - scene flow
KW  - unconstrained motions
KW  - camera motions
KW  - object tracking
KW  - stereo/RGB-D camera
KW  - multimodal visual odometry pipeline
KW  - Cameras
KW  - Motion segmentation
KW  - Tracking
KW  - Dynamics
KW  - Trajectory
KW  - Estimation
KW  - Image segmentation
DO  - 10.1109/IROS.2018.8594213
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Estimating motion from images is a well-studied problem in computer vision and robotics. Previous work has developed techniques to estimate the motion of a moving camera in a largely static environment (e.g., visual odometry) and to segment or track motions in a dynamic scene using known camera motions (e.g., multiple object tracking). It is more challenging to estimate the unknown motion of the camera and the dynamic scene simultaneously. Most previous work requires a priori object models (e.g., tracking-by-detection), motion constraints (e.g., planar motion), or fails to estimate the full SE (3) motions of the scene (e.g., scene flow). While these approaches work well in specific application domains, they are not generalizable to unconstrained motions. This paper extends the traditional visual odometry (VO) pipeline to estimate the full SE (3) motion of both a stereo/RGB-D camera and the dynamic scene. This multimotion visual odometry (MVO) pipeline requires no a priori knowledge of the environment or the dynamic objects. Its performance is evaluated on a real-world dynamic dataset with ground truth for all motions from a motion capture system.
ER  - 

TY  - CONF
TI  - Underwater Surveying via Bearing Only Cooperative Localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3957
EP  - 3963
AU  - H. Damron
AU  - A. Q. Li
AU  - I. Rekleitis
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - underwater vehicles
KW  - bearing only cooperative localization
KW  - aerial ground vehicles
KW  - underwater domain
KW  - robotic applications
KW  - cave mapping
KW  - marine archeology surveying
KW  - fresh water
KW  - South Carolina
KW  - visibility conditions
KW  - depth sensors
KW  - magnetic sensors
KW  - inertial sensors
KW  - Florida
KW  - Barbados
KW  - Cameras
KW  - Springs
KW  - Robot kinematics
KW  - Lakes
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593431
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.
ER  - 

TY  - CONF
TI  - Ego-Motion Estimate Corruption Due to Violations of the Range Flow Constraint
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3964
EP  - 3969
AU  - C. D. Monaco
AU  - S. N. Brennan
PY  - 2018
KW  - distance measurement
KW  - image sensors
KW  - image sequences
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - range sensors
KW  - visual odometry techniques
KW  - dense geometry-based visual odometry methods
KW  - range flow constraint equation
KW  - temporal derivatives
KW  - spatial derivatives
KW  - range images
KW  - ego-motion estimation
KW  - range data
KW  - Mathematical model
KW  - Cameras
KW  - Optical imaging
KW  - Visual odometry
KW  - Optical sensors
KW  - Adaptive optics
KW  - Optical variables control
DO  - 10.1109/IROS.2018.8594131
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual odometry methods are increasingly being used to estimate a vehicle's ego-motion from range data due to the decreasing cost of range sensors and the impressive speed and accuracy of visual odometry techniques. Dense geometry-based visual odometry methods are fundamentally based on the range flow constraint equation, an equation which depends on the temporal and spatial derivatives of range images. However, these derivatives are calculated with the fundamental assumption that the range flow is magnitude-limited. When scaling this method for faster vehicles, this assumption could be violated, invaliding the range flow constraint equation and thus corrupting the resulting ego-motion estimates. This paper derives the sensor, motion, environment, and sampling frequency conditions that would mathematically violate the range flow constraint. This information is useful for defining the operational limits of dense geometry-based visual odometry methods.
ER  - 

TY  - CONF
TI  - Semi-Supervised SLAM: Leveraging Low-Cost Sensors on Underground Autonomous Vehicles for Position Tracking
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3970
EP  - 3977
AU  - A. Jacobson
AU  - F. Zeng
AU  - D. Smith
AU  - N. Boswell
AU  - T. Peynot
AU  - M. Milford
PY  - 2018
KW  - cameras
KW  - learning (artificial intelligence)
KW  - mining
KW  - mining industry
KW  - mobile robots
KW  - object tracking
KW  - robot vision
KW  - SLAM (robots)
KW  - ORB-SLAM2
KW  - ground map locations
KW  - deep learning
KW  - position tracking
KW  - operational underground mining vehicles
KW  - single camera localization
KW  - map creation
KW  - mine environment
KW  - mining companies
KW  - underground environment
KW  - SemiSupervised SLAM
KW  - underground autonomous vehicles
KW  - low-cost sensors
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Measurement
KW  - Grounding
KW  - Visual odometry
KW  - Lighting
DO  - 10.1109/IROS.2018.8593750
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work presents Semi-Supervised SLAM - a method for developing a map suitable for coarse localization within an underground environment with minimal human intervention, with system characteristics driven by real-world requirements of major mining companies. This work leverages existing information common within a mining environment - namely a surveyed mine map - which is used to sparsely ground map locations within the mine environment, increasing map accuracy and allowing localization within a global frame. Map creation utilizes a low cost camera sensor and minimal user information to produce a map which can be used for single camera localization within a mining environment. We evaluate the localization capabilities of the proposed approach in depth by performing data collection on operational underground mining vehicles within an active underground mine and by simulating occlusions common to the environment such as dust and water. The proposed system is capable of producing maps which have an average localization error 2.5 times smaller than the next best performing method ORB-SLAM2, comparable localization performance to a state-of-the-art deep learning approach (which is not a feasible solution due to both compute and training requirements) and is robust to simulated environmental obscurants.
ER  - 

TY  - CONF
TI  - An Automatic Tracked Robot Chain System for Gas Pipeline Inspection and Maintenance Based on Wireless Relay Communication
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3978
EP  - 3983
AU  - W. Zhao
AU  - M. Kamezaki
AU  - K. Yoshida
AU  - M. Konno
AU  - A. Onuki
AU  - S. Sugano
PY  - 2018
KW  - cooperative communication
KW  - inspection
KW  - mobile robots
KW  - protocols
KW  - automatic tracked robot chain system
KW  - gas pipeline inspection
KW  - wireless relay communication
KW  - wireless signal attenuation
KW  - relay communication node
KW  - wireless application layer communication protocol
KW  - relay transmission efficiency
KW  - RSSI-based coordinated movement
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Pipelines
KW  - Relays
KW  - Wireless communication
KW  - Wireless sensor networks
DO  - 10.1109/IROS.2018.8593550
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Gas pipeline requires to be inspected regularly for leakages caused by natural disaster. Robots are widely used for pipeline inspection since they are more convenient than manual inspection. Several problems, however, exist due to the restriction by complex pipe networks. The most significant one is limited inspection range caused by restriction of cable length or wireless signal attenuation. In this paper, we proposed a concept of wireless relay communication to assist robot to extend the inspection range, and we newly developed a tracked robot chain system. In this system, each robot serves as a relay communication node. Leakage information of pipes are transmitted via these relay nodes. To ensure the stability of relay communication between adjacent robots, we adopted RSSI (received signal strength indication)-based evaluation method for cooperative and coordinated movement of robot chain system. Moreover, wireless application layer communication protocol (WALCP) was used to increase the stable performance of wireless relay communication. Each robot can self-navigate based on distance measurement module, which enables robots to pass through an elbow junction. Multiple experiments to evaluate relay transmission efficiency, RSSI-based cooperative movement, and comprehensive performance were conducted. Results revealed that our proposed system could realize relatively accurate relay transmission and RSSI-based coordinated movement.
ER  - 

TY  - CONF
TI  - Multi-Level Bayesian Decision-Making for Safe and Flexible Autonomous Navigation in Highway Environment
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 3984
EP  - 3990
AU  - D. Iberraken
AU  - L. Adouane
AU  - D. Denis
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - decision making
KW  - navigation
KW  - probability
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - traffic engineering computing
KW  - TSLDN
KW  - driving situation assessment
KW  - vehicle navigation task
KW  - control architecture
KW  - probabilistic decision-making
KW  - safe navigation
KW  - flexible autonomous navigation
KW  - highway environment
KW  - MCA
KW  - multi-level Bayesian decision-making
KW  - multi-controller architecture
KW  - two-sequential level decision network
KW  - Extended Time-To-Collision metric
KW  - ETTC metric
KW  - Predicted Inter-Distance Profile
KW  - Safety
KW  - Decision making
KW  - Navigation
KW  - Trajectory
KW  - Road transportation
KW  - Uncertainty
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8593565
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes an overall Multi-Controller Architecture (MCA) for safe and flexible navigation of autonomous navigation, under uncertainties in highway use-cases. In addition to the details given about the main modules (and their interactions) composing the proposed MCA, an important focus of the paper is made on the definition of a robust Two-Sequential Level Decision Network (TSLDN), which uses both: Extended Time-To-Collision (ETTC) metric and a new definition of a specific Predicted Inter-Distance Profile (PIDP, between vehicles during lane changes maneuvers) in order to estimate the maneuvers risks. The TSLDN is utilized for: the driving situation assessment, decision-making and for safety retrospection over the current maneuver risk. It allows us to have the best decision to achieve the vehicle navigation task while maximizing its safety. Several simulation results show the good performance of the overall proposed control architecture, mainly in terms of efficiency to handle probabilistic decision-making even for very risky scenarios.
ER  - 


